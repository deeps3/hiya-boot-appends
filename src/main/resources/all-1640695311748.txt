


---------------------------------------------------------------------------------------------------------------
---------------------------------------------第一部分：架构总览 start------------------------------------------
---------------------------------------------------------------------------------------------------------------

@ jiagoushi定义
1)评估系统需求，比如说性能，可用性，可靠，扩展性，安全，可修改性等
2)给出开发规范，比如基本开发规范，该用什么设计模式，DDD规范等
3)搭建核心构架，比如技术栈，服务治理等
4)澄清技术细节，培训的方式梳理细节，或者提问方式，编写相应的设计文档
5)迭代技术方案，
6)扫清主要难点，系统不断演化，途中遇到各种问题，比如内存溢出，锁等待等
7)预研技术方向，比如新技术的引入和预研，系统优化


@ 具体工作：
根据业务模型搭建和设计高性能，高可用，可扩展，可伸缩，安全的软件架构（逻辑jg,开发jg,运行jg,数据jg,物理jg),解
决开发中各种架构问题。
系统不断优化，技术选型和攻关，核心代码编写；
需求不断细化的工程中校正整体的架构设计，以及详细模块拆分设计评审。
营造技术学习氛围，带领团队提升开发效率与质量，加强技术标准及规范
参与讨论公司产品发展方向，完整的规划和把握产品研发架构方向。


@ 技术和业务重要性
)技术是为了解决业务问题的，只有在实现业务的前提下，技术的存在才有意义；
2)没有技术，业务就无法被虚拟化，生产效率就很难有效提升；
3)结论：技术和业务同等重要，相辅相成，缺一不可。


@ 架构5视图
(1)逻辑架构-逻辑架构的重点是考虑软件功能性需求。
子系统，功能模块，功能，交互，界面，接口
(2)开发架构-开发架构重点关注的是开发编码实现方面的问题。
分层架构，模块划分，开发技术，开发规范，软件质量
(3)运行架构-运行架构关注的不再是全局而是局部，着重关注那些关键点与难点，常常需要技术攻关与预研。
控制流、通讯机制、资源争用、锁机制、同步异步、并发串行、响应时间、吞吐量、容量设计
(4)数据架构--数据架构不仅仅要考虑开发中涉及到的数据库，实体模型，也要考虑物理架构中数据存储的设计。
分布式存储，ER图，关系数据库，NOSQL数据库
(5)物理架构--物理架构主要考虑硬件选择和拓扑结构，软件到硬件的映射，软硬件的相互影响。
网络拓扑、安全机制、可靠性、可伸缩性、分布式部署


@ 架构风格和架构模式
1)架构风格：架构风格是在更高级的层面上，逻辑级别的架构复用，系统家族
管道过滤器风格、面向对象风格、分布式风格、SOA风格、微服务风格
2)架构模式：架构模式是一个通用的、可重用的解决方案，用以解决特定上下文内的某个常见的架构问题，是一个解决方
案。
client-server模式、MVC模式、三层C/S模式


@ 架构图
1)单体架构图，MVC架构
2)分布式架构图
逻辑架构图，业务流程图，ER图，用例图，活动图，状态图，序列图，泳道图
开发架构图，类图，包图，组件图
进程架构图，进程，线程，运行时，线上问题
数据架构图，主从同步，读写分离，哨兵模式
物理架构图，部署图，拓扑图，网络图
3)微服务架构图
DNS+负载均衡器f5,lvs,nginx,+网关+微服务
注册中心+监控中心+链路追踪
基础服务：安全，异常


@ 技术要求
1)熟悉分布式、高性能架构和开发技术，如分布式应用开发、数据分布式管理和同步等；
2)精通JAVA EE系统架构，深刻理解JAVA EE架构的优缺点，具有大型基于JAVA EE体系结构的项目规划、系统架构设计
发经验，精通JAVA EE设计模式；
3)深刻理解软件系统架构，精通面向对象分析设计方法，逻辑能力佳，具有丰富的OOA、OOD、OOP、UML及SOA经验
精通RationalRose、PowerDesigner等设计工具
4)技术视野广阔，具有良好的前瞻性，思路清晰、逻辑性强，对移动支付和互联网支付的相关技术具有优秀的领悟力和前瞻
性，有较强的业务分析能力；
5)良好的沟通能力、团队合作精神和服务意识；认真负责、具有高度责任感和敬业精神；
6)对于性能瓶颈可以给出最优的切片，集群和分布式服务器搭建解决方案
7)理解面向对象分析和设计的基本原则，熟悉常用的设计模式，熟悉UML;
8)熟悉Java的多线程，线程与线程，进程与进程的通信机制；
9)精通系统优化，对系统优化原理有深入的理解。对系统端到端性能优化有丰富的实践经验，熟悉各种远程本地Cachet组件
尤其是Memcached,Redis),对Cache服务器集群架构有丰富的经验；


@ 素质要求
1)全局思维
从业务、市场，到技术实现；
从软件的过去、到现在、到将来；
从外部客户，到内部研发；
从软件研发，到硬件部署；
从功能实现，到运行效率
2)战略思维
在所在行业的发展战略；
在业务领域的发展战略；
在技术方向的发展战略；
在潜在市场的发展战略。
3)前瞻思维
市场趋势的发展动向；
前沿技术的发展动向；
竞争对手的发展动向；
合作伙伴的发展动向。
4)抽象思维
各项业务需求：抽象成功能模块
各项功能的实现：抽象成软件架构。
5)逆向思维
假如不实现会怎样？
假如没搞定会怎样？
假如没有它会怎样？
假如被延期会怎样？


@ 架构师分类
1)解决方案架构师与客户探讨业务需求，将业务、市场，与技术、产品结合起来，为客户提供解决他们需求的方案。
2)系统架构师
也称应用架构师。最终确认和评估系统需求，并将业务转换为技术，为研发人员制订核心框架与技术规范为
研发工作澄清技术细节并扫清技术障碍。
3)业务架构师
业务架构其实已经开始脱离技术层面了，但是它要求架构师有跨越多系统的大局观，去整合和组织不同系统
的技术平台与交互模式。其实这个职位的未来也就是CIO了。
)网络架构师一个优秀的网络架构师必须有足够的网络技术基底，并且它的关注点也是系统的基础架构。比如说如果搭建
并优化集群环境，如果构建基于云计算的系统应用与部署等等。它对于像淘宝、腾讯这样的互联网公司是极其重要的。
5)移动架构师
移动互联网的迅猛发展横向和纵向都细分出了很多新的职责和岗位，移动架构师的职责和作用日益重要，既
要整体和全局考虑整个前后端的软件系统架构，又要重点深入移动客户端的架构设计的方方面面。
6)前端架构师
这也是移动互联网的迅猛发展而细分出来的新的职责和岗位，这里的前端特指网站开发中的前端，主要考虑
前端呈现层的设计(HTML/CSS/JS/AJAX/RIA/.),跨浏览器设计等等。
7)……


@ 架构设计考虑因素
1 基本因素设计
1)扩展性设计，横向扩展和纵向扩展
2)可用性设计，高可用，心跳检查
3)可靠性设计，容错和检错，恢复
4)一致性设计，分布式事物
5)负载均衡设计，nginx.f5,lvs
6)过载保护设计，熔断，隔离
7)协议设计，二进制协议，比如netty.自定义协议；本文协议，文本类型的

2 接入层架构设计
1)DNS轮询，nginx
2)动静态分离，nginx
3)静态化，静态化是解决减轻网站压力，提高网站访问速度的常用方案
4)反向代理，nginx)LVS,负载均衡
5)FS,分布式文件系统
6)CDN,将这些缓存服务器分布到用户访问相对集中的地区或网络中。

3 逻辑层架构设计
1)连接池，Durid
2)串行化技术，Serializable
3)批量写入
4)配置中心，zookeeper:分布式配置中心
5)去中心化，减轻中心的负担
6)通讯机制PRC同步
7)通讯机制RMI同步
8)通讯机制MQ异步，Kafka
9)通讯机制Cron异步，Quartz
10)双工架构，允许二台设备间同时进行双向资料传输。一般的电话、手机就是全双工的系统，因为在讲话时同时也可以听到
对方的声音。
11)主从同步，Slave将masterE的binary log复制到其中继日志。首先slave开始一个工作线程(I/O),1/O线程在master.上打开
一个普通的连接，然后开始binlog dump process。
12)读写分离，读写分离就是在主服务器上修改，数据会同步到从服务器，从服务器只能提供读取数据，不能写入，实现备份
的同时也实现了数据库性能的优化，以及提升了服务器安全
13)高可用缓存优化，Redis

4 代码结构SOLID设计
1)单一职责原则(Single Responsibility Principle-SRP)
理解：对于一个类而言，应该仅有一个引起它变化的原因。说白了就是，不同的类具备不同的职责，各施其责。这就好比一个
团队，大家分工协作，互不影响，各做各的事情。
应用：当我们做系统设计时，如果发现有一个类拥有了两种的职责，那就问自己一个问题：可以将这个类分成两个类吗？如果
真的有必要，那就分吧。千万不要让一个类干的事情太多！
2)开闭原则(Open Closed Principle-OCP)
理解：简言之，对扩展开放，对修改封闭。换句话说，可以去扩展类，但不要去修改类。
应用：当需求有改动，要修改代码了，此时您要做的是，尽量用继承或组合的方式来扩展类的功能，而不是直接修改类的代
码。当然，如果能够确保对整体架构不会产生任何影响，那么也没必要搞得那么复杂了，直接改这个类吧。
3)里氏替换原则(Liskoy Substitution Principle-LSP)
理解：父类能够替换子类，但子类不一定能替换父类。也就是说，在代码中可以将父类全部替换为子类，程序不会报错，也不
会在运行时出现任何异常，但反过来却不一定成立。
应用：在继承类时，务必重写(Override)父类中所有的方法，尤其需要注意父类的protected方法（它们往往是让您重写
的)，子类尽量不要暴露自己的public方法供外界调用。
4)最少知识原则(Least Knowledge Principle-LKP)
理解：尽量减少对象之间的交互，从而减小类之间的耦合。简言之，一定要做到：低耦合，高内聚。
应用：在做系统设计时，不要让一个类依赖于太多的其他类，需尽量减小依赖关系，否则，您死都不知道自己怎么死的。
5)接口隔离原则(Interface Segregation Principle-ISP)
理解：不要对外暴露没有实际意义的接口。也就是说，接口是给别人调用的，那就不要去为难别人了，尽可能保证接口的实用
性吧。她好，我也好。
应用：当需要对外暴露接口时，需要再三斟酌，如果真的没有必要对外提供的，就删了吧。一旦您提供了，就意味着，您不
要多做一件事情，何苦要给自己找事做呢。
6)依赖倒置原则(Dependence Inversion Principle-DIP)
理解：应该面向接口编程，不应该面向实现类编程。面向实现类编程，相当于就是论事，那是正向依赖（正常人思维）；面向
接口编程，相当于通过事物表象来看本质，那是反向依赖，即依赖倒置（程序员思维）。
应用：并不是说，所有的类都要有一个对应的接口，而是说，如果有接口，那就尽量使用接口来编程吧。


@ 架构设计原则
1)可（异地）部署和就近路由接入，破除单点故障；
(可分布，可调度的原则)
2)数据上报和监控平台；
(用户行为数据，系统性能监控数据，系统异常和业务相关数据等的上报)
3)数据分级存储原则：单内存cache存储，内存cache+异步更新，内存cache+同步更新；
(从三个纬度分析用户行为模型，决定相关数据的存储策略：1，能忍受用户数据的丢失吗？2，能忍受数据的非及时性吗？数
据的读写比例分布如何？)
4)动静分离原则；
(能静态化尽量静态化，在代码和进程部署上，在DNS层上做好动静分离的系统设计准备)
5)轻重分离原则；
(保持接入和业务处理的分离，接入尽量轻量化，使得系统具有很好的吞吐量，处理尽量异步化，使得可以平滑扩展)
RaZER
6)破除服务依赖原则：同一DC的其他服务对系统的影响，第三方调用系统接口的隔离和过载保护，依赖第三方服务的
监控和安全保护原则等。
7)柔性可用原则：
(处理好异常情况下的灰度体验，区分好关键处理路径和非关键路径，而系统设计要尽量把关键路径转换成非关键路径)
8)能异步的尽量异步原则：
(通过内存管道，操作流水等技术进行拼接各个处理模块)
9)灰度原则；
(灰度发布策略是根据用户号码段，用户ip段，还是用户i2等级，用户所在城市等进行灰度升级，保证系统的平滑迭代)
10)异常的快速响应和一键切换原则；
(IDC断电？系统切换到正常的成本是多少？时间呢？需要几个人操作？牛的系统可以一个人在管理后台按一个按钮就可以切
换，再按一下就可以切换回来)
11)有损服务原则；
(用低成本提供海量的服务原则)
12)一切简单化处理的原则，真真假假，假假真真！


@ 架构优化
1) 一台全能的服务器
把应用系统网站、数据库、文件系统等都在一台服务器下，这样形成了最初级的服务器，一般是非常简单的应用，使用的用户
量相当有限。一些企业的门户网站或刚上线使用的系统会采用这样的方式进行部署。
2) 系统网站、数据库和文件系统不同的服务器进行部署
这个有先考虑的是把数据库和系统网站分离出来部署到不同的服务器。很多的系统网站很长一段时间都是把系统网站和文件服
务器放在一起，把数据库分离出去后发现网站的性能没有多大的提升时，才考虑把文件系统从系统站点分离出去，减少读取文
件带来了网络开销和○读取。在配置服务是需要根据服务器所承载的职责用途分配不同性能的硬件设备，如文件服务器更需要
考虑的是硬盘。
3) 集群的方式进行部署
当随着业务发展和数据的不断积累，大量的数据和高并发用户的集中访问，在高性能的一台服务器也无法承受进行处理，即使
是把系统网站、数据库和文件系统分离到不同的服务器中。作为web服务器是直接面向用户，所有的用户都需要从web服务器
作为入口进入系统，承担着大量的用户请求，此时需要考虑的是web服务器的压力问题，一般的处理方式在web服务器前面部
署负载均衡服务器调用用户请求，根据设置不同的调度策略把用户的请求分发到各个wb服务器中，通常负载均衡和反向代理
服务器部署在同一台服务器，到后续才会把他们分开。常见的负载均衡的硬件有F⑤，软件产品如HAProxy、LVS、Nginx。当
然，这种情况下需要考虑的是用户的请求用可能会分发到不同的服务器中（负载均衡可以进行配置），保证不同请求间的服务端
的使用状态(Session、Application、ViewState、Cache)一致性成为需要解决的问题，因此保证是系统是无状态的这个问题
就不是问题了。我们要考虑Cache-一致性的问题，则把Cachet部署到独立的一台或多台缓存服务器中，现在流行的是Redis,也
可考虑使用memerycache、AppFabric.。可以参考是Docker。
4) 根据业务拆分成多个应用服务器，web服务与应用进行分离
一般Web服务和应用都会部署在同一台服务器上，此时则需要把应用从web服务器中独立出来，并且根据业务模块把各个应用
部署到不同的服务器中，如数据查询应用、用户管理应用、报表管理应用等。b服务器只处理用户请求和用户数据交互的呈
现，应用服务器处理业务逻辑处理和数据读写。应用分布到多个服务器中遵循的规则是每个应用可以承担起相当独立的运作，
减少相互间的依赖。不同应用间的通讯可以使用消息队列(Q)的方式实现，也可以是SOA服务、微服务的方式提供。数据库也
可以按照此方式进行拆分。同时把web服务器中的所有js、CSS、imagei都分离出来部署到静态文件服务器中。
5)海量数据的查询
数据的不断积累，到了海量数据时，则会造成数据集查询的性能瓶颈。通常使用的方式是osq数据库和搜索引擎来解决查询
的问题。系统的数据不是一定要使用我们常规的方式放到关系型数据库中，把一下常使用查询的数据或数据库的索引数据放到
nosql中。现在使用比较多的是Redisi和Mongodb,搜索引擎有lucene和支持.net版本的lucene.net。也有基于lucene内核实现
的Solr、ElasticSearch等搜索引擎，这些都可支持集群的方式部署。
6)系统之间的交互
随着业务的不断深入和拓展，会出现系统群的存在，而系统系统之间的通讯和数据交互也会频繁的进行，在此时就会出现服务
层。服务层是为各个客户端（调用方）提供数据服务，在应用层之上。net一般服务器层使用的是WCF、WebService和Restful方
式的NebAP,数据传输实体一般都定义成DTO。在我们服务器设计层面上的考虑保证数据事务的一致性，例如事务补偿
的机制。对每个服务器记录在特定时间段中负荷、资源使用情况、访问量和连接数等参数数据，随时可以掌握每台服务器的运
行情况，根据每个业务模块的服务器使用情况进行调度，保证所有的服务器的压力达到相对的均衡。
7)CDN和数据仓库
CDN需要考虑两个方面的内容存储问题，一个是内容源的集中存储，另一个是内容在Cache节点中的分布式存储。它借助于建
立索引、缓存、流分裂、组播(Multicast)等技术，将内容发布或投递到距离用户最近的远程服务点(POP)处。整体性的网
络负载均衡技术，通过内容路由器中的重定向(DNS)机制，在多个远程POP上均衡用户的请求，以使用户请求得到最近内容
源的响应。根据内容的可用性、服务器的可用性以及用户的背景，在POP的缓存服务器上，利用应用层交换、流分裂、重定向
(ICP、WCCP)等技术，智能地平衡负载流量。通过内部和外部监控系统，获取网络部件的状况信息，测量内容发布的端到端
性能（如包丢失、延时、平均带宽、启动时间、帧速率等），保证网络处于最佳的运行状态。可以搭建几个中心，中心之间的
数据需要保持同步。
8)云
一般企业可以考虑使用云来部署系统，现在比较流行的是Azue、阿里云、亚马逊等多会提供服务，如阿里云，ECS提供虚拟服
务器、SLB提供负载均衡、RDS提供数据库服务、OSS提供存储服务、DRDS提供分布式数据服务MaxCompute提供大数据服
务、RocketMQ提供MQ、OCS提供分布式缓存服务，还有很多的服务。这样企业可以根据自身的情况可以购买对应的服务，从
而节省成本。


@ 架构5要素概述
1)高性能（响应时间，并发数，吞吐量(TPS.QPS),性能测试、负载测试、压力测试）
2)高可用/高可靠（高可用的服务器（集群，选主，避免单点故障），高可用的服务（容错，熔断，限并发，降级，幂等性），高可
用数据(CAP原理))
3)可扩展（代码扩展性，新功能加入无需推翻整体架构）
4)可伸缩(K8 S scale)
5)安全性（系统侧(https.sgl注入，服务tokeni认证，XSS,cxsf),用户侧（认证和鉴权）)





---------------------------------------------------------------------------------------------------
---------------------------------@@@@@架构要素详解---------------------------------
1)  **分布式***
微服务是架构设计方式，分布式是系统部署方式，两者概念不同。
微服务重在解耦合，使每个模块都独立。分布式重在资源共享与加快计算机计算速度
微服务架构（服务治理、服务注册与发现、网关路由、负载均衡、容错、熔断、降级、限流、容灾、服务追踪）
分布式配置(apollo,spring cloud config,热推送)
分布式事务（两阶段提交、MQ最终一致性、seata)、
分布式调度(cronsun、Elastic-job、saturn、lts、TBSchedule、xxl-job)、
分布式互斥（集中式算法/令牌环算法/分布式锁）
高可用（心跳上报、双机热备，多机热备、一致性哈希解决集群新增或移除节点、选举算法决选选主、限流、负载均衡）
分布式存储、分布式计算

2)**高并发**
@ 高并发数据库场景
1单库时代，
2读写分离：传统关系型数据库足以应对，读（从）写（主）分离（最好使用数据库中间件mycat.DBproxy等），一主多从，主
从同步（毫秒级别的延迟），读写锁保证数据安全，分布式缓存提升效率；
3解决单点主库宕机：双主备份，都为主，都为从。
4数据量继续增长，读写分离成为高并发的瓶颈，分表分库通常用mycat,但是统计不方便。
5数据量继续增长，考虑nosql数据库。
读多写少考虑读写分离或分表分库
读少写多考虑读双主备份或分表分库
读多写多考虑分表分库
分表分库：先垂直在水平。
垂直分库（一个库变成多个库）、水平分库（一个表存储不同数据库）、垂直分表（一个表变成多个表）、水平分表（一个表
存储不同表)

@ 高并发超卖
生成订单、减扣库存、用户支付这三个基本的阶段；
下单减库存：数据库○压力大，恶意下单少卖单子
支付减库存：不能避免并发操作数据库磁盘，当库存减为零的时候很多用户发现抢到的订单支付不了了，这也就是所谓的
“超卖”。
预扣库存：预扣库存，消息创建订单，订单都有效期过后回收库存。
本地redis减库存，解决事务阻塞；
不
集群每台机.器木地reis减库存解决离并发求·
预扣库存：预扣库存，消息创建订单，订单都有效期过后回收库存。
本地redis减库存，解决事务阻塞；
集群每台机器本地redis减库存，解决高并发请求：
远程统一减库存容错方案，解决宕机，机票分布不均问题。

@ 秒杀系统设计
设计难点：并发量大，应用、数据库都承受不了。另外难控制超卖。
请求拦截在系统上游，CDN,限流，答题，缓存，异步，乐观锁
业务隔离：把秒杀做成一种营销活动，卖家要参加秒杀这种营销活动需要单独报名，从技术上来说，卖家报名后对我们来说就
是已知热点，当真正开始时我们可以提前做好预热。
系统隔离：系统隔离是运行时的隔离，可以通过分组部署的方式和另外99%分开。秒杀还申请了单独的域名，目的也是
让请求落到不同的集群中。
数据隔离：秒杀所调用的数据大部分都是热数据，比如会启用单独cache集群或MySQL数据库来放热点数据，目前也是不想
0.01%的数据影响另外99.99%。
预防缓存穿透、雪崩等等问题，主要的流量都落在了缓存数据库上，需要针对缓存数据库的高可用作保障。

@ 100亿高并发支撑
O)通用方面：垂直扩展单机cu和内存，集群多活高可用，集群扩缩容
1)前端方面：F5(100亿PV)+nginxi高可用，限流，CDN处理，nginxi静态代理，负载均衡
)网关方面：必须是高可用，限流，白名单机制，接口限流，过滤器，认证、授权，审计以及访问控制，负载均衡，技术选
型一定是nio.epoll,如Netty.,Go语言的goroutine加channel。
3)服务方面：水平扩展机器数量，缓存加速（注意缓存穿透击穿雪崩），微服务，限流，限并发，服务降级，服务熔断，代
码优化，消息中间件，软负载均衡，并发处理
4)存储方面：分表分库，读写分离，读多写少，nosql,es或者大数据
以10亿v算，每天8w6秒，白天有4w3秒，算出qps是10y/4w3=20000+;按照二八原则，80%的业务量在20%的时间里完成
峰值gps=80000+;
以一台4c8g机器，tomcat压测单机能抗住1000+的QPS,需要80000/1000=80台机器；
F5,硬件层，物理层，80亿py,100万并发，一般是F5+nginx集群；
LVS,OS层，网络层，达到F5的60%，利用linux的内核进行，一般是LVS+nginx集群（此时nginx不用keepalive,如果nginv挂了，Lvs会帮你到其他可用的nginx.上)；
Nginx,软件层，应用层，py千万左右。

为何不用lvs负载均衡而是nginx?
所有的请求和响应流量都会经过nginx;但是使用vs时，仅请求流量经过vs的网络，响应流量由后端服务器的网络返回。
LVS+nginx集群既能避免单nginxl的流量集中瓶颈，又能避免单lvs一次请求失败
1)DNS+Server,根据域名对一台服务器ip,非高可用(server挂了整体挂)，扩展性差（吞吐量）
2)DNS+Server集群，根据域名轮询多台服务器ip,非高可用(server挂了局部影响)，外网ip暴露
3)DNS+Nginx+Server集群，非高可用(nginx挂了)
4DNS+Nginx+Keepalived+Server集群，资源利用率50%，吞吐量超过nginxl的性能扛不住
5)DNS+F5/LVS+Keepalived+Nginx集群+Gateway+Server集群，F5/LVS自动保证Nginx的高可用，几乎99%的场景OK了，但是100亿pv如何？
6)终极：DNS轮询+F5/LVS集群+Keepalived+Nginx集群+Gateway+Server集群，扩展多个F5/LVS,每个VIP对应一个Ng集群，不同的Nginx集群可以负载同一个域名，

1)通过DNS轮询来线性扩展入口lVS/F5层的性能，保证水平扩展，一个vS/F5的PV是100亿
2)通过keepalived来保证高可用；
3)通过lvs来扩展多个nginx,保证多个nginxl同时工作并且高可用；
4)通过nginx来做负载均衡，业务七层路由


3)***高性能**
系统优化：内存，cu,网络，集群，负载均衡，扩展，JVM参数
架构优化：缓存，异步，MQ,横向扩展
程序优化：内存，stringbuffer,避免递归，懒加载的策略，循环内不要不断创建对象引用


4)**高可用
米米**
通过DNS轮询来线性扩展入口vS/F5层的性能，保证水平扩展，一个IVS/F5的PV是100亿
通过keepalived来保证高可用；
通过lvs来扩展多个nginx,保证多个nginxl同时工作并且高可用；
通过nginx来做负载均衡，业务七层路由；
@搭建高可用系统；高可用就是保证系统在几乎任务时候都要有正常运行，功能正常。
第一，提高系统自身的性能。（防缓存穿透雪崩；代码优化；）
第二，提高系统的防御能力。（主备集群模式防止单点；限流MQ削峰防止后端压力过大；熔断降级机制；容灾异地部署）
第三，冗余-自动故障转移能力，
典型互联网分布式架构的高可用，通过每一层的冗余+自动故障转移来综合实现的
(1)客户端层：典型调用方是浏览器browser或者手机应用APP;
(2)反向代理层：系统入口，反向代理，nginx;措施：nginx+keepalive或者lvs+nginx集群
(3)站点应用层：实现核心应用逻辑，返回html或者json,前后端分离，这里是前端；措施：web-server冗余+自动故障转移
(4)服务层：如果实现了服务化，就有这一层，后端；
(5)数据-缓存层：缓存加速访问存储，措施：sentinelD哨兵机制或者redis集群模式
(6)数据-数据库层：数据库固化数据存储
数据库层高可用：
当前市场上常见的容灾模式可分为同城容灾、异地容灾、双活数据中心、两地三中心；
两地三中心：是指同城双中心加异地灾备一种商用容灾备份解决方案；
两地是指同城、异地；
三中心是指生产中心、同城容灾中心、异地容灾中心；
冷备主备~主备的另一个站点完全是不承载任何流量的；
所谓“双活”或“多活”数据中心，区别于传统数据中心和灾备中心的模式，前者多个或两个数据中心都处于运行当中
运行相同的应用，具备同样的数据，能够提供跨中心业务负载均衡运行能力，实现持续的应用可用性和灾难备份能力，
所以称为“双活”和“多活”；后者是生产数据中心投入运行，灾备数据中心处在不工作状态，只有当灾难发生时，生产数
据中心瘫痪，灾备中心才启动。
双活~其实就是两个站点，同时承载业务流量，可以根据用户D、地域或者其他业务属性也决定怎么分担流量，当一个站点故
障时，可以快速（分钟级）切换到另一个站点，理想情况下，对业务基本是无损或者非常小的。

高可用脑裂：
当两（多）个节点同时认为自已是唯一处于活动状态的服务器从而出现争用资源的情况，这种争用资源的场景即是所谓的“脑
裂”(split-brain)或”区间集群“(partitioned cluster)。
在“双机热备”高可用(HA)系统中，当联系2个节点的“心跳线”断开时，本来为一整体、动作协调的HA系统，就分裂成为2个
独立的个体。由于相互失去了联系，都以为是对方出了故障，
2个节点上的日A软件像“裂脑人”一样，“本能”地争抢“共享资源”、争起“应用服务”，就会发生严重后果：或者共享资源被瓜
分、2边“服务”都起不来了；或者2边“服务”都起来了，但同时读写“共享存储”，导致数据损坏。

脑裂预防措施：
添加冗余的心跳线，例如双线条线。
在A中设计“智能”锁。正在服务的一方只在发现心跳线全部断开（察觉不到对端）时才启用磁盘锁。平时就不上锁了。
设置仲裁机制，设置参考P(如网关IP),当心跳线完全断开时，2个节点都各自ping一下参考IP,不通则表明断点就出右
端，主动放弃竞争，让能够ping通参考IP的一端去起服务。



5)**可扩展**
@ 搭建可扩展系统
主要是开闭原则，基础设施不需要经常变更，应用之间较少依赖或耦合，可以对需求变更快速响应。
主要手段是采用设计模式架构，低耦合，不要使模块之间的强依赖，开闭原则，复用性。
把一个大系统分解为个低耦合的子模块的能力，这些子模块包含横向的业务模块与纵向的基础技术模块。
可扩展的数据结构，nosgl,哈希分片扩展。
使用分布式服务构建可复用的业务平台，分布式消息队列解耦；


6)***高内聚松耦合*****
@ 高内聚低耦合
高内聚是指一个软件模块是由相关性很强的代码组成，只负责一项任务，也就是常说的单一责任原则。比如只提供一个对外接口。
低内聚的模块设计的坏处有：首先模块的功能不单一，模块的职责不明确，比较松散，更有甚者是完成不相关的功能。这样的
设计往往是不可取的。
一个完整的系统，模块与模块之间，尽可能的使其独立存在，采用设计模式外观，消息队列（发布订阅）解耦。
高内聚是封装的概念，同一类操作封装到一起，低耦合是○C的体现，依赖注入。
高内聚：有a,b,c,d,e,5个方法，a,b,c,d,e分别可以实现一个功能，a和b一起工作又可以实现另一功能。
模板方法设计模式高内聚；



@ 六大设计原则SOLID
(1)单一职责，不同的类具备不同的职责，各施其责，避免上帝类的出现。
(2)开闭原则，对扩展开放，对修改关闭。
(3)接口隔离，用多个专门的接口，而不使用庞大臃肿总接口，客户端不应该依赖他不需要的接口
(4)依赖倒转，依赖抽象而不是实现类，面向接口编程
(5)最少知道，降低耦合度，类与类耦合（依赖、关联、组合、聚合）度越大，当一个类发生改变时，对另一个类的影响也
越大。
成员变量、方法参数、方法返回值中的类为直接的朋友，而出现在局部变量中的类则不是直接的朋友。也就是说，陌生的类
最好不要作为局部变量的形式出现在类的内部。
举例：总公司调用分公司类拿到分公司的员工信息，从逻辑上讲总公司只与他的分公司耦合就行了，与分公司的员工并没
有任何联系，这样设计显然是增加了不必要的耦合。
(6)里氏替换，在继承类时，务必重写(Override)父类中所有的方法，尤其需要注意父类的protected方法（它们往往不
计您重写的)子类尽量不要暴露自己的public方法供外界调用
(7)高内聚低耦合，高内聚是封装的概念，同一类操作封装到一起，低耦合是0C的体现，依赖注入。
高内聚：有a,b,c,d,e,5个方法，a,b,c,d,e分别可以实现一个功能，a和b一起工作又可以实现另一功能。



@ 提升研发效率
经验总结的复用：脚手架、模板、组件，不重复造轮子；
做好设计，评审过程发现问题，避免返工。
团队气氛，协同作战，防止单兵，及时寻求帮助，30分钟之内没头绪；
责任田明确，防止共同管辖区，推卸责任；
技术培训提升能力和技能；



@ 技术问题以及解决
相同class加载顺序，sit出现问题
动态代理的classloader,使用接口的取代当前线程
分布式事务和本地事务混用，异步模式
报表缓慢，查询中间表并且同步


@ 微服务和单体
单体优势：开发/测试/部署简单
单体劣势：项目过度复杂维护性差；开发速度缓慢，修改其中部分功能整个应用都要部署；技术栈不易拓展阻碍创新；业务不
易拓展改一点功能影响整体架构；没有服务治理；构建和部署的时间增加；
可靠性差（其中一个问题导致应用的崩溃）；
微服务优势：大项目可以持续交付；易于维护；服务可以独立扩展；可以灵活的采用最新的技术
微服务劣势：服务的拆分；服务通信；分布式事务；




---------------------------------------------------------------------------------------------------
---------------------------------@@@@@云原生技术详解---------------------------------
@ 云原生技术
https/www.cnblogs.com/ufei33180/p/13462895.html超详细
与生俱来的，应用原生被设计为在云上以最佳的方式运行，充分发挥云的优势；
云的支持应该让的应用更加关注业务，云+原生的业务开发，非业务需求都交给云去实现，一些优秀的产品就是尽可能的把
你的平台变得原生；
把服务治理从代码层(springcloud和dubbo)移到容器层(k8s,istio,servicemeth)
在后Kubernetes时代，服务网格(Service Mesh)技术已完全取代了使用软件库实现网络运维（例如Hystrix断路器）的方
式。
如果说Kubernetes对Spring Cloud开了第一枪，那么Service Mesh就是Spring Cloud的终结者。
云原生是容器技术(KS编排)、微服务（网格服务无入侵）、DevOps(持续集成/持续部署/继续交付)组成。
云原生为用户指定了一条低负担的、敏捷的、能够以可扩展、可复制的方式最大化地利用云的能力、发挥云的价值的最佳路
径。指导进行软件架构设计的思想。


@ 一些概念
CNCF:英文全称为Cloud Native Computing Foundation,中文译为“云原生计算基金会”。
华为的KubeEdge(边缘计算平台)，基于Kubernetes。
谷歌的Kubernetes(容器编排引擎)
Rancher:界面可视化管理Kubernetes集群；
安装->启动->访问Rancher Ul->添加集群->导入现有的Kubernetes:集群
直观的查看和操作托管的Kubernetes集群资源，包括添加命名空间、存储卷、告警、通知、日志、部署服务、负载均衡务发现、CI/CD流水线等等功
Spinnaker:多云持续交付，CD持续部署，Netflix出品，类似于Jenkins2.O;一键配置，快速多云部署；两个核心（应用管
理和应用部署)
https://wiki.huawei.com/domains/1070/wiki/5731/WIK1573188415484??
Jenkins:Cl持续集成
Service Meth服务网格
Linkerd,cNCF托管
Istio,谷歌、IBM产品，重要级服务网格。
KUma,CNCF沙盒项目，轻量级的开源服务网格。
Open Service Mesh,OSM,微软产品，捐献给CNCF。


@ Istio
Istio是Service Mesh(服务网格)的主流实现方案。该方案降低了与微服务架构相关的复杂性，并提供了负载均衡、服务发
现、流量管理、断路器、监控、
故障注入和智能路由等功能特性。对业务无侵入式。
为每个pod增加了一个代理container(sidecar),该containerl用于处理应用container之间的通信，包括服务发现，路由规则处
理等。
从下面的配置文件中可以看到proxy.containeri通过15001端口进行监听，接收应用containerE的流量。
为每个pod增加了一个init-container,该container用于配置iptable,将应用containerf的流量导入到代理containert中。
Istio的kube-inject工具的用途即是将代理sidecar注入了Bookinfo的kubernetes yamla部署文件中。通过该方式，不需要用动修改kubernetes的部署文件
即可在部署服务时将sidecar和应用一起部署。

Istio核心组件
Envoy:Istio使用Envoyi调解服务网格中所有服务的入站和出站流量。属于数据平面。
Mixe:负责在服务网格上执行访问控制和使用策略，以及收集从Envoy和其他服务自动监控到的数据。
Pilot:为Envoy sidecar提供服务发现功能，为智能路由（例如A/B测试、金丝雀部署等）和弹性（超时、重试、熔断器等）
提供流量管理功能。属于控制平面。
Citadel:提供访问控制和用户身份认证功能。


@云原生生态中的技术栈
https://blog.csdn.net/weixin 41020960/article/details/114363304
在CNCF基金会成立以后，社区得发展得到了飞速得增长，加上各大云厂商得加入，云原生社区形成1+N的技术生态格局
1 应用层
(1)应用定义及部署(App Definition and Development)
@数据库(Database):应用层的数据库，其中PingCAP公司推出的TiDB就是其中的佼佼者之一，其具有水平弹性扩展、分
布式事务等特性让其和云原生应用理念天然的契合。
@流式处理和消息队列(Streaming and Messaging):常用的消息队列有kafka、NATS、RabbitMQ等，常用的应用系统中也用
的比较多。流式处理有Spark streaming、storm、flink等，都是常用的大数据流式计算框架。
@应用定义和镜像构建（△2p Definition and Image Build):云原生的应用构建一般由于一堆YAML文件组成，为了能更灵活的
生成和打包管理这些配置定义文件，我们需要一些工具，而Helm就是ks应用比较多的一种应用程序Chat的创建、打包个
@持续集成与持续部署(Continuous Integration and Continuous Delivery):持续集成和持续部署是一种基于敏捷开发提出的
开发工具，由于敏捷开发中要求要以快步小走的方式进行迭代，为了节约测试、部署时间周期，必须需要一个能做到和代码管
理进行结合的自动化测试和部署工具，而这就是持续集成和部署（简称CI/CD)。常用的CI/CD工具有Jenkins、Travis Cl、
gitlab runner等。
(2)西配置(Provisioning)
@自动化与配置(Automation&Configuration):用于自动化部署和配置容器运行平台和环境，代表工具包括Ansible、Chef、
Puppet、VMware、OpenStack.。
@容器注册(Container Registry):容器注册是整个CNCF云原生中的重要部件，因为基于容器的运行环境中，所有的应用都需
要借助容器镜像库来进行安装和部署。容器注册工具主要分公有工具和私有工具，公有的容器镜像库主要包括docker官方的
registry,在私有镜像库最著名的是Harbor,目前市面上大量的容器平台目前都基于Harbort构建其镜像仓库。
@安全与合规性(Security&Compliance):安全性和合规性基本是所有系统都会面临的东西，Notary和TUF是这个领域两个主
要的项目，其中TUF是一个开源的安全标准，Notary:是其中一个实现。
@密钥管理(Key Management):秘钥管理做权限管理和身份认证，比如雅虎发布的athenz,就是一个基于RBAC的权限管理
和配置。SPIFFE通用安全身份框架提供了统一的工作负载身份解决方案。
(3)可观测性和分析(Observability.and Analysis)
@监控(Monitoring):监控主要是对运行系统和应用的状态进行观测与预警，常用的监控有Prometheus、Zabbix等，Grafana
通常会配合Prometheus做图形化的展示。
@日志(Logging):日志采集模块，如ELK(elastic/logstash/kibana)、fluentd等。
@追踪(Tracing):这里的tracing:是指分布式链路追踪，因为在分布式系统中，各服务之间相互调用，一个地方出问题可以会导
致很多其他服务上的组件出现连锁问题，因此在定位问题的时候十分困难，必须要建立分布式链路追踪来对错误和故障进行定
位，分布式跟踪是对日志和监控指标的重要补充。OpenTracing是一套分布式系统跟踪标准协议，为大家建立一套统一的标准
来实现分布式跟踪信息的描述和传递。
@混沌工程(Chaos Engineering):混沌工程主要是解决在高复杂性的分布式系统之上建立起值得信任的生产部署体系，比如
服务不可用时后备设置不当；因超时设置不当导致反复重试；下游依赖关系在接收到大量流量时出现中断；发生单点故障时连锁
引发后续问题等一系列混乱的难题，建立受控实验观察分布式系统。
(4)无服务(Serverless)
@工具(Tools):一些工具集，，比如CNCF的landscape作为一个信息聚合网站可以用于查看各种新的软件工具(CNCF永远把
自己放第一)、Dashbird可以用于serverless!监控和故障排查工具。
@安全(Security):主要提供serverless的安全防护。
@框架(Framework):指直接用于构建、管理serverless应用的框架，比如Apex可以用于构建、发布和管理AWS Lambda
SAM一个Pythonl的开源serverless应用构建框架。
@注册平台(Hosted Platfrom):指提供第三方注册的厂商服务，比如AWS的Lambda、阿里云的函数计算服务、Googlet的
@注册平台(Hosted Platfrom):指提供第三方注册的厂商服务，比如AWS的Lambda、阿里云的函数计算服务、Googlel的
cloud functions服务等。
@可安装平台(Installable Platform):这里就是用于自己搭建serverless平台的工具，比如著名的Knative,就是由谷歌开源的
serverless架构方案。

2 集群
(1)编排与管理(Orchestration&Management)
@容器编排与调度(Orchestration and Scheduling):容器的编排和管理可以说是云原生的基石，而Kubernetes可以说是这个
领域的事实标准，作为CNCF基金会的首个毕业项目和金字招牌甚至很多人认为云原生就是ks和其相关的一系列技术，虽然
这样的说法是很不准确的，不过现在云原生技术确实和k绑定的越来越紧密，由此而衍生了一大批的工具生态。
@一致性与服务发现(Coordination and Service Discovery):各服务之间的协同以及服务发现是分布式计算中的核心，分布式
架构作为云原生的基础特性之一可以说是不可或缺的功能组件，从大数据时代的老牌的Zookeeper到到Docker Swarm3采用不
Consul,再到ks中集成的分布式键值数据库etcd和DNS服务发现CoreDNS都是其中的佼佼者。
@远程调用服务(Remote Procedure Call):广义上的远程调用一般分为两种，一种基于HTTP协议，一种基于RPC,而狭义的
远程调用一般指的RPC。比较常用的RPC框架有Google开源的gRPC和Apache旗下的Thrift框架，ks是采用gRPC框架作
为服务间调用。
@服务代理(Service Proxy.):平常用的最多的服务代理应该就是nginx了，作为一个高性能支持正向和方向代理的服务器，
nginx.具备成熟和广泛的应用场景。envoy则是一个新生的用go写的服务代理，像Istio、AmbassadorE的服务代理就是采用了
envoy,因此在云原生应用中envoy也具备强大的生命力。
@API网关(API Gateway):API网格主要起到对所有的APi的调用进行统一接入和管理、认证、授权等功能。ambassador、
traefik、kong等都是优秀的微服务网关。
@服务网格(Service Mesh):服务网格是用于控制应用的不同部分之间如何共享数据，服务网格是内置于应用程序中的专用基
础架构层，用于记录应用的不同部分是否能正常交互。服务网格可以更细粒度地为每个服务提供限流、管控、熔断、安全等功
能。Istio是最流行的Service Mesh之一，其以易用性、无侵入、功能强大赢得众多用户青睐，相信不久将来应该有可能会成
为服务网格的事实标准。

3 底层运行环境
(1)运行环境(Runtime)
@云原生存储(Cloud Native Storage):随着数据库、消息队列等中间件逐步在容器环境中得到应用，容器持久化存储的需求
也逐步增多，随之而来的是建立一套基于云原生的存储系统，在k8s中对应的就是C一一容器存储接口。持久化存储中用的比
较多的是Ceph,作为一个分布式存储系统，Ceph提供较好的性能、可靠性和可扩展性。
@容器运行时(Container Runtime):容器运行时就是指容器的运行环境，比如最常用的Docker.。除了docker,还有一个比较著
名的开源容器运行时标准组织(Open Container Initiative),简称OCl。OCI由Linux基金会于2015年6月成立，旨在围绕容器
格式和运行时制定一个开放的工业化标准，目前主要有两个标准文档：容器运行时标准(runtime spec)和容器镜像标准
(image spec),Containerdi就是一个满足OC规范的核心容器运行时。
@云原生网络(Cloud Native Network):容器的网络方案，为容器集群提供一层虚拟化的网络，像ks的CN就是其中一个
的网络接口，flannel是CoreOS公司主推的容器网络方案，现在现在比较主流的一种网络之一。



---------------------------------------------------------------------------------------------------------------
--------------------------------------------第一部分：架构总览 end----------------------------------------------------
---------------------------------------------------------------------------------------------------------------









---------------------------------------------------------------------------------------------------------------
---------------------------------------------第二部分：工作总览 start------------------------------------------
---------------------------------------------------------------------------------------------------------------

@ jianli

                           个 人 简 历  
基本信息
姓名：曹智军              出生年月：1988/2/2                工作经验：12年
电话：13802706376           邮箱：287119069@qq.com       居住地：深圳市龙华区富茂新村
学历：本科                    籍贯：江西省吉安市             意向岗位：Java架构师/技术经理

工作经验
2019/02-2022-02   软通动力信息技术有限公司  Java架构师  
2017/02-2019/02   广州云移信息科技有限公司  部门经理/系统架构师  
2015/07-2017/02   埃森哲信息技术有限公司    Java高级工程师  
2013/03-2015/07   顺丰速运集团              Java中级工程师/代理PM         
2010/03-2013/03   博彦科技股份有限公司      Java程序员 

技术专长
￭  Java基础扎实，编码规范良好，熟悉JMM内存模型、类加载机制、GC原理，有JVM调优和线上问题处理经验，有多次的技术培训经验；
￭ 熟练掌握java并发编程，对线程池、阻塞队列、读写锁、异步回调、AQS、CAS原理、公平所、重入锁、自旋锁有深入分析，熟悉并发包核心代码的源码，对亿级PV高并发性能优化策略有独到见解。
￭ 精通各种设计模式，多次过对坏味道设计（不符合开闭/上帝类/过多嵌套/过多ifelse/扩展差）的系统运用多种设计模式重构和开发，大大提升代码架构的可复用/可维护/可读性/稳健性以及安全性。
￭ 熟悉软件架构模式和架构优化，丰富的高性能、高可用、可扩展，可伸缩，安全的软件架构建设经验，以及丰富的DDD分层架构理论和实战经验，良好的面向对象分析/设计/开发能力。
￭ 深入研究过分布式架构，以及使用dubbo搭建微服务框架，对于分布式锁、分布式事务、分布式配置、分布式调度有较深的实践经验。
￭ 对SpringBoot-+SpringCloud微服务各个组件深入研究，以及有过服务治理和监控，分布式事务，熔断限流和降级，网关，负载均衡，分布式配置Apollo框架。
￭ 追踪和阅读过多个框架或技术源码实现，比如并发包，String,数据库连接池，Spring ，Springboot，Springcloud，Tomcat，Mybatis，Dubbo，HashMap，Activiti流程引擎等。
￭ 多年的云原生实践经验，深入了解容器编排引擎Kubernetes，有丰富的集群部署/管理/升级的实战，熟悉服务网格lstio以及DevOps知识。
￭ 对消息中间件如Kafka/RocketMQ等有深入探索，有过消息积压/顺序消费/重复消费/延时消费/重试/消息事务/消息回溯/消息幂等/消息可靠/消息最终一致性处理经验。
￭ 对缓存中间件Redis原理深入认识，譬如分页、数据类型、事务、哨兵、淘汰策略、持久化备份策略、线程模型、分片、集群高可用，对高并发问题缓存穿透/缓存击穿/缓存雪崩等有过研究。
￭ 对网络高并发NIO以及Netty连接句柄、粘包拆包、心跳检测、多路复用、线程模型以及TCP协议连接有深入了解以及实战经验。
￭ 较多的Activiti流程引擎实践经验，以及使用过多实例会签、aop监听器、复杂流程图等高级特性。
￭ 深入研究过微服务安全技术，譬如人机认证，机器认证以及鉴权、加解密技术、跨站攻击、请求伪造、HTTPS协议有深入认识，丰富的微服务HTTPS建设经验。
￭ 对建立mysql高性能索引有独到见解，熟悉覆盖索引、聚集索引、事务锁、最左前缀、B+Tree索引、MVCC并发控制、三星索引、Buffer Pool调优原理。
￭ 对于lua语言，go语言，python语言有一定了解，有实际运用经验。
￭ 熟悉Hadoop,Hbase,Storm,ELK,Spark,Hive,Pig等大数据技术；
￭ 熟悉前后端分离思想以及Jquery,AngularJs,RequireJS,Bootstrap:等前端框架，熟练运用JS,AMD,闭包，继承等前端技术。
￭ 有20+团队管理经验，任职部门经理期间组建开发团队，带领3个项目的正常敏捷迭代。
￭ 考取PMP,熟悉管理思路，五大过程组，九大领域，团建，猴子法则，绩效考核等管理手段。
￭ 责任心和沟通能力强，有良好的团队精神，可以承担较强的工作压力。
￭ Java开发经验5年，Java架构经验3年，项目管理经验4年，云原生/云计算经验3年。

项目经历
2019/02-2022/02   云计算-应用部署PaaS平台
￭ 项目介绍：中间件云是一种大混合云的大型PaaS平台，即服务的T产品解决方案，基于laaS提供的Hypervisor、Network和Storagel虚拟化资源，冒在提供一套端到端的应用集群部署升级管理监控服务，能够系统流程化处理资源的申请，集群的创建，中间件的配置及应用部署，提供基于监控、自动告警等的高可用的服务。分为ADS应用部署和ALB应用负载均子产品，按照资源分为虚机Tomcat,虚机Was,容器Docker三种，按照云计算类型分为蓝版公有云和红版私有云，蓝版主要用户是荣耀以及上千个外部客户提供部署服务，红版为华为内部系统提供服务，承载数万个集群和数十万实例的管理。
￭ 担任职位：Java架构师
￭ 技术栈：Springboot,Jalor6(基于Springcloud封装)，DDD,Mybatis,KS,Redis,Kafka,ZK,
Mongodb,StackSalt,Prometheus,Mysql
￭ 主要功能：
1)通用域：1AA$资源池、购买资源、部署单元、创建集群、集群配置、集群下线等
2)支撑域：灰度切换、K8S调度器、日至下载、任务调度等
3)ADS-虚机全链路(Saltstack):中断部署、在线部署、灰度发布、弹性伸缩、重启、停止、启动、销毁
4)ADS-容器全链路（镜像工厂+K8S),在线部署、灰度发布、弹性伸缩、重启、停止、启动、销毁
5)ADS-监控全链路，虚拟机安装探针,push到普罗米修斯服务器，Web或者Grafana展示监控图形；
￭ 工作描述：
1 DDD预研，DDD领域模型分析，DDD微服务框架设计与建设，DDD服务治理。
2 架构设计相关
(1)集群创建，容器部署，容器弹性伸缩，灰度切换等20个场景的领域模型梳理和关键事件分析。
(2)DDD微服务搭建脚手架，输出分层架构图（接口层/应用层/领域层/基础设施层/基础设施持久层）。
(3) ALB/ADS质量指标对接esee概要设计，搭建工程，运用模板方法设计模式搭建代码架子。
(4 ) ADS重启优化，HRN上报,ARM适配，双因子，调度器迁移job异步任务等40多个功能的概要设计。
(5 )抽象工厂+适配器+模板方法+责任链设计模式输出经典部署到云原生的转换逻辑，核心代码开发。
3 welink接入云原生总设计、总负责工作
(1)输出总体设计技术方案，泳道图以及澄清技术细节核心代码编写
(2)设计和搭建高扩展代码架构，比如解释器模式解决表达式匹配、策略模式解决不同镜像类型的制作.
(3)华为welink应用云原生部署服务，支持超过150个微服务设计、开发，拉通
(4)各种镜像模型war/jar/tar/tar.gz设计和P2P拉通
(5)多种8S资源譬如Job,Deployment,Service,Ingress,DaemonSet,HPA,CM,Secret,PV,PVC的部署拉通
(6)支持和分析客户应用部署各种问题，如镜像制作超时、tokeni秘钥等问题以及给出解决方案
4 Jalor架构开发
(1)Jalorlnject微服务RPC注解+负载均衡组件开发，使用动态代理技术，类似dubbol的RPC代理
(2)分布式调度，排除本机乐观锁或者悲观锁性能低下的方式，为华为系统提供分布式调度的组件
5 Seata分布式事务引入
(1)Seata预研，引入到实际微服务中解决分布式事务以及问题的跟踪解决
(2)对Seata进行向注册中心注册权限认证的二次开发以及后期维护
6 微服务安全设计
动态token认证，JWT认证、网关调微服务认证、微服务调微服务认证、根秘钥+工作秘钥设计和开发
7 系统优化和分析
比如制定开发规范、重构坏味道代码、oom异常分析、Arthas)压测、VM调优等
8 任务编排组件
任意同/异步的任务编排、自动调度组件，使用技术：代理、阻塞队列、轮询、异步回调、流程引擎 
9 架构评审，详细设计评审，代码Review,核心代码编写。
10 带领DE,MDE完成功能开发，跟进和解决开发人员遇到的技术问题。

2018/04-2019/02	掌贝政经平台
￭ 项目介绍：运营平台部改成基础平台部，新成立掌贝政经平台项目，总人数5人（前端1；后端4）。之前公司人事招聘这一块是由excel保存，缺乏信息化的管理，该系统由HR部门使用，记录招聘信息和人事信息，主要驱动力是支撑掌贝的业务升级和转型，由此带动降本增效和响应速度提升。涵盖了管理员工入职/转正/调动/休假/奖惩/培训以及业务报表等功能。
￭ 项目模块：人事管理，招聘管理，处罚，培训，招聘管理，人员编制，录用管理，离职管理，图表 
￭ 担任职位：运营平台部-部门经理 
￭ 工作描述： 
1 搭建框架 pep,pep-common,pep-generator,pep-config,pep-mod-biz,pep-mod-biz-api,pep-mod-facade-api,pep-web-admin,pep-web-ui
@需求工具：Wiki; Jira; XMind； 
@前端技术栈：前后端分离; Nodejs; Webpack; Vuejs; Jquery; 
@后端技术栈：SpringBoot; MybatisPlus; Dubbo; Maven; Apollo; DFS；
@数据存储层：Mysql; Redis; Mycat; 
@构建运维：Gitlab; Jenkins; Nginx; Dubbo-admin; Dubbo-monitor; ELK; 
@项目管理：项目晨会; 需求评审; 需求串讲; 概要设计; 设计评审; 代码评审; 交叉测试; 质量分析; 
2 需求评审，需求拆分,工作量，任务分配，进度把控，代码质量，问题跟进，解决疑难问题，项目周例会。
3 解决诸多框架问题，springboot+apollo不注册,不消费dubbo，本地dubbo的调试功能等 ，查看Dubbo,Spring boot源码解决问题。
4 开发定时任务分布式锁，dubbo事务，分布式安全，服务治理，开发dubbo网关组件。
5 资源管理，电子流审批，绩效考核和面谈，招聘，面试，组织团建活动 。

2017/11-2019/02	贝蚁-掌贝运营服务平台 
￭ 项目介绍：新成立运营平台部，调岗任部门经理，之前掌贝公司对运营人员招聘要求高，培训时间较长才能上手，人员流动性大，时而出现商户资料无故丢失的情况，缺乏绩效统计等奖惩制度的监控，阻碍公司的发展。由线下转化成线上管理。运营人员通过为商户购买商品，生产订单，根据服务项目启动工作流，指派订单处理人员，经营诊断，营销策划，账号开通，上门服务等任务节点快速完成运营服务，实现交付服务工作流线上化。具备基本计算机技术短时间培训就能上手，提高产出效率，降低运营成本。形成一种支持运营人员生产聚引客订单，生产客常来交付服务订单，商户进件，支持商户在小程序完善商户基本/微信/银联/门店/广告组/推广资料，查看订单生产进度，业务通知的产品。该产品面向客户实现完整店铺营销的重要组成，掌贝实现销售团队快速出单，快速规模化核心引擎。总人数5人（前端1；后端4）
￭ 项目模块：流程引擎,订单模块,商品模块,商户模块,小程序,服务商,运营统计,系统管理
￭ 担任职位：运营平台部-部门经理
￭ 工作描述：
1 搭建ops-web-erp和wxapp-web-erp，ops-facadde-erp项目 
本系统的权限控制采用shiro技术实现，权限控制到菜单，按钮，权限点等粒度,调用LDAP接口进行统一认证。前后端采用springMVC进行分离。使用activiti流程引擎，持久层采用Mybatis框架，使用DWR长连接实现代办消息实时推送。数据库方面对于基础数据采用mysql存储。对于统计数据则利用redis进行缓存处理。RPC方面则采用了dubbo实现接口的暴露和对其他模块的引用。引入apollo实现分布式配置。前端使用vue+webpack构建工程，采用jsp引入webpack打包js的方式，采用jstl+el表达式，引入了jquery框架。项目UI框架采用bootstrap。 
2 需求评审，需求拆分,工作量，任务分配，进度把控，代码质量，问题跟进，解决疑难问题，项目周例会。
3 底层代码，集群支持，定时任务单机执行，引入dubbo，流程监听器设计，解决apollo不消费dubbo
4 资源管理，电子流审批，绩效考核和面谈，招聘，面试，组织团建活动 。

2017/03-2017/11	安广收视分析项目
￭ 项目介绍：此项目属于公司商业应用部，为安徽广播电视台做收视分析功能，终端机顶盒apk采集用户的行为数据上报到Mqtt, Mqtt收集到数据写入日志文件，使用Filebeat采集文件到Logstash，经过过滤和清洗，灌入数据到ElasticSearch，集成的Kinaba根据不同的横纵坐标产出报表，有些特殊的报表借助Echat实现。按照地区，频道，频道组，时间范围统计用户次数，收视率，收视排行榜等报表。
￭ 项目模块：直播，点播，回看，时移，EPG访问，实时和非实时分析 
￭ 担任职位：平台架构部-系统架构师 
￭ 工作描述：
1 搭建安广项目架构，前端和后端。
（1）前端框架：AngularJS+Bootstrap+Jquery+Echat ;
（2）后端框架：Spring boot+Spring data jpa+Spring data es+Maven+Junit+Netty ;
（3）大数据框架：Elasticsearch+Logstash+Kinaba+Filebea t;
2 申请云主机，协助运维部搭建开发/联调/测试/预发布/生产环境 
3 需求分解，任务分配，编写项目计划，进度跟踪，问题跟进。
4 制定编码规范，编写框架代码模板，直播实时分析图表，表格增删改查。
5 技术调研，研究ELK数据采集，抓取，清洗，报表 。
6 人员招聘，面试 。

2015/07-2017/03	华为iDeal电商项目
￭ 项目介绍：项目总人数180人，业务包括B2B,B2C,B2P三大块，是诸如P7,P8,MATE8,荣耀等华为手机品牌向 渠道商和代理商销售的一个统一平台。
软件环境：HAE,Spring AOP,Spring IOC,Mybatis,Activiti引擎,,jquery,Maven,,Oracle,MongoDB,
Druid,MQ,Webservice,分布式架构,分布式数据库,分布式缓存，eclipse,SVN,Powerdesigner 
￭ 项目模块：订单中国区，订单沃达丰欧洲，订单Pmall，框架，组件集成，流程引擎，财经，交付
￭ 担任职位：高级工程师/PL/SE
￭ 工作描述：
1 流程引擎模块包括activiti流程，规则引擎，人工评审三大块，activiti采用命令模式以降低耦合性。
2 流程引擎切换工作：之前用的是IBM流程引擎，存在稳定性不足，性能不高，扩展性不足，外围依赖性大的弱点。2016.1~2016.7期间总体负责iDeal的流程切换工作，切换成开源的Activiti引擎，以及在途订单从老工作流到新工作流的动态切换。
切换步骤：
（1）协助华为SE使用Mybatis+Spring+Activiti+Maven技术搭建好开发架构,完成流程图,多处理人,监听器和回调服务,代办和邮件等核心功能的设计。提供和开发流程主要的API，用新工作流自测试订单流程从下单到sign的整体过程。
（2）先切换节点相对简单的框架流程am_process,制定相关规范,把所有场景测试通过。
（3）所有流程（订单,offer,交付申请,沃达丰,回款,核销）的切换工作
3 需求分析和评审,story拆分,高阶设计。负责流程引擎模块的需求分析和评审，工作量的拆分，功能概要设计以及评审。
4 BUG分配及跟踪,开发进度跟踪
负责流程引擎模块的问题单分配和跟踪以及记录产生BUG的原因分类，防止下次再次发生，开发任务的分配和跟踪以及指导工作。
5 核心编码,业务支持等工作
负责流程引擎模块的核心代码封装，包括监听器，回调，代办，W3代办，邮件，在途切换等功能，
封装的核心思想是流程来驱动业务，对扩展开放，对修改关闭。
6 分析和解决生产问题或者协助其他模块定位生产问题。

2013/03-2015/06	顺丰速运HRSSC人资共享服务中心
￭ 项目介绍：顺丰人力资源共享服务中心实施项目HR工作台及相关系统（ECP、SAP）对接。顺丰人力资源共享中心设立的主要驱动力是支撑顺丰的业务升级和转型，由此带动降本增效和响应速度提升。HR工作台及相关系统需求的业务范围：涵盖了管理员工入职/转正/调动/休假/奖惩以及 薪资核算、业务报表等功能。项目总人数24人，项目从0开始，周期14个月，2015年4月4日正式上生产。
￭ 软件环境：Spring MVC,ETL,Spring AOP,Mybatis,Jquery,Jquery ui,Jquery easy ui,Oracle 10g,eclipse,SVN,Tomcat 
￭ 项目模块：员工事务、薪资核算、员工自助、事件管理、业务报表、系统配置 
￭ 担任职位：Java中级工程师/代理PM 
￭ 工作描述： 
1 项目整体运作,保证在分析,设计,dev,sit,uat,pro各个环节的稳定和问题的快速响应。 
2 基于Spring MVC+Mybatis+Jquery的开发架构搭建，开发服务器配置分离等系统核心代码。 
3 需求分析、工作量评估和IBM业务顾问 核对和评审需求，提供技术方案，以及需求的工期讨论。
4 项目开发任务分配和进度跟踪，以及技术指导。
5 申请数据库资源和服务器资源，搭建SIT,UAT环境服务器以及维护
6 SIT,UAT期间问题单的整体跟踪以及技术跟进。
7 分析和解决生产问题,后续的性能优化,外围接口的梳理和维护。

2010/03-2013/03	华为 OCS在线充值系统
￭ 项目介绍：OCS在线充值系统是华为技术公司向国外电信供应商 提供业务支持和解决方案的一个平台系统，涉及主要国家主要包括塞尔维亚，南非，塞浦路斯等。主要包括BUS,CHR,SER三个子系统，分别负责业务维护，计费管理，系统集成管理的职责。
￭ 软件环境：Eclipse、Tomcat、Jboss、Oracle 10g、Struts1、Mybatis、Jquery、SVN、POI、Powerdesigner
￭ 项目模块：个人业务、集团业务、产品管理、单表维护、交互日志、资源导入、系统窗口
￭ 担任职位：Java程序员 
￭ 工作描述： 
（1）负责AR、CR需求的开发和问题单的修改工作
（2）产品管理优化和重构，采用树形菜单展示产品分层目录 
（3）子母卡业务导出，采用POI开源控件导出子母卡相关的属性，包含客户名称，有效期等。 
（4）批量开户，资源导入客户信息

考取证书
2020/09  PMP 国际项目管理专业人士资格认证
2016/03  NCRE-1 全国计算机等级考试
2008/09  PETS-3 全国英语等级考试

培训经历
2020/04-2020/09  深圳弘博管理学院  管理培训   项目管理培训
2018/07-2018/08  掌贝商学院        管理培训   干部法则培训
2009/05-2010/02  深圳优迈技术学院  技术培训   Java开发技术

教育经历
2005/09-2009/06  上海工商学院      本科       计算机科学与技术
2002/09-2005/06  吉安县第一中学    高中       理工







@ hiya-all生成器
package com.hiya.pic;
import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.InputStreamReader;
import java.io.OutputStreamWriter;

public class HiyaAllUtils {
	public static void main(String[] args) {
		String appendsDir = "D://HIYA HOME/2 ShiYeDianFeng/2.0 hiya jiagou job/HIYA ALL/appends";
		String basicsDir = "D://HIYA HOME/2 ShiYeDianFeng/2.0 hiya jiagou job/HIYA ALL/basics";
		String deepsDir = "D://HIYA HOME/2 ShiYeDianFeng/2.0 hiya jiagou job/HIYA ALL/deeps";
		String targetFile = "D://HIYA HOME/2 ShiYeDianFeng/2.0 hiya jiagou job/HIYA ALL/alls";
		doLoop(appendsDir, basicsDir, deepsDir, targetFile);
		System.out.println("doLoop finish.");
	}

	private static void doLoop(String appendsDir, String basicsDir, String deepsDir, String targetFile) {
		try {
			targetFile = targetFile + "/all-" + System.currentTimeMillis() + ".txt";
			FileOutputStream fos = new FileOutputStream(targetFile);
			OutputStreamWriter osr = new OutputStreamWriter(fos);
			BufferedWriter output = new BufferedWriter(osr);
			doCopy(appendsDir, targetFile, output);
			doCopy(basicsDir, targetFile, output);
			doCopy(deepsDir, targetFile, output);
			output.close();
		} catch (Exception e) {

			System.out.println("doLoop error ");
			e.printStackTrace();
		}

	}

	public static void doCopy(String dirPath, String targetFile, BufferedWriter output) {
		if (null == dirPath || "".equals(dirPath)) {
			return;
		}
		File dir = new File(dirPath);
		try {
			doSingle(dir, output);
		} catch (FileNotFoundException e) {
			System.out.println("读取文件出错！");
			e.printStackTrace();
		} catch (IOException e) {

			System.out.println("文件IO流异常！！");
			e.printStackTrace();
		}

	}

	private static void doSingle(File dir, BufferedWriter output) throws IOException, FileNotFoundException {
		File[] files = dir.listFiles();
		for (File file : files) {
			output.write("\r\n");
			output.write("\r\n");
			output.write("\r\n");

			if (-1 == file.getName().indexOf("Hiya-append-0")) {
				output.write(
						"---------------------------------------------------------------------------------------------------------------");
				output.write("\r\n");
				output.write("------------------------------------------");
				output.write(file.getName());
				output.write("   start-------------------------------------------");
				output.write("\r\n");
				output.write(
						"---------------------------------------------------------------------------------------------------------------");
				output.write("\r\n");
			}

			FileInputStream fis = new FileInputStream(file);
			InputStreamReader isr = new InputStreamReader(fis);
			BufferedReader reader = new BufferedReader(isr);
			String tempStr = null;
			while ((tempStr = reader.readLine()) != null) {
				output.write(tempStr);
				output.newLine();
			}
			output.flush();
			if (-1 == file.getName().indexOf("Hiya-append-0")) {
				output.write(
						"---------------------------------------------------------------------------------------------------------------");
				output.write("\r\n");
				output.write("------------------------------------------");
				output.write(file.getName());
				output.write("   end-------------------------------------------");
				output.write("\r\n");
				output.write(
						"---------------------------------------------------------------------------------------------------------------");
				output.write("\r\n");
				output.write("\r\n");
				output.write("\r\n");
			}

		}
	}
}




@ 云计算范畴
云计算（弹性云、加速云，并行计算）
云存储（云硬盘、OBS,S3,NFS,CDN加速）
云网络（私有网络VPC,网络地址转换NAT,在家办公VPN(在公用网络上建立专用网络进行加密通讯），弹性负载均衡ELB,EIP)
云容器（云容器引擎，容器镜像服务，云容器实例）
云数据库（关系，非关系，数据复制，数据库迁移，数据管理）
云人工智能（基础平台，语言处理，图像识别，文字识别，人脸识别，视频技术）
云大数据（实时Storm、Spark、非实时Hadoop、ES可视化）
云物联网（智能硬件、设备接入、云通信、边缘计算）
云中间件（应用部署，路由负载均衡，消息网格kafka、分布式存储redis、分布式协调zk)


@ ADS介绍
1)简介
中间件云ADS是一种混合云的PaaS平台，即服务的T产品解决方案，旨在提供一套端到端的应用集群部署升级管理监控服务，
能够系统流程化处理资源的申请，集群的创建，中间件的配置及应用部署，提供基于监控、自动告警等的高可用的服务。
ADS分为蓝版公有云和红版私有云，蓝版主要用户是荣耀以及若干个外部客户提供部署服务，红版为华为内部T系统提供服
务，承载数万个集群和数十万实例的管理，升级，监控。
蓝版生产环境公有云1个实例，5万运行实例
红版生产环境私有云5万集群，50万运行实例
2)主要功能
)通用全链路，1AAS资源池、购买资源、创建部署单元、创建集群、集群配置、集群下线、日至下载、任务调度
≌)ADS-虚机全链路，中断部署、在线部署、灰度发布、弹性伸缩、重启、停止、启动、销毁
实现原理：saltstack(master-+minion)
3)ADS-容器全链路，在线部署、灰度发布、弹性伸缩、重启、停止、启动、销毁、s证书
实现原理：制作镜像+kubernates
4)ADS-监控全链路，
实现原理：探针+普罗米修斯，主机安装探针exporter,push到普罗米修斯server,联合web或者Grafana展示图形；
4)ADS-WAS淘汰。
3)蓝版划分领域：
前后端分离：yaue打包到nginx,调用网关服务；
BFF域：前端适配层、可以查询不能操作
应用域：集群和应用操作
运行时域：部署实例操作
产物域：文件，镜像，发布包操作
通用域：资源池，系统配置，应用，部署单元，环境
任务域：任务编排，下发任务，支持串并行，回调，超时时间配置，
后台域：salt、k8s、镜像工厂、路由规则


@ 灰度切换原理
正式集群和灰度集群相互独立，灰度授权，ip not in1.2.3.4(走灰度)或者ipin1.2.3.4(走正式)
负载均衡器openrestry:nginx使用lua读取redis授权信息，匹配域名上下文，根据不同的授权找到usf环境隔离，路由到对应的网关；


@ ALB原理
路由规则的原理是用lua语言读取redisE的规则写进nginx配置，然后重启nginx,这个和ks的ingress差不多，这个也是监听用
户的ingress,写入nginxl的pod。
ALB应用负载均衡，基于第七层（应用层）对访问进行负载均衡；
ALB负载均衡器只是一个规范，有多种实现，目前实现方式是nginx集群；
一个ALB集群包括一个Sentinel集群，包括多个ALB负载均衡器；
安装redis自动就有哨兵了，只要配置下就可以，哨兵不需要另外安装。
域名可以绑定到负载均衡器上面，一个负载均衡器可以负责个域名的；
客户端-域名-dns解析-F5负载均衡-ab负载均衡器-web服务器
ip就是F5的ip,也就是nginx.之前的硬件负载均衡；
至于dns是有层级的，会递归解析。
静态路由：容器才有的概念，路由规则中除了应用实例之外的内容，不容易变化部分；
动态路由：容器才有的概念，路由规则中应用实例的内容，可以变化的；
路由规则：一个路由规则对应Redisl的一个Key,Key由域名+入站上下文根组成，路由规则通过HIC_ALB_Domain_Context表保存。

可以设置负载均衡是轮询还是随机，设置某个服务进行限流，修改上下文根，cookie加密，请求头新增内容，健康检
域名+上下文根才是决定一个应用的，一个域名+上下文根对应一个路由规则；
server name localhost表示访问nginx本机；
server_name ssss.com表示访问域名；



@ Jalor6基础服务
处理方式：一种是集中式管理调用接口获取人员，本地也建表进行同步；另一种是去中心化，本地建表，怎么和公司同步？
jalore6 common_service是一个前端工程带着html文件，每个工程都带有数据表；
用户管理：人员，人员授权
角色权限：写脚本预准备权限点数据，每个方法注解权限，AOP拦截拿到用户角色，根据角色拿到权限点，进行鉴权；
栏目：栏目权限点映射到服务权限点，原理同上
富文本：略
国际化：略
数据字典：略


@ Jalore6公共组件
1)配置：系统参数设置配置中心的url,带上动态token拿到配置数据放到spring环境中，支持热推送；
2)异常码：国际化和异常码；
3)安全-加解密：
随机uuid生成2个字符串数组configPart(根秘钥第一部分)，根据2个字符串计算calculate生成根秘钥；
SystemComponentLoaderlmplAe.loadRootComponent初始化主辅秘钥路径，拿到主辅秘钥
再根据原来的根秘钥+主辅秘钥（根秘钥第二部分）计算calculate生成新的根秘钥；
新的根秘钥+写死的盐值数组pkcs5s2进行AES加密生成最终的根秘钥rootKey;
工作秘钥workKey明文随机uuid生成，根据rootKey+workKey经过AES(AESCipherAdapter)生成最终的workKey密
文。AESCipherAdapter根据workKey+明文，加密成密文；解密过程相反；
4)存储：S3,NFS
5)上传下载：Multipart
6)定时任务：分布式锁，乐观锁，基于数据库的分布式功能，只有一台机器执行；ScheduleServlet
7)任务编排：
a:xxl-job注重分布式和告警日志等功能，串行用subjobid,对工作流任务编排-串行并行同步异步缺乏支持；
bjob_service只能是往下游处理的任务编排，不支持子任务也是job的形式，下游系统个必须要回调；
C:自研多异步调度组件
callback+rest,改动较小，不可重用，组件耦合较大，原子能力只是专注业务实现，这种方法就会在最后面增加callbackl的代
码，这样就会破坏原子能力。每个原子能力都会增加回调难以维护。
callback+mg,改动较小，不可重用，消息异步机制解耦，也会破坏原子能力。
多异步调度组件：业务逻辑和流程调度完全分离，组件重用，保护原子能力，以轮询代替回调，支持异步+异步、异步+同的编排和调度。
context总线、任务轮询、masteri和work线程、阻塞队列、动态代理
d:分布式任务编排调度框架czj-job
自研分布式调度、定时任务、任务编排、监控告警、日志追溯、弹性扩缩容、并行调度、轮询+回调RPC+回调消息、
handler-+rest、web注册、sdk一键启动、路由策略、故障转移、
引入activiti流程引擎，支持串行，并行，同步，异步，条件表达式



@ Jalore6服务治理
负载均衡：软负载均衡，进程内负载均衡，重写Ribbon客户端负载均衡RibbonLoadBalancer,调用eureka接口根据key拿到
serverList,根据usf分组过滤之后，客户端负载均衡选择一台；
服务网关：集成spring-cloud-gateway,tar.gz,内嵌netty.服务器，nio,总开关，根据url找到eurekal的实例发起请求；
服务发现：eureka服务器
容错：熔断/限流/降级，hystrix,在yml配置中开启熔断，并且以5秒为度量周期，当5秒内请求超过4个错误超过50%时，就会
开启熔断器，所有的请求都会直接降级；
10秒后熔断器进入半打开状态会让一部分请求向服务端发起调用，如果成功关闭熔断器，否则再次进入熔断状态。
分布式配置：配置中心
注解RPC调用：应用启动注解写好应用名称，反射获取api接口的路径，两者可以从eureka拿到注册的实例信息，生成代理对
象，对象持有RPC对象的引用，软负载均衡发起RPC调用；jWt认证；
分布式事务：seata,TC调度XID下管辖的全部分支事务完成提交或回滚（对undolog记录进行undo或delete操作）请求。
f分组隔离：将每个服务实例分组标示好，然后自定义实现负载均衡的策略，根据服务消费者的分组名找到对应分组的服务提
供者，选择性的请求。
链路追踪：Zipkin+Sleuth,

Zipkin是一个开放源代码分布式的跟踪系统，收集服务的时间数据，以解决微服务架构中的延迟问题，包括数据的收集、存
储、查找和展现
每个服务向zipkin报告计时数据，zipkin会根据调用关系通过Zipkin U生成依赖关系图，展示多少跟踪请求经过了哪些服
务，提供了可插拔数据存储方式：In-Memory、MySql、Cassandral以及Elasticsearch
生产数据量大的情况则推荐使用Elasticsearch。Sleuth和Zipkin结合，将信息发送到Zipkin,利用Zipkint的存储来存储信
息，利用Zipkin U来展示信息。
RPC:默认是openfeign,底层是HttpURLConnection,使用http协议；也可以用RestTemplatel底层也是HttpURLConnection。
可以自研netty的tcp调用，和dubbo一样。


@ Jalore6服务安全
人机认证：cookie+session;
外部接口机器认证：iam权限中心，拿着应用的静态token生成动态token)放到HeaderE的Authorization!里面，服务提供者拿到动
态token调用iam进行校验；
内部网关调微服务：网关生成x-jwt-gw-token携带者，微服务根据x-jwt-gw-token得到用户信息，验证有效性
内部微服务调微服务：x-jwt-ms-token,也就是api的代理类，框架自动塞入header;如果是openfeign,自己定义实现
RequestInterceptor塞入header;
yml和oroperties参数：
1)jwt开关、公钥、加密算法、jwt排除验证uri
2)aQp鉴权参数，鉴权角色，数据范围
3)开启合法鉴权请求头、开启Referert校验
4)认证中心(iam)地址，认证排除地址
⑤)网关iam认证开关和地址、网关jwt私钥加密算法，合法域名和认证不过跳转的登录页面



---------------------------------------------------------------------------------------------------------------
---------------------------------------------第二部分：工作总览 end------------------------------------------
---------------------------------------------------------------------------------------------------------------



---------------------------------------------------------------------------------------------------------------
------------------------------------------Hiya-append-1.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------

@ 时间轮
时间轮，是一种实现延迟功能（定时器）的巧妙算法，在Netty.,Zookeeper,Kafka等各种框架中，甚至Linux内核中都有用
到。
kafka中存在大量的延时操作，比如延时生产，延时消费，延时等。kafka并没有使用JDK自带的Timer和DelayQuene来实
现延时的功能，
而是基于时间轮的概念自定义实现了一个用于延时操作的定时器(SystemTimer)。
https://blog.csdn.net/Theo9/article/details/106722067/
若时间轮的tickMs=1ms,wheelSize=20,那么可以计算得出interval为20ms。初始情况下表盘指针currentTime指向时间格不
0,此时有一个定时为2ms的任务插入进来会存放到时间格为2的TimerTaskList中。随着时间的不断推移，指针currentTime不断向前推进，过了2ms
之后，当到达时间格2时，就需要将时间格2所对应的TimeTaskList中的任务做相应的到期操作。此时若又有一个定时为8ms的任务插入进来，则
会存放到时间格10中，currentTime再过8ms后会指向时间格10。


@ Nosql选择
https://blog.csdn.net/weixin 42557879/article/details/102648996
如果你对数据的读写要求极高，并且你的数据规模不大，也不需要长期存储，选redis;
如果你的数据规模较大，对数据的读性能要求很高，数据表的结构需要经常变，有时还需要做一些聚合查询，选MogoDB;
如果你需要构造一个搜索引擎或者你想搞一个看着高大上的数据可视化平台，并且你的数据有一定的分析价值或者你的老板是
土豪，选ElasticSearch;
如果你需要存储海量数据，连你自己都不知道你的数据规模将来会增长多么大，那么选HBase。
不


@ 二维数据
二维数据占用的内存空间比一维数组多得多，大概10倍以上，避免使用。
按照范围分片虽然数据的分布是均衡的，每一个库的数据量差不多，但请求的负载会不均衡。
按照hash路由数据分布和请求负载也是均衡的，如果两个分片数据量过大，要变成三个分片，数据迁移会比较麻烦，即扩展性
会受限，一致性hash分片数据分布和请求负载也是均衡的，扩展性也好。



@ 分层和分割
将分层和分割后的应用和服务模块分布式部署，可以改善网站性能和并发性、加快开发和发布速度、减少数据库连接资源消
耗。


@ 闭锁和栅栏
闭锁和栅栏都是计数降到某一个数字的时候干一件事情，不同的是闭锁可以是同一个线程多次countDown,栅栏每次awaiti都
只能是不同的线程。
不


@ join和fork--join
它可以将一个大的任务拆分成多个子任务进行并行处理，最后将子任务结果合并成最后的计算结果，并进行输出。
docker run创建容器同时执行命令；docker exec针对已经创建好的容器执行命令；
/etc/docker/daemon.json这里面配置的是仓库走http,不安全的"insecure-registries":["http:/kweecrO2-
beta.huawei.com:80"]
/xxx/.docker/config.json这里面是login之后记录下认证信息，身份密码等信息，base64加密


@ 序列化
当两个进程进行远程通信时，可以相互发送各种类型的数据，包括文本、图片、音频、视频等，而这些数据都会以二进制序列
(字节数组)的形式在网络上传送。
一方面，发送方需要把这个Java对象转换为字节数组，然后在网络上传送；另一方面，接收方需要从字节数组中恢复出Java对
象。
public <T>bytel]serialize(T obj)
public <T>T deserialize(byte[]data,Class<T>clazz)(}




@ dubbo的token认证：
ProviderConfig.setToken("123456");
RpcContext.getContext().setAttachment("token","123456");


@ XA 
XA是一种协议或者规范，由X/Open组织提出的分布式事务的架构（或者叫协议）。XA架构主要定义了（全局）事务管理器
(Transaction Manager)和（局部）资源管理器(Resource Manager)之间的接口。也是2PC协议；
JTA是jaVa根据XA规范提供的事务处理标准；
spring.支持JTA事务，但是有不同厂商实现，遵循XA规范；
JTA支持多数据源的事务，Java Transaction API,
本地事务管理器-底层技术使用单连接器。例如，AbstractPlatformTransactionManageri这个是本地事务的抽象类，有很多具
体实现，JDBC使用连接级事务、Hibernate以及JDO使用会话级事务。可以应用使用AOP和拦截器的声明式事务管理。
全局事务管理器-底层技术具有使用多个连接器的能力。当有这方面需求时，JTA是最好的选择。此策略需要启用JTA的数据源
实例。JBOSSTS、Atomikos、Bitronix都是开源的JTA实现。
RDD是一个只读的有属性的数据集。属性用来描述当前数据集的状态，数据集是由数据的分区(partition)组成，并（由
block)映射成真实数据。
RDD属性：名称、分区方式、存储类型、父RDD指针、数据本地化、数据依赖关系等，只是一个引用，由bock映射成真实数据。
NAS是一个设备，一个功能，需要安装专业的NAS操作系统（常见的openfiler/freenas),有对应的菜单。
CIFS/NFS是一种协议。可以在NAS上启用CIFS/NFS协议，这样，用户就能使用CIFS/NFS协议进行访问了。


@ nas
CIFS/NFS是一种协议。可以在NAS上启用CIFS/NFS协议，这样，用户就能使用CIFS/NFS协议进行访问了。
Java程序可以访问nas,创建文件等操作。
hashCodel的存在主要是用于查找的快捷性，如Hashtable,HashMap等，hashCode是用来在散列存储结构中确定对象的存储
地址的；
如果两个对象相同，就是适用于equals(java.ang.Object)方法，那么这两个对象的hashCode-一定要相同；
如果对象的equals方法被重写，那么对象的hashCode也尽量重写；
两个对象的hashCode相同，并不一定表示两个对象就相同，也就是不一定适用于equals(ava.lang.Object)方法，只能够
数组的特点是：寻址容易，插入和困难；
而链表的特点是：寻址困难，插入和容易。
那么我们能不能综合两者的特性，做出一种寻址容易，插入也容易的数据结构？答案是肯定的，这就是我们要提起的哈希
表。
左边是个数组，每个元素指向一个链表的头，这个链表可能为空，也可能元素很多。
https://www.itsource.cn/web/news/1672.html
HashMap底层基于数组、链表、红黑树实现。在HashMap中，初始化一个数组长度为16的数组。在创建一个map对象后调用
put方法，传入key值及value值，
此时将key值进行hash运算得到的hash值作为该entry键值对在数组中的索引位置。此时确定该位置后，首先去判断该位置是不
为null,如果为null,则将entry存储在该位置，如果不为null,此时将entry以链表的方式存储在数组中。当链表长度大于时，将链表结构转为红黑树继续存
储entry。
JDK7中HashMap采用的是位桶+链表的方式，即我们常说的散列链表的方式，而JDK8中采用的是位桶+链表/红黑树，本文研
究的是JDK8中的put方法。
HashMap:在jdk1.8之后引入了红黑树的概念，表示若桶中链表元素超过8时，会自动转化成红黑树（平衡二叉树）；若桶中元
素小于等于6时，树结构还原成链表形式。为了查找更快。


@ 工厂模式
工厂方法：只考虑生产同等级的产品
抽象工厂：综合型的工厂能生产多等级的产品
抽象工厂(Connection)定义两个产品的生产(Statement、PreparedStatement),不同的厂商(mysql,oracle)实现接口
go创建一个goroutine,调度器会将其放入全局队列。调度器为每个goroutine分配一个逻辑处理器。并放到逻辑处理器的本地
队列中
本地队列中的goroutine会一直等待直到被逻辑处理器运行.
java因为采用的是1：1的线程模型，线程数量特别是并发线程数会受到CPU和操作系统的限制
Java中Thread实际上就是对M的封装，通过指定runO函数指定要执行的逻辑。GO语言中讲二者分开，通过P建立G和M的联系
从而执行。
P是G的管理者，P将G交由M执行。P的存在解耦了G和M,当M执行的G被阻塞时，P可以绑定到其他M上继续执行其管理的提升并发性能。。


@ pig和hive
pig和hive都可以转化成mapreducet任务，hive偏向于数据库管理员用，sql语句便利生成mapreducet任务，pig偏向于开发和运
维，Java APls可大幅削减代码量。
说穿了一个是数据库管理员用，一个运维人员用；
一个是类似sgl,一个是命令，group A,dump a,group B,dump b;


@ 传播特性
在同一个类中，非事务方法A调用事务方法B,事务失效，得采用AopContext.currentProxy().xx)来进行调用，事务才能生效。
注意是非是非事务方法A调用事务方法B,如果是事务方法就是事务的传播特性了。
在不同类中，非事务方法A调用事务方法B,事务生效。
在同一个类中，事务方法A调用非事务方法B,事务具有传播性，事务生效
在不同类中，事务方法A调用非事务方法B,事务生效。
不

@ Agent
在JDK1.5以后，我们可以使用agent技术构建一个独立于应用程序的代理程序（即为Agent),用来协助监测、运行甚至替换
其他JVM上的程序。
使用它可以实现虚拟机级别的AOP功能
Spring提供的一款热部署插件，它只是部分重启，相当于重新加载了我们自己写的代码，效率提高很多。
Jrebel,它只重新加载我们修改的那个类，比Springboot热部署插件重启速度更快
都是通过Java Agent:来实现的。
VM options:
-javaagent:你的路径/test-1.0-SNAPSHOTjar=hah
javaagent是一个JVM“插件”，一种专门精心制作的jar文件，它能够利用JVM提供的Instrumentation APl。
在JDK中com.sun.tools.attach.VirtualMachine提供了一些从外部进程attach到jvm上，并执行一些操作的功能。
loadAgent
dumpHeap
ava类从加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括
加载，查找和导入Class文件



@ 类加载 
1 连接
1）验证，检查载入的class.文件数据的正确性
2）准备，给类的静态变量分配存储空间
3）解析，在编译的时候一个每个java类都会被编译成一个class文件，但在编译的时候虚拟机并不知道所引用类的地址，
      多以就用符号引用来代替，而在这个解析阶段就是为了把这个符号引用转化成为真正的地址的阶段。
2 初始化，对静态变量，静态代码块执行初始化工作（门ew反射），只有对类的主动使用才会导致类的初始化
3 使用，编译生成class文件时，编译器会产生两个方法加于class文件中，一个是类的初始化方法clinit,另一个是实例的初始化方法init。
4 卸载，执行了System.exit)或者程序正常结束，jvm进程终止






@ 一些总结 
orElseThrow为空抛异常
orElse.三目运算符取代
ifPresent存在做什么
Holderf偏向于实际的值，Supplierf偏向于对象类型
使用Optionalt包装可能为空的返回值
@NonNull7方法不能返回空
@Nullable方法可以返回空
Optional.map解决多级判空
RequiredArgsConstructor+@NonNully必要参数构造器，access访问级别
@Setter+@Accessors(fluent=true)实现类似builderl的链式操作
@ToString(exclude排除脱敏数据
@ToString(callSuper=true)包含父类的
Objects.equalsl取代对象.equals01.2对象操作，也可以用StringUtils.equals
浮点数大小比较转换成BigDecimal
StringUtils.compare比较
StringUtils.countMatches:统计出现次数

@try-with-resource取代finally
@如果类具有自己特有的“逻辑相等”概念（不同于对象等同的概念），且超类并没有覆盖equals7方法以实现期望的行为，我们
就应覆盖equals方法。
@如果对象的equals相等，hashCodet也必须相等；
如果对象的equals.不相等，hashCode可以相等，也可以不相等，但不等最好，这样可以提高散列表的性能。
如果你的对象想要和散列表的结构一起使用，就需要覆盖hashCode,不然是不能作用Map的key。
@lambda优先于内部类，但是方法引用优先于lambda表达式。
@注意EnumSet和EnumMap.
@继承可能破坏子类的数据，用复合。


@ K8S版本
extensions/v1beta1:1.6.0以前
apps/v1beta2
1.8
apps/v1 1.9
弃用extensions/v1beta11.16迁移1.13
v1.16版本将停止为以下不建议使用的AP1版本服务，而将支持更新和更稳定的AP1版本：
不再为extensions.v1beta1API版本中的NetworkPolicy服务
迁移至使用networking.k8s.io/v1AP版本，从v1.8开始提供。可以通过新版本检索/更新现有持久化数据。



@ TCP协议 
一个TCP连接需要四个元组来表示是同一个连接(src_ip,src_port,dst_ip,dst_port),TCP报头中的源端口号和目的端口号同
IP数据报中的源IP与目的IP唯一确定一条TCP连接。
@TCP的状态机适合使用状态设计模式，三次握手(LISTEN-SYN-SENT-ESTABLISHED),四次挥手(FIN-WAIT-
1,CLOSE WAIT,FIN-WAIT-2,TIME-WAIT)
@TCP超时丢包重传机制：在发送一个数据之后，就开启一个定时器，若是在这个时间内没有收到发送数据的ACK确认报文，
则对该报文进行重传，在达到一定次数还没有成功时放弃并发送一个复位信号。

TCP协议的报文格式：
1、端口号：用来标识同一台计算机的不同的应用进程。
1)源端口：源端口和1P地址的作用是标识报文的返回地址。
2)目的端口：端口指明接收方计算机上的应用程序接口。
2、序号和确认号：是TCP可靠传输的关键部分。序号是本报文段发送的数据组的第一个字节的序号。在TCP传送的流中，每一
个字节一个序号。e.g.一个报文段的序号为300，此报文段数据部分共有100字节，则下一个报文段的序号为400。所以序号确
保了TCP传输的有序性。确认号，即ACK,指明下一个期待收到的字节序号，表明该序号之前的所有数据已经正确无误的收
到。确认号只有当ACK标志为1时才有效。比如建立连接时，SYN报文的ACK标志位为0。
3、数据偏移/首部长度：4bts。由于首部可能含有可选项内容，因此TCP报头的长度是不确定的，报头不包含任何任选字段
则长度为20字节，4位首部长度字段所能表示的最大值为1111，转化为10进制为15,15*32/8=60，故报头最大长度为60字
节。首部长度也叫数据偏移，是因为首部长度实际上指示了数据区在报文段中的起始偏移值。
4、保留：为将来定义新的用途保留，现在一般置0。
5、控制位：URG ACK PSH RST SYN FIN,共6个，每一个标志位表示一个控制功能。
1)URG:紧急指针标志，为1时表示紧急指针有效，为0则忽略紧急指针。
2)ACK:确认序号标志，为1时表示确认号有效，为0表示报文中不含确认信息，忽略确认号字段。
3PSH:push标志，为1表示是带有push标志的数据，指示接收方在接收到该报文段以后，应尽快将这个报文段交给应用
程序，而不是在缓冲区排队。
4)RST:重置连接标志，用于重置由于主机崩溃或其他原因而出现错误的连接。或者用于拒绝非法的报文段和拒绝连接请
求。
5)SYN:同步序号，用于建立连接过程，在连接请求中，SYN=1和ACK=0表示该数据段没有使用捎带的确认域，而连接应
答捎带一个确认，即SYN=1和ACK=1。
6)FN:finish标志，用于释放连接，为1时表示发送方已经没有数据发送了，即关闭本方数据流。
、窗口：滑动窗口大小，用来告知发送端接受端的缓存大小，以此控制发送端发送数据的速率，从而达到流量控制。窗口大
小时一个16bit字段，因而窗口大小最大为65535。
个
7、校验和：奇偶校验，此校验和是对整个的TCP报文段，包括TCP头部和TCP数据，以16位字进行计算所得。由发送端计
算和存储，并由接收端进行验证。
8、紧急指针：只有当URG标志置1时紧急指针才有效。紧急指针是一个正的偏移量，和顺序号字段中的值相加表示紧急数据
最后一个字节的序号。TCP的紧急方式是发送端向另一端发送紧急数据的一种方式。
9、选项和填充：最常见的可选字段是最长报文大小，又称为MSS(Maximum Segment Size),每个连接方通常都在通信的
第一个报文段（为建立连接而设置YN标志为的那个段）中指明这个选项，它表示本端所能接受的最大报文段的长度。选项
长度不一定是32位的整数倍，所以要加填充位，即在这个字段中加入额外的零，以保证TCP头是32的整数倍。
10、数据部分：TCP报文段中的数据部分是可选的。在一个连接建立和一个连接终止时，双方交换的报文段仅有TCP首部。
如果一方没有数据要发送，也使用没有任何数据的首部来确认收到的数据。在处理超时的许多情况中，也会发送不带任何数据
的报文段。



@ Netty百万连接
可以同时支持Reactor单线程模型(boss和work都是同一个线程)、多线程模型(boss和work不同线程)和主从模型(boss
和work分别是一个线程池)。
TCP是以一个四元组概念，以原P、原端口号、目的P、目的端口号来确定的，当原P和原端口号相同，但目的端口号不同，
最终系统会把他当成两条TCP连接来处理。
在服务端启动800~8100，而客户端依旧使用1025-65535范围内可用的端口号，让同一个端口号，可以连接Server的不同端
口。这样的话，6W的端口可以连接ServerE的100个端口，累加起来就能实现近600W左右的连接。
突破局部文件句柄的限制（一个VM进程能够打开的最大文件数）：
/etc/security/limits.conf(其中soft表示警告的限制，hard表示真正限制)
65535,代表一个进程能够打开的最大文件数，一条TCP连接，对应Li门ux系统里面是一个文件，最大连接数会受限于这个字。
hard nofile 1000000
soft nofile 1000000
突破全局文件句柄的限制（所有进程能够打开的最大文件数）：
cat /proc/sys/fs/file-max
etc/sysctl.conf


@ byName 和 byType
spring iocl用byType装配在相同的中class中设置了两个实例则抛出异常，byNames就是唯一的实例；
@Autowired默认使用的是byTypel的方式向Bean里面注入相应的Bean,Autowired+Qualifiers就是byName;


@ 消息中间件的难点：
集群是否支持；
持久化是否支持；
消息重试；
分布式事务；
顺序消息；
消息延时支持（时间轮）；
消息积压（要么消息发送变快了，要么消息消费变慢）；
消息回溯（成功消费并消息后重新消费已的消息）。



@ 消息幂等性方法
重复消费或者反复生产有幂等性问题，一般都是消费端解决
1)报文有一个唯一id,判断id如果消费过了（存入redis)不再消费，这个只针对重复消费，但是不适合反复生产（唯一id变了)
2)数据库层面悲观锁，利用数据库的唯一约束实现幂等，或者查一下是否有了？
3)数据库层面乐观锁，多版本（乐观锁）控制
4)如果你是写redis,那没问题了。每次都是set,天然幂等。



@消息可靠性，处理消息丢失
1)生产者事务，可以解决但是同步阻塞卡住，等待是成功还是失败，会导致生产者发送消息的吞吐量下降
2)生产者调成confirm模式，异步回调方式，不会阻塞，吞吐量比较高。
3)MQ持久化，开启了持久化机制，也有一种可能，就是这个消息写到了RabbitMQ中，但是还没来得及持久化到磁盘，此时挂了，在内存中的数据可能就丢了。
4)消费者需要将autoACK自动关闭。否则可能导致数据弄丢。


@ mq吞吐量
Kafka最强17.3w/s,RocketMQ:11.6w/s,RabbitMQ:2.6w/s,ActiveMQ更低。
ActiveMQ和RocketMQ是java开发，RabbitMQ是Erlang,Kafka是Scala/Java开发，ZeroMQ是C开发。
RocketMQ和Kafka支持顺序消息，其他不支持；
RocketMQ和Kafka支持大量堆积，ActiveMQ和RabbitMQ支持少量堆积，ZeroMQ不支持


@ 线上问题
cpu利用率高(top找到pid;top Hp pid找到线程id;转换16进制；jstack pid lgrep16进制)


@ 长连接
WebSocket是HTML5下一种新的协议，解决了htp被动型的问题；全双工方式。
可以用netty.实现。



@ 公平所、重入锁、偏向锁、自旋锁、锁消除、锁膨胀？
锁机制(CAS机制、synchronized、ReentrantLock、ReentrantReadWriteLock)
共享锁：线程可以同时获取锁。ReentrantReadWriteLock对于读锁是共享的。在读多写少的情况下使用共享锁会非常高效。
重入锁：线程获取锁后可以重复执行锁区域。Java提供的锁都是可重入锁。不可重入锁非常容易导致死锁。
排它锁：多线程不可同时获取的锁，与共享锁对立。与重入锁不矛盾可以是并存属性。
乐观锁：其实是一种采用具有原子性的CAS非加锁机制，保证当前线程原子性执行。
悲观锁：直接加锁进行线程隔离。synchronized、ReentrantLock、ReentrantReadWriteLock的写锁都属于悲观锁
公平锁：线程试图获取锁时，先按尝试获取锁的时间顺序排队
非公平锁：线程试图获取锁时，如果当前锁没有线程占有，则跟排队获取锁的线程一起竞争锁而无序按顺序排队，则为非公平锁。如果竞选失败，依然要排队。
偏向锁：一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。类似于乐观锁。
轻量级锁：当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取
锁，不会阻塞，提高性能
重量级锁：当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取
到锁，就会进入阻塞，该锁膨胀为重量级锁。
重量级锁会让其他申请的线程进入阻塞，性能降低。



@ JVM之DCL
DCL,即Double Check Lock,双重检查锁定。
单例模式之懒汉无法保证线程安全；
public static Singleton getlnstance()可以保证线程安全但是性能低下；
DCL来了，if(singleton==null{synchronized(Singleton.class){看起来没问题；
问题是指令重排，实例化一个对象2)和3)可能先执行3)，所以singleton可能没有初始化
1)分配内存空间
2)初始化对象
3)将内存空间的地址赋值给对应的引用
解决DCL的关键是用volatile.不允许初始化阶段步骤2、3发生重排序；
解决DCL的关键是private static class SingletonHolder允许初始化阶段步骤2、3发生重排序，但是不允许其他线程“看至
不重排序。


@ 并发之AQS
AQS,AbstractQueuedSynchronizer,即队列同步器。它是J.U.C并发包中的核心基础组件。设计模式是模板方法模式，子
类们必须实现改变state变量的protected方法，这些方法定义了state是如何被获取或释放的。
它是一个底层同步工具类，比如CountDownLatch,Sammphore,ReentrantLock,ReentrantReadWriteLock等等都是基于AQS
1.state(用于计数器)
2.线程标记(CAS获得锁，成功的话更新state=1,其他没有获得锁的放到阻塞队列，等待释放锁)
3.阻塞队列（用于存放阻塞线程）


@ 限流
1基本思路：
漏桶算法（水桶固定速率流出，缓冲请求，满之后请求丢弃，匀速处理）
令牌桶算法（令牌以固定速率到固定容量的令牌桶，多余的令牌丢弃；请求携带令牌才能处理；令牌不够请求被缓存起来；最
大的处理=桶容量+缓存容量)
漏桶算法能够强行限制数据的实时传输速率，对突发流量不做额外处理；而令牌桶算法能够在限制数据的平均传输速率的同时
允许某种程度的突发传输。
2 nginxl限流：采用漏桶算法，limit_req_zone限流（单位时间内请求数），limit_req_conn限并发（统一时间内请求数）
3kong限流：Kong网关提供的限流插件：rate-limiting
4服务限流：并发计数器算法，漏桶算法，令牌桶算法。
前两种算法不支持突发流量的限流，令牌桶算法支持突发流量的限流（因为有桶深）。
一般用谷歌guava落地令牌桶算法，用sentinel作为服务限流的中间件。


@ 内存泄漏
静态变量生命周期与程序一致
各种连接，如数据库连接、网络连接和○连接等
没有及时地把大对象设置为null
单例，持有长生命周期实例

@ nginx的多进程模型
nginx在启动后，会有一个masteri进程和多个workeri进程；
一个请求，只可能在一个workeri进程中处理。nginx提供了一个accept_mutexi这个东西，这是一个加在accept.上的一把共享
锁解决惊群现象。
一个完整的请求读取请求、解析请求、处理请求，产生数据后，再返回给客户端，最后断开连接，这些操作都是在同一个wok
进程执行的，
但是单个Wok进程采用NIO的事件处理机制，由进程中的轮询线程循环处理多个准备好的事件，从而实现高并发和轻量级。这
个和redis,netty.同一套原理。


@redis缓存击穿
---缓存穿透
-定义：key对应的数据在数据源并不存在，每次针对此key的请求从缓存获取不到，请求都会到数据源，从而可能压垮数据源。
-解决：
1)布隆过滤器，所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmapt拦截不
掉，从而避免了对底层存储系统的查询压力。。
2)简单粗暴，把查不到的空结果进行缓存null,设置过期时间；

---缓存击穿：
-定义：一个缓存失效高并发给DB带来很大压力。
-解决：)redis的SETNX,多个请求同事操作只有一个操作返回成功，成功后进行load db的操作并回设缓存；否则，就重试整个get缓存的方法
2)简单粗暴，不设置有效期。

---缓存雪崩：
-定义：大量缓存集中在某一个时间段失效高并发给DB带来很大压力。
-解决：
1)为key设置不同的缓存失效时间，错开集中失效的机会；
2)简单粗暴，不设置有效期




@ hbase组成
HBase体系架构：Client、Zookeeper(高可用，元数据存储)、HMaster(负责RegionServer的负载均衡，管理Region和
HRegionServer)、HRegionServer(绕开masteri进行/O操作)
HBase读取数据优先读取HMemcache中的内容，如果未取到再去读取Hstore中的数据，提高数据读取的性能。
HBase写入数据会写到HMemcache和Hlog中，HMemcache建立缓存，Hlog同步Hmemcache和Hstorel的事务日志，发起
Flush Cachel时，数据持久化到Hstore中，并清空HMemecache。




@ DDD建模
每个微服务是一个界限上下文，界限上下文之间访问通过防腐层，界线上下文下麦包括核心子域，通用子域，支撑子域；
界限上下文，子域，聚合根，实体，值对象，属性；
场景地图（业务层）->关键活动（比如创建魔板，绑定路由）->命令（发起保存/发送XX命令）->事件(xx已完成/已创建)->
聚合根（实体，值对象）
一个场景地图是一个applicaionl服务，里面调用多个领域服务，完成；比如创建集群(ADS领域，KS领域，路由等不同领
域)；
分布式事务的控制本地事务控制在application层，分布式事务最终一致性，
仓储层的作用仓储层和领域相关，领域层与基础设施之间的桥梁；
应用层的作用协调多个领域服务共同完成应用服务；
工厂模式尽量满足开闭原则；
基础设施层包括的组件（工具类，系统层，dao,nosql,mq,Globalconfiguration);
界限上下文之间的服务通信(external和防腐层)；
服务治理(SGOV);
pom依赖版本制定；
脚手架组件的开发和使用；
领域模型
1.门界限上下文，每个界限上下文都是一个微服务；
1.n核心子域，通用子域，支撑子域；
1.n聚合（聚合根，实体，值对象）；
聚合根到聚合根：通过D关联；
聚合根到其内部的实体，直接引用；
聚合根到值对象，直接引用；
实体到聚合根：通过D关联；
实体到其聚合内的实体：直接引用，但不要循环引用；
实体到其聚合外的实体：不可能有这种情况，因为实体都是在聚合内部的，对外不可见；
实体到值对象：直接引用；
值对象到聚合根：通过D关联；
值对象到实体：直接引用；
值对象到值对象：直接引用；


@ jdk收集器
新生代收集器：Serial(单线程复制收集)、ParNew(并行，多线程理)、Parallel Scavenge(并行)；
老年代收集器：Serial Old(单线程标记整理)、Parallel Old(并行，多线程标记整理)、CMS(并发，标记清除，多线
程)；
整堆收集器：G1(并发，jdk11,大内存的多核处理器，技术前沿，新老不用物理隔离，Region集合，)；
Serial:必须暂停其他所有的工作线程，直到它收集结束
Parallel:工作线程独立，多核CPU
JDK5.0以前都是使用串行收集器；
jdk8中，默认使用Parallel Scavenge(新生代)+Serial Old(老年代)；
jdk11中，G1已经取代了CMS,是默认的垃圾收集器；
不
XX:+UseSerialGC:设置串行收集器
-XX:+UseParallelGC:此配置仅对年轻代有效，而年老代仍旧使用串行收集。
-XX:+UseParalledlOldGO:设置并行年老代收集器
-XX:+UseConcMarkSweepGC:设置并发收集器
并行收集器：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态；
并发收集器：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行）


@ 线程池大小设置
最佳线程数目=（线程等待时间与线程CPU时间之比+1）*CPU数目
例如：平均每个线程CPU运行时间为0.5s,而线程等待时间（非CPU运行时间，比如1O)为1.5s,CPU核心数为8，那么根据上面
这个公式估算得到：(0.5+1.5)/0.5)*8=32。

@ nacos构建云原生应用的动态服务发现、配置管理和服务管理平台
nacos(阿里)=Eureka+spring cloud config


@ JStorm
JStorm比Storm更稳定，更强大，更快，Storm.上跑的程序，一行代码不变可以运行在JStorm.上。直白的讲JStorm:是阿里巴巴
的团队基于Storm的二次开发产物。
JStorm出现背景是解决现有Storm无法满足一些需求：
1现有storm调度太简单粗暴，无法定制化
2 Storm任务分配不平衡
3 RPC OOM(OOM-Out of Memory,内存溢出一一俗称雪崩问题)一直没有解决
4 监控太简单
5 对ZK访问频繁


@ 短链接生成
分布式ID生成器产生D
1D转62进制字符串
记录数据库，根据业务要求确定过期时间，可以保留部分永久链接
主要难点在于分布式D生成。鉴于短链一般没有严格递增的需求，可以使用预先分发一个号段，然后生成的方式。


@ 一致性算法Zab和Raft
raft和zookeeper的ZAB都是leader-based一致性协议，通过选举一个proposerf作为leader降低多个proposeri引起的冲突问题，大致都可以分为两个阶段
l)leader?在时，由leaderl向follow同步日志，日志复制过程raft和zab的处理流程基本一致，一旦leader发给follower的数据出
现超时等异常raft:会不断重试，并且接口是幂等的，Zab:follower会断开与leader:之间的连接，重新加入该集群
2)leader不在时，用选举算法选出一个新leader,
raft
follower有一个选举时间，在该时间内如果未收到leadert的心跳信息，则follower转变成candidate,自增term发起新一轮的投
票，leaderi遇到新的term则自动转变成followerl的状态
ZAB leaderi和followeri都有各自的检测超时方式，leader:是检测是否过半follower心跳了，follower检测leader是否发送心跳
了。一旦leader检测失败，则leaderi进入LOOKING状态，
其他followeri过一段时间因收不到leader/心跳也会进入LOOKING状态，从而出发新的leaderi选举
选举过程：
一般的leaderi选举过程有2个要素：选举轮次和leadert包含的日志
Raft定义了term来表示选举轮次，ZooKeeper定义了electionEpoch:来表示
在选举leaderE的时候，通常都希望选举出来的leader至少包含之前全部已提交的日志
有种选择，一种就是所有日志中的最后一个日志，另一种就是所有已提交中的最后一个日志。
目前Raft和ZooKeeper都是采用前一种方式。日志的越新越大表示：轮次新的优先，然后才是同一轮次下日志记录大的优先
Raft:term大的优先，然后entry的index大的优先
ZooKeeper:peerEpoch大的优先，然后zxid大的优先


@ mysql死锁
Lock wait timeout exceeded;try restarting transaction
窗口1：
set autocommit 0;
update cluster_attribute set is_deleted='Y'where cluster_id 100000001285 and is_deleted='N'and attribute_key
is key store secret set up';

窗口2：
set autocommit 0;
update cluster_attribute set is_deleted='Y'where cluster_id 100000001285 and is_deleted='N'and attribute_key=
is key store secret_set _up';

解锁：
select from information schema.innodb_trx;
kill15318439;
innoDb支持表锁、行锁
myslam表锁
分析：
同一个事务没关系，2个不同的事务，一个事物未提交，另一个事物可能死锁；
update where后面加了索引才会行锁、否则表锁；
EXPLAIN update cluster_attribute set is deleted='Y'where id 444;cluster id 100000001285 and is_deleted='N'and
attribute key is trust _store secret_set_up';
看possible_key和key可能用到的索引，idx_cluster_id和idx_attribute_key;
如果是单独的索引l,就会锁住cluster_id或者attribute_key多条数据；
如果是组合索引，就会锁住满足组合的数据，有可能是一条；
如果是主键，那肯定是一个；
in通常是走索引的，当in后面的数据在数据表中超过30%（上面的例子的匹配数据大约6000/16000=37.5%）的匹配时，会走全
表扫描，即不走索引，因此in走不走索引和后面的数据有关系。
解决方案：根据id去，建立组合索引，串行提交；


@分布式事务seata
TM向TC申请开启一个全局事务，全局事务创建并生成一个全局唯一的XID。
XD在微服务调用链路的上下文中传播。
RM向TC注册分支事务，将其纳入XID对应全局事务的管辖，分支事务，branchld。
TM向TC发起针对XID的全局提交或回滚决议。
原理：TC调度XID下管辖的全部分支事务完成提交或回滚（对undolog记录进行undo或delete操作）请求。

Undo和Redo:
Undo Logl的原理很简单，为了满足事务的原子性，在操作任何数据之前，首先将数据备份到Undo Log.然后进行数据的修
改。
如果出现了错误或者用户执行了ROLLBACK语句，系统可以利用Undo Log中的备份将数据恢复到事务开始之前的状态。
和Undo Log相反，Redo Log记录的是*新数据*的备份。在事务提交前，只要将Redo Log:持久化即可，不需要将数据持久
化，减少了的次数。
主要是可以重新发起操作；
假设有A、B两个数据，值分别为1,2
A.事务开始
B.记录A=1到undo log buffer.
C.修改A=3.
D.记录A=3到redo log buffer.
E.记录B=2到undo log buffer.
F.修改B=4.
G.记录B=4到redo log buffer.
H.将undo log:写入磁盘
l将redo log写入磁盘
J事务提交
如何保证原子性？
如果在事务提交前故障，通过undo log日志恢复数据。
如果undo log都还没写入，那么数据就尚未持久化，无需回滚。


@ 六边形架构&充血和贫血
六边形架构又称为端口-适配器，内部通过端口和外部系统通信，端口代表了一定协议，以AP呈现。一个端口可能对应多个外
部系统，不同的外部系统需要使用不同的适配器，适配器负责对协议进行转换。
六边形架构有一个明确的关注点，从一开始就强调把重心放在业务逻辑上，外部的驱动逻辑或被驱动逻辑存在可变性、可替换
性，依赖具体技术细节，外部可替换，
对于驱动者适配器，就是外部依赖内部的。但是对于被驱动者适配器，实际是内部依赖外部，这时需要使用依赖倒置，由
驱者适配器将被驱动者适配器注入到应用内部，这时端口的定义在应用内部，但是实现是由适配器实现。

充血和贫血模型：最好的方式就是pojg里面提供setget方法之外还有简单的业务逻辑，主要核心的逻辑在service层，这样pojo
不会是上帝类。



@ pv要点
1 同步：是生产消费的问题，比如A生产了B才能消费；P不对称，根据实际情况；
2 互斥：是一个临界资源同时只能有一个进程访问（读和读不互斥，读写才互斥），P是对称的。
3 P的意思是P=P-1,如果大于等于0，则执行程序，小于0表示排队等待，它的绝对值是等待的数量；
4 V的意思是V=V+1,如果大于等于0，则执行程序，小于0表示还有排队的，需要唤醒其中一个。
5 一个进程要干活首先要同步的资源然后在互斥，互斥PV实对称的并且被外层包裹着。
6 生产流程，那就是P(empty),因为生产一个效果就是empty-1;然后PV(mutex).生产完了呢？V(full,生产完了就是full+1;
7 消费流程，那就是P(full),因为消费一个效果就是full1;然后PV(mutex).消费完了呢？V(empty),生产完了就是empty+1;
8 有可能存在多个同步和多个互斥，也可灵活比如empty:=n,full可以变成奇数f1偶数f2之类的，根据if判断，full被f1和f2取代了。



@ 消费https:
1)tomcat,把外部的https证书导入到jdk证书库
2)docker,基础镜像把外部的https证书打进去提供https:
1)域名，负载均衡器，nginxi配置证书密码和位置
2)如果是前端工程，不用做什么，使用的是nginxi静态服务器
3)如果是tomcati部署，tomcati配置需要放开443端口
4)如果是springbootl内嵌的tomcat,yaml里面配置ssl
5)如果是springboot打包war则tomcati配置需要放开443端口，yaml不用配置ssl
6)如果是springcloudgateway.内嵌的netty服务器，jar包成targz,则yaml里面配置ssl
7)如果是dockert部署war,tomcat基础镜像放开443端口
8)如果是docker部署jar,yaml里面配置ssl
9)K8S用httpsi访问，ingress配置ssl就可以了（和第一点类似）
jdk一般在java8\lib\security\cacerts,程序可以指定信任证书库：
-Djavax.net.ssl.keyStore=clientKeys
-Djavax.net.ssl.keyStorePassword=password
-Djavax.net.ssl.trustStore=clientTrust
-Djavax.net.ssl.trustStorePassword=password

keystore是Eclipse打包生成的签名，jks是Android studio生成的签名。
很多第三方市场，上传apk时，只支持keystore(目前我没遇到过)，需要把jks签名转化为.keystore
keystore包含证书和私钥，trustStore包含公钥；
导出证书命令：
keytool -export -alias ssodemo -keystore D:\work\key\ssodemo.keystore -file D:\worklkeylssodemo.crt-storepass
123456
将证书导入jdk中：
keytool -import -keystore "C:\Program Files\Java\jdk1.8.0_66\jre\lib\security\cacerts"-file "D:\iam\iam2.cer"-alias iam
keytool -import -keystore "C:\Program Files\Javaljdk1.8.0_66\jre\liblsecurity\cacerts"-file "D:\iamlicsl-eureka.cer"-alias icsl-eureka
keytool -import -keystore "C:\Program Files\Java\jdk1.8.0_66\jrel lib\security\cacerts"-file "D:\iamlapig-icsl.cer"-alias apig-icsl
(密码：changeit)
查看添加到jd业中的所有证书：
keytool -list -keystore "C:\Program Files\Java\jdk1.8.0_66\jre\liblsecurity\cacerts"
谷歌浏览器提示不安全连接：
在浏览器地址栏输入：chrome:/net-internals/#hsts
然后到Add domain下，Domain添上诸如google.com和google.com.hk,并勾选Include subdomains,再点击Add确定以就设置完毕了。



@ arthas熟练用法
Arthas是Alibaba开源的Java诊断工具，功能很强大，它是通过Agent7方式来连接运行的Java进程、主要通过交互式来完成功能。
下载：curl-O https://alibaba.github.io/arthas/arthas-boot.jar
启动：java-jar arthas-boot.jar
显示当前虚拟机java进程，有编号
输入编号3
也可以通过浏览器连接arthas(port:3658),只是执行命令的时候需要加-target-ip参数
dashboard:查看线程，内存，GC等信息
thread:显示粘附的这个进程所有线程信息，和dashboard里面展示的线程一样
thread-n:最繁忙的3个线程（占用cpu最多的前3个），输出栈信息
thread18:查看某个指定（编号18）的线程，输出栈信息
thread-b:输出阻塞的线程栈信息，如果响应慢，阻塞状态的线程比较多，我们需要重点关注
thread lgrep BLOCKED:找出阻塞状态的线程
jm:关注下死锁(DEADLOCK-COUNT,下面不为O,表示有死锁)，jvm相关的
jadcom.qzcsbj.controller.UserController mem:反编译指定方法，除了展示代码，还展示了类加载器的信息
jadcom.qzcsbj.controller.UserController:反编译指定的类，除了展示代码，还展示了类加载器的信息
sm-dcom.qzcsbj.controller.UserController mem:显示方法的：修饰符、注解、参数、返回类型
monitor com.qzcsbj.controller.UserController m-c2:重点看成功次数、平均响应时间、失败率
watch com.qzcsbj.controller.UserController login{params,returnObjl}-x2:类似debug,断点调试，查看入参和返回值，中-×表示深度
trace com.qzcsbj.controller.UserController m:找到耗时多的方法
远程监控：
1)arthas-x.x.x-bin,这个包含监控的插件，可作为远程监控的客户端，下载地址：
https://arthas.aliyun.com/doc/download.html
2)arthas-tunnel-server-x.x.x-fatjar.jar,这个是远程监控的服务端，下载地址：https:/2github.com/alibaba/arthas/releases
3)第一步先启动远程服务端，也就是在你自己的电脑上启动服务端arthas-tunnel-server的jar包，启动后记下地址给客户端也
就是要监控的电脑启动arthas)用，一般默认为，ws:/xxx.xxx.x.xxx/ws,这个ip是自己电脑的ip。
4)第二步把下载好的arthas-X.x.x-bin文件夹拷贝到要监控的服务器上，然后输入启动命令并带上第1条保存下来的tunnel服务
地址，java-jar arthas-boot.jar-tunnel-server ws:/xxx.xxx.x.xxx/ws-agent-id xxxxxxx,agent-id为自定义的id,作为注册到tunnel服务器上的唯一id
trace com.qzcsbj.controller.UserController m:找到耗时多的方法

远程监控：
1)arthas-X.x.x-bin,这个包含监控的插件，可作为远程监控的客户端，下载地址：
https://arthas.aliyun.com/doc/download.html
2)arthas--tunnel-server-x.x.x-fatjar.jar,这个是远程监控的服务端，下载地址：https:/Zgithub.com/alibaba/arthas/releases
3)第一步先启动远程服务端，也就是在你自己的电脑上启动服务端arthas-tunnel-server的jar包，启动后记下地址给客户端也
就是要监控的电脑启动arthas用，一般默认为，ws:/xxx.xxx.x.xxx/ws,这个ip是自己电脑的ip。
4)第二步把下载好的arthas-x.x.x-bin文件夹拷贝到要监控的服务器上，然后输入启动命令并带上第1条保存下来的tunnel服务
地址，java-jar arthas-boot.jar-tunnel-server ws:/xxx.xxx.x.xxx/ws-agent-id xxxxxxx,agent-id为自定义的id,作为注
册到tunnel服务器上的唯一id



@ java visualVM熟练用法
VisualVM是一款免费的，集成了多个JDK命令行工具的可视化工具，它能为您提供强大的分析能力，对Java应用程序做性
能分析和调优。这些功能包括生成和分析海量数据、跟踪内存泄漏、监控垃圾回收器、执行内存和CPU分析，同时它还支持
在MBeans上进行浏览和操作。本文主要介绍如何使用VisualVM进行性能分析及调优。
工具所在位置：windows下jdk安装路径内，C:Program Files\Javaljdk1.8.0_20\bin\jvisualvm.exe双击执行
VisualVM可以根据需要安装不同的插件，每个插件的关注点都不同，有的主要监控GC,有的主要监控内存，有的监控线程
等。
(1)安装插件
1)从主菜单中选择“工具”>“插件”。
2)在“可用插件”标签中，选中该插件的“安装”复选框。单击“安装”。
3)逐步完成插件安装程序。
如果可选插件没有，那么需要更换插件更新地址：在如下网址中找到自己j业版本的插件地址：
https://visualvm.github.io/pluginscenters.html
Monitor下面有四个checkbox:CPU/Memory./Class/Thrteads
(2)监控范围
本地和远程（输入ip端口）
(3)内存堆Heap监控
生成dump:在程序运行结束之前，点击Heap Dump按钮，等待一会儿，得到dump结果，可以看到一些Summary信息
到哪些对象占内存大。
个
(4)永久保留区域PermGen监控
一个类型装载之后会创建一个对应的java.lang.Class实例，这个实例本身和普通对象实例一样存储于堆中，我觉得之所以说是
这是一种特殊的实例，
某种程度上是因为其充当了访问PermGenl区域中类型信息的代理者。运行一段时间后抛OutOfMemoryError.了
PermGen区域分配的堆空间过小，我们可以通过设置-XX:PermSize参数和-XX:MaxPermSize:参数来解决。
(5)CPU分析篇
过高的CPU使用率可能是由于我们的项目中存在低效的代码；
点击取样器Sampler.点击“CPU”按钮，启动CPU性能分析会话，VisualVM会检测应用程序所有的被调用的方法，
在CPU samples tab下可以看到我们的方法cpufix(的自用时间最长
(6)线程分析篇
Java语言能够很好的实现多线程应用程序。当我们对一个多线程应用程序进行调试或者开发后期做性能调优的时候，往往需要
了解当前程序中所有线程的运行状态，是否有死锁、热锁等情况的发生，从而分析系统可能存在的问题。
在VisualVM的监视标签内，我们可以查看当前应用程序中所有活动线程(Live threads)和守护线程(Daemon threads)的
数量等实时信息
(7)远程监控
linux远程机器配置JMX,在server.xml中添加listener,添加catalina-jmx-remote.jar,设置防火墙
https://blog.csdn.net/autfish/article/details/51326340
参考：https://www.cnblogs.com/happy-rabbit/p/6232581.html



@ stw和cms和G1详细
(1)STW
Java中Stop-The-World机制简称STW,是在执行垃圾收集算法时，Java应用程序的其他所有线程都被挂起（除了垃圾收集帮
助器之外)。Java中一种全局暂停现象，全局停顿，所有Java代码停止，native代码可以执行，但不能与JVM交互；这些现象多半是由于gg
引起。GC时的Stop the World(STW)是大家最大的敌人。
不管选择哪种GC算法，stop-the-world(stw)都是不可避免的。Stop-the-world意味着从应用中停下来并进入到Gc执行过
程中去。一旦Stop-the-world发生，除了GC所需的线程外，其他线程都将停止工作，中断了的线程直到GC任务结束才继续它们的任
务。GC调优通常就是为了改善stop-the-world的时间。

(2)CMS--基于标记清除
).初始标记(Stop the World事件CPU停顿，很短)初始标记仅标记一下GC Rootsi能直接关联到的对象，速度很快；
).并发标记（收集垃圾跟用户线程一起执行）初始标记和重新标记任然需要“stop the world”,并发标记过程就是进行GC
Roots Tracing的过程；
3).重新标记(Stop the World事件CPU停顿，比初始标记稍微长，远比并发标记短)修正并发标记期间因用户程序继续运作而
导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记时间短
4).并发清理-清除算法；
整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，所以，从总体上来说，C收集器
不
内存回收过程是与用户线程一起并发执行的。
优点：并发收集、低停顿
缺点：CMS收集器对CPU资源非常敏感、CMS处理器无法处理浮动垃圾、CMS是基于“标记-清除”算法实现的，所以在收集结
束的时候会有大量的空间碎片产生。
CMS在并发清理阶段线程还在运行，伴随着程序的运行自然也会产生新的垃圾，这一部分垃圾产生在标记过程之后，CMS
无法再当次过程中处理

(3)G1(Garbage First)--基于标记整理
1).初始标记(stop the world事件CPU停顿只处理垃圾)；
2).并发标记（与用户线程并发执行）；（不会触发stop the world事件）
3).最终标记(stop the world事件，CPU停顿处理垃圾)；
4).筛选回收(stop the world事件根据用户期望的GC停顿时间回收)；
不

(4)与其他GC收集器相比，G1具备如下特点：
1).并行于并发：G1能充分利用CPU、多核环境下的硬件优势，使用多个CPU(CPU或者CPU核心)来缩短Stop-The-World停
顿时间。部分其他收集器原本需要停顿Java线程执行的GC动作，G收集器仍然可以通过并发的方式让java程序继续执行。
2.分代收集：虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但是还是保留了分代的概念。它能够采用不同的方
式去处理新创建的对象和已经存活了一段时间，熬过多次的旧对象以获取更好的收集效果。
3).空间整合：与CM的“标记-清理”算法不同*，G1从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于
“复制”算法实现的*。
4.可预测的停顿：这是G1相对于CMS的另一个大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了追求低停顿
外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为毫秒的时间片段内。
5).都支持并发和分代，G1最大化释放堆内存没有内存碎片，吞吐量高，可预测性强，G1充分利用多CPU、多核环境下的硬件优
势



@ 能否JVM调优几乎不触发fullgc?什么时候触发Full gc和Minor gc?
(1)Minor gc-复制算法
发生在新生代上，因为新生代对象存活时间很短，因此Minor GC会频繁执行，执行的速度一般也会比较快毫秒级，通过幸存区交换来处理
触发条件：当创建对象时Eden区空间不够时触发，当执行MinGCE时。
初级回收将年轻代分为三个区域，一个新生代Ede,2个大小相同的复活代(S0-S1),应用程序只能使用一个新生代和一个复活代。
当对象在Eden出生后，在经过一次Minor GC后，如果对象还存活，并且能够被另外一块Survivor区域所容纳，则使用
算法将这些仍然还存活的对象复制到另外一块Survivor区域中
然后清理所使用过的Eden以及Survivor区域，并且将这些对象的年龄设置为,以后对象在Survivor区每熬过一次Minor
GC,就将对象的年龄+1，
当对象的年龄达到某个值时（默认是15岁，可以通过参数-XX:MaxTenuringThreshold来设定），这些对象就会成为老年代。
但这也不是一定的，对于一些较大的对象（即需要分配一块较大的连续内存空间）则是直接进入到老年代。

(2)Full GC-标记-清除
发生在老年代上，老年代对象其存活时间长，因此Full GC很少执行，执行速度会比Minor GC慢很多秒级
标记-清除算法收集垃圾的时候会产生许多的内存碎片（即不连续的内存空间），此后需要为较大的对象分配内存空间时，若无
法找到足够的连续的内存空间，就会提前触发一次GC的收集动作。
触发条件：
1)调用System.gc),建议虚拟机执行不一定真正去执行。不建议
2)老年代空间不足
老年代空间不足的常见场景为前文所讲的大对象直接进入老年代、长期存活的对象进入老年代等。
为了避免以上原因引起的Full GC,应当尽量不要创建过大的对象以及数组。
除此之外，可以通过-Xm虚拟机参数调大新生代的大小，让对象尽量在新生代被回收掉，不进入老年代。
还可以通过-XX:MaxTenuringThreshold调大对象进入老年代的年龄，让对象在新生代多存活一段时间。
3)JDK1.7及以前的永久代空间不足
在Java8中，永久代被彻底移除，取而代之的是另一块与堆不相连的本地内存一一元空间。
(3)尽可能不执行Full GC
Full GC最根本的产生原因就是有对象不停的进入老年代，最后导致空间不足，引发Full GC。
解决思路就是直接破坏掉产生条件，直接减少运行时期间从新生代晋升到老年代的对象，或者没有对象晋升到老年代就行了。

# 大对象频繁进行老年代，造成老年代空间快速被占满，造成Full GC。
解决方案：合理配置-XX:PretenureSizeThreshold大小。避免过多非必要对象进入老年代。
# metaspace空间不足
解决方案：一般这个里面存放的都是一些Class类信息，Class本身也是一个对象，需要空间存放。那么程序代码中什么时候
会产生对象进入呢，当使用CGLIB动态代理不停的生成代理类的时候，
就会加载到元数据空间，当然一般4核8G内存的物理机分配个512M是完全没问题的。
#从年轻代晋升到老年代的对象，默认是15次
解决方案：弱引用，单例模式内存泄漏，o流关闭，合理分配新生代老年代内存比例大小，Xmx和ms一样大

新生代可以按照默认比例1/3；Xss一兆左右；
我们按照默认情况下的设置，新生代1/3的堆空间，老年代2/3的堆空间。Eden:S0:S1=8:1:1


@ 单机几十万并发JVM调优
(1)设置tomcat的线程池，maxThreads:最大并发数，默认设置200，一般建议在500~1000，根据硬件设施和业务来判断
(2)设置tomcat的运行模式为NIO2模式
(3)先考虑增大堆内存，增大年轻代大小，再进行压测。
(4)JVM参数设定不能拍脑袋，需要从实际出发，根据压测结果来定；
(5)内存中临时对象较多，将年轻代调大一些。
(6)调优过程依赖于GC日志的分析结果，来找到问题
(7)超大流量电商大促高并发系统下JVM调优思路
把转换成QPS,一天4万秒，28原则，只需要解决每台机器能抗住208单/s即可。
·对于重点关注的业务区域分析，估计每个每个对象的大小，然后将每个订单对象大小进行扩大，比如扩大100倍。假设每
个对象为1K,扩大100倍后就是产生一个订单，就会占用100K内存空间；
·大促期间，前一小时就是，每秒占用空间就是208*100=20800K=20M。
·根据上面的分析结果来给出JVM主要参数。
·然后依据初始参数，进行压力测试，不断调整参数，不断进行压测，直至满足性能指标。
(8)调优设置
-Xms3000m"
/堆初始值
-Xmx3000m"
/堆最大值
-XX:MaxPermSize=256m
/Java虚拟机永久代大小最大值
-Xmn512m"
/堆最小值
-XX:+UseConcMarkSweepGC"/使用CMS垃圾收集器
-XX:+UseParNewGC"
/使用parallel New垃圾收集器
-XX:+UseG1GC
/使用G1GC
-XX:MaxGCPauseMillis=200/最大GC暂停时间，用户可以设置这个值，G1GC尽量保证软实时性
G1是包括年轻代和年老代的GC、CMS是年老代GC



@ 亿级流量电商JVM调优
(1)超大流量电商大促高并发系统下VM调优思路
把pv转换成QPS,一天4万秒，28原则，只需要解决每台机器能抗住208单/s即可。
·对于重点关注的业务区域分析，估计每个每个对象的大小，然后将每个订单对象大小进行扩大，比如扩大100倍。假设每
个对象为1K,扩大100倍后就是产生一个订单，就会占用100K内存空间；
·大促期间，前一小时就是，每秒占用空间就是208*100=20800K=20M。
·根据上面的分析结果来给出JVM主要参数。
·然后依据初始参数，进行压力测试，不断调整参数，不断进行压测，直至满足性能指标。
(2)调优设置
-Xms3000m"
/堆初始值
-Xmx3000m"
/堆最大值
-XX:MaxPermSize=256m"
/Java虚拟机永久代大小最大值
-Xmn512m"
/堆最小值
-XX:+UseConcMarkSweepGC”/使用CMS垃圾收集器
-XX:+UseParNewGC"
/使用parallel New.垃圾收集器
-XX:+UseG1GC
/使用G1GC
-XX:MaxGCPauseMillis=200/最大GC暂停时间，用户可以设置这个值，G1GC尽量保证软实时性
G1是包括年轻代和年老代的GC、CMS是年老代GC




@ 高并发为何选择G1?
(1)高并发下面：每台订单服务器也就是大概500单/秒我们测试发现，每个订单处理过程中会占据0.2MB大小的空间（什
么订单信息、优惠券、支付信息等等)，那么一台服务器每秒产生100M的内存空间，这些对象基本上都是朝生夕死，也就是
1秒后都会变成垃圾对象。

(2)G1是一款【并行+并发】方式的【增量】垃圾收集器，将堆内存划分为很多个region,与其他GC算法实现相比，提供
了可预测性更精准的暂停时间。
增量特性使得G可以处理更大的堆内存空间，在最坏情况下依然保持合理的响应时间。
G1具有自适应特性，一般情况下，只需要设置3个调优参数即可：
期望的最大暂停时间，例如-XX:MaxGCPauseMillis:=50
堆内存的最大值，例如-Xmx4g
堆内存的最小值，例如-Xms4g

(3)与其他GC收集器相比，G1具备如下特点：
1).并行于并发：G1能充分利用CPU、多核环境下的硬件优势，使用多个CPU(CPU或者CPU核心)来缩短Stop-The-World停
顿时间。部分其他收集器原本需要停顿Java线程执行的GC动作，G收集器仍然可以通过并发的方式让java程序继续执行。
2.分代收集：虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但是还是保留了分代的概念。它能够采用不同的方
式去处理新创建的对象和已经存活了一段时间，熬过多次GC的旧对象以获取更好的收集效果。
3.空间整合：与CM的“标记-清理”算法不同*，G从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于
“复制”算法实现的**。
4).可预测的停顿：这是G1相对于CMS的另一个大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了追求低停顿
外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为毫秒的时间片段内。
5).都支持并发和分代，G1最大化释放堆内存没有内存碎片，吞吐量高，可预测性强，G1充分利用多CPU、多核环境下的硬



@ 千万级数据如何用索引快速查找
到+树上两层都是存放的索引，最后一层存放的索引+数据，最后一层的索引和上两层的是冗余的，这样的话两层可以去放更多的索引
那么B+tree可以支持多少数据的查找呢？
MySQL官方对非叶子节点（如最上层h=1的节点，B+Tee高度为3）的大小是有限制的，最大的大小是16K,可以通过以下sQL
语句查询到当然这个值是可以调的，既然官方给出这个阈值说明再大的话会影响磁盘○效率
一个节点的大小：索引+指针索引节点类型Bigint(8B)+指针大小(6B)=14B
第一层和第二层存放的全是节点那么第一层第二层可以存放的节点数：16k/14B=1170
第一层1右故1170个书占包一个书占却右++向下一一恤+小数旦1人州战旦1170个书占依次米堆三可

一个节点的大小：索引+指针索引节点类型Bigint(8B)+指针大小(6B)=14B
第一层和第二层存放的全是节点那么第一层第二层可以存放的节点数：16k/14B=1170
第一层可以存放1170个节点每一个节点都有指针，指针指向下一块每一块大小都是16K也就是1170个节点依次类推第三层可
以有11701170快16k的空间。假设我们第三城每个数据是1K的话那么一块可以存放16个data数据总共就是11701170*16条数据.

1170117016=21,902,400也就是说我们B+tree可以存放2000w条数据




@ 红黑树和B+树区别，为何数据库索引不用红黑树？
红黑树：二叉查找树+平衡二叉树（大致平衡的）
AVL树和红黑树这些二叉树结构的数据结构可以达到最高的查询效率这是毋庸置疑的，所以jdk中hashmap。
既然如此，那么数据库索引为什么不用AVL树或者红黑树呢？
这就牵扯到一个问题了，不考虑每种数据结构的前提条件而选择数据结构都是在耍流氓。
A儿数和红黑树基本都是存储在内存中才会使用的数据结构，那磁盘中会有什么不同呢？
这就要牵扯到磁盘的存储原理了
操作系统读写磁盘的基本单位是扇区，而文件系统的基本单位是簇(Cluster)。
也就是说，磁盘读写有一个最少内容的限制，即使我们只需要这个簇上的一个字节的内容，我们也要含着泪把一整个簇上的个
容读完。
那么，现在问题就来了
一个父节点只有个子节点，并不能填满一个簇上的所有内容啊？那多余的内容岂不是要浪费了？我们怎么才能把浪费的这部
分内容利用起来呢？答案就是B+树。
由于B+树分支比二叉树，所以相同数量的内容，B+树的深度更浅，深度代表什么？代表磁盘次数啊！数据库设计的
时候+树有多少个分支都是按照磁盘一个簇上最多能放多少节点设计的啊！
所以，涉及到磁盘上查询的数据结构，一般都用+树。




@ 索引结构和数据的映射？
在B树中，你可以将键和值存放在内部节点和叶子节点；但在B+树中，内部节点都是键，没有值，叶子节点同时存放键和值。
B+树的叶子节点有一条链相连，而B树的叶子节点各自独立
如果没有索引，磁盘上数据杂乱无章，简历索引之后，根据字段name搭建一颗B+树，叶子节点key指向数据磁盘位置，
如果根据name查找，用的是B+查找树，矮胖型，lO少，顶多3层就可以找到对应的数据位置。
如果有多个索引也是一样的。



@ 如何基于B+树索引建立高性能索引？
https://blog.csdn.net/u014253011/article/details/80200927
(1)索引性能
索引对于良好的性能非常关键。尤其是当表中的数据量越来越大时，索引对性能的影响愈发重要。
在数据量小且负载较低时，不恰当的索引对性能的影响可能还不明显，但是当数据量逐渐增大时，性能会急剧下降。索引可以
包含一个或者多个列的值。
如果索引包含了多个列，那么列的顺序也十分重要。
因为MySQL只能高效地使用索引的最左前缀列(B+树的数据结构决定的)。
创建一个包含两个列的索引和创建两个包含一列的索引是大不相同的。

(2)高性能的索引策略
1)独立的列
指索引不能是表达式的一部分，也不能是函数的参数。常见的非独立的列：
select act id from table whereact id+1=5;/(表达式的一部分，不是独立列)
select*from table where TO DAYS(CURRENT DATE)-TO DAYS(date col)<=1O;/函数的参数

2)索引的选择性
不重复的值(Cardinality,基数)占数据表总数的比值。索引的选择性越高则查询效率越高，因为选择性高的索引可以让
MySQL在查找时过滤掉的行。
唯一索引的选择性是1，这时最好的索引选择性，性能也是最好的。
选择索引时应该选择足够长的前缀以保证较高的选择性，同时又不能太长。

3)善用前缀索引
索引选择性：select1.O*count(distinct column_name)/count(*)from table_name
column_name总数7达到75%，前面5位达到73%，非常接近，适合建立前缀索引。

4)善用组合索引
组合索引可以这样理解，比如(a,b,c),abc都是排好序的，在任意一段a的下面b都是排好序的，任何一段b下面c都是排好月
的；
组合索引的生效原则是从前往后依次使用生效，如果中间某个索引没有使用，那么断点前面的索引部分起作用，断点后面的
索引没有起作用；
where a=3andb=45andc=5这种三个索引顺序使用中间没有断点，全部发挥作用；
where a=3andc=5.….这种情况下b就是断点，a发挥了效果，c没有效果
where b=3andc=4…这种情况下a就是断点，在a后面的索引都没有发挥作用，这种写法联合索引没有发挥任何效果
where b=45anda=3andc=5…这个跟第一个一样，全部发挥作用，abc只要用上了就行，跟写的顺序无关
因为mysgl组合索引“最左前缀”的结果。

5)善用聚簇索引
聚簇索引并不是一种单独的索引类型，而是一种数据存储方式。InnoDB的聚簇索引实际上在同一个结构中保存了B-Tree索引和
数据行（索引的顺序与数据的物理存放位置一致，聚簇表示数据行和相应的键值紧凑地存储在一起），
因为无法同时把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。
InnoDB通关过主键聚集数据。如果没有定义主键，InnoDB会选择一个唯一的非空索引作为替代。
如果没有这样的索引，InnoDB会隐式定义一个主键来作为聚簇索引。
InnoDB只聚集在同一个页面中的记录，包含相邻键值的页面可能会相距很远。
#可以把相关的数据保存在一起
#数据访问更快。聚集索引将索引和数据保存在同一个B-ee中，因此从聚簇索引中获取数据通常比在非聚簇索引中更快。
#聚簇索引最大限度的提高了/密集型应用的性能
#一般的索引都是key指向数据的位置，聚集索引存在一起，主键

6)善用覆盖索引
就是selectl的数据列只用从索引中就能够取得，不必从数据表中读取，换句话说查询列要被所使用的索引覆盖。
当发起一个被索引覆盖的查询（也叫作索引覆盖查询）时，在EXPLAIN的Extra列可以看到“Using index”的信息
建了索引但是查询不走索引：
select order code,order amount from t order order by order code limit 1000;
发现虽然在order code上建了索引，但是看查询计划却不走索引，为什么呢？因为数据行读取order amount,所以是随机io。
那怎么办？重新建索引，使用覆盖索引。
ALTER TABLE 't order'ADD INDEX idx_ordercode orderamount'USING BTREE (order_code ASC,'order amount'ASC);
覆盖索引是一种非常强大的工具，能大大提高查询性能，只需要读取索引而不需要读取数据，有以下优点：
#索引项通常比记录要小，所以MySQL访问更少的数据。
#索引都按值得大小存储，相对于随机访问记录，需要更少的/。
#数据引擎能更好的缓存索引，比如MyISAM.只缓存索引。
#覆盖索引对InnoDB尤其有用，因为InnoDB使用聚集索引组织数据，如果二级索引包含查询所需的数据，就不再需要在聚集索引中查找了。
限制：
#覆盖索引也并不适用于任意的索引类型，索引必须存储列的值。
#Hash和full-text索引不存储值，因此MySQL只能使用BTree。
#不同的存储引擎实现覆盖索引都是不同的，并不是所有的存储引擎都支持覆盖索引。
#如果要使用覆盖索引，一定要注意SELECT列表值取出需要的列，不可以SELECT*,因为如果将所有字段一起做索引会导致
索引文件过大，查询性能下降。

7)使用索引扫描做排序
mysql有两种方式可以生成有序的结果：通过排序操作或者按索引顺序扫描，如果explain出来的type列的值为index,则说明
mysql1使用了索引扫描来做排序。
扫描索引本身是很快的，因为只需要从一条索引记录移动到紧接着的下一条记录。但如果索引不能覆盖查询所需的全部列，那
么就不得不每扫描一条索引记录就得回表查询一次对应的行
这基本都是随机◎，因此按索引顺序读取数据的速度通常要比顺序地全表扫描慢。

8)使用前缀压缩索引
MyISAM使用前缀压缩来减少索引的大小，从而让的索引可以放入内存中，这在某种情况下可以极大地提高性能。默认只
压缩字符串，但通过参数设置也可以对整数压缩。
如：索引块中的第一个值是perform,第二个是performance,那么第二个值的前缀压缩后存储的是类似7，ance,这样的形
式，myisam对行指针也采用类似的前缀压缩方式。
对于CPU密集型的应用，因为扫描需要随机查找，压缩索引使得MyISAM在索引上查找要慢很多，压缩索引的倒序扫描更慢

9)冗余和重复索引
重复索引指在相同的列上按照相同的顺序创建的相同类型的索引，应该避免创建重复索引，发现之后应该立即，否者会影
响性能。
冗余索引与重复索引不同，如果创建了索引(A,B),之后又创建了索引(A)就是冗余索引。大多数情况下不需要冗余索引，应该
尽量扩展已有的索引而不是创建新索引。
冗余索引的缺点是维护索引的成本更高（典型的如：插入表的速度变慢。实际上，增加索引会导致INSERT,UPDATE,DELETE
等操作变慢)

10)利用索引锁定更少的记录
索引可以让查询锁定更少的行。如果你的查询从不访问哪些不需要的行，那么就会锁定更少的行，从两个方面来看这对性能都
有好处。
首先，虽然InnoDB的行锁的效率很高，内存使用也很少，但是锁定行的时候依然会带来额外开销；
其次，锁定需要的行会增加所争用并减少并发性。
InnoDB只有在访问行的时候才会对其加锁，只要走了索引只对相关的锁住。

11)维护索引和表
维护表的主要目的有三个：找到并修复损坏的表，维护准确的索引统计信息，减少碎片。
Check Table可以找出大多数表和索引的错误。
可以使用RepairTable来修复损坏的表。
也可以通过alter tablel的方式来修复表（修改表的引擎为当前的引擎，如alter table xxx ENGINE=InnoDB)
一般情况下，InnoDB表不容易损坏，如果损坏，很大可能是数据库的硬件问题（内存或者硬盘）。

12)减少索引和数据的碎片
B-Tee索引可能会碎片化，这会降低查询的效率。碎片化的索引可能会以很差或者无序的方式存储在磁盘上
可以通过执行OPTIMIZE TABLE或者导出再导入的方式来重新整理数据。



@  聚集索引和非聚集索引深入
聚簇索引并不是一种单独的索引类型，而是一种数据存储方式。InnoDB的聚簇索引实际上在同一个结构中保存了B-Tree索引和
数据行（索引的顺序与数据的物理存放位置一致，聚簇表示数据行和相应的键值紧凑地存储在一起），
因为无法同时把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。
InnoDB通关过主键聚集数据。如果没有定义主键，InnoDB会选择一个唯一的非空索引作为替代。
如果没有这样的索引，InnoDB会隐式定义一个主键来作为聚簇索引。
InnoDB只聚集在同一个页面中的记录，包含相邻键值的页面可能会相距很远。
#可以把相关的数据保存在一起
#数据访问更快。聚集索引将索引和数据保存在同一个B-Tee中，因此从聚簇索引中获取数据通常比在非聚簇索引中更快
#聚簇索引最大限度的提高了/◎密集型应用的性能
#一般的索引都是key指向数据的位置，聚集索引存在一起，主键
非聚集索引：该索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同。





@ 联合索引和单个索引？覆盖索引？三星索引？
(1)联合索引和单个索引
分别在vc_Name,vc_City,i_Age上建立单列索引，让该表有3个单列索引，查询时和上述的组合索引效率一样吗？
3个单列索引远远低于组合索引。虽然此时有了三个索引，但MySQL只能用到其中的那个它认为似乎是最有效率的单列索引。

(2)覆盖索引
就是selectl的数据列只用从索引中就能够取得，不必从数据表中读取，换句话说查询列要被所使用的索引覆盖。
当发起一个被索引覆盖的查询（也叫作索引覆盖查询）时，在EXPLAIN的Extra列可以看到“Using index”的信息
建了索引但是查询不走索引：
select order code,order amount from t order order by order code limit 1000;
发现虽然在order code.上建了索引，但是看查询计划却不走索引，为什么呢？因为数据行读取order amount.所以是随机iO。
那怎么办？重新建索引，使用覆盖索引。
ALTER TABLE 't order'ADD INDEX idx ordercode orderamount'USING BTREE (order code'ASC,'order amount ASC);
覆盖索引是一种非常强大的工具，能大大提高查询性能，只需要读取索引而不需要读取数据，有以下优点：
#索引项通常比记录要小，所以MySQL访问更少的数据。
#索引都按值得大小存储，相对于随机访问记录，需要更少的/◎。
#数据引擎能更好的缓存索引，比如MyISAM只缓存索引。
#覆盖索引对InnoDB尤其有用，因为InnoDB使用聚集索引组织数据，如果二级索引包含查询所需的数据，就不再需要在聚集
索引中查找了。

限制：
#覆盖索引也并不适用于任意的索引类型，索引必须存储列的值。
#Hash和full-text索引不存储值，因此MySQL只能使用BTree。
#不同的存储引擎实现覆盖索引都是不同的，并不是所有的存储引擎都支持覆盖索引。
#如果要使用覆盖索引，一定要注意SELECT列表值取出需要的列，不可以SELECT*,因为如果将所有字段一起做索引会导致
索引文件过大，查询性能下降。

(3)三星索引
建立索引l:create index id.idx cust on id.cust(city,Iname,fname,cno);
第一颗星：where后面所有谓词的列，把这些做组合索引的开头的列，如下sgl的where条件的city,Iname开头，顺序随意。
第二颗星：order by的字段加入组合索引中，并且索引顺序靠前，比如where Iname order by fname不满足。where fname
order by Iname满足。
第三颗星：覆盖索引，不回表，将查询中剩余的列加入组合索引中select中的cno字段(fname之前已加入过)



@ 自增主键和uuid对索引的影响？
(1)自增主键优点
数据库自动编号，速度快，而且是增量增长，按顺序存放，对于检索非常有利
数字型，占用空间小，易排序，在程序中传递也方便；
如果通过非系统增加记录时，可以不用指定该字段，不用担心主键重复问题。
(2)自增主键缺点
因为自动增长，在手动要插入指定D的记录时会显得麻烦，尤其是当系统与其它系统集成时，需要数据导入时，很难保证原系
统的ID不发生主键冲突（前提是老系统也是数字型的）。
特别是在新系统上线时，新旧系统并行存在，并且是异库异构的数据库的情况下，需要双向同步时，自增主键将是你的噩梦：
在系统集成或割接时，如果新旧系统主键不同是数字型就会导致修改主键数据类型，这也会导致其它有外键关联的表的修后果同样很严重；
若系统也是数字型的，在导入时，为了区分新老数据，可能想在老数据主键前统一加一个字符标识（例如“o”,o)来表示这
是老数据，那么自动增长的数字型又面临一个挑战。
(3)UUID优点
出现数据拆分、合并存储的时候，能达到全局的唯一性
(4)UUID缺点
影响插入速度，并且造成硬盘使用率低
uuid之间比较大小相对数字慢不少，影响查询速度。
uuid占空间大，如果你建的索引越多，影响越严重。
(5)自增对索引的影响
InnoDB使用聚集索引，数据记录本身被存于主索引（一颗B+Tree)的叶子节点上。这就要求同一个叶子节点内（大小为-个
内存页或磁盘页)的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，
MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子(InnoDB默认为15/16)，则开辟一个新的页（节点)。
如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。
这样就会形成一个紧凑的索引结构，近似顺序填满。由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多开销在维护索引上。
如果使用非自增主键uuid,由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置，此时MySQL不得不为了将新记录插到合适位置而移动数据，
甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分
页操作造成了大量的碎片，
得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。
因此，只要可以，请尽量在InnoDB上采用自增字段做主键。



@ 建立索引原则深入
#查询频率高的字段创建索引，注意覆盖索引
#对排序order by、分组group by、连接字段join on频率高的字段创建索引l,注意第二星
#根据多个字段查询建立组合索引，注意第一星
#索引的数目不宜太多5-6个，维护占空间，并且影响insert、update、delete性能
#索引尽可能唯一性，性别，名族，clob这种不能建索引
#尽量使用前缀来索引
#利用索引锁定更少的记录
#in里面的数据量三分之一之内走索引，大于不走
#如果条件中有or不走索引
#ike查询是以%开头，索引不会命中
#B+tree索引is null不会走，is not null会走



@  mysgli最左前缀原则优化？
组合索引可以这样理解，比如(a,b,c),abc都是排好序的，在任意一段a的下面b都是排好序的，任何一段b下面c都是排好序的；
组合索引的生效原则是从前往后依次使用生效，如果中间某个索引没有使用，那么断点前面的索引部分起作用，断点后面的
索引没有起作用；
where a=3 and b=45 and c=5…这种三个索引顺序使用中间没有断点，全部发挥作用；
where a=3 and c=5…这种情况下b就是断点，a发挥了效果，c没有效果
where b=3 and c=4..这种情况下a就是断点，在a后面的索引都没有发挥作用，这种写法联合索引没有发挥任何效果；
where b=45 and a=3 and c=5…这个跟第一个一样，全部发挥作用，abc只要用上了就行，跟写的顺序无关，重要！！
因为mysql组合索引“最左前缀”的结果。
17为何DBA推荐自增主键做索引
InnoDB使用聚集索引，数据记录本身被存于主索引（一颗B+Tree)的叶子节点上。这就要求同一个叶子节点内（大小为一个
内存页或磁盘页)的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，
MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子(InoDB默认为15/16)，则开辟一个新的页



@ 为何DBA推荐自增主键做索引
InnoDB使用聚集索引，数据记录本身被存于主索引（一颗B+Tree)的叶子节点上。这就要求同一个叶子节点内（大小为一个
内存页或磁盘页)的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，
MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子(InnoDB默认为15/16)，则开辟一个新的页（节点)。
如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。
这样就会形成一个紧凑的索引结构，近似顺序填满。由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多
开销在维护索引上。
如果使用非自增主键uid,由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置，此不MySQL不得不为了将新记录插到合适位置而移动数据，
甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分
页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。
因此，只要可以，请尽量在InnoDB上采用自增字段做主键。




@ 阿里巴巴索引优化军规
1.业务上具有唯一特性的字段，即使是多个字段的组合，也必须建成唯一索引。
说明：不要以为唯一索引影响了insert速度，这个速度损耗可以忽略，但提高查找速度是明显的；另外，即使在应用层做了非常
完善的校验控制，只要没有唯一索引，根据墨菲定律，必然有脏数据产生。

2 超过三个表禁止join。需要join的字段，数据类型必须绝对一致；多表关联查询时，保证被关联的字段需要有索引。
说明：即使双表join也要注意表索引、SQL性能。

3 页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎来解决。
说明：索引文件具有B-Tree的最左前缀匹配特性，如果左边的值未确定，那么无法使用此索引。

4.如果有order by的场景，请注意利用索引的有序性。order by最后的字段是组合索引的一部分，并且放在索引组合顺序的
最后，避免出现file_sort的情况，影响查询性能。正例：where a=?andb=?order by c;索引：abc反例：索引中有范围查找
那么索引有序性无法利用，如：WHERE a>10 ORDER BY b;索引ab无法排序。
有组合索引Index(A,B)。
(1)下面条件可以用上组合索引排序：
ORDER BY A一一首列排序
A=5 ORDER BY B一一第一列过滤后第二列排序
ORDER BY A DESC,B DESC一一注意，此时两列以相同顺序排序
A>5 ORDER BYA一一数据检索和排序都在第一列
(2)下面条件不能用上组合索引排序：
ORDER BY B一一排序在索引的第二列
A>5 ORDER BY B一一范围查询在第一列，排序在第二列
AIN(1,2)ORDER BY B一一理由同上
ORDER BY AASC,B DESC一一注意，此时两列以不同顺序排序
如果对有没有用上索引有疑惑可以写完sql以后用explain来运行一下sgl可以更有利于理解sgl的执行过程

5.利用覆盖索引来进行查询操作，避免回表。
说明：如果一本书需要知道第11章是什么标题，会翻开第11章对应的那一页吗？目录浏览一下就好，这个目录就是起到覆盖索
引的作用。正例：能够建立索引的种类分为主键索引、唯一索引、普通索引三种，而覆盖索引只是一种查询的一种效果，用
explain的结果，extra列会出现：using index.。

6.利用延迟关联或者子查询优化超多分页场景。
说明：MySQL并不是跳过offset行，而是取offset+N行，然后返回放弃前offset行，返回N行，那当offset特别大的时
效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行QL改写。
正例：先快速定位需要获取的id段，然后再关联：
SELECT a.*FROM表1a,(select id from表1 where条件LIMIT100000,20)b where a.id=b.id

7.SQL性能优化的目标：至少要达到range级别，要求是ref级别，如果可以是consts最好。
1)consts单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。
2)ref指的是使用普通的索引(normal index)。
3)range对索引进行范围检索。
反例：explain表的结果，type=index,索引物理文件全扫描，速度非常慢，这个index级别比较range还低，与全表扫描
巫见大巫。

8 explain type类型
1)const
当你使用主键或者唯一索引的时候，就是const类型，比如下面这两种查询
#单一主键
SELECT FROM tbl_name WHERE primary_key=1;
#联合主键
SELECT FROM tbl_name WHERE primary_key_part1=1 AND primary_key_part2=2;
2)ref
在对已经建立索引列进行=或者<=>操作的时候，ref会被使用到。与eq_ref不同的是匹配到了多行
#根据索引（非主键，非唯一索引），匹配到多行
SELECT FROM ref table WHERE key_column=expr;
#多表关联查询，单个索引，多行匹配
SELECT FROM ref table,other table WHERE ref table.key column=other table.column;
3)range
只有给定范围内的行才能被检索，使用索引来查询出多行。输出行中的类决定了会使用哪个索引。key_len3列表示使用的最长
的key部分。这个类型的ref列是NULL。
#常量比较，可能多行（但是这里的例子和上面ef的第一个例子不一样吗？）
SELECT FROM tbl_name WHERE key_column 10;
#范围查找
SELECT FROM tbl name WHERE key column BETWEEN 10 and 20;
#范围查找
SELECT FROM tbl name WHERE key_column IN (10,20,30);
4)index
#如果索引是查询的覆盖索引，就是说索引查询的数据可以满足查询中所需的所有数据，则只扫描索引树，不需要回表查询。
在这种情况下，explain的Extra列的结果是Using index.。仅索引扫描通常比ALL快，因为索引的大小通常小于表数据。
#全表扫描会按索引的顺序来查找数据行。使用索引不会出现在Extra列中。
5)ALL
全表扫描就不用看了，赶快优化吧。

9建组合索引的时候，区分度最高的在最左边。
正例：如果where a:=?andb=?,如果a列的几乎接近于唯一值，那么只需要单建idxa索引即可。说明：存在非等号和等号混
合时，在建索引时，请把等号条件的列前置。如：where c>?andd=?那么即使c的区分度更高，也必须把d放在索引的最前
列，即索引idx d_c。

10.防止因字段类型不同造成的隐式转换，导致索引失效。
列类型与where值类型不符；join字段类型不符。
11.【参考】创建索引时避免有如下极端误解
1)宁滥勿缺。认为一个查询就需要建一个索引。
2)宁缺勿滥。认为索引会消耗空间、严重拖慢更新和新增速度。
3)抵制惟一索引。认为业务的惟一性一律需要在应用层通过“先查后插”方式解决。



@ nacos详细
阿里的一个开源产品，是针对微服务架构中的服务发现(Eureka)+配置管理(Spring cloud config)综合型解决方案。
Nacos:选择CP+AP原理，健康检查支持TCP/HTTP/MYSQL/Client Beat,提供雪崩保护，访问协议支持HTTP/DNS,支持跨注册
中心同步，支持集成SpringCloud、Dubbo、K8S。
Eureka是AP,zk是cp



@ 注册中心脑裂问题研究
在“双机热备”高可用(HA)系统中，当联系2个节点的“心跳线”断开时，本来为一整体、动作协调的HA系统，就分裂成为2个
独立的个体。由于相互失去了联系，
都以为是对方出了故障，2个节点上的A软件像“裂脑人”一样，“本能”地争抢“共享资源”、争起“应用服务”，就会发生严重后果：或者共享资源被瓜分
2边“服务”都起不来了；或者2边“服务”都起来了，但同时读写“共享存储”，导致数据损坏。
·假死：由于心跳超时（网络原因导致的）认为Leader死了，但其实Leaderi还存活着。
·脑裂：由于假死会发起新的Leaderi选举，选举出一个新的Leader,但|旧的Leaderl网络又通了，导致出现了两个Leader,有
的客户端连接到老的Leader,而有的客户端则连接到新的Leader。

解决脑裂问题
(1) 集群中最少的节点数用来选举Leader保证集群可用
引申：Zookeeper集群节点为什么要部署成奇数？
zookeeper容错指的是：当宕掉几个zookeeper节点服务器之后，剩下的个数必须大于宕掉的个数，也就是剩下的节点服务数
必须大于n/2,这样zookeeper集群才可以继续使用，无论奇偶数都可以选举leader.。例如5台zookeeper节点机器最多宕掉2
台，还可以继续使用，因为剩下3台大于5/2。至于为什么最好为奇数个节点？这样是为了以最大容错服务器个数的条件下，能
节省资源。比如，最大容错为2的情况下，对应的zookeeper服务数，奇数为5，而偶数为6，也就是6个zookeeper服务的情况
下最多能宕掉2个服务，所以从节约资源的角度看，没必要部署6（偶数）个zookeeper服务节点。

zookeeperl的过半机制：
在领导者选举的过程中，如果某台zkServer获得了超过半数的选票，则此zkServer就可以成为Leader了。举个简单的例子：如
果现在集群中有5台zkServer,那么half=5/2=2,那么也就是说，领导者选举的过程中至少要有三台zkServer投了同一个
zkServer,才会符合过半机制，才能选出来一个Leader。
zookeeper过半机制中为什么是大于，而不是大于等于？
这就是更脑裂问题有关系了，比如回到上文出现脑裂问题的场景[如上图]：当机房中间的网络断掉之后，机房内的三台服务
器会进行领导者选举，但是此时过半机制的条件是“节点数>3”，也就是说至少要4台zkServer才能选出来一个Leader,所以对
于机房1来说它不能选出一个Leader,同样机房2也不能选出一个Leader,这种情况下整个集群当机房间的网络断掉后，整个
集群将没有Leader。而如果过半机制的条件是"节点数>=3"，那么机房1和机房2都会选出一个Leader,这样就出现了脑裂。
这就可以解释为什么过半机制中是大于而不是大于等于，目的就是为了防止脑裂。
因此总结得出，有了过半机制，对于一个Zookeepers集群来说，要么没有Leader,要么只有1个Leader,这样zookeepert个
能避免了脑裂问题。

(2) 采用Redundant communications(冗余通信)方式：集群中采用多种通信方式，防止一种通信方式失效导致集群中的节
点无法通信。

(3) Fencing(共享资源)方式：比如能看到共享资源就表示在集群中，能够获得共享资源的锁的就是Leader,看不到共享资
源的，就不在集群中。

(4) 仲裁机制方式。
设置仲裁机制的方案通常是设置一个第三方检测服务器，当slavei确定准备接管master时候，monitor会ping一下master,如
果master:未，则判定其死亡！
同时master)对外提供服务时候，monitort也会定时ping masteri和slave,保证出现异常情况下，暂停服务器业务操作！
仲裁机制的主要问题是monitor存在高可用性能瓶颈。

(5)启动磁盘锁定方式。




@ jmm底层原理
内存模型可以理解为在特定的操作协议下，对特定的内存或者高速缓存进行读写访问的过程抽象描述，不同架构下的物理机拥
有不一样的内存模型，Java虚拟机是一个实现了跨平台的虚拟系统，
因此它也有自己的内存模型，即Java内存模型(Java Memory Model,JMM)。
因此它不是对物理内存的规范，而是在虚拟机基础上进行的规范从而实现平台一致性，以达到va程序能够“一次编写，到处运行”。
内存模型描述了程序中各个变量（实例域、静态域和数组元素）之间的关系，以及在实际计算机系统中将变量存储到内存和从
内存中取出变量这样的底层细节
Java Memory Model(Java内存模型)，围绕着在并发过程中如何处理可见性、原子性、有序性这三个特性而建立的模型。
多核计算机经过各自的cache缓存都要经过缓存一致性协议(MESI)到主内存。
MESI中每个缓存行都有四个状态，分别是E(exclusive)、M(modified)、S(shared)、(invalid)。

这四个状态分别代表什么意思：
M:代表该缓存行中的内容被修改了，并且该缓存行只被缓存在该CPU中。这个状态的缓存行中的数据和内存中的不一样，在
未来的某个时刻它会被写入到内存中（当其他CPU要读取该缓存行的内容时。或者其他CPU要修改该缓存对应的内存中的内容
时（个人理解CPU要修改该内存时先要读取到缓存中再进行修改），这样的话和读取缓存中的内容其实是一个道理)。
E:E代表该缓存行对应内存中的内容只被该CPU缓存，其他CPU没有缓存该缓存对应内存行中的内容。这个状态的缓存行的
内容和内存中的内容一致。该缓存可以在任何其他CPU读取该缓存对应内存中的内容时变成S状态。或者本地处理器写该缓个
就会变成M状态
S:该状态意味着数据不止存在本地CPU缓存中，还存在别的CPU的缓存中。这个状态的数据和内存中的数据是一致的。当有一
个CPU修改该缓存行对应的内存的内容时会使该缓存行变成状态。
:代表该缓存行中的内容时无效的。
当线程共享变量的时候，情况就变得非常复杂了，如果处理器对某个变量进行了修改，可能只是体现在该内核的缓存里，而运行在其
它内核上的线程可能加载的是旧状态，这很可能导致一致性的问题，
从理论上来说，多线程共享引入了复杂的数据依赖性问题，不管处理器，编译器怎么做重排序都必须尊重数据依赖型的要求，否则就
打破了数据的正确性.这就是jmm所要解决的问题（遵照if else指令重排）、
volatile解决了可见性和有序性；
多个索引键可能映射到同一个哈希Bucket.哈希函数经过均衡处理，这意味着索引键值在哈希桶上的分布通常符合泊松分布。
泊松分布并非均匀分布。


@  模拟高并发场景Jmeter
1)jmeter下载https://jmeter.apache.org/download jmeter.cgi
2)到文件bin,执行对应到启动脚本jmeter.sh
3)页面新建一个线程组，然后添加一个HTTP请求
4)设置参数：线程数，时间段，每个用户请求数，请求url,路由
5)发起，查看结果树



@ 基于redisson实现分布式锁
(1)基本用法
<dependency>
<groupld>org.redisson</groupld>
<artifactld>redisson</artifactld>
<version>3.8.2</version>
</dependency>
Config config new Config();
config.useClusterServers()
setScanInterval(2000)//cluster state scan interval in milliseconds
addNodeAddress("redis:/127.0.0.1:7000","redis:/127.0.0.1:7001"
addNodeAddress("redis:/127.0.0.1:7000","redis:/127.0.0.1:7001")
addNodeAddress("redis://127.0.0.1:7002");
RedissonClient redisson Redisson.create(config);
RLock lock redisson.getLock("anyLock");
lock.lock);
try{
finally
lock.unlock);
}
(2)原理
SETNX
将key设置值为value,如果key不存在，这种情况下等同SET命令。当key存在时，什么也不做。SETNX是”SETif Not eXists'”的简写。返回值Integer reply,特定值：
1-如果key被设置了
0-如果key没有被设置




@ 高性能分布式锁实现
分布式环境下synchronized失效，因为synchronized是单JVM下保证锁。
乐观锁>redis锁>zk>db(io性能瓶颈)



@ 本地方法栈研究
(1)本地方法栈(Native Method Stack)
本地方法栈的功能和特点类似于虚拟机栈，均具有线程隔离的特点以及都能抛出StackOverflowErrori和DutOfMemoryError!异常。
不同的是，本地方法栈服务的对象是JVM执行的native方法，而虚拟机栈服务的是JVM执行的java方法。
一个Native Method就是一个java调用非java代码的接口。一个Native Method:是这样一个java的方法：该方法的实现由非java
语言实现，比如C。这个特征并非java所特有，很多其它的编程语言都有这一机制，比如在C++中，你可以用extern“告知C
++编译器去调用一个C的函数。在定义一个native methodl时，并不提供实现体（有些像定义一个java interface),因为其
实现体是由非java语言在外面实现的。，下面给了一个示例：
native public void Native1(int x )
native static public long Native2();
native synchronized private float Native3(Object o )
native void Native4(int]ary.throws Exception
}
标识符native可以与所有其它的java标识符连用，但是abstractl除外。

(2)为什么要使用Native Method
与java环境外交互，与操作系统交互
(3)JVM怎样使Native Method跑起来
我们知道，当一个类第一次被使用到时，这个类的字节码会被加载到内存，并且只会回载一次。在这个被加载的字节码的
维持着一个该类所有方法描述符的list

(3)JVM怎样使Native Method跑起来
我们知道，当一个类第一次被使用到时，这个类的字节码会被加载到内存，并且只会回载一次。在这个被加载的字节码的入口
维持着一个该类所有方法描述符的list
这些方法描述符包含这样一些信息：方法代码存于何处，它有哪些参数，方法的描述符(public之类)等等。如果一个方法描
述符内有native,这个描述符块将有一个指向该方法的实现的指针。这些实现在一些DLL文件内，但是它们会被操作系统加载
到java程序的地址空间。
当一个带有本地方法的类被加载时，其相关的D儿L并未被加载，因此指向方法实现的指针并不会被设置。当本地方法被调用之
前，这些DLL才会被加载，这是通过调用java.system.loadLibrary():实现的。



@ 高性能分布式锁？违背->乐观锁、分段锁？
分布式环境下synchronized失效，因为synchronized:是单JVM下保证锁。
乐观锁>redis锁>zk>db(io性能瓶颈)




@ redis与数据库双写不一致问题
(1)先更新数据库，再更新缓存
1)线程A写操作先更新数据库
2)线程B写操作也更新数据库
3)当线程B比线程A先更新缓存（线程A停滞卡顿）
4)线程A最后更新缓存
导致redis缓存与数据库不一致，出现脏数据，频繁更新，浪费性能

(2)先缓存，再更新数据库
1)请求A进行写操作，缓存
2)请求B查询发现缓存不存在
3)请求B去数据库查询得到旧值
4)请求B将旧值写入缓存
5)请求A将新值写入数据库
上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。
那么，如何解决呢？采用延时双删策略
1)先淘汰缓存
2)再写数据库（这两步和原来一样）
3)休眠1秒，再次淘汰缓存

(3)先更新数据库，再缓存
1)缓存刚好失效
2)请求A查询数据库，得一个旧值
3)请求B将新值写入数据库
4)请求B缓存
5)请求A将查到的旧值写入缓存
但读操作比写操作耗时更少，上述情况出现概率极低

(4)串行化
一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统不是严格要求“缓存+数据库”必须
保持一致性的话，最好不要做这个方案，即：读请求和写请求串行化，串到一个内存队列里去。
串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑
线上的一个请求。

(5)终极方案-Cache Aside Pattern
读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
·更新的时候，先更新数据库，然后再缓存。
为什么是缓存，而不是更新缓存？
#很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。
比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值
的。



@  MySQL中的Buffer Pool-支撑高并发的一些设计
Buffer Pool是什么？从字面上看是缓存池的意思，没错，它其实也就是缓存池的意思。它是MySQL当中至关重要的一个组件，
可以这么说，MySQL的所有的增删改的操作都是在Buffer Pool中执行的。
但是数据不是在磁盘中的吗？怎么会和缓存池又有什么关系呢？那是因为如果MyQL的操作都在磁盘中进行，那很显然效率
是很低的，效率为什么低？因为数据库要从磁盘中拿数据啊，那肯定就需要○啊，并且数据库并不知道它将要查找的数据是磁盘的哪个位置，
所以这就需要进行随机IO,那这个性能简直就别玩了。所以MySQL对数据的操作都是在内存中进行的，也就是在Buffer Pool
这个内存组件中。

MySQL并不会像我们一样去操作行数据，而是抽象出来一个一个的数据页概念，每个数据页的大小默认是16KB,这些参数都
是可以调整的。但是建议使用默认的就好，毕竟MySQL能做到极致的都已经做了。每个数据页存放着多条的数据，MySQL在
执行增删改首先会定位到这条数据所在数据页，然后会将数据所在的数据页加载到Buffer Pool中。
当数据页被加载到缓冲池中后，Buffer Pool中也有叫缓存页的概念与其一一对应，大小同样是16KB,
但是MySQL还为每个缓存也开辟额外的一些空间，用来描述对应的缓存页的一些信息，例如：数据页所属的表空间，数据页
号，这些描述数据块的大小大概是缓存页的15%左右（约800KB)。
当MSql启动的时候，就会初始化Buffer Pool,这个时候MySQL会根据系统中设置的innodb_buffer_pool_size大小去内存中
申请一块连续的内存空间，实际上在这个内存区域比配置的值稍微大一些，因为【描述数据】也是占用一定的内存空间的，当在内存区域申请完毕之
MySql会根据默认的缓存页的大小(16KB)和对应缓存页*15%大小(800B左右)的数据描述的大小，将内存区域划分为一个
个的缓存页和对应的描述数据

--Free链表
当加载数据页到缓存池中的时候，MySQL会从free链表中获取一个描述数据的信息，根据描述节点的信息拿到其对应的缓存
页，然后将数据页信息放到该缓存页中同时将链表中的该描述数据的节点移除。这就是数据页被读取Buffer Pool中的缓存页的过程。

--页号哈希表
但MySQL是怎么知道哪些数据页已经被缓存了，哪些没有被缓存呢。实际上数据库中还有后一个哈希表结构，他的作用是用
来存储表空间号+数据页号作为数据页的key,缓存页对应的地址作为其value,这样数据在加载的时候就会通过哈希表中的
key来确定数据页是否被缓存了。

-Flush链表
MySql在执行增删改的时候会一直将数据以数据页的形式加载到Buffer Pool的缓存页中，增删改的操作都是在内存中执行
的，然后会有一个后台的线程数将脏数据刷新到磁盘中
但是后台的线程肯定是需要知道应该刷新哪些啊。针对这个问题，MySQL设计出了Fush链表，他的作用就是记录被修改过的
脏数据所在的缓存页对应的描述数据。如果内存中的数据
和数据库和数据库中的数据不一样，那这些数据我们就称之为脏数据，脏数据之所以叫脏数据，本质上就是被缓存到缓存池中
的数据被修改了，但是还没有刷新到磁盘中。
同样的这些已经被修改了的数据所在的缓存页的描述数据会被维护到Flush中（其实结构和free链表是一样的）。


--LRU链表
mysgl是基于冷热数据分离的LRU链表，所谓的冷热分离，就是将LRU链表分成两部分，一部分是经常被使用到的热数据，另
一部分是被加载进来但是很少使用的冷数据。通过参数innodb old blocks_pct参数控制的，默认为37，也就是37%。
数据在从磁盘被加载到缓存池的时候，首先是会被放在冷数据区的头部，然后在一定时间之后，如果再次访问了这个数据，那
么这个数据所在的缓存页对应描述数据就会被放转移到热数据区链表的头部。
-Buffer Pool的并发性能
我们平时的系统绝对不可能每次只有一个请求来访问的，说白了就是如果多个请求同时来执行增删改，那他们会并行的去操作
Buffer Pool中的各种链表吗？如果是并行的会不会有什么问题。
实际上MySQL在处理这个问题的时候考虑得非常简单，就是：Buffer Pool一次只能允许一个线程来操作，一次只有一个线程
来执行这一系列的操作，因为MySQL为了保证数据的一致性，操作的时候必须缓存池加锁，一次只能有一个线程获取到
这个时候，大家这时候肯定满脑子问号。串行那还谈什么效率？大家别忘记了，这一系列的操作都是在内存中操作的，


这是一个瞬时的过程，在内存中的操作基本是几毫秒的甚至微妙级别的事情。
但是话又说回来，串行执行再怎么快也是串行，虽然不是性能瓶颈，这还有更好的优化办法吗？那肯定的MySQL早就设计好
了这些规则。那就是Buffer Pool是可以有多个的，可以通过MySQL的配置文件来配置，参数分别是：
#Buffer Pool的总大小
innodb_buffer_pool_size=9663676416
#Buffer Pool的实例数（个数）
innodb buffer pool instance=3

#问：多个Buffer Pool所带来的问题思考
在多个线程访问不同的Buffer Pool那不同的线程加载的数据必然是在不同的Buffer Pool中，假设A线程加载数据页A到
Buffer Pool A中，B线程加载数据页B到Buffer Pool B中，然后两个都执行完了，这个时候C线程来了，他到达的是Buffer
Pool B中，但是C要访问的数据是在Buffer Pool A中的数据页上了，这个时候C还会去加载数据页A吗？，这种情况会发生
吗？在不同的Buffer Pool缓存中会去缓存相同的数据页吗？
#答：这种情况很显然不会发生，既然不会发生，那My9l是如何解决这种问题的？其实前面已经提到过了，那就是数据页缓
存哈希表（看下图），里面存放的是表空间号+数据页号=缓存页地址，所以MySQL在加载数据所在的数据页的时候根据这
一系列的映射关系判断数据页是否被加载，被加载到了那个缓存页中，所以MySQL能够精确的确定某个数据页是否被加载
被加载的到了哪个缓存页，绝不可能出现重复加载的情况。



@ jdk7/dk8的hashmap
(1)容量(Capacity)和负载因子(Load factor)
Capacity就是bucket的大小，Load factor就是bucket填满程度的最大比例。如果对迭代性能要求很高的话，不要把
capacity设置过大，
也不要把load factor设置过小。当oucket中的entries的数目大于capacity'*load factor时，就需要调整bucket的大小为当前
的2倍。

(2)put方法
jdk7在createEntry)方法中，新添加的元素直接放在slot槽(slot哈希槽，tablel[]这个位置)使新添加的元素在下一次提取
后可以更快的被访问到。
如果两个线程同时执行(**)处时，那么一个线程的赋值就会被另一个覆盖掉，这是对象丢失的原因之一。
我们构造一个HashMap集合，把所有元素放置在同一个哈希桶内，达到扩容条件后，观察一下resizel方法是如何进行数据
迁移的。
JDK7是先对size++进行检查，如果超过阈值，则扩容，最后把节点放入table。
而JDK8相反，先把节点放入，放入后的size若超出，则扩容.

(3)JDK7与JDK8中关于HashMapl的对比
#JDK8为红黑树+链表+数组的形式，当桶内元素大于8时&&数组长度>64，便会树化；
#hash值的计算方式不同(idk8简化)；
#1.7 table在创建hashmapl时分配空间，而1.8在put的时候分配，如果table为空，则为table分配空间；
#在发生冲突，插入链中时，7是头插法，8是尾插法；
#在resize操作中，7需要重新进行indexE的计算，而8不需要，通过判断相应的位是0还是1，要么依旧是原index,要么是
oldCap+原index

(4)什么时候会使用HashMap?
是基于Map接口的实现，存储键值对时，它可以接收null的键值，是非同步的，HashMap存储着Entry(hash,key,value,next
对象。

(5)get和put工作原理？
通过hash的方法，通过put和get存储和获取对象。
存储对象时，我们将K/V传给put方法时，它调用hashCode计算hash从而得到bucket位置，进一步存储，HashMap会根据当
前bucket的占用情况自动调整容量（超过Load Facotr则resize为原来的倍）。
获取对象时，我们将K传给get,它调用hashCodeO)计算hash从而得到bucket位置，并进一步调用equals(方法确定键
值对。
如果发生碰撞的时候，Hashmap通过链表将产生碰撞冲突的元素组织起来，在Java8中，如果一个bucket中碰撞冲突的
超过某个限制（默认是8），则使用红黑树来替换链表，从而提高速度。

(6)equals()和nashCode()的都有什么作用？
通过对key的hashCode()进行hashing,并计算下标((n-l)&hash),从而获得buckets的位置。
如果产生碰撞，则利用key.equals方法去链表或树中去查找对应的节点

(7)hash的实现吗？为什么要这样实现？
在Java1.8的实现中，是通过hashCodel(的高16位异或低16位实现的：(h=k.hashCode0)^(h>>16),主要是从速度
功效、质量来考虑的，
这么做可以在bucket的n比较小的时候，也能保证考虑到高低bit都参与到hash的计算中，同时不会有太大的开销。

(8)如果HashMapl的大小超过了负载因子(load factor)定义的容量，怎么办？
如果超过了负载因子（默认0.75），则会重新resize一个原来长度两倍的HashMap,并且重新调用hash方法。

(9)为什么capcity.是2的幂？
因为算index时用的是(n-1)&hash,这样就能保证n-1是全为1的二进制数，如果不全为1的话，存在某一位为0，那么0,1
与0与的结果都是0
这样便有可能将两个hash不同的值最终装入同一个桶中，造成冲突。所以必须是2的幂。

(10)jdk8为何用红黑树取代链表？
Java对HashMap做了改进，在链表长度大于的时候，将后面的数据存在红黑树中，以加快检索速度。
同样是8个节点，如果是链表最大查询8次，红黑树就3次左右，提升查询效率；

(11)jdk8为何不用alv树而是红黑树？
AV儿树是一种高度平衡的二叉树，所以查找的非常高，但是，有利就有弊，AVL树为了维持这种高度的平衡，就要付出代价。
每次插入、都要做调整，就比较复杂、耗时。
所以，对于有频繁的插入、操作的数据集合，使用AV儿树的代价就有点高了。
红黑树只是做到了近似平衡，并不严格的平衡，所以在维护的成本上，要比AV儿树要低。
所以，红黑树的插入、、查找各种操作性能都比较稳定。
java8不是用红黑树来管理hashmap,而是在hash值相同的情况下（且重复数量大于8），用红黑树来管理数据。
红黑树相当于排序数据，可以自动的使用二分法进行定位，性能较高。一般情况下，hah值做的比较好的话基本上用不到红黑树。
红黑树牺牲了一些查找性能但其本身并不是完全平衡的二叉树。因此插入操作效率略高于AV儿树。
AV儿树用于自平衡的计算牺牲了插入性能，但是因为最多只有一层的高度差，查询效率会高一些。



@ AQS详解
谈到并发，不得不谈ReentrantLock;而谈到ReentrantLock,不得不谈AbstractQueuedSynchronizer(AQS)!
抽象的队列式的同步器，AQ定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的
ReentrantLock/Semaphore/CountDownLatch....
它维护了一个volatile int state(代表共享资源)和一个FIFO线程等待队列（多线程争用资源被阻塞时会进入此队列）。
·tryAcquire(int):独占方式。尝试获取资源，成功则返回true,失败则返回false。
·tryRelease(int):独占方式。尝试释放资源，成功则返回true,失败则返回false。
·tryAcquireShared(int):共享方式。尝试获取资源。负数表示失败；O表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
·tryReleaseShared(int):共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true,否则返回false。
以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock)时，会调用tryAcquirel独占该锁并将state+1。此
后，其他线程再tryAcquire()时就会失败，直到A线程unlock(到state=0(即释放锁)为止，其它线程才有机会获取该锁。当
然，释放锁之前，A线程自己是可以重复获取此锁的(state会累加)，这就是可重入的概念。但要注意，获取多少次就要释放
多么次，这样才能保证state是能回到零态的。
再以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N(注意N要与线程个数一致)。这N个子线程是并
行执行的，每个子线程执行完后countDown(一次，state会CAS减1。等到所有子线程都执行完后（即state=0),会unpark(主
调用线程，然后主调用线程就会从await)函数返回，继续后余动作。



@ kubesphere,k8s自带的可视化
(1)dashboard
github拉取yaml,yaml里面的镜像是做好的在网络上
使用kubectl apply部署pod和service
客户端访问测试
使用Tokenl的方式登录
(2)Weave Scope
github拉取yaml
vim scope.yaml+212定位到212行修改serviceType为NodePort
使用kubectl apply部署pod和service
客户端访问测试
(3)kubesphere
属于青云产品，青云是基于公有云和私有云一致的云平台实现技术，QingCloud提供混合云解决方案，以帮助希望将敏感数据
放到企业内部私有部署的客户快速构建混合部署架构。
通过KubeSphere可以快速管理Kubernetes集群、部署应用、服务发现、Cl/CD流水线、集群扩容、微服务治理、日志查询
和监控告警。换句话说，Kubernetes是一个很棒的开源项目（或被认为是一个框架），但是KubeSphere是一款非常专业
企业级平台产品，专注于解决用户在复杂业务场景中的痛点，提供更友好更专业的用户体验。

1)Kubernetes资源管理
对底层Kubernetes中的多种类型的资源提供可视化的展示与监控数据，以向导式U实现工作负载管理、镜像管理、服务与应
用路由管理（服务发现）、密钥配置管理等，并提供弹性伸缩(HPA)和容器健康检查支持，支持数万规模的容器资源调度，保证
业务在高峰并发情况下的高可用性

2)微服务治理
灵活的微服务框架：基于Istio微服务框架提供可视化的微服务治理功能，将Kubernetes的服务进行更细粒度的拆分
完善的治理功能：支持熔断、灰度发布、流量管控、限流、链路追踪、智能路由等完善的微服务治理功能，同时，支持代码无
侵入的微服务治理

3)多租户管理
·多租户：提供基于角色的细粒度多租户统一认证与三层级权限管理
·统一认证：支持与企业基于LDAP/AD协议的集中认证系统对接，支持单点登录(SSO),以实现租户身份的统一认证
·权限管理：权限等级由高至低分为集群、企业空间与项目三个管理层级，保障多层级不同角色间资源共享且互相隔离，保障资源安全性

4)DevOps
开箱即用的DevOps:基于Jenkins的可视化Cl/CD流水线编辑，无需对Jenkins进行配置，同时内置丰富的C/CD流水线插件

5)快速构建与发布
提供对代码(Source-to-Image)或者制品(Binary-to-Image)进行快速容器化的工具，无需编写dockerfile,仅需要通过简
单的设置即可将制品和代码构建成服务。

6)多维度监控
KubeSphere全监控运维功能可通过可视化界面操作，同时，开放标准接口，易于对接企业运维系统，以统一运维入口实现集中化运维

7)日志查询与收集
·提供多租户日志管理，在KubeSphere的日志查询系统中，不同的租户只能看到属于自己的日志信息，支持中文日志检索
支持日志导出

8)多存储类型支持
·支持GlusterFS、CephRBD、NFS等开源存储方案，支持有状态存储

9)多网络方案支持
·支持Calico、Flannel等开源网络方案
·开发了适用于物理机部署Kubernetes的负载均衡器插件Porter




@ VPC,VPN,NAT,ECS,EIP,ELB
(1)VPC--Virtual Private Cloud(虚拟私有云)
为弹性云服务器构建隔离的、用户自主配置和管理的虚拟网络环境，提升用户云上资源的安全性，简化用户的网络部署。
您可以在VPC中定义安全组、VPN、IP地址段、带宽等网络特性。用户可以通过VPC方便地管理、配置内部网络，进行安全、
快捷的网络变更。同时，用户可以自定义安全组内与组间弹性云服务器的访问规则，加强弹性云服务器的安全保护。

(2)VPC使用场景：
1)通用性Web应用。
在VPC中托管Web应用或网站，可以像使用普通网络一样使用VPC。通过弹性公网IP连接弹性云服务器与Internet,运行
服务器上部署的Web应用程序。系统通过VPN网关与云端业务系统建立VPN通道，保证网站业务系统高速互通。
应用程序转移到云中、启动额外的Web服务器、增加网络的计算容量，从而实现企业的混合云架构，既降低了企业T运维成
本，又不用担心企业核心数据的扩散。VPC能够跨AZ部署，提升了电商平台的高可用性。

(3)VPC连接
VPC连接Internet,VPC连接VPC,VPC连接本地数据中心lDC

(4)VPN--Virtual Private Network(虚拟专用网络)
被定义为通过一个公用互联网络建立一个临时的、安全的连接，是一条穿过混乱的公用网络的安全、稳定隧道，使用这条隧道
可以对数据进行几倍加密达到安全使用互联网的目的，广泛使用企业办公当中。
也就是利用公网访问公司内网，在家办公。
VP的实质就是利用加密技术在公用网上面封装出一个数据通讯隧道。

(5)NAT--网络地址转换
NAT的基本工作原理是，当私有网主机和公共网主机通信的IP包经过NAT网关时，将IP包中的源IP或目的IP在私有IP和NAT的公
共IP之间进行转换。
比如192.168.1.1转换成10.2.3.56
NAT主要可以实现以下几个功能：数据包伪装、平衡负载、端口和透明代理。
#数据伪装：可以将内网数据包中的地址信息更改成统一的对外地址信息，不让内网主机直接暴露在因特网上，保证内网主机的
安全。同时，该功能也常用来实现共享上网。例如，内网主机访问外网时，为了隐藏内网拓扑结构，使用全局地址替换私有地址。
#端口：当内网主机对外提供服务时，由于使用的是内部私有地址，外网无法直接访问。因此，需要在网关上进行端口转
发，将特定服务的数据包给内网主机。
例如公司小王在自己的服务器上架设了一个Wb网站，他的1P地址为192.168.0.5，使用默认端口80，现在他想让局域网外时
户也能直接访问他的Web站点。
利用NAT即可很轻松的解决这个问题，服务器的1P地址为210.59.120.89，那么为小王分配一个端口，例如81，即所有访问
210.59.120.89:81的请求都自动转向192.168.0.5：80，而且这个过程对用户来说是透明的。

#负载平衡：目的地址转换NAT可以重定向一些服务器的连接到其他随机选定的服务器。例如1.2.3所讲的目的NAT的例子。
#失效终结：目的地址转换A可以用来提供高可靠性的服务。如果一个系统有一台通过路由器访问的关键服务器，一旦路由器
检测到该服务器当机，它可以使用目的地址转换AT透明的把连接转移到一个备份服务器上，提高系统的可靠性。
#透明代理：例如自己架设的服务器空间不足，需要将某些链接指向存在另外一台服务器的空间；或者某台计算机上没有安装
服务，但是却想让网友访问该台计算机上的内容，这个时候利用的Web站点重定向即可轻松的帮助我们搞定。

(6)ECS云服务器(Elastic Compute Service,简称ECS)
一种简单高效、安全可靠、弹性可伸缩的计算服务，帮助您快速构建更稳定、安全的应用，提升运维效率，降低π成本，使您更专注
于核心业务创新。
其实就是云服务器。

(7)云服务器的特点
1)弹性扩展，配置可升级，按需付费。
2)简单高效，无须提前采购机器，即开即用，快速业务部署。
3)独立操作系统，硬件资源的隔离+独享带宽。
4)集中化的远程管理平台+多级业务备份。

(8)云虚拟主机特点
1)站点连接数随着节点服务器的增加而线性上升，突破单个站点连接数的限制。
2)多台节点服务器实现负载均衡，当某个节点的负载过高时，集群内部将自动把过多的负载均摊到其他节点上去，可有效抵挡黑客的攻击。
3)当某个节点上的某个站点不能访问时，站点的访问将会自动转移到下一个节点的同一个站点上去，从而有效地避免了单点故障的发生。

(9)弹性负载均衡ELB,和ALB差不多
客户端-域名-dns解析成ip-F5负载均衡-ab负载均衡器-web服务器
负载均衡器其实就是nginx:集群
VIP是F5/ELB的IP
EIP是dns解析成的ip也就是公网IP


@ ADS购买资源ip问题，K8S通常的访问，K8S内部通信，k8s安全，alb域名访问？
ADS购买资源，如果是tomcat资源则是固定的ip,如果是容器资源，实际上是副本数，比如买了10个4C4G的资源，只能部署
10个4C4G的replicas
部署之后，如果是ingressi访问的话，需要搭配service,servicei通过nodelp+nodeport。
如果是测试单机访问，直接nodelp+nodeport;
如果是外部ELB的话，nginx只要负载均衡到deployment相关的ood nodelp+nodeport,前提是pod ready.之后上报pod名称，
nodelp,nodeport,这样elb才会知道。
service就是一个映射作用，把容器端口映射到nodeport,如果在yaml里面直接写了hostPort,pod ready之后上报了不用
service.

负载均衡器到网关，api之间调用使用的eureka,eurekai记录了nodelp+nodeport;
红版的没有网关怎么做的？比如kweheds-devpaas.huawei.com/ads_admin_service数据库里面记录了7.180.146.177：50503
nginx怎么找到ip集合的？路由规则这些存在了redis,ua可以读取，ip也存在了redisl吗？答案：容器实例是kubewatch.上报到
consul中，然后router watch.从consul中拿到再写入到redis中
K8S内部通信使用的clusterlp+虚拟网桥
ks安全：API SERVER权限控制，Authentication(认证)、Authorization(授权)、AdmissionControl(准入控制)
APIServer)启动时，可以指定一种Authentication方法，也可以指定多种方法。如果指定了多种方法，那么APIServer将会逐个
使用这些方法对客户端请求进行验证，只要请求数据通过其中一种方法的验证，APIServeri就会认为Authentication成功；
ks组件通过客户端证书（借助kubeconfig)访问apiserver,应用通过serviceaccounti访问apiserver,用户通过用户名、密码
或openid connect(我们使用的就是这种，DEX)访问apiserver。一次可以指定多个认证方式，会依顺序认证，直到有一个认
证方式通过。


@ deploymenti滚动更新和版本回退总结
(1)功能
·支持replicaset的所有功能
·支持版本的滚动更新和版本回退
·支持发布的停止、继续

(2)滚动更新
RollingUpdate(滚动更新)
通过参数maxUnavailable.与maxSurge:来控制滚动更新过程
maxUnavailable:最大不可用数量，数量或者百分比
maxSurge:超过pod期望副本数的最大值，数量或者百分比
两个值不能是0，maxUnavailable如果是O不能有不可用，maxSurge=O不能有额外的实例，死循环了。

(3)版本回退
revisionHistoryLimit:#保留历史版本，默认是10
kubectl rollout:版本升级相关功能，支持下面的选项：
·status:显示当前升级状态
·history:显示升级历史记录
pause:暂停版本升级过程
·resume:继续已经暂停的版本升级过程
restart:重启版本升级过程
·undo:回滚到上一级版本（可以使用-to-revisionl回滚到指定版本）
kubectl rollout status deploy nginx-deployment查看升级状态
kubectl rollout history deploy nginx-deployment查看升级历史
kubectl rollout undo deployment/nginx-deployment回退到上一个版本
kubectl rollout undo deployment/nginx-deployment-to-revision=2根据-revision参数指定某个历史版本

(4)金丝雀发布（灰度发布）
deployment支持更新过程中的控制，如"暂停(pause)"或"继续(resume)"更新操作，观察新服务实际运行状况再决定操作
金丝雀发布（可以理解为灰度发布）：比如有一批新的pod资源创建完成后立即暂停更新过程，此时，仅存在一部分新版本的
应用，主体部分还是旧的版本。然后，再筛选一小部分的用户请求路由到新的pod应用，
继续观察能否稳定地按期望的方式运行。确定没问题之后再继续完成余下的od资源滚动更新，否则立即回滚更新操作。这就
是所谓的金丝雀发布。
kubectl rollout pause deploy nginx-deployment暂停deployment
kubectl get rs,deploy查看rs,发现老版本rs没有减少，新版本rs增加一个，状态为更新中
kubectl rollout resume deployment nginx-deployment继续deploy的更新



@  devops,ci+cd,jenkins,云龙流水线总结
(1)devops
一种重视“软件开发人员(Dev)”和“IT运维技术人员(Qs)”之间沟通合作的文化、运动或惯例。透过自动化“软件交付”和
“架构变更”的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。
它的出现是由于软件行业日益清晰地认识到：为了按时交付软件产品和服务，开发和运维工作必须紧密合作。

(2)ci:持续集成
持续集成(CONTINUOUS INTEGRATION)
在持续集成环境中，开发人员将会频繁的提交代码到主干。这些新提交在最终合并到主线之前，都需要通过编译和自动化测试
流进行验证。这样做是基于之前持续集成过程中很重视自动化测试验证结果，以保障所有的提交在合并主线之后的质量问题
对可能出现的一些问题进行预警。

(3)cd:持续交付
持续交付(CONTINUOUS DELIVERY)
持续交付就是讲我们的应用发布出去的过程。这个过程可以确保我们尽可能快的实现交付。这就意味着除了自动化测试，我们
还需要有自动化的发布流，以及通过一个按键就可以随时随地实现应用的部署上线。
通过持续交付，您可以决定每天，每周，每两周发布一次，这完全可以根据自己的业务进行设置。

(4)cd:持续部署
持续部署(CONTINUOUS DEPLOYMENT)
如果我们想更加深入一步的话，就是持续部署了。通过这个方式，任何修改通过了所有已有的工作流就会直接和客户见面。没
有人为干预（没有一键部署按钮），只有当一个修改在工作流中构建失败才能阻止它部署到产品线。
直接连接codehub,maven构建，代码检查，打包，制作镜像，部署一气呵成。

(5)jenkins
直接连接codehub,maven构建，代码检查，打包+部署tomcat或者容器，但是简单的容器，没有集群管理
maven安装在jenkins机器上，配置环境变量，搭建部署Harbor仓库，配置master地址。

(6)云龙
直接连接codehub,maven构建，代码检查，打包+ads api


@ 自旋锁，可重入锁，公平锁深入总结
(1)可重入锁
如果锁具备可重入性，则称作为可重入锁。像synchronized和ReentrantLock都是可重入锁，可重入性在我看来实际上表明了
锁的分配机制：基于线程的分配，而不是基于方法调用的分配。
举个简单的例子，当一个线程执行到某个synchronized方法时，比如说method1,而在method1中会调用另外一个
synchronized方法method2,此时线程不必重新去申请锁，而是可以直接执行方法method2。
class MyClass
public synchronized void method10{
method20;
}
public synchronized void method2(){
}
上述代码中的两个方法method1和method:2都用synchronized修饰了，假如某一时刻，线程A执行到了method1,此时线程A
获取了这个对象的锁，而由于method2也是synchronized方法
假如synchronized不具备可重入性，此时线程A需要重新申请锁。但是这就会造成一个问题，因为线程A已经持有了该对象的
锁，而又在申请获取该对象的锁，这样就会线程A一直等待永远不会获取到的锁。
而由于synchronized和Lock都具备可重入性，所以不会发生上述现象。

(2)可中断锁
Lock是可中断锁，而synchronized不是可中断锁。现假设线程A和B都要获取对象O的锁定，假设A获取了对象O锁，B将等待A
释放对O的锁定，如果使用synchronized,如果A不释放，B将一直等下去，不能被中断；
如果使用ReentrantLock,如果A不释放，可以使B在等待了足够长的时间以后，中断等待，而干别的事情。获取锁超时机制还
是属于不可中断，属于超时被动放弃去竞争锁，而lockInterruptibly:是可主动放弃竞争锁行为的一种方式。

Lock接口的线程获取锁的三种方式
1)0ck),如果获取了锁立即返回，如果别的线程持有锁，当前线程则一直处于休眠状态，直到获取锁；
2)tryLock(),如果获取了锁立即返回true,如果别的线程正持有锁，立即返回false;
3)tryLock(long timeout,TimeUnit unit),如果获取了锁定立即返回true,如果别的线程正持有锁，会等待参数给定的时
间，在等待的过程中，如果获取了锁定，就返回true,如果等待超时，返回false;

(3)公平锁
公平锁即尽量以请求锁的顺序来获取锁。比如同是有多个线程在等待一个锁，当这个锁被释放时，等待时间最久的线程（最先
请求的线程)会获得该所，这种就是公平锁。
非公平锁即无法保证锁的获取是按照请求锁的顺序进行的。这样就可能导致某个或者一些线程永远获取不到锁。
在Java中，synchronized就是非公平锁，它无法保证等待的线程获取锁的顺序。
而对于ReentrantLock和ReentrantReadWriteLock,它默认情况下是非公平锁，但是可以设置为公平锁。
ReentrantLock lock new ReentrantLock(true);
如果参数为true表示为公平锁，为fasle为非公平锁。默认情况下，如果使用无参构造器，则是非公平锁。
另外在ReentrantLock类中定义了很多方法，比如：
isFair)
/判断锁是否是公平锁
/判断锁是否被任何线程获取了
isHeldByCurrentThread)/判断锁是否被当前线程获取了
hasQueuedThreads()/判断是否有线程在等待该锁
在ReentrantReadWriteLock中也有类似的方法，同样也可以设置为公平锁和非公平锁。不过要记住，
ReentrantReadWriteLock并未实现Lock接口，它实现的是ReadWriteLock接口。

(4)自旋锁
首先是一种锁，与互斥锁相似，基本作用是用于线程（进程）之间的同步。与普通锁不同的是，一个线程A在获得普通锁后
如果再有线程B试图获取锁，那么这个线程B将会挂起（阻塞）；
如果两个线程资源竞争不是特别激烈，而处理器阻塞一个线程引起的线程上下文的切换的代价高于等待资源的代价的时候（锁
的已保持者保持锁时间比较短)，那么线程B可以不放弃CPU时间片，
而是在“原地”忙等，直到锁的持有者释放了该锁，这就是自旋锁的原理，可见自旋锁是一种非阻塞锁。
).过多占据CPU时间：如果锁的当前持有者长时间不释放该锁，那么等待者将长时间的占据gPu时间片，导致CPU资源的浪
费，因此可以设定一个时间，当锁持有者超过这个时间不释放锁时，等待者会放弃CPU时间片阻塞；
JAVA中一种自旋锁的实现：CAS是Compare And Set的缩写

CAS实现自旋锁
既然用锁或synchronized关键字可以实现原子操作，那么为什么还要用CAS呢，因为加锁或使用synchronized关键字带来
的性能损耗较大，而用CAS可以实现乐观锁，它实际上是直接利用了CPU层面的指令，所以性能很高。
CAS是实现自旋锁的基础，CAS利用CPU指令保证了操作的原子性，以达到锁的效果，至于自旋呢，看字面意思也很明白，
自己旋转，翻译成人话就是循环，一般是用一个无限循环实现。
这样一来，一个无限循环中，执行一个CAS操作，当操作成功，返回true时，循环结束；当返回false时，接着执行循环
继续尝试CAS操作，直到返回true。
其实JDK中有好多地方用到了CAS,尤其是java.util.concurrent包下，比如CountDownLatch、Semaphore、
ReentrantLock中，再比如java.util.concurrent.atomic包下，相信大家都用到过Atomic'*,比如AtomicBoolean、
Atomiclnteger等。



@ tcpdump总结
tcpdump是Linux下自带的网络分析工具。可以将网络中传送的数据包完全截获下来提供分析。它支持针对网络层、协议、主
机、网络或端口的过滤，并提供and、or、not等逻辑语句来帮助你去掉无用的信息。
监听来自172.25.38.145到端口7012的数据，并到处到指定文件output.dat:
tcpdump tcp dst port 7012 and src host 172.25.38.145-yv -w output.dat
监听主机192.168.1.10或192.168.1.11的80端口。
tcpdump port80and/(host192.168.1.10 or host192.168.1.11/)。
不使用)一定要用/转义。
获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的i2包：
tcpdump ip host 210.27.48.1 and 210.27.48.2
监听指定主机的80端口。
tcpdump host192.168.1.124 and port80。
用tcpdump解析tcp连接建立和释放
tcpdump tcp port 7012 and host 172.25.34.88 -ieth1-n
如何抓取某个主机的数据包？
tcpdump host localhost1
获取目的主机是192.168.1.3的数据包？
tcpdump -en -i etho dst 192.168.1.3
获取来自主机192.168.1.3端口是22的数据包？
tcpdump -enf -i any src 192.168.1.3 port 22
获取来自主机192.168.1.3或是主机192.168.1.4端口是22的数据包？
tcpdump -enf -i any host 192.168.1.3 or 192.168.1.4 and port 22


@ istio总结
作为一种架构模式，微服务将复杂系统切分为数十乃至上百个小服务，每个服务负责实现一个独立的业务逻辑。
这些小服务易于被小型的软件工程师团队所理解和修改，并带来了语言和框架选择灵活性，缩短应用开发上线时间，可根据不
同的工作负载和资源要求对服务进行独立缩扩容等优势。
另一方面，当应用被拆分为多个微服务进程后，进程内的方法调用变成了了进程间的远程调用。引入了对大量服务的连接、管
理和监控的复杂性。

该变化带来了分布式系统的一系列问题，例如：
如何找到服务的提供方？
如何保证远程方法调用的可靠性？
如何保证服务调用的安全性？
如何降低服务调用的延迟？
如何进行端到端的调试？

生产部署中的微服务实例也增加了运维的难度，例如：
如何收集大量微服务的性能指标已进行分析？
如何在不影响上线业务的情况下对微服务进行升级？
如何测试一个微服务集群部署的容错和稳定性？

这些问题涉及到成百上千个服务的通信、管理、部署、版本、安全、故障转移、策略执行、遥测和监控等，要解决这些微照冬
架构引入的问题并非易事。

在出现服务网格之前，最开始是在微服务应用程序内理服务之间的通讯逻辑，包括服务发现、熔断、重试、超时、加密、限流等逻辑。
服务网格(Service Mesh)是一个基础设施层，用于处理服务间通信。云原生应用有着复杂的服务拓扑，服务网格保证请求可
以在这些拓扑中可靠地穿梭。在实际应用当中，服务网格通常是由一系列轻量级的网络代理组成的，
它们与应用程序部署在一起，但应用程序不需要知道它们的存在。
服务网格(Service Mesh)中有数量众多的Sidecar代理，如果对每个代理分别进行设置，工作量将非常巨大。为了更方便地对
服务网格中的代理进行统一集中控制，在服务网格上增加了控制面组件。
这里可以类比SDN的概念，控制面就类似于SDN网管中的控制器，负责路由策略的指定和路由规则下发；数据面类似于SDN网
络中交换机，负责数据包的。
由于微服务的所有通讯都由服务网格基础设施层提供，通过控制面板和数据面板的配合，可以对这些通讯进行监控、托管和控
制，以实现微服务灰度发布，调用分布式追踪，故障注入模拟测试，动态路由规则，微服务闭环控制等管控功能。

Istio是一个Service Mesh开源项目，是Google继Kubernetes.之后的又一力作，主要参与的公司包括Google,lBM和Lyf。
Istio是Service Mesh(服务网格)的主流实现方案。该方案降低了与微服务架构相关的复杂性，并提供了负载均衡、服务发现、流量管理、断路器、监控
故障注入和智能路由等功能特性。对业务无侵入式。
为每个pod增加了一个代理container(sidecar),该container/用于处理应用container之间的通信，包括服务发现，路由规则处理等。
从下面的配置文件中可以看到oroxy.containeri通过15001端口进行监听，接收应用containert的流量。
为每个pod增加了一个init-container,该container用于配置iptable,将应用containerE的流量导入到代理containert中。
Istiol的kube-inject工具的用途即是将代理sidecar注入了Bookinfo的kubernetes yaml部署文件中。通过该方式，不需要用户手
动修改kubernetesl的部署文件，即可在部署服务时将sidecari和应用一起部署。

Istio核心组件
Envoy:Istio使用Envoy调解服务网格中所有服务的入站和出站流量。属于数据平面。
Mixe:负责在服务网格上执行访问控制和使用策略，以及收集从Envoy和其他服务自动监控到的数据。
Pilot:为Envoy sidecar提供服务发现功能，为智能路由（例如A/B测试、金丝雀部署等）和弹性（超时、重试、熔断器等）
提供流量管理功能。属于控制平面。
Citadel:提供访问控制和用户身份认证功能。




@ 消息最终一致性总结
随着分布式服务架构的流行与普及，原来在单体应用中执行的多个逻辑操作，现在被拆分成了多个服务之间的远程调用。虽然
服务化为我们的系统带来了水平伸缩的能力
然而随之而来挑战就是分布式事务问题，多个服务之间使用自己单独维护的数据库，它们彼此之间不在同一个事务中，假如
执行成功了，B执行却失败了，而A的事务此时已经提交，无法回滚，那么最终就会导致两边数据不一致性的问题；、
尽管很早之前就有基于两阶段提交的X分布式事务，但是这类方案因为需要资源的全局锁定，导致性能极差；因此后面就逐渐
衍生出了消息最终一致性、TCC等柔性事务的分布式事务方案，本文主要分析的是基于消息的最终一致性方案。
(1)普通消息的处理流程
1.消息生成者发送消息
2.MQ收到消息，将消息进行持久化，在存储中新增一条记录
3.返回ACK给生产者
4.MQ push消息给对应的消费者，然后等待消费者返回ACK
5.如果消息消费者在指定时间内成功返回aC,那么MQ认为消息消费成功，在存储中消息，即执行第6步；如果MQ在指定
时间内没有收到ACK,则认为消息消费失败，会尝试重新push消息，重复执行4、5、6步骤
6.MQ消息

(2)普通消息处理存在的一致性问题
我们以订单创建为例，订单系统先创建订单（本地事务），再发送消息给下游处理；如果订单创建成功，然而消息没有发送出
去，那么下游所有系统都无法感知到这个事件，会出现脏数据；
public void processOrder){
/订单处理（业务操作）
orderService.process);
/发送订单处理成功消息（发送消息）
sendBizMsg ()
}
如果先发送订单消息，再创建订单；那么就有可能消息发送成功，但是在订单创建的时候却失败了，此时下游系统却认为这个
订单已经创建，也会出现脏数据。
public void processOrder(){
/发送订单处理成功消息（发送消息）
sendBizMsg )
/订单处理（业务操作）
orderService.process();
}

(3)try-catch-callback不完善
此时可能有同学会想，我们可否将消息发送和业务处理放在同一个本地事务中来进行处理，如果业务消息发送失败，那么本地
事务就回滚，这样是不是就能解决消息发送的一致性问题呢？
@Transactionnal
public void processOrder(){
tryf
/订单处理（业务操作）
orderService.process();
/发送订单处理成功消息（发送消息）
sendBizMsg ()
}catch(Exception e){
事务回滚；
}
}
}
订单处理成功，然后突然宕机，事务未提交，消息没有发送出去一致
订单处理成功，由于网络原因或者Q宕机，消息没有发送出去，事务回滚一致
订单处理成功，消息发送成功，但是Q由于其他原因，导致消息存储失败，事务回滚一致
订单处理成功，消息存储成功，但是MQ处理超时，从而ACK确认失败，导致发送方本地事务回滚不一致
从上面的情况分析，我们可以看到，使用普通的处理方式，无论如何，都无法保证业务处理与消息发送两边的一致性，其根本
的原因就在于：远程调用，结果最终可能为成功、失败、超时；
而对于超时的情况，处理方最终的结果可能是成功，也可能是失败，调用方是无法知晓的。

(4)事务消息
由于传统的处理方式无法解决消息生成者本地事务处理成功与消息发送成功两者的一致性问题，因此事务消息就诞生了，它实
现了消息生成者本地事务与消息发送的原子性，保证了消息生成者本地事务处理成功与消息发送成功的最终一致性问题。
1.事务消息与普通消息的区别就在于消息生产环节，生产者首先预发送一条消息到MQ(这也被称为发送alf消息)
2.MQ接受到消息后，先进行持久化，则存储中会新增一条状态为待发送的消息
3.然后返回ACK给消息生产者，此时MQ不会触发消息推送事件
4.生产者预发送消息成功后，执行本地事务
5.执行本地事务，执行完成后，发送执行结果给MQ
6.MQ会根据结果或者更新消息状态为可发送
7.如果消息状态更新为可发送，则MQ会push消息给消费者，后面消息的消费和普通消息是一样的

注意点：由于MQ通常都会保证消息能够投递成功，因此，如果业务没有及时返回ACK结果，那么就有可能造成MQ的重复消息
投递问题。
因此，对于消息最终一致性的方案，消息的消费者必须要对消息的消费支持幂等，不能造成同一条消息的重复消费的情况。

(5)支持事务消息的MQ
现在目前较为主流的MQ,比如ActiveMQ、RabbitMQ、Kafka、RocketMQ等，只有RocketMQ支持事务消息。据笔者了解，
早年阿里对Q增加事务消息也是因为支付宝那边因为业务上的需求而产生的。
因此，如果我们希望强依赖一个Q的事务消息来做到消息最终一致性的话，在目前的情况下，技术选型上只能去选择
RocketMQ来解决。
上面我们也分析了事务消息所存在的异常情况，即MQ存储了待发送的消息，但是MQ无法感知到上游处理的最终结果。
对于RocketMQ而言，它的解决方案非常的简单，就是其内部实现会有一个定时任务，去轮训状态为待发送的消息，然后给
producer发送check请求，而producer!必须实现一个check监听器，监听器的内容通常就是去检查与之对应的本地事务是否成功（一般就是查询DB),如果成功了，则MQ会将消息设置为可发送，
否则就消息。

(6)常见的问题
1.问：如果预发送消息失败，是不是业务就不执行了？
答：是的，对于基于消息最终一致性的方案，一般都会强依赖这步，如果这个步骤无法得到保证，那么最终也就不可能做到最
终一致性了。
.问：为什么要增加一个消息预发送机制，增加两次发布出去消息的重试机制，为什么不在业务成功之后，发送失败的话使用
一次重试机制？
答：如果业务执行成功，再去发消息，此时如果还没来得及发消息，业务系统就已经宕机了，系统重启后，根本没有记录之前
是否发送过消息，这样就会导致业务执行成功，消息最终没发出去的情况。
3.如果consumeri消费失败，是否需要producerf做回滚呢？
答：这里的事务消息，producer:不会因为consumeri消费失败而做回滚，采用事务消息的应用，其所追求的是高可用和最终一
致性，消息消费失败的话，Q自己会负责重推消息，直到消费成功。因此，事务消息是针对生产端而言的，而消费端，消费
端的一致性是通过MQ的重试机制来完成的。
4.如果consumer端因为业务异常而导致回滚，那么岂不是两边最终无法保证一致性？
答：基于消息的最终一致性方案必须保证消费端在业务上的操作没障碍，它只允许系统异常的失败，不允许业务上的失败，比
如在你业务上抛出个PE之类的问题，导致你消费端执行事务失败，那就很难做到一致了。
由于并非所有的MQ都支持事务消息，假如我们不选择RocketMQ来作为系统的MQ,是否能够做到消息的最终一致性呢？答案
是可以的。

(7)基于本地消息的最终一致性
基于本地消息的最终一致性方案的最核心做法就是在执行业务操作的时候，记录一条消息数据到DB,并且消息数据的记录与业
务数据的记录必须在同一个事务内完成，这是该方案的前提核心保障。
在记录完成后消息数据后，后面我们就可以通过一个定时任务到DB中去轮训状态为待发送的消息，然后将消息投递给MQ。这
个过程中可能存在消息投递失败的可能，此时就依靠重试机制来保证，
直到成功收到MQ的ACK确认之后，再将消息状态更新或者消息清除；而后面消息的消费失败的话，则依赖MQ本身的重试来完
成，其最后做到两边系统数据的最终一致性。基于本地消息服务的方案
虽然可以做到消息的最终一致性，但是它有一个比较严重的弊端，每个业务系统在使用该方案时，都需要在对应的业务库创建
一张消息表来存储消息。针对这个问题，我们可以将该功能单独提取
出来，做成一个消息服务来统一处理，因而就衍生出了我们下面将要讨论的方案。

(8)独立消息服务最终一致性
独立消息服务最终一致性与本地消息服务最终一致性最大的差异就在于将消息的存储单独地做成了一个PC的服务，在消息服
务中，还有一个单独地定时任务，它会定期轮训长时间处于待发送状态的消息
通过一个check补偿机制来确认该消息对应的业务是否成功，如果对应的业务处理成功，则将消息修改为可发送，然后将其投
递给MQ;如果业务处理失败，则将对应的消息更新或者即可。因此在使用
该方案时，消息生产者必须同时实现一个check服务，来供消息服务做消息的确认。对于消息的消费，该方案与上面的处理是
一样，都是通过MQ自身的重发机制来保证消息被消费。

(9)总结
上游事务提交之后，在基于Q的场景下就不考虑回滚了。失败的可能是由于网络、服务宕机所导致，文章中提到说业务上执
行是无障碍的。
如果下游服务长时间没有恢复，那么就应该设置告警，假如上游消息始终发送失败设置报警机制比如发生异常时可以打印日
志，发送短信，发送邮件，将异常订单保存到数据库，
这些措施可以同时用于下游一些异常订单，同时也可以在发生异常的时候新建一个异常Toic的消息提示，让人工来介入数据订
正。





@ 12306的超卖，少卖，高并发总结
超卖的意思是线程不安全，但是jdk锁只能锁住单虚拟机，分布式锁redisi最高效但是并发量一上来也不行，最好就是把流量拦
截在前面，阻塞队列+乐观锁机制。
如果采用付款才减库存的方式，可能会出现商品超卖的情况，用户下的单大量没有无效。
如果采用下单减库存，下单后不付款，导致商品下架，使真正想买的用户没有买到商品，导致少卖。
最好的方式就是，发消息下订单，预减库存，支付超时加库存。




@ mysqlE的MVCc?
(1)MVCC
全称Multi-Version Concurrency Control,即多版本并发控制。MVCC是一种并发控制的方法，一般在数据库管理系统中，实
现对数据库的并发访问，在编程语言中实现事务内存。

(2)当前读和快照读
1)当前读
select lock in share mode(共享锁)，select for update;update,insert,delete(排他锁)这些操作都是一种当前读当前读就是读取
的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁

2)快照读
不加锁的操作(select)就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化
成当前读；即MVCC,可以认为MVCC是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销快照读的实现是基
于多版本并发控制，既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本

(3)数据库并发场景
1)读-读：不存在任何问题，也不需要并发控制
)读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读
3)写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失
MVCC作用：解决读-写冲突的无锁并发控制，这里的读是快照读
在并发读-写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能同时
还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决更新丢失问题

(4)MVCC组合拳
·MVCC+悲观锁：MVCC解决读写冲突，悲观锁解决写写冲突
·MVCC+乐观锁：MVCC解决读写冲突，乐观锁解决写写冲突

(5)读写冲突并发实现原理
MVCC的目的就是多版本并发控制，在数据库中的实现，就是为了解决读写冲突，它的实现原理主要是依赖记录中的3个隐式
字段，undo日志，Read View来实现的
DB_ROW_ID:byte,隐含的自增ID(隐藏主键)，如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引
DB_TRX_ID:6byte,最近修改（修改/插入）事务D:记录创建这条记录/最后一次修改该记录的事务D
DB_ROLL PTR:7byte,回滚指针，指向这条记录的上一个版本（存储于rollback segment【回滚段】里）

对MVCC有帮助的实质是update undo log,它的执行流程如下：
在事务1修改该行（记录）数据时，数据库会先对该行加排他锁然后把该行数据拷贝到undo log中，作为旧记录，既在undo log中
有当前行的拷贝副本拷贝完毕后，修改该行name为Tom,
并且修改隐藏字段的事务D为当前事务1的D,我们默认从1开始，之后递增，回滚指针指向拷贝到undo log的副本记录，既表示
我的上一个版本就是它事务提交后，释放锁。
又来了个事务2修改person:表的同一个记录，将age修改为30岁在事务2修改该行数据时，数据库也先为该行加锁然后把该行数
据拷贝到undo log中，作为旧记录，发现该行记录已经有undo log了，那么最新的旧数据作为链表的表头，插在该行记录的
undo log:最前面修改该行age为30岁，并且修改隐藏字段的事务1D为当前事务2的ID,那就是2，回滚指针指向刚刚拷贝到undo
log的副本记录事务提交，释放锁
Read View的组成：所有未提交事务id数组【活跃事务】和已创建的最大事务id组成
作用：用来做可见性判断的，即当我们某个事务执行快照读的时候，对该记录创建一个Read View读视图，把它比作条件用来判
断当前事务能够看到哪个版本的数据，既可能是当前最新的数据，也有可能是该行记录的undo log!里面的某个版本的数据。





@ mysgl成本计算trace
(1)Explain
MySQL数据库，通过Explain:指令查看SELECT(5.6.3+版本开始支持update/delete/insert等)，下图为sakila.actor的表结构和一
个主建过滤查询的执行计划。
只是一个大概的，没有明细，不利于DBA优化语句。

(2)Optimizer Trace
lO成本：mys9的数据和索引是存储在磁盘上的，我们查询数据是，需要将数据页从磁盘上读出，这里就是O成本
CPU成本：数据或索引读出后，需要检测记录是否满足对应的搜索条件(whee条件)、对结果集进行排序等，这里就涉及到CPU成本。
从MySQL5.6版本开始，可支持把MySQL查询执行计划树打印出来，对DBA深入分析SQL执行计划，COST成本都非常有用，打
印的内部信息比较全面；
功能支持动态开关，因为对性能有20%左右影响，只建议分析问题时，临时开启
1使用方式
set session optimizer trace=“enabled=on";
select from actor
SELECT trace FROM information schema.OPTIMIZER TRACE
有一个大大的json串
重要看以下信息：
“rows_estimation”:[-预估表的访问成本
“potential range_indexes'”:[-查询可能使用的索引
“analyzing_range_alternatives”:{-分析各个索引使用成本
“best_access_path”:{--最优访问路径
结论：全表扫描的成本低于索引扫描，所以mysgli最终选择全表扫描
关闭trace.工具，因为trace.工具会影响mysql't性能
set session optimizer trace="enabled=off'



@ epoll和Reactor总结
ety是Java领域有名的开源网络库，特点是高性能和高扩展性，因此很多流行的框架都是基于它来构建的，比如我们熟知的
Dubbo、Rocketmg、Hadoop等
reactor模型：基于NIO技术，可读可写时通知应用；
·proactor模型：基于AIO技术，读完成时通知应用，写操作应用通知内核。
nettyl的线程模型是基于Reactor模型的。
(1)Reactor单线程模型
所有的I/O操作都在同一个NO线程上面完成的，此时NIO线程职责包括：接收新建连接请求、读写操作等。
RedisE的请求处理也是单线程模型，为什么Redisl的性能会如此之高呢？因为Redis的读写操作基本都是内存操作，并且Redis协
议比较简洁，序列化/反序列化耗费性能更低)。
但是对于高负载、大并发的应用场景却不合适，主要原因如下：
·一个N1O线程同时处理成百上千的连接，性能上无法支撑，即便NI0线程的CPU负荷达到100%，也无法满足海量消息的编码、解码、读取和发送。
·当NO线程负载过重之后，处理速度将变慢，这会导致大量客户端连接超时，超时之后往往会进行重发，这更加重了O线程的负载，最终会导致大量消息积压和处理超时，成为系统的性能瓶颈。
·可靠性问题：一旦○线程意外跑飞，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。

(2)Rector多线程模型
与单线程模型最大的区别就是有一组NIO线程来处理连接读写操作，一个NIO线程处理Accept.一个NIO线程可以处理多个连
接事件，一个连接的事件只能属于一个NIO线程。
在绝大多数场景下，Reactor多线程模型可以满足性能需求。但是，在个别特殊场景中，一个NIO线程负责监听和处理所有客户端连接可能会存在性能问题。
例如并发百万客户端连接，或者服务端需要对客户端握手进行安全认证，但是认证本身非常损耗性能。在这类场景下，单独一个Acceptor线程可能会存在性能不足的问题，
为了解决性能问题，产生了第三种Reactor线程模型一一主从Reactor多线程模型。

(3)主从Reactor线程模型
服务端用于接收客户端连接的不再是一个单独的NIO线程，而是一个独立的NIO线程池。Acceptor接收到客户端TCP连接请
求并处理完成后（可能包含接入认证等），将新创建的SocketChannel注册到/O线程池(sub reactor线程池)的某个
l/O线程上，由它负责SocketChannel的读写和编解码工作。Acceptor线程池仅仅用于客户端的登录、握手和安全认证，一旦
链路建立成功，就将链路注册到后端subReactor线程池的/O线程上，由l/O线程负责后续的l/O操作。

nety的线程模型并不是一成不变的，它实际取决于用户的启动参数配置。通过设置不同的启动参数，etty可以同时支持
Reactor单线程模型、多线程模型。
Netty拥有两个NIO线程池，分别是bossGroupi和workerGroup。
前者处理新建连接请求，然后将新建立的连接轮询交给workerGroup中的其中一个NioEventLoop:来处理，
后续该连接上的读写操作都是由同一个NioEventLoop:来处理。
注意，虽然bossGroup也能指定多个NioEventLoop(一个NioEventLoop对应一个线程)，但是默认情况下只会有一个线程，
因为一般情况下应用程序只会使用一个对外监听端口。

epoll为处理大批量句柄而作了改进的poll。当然，这不是2.6内核才有的，它是在2.5.44内核中被引进的，被公认为Linux2.6下性能最好的多路/就绪通知方法。
epoll是一种lO多路复用技术，可以非常高效的处理数以百万计的sockett句柄，比起以前的Iselect和pl效率高大发了。我们不
起poll来都感觉挺爽，确实快，那么，它到底为什么可以高速处理这么多并发连接呢？
首先要调用epoll_create建立一个epolly对象。参数size是内核保证能够正确处理的最大句柄数，多于这个最大数时内核可不保证效果。
epoll_ctl|可以操作上面建立的epoll,例如，将刚建立的socket加入到epoll中让其监控，或者把epollI正在监控的某个socket句柄移出epoll,不再监控它等等。
epoll_wait在调用时，在给定的timeout时间内，当在监控的所有句柄中有事件发生时，就返回用户态的进程。从上面的调用方式就可以看到epollb比select/poll的优越之处：因为后者每次调用时都要传递你所要监控的所有socket给
select/poll系统调用，这意味着需要将用户态的socket列表copy到内核态，如果以万计的句柄会导致每次都要copy几十几百KB的内存到内核态，非常低效。而我们调用epoll waitE时就相当于以往调用
select/poll,但是这时却不用传递socket句柄给内核，因为内核已经在epoll ct|中拿到了要监控的句柄列表。




@ 6nety/redis/kafka/nginx线性模型
(1)netty.的线程模型
netty.的线程模型并不是一成不变的，它实际取决于用户的启动参数配置。通过设置不同的启动参数，etty可以同时支持
Reactor单线程模型、多线程模型。
Netty:拥有两个NlO线程池，分别是bossGroup和vorkerGroup。
前者处理新建连接请求，然后将新建立的连接轮询交给workerGroupl中的其中一个NioEventLoop:来处理，
后续该连接上的读写操作都是由同一个NioEventLoop:来处理。
注意，虽然bossGroup也能指定多个NioEventLoop(一个NioEventLoop对应一个线程)，但是默认情况下只会有一个线程
因为一般情况下应用程序只会使用一个对外监听端口。

(2)redis线程模型
多个socket->O多路复用程序->scocketl队列->文件事件分配器->事件处理器（连接应答处理器，命令请求处理器，命令
处理器)
redisa基于reactort模式开发了网络事件处理器，这个处理器叫做文件事件处理器，file event handler。
这个文件事件处理器，是单线程的，redis才叫做单线程的模型，采用lO多路复用机制同时监听多个socket,根据socket上的事
件来选择对应的事件处理器来处理这个事件。
如果被监听的socket)准备好执行accept、read、write、close等操作的时候，跟操作对应的文件事件就会产生，这个时候文件
事件处理器就会调用之前关联好的事件处理器来处理这个事件。
文件事件处理器是单线程模式运行的，但是通过O多路复用机制监听多个socket,可以实现高性能的网络通信模型，又可以跟
内部其他单线程的模块进行对接，保证了redis内部的线程模型的简单性，事件处理器也是单线程快的原因是纯内存操作、避免

线程切换
警告：这里我们一直在强调的单线程，只是在处理我们的网络请求的时候只有一个线程来处理，一个正式的Redis Server运行
的时候肯定是不止一个线程的，这里需要大家明确的注意一下！例如Redis进行持久化的时候会以子进程或者子线程的方式执行
警告2：从Redis4.0版本开始会支持多线程的方式，但是，只是在某一些操作上进行多线程的操作。
1).Redis6.0之前的版本真的是单线程吗？
Redis在处理客户端的请求时，包括获取(socket读)、解析、执行、内容返回(socket写)等都由一个顺序串行的主线程处理
这就是所谓的“单线程”。
但如果严格来讲从Redis.0之后并不是单线程，除了主线程外，它也有后台线程在处理一些较为缓慢的操作，例如清理脏数
据、无用连接的释放、大key的等等。
其中执行命令阶段，由于Redis是单线程来处理命令的，所有每一条到达服务端的命令不会立刻执行，所有的命令都会进入
个Socket队列中，当socket可读则交给单线程事件分发器逐个被执行。

2).Redis6.0之前为什么一直不使用多线程？
应用程序主要使用O(N)或O(log(N)的命令，它几乎不会占用太多CPU。
使用了单线程后，可维护性高。多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，带来了并发
读写的一系列问题，增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗。
Redis通过AE事件模型以及lO多路复用等技术，处理性能非常高，因此没有必要使用多线程。单线程机制使得Redis内部实现
的复杂度大大降低，Hash的惰性Rehash、Lpush等等“线程不安全”的命令都可以无锁进行。

3).Redis6.0为什么要引入多线程呢？
Redis将所有数据放在内存中，内存的响应时长大约为100纳秒，对于小数据包，Redis服务器可以处理80.000到100,000
QPS,这也是Redis处理的极限了，对于8O%的公司来说，单线程的Redisi已经足够使用了。
但随着越来越复杂的业务场景，有些公司动不动就上亿的交易量，因此需要更大的QP。
常见的解决方案是在分布式架构中对数据进行分区并采用多个服务器，但该方案有非常大的缺点，例如要管理的Redis服务器
太多，维护代价大；
某些适用于单个Redis服务器的命令不适用于数据分区；数据分区无法解决热点读/写问题；数据偏斜，重新分配和放大/缩小变
得更加复杂等等。
所以总结起来，redis支持多线程主要就是两个原因：
·可以充分利用服务器CPU资源，目前主线程只能利用一个核
·多线程任务可以分摊Redis同步lO读写负荷

4).Redis6.0默认是否开启了多线程？
Redis6.0的多线程默认是禁用的，只使用主线程。
如需开启需要修改redis.conf配置文件：io-threads-do-reads yes

5).Redis6.0多线程的实现机制？
#主线程获取socket放入等待列表
#将socket分配给各个lO线程（并不会等列表满）
#主线程阻塞等待lO线程（多线程）读取socket完毕
#主线程执行命令-单线程（如果命令没有接收完毕，会等下次继续）
#主线程阻塞等待O线程（多线程）将数据回写socket完毕（一次没写完，会等下次再写）
#解除绑定，清空等待队列

(3)nginx线程模型
nginx是以多进程的方式来工作的。
nginx在启动后，会有一个masteri进程和多个workeri进程。
master进程主要用来管理worker进程：
#接收来自外界的信号，向各workeri进程发送信号。
#监控workeri进程的运行状态，当workeri进程退出后（异常情况下），会自动重新启动新的workeri进程。
而基本的网络事件，则是放在workeri进程中来处理了。worker进程之间是对等的，一个请求，只可能在一个workeri进程中处
理，一个workeri进程，不可能处理其它进程的请求。
worker进程的个数，一般会设置与机器cpu核数一致。当我们提供O端口的http服务时，一个连接请求过来，每个进程都有可
能处理这个连接。




@ aop引入&织入
(1)Springl AOP之引入(Introductions)
使用Spring AOP,我们可以为bean引入新的方法，代理拦截调用并委托给实现该方法的其他对象。
图中，A就是原目标类，B就是新添加的方法所在的类，通过建立一个代理类同时代理A和B,调用者调用该代理时，就可以同
时A和B中的方法了。
原接口和实现类(A类)：
public interface IPerformance
boolean perform(String programName);
}
public class Performance implements IPerformance
@Override
public boolean perform(String programName){
System.out println("开始表演节目："+programName);
System.out.printIn("表演节目结束！)；
return true;
}
}
增强接口和增强接口默认实现类(B类)：
public interface IEnhancePerformance
void thank();
}
public class EnhancePerformance implements IEnhancePerformance
@Override
public void thank(){
System.out.orintln("感谢大家的观看！")；
}
}
代理Schema配置：
<aop:aspectj-autoproxy.proxy.-target-class="true"expose-proxy="false"></aop:aspectj-autoproxy>
saop:config2
≤aop:aspect>
impl="com.yveshe.aop.EnhancePerformance"/>
</aop:aspect>
</aop:config2
Springi引入允许为目标对象引入新的接口，通过在<aop:aspect>标签内使用<aop:declare-parents:标签进行引入，定义方式
如下：
<aop:declare-parents
types-matching="AspectJ语法类型表达式
implement-interface:=引入的接口"
default-impl="引入接口的默认实现"
delegate-ref="引入接口的默认实现Bean引用"/>
分析：
1)目标对象类型匹配：使用types-matching:=com.yveshe.IPerformance+”匹配IPerformance:接口的子类型，如Performance实现；
2)引入接口定义：通过implement-interfacel属性表示引入的接口，如“com.yveshe.aop.IEnhancePerformance'”。
3)引入接口的实现：通过default-impl属性指定，如“com.yveshe.aop.EnhancePerformance'”,也可以使用“delegate-ref”指定实现的Bean。
4)获取引入接口：如使用“IEnhancePerformance ePerformance=context.getBean(“performance'”,
IEnhancePerformance.class);”可直接获取到引入的接口。

(2)AOP织入wave
织入是将切面和业务逻辑对象连接起来，并创建通知代理的过程。
织入可以在编译时，类加载时和运行时完成。在编译时进行织入就是静态代理，而在运行时进行织入则是动态代理。



@ Spring Boot Actuator
Actuator是Springboot提供的用来对应用系统进行自省和监控的功能模块，借助于Actuator开发者可以很方便地对应用系统某
些监控指标进行查看、统计等。
<dependency>
org.springframework.boot
<artifactld>spring-boot-starter-actuator</artifactld>
</dependency>
/autoconfig用来查看自动配置的使用情况，包括：哪些被应用、哪些未被应用以及它们未被应用的原因、哪些被排除。
/configprops可以显示一个所有@ConfigurationProperties的整理列表。
不
/beans可以显示Spring容器中管理的所有Bean的信息。
/dump用来查看应用所启动的所有线程，每个线程的监控内容如下图所示。
/env用来查看整个应用的配置信息，使用/env/[name]可以查看具体的配置项。
/health用来查看整个应用的健康状态，包括磁盘空间使用情况、数据库和缓存等的一些健康指标。
/info可以显示配置文件中所有以info.开头或与Git相关的一些配置项的配置信息。
/mappings用来查看整个应用的URL地址映射信息。
/metrics用来查看一些监控的基本指标，也可以使用/metrics/[name]查看具体的指标。
/shutdown是一个POST请求，用来关闭应用，由于操作比较敏感，默认情况下该请求是被禁止的，若要开启需在配置文件中添
加以下配置：
endpoints.shutdown.enabled:true
/tracel用来监控所有请求的追踪信息，包括：请求时间、请求头、响应头、响应耗时等信息。


此外，Springbooti还为提供了CounterService和GaugeServicep两个Bean来供开发者使用，可以分别用来做计数和记录double值。
@RestController
public class ActuatorController
@Autowired
private CounterService counterService;
@Autowired
private GaugeService gaugeService;
@GetMapping("/home")
public String home(){
/请求一次浏览数加1
counterService.increment("home browse count");
/请求时将app.version设置为1.0
gaugeService.submit("app.version",1.0);
return "Actuator home";
}
}


此外，Springbooti还允许用户自定义健康指标，只需要定义一个类实现Healthlndicator接口，并将其纳入到Spring容器的管理
之中。
@Component
public class MyHealthlndicator implements Healthlndicator{
@Override
public Health health(){
return Health.down().withDetail("error","spring boot error").build();
}



@ zk选主，zk分布式锁，kafka选主？
在分布式场景中经常会用到zookeeper,常用的有利用zookeeper来选举主从，管理节点状态，或者使用zookeeper来实现分布
式锁；具体原理是什么呢？
(1)编号大小来实现
选主：所有的节点向zk的某个路径下注册，创建临时节点（临时节点，zookeeper会主动监控，一旦连接失效，zk会该临
时节点)，每个注册者创建时会有一个编号，
每次选举编号最小的为主节点，其他节点就为从节点，从节点会监控主节点是否失效（怎么监控？k有事件，监听事件的状态
变化，然后重新选举)，为避免“惊群”现象，每个节点只监控比它小的一个临近节点。
分布式锁：也是一样，每次编号最小的获取锁。

(2)通过创建节点实现
集群中的所有机器将自己置为looking状态，准备开始选举，所有looking:状态的机器尝试去创建/leader-nfo节点。
创建成功的将自己的状态修改为leader,同时将自己的一些信息写入到/leader-info这个节点上，创建失败的将自己的状态置为
follower.

(3)kafka Controller leader
当broker)启动的时候，都会创建KafkaController对象，但是集群中只能有一个leader对外提供服务，这些每个节点上的
KafkaController会在指定的zookeeperi路径下创建临时节点，
只有第一个成功创建的节点的KafkaController:才可以成为leader,其余的都是follower。当leadert故障后，所有的follower:会收
到通知，再次竞争在该路径下创建节点从而选举新的leader

(4)Partition leader
由controller leader:执行
·从Zookeeper中读取当前分区的所有ISR(n-sync replicas)集合
·调用配置的分区选择算法选择分区的leader

(5)选举算法
1)Leaderi选举算法非常多，大数据领域常用的有以下两种：
·Zab(zookeepert使用)；
·Raft;
它们都是Paxos算法的变种。
2)Zab协议有四个阶段：
·Leader election;
·Discovery
·Synchronization(
·Broadcast
比如3个节点选举leader,编号为1,2,3。
1先启动，选择自己为leader,然后2启动首先也选择自己为leader,由于1,2都没过半，选择编号大的为leader,所以1,2都选
择2为leader,然后3启动发现1,2已经协商好且数量过半，于是3也选择2为leader,leaderi选举结束。
3)在Raft中，任何时候一个服务器可以扮演下面角色之一
·Leader:处理所有客户端交互，日志复制等，一般只有一个Leader;
·Follower:类似选民，完全被动
·Candidate候选人：可以被选为一个新的领导人
启动时在集群中指定一些机器为Candidate,然后Candidate:开始向其他机器（尤其是Follower)拉票，当某一个Candidatel的票
数超过半数，它就成为leader.。

4)常用选主机制的缺点
·split-brain(脑裂)：这是田ZooKeeper的特性引起的，虽然ZooKeeperi能保证T有Watch按顺序触友，但开不能保证同一的刻
所有Replica“看”到的状态是一样的，这就可能造成不同Replical的响应不一致；
·herd effect(羊群效应)：如果宕机的那个Broker_上的Partitionl比较多，会造成多个Watch被触发，造成集群内大量的调整；
·ZooKeeper负载过重：每个Replica都要为此在ZooKeeper.上注册一个Watch,当集群规模增加到几千个Partitionl时ZooKeeper负载会过重。








---------------------------------------------------------------------------------------------------------------
------------------------------------------Hiya-append-1.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------activiti basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
Activiti

一、基础知识
1 Activiti的优势：
（1）与jBPM4相比，Activiti5最令人瞩目的特性就在于它的协作工具组件。
Activiti Modeler—建模器，基于开源Signavio Web流程编辑器的一个定制版本，提供了对BPMN2.0图形化规范的支持，建模后的流程以文件格式进行存储。
Activiti probe—管理及监控组件，对流程引擎运行期实例提供管理及监控的Web控制台。包含部署的管理、流程定义的管理、数据库表的检视、日志查看、事务的平均执行时间、失败多次的工作等功能。

（2）Activiti拥有更简洁健壮的接口
Activiti中提供TaskQuery接口，可以设置各种查询过滤，排序方式，最终通过list方法执行查询，相比jbpm，它还提供了分页查询功能，双方高下立判。

（3）Activiti拥有更友好的用户体验
JBPM核心引擎完全没有关于表单的任何抽象，它的工作机制是通过全局常量，流程变量，任务变量，这些概念十分技术化。
相比之下Activiti则更贴近实际的应用场景，它将为开始节点，以及人工任务提供了表单设置，用户可以设置字段名称，字段类型。通过Activiti的平台可以根据这些设置去生成表单，
但如果不使用其平台只使用引擎的话，也支持通过它来表达与第三方表单的关系。这些表单设置的元数据信息也可以通过接口去获取。

（4）Activiti支持启动引擎后随时热部署
JBPM存在一个软肋，一个RuntimeService只能在启动的时候指定bpmn资源，一旦启动后便不再能够去更新或者增加bpmn了，这会导致我们系统集成的困难，因为我们自然希望整个系统只有一个工作流引擎实例运行。Activiti则提供了Deploy机制，将bpmn资源的热部署，热更新都做了很好的支持

（5）Activiti拥有更友好易用的Eclipse编辑插件和在线插件

（6）Activiti依赖更少的jar包
Activiti依赖的第三方jar包较少，主要就是mybatics，而JBPM则依赖了一大堆的jar，从drools到繁杂的hibernate，再到自身拆分的零零散散的jar包，让人不由觉得它是一个庞大的怪物。工作流有版本的概念，jBPM和Activiti上传一个新的版本后，版本号会增加1，旧版本还没执行完的流程实例还会继续执行。SWF的版本是个字符串，随意指定好了，这样也很好，字符串名称更明确。嵌入式部署即将流程引擎嵌入部署于Web应用中。

2 各个Service的作用
RepositoryService	Activiti的仓库服务类。所谓的仓库指流程定义文档的两个文件：bpmn文件和流程图片
该service可以用来删除部署的流程定义。
RuntimeService	执行管理，包括启动，推进，删除流程实例等操作
TaskService	是activiti的任务服务类。可以从这个类中获取任务的相关信息，如当前正在执行的个人待办和用户组待办任务。
HistoryService	是activiti的查询历史信息的类，在一个流程执行完成后，这个对象为我们提供查询历史信息，可以跟踪流程实例对应所有待办节点的运行情况。
IdentityService	认证服务，在工作流执行过程中进行用户查询、认证等操作
FormService	Activiti表单引擎产生的用户任务表单服务

3 网关分类
1）互斥网关
只会返回一条结果。当流程执行到排他网关时，流程引擎会自动检索网关出口，从上到下检索如果发现第一条决策结果为true或者没有设置条件的(默认为成立)，则流出。
如果没有任何一个出口符合条件，则抛出异常。
${stuType==1}
${stuType==2}

2）并行网关
无条件触发，不会解析条件，写了条件也会被忽略。进入和外出的数目不一定相等。分支(fork)： 并行后的所有外出顺序流，为每个顺序流都创建一个并发分支。汇聚(join)： 所有到达并行网关，在此等待的进入分支， 直到所有进入顺序流的分支都到达以后， 流程就会通过汇聚网关。
流入下一个节点可以设置条件，可以是全部子任务都完成还是50%完成。

3）包容性网关
集中了前两个网关的特点，可以定义条件，多条件执行，只要条件返回true就会执行，包含网关只会等待被选中执行了的进入顺序流。

4）事件网关
基于事件网关允许根据事件判断流向。网关的每个外出顺序流都要连接到一个中间捕获事件。 当流程到达一个基于事件网关，网关会进入等待状态：会暂停执行。 与此同时，会为每个外出顺序流创建相对的事件订阅。

4 setVariableLocal
setVariable：设置流程变量的时候，流程变量名称相同的时候，后一次的值替换前一次的值，而且可以看到TASK_ID的字段不会存放任务ID的值           
setVariableLocal：设置流程变量的时候，针对当前活动的节点设置流程变量，如果一个流程中存在2个活动节点，对每个活动节点都设置流程变量，即使流程变量的名称相同，后一次的版本的值也不会替换前一次版本的值，它会使用不同的任务ID作为标识，存放2个流程变量值，而且可以看到TASK_ID的字段会存放任务ID的值。

5 AOP式的监听器
（1） 一般思路：
ACT_RE_actdef_ext表配置每个节点的处理人（变量，角色，用户组，团队），邮件通知人，回调服务等信息。在配置文件中配置ParseHandler，启动服务器会自动为所有流程的 process(start,end); usertask(start,complete,end); sequence(take) 添加监听器,根据 配置的节点对应的信息做相应的业务逻辑处理。
  <bean id="processEngineConfiguration" class="org.activiti.spring.SpringProcessEngineConfiguration">  
        <property name="dataSource" ref="dataSource" />  
        <property name="transactionManager" ref="transactionManager" />  
        <property name="databaseSchemaUpdate" value="true" />  
        <property name="jpaHandleTransaction" value="true" />  
        <property name="jpaCloseEntityManager" value="true" />  
        <property name="jobExecutorActivate" value="false" />  
        <property name="idGenerator" ref="uuidGenerator"/>
        <!-- <property name="deploymentResources" value="classpath*:diagrams/*.*" />   -->
        <property name="customDefaultBpmnParseHandlers">
			<list>
				<bean class="com.parse.ActivitiProcessExtParseHandler" />
				<bean class="com.parse.ActivitiReceiveTaskExtParseHandler" />
				<bean class="com.parse.ActivitiSequenceFlowExtParseHandler" />
				<bean class="com.parse.ActivitiServiceTaskExtParseHandler" />
				<bean class="com.parse.ActivitiUserTaskExtParseHandler" />
			</list>
	   </property>
    </bean> 

（2）扩展Activiti流程定义文件,实现自定义节点属性 
customDefaultBpmnParseHandlers 注册各种监听器
监听器包括启动流程日志，任务完成日志，流程开始，流程结束，消息任务开始，消息任务结束，服务任务开始，服务任务结束，用户任务开始，用户任务完成等监听器。

6 命令模式和责任链模式
Activiti任务的执行 用到了设计模式中的命令模式和责任链模式。
命令模式是将行为请求者和行为实现者解耦合的方式。对命令进行封装，将命令和执行命令分隔开。请求的一方发出命令，要求执行某些操作，接受一方收到命令，执行这些操作的真正实现。
请求的一方不必知道接受方的接口，以及如何被操作。

以启动流程拦截器链为，一般是默认的拦截器，可以自定义before/after拦截器。 
logger拦截器-->spring事务拦截器-->CommandContext拦截器-->CommandInvoker拦截器




二、ms相关
1 什么是工作流，工作流的核心对象是什么，activiti共操作数据库多少张表
 工作流就是多个参与者，按照某种预定义的规则，传递业务信息，进行审核的功能一个框架（Activiti）
 processEngine，调用Service，从而操作数据库的表
 23表

2 工作流中RepositoryService、RuntimeService、TaskService、HistoryService分别表示什么操作
RepositoryService:流程定义和部署对象
RuntimeService 执行管理，包括流程实例和执行对象（正在执行）
TaskService 执行任务相关的（正在执行）
HistoryService 历史管理
IdentityService Activiti表的用户角色组

3 流程实例和执行对象的区别
 流程从开始到结束的最大分支，一个流程中，流程实例只有1个
 执行对象，就是按照流程定义的规则执行一次的操作，一个流程中，执行对象可以有多个

4 流程变量在项目中的作用
1）用来传递业务参数，目的就是审核人可以通过流程变量查看申请人的一些审核信息
2）在连线的condition中设置流程变量，用来指定应该执行的连线${message==’重要’}
3）使用流程变量指定个人任务和组任务的办理人#{userID}

5 activiti工作流中，如果一个任务完成后，存在多条连线，应该如何处理？
 使用流程变量
 当一个任务完成之后，根据这几条连线的条件和设置流程变量，例如${流程变量的名称==’流程变量的值’}，{}符号是boolean类型，判断走哪条连线
 
6 activiti工作流中，排他网关和并行网关都能执行什么功能
排他网关 分支，通过连线的流程变量，判断执行哪条连线，如果条件不符合，会执行默认的连线离开，注意 只能执行其中的一个流程。
并行网关 可以同时执行多个流程，直到总流程的结束。可以对流程进行分支和聚合，注意 流程实例和执行对象是不一样的

7 分配个人任务的三种方式
直接给值，在Xxxx.bpmn文件中指定
流程变量${流程变量的名称}或者#{}
使用类 监听这个类（实现一个接口），指定任务的办理人（setAssgnee()）

8 个人任务和组任务的查询一样吗？
 不一样
 都是用TaskService完成（TaskService.createTasQuery）
 个人任务（taskAssgnee），组任务（taskCandidateUser）
 数据库存放，个人任务（类型 参与），组任务（类型，参与，候选）

9 activiti会签
 Activiti实现会签是基于多实例任务，将节点设置成多实例，主要通过在UserTask节点的属性上配置
 会签环节中设计的几个默认流程变量 
nrOfInstances（numberOfInstances）：会签中总共的实例数
nrOfCompletedInstances：已经完成的实例数量
nrOfActiviteInstances：当前活动的实例数量，即还没有完成的实例数量
条件${nrOfInstances == nrOfCompletedInstances}表示所有人员审批完成后会签结束。
条件${ nrOfCompletedInstances == 1}表示一个人完成审批，该会签就结束。


---------------------------------------------------------------------------------------------------------------
------------------------------------------activiti basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------ai basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
AI

一、基础知识
1 人工智能
AI（Artificial Intelligence）是在计算机科学、控制论、信息论、神经心理学、哲学、语言学等多种学科研究的基础上发展起来的一门交叉学科。
AI与空间技术、原子技术一起誉为21世纪的三大科学技术成就，前三次工业革命主要是延长了人手的功能，AI延伸了人脑的功能，实现了脑力劳动的自动化。

2 AI研究的基本内容
（1）知识表示
将人类知识形式化或者模型化。实际上就是对知识的一种描述，或者说是一组约定，一种计算机可以接受的用于描述知识的数据结构。分两大类：符号表示法，连接机制表示法。
（2）机器感知
使机器具有类似于人的感知能力，其中以机器视觉与机器听觉为主。机器视觉是让机器能够识别并理解文字、图像、物景等；机器听觉是让机器能识别并理解语言、声响等。模式识别与自然语言理解
（3）机器思维
对通过感知得来的外部信息及机器内部的各种工作信息进行有目的的处理，是AI研究中最重要、最关键的部分
（4）机器学习
研究如何是计算机具有类似人的学习能力，使它能通过学习自动地获取知识。计算机可以直接向书本学习，通过与人谈话和对环境的观察学习，并在实践中实现自我完善。机器学习研究的目标有3个：人类学习过程的认知模型；通用学习算法；构造面向任务的专用学习系统的方法。
（5）机器行为
与人的行为能力相对应，机器行为主要是指计算机的表达能力，即“说”、“写”、“画”等能力。对于智能机器人，它还应具有人的四肢功能，即能走路、能取物、能操作等。

3 机器学习应用
天气预报
搜索引擎
机器学习技术支撑各类搜索引擎技术
汽车的自动驾驶
汽车在复杂道路行驶时，自动行驶可大大减少交通事故的发生 
天文数据的分析
生物技术
蛋白质片段预测，基因表达分析
计算机系统特性预测
银行
信用卡欺诈行为识别
字符识别
手写字识别、车牌号码识别
Web应用
网络安全-----入侵检测
利用这些数据建立一个把正常访问模式和入侵模式分开的模型
通过检查服务器日志等手段收集大量的网络访问数据，这些数据包含正常访问模式和入侵模式
接收到新访问模式时，利用这个模型判断这个模式是正常还是入侵模式，甚至判断是何种类型的入侵

4 机器学习算法
推荐算法、神经网络算法、支持向量机算法、聚类算法、决策树算法、叶贝斯算法、文本挖掘

5 深度学习
通过构建具有很多隐层的机器学习模型和海量的训练数据，来学习更有用的特征，从而最终提升分类或预测的准确性。因此，“深度模型”是手段，“特征学习”是目的。区别于传统的浅层学习，深度学习的不同在于：
强调了模型结构的深度，通常有5层、6层，甚至10多层的隐层节点；
明确突出了特征学习的重要性，也就是说，通过逐层特征变换，将样本在原空间的特征表示变换到一个新特征空间，从而使分类或预测更加容易。与人工规则构造特征的方法相比，利用大数据来学习特征，更能够刻画数据的丰富内在信息。

6 人工智能包含机器学习、机器学习包含深度学习

7 深度算法神经网络
感知器神经网络、BP神经网络、RBF径向基神经网络、卷积神经网络(CNN)、循环神经网络(RNN)、生成对抗网络(GAN）

8 区块链
一种“共识”实现技术，通过区块链可以记录网际间所有的交易，供区块链的用户见证实现“共识”，且链上信息内容“不可篡改”。而这种“不可篡改”性是通过系统内多个副本的存在增加了内容被恶意篡改的成本。以比特币系统而言，下图中的所有亮点代表一套内容一致的账本。因此，当所有的记录得到公示，就解决了现实生活中的“两表不可测”问题。

区块链的本质是一个分布式的公共账本，任何人都可对这个账本进行核查，但不存在单一的用户可以对它控制。在区块链系统中的参与者共同维持账本的更新：它只能按照严格的规则和共识进行修改。
举例：如果A借了B 100块钱，这个时候，A在人群中大喊“我是A，我借给了B 100块钱！”，B也在人群中大喊“我是B，A借给了我100块！”此时路人甲乙丙丁都听到了这些消息，因此所有人都在心中默默记下了“A借给了B100块钱”。这个系统中不需要银行，也不需要借贷协议和收据，严格来说，甚至不需要人与人长久的信任关系（比如B突然又改口说“我不欠A钱！”，这个时候人民群众就会站出来说“不对，我的小本本上记录了你某天借了A100块钱！”）。

9 从技术角度简单理解区块链
1） 区块链的本质
区块链是一种特殊的分布式数据库。
首先，区块链的主要作用是储存信息。任何需要保存的信息，都可以写入区块链，也可以从里面读取，所以它是数据库。
其次，任何人都可以架设服务器，加入区块链网络，成为一个节点。区块链的世界里面，没有中心节点（去中心化），每个节点都是平等的，都保存着整个数据库。你可以向任何一个节点，写入/读取数据，因为所有节点最后都会同步，保证区块链一致。
2）区块链的最大特点
区块链没有管理员，它是彻底无中心的。其他的数据库都有管理员，但是区块链没有。如果有人想对区块链添加审核，也实现不了，因为它的设计目标就是防止出现居于中心地位的管理当局。没有了管理员，人人都可以往里面写入数据，怎么才能保证数据是可信的呢，这就是区块链奇妙的地方。


二、ms相关
1 深度学习（Deep Learning, DL）和机器学习（Machine Learning, ML）的关系是什么？
深度学习是机器学习的子类，是利用深度神经网络提取特征进行学习。机器学习还有其他非深度学习的技术，例如SVM、Decision Tree、Naive Bayes等。

2 深度学习流行的框架有哪些？各有什么特点？
TensorFlow：最主流，生态支持完备，硬件友好，同时有Google Brain研究支撑。
PyTorch：后起之秀，融合了Torch和Caffe2，和python混合编程体验好，学术界宠儿。
以及国内的PaddlePaddle，MindSpore等。

3 精确率（Precision）和召回率（Recall）以及F1值/分数（F1 value/score）是什么？查准率和查全率呢？
先解释缩写：
TP: True Positive，预测为真，结果也为真的数量；
FP: False Positive，预测为真，结果为假的数量；
FN: False Negative，预测为假，结果为真的数量。
精确率：P = TP/(TP+FP)，西瓜书里也叫查准率；
召回率：R = TP/(TP+FN)，西瓜书里也叫查全率。
F1值：F1 = 2*(P*R)/(P+R)，精确率和召回率的调和均值。
可以看出，精确率和召回率的区别在于分母，精确率关心的是预测为真的数量中有多少真正对的（而不是其他类错误预测为这一类），而召回率关注的是这一类有多少判断正确了（而不是判断为其他类了）。直观理解：召回的意思是，如果这一类错误预测为其他类了，要找回来，即为召回。

4 AUC指标与precesion/recall/F1评估模型的手段有何区别，什么情况下应该用哪一种？
AUC是Area under Curve，曲线下面积。这个曲线横纵坐标分别为TPR和FPR.
TPR: True Positive Rate, 即recall; TPR = TP/(TP+FN), 表示正确分类的正样本所占所有正样本的比例；
FPR: False Positive Rate, FPR = FP/(FP+TN)，表示错误分类的负样本占所有负样本的比例。
对于同一个模型，TPR和FPR是一对跷跷板，可以通过修改阈值的方式来调节，例如调低分类为正样本的门槛，则更多的样本被分类为正样本，TP会增加，导致FPR增加；但此时，FP也会增加，导致FPR增加。
F1 score相当于是综合了precision和recall，使用默认阈值；AUC是一个模型更为全面的指标，考虑了不同的阈值。但由于AUC比较复杂，一般情况下使用F1 score就可以了。

5 SGD 中 S代表什么，如何理解？
S即为stochastic，随机梯度是指用来计算梯度的输入数据是随机选取的一部分（batch），而不是所有的数据。使用所有数据一方面计算量巨大，不太现实，另一方面容易陷入局部极小值难以跳出，随机batch的梯度反而增加了跳出局部极限值的可能性，从而获得更好的结果。

6 激活函数（Activation Function）有什么用处，有哪几种？
提供了非线性单元，使得整个网络变为非线性，从而能够解决各种非线性问题。
有ReLU / PReLU / Relu6 / Sigmond / Tanh / SELU / SWISH等，目前最常用的还是ReLU, 复杂度低，效果还可以。

7 监督学习和无监督学习的区别？请分别举例。
监督学习必须要标注，使用标记数据牵引训练，例如LR、SVM；
无监督机器学习不需要标注，模型通过自己发现数据的内部关系，例如Kmeans。

8 机器学习/深度学习项目中所需的步骤？
采集数据、预处理与特征选择、选择模型、训练模型、评估模型、诊断模型、调整参数，最后是预测、上线运行。

9 神经网络参数初始化方法有哪些，适用范围是什么？
weight最常用的是由Kaiming He提出的MSRA，在Xavier的基础上改进。Xavier假设激活函数关于原点中心对称，而常用的ReLU并不满足该条件。MSRA初始化是一个均值为0，方差为sqrt(2/Fin)的高斯分布。Xavier初始化是一个均匀分布U[-sqrt(6/(Fin+Fout))]，Fin、Fout代表扇入、扇出，即为输入和输出的维度。
bias一般初始化为0，另外提醒一下如果conv后面接bn，可以省略bias，是等价的，有兴趣的可以自己推导一下。
因此，如果激活函数使用ReLU，则推荐使用MSRA；如果激活函数使用tanh等中心对称的函数，则使用Xavier初始化。

10 列举深度学习中常用的分类网络、检测网络、分割网络（语义分割、多实例分割）、超分网络。
分类网络：ResNet，SENet，EfficientNet等；
检测网络：Faster RCNN，YOLO，SSD等；
分割网络：Mask RCNN、UNet等；
超分网络：SRCNN、FSRCNN等。
具体网络介绍可以关注我的公众号和博客。

11 ResNet解决了什么问题？结构有何特点？
ResNet提出是为了解决或缓解深度神经网络训练中的梯度消失问题。通过增加shortcut，使得梯度多了一个传递的途径，让更深的网络成为可能。

12 在图像处理中为什么要使用卷积神经网络（CNN）而不是全连接网络（FC）？
首先，CNN相对于FC的参数量减少非常多，对于图像这种输入维度相对较大的任务，全部使用FC不现实，另外参数量过多而数据规模跟不上非常容易过拟合，网络本身也难以训练。图像本身附近像素的关联信息很多，CNN正好能够提取一个区域数据的特征，并且能够通过不断加深扩展感受野，使得其适用于图像任务。

13 分类网络和检测网络的区别？
任务不同，Loss函数不同，一般分类网络使用cross entropy loss，而检测网络的loss是分类的loss和检测框回归loss的加权和。

14 损失函数（loss函数）有什么作用？
牵引网络的更新，梯度是loss函数相对于权重的偏导。

15 网络训练时为何要加正则化，有哪些手段？
目的是防止网络过拟合。
手段有：
L1/L2正则化
Dropout
Early stop
数据增强也可以视为是一种正则化，例如图像的平移、旋转、缩放等。

16 如何判断网络是过拟合还是欠拟合？有哪些手段改善？
通过train和test的准确率来判断，如果train和test准确率差距非常大，即train的准确率接近100%，而test较差，说明过拟合；如果train的准确率就较差，说明欠拟合。
过拟合可以通过增加数据，或者加正则化缓解；欠拟合可以增加网络容量，例如加深或者加宽网络来改善。

17 Batch Normalization有什么作用？使用时需要注意什么？
BN的主要作用有：
加速网络的训练（缓解梯度消失，支持更大的学习率）
防止过拟合
降低了参数初始化的要求
使用时需要注意train时更新bn的相关参数，而test时要固定，一般有is_training的flag.

18 梯度爆炸有哪些解决办法？
梯度截断（gradient clipping）
良好的参数初始化策略
调小lr



---------------------------------------------------------------------------------------------------------------
------------------------------------------ai basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------commons basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------

一、ms相关
1自我介绍？
你好，名字，户籍，学校，工作经验和经历，职业规划，收尾

2什么时候可以到岗？住在哪里？上班是否方便？
随时，龙华，方便

3怎么看加班？
项目进度紧急，上线，有紧急线上问题的时候可以接受加班

4平时工作中遇到什么困难，怎么解决的？
@Activiti异步task，去除异步选项
@报表缓慢，查询中间表并且同步
@同步axis接口超时连接中断，更换方案 

5为什么离职？
个人原因

6做过什么自认为有挑战性的工作？
@切换工作流到activiti, 整个电商系统完全重构，所有场景需要回归测试
@三条业务线并行研发，基本能够准时交付
@elk收视分析，客服困难  

7说下自己的工作中的优势和缺点？
@优势，积极主动，工作效率高，态度好，有责任心
@缺点，事情比较集中有点急躁

8 经常溜达的IT学习网站是？
CSDN; 博客园; Github; 码云 ；微信公众号 

9最近一个项目的前后端技术栈是什么？技术框架的版本号？
Spring4.1,mybatis3.2,activiti5.21

10你在最近一个项目中担任什么角色，具体的工作是什么？
部门经理，三个项目的整体进度把控，跟进转测问题，解决生产问题，需求分解
11最近一个项目构建和部署方式是什么？
Jenkins+maven+git 

12开发模式和开发流程？有没有设计阶段？用什么工具设计？画过什么图？
敏捷开发，需求分析--概要设计--编码自测试---测试---预发布---生产环境  
有，visio和powerdesigner; 类图，状态图等 

13有没有采用分布式架构？为什么？
采用了，业务量比较大，按照订单，框架，流程，组件，交付 进行垂直分割，分割后每个模块有独立的集群环部署环境，独立的数据库。

14项目开发中哪些场景采用设计模式，用了哪些？
适配器模式：activiti监听器
单例模式：activiti事件逻辑
代理模式：aop记录日志
命令模式：流程监控功能 

15项目的单点登录怎么实现的？	
CAS服务器 

16项目开发中有没有性能优化的例子？采用什么方法解决什么问题？
有，我的任务性能优化，用sql语句取代后台逻辑，简化设计，去除繁冗的逻辑 

17项目怎么保证接口安全问题？ 
Ip白名单，签名机制和数字证书  

18有集群部署吗？怎么解决多台服务器共享session问题？ 
有，CAS或者Redis 

19 介绍下最有代表性的项目的整体情况？ 
Ideal电商切换底层流程引擎

20 介绍下最近一个参与项目的整体情况？
聚引客




---------------------------------------------------------------------------------------------------------------
------------------------------------------commons basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------concurrent basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 线程状态
1）新建状态（New）：新创建了一个线程对象。
2）就绪状态（Runnable）：线程对象创建后，其他线程调用了该对象的start()方法。该状态的线程位于可运行线程池中，变得可运行，等待获取CPU的使用权。
3）运行状态（Running）：就绪状态的线程获取了CPU，执行程序代码。
4）阻塞状态（Blocked）：阻塞状态是线程因为某种原因放弃CPU使用权，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。阻塞的情况分三种：
（一）等待阻塞：运行的线程执行wait()方法，JVM会把该线程放入等待池中。(wait会释放持有的锁)   。在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池中。
（二）同步阻塞：运行的线程
（三）其他阻塞：运行的线程执行sleep(不会释放持有的锁)或join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()超时）join()）I/O处理完毕时，线程重新转入就绪状态。
5）死亡状态（Dead）：线程执行完了或者因异常退出了run()方法，该线程结束生命周期。

2 死锁
两个线程互相等待对方释放同步监视器，就发生了死锁。
死锁的产生是有规律可循的，只有同时满足以下四个条件，死锁才会产生。
1）.互斥条件：一个资源每次只能被一个进程使用。独木桥每次只能通过一个人。
2）.请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。乙不退出桥面，甲也不退出桥面。
3）.不剥夺条件: 进程已获得的资源，在未使用完之前，不能强行剥夺。甲不能强制乙退出桥面，乙也不能强制甲退出桥面。
4）.循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。如果乙不退出桥面，甲不能通过，甲不退出桥面，乙不能通过。

3 同步策略和秒杀系统
1）. 超发的原因
假设某个抢购场景中，我们一共只有100个商品，在最后一刻，我们已经消耗了99个商品，仅剩最后一个。这个时候，系统发来多个并发请求，这批请求读取到的商品余量都是99个，然后都通过了这一个余量判断，最终导致超发。
在上面的这个图中，就导致了并发用户B也“抢购成功”，多让一个人获得了商品。这种场景，在高并发的情况下非常容易出现。
2）. 悲观锁思路
解决线程安全的思路很多，可以从“悲观锁”的方向开始讨论。
悲观锁，也就是在修改数据的时候，采用锁定状态，排斥外部请求的修改。遇到加锁的状态，就必须等待。
虽然上述的方案的确解决了线程安全的问题，但是，别忘记，我们的场景是“高并发”。也就是说，会很多这样的修改请求，每个请求都需要等待“锁”，某些线程可能永远都没有机会抢到这个“锁”，
这种请求就会死在那里。同时，这种请求会很多，瞬间增大系统的平均响应时间，结果是可用连接数被耗尽，系统陷入异常。
3）. FIFO队列思路
那好，那么我们稍微修改一下上面的场景，我们直接将请求放入队列中的，采用FIFO（First Input First Output，先进先出），这样的话，我们就不会导致某些请求永远获取不到锁。看到这里，是不是有点强行将多线程变成单线程。
然后，我们现在解决了锁的问题，全部请求采用“先进先出”的队列方式来处理。那么新的问题来了，高并发的场景下，因为请求很多，很可能一瞬间将队列内存“撑爆”，然后系统又陷入到了异常状态。或者设计一个极大的内存队列，也是一种方案，但是，系统处理完一个队列内请求的速度根本无法和疯狂涌入队列中的数目相比。也就是说，队列内的请求会越积累越多，最终Web系统平均响应时候还是会大幅下降，系统还是陷入异常。
4）. 乐观锁思路
这个时候，我们就可以讨论一下“乐观锁”的思路了。乐观锁，是相对于“悲观锁”采用更为宽松的加锁机制，大都是采用带版本号（Version）更新。实现就是，这个数据所有请求都有资格去修改，但会获得一个该数据的版本号，只有版本号符合的才能更新成功，其他的返回抢购失败。这样的话，我们就不需要考虑队列的问题，不过，它会增大CPU的计算开销。但是，综合来说，这是一个比较好的解决方案。
有很多软件和服务都“乐观锁”功能的支持，例如Redis中的watch就是其中之一。通过这个实现，我们保证了数据的安全。
5）.concurrentHashMap思路
保证了同步和效率。
package com.hiya.concurrent.safety.method;
import java.util.Date;
import java.util.Iterator;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;
public class ThreadSafety
{
    /**
     * 普通的线程不安全，不能保证原子性，可见性 
     * 几个线程分别进行了一次自增操作后，inc只增加了1
     * 由于不能保证可见性，所以数值比incVolatile要小 
     */
    public   int   incCommon = 0;
    Lock lock = new ReentrantLock();
    public  AtomicInteger incAtomic = new AtomicInteger(0);
    
    /**
     *  假如某个时刻变量incVolatile的值为10，
            线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了；
            然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，
            所以线程2会直接去主存读取inc的值，发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。
            然后线程1接着进行加1操作，由于已经读取了inc的值，注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。
            
            那么两个线程分别进行了一次自增操作后，inc只增加了1。
            
            解释到这里，可能有朋友会有疑问，不对啊，前面不是保证一个变量在修改volatile变量时，会让缓存行无效吗？然后其他线程去读就会读到新的值，对，这个没错。这个就是上面的happens-before
            规则中的volatile变量规则，但是要注意，线程1对变量进行读取操作之后，被阻塞了的话，并没有对inc值进行修改。然后虽然volatile能保证线程2对变量inc的值读取是从内存中读取的，但是线程1没
            有进行修改，所以线程2根本就不会看到修改的值。
            根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。
     */
    public volatile  int   incVolatile= 0;
    

    /**
     * 线程不安全
     */
    public void increase()
    {
        incCommon++;
    }
    
    /**
     * 保证可见性（立即写入内存通知其他线程）和有序性（阻止cpu进行指令重排，但是仅仅针对该变量），但是没有原子性 
     */
    public void increaseVolatile()
    {
        incVolatile++;
    }
    
    /**
     * 线程安全，传统办法
     */
    public synchronized void increaseSynchronized()
    {
        incCommon++;
    }
    
    /**
     * 线程安全，lock方法，速度快一倍 
     */
    public  void increaseLock() 
    {
        lock.lock();
        try 
        {
            incCommon++;
        } 
         finally
        {
            lock.unlock();
        }
    }
    
    /**
     * 在java 1.5的java.util.concurrent.atomic包下提供了一些原子操作类，即对基本数据类型的 自增（加1操作），自减（减1操作））以及加法操作（加一个数），
     * 减法操作（减一个数）进行了封装，保证这些操作是原子性操作。atomic是利用CAS来实现原子性操作的（Compare And Swap），CAS实际上是利用处理器提供的
     * CMPXCHG指令实现的，而处理器执行CMPXCHG指令是一个原子性操作。
     */
    public  void increaseAtomic() 
    {
        incAtomic.getAndIncrement();
    }
    
    public static void doBusiness(String type)
    {
        System.out.println("Begin time:"+new Date(System.currentTimeMillis()));
        final ThreadSafety test = new ThreadSafety();
        for (int i = 0; i < 10; i++)
        {
            new Thread()
            {
                public void run()
                {
                    for (int j = 0; j < 10000000; j++)
                    {
                        if("Common".equals(type))
                        {
                            test.increase();
                        }
                        else  if("Volatile".equals(type))
                        {
                            test.increaseVolatile();
                        }
                        else  if("Synchronized".equals(type))
                        {
                            test.increaseSynchronized();
                        }
                        else  if("Lock".equals(type))
                        {
                            test.increaseLock();
                        }
                        else  if("Atomic".equals(type))
                        {
                            test.increaseAtomic();
                        }
                        else
                        {
                            test.increase();
                        }
                    }
                };
            }.start();
        }

        while (true) 
        {
            int activeCount = Thread.activeCount() ;
            //System.out.println("activeCount="+activeCount );
            if(activeCount >1)
            {
                Map<Thread, StackTraceElement[]> map = Thread.getAllStackTraces();
                Set<Entry<Thread, StackTraceElement[]>> entry = map.entrySet();  
                Iterator<Map.Entry<Thread, StackTraceElement[]>>  ite = entry.iterator();  
                while(ite.hasNext())  
                {  
                    Map.Entry<Thread, StackTraceElement[]> en = ite.next();  
                    Thread key = en.getKey();  
                    System.out.println("当前线程："+key.getName() );
                } 
            }
            //只有主线程 main
            if(activeCount == 1)
            {
                System.out.println("incCommon="+test.incCommon);
                System.out.println("incVolatile="+test.incVolatile);
                System.out.println("incAtomic="+test.incAtomic);
                System.out.println("End time:"+new Date(System.currentTimeMillis()));
                break;
            }
        }
    }
}

4 lock 概述
1） java.util.concurrent.lock 中的 Lock 框架是锁定的一个抽象，它允许把锁定的实现作为 Java 类，而不是作为语言的特性来实现。这就为 Lock 的多种实现留下了空间，各种实现可能有不同的调度算法）性能特性或者锁定语义。 ReentrantLock 类实现了 Lock ，它拥有与 synchronized 相同的并发性和内存语义，但是添加了类似锁投票）定时锁等候和可中断锁等候的一些特性。此外，它还提供了在激烈争用情况下更佳的性能。（换句话说，当许多线程都想访问共享资源时，JVM 可以花更少的时候来调度线程，把更多时间用在执行线程上。）lock 必须在 finally 块中释放。否则，如果受保护的代码将抛出异常，锁就有可能永远得不到释放！
2） reentrant 锁意味着什么呢？简单来说，它有一个与锁相关的获取计数器，如果拥有锁的某个线程再次得到锁，那么获取计数器就加1，然后锁需要被释放两次才能获得真正释放。
3） ReentrantLock与synchronized的比较
@相同：ReentrantLock提供了synchronized类似的功能和内存语义。
@不同：
（1）ReentrantLock功能性方面更全面，比如时间锁等候，可中断锁等候，锁投票等，因此更有扩展性。在多个条件变量和高度竞争锁的地方，用ReentrantLock更合适，ReentrantLock还提供了Condition，对线程的等待和唤醒等操作更加灵活，一个ReentrantLock可以有多个Condition实例，所以更有扩展性。
（2）ReentrantLock 的性能比synchronized会好点，同样的测试，时间缩短一半。
（3）ReentrantLock提供了可轮询的锁请求，他可以尝试的去取得锁，如果取得成功则继续处理，取得不成功，可以等下次运行的时候处理，tryLock所以不容易产生死锁，而synchronized则一旦进入锁请求要么成功，要么一直阻塞，所以更容易产生死锁。
4） 在内部锁中，死锁是致命的——唯一的恢复方法是重新启动程序，唯一的预防方法是在构建程序时不要出错。而可轮询的锁获取模式具有更完善的错误恢复机制，可以规避死锁的发生。 如果你不能获得所有需要的锁，那么使用可轮询的获取方式使你能够重新拿到控制权，它会释放你已经获得的这些锁，然后再重新尝试。可轮询的锁获取模式，由tryLock()方法实现。此方法仅在调用时锁为空闲状态才获取该锁。如果锁可用，则获取锁，并立即返回值true。如果锁不可用，则此方法将立即返回值false。
tryLock(long, TimeUnit) 实现可定时的锁请求  
lockInterruptibly()方法能够使你获得锁的时候响应中断
    Lock lock = ...;   
    if (lock.tryLock()) {   
    try {   
     
    } finally {   
    lock.unlock();   
    }   
    } else {   
    } 

5） Condition条件变量是为了解决Object.wait/notify/notifyAll难以使用的问题
条件变量需要与锁绑定，而且多个Condition需要绑定到同一锁上。获取一个条件变量的方法是Lock.newCondition()。

    void await() throws InterruptedException;  
    void awaitUninterruptibly();  
    long awaitNanos(long nanosTimeout) throws InterruptedException;  
    boolean await(long time, TimeUnit unit) throws InterruptedException;  
    boolean awaitUntil(Date deadline) throws InterruptedException;  
    void signal();  
    void signalAll();  
以上是Condition接口定义的方法，await*对应于Object.wait，signal对应于Object.notify，signalAll对应于Object.notifyAll。特别说明的是Condition的接口改变名称就是为了避免与Object中的wait/notify/notifyAll的语义和使用上混淆，因为Condition同样有wait/notify/notifyAll方法。每一个Lock可以有任意数据的Condition对象，Condition是与Lock绑定的，所以就有Lock的公平性特性：如果是公平锁，线程为按照FIFO的顺序从Condition.await中释放，如果是非公平锁，那么后续的锁竞争就不保证FIFO顺序了。







二、ms相关
1、在java中守护线程和本地线程区别？
java中的线程分为两种：守护线程（Daemon）和用户线程（User）。
任何线程都可以设置为守护线程和用户线程，通过方法Thread.setDaemon(bool on)；true则把该线程设置为守护线程，反之则为用户线程。Thread.setDaemon()必须在Thread.start()之前调用，否则运行时会抛出异常。
两者的区别：
唯一的区别是判断虚拟机(JVM)何时离开，Daemon是为其他线程提供服务，如果全部的User Thread已经撤离，Daemon 没有可服务的线程，JVM撤离。也可以理解为守护线程是JVM自动创建的线程（但不一定），用户线程是程序创建的线程；比如JVM的垃圾回收线程是一个守护线程，当所有线程已经撤离，不再产生垃圾，守护线程自然就没事可干了，当垃圾回收线程是Java虚拟机上仅剩的线程时，Java虚拟机会自动离开。
扩展：Thread Dump打印出来的线程信息，含有daemon字样的线程即为守护进程，可能会有：服务守护进程、编译守护进程、windows下的监听Ctrl+break的守护进程、Finalizer守护进程、引用处理守护进程、GC守护进程。

2、线程与进程的区别？
进程是操作系统分配资源的最小单元，线程是操作系统调度的最小单元。
一个程序至少有一个进程,一个进程至少有一个线程。

3、什么是多线程中的上下文切换？
多线程会共同使用一组计算机上的CPU，而线程数大于给程序分配的CPU数量时，为了让各个线程都有执行的机会，就需要轮转使用CPU。不同的线程切换使用CPU发生的切换数据等就是上下文切换。

4、死锁与活锁的区别，死锁与饥饿的区别？
死锁：是指两个或两个以上的进程（或线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。
产生死锁的必要条件：
1） 互斥条件：所谓互斥就是进程在某一时间内独占资源。
2） 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
3） 不剥夺条件:进程已获得资源，在末使用完之前，不能强行剥夺。
4） 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。
活锁：任务或者执行者没有被阻塞，由于某些条件没有满足，导致一直重复尝试，失败，尝试，失败。
活锁和死锁的区别在于，处于活锁的实体是在不断的改变状态，所谓的“活”， 而处于死锁的实体表现为等待；活锁有可能自行解开，死锁则不能。
饥饿：一个或者多个线程因为种种原因无法获得所需要的资源，导致一直无法执行的状态。
Java中导致饥饿的原因：
- 高优先级线程吞噬所有的低优先级线程的CPU时间。
- 线程被永久堵塞在一个等待进入同步块的状态，因为其他线程总是能在它之前持续地对该同步块进行访问。
- 线程在等待一个本身也处于永久等待完成的对象(比如调用这个对象的wait方法)，因为其他线程总是被持续地获得唤醒。

5、Java中用到的线程调度算法是什么？
采用时间片轮转的方式。可以设置线程的优先级，会映射到下层的系统上面的优先级上，如非特别需要，尽量不要用，防止线程饥饿。

6、什么是线程组，为什么在Java中不推荐使用？
ThreadGroup类，可以把线程归属到某一个线程组中，线程组中可以有线程对象，也可以有线程组，组中还可以有线程，这样的组织结构有点类似于树的形式。
为什么不推荐使用？因为使用有很多的安全隐患吧，没有具体追究，如果需要使用，推荐使用线程池。

7、为什么使用Executor框架？
每次执行任务创建线程 new Thread()比较消耗性能，创建一个线程是比较耗时、耗资源的。
调用 new Thread()创建的线程缺乏管理，被称为野线程，而且可以无限制的创建，线程之间的相互竞争会导致过多占用系统资源而导致系统瘫痪，还有线程之间的频繁交替也会消耗很多系统资源。
接使用new Thread() 启动的线程不利于扩展，比如定时执行、定期执行、定时定期执行、线程中断等都不便实现。

8、在Java中Executor和Executors的区别？
Executors 工具类的不同方法按照我们的需求创建了不同的线程池，来满足业务的需求。
Executor 接口对象能执行我们的线程任务。
ExecutorService接口继承了Executor接口并进行了扩展，提供了更多的方法我们能获得任务执行的状态并且可以获取任务的返回值。
使用ThreadPoolExecutor 可以创建自定义线程池。
Future 表示异步计算的结果，他提供了检查计算是否完成的方法，以等待计算的完成，并可以使用get()方法获取计算的结果。

9、如何在Windows和Linux上查找哪个线程使用的CPU时间最长？
（1）获取项目的pid，jps或者ps -ef | grep java，这个前面有讲过
（2）top -H -p pid，顺序不能改变

10、什么是原子操作？在Java Concurrency API中有哪些原子类(atomic classes)？
原子操作（atomic operation）意为”不可被中断的一个或一系列操作” 。
处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。
在Java中可以通过锁和循环CAS的方式来实现原子操作。 CAS操作——Compare & Set，或是 Compare & Swap，现在几乎所有的CPU指令都支持CAS的原子操作。

原子操作是指一个不受其他操作影响的操作任务单元。原子操作是在多线程环境下避免数据不一致必须的手段。
int++并不是一个原子操作，所以当一个线程读取它的值并加1时，另外一个线程有可能会读到之前的值，这就会引发错误。
为了解决这个问题，必须保证增加操作是原子的，在JDK1）5之前我们可以使用同步技术来做到这一点。到JDK1）5，java.util.concurrent.atomic包提供了int和long类型的原子包装类，它们可以自动的保证对于他们的操作是原子的并且不需要使用同步。
java.util.concurrent这个包里面提供了一组原子类。其基本的特性就是在多线程环境下，当有多个线程同时执行这些类的实例包含的方法时，具有排他性，即当某个线程进入方法，执行其中的指令时，不会被其他线程打断，而别的线程就像自旋锁一样，一直等到该方法执行完成，才由JVM从等待队列中选择一个另一个线程进入，这只是一种逻辑上的理解。
原子类：AtomicBoolean，AtomicInteger，AtomicLong，AtomicReference
原子数组：AtomicIntegerArray，AtomicLongArray，AtomicReferenceArray
原子属性更新器：AtomicLongFieldUpdater，AtomicIntegerFieldUpdater，AtomicReferenceFieldUpdater
解决ABA问题的原子类：AtomicMarkableReference（通过引入一个boolean来反映中间有没有变过），AtomicStampedReference（通过引入一个int来累加来反映中间有没有变过）

11、Java Concurrency API中的Lock接口(Lock interface)是什么？对比同步它有什么优势？
Lock接口比同步方法和同步块提供了更具扩展性的锁操作。
他们允许更灵活的结构，可以具有完全不同的性质，并且可以支持多个相关类的条件对象。
它的优势有：
可以使锁更公平
可以使线程在等待锁的时候响应中断
可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间
可以在不同的范围，以不同的顺序获取和释放锁
整体上来说Lock是synchronized的扩展版，Lock提供了无条件的、可轮询的(tryLock方法)、定时的(tryLock带参方法)、可中断的(lockInterruptibly)、可多条件队列的(newCondition方法)锁操作。另外Lock的实现类基本都支持非公平锁(默认)和公平锁，synchronized只支持非公平锁，当然，在大部分情况下，非公平锁是高效的选择。

12、什么是Executors框架？
Executor框架是一个根据一组执行策略调用，调度，执行和控制的异步任务的框架。
无限制的创建线程会引起应用程序内存溢出。所以创建一个线程池是个更好的的解决方案，因为可以限制线程的数量并且可以回收再利用这些线程。利用Executors框架可以非常方便的创建一个线程池。

13、什么是阻塞队列？阻塞队列的实现原理是什么？如何使用阻塞队列来实现生产者-消费者模型？
阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。
这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。
阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。
JDK7提供了7个阻塞队列。分别是：
ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。
LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。
PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。
DelayQueue：一个使用优先级队列实现的无界阻塞队列。
SynchronousQueue：一个不存储元素的阻塞队列。
LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。
LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。
Java 5之前实现同步存取时，可以使用普通的一个集合，然后在使用线程的协作和线程同步可以实现生产者，消费者模式，主要的技术就是用好，wait ,notify,notifyAll,sychronized这些关键字。而在java 5之后，可以使用阻塞队列来实现，此方式大大简少了代码量，使得多线程编程更加容易，安全方面也有保障。
BlockingQueue接口是Queue的子接口，它的主要用途并不是作为容器，而是作为线程同步的的工具，因此他具有一个很明显的特性，当生产者线程试图向BlockingQueue放入元素时，如果队列已满，则线程被阻塞，当消费者线程试图从中取出一个元素时，如果队列为空，则该线程会被阻塞，正是因为它所具有这个特性，所以在程序中多个线程交替向BlockingQueue中放入元素，取出元素，它可以很好的控制线程之间的通信。
阻塞队列使用最经典的场景就是socket客户端数据的读取和解析，读取数据的线程不断将数据放入队列，然后解析线程不断从队列取数据解析。

14、什么是Callable和Future?
Callable接口类似于Runnable，从名字就可以看出来了，但是Runnable不会返回结果，并且无法抛出返回结果的异常，而Callable功能更强大一些，被线程执行后，可以返回值，这个返回值可以被Future拿到，也就是说，Future可以拿到异步执行任务的返回值。
可以认为是带有回调的Runnable。
Future接口表示异步任务，是还没有完成的任务给出的未来结果。所以说Callable用于产生结果，Future用于获取结果。

15、什么是FutureTask?使用ExecutorService启动任务。
在Java并发程序中FutureTask表示一个可以取消的异步运算。它有启动和取消运算、查询运算是否完成和取回运算结果等方法。只有当运算完成的时候结果才能取回，如果运算尚未完成get方法将会阻塞。一个FutureTask对象可以对调用了Callable和Runnable的对象进行包装，由于FutureTask也是调用了Runnable接口所以它可以提交给Executor来执行。

16、什么是并发容器的实现？
何为同步容器：可以简单地理解为通过synchronized来实现同步的容器，如果有多个线程调用同步容器的方法，它们将会串行执行。比如Vector，Hashtable，以及Collections.synchronizedSet，synchronizedList等方法返回的容器。
可以通过查看Vector，Hashtable等这些同步容器的实现代码，可以看到这些容器实现线程安全的方式就是将它们的状态封装起来，并在需要同步的方法上加上关键字synchronized。
并发容器使用了与同步容器完全不同的加锁策略来提供更高的并发性和伸缩性，例如在ConcurrentHashMap中采用了一种粒度更细的加锁机制，可以称为分段锁，在这种锁机制下，允许任意数量的读线程并发地访问map，并且执行读操作的线程和写操作的线程也可以并发的访问map，同时允许一定数量的写操作线程并发地修改map，所以它可以在并发环境下实现更高的吞吐量。

17、多线程同步和互斥有几种实现方法，都是什么？
线程同步是指线程之间所具有的一种制约关系，一个线程的执行依赖另一个线程的消息，当它没有得到另一个线程的消息时应等待，直到消息到达时才被唤醒。
线程互斥是指对于共享的进程系统资源，在各单个线程访问时的排它性。当有若干个线程都要使用某一共享资源时，任何时刻最多只允许一个线程去使用，其它要使用该资源的线程必须等待，直到占用资源者释放该资源。线程互斥可以看成是一种特殊的线程同步。
线程间的同步方法大体可分为两类：用户模式和内核模式。顾名思义，内核模式就是指利用系统内核对象的单一性来进行同步，使用时需要切换内核态与用户态，而用户模式就是不需要切换到内核态，只在用户态完成操作。
用户模式下的方法有：原子操作（例如一个单一的全局变量），临界区。内核模式下的方法有：事件，信号量，互斥量。

18、什么是竞争条件？你怎样发现和解决竞争？
当多个进程都企图对共享数据进行某种处理，而最后的结果又取决于进程运行的顺序时，则我们认为这发生了竞争条件（race condition）。

19、你将如何使用thread dump？你将如何分析Thread dump？
java线程的状态转换
新建状态（New）
用new语句创建的线程处于新建状态，此时它和其他Java对象一样，仅仅在堆区中被分配了内存。
就绪状态（Runnable）
当一个线程对象创建后，其他线程调用它的start()方法，该线程就进入就绪状态，Java虚拟机会为它创建方法调用栈和程序计数器。处于这个状态的线程位于可运行池中，等待获得CPU的使用权。
运行状态（Running）
处于这个状态的线程占用CPU，执行程序代码。只有处于就绪状态的线程才有机会转到运行状态。
阻塞状态（Blocked）
阻塞状态是指线程因为某些原因放弃CPU，暂时停止运行。当线程处于阻塞状态时，Java虚拟机不会给线程分配CPU。直到线程重新进入就绪状态，它才有机会转到运行状态。
阻塞状态可分为以下3种：
位于对象等待池中的阻塞状态（Blocked in object’s wait pool）：当线程处于运行状态时，如果执行了某个对象的wait()方法，Java虚拟机就会把线程放到这个对象的等待池中，这涉及到“线程通信”的内容。
位于对象锁池中的阻塞状态（Blocked in object’s lock pool）：当线程处于运行状态时，试图获得某个对象的同步锁时，如果该对象的同步锁已经被其他线程占用，Java虚拟机就会把这个线程放到这个对象的锁池中，这涉及到“线程同步”的内容。
其他阻塞状态（Otherwise Blocked）：当前线程执行了sleep()方法，或者调用了其他线程的join()方法，或者发出了I/O请求时，就会进入这个状态。
死亡状态（Dead）
当线程退出run()方法时，就进入死亡状态，该线程结束生命周期。
我们运行之前的那个死锁代码SimpleDeadLock.java，然后尝试输出信息(/*这是注释，作者自己加的*/)：

20、为什么我们调用start()方法时会执行run()方法，为什么我们不能直接调用run()方法？
当你调用start()方法时你将创建新的线程，并且执行在run()方法里的代码。
但是如果你直接调用run()方法，它不会创建新的线程也不会执行调用线程的代码，只会把run方法当作普通方法去执行。

21、Java中你怎样唤醒一个阻塞的线程？
在Java发展史上曾经使用suspend()、resume()方法对于线程进行阻塞唤醒，但随之出现很多问题，比较典型的还是死锁问题。
解决方案可以使用以对象为目标的阻塞，即利用Object类的wait()和notify()方法实现线程阻塞。
首先，wait、notify方法是针对对象的，调用任意对象的wait()方法都将导致线程阻塞，阻塞的同时也将释放该对象的锁，相应地，调用任意对象的notify()方法则将随机解除该对象阻塞的线程，但它需要重新获取改对象的锁，直到获取成功才能往下执行；其次，wait、notify方法必须在synchronized块或方法中被调用，并且要保证同步块或方法的锁对象与调用wait、notify方法的对象是同一个，如此一来在调用wait之前当前线程就已经成功获取某对象的锁，执行wait阻塞后当前线程就将之前获取的对象锁释放。

22、在Java中CycliBarriar和CountdownLatch有什么区别？
CyclicBarrier可以重复使用，而CountdownLatch不能重复使用。
Java的concurrent包里面的CountDownLatch其实可以把它看作一个计数器，只不过这个计数器的操作是原子操作，同时只能有一个线程去操作这个计数器，也就是同时只能有一个线程去减这个计数器里面的值。
你可以向CountDownLatch对象设置一个初始的数字作为计数值，任何调用这个对象上的await()方法都会阻塞，直到这个计数器的计数值被其他的线程减为0为止。
所以在当前计数到达零之前，await 方法会一直受阻塞。之后，会释放所有等待的线程，await的所有后续调用都将立即返回。这种现象只出现一次——计数无法被重置。如果需要重置计数，请考虑使用 CyclicBarrier。
CountDownLatch的一个非常典型的应用场景是：有一个任务想要往下执行，但必须要等到其他的任务执行完毕后才可以继续往下执行。假如我们这个想要继续往下执行的任务调用一个CountDownLatch对象的await()方法，其他的任务执行完自己的任务后调用同一个CountDownLatch对象上的countDown()方法，这个调用await()方法的任务将一直阻塞等待，直到这个CountDownLatch对象的计数值减到0为止。
CyclicBarrier一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。在涉及一组固定大小的线程的程序中，这些线程必须不时地互相等待，此时 CyclicBarrier 很有用。因为该 barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。

23、什么是不可变对象，它对写并发应用有什么帮助？
不可变对象(Immutable Objects)即对象一旦被创建它的状态（对象的数据，也即对象属性值）就不能改变，反之即为可变对象(Mutable Objects)。
不可变对象的类即为不可变类(Immutable Class)。Java平台类库中包含许多不可变类，如String、基本类型的包装类、BigInteger和BigDecimal等。
不可变对象天生是线程安全的。它们的常量（域）是在构造函数中创建的。既然它们的状态无法修改，这些常量永远不会变。
不可变对象永远是线程安全的。
只有满足如下状态，一个对象才是不可变的；
它的状态不能在创建后再被修改；
所有域都是final类型；并且，
它被正确创建（创建期间没有发生this引用的逸出）。

24、什么是多线程中的上下文切换？
在上下文切换过程中，CPU会停止处理当前运行的程序，并保存当前程序运行的具体位置以便之后继续运行。从这个角度来看，上下文切换有点像我们同时阅读几本书，在来回切换书本的同时我们需要记住每本书当前读到的页码。在程序中，上下文切换过程中的“页码”信息是保存在进程控制块（PCB）中的。PCB还经常被称作“切换桢”（switchframe）。“页码”信息会一直保存到CPU的内存中，直到他们被再次使用。
上下文切换是存储和恢复CPU状态的过程，它使得线程执行能够从中断点恢复执行。上下文切换是多任务操作系统和多线程环境的基本特征。

25、Java中用到的线程调度算法是什么？
计算机通常只有一个CPU,在任意时刻只能执行一条机器指令,每个线程只有获得CPU的使用权才能执行指令.所谓多线程的并发运行,其实是指从宏观上看,各个线程轮流获得CPU的使用权,分别执行各自的任务.在运行池中,会有多个处于就绪状态的线程在等待CPU,JAVA虚拟机的一项任务就是负责线程的调度,线程调度是指按照特定机制为多个线程分配CPU的使用权.
有两种调度模型：分时调度模型和抢占式调度模型。
分时调度模型是指让所有的线程轮流获得cpu的使用权,并且平均分配每个线程占用的CPU的时间片这个也比较好理解。
java虚拟机采用抢占式调度模型，是指优先让可运行池中优先级高的线程占用CPU，如果可运行池中的线程优先级相同，那么就随机选择一个线程，使其占用CPU。处于运行状态的线程会一直运行，直至它不得不放弃CPU。

26、什么是线程组，为什么在Java中不推荐使用？
线程组和线程池是两个不同的概念，他们的作用完全不同，前者是为了方便线程的管理，后者是为了管理线程的生命周期，复用线程，减少创建销毁线程的开销。

27、为什么使用Executor框架比使用应用创建和管理线程好？
为什么要使用Executor线程池框架
1）每次执行任务创建线程 new Thread()比较消耗性能，创建一个线程是比较耗时、耗资源的。
2）调用 new Thread()创建的线程缺乏管理，被称为野线程，而且可以无限制的创建，线程之间的相互竞争会导致过多占用系统资源而导致系统瘫痪，还有线程之间的频繁交替也会消耗很多系统资源。
3）直接使用new Thread() 启动的线程不利于扩展，比如定时执行、定期执行、定时定期执行、线程中断等都不便实现。
使用Executor线程池框架的优点
1）能复用已存在并空闲的线程从而减少线程对象的创建从而减少了消亡线程的开销。
2）可有效控制最大并发线程数，提高系统资源使用率，同时避免过多资源竞争。
3）框架中已经有定时、定期、单线程、并发数控制等功能。
综上所述使用线程池框架Executor能更好的管理线程、提供系统资源使用率。

28、java中有几种方法可以实现一个线程？
继承 Thread 类
实现 Runnable 接口
实现 Callable 接口，需要实现的是 call() 方法

29、如何停止一个正在运行的线程？
使用共享变量的方式
在这种方式中，之所以引入共享变量，是因为该变量可以被多个执行相同任务的线程用来作为是否中断的信号，通知中断线程的执行。
使用interrupt方法终止线程
如果一个线程由于等待某些事件的发生而被阻塞，又该怎样停止该线程呢？这种情况经常会发生，比如当一个线程由于需要等候键盘输入而被阻塞，或者调用Thread.join()方法，或者Thread.sleep()方法，在网络中调用ServerSocket.accept()方法，或者调用了DatagramSocket.receive()方法时，都有可能导致线程阻塞，使线程处于处于不可运行状态时，即使主程序中将该线程的共享变量设置为true，但该线程此时根本无法检查循环标志，当然也就无法立即中断。这里我们给出的建议是，不要使用stop()方法，而是使用Thread提供的interrupt()方法，因为该方法虽然不会中断一个正在运行的线程，但是它可以使一个被阻塞的线程抛出一个中断异常，从而使线程提前结束阻塞状态，退出堵塞代码。

30、notify()和notifyAll()有什么区别？
当一个线程进入wait之后，就必须等其他线程notify/notifyall,使用notifyall,可以唤醒所有处于wait状态的线程，使其重新进入锁的争夺队列中，而notify只能唤醒一个。
如果没把握，建议notifyAll，防止notigy因为信号丢失而造成程序异常。

31、什么是Daemon线程？它有什么意义？
所谓后台(daemon)线程，是指在程序运行的时候在后台提供一种通用服务的线程，并且这个线程并不属于程序中不可或缺的部分。因此，当所有的非后台线程结束时，程序也就终止了，同时会杀死进程中的所有后台线程。反过来说，
只要有任何非后台线程还在运行，程序就不会终止。必须在线程启动之前调用setDaemon()方法，才能把它设置为后台线程。注意：后台进程在不执行finally子句的情况下就会终止其run()方法。
比如：JVM的垃圾回收线程就是Daemon线程，Finalizer也是守护线程。

32、java如何实现多线程之间的通讯和协作？
中断 和 共享变量

33、什么是可重入锁（ReentrantLock）？
举例来说明锁的可重入性
public class UnReentrant{
    Lock lock = new Lock();
    public void outer(){
        lock.lock();
        inner();
        lock.unlock();
    }
    public void inner(){
        lock.lock();
        //do something
        lock.unlock();
    }
}
outer中调用了inner，outer先锁住了lock，这样inner就不能再获取lock。其实调用outer的线程已经获取了lock锁，但是不能在inner中重复利用已经获取的锁资源，这种锁即称之为 不可重入可重入就意味着：线程可以进入任何一个它已经拥有的锁所同步着的代码块。
synchronized、ReentrantLock都是可重入的锁，可重入锁相对来说简化了并发编程的开发。

34、当一个线程进入某个对象的一个synchronized的实例方法后，其它线程是否可进入此对象的其它方法？
如果其他方法没有synchronized的话，其他线程是可以进入的。
所以要开放一个线程安全的对象时，得保证每个方法都是线程安全的。

35、乐观锁和悲观锁的理解及如何实现，有哪些实现方式？
悲观锁：总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。再比如Java里面的同步原语synchronized关键字的实现也是悲观锁。
乐观锁：顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。
乐观锁的实现方式：
1）使用版本标识来确定读到的数据与提交时的数据是否一致。提交后修改版本标识，不一致时可以采取丢弃和再次尝试的策略。
2）java中的Compare and Swap即CAS ，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。　CAS 操作中包含三个操作数 —— 需要读写的内存位置（V）、进行比较的预期原值（A）和拟写入的新值(B)。如果内存位置V的值与预期原值A相匹配，那么处理器会自动将该位置值更新为新值B。否则处理器不做任何操作。
CAS缺点：
1） ABA问题：
比如说一个线程one从内存位置V中取出A，这时候另一个线程two也从内存中取出A，并且two进行了一些操作变成了B，然后two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后one操作成功。尽管线程one的CAS操作成功，但可能存在潜藏的问题。从Java1）5开始JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。
2）循环时间长开销大：
对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。
3）只能保证一个共享变量的原子操作：
当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。

36、SynchronizedMap和ConcurrentHashMap有什么区别？
SynchronizedMap一次锁住整张表来保证线程安全，所以每次只能有一个线程来访为map。
ConcurrentHashMap使用分段锁来保证在多线程下的性能。ConcurrentHashMap中则是一次锁住一个桶。ConcurrentHashMap默认将hash表分为16个桶，诸如get,put,remove等常用操作只锁当前需要用到的桶。这样，原来只能一个线程进入，现在却能同时有16个写线程执行，并发性能的提升是显而易见的。
另外ConcurrentHashMap使用了一种不同的迭代方式。在这种迭代方式中，当iterator被创建后集合再发生改变就不再是抛出ConcurrentModificationException，取而代之的是在改变时new新的数据从而不影响原有的数据 ，iterator完成后再将头指针替换为新的数据 ，这样iterator线程可以使用原来老的数据，而写线程也可以并发的完成改变。

37、CopyOnWriteArrayList可以用于什么应用场景？
CopyOnWriteArrayList(免锁容器)的好处之一是当多个迭代器同时遍历和修改这个列表时，不会抛出ConcurrentModificationException。在CopyOnWriteArrayList中，写入将导致创建整个底层数组的副本，而源数组将保留在原地，使得复制的数组在被修改时，读取操作可以安全地执行。
1）由于写操作的时候，需要拷贝数组，会消耗内存，如果原数组的内容比较多的情况下，可能导致young gc或者full gc；
2）不能用于实时读的场景，像拷贝数组、新增元素都需要时间，所以调用一个set操作后，读取到数据可能还是旧的,虽然CopyOnWriteArrayList 能做到最终一致性,但是还是没法满足实时性要求；
CopyOnWriteArrayList透露的思想
1）读写分离，读和写分开
2）最终一致性
3）使用另外开辟空间的思路，来解决并发冲突

38、什么叫线程安全？servlet是线程安全吗?
线程安全是编程中的术语，指某个函数、函数库在多线程环境中被调用时，能够正确地处理多个线程之间的共享变量，使程序功能正确完成。
Servlet不是线程安全的，servlet是单实例多线程的，当多个线程同时访问同一个方法，是不能保证共享变量的线程安全性的。
Struts2的action是多实例多线程的，是线程安全的，每个请求过来都会new一个新的action分配给这个请求，请求完成后销毁。
SpringMVC的Controller是线程安全的吗？不是的，和Servlet类似的处理流程。
Struts2好处是不用考虑线程安全问题；Servlet和SpringMVC需要考虑线程安全问题，但是性能可以提升不用处理太多的gc，可以使用ThreadLocal来处理多线程的问题。

39、volatile有什么用？能否用一句话说明下volatile的应用场景？
volatile保证内存可见性和禁止指令重排。
volatile用于多线程环境下的单次操作(单次读或者单次写)。

40、为什么代码会重排序？
在执行程序时，为了提供性能，处理器和编译器常常会对指令进行重排序，但是不能随意重排序，不是你想怎么排序就怎么排序，它需要满足以下两个条件：
在单线程环境下不能改变程序运行的结果；
存在数据依赖关系的不允许重排序
需要注意的是：重排序不会影响单线程环境的执行结果，但是会破坏多线程的执行语义。

41、在java中wait和sleep方法的不同？
最大的不同是在等待时wait会释放锁，而sleep一直持有锁。Wait通常被用于线程间交互，sleep通常被用于暂停执行。
wait()方法会释放CPU执行权 和 占有的锁。
sleep(long)方法仅释放CPU使用权，锁仍然占用；线程被放入超时等待队列，与yield相比，它会使线程较长时间得不到运行。
yield()方法仅释放CPU执行权，锁仍然占用，线程会被放入就绪队列，会在短时间内再次执行。
wait和notify必须配套使用，即必须使用同一把锁调用；
wait和notify必须放在一个同步块中调用wait和notify的对象必须是他们所处同步块的锁对象。

42、用Java实现阻塞队列
实现一个阻塞队列，阻塞过程使用ReentrantLock锁和Condition来控制。
循环队列是如何实现的，以及实现的原理

43、一个线程运行时发生异常会怎样？
如果异常没有被捕获该线程将会停止执行。Thread.UncaughtExceptionHandler是用于处理未捕获异常造成线程突然中断情况的一个内嵌接口。当一个未捕获异常将造成线程中断的时候JVM会使用Thread.getUncaughtExceptionHandler()来查询线程的UncaughtExceptionHandler并将线程和异常作为参数传递给handler的uncaughtException()方法进行处理。

44、如何在两个线程间共享数据？
在两个线程间共享变量即可实现共享。
一般来说，共享变量要求变量本身是线程安全的，然后在线程内使用的时候，如果有对共享变量的复合操作，那么也得保证复合操作的线程安全性。

45、Java中notify 和 notifyAll有什么区别？
notify() 方法不能唤醒某个具体的线程，所以只有一个线程在等待的时候它才有用武之地。而notifyAll()唤醒所有线程并允许他们争夺锁确保了至少有一个线程能继续运行。

46、为什么wait, notify 和 notifyAll这些方法不在thread类里面？
一个很明显的原因是JAVA提供的锁是对象级的而不是线程级的，每个对象都有锁，通过线程获得。由于wait，notify和notifyAll都是锁级别的操作，所以把他们定义在Object类中因为锁属于对象。

47、什么是ThreadLocal变量？
ThreadLocal是Java里一种特殊的变量。每个线程都有一个ThreadLocal就是每个线程都拥有了自己独立的一个变量，竞争条件被彻底消除了。它是为创建代价高昂的对象获取线程安全的好方法，比如你可以用ThreadLocal让SimpleDateFormat变成线程安全的，因为那个类创建代价高昂且每次调用都需要创建不同的实例所以不值得在局部范围使用它，如果为每个线程提供一个自己独有的变量拷贝，将大大提高效率。首先，通过复用减少了代价高昂的对象的创建个数。其次，你在没有使用高代价的同步或者不变性的情况下获得了线程安全。

48、Java中interrupted 和 isInterrupted方法的区别？
interrupt
interrupt方法用于中断线程。调用该方法的线程的状态为将被置为”中断”状态。
注意：线程中断仅仅是置线程的中断状态位，不会停止线程。需要用户自己去监视线程的状态为并做处理。支持线程中断的方法（也就是线程中断后会抛出interruptedException的方法）就是在监视线程的中断状态，一旦线程的中断状态被置为“中断状态”，就会抛出中断异常。
interrupted
查询当前线程的中断状态，并且清除原状态。如果一个线程被中断了，第一次调用interrupted则返回true，第二次和后面的就返回false了。
isInterrupted
仅仅是查询当前线程的中断状态

49、为什么wait和notify方法要在同步块中调用？
Java API强制要求这样做，如果你不这么做，你的代码会抛出IllegalMonitorStateException异常。还有一个原因是为了避免wait和notify之间产生竞态条件。

50、为什么你应该在循环中检查等待条件?
处于等待状态的线程可能会收到错误警报和伪唤醒，如果不在循环中检查等待条件，程序就会在没有满足结束条件的情况下退出。

51、Java中的同步集合与并发集合有什么区别？
同步集合与并发集合都为多线程和并发提供了合适的线程安全的集合，不过并发集合的可扩展性更高。在Java1）5之前程序员们只有同步集合来用且在多线程并发的时候会导致争用，阻碍了系统的扩展性。Java5介绍了并发集合像ConcurrentHashMap，不仅提供线程安全还用锁分离和内部分区等现代技术提高了可扩展性。

52、什么是线程池？ 为什么要使用它？
创建线程要花费昂贵的资源和时间，如果任务来了才创建线程那么响应时间会变长，而且一个进程能创建的线程数有限。为了避免这些问题，在程序启动的时候就创建若干线程来响应处理，它们被称为线程池，里面的线程叫工作线程。从JDK1）5开始，Java API提供了Executor框架让你可以创建不同的线程池。

53、怎么检测一个线程是否拥有锁？
在java.lang.Thread中有一个方法叫holdsLock()，它返回true如果当且仅当当前线程拥有某个具体对象的锁。

54、你如何在Java中获取线程堆栈？
kill -3 [java pid]
不会在当前终端输出，它会输出到代码执行的或指定的地方去。比如，kill -3 tomcat pid, 输出堆栈到log目录下。
Jstack [java pid]
这个比较简单，在当前终端显示，也可以重定向到指定文件中。
-JvisualVM：Thread Dump
不做说明，打开JvisualVM后，都是界面操作，过程还是很简单的。

55、JVM中哪个参数是用来控制线程的栈堆栈小的?
-Xss 每个线程的栈大小

56、Thread类中的yield方法有什么作用？
使当前线程从执行状态（运行状态）变为可执行态（就绪状态）。
当前线程到了就绪状态，那么接下来哪个线程会从就绪状态变成执行状态呢？可能是当前线程，也可能是其他线程，看系统的分配了。

57、Java中ConcurrentHashMap的并发度是什么？
ConcurrentHashMap把实际map划分成若干部分来实现它的可扩展性和线程安全。这种划分是使用并发度获得的，它是ConcurrentHashMap类构造函数的一个可选参数，默认值为16，这样在多线程情况下就能避免争用。
在JDK8后，它摒弃了Segment（锁段）的概念，而是启用了一种全新的方式实现,利用CAS算法。同时加入了更多的辅助变量来提高并发度，具体内容还是查看源码吧。

58、Java中Semaphore是什么？
Java中的Semaphore是一种新的同步类，它是一个计数信号。从概念上讲，从概念上讲，信号量维护了一个许可集合。如有必要，在许可可用前会阻塞每一个 acquire()，然后再获取该许可。每个 release()添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore只对可用许可的号码进行计数，并采取相应的行动。信号量常常用于多线程的代码中，比如数据库连接池。

59、Java线程池中submit() 和 execute()方法有什么区别？
两个方法都可以向线程池提交任务，execute()方法的返回类型是void，它定义在Executor接口中。
而submit()方法可以返回持有计算结果的Future对象，它定义在ExecutorService接口中，它扩展了Executor接口，其它线程池类像ThreadPoolExecutor和ScheduledThreadPoolExecutor都有这些方法。

60、什么是阻塞式方法？
阻塞式方法是指程序会一直等待该方法完成期间不做其他事情，ServerSocket的accept()方法就是一直等待客户端连接。这里的阻塞是指调用结果返回之前，当前线程会被挂起，直到得到结果之后才会返回。此外，还有异步和非阻塞式方法在任务完成前就返回。

61、Java中的ReadWriteLock是什么？
读写锁是用来提升并发程序性能的锁分离技术的成果。

62、volatile 变量和 atomic 变量有什么不同？
Volatile变量可以确保先行关系，即写操作会发生在后续的读操作之前, 但它并不能保证原子性。例如用volatile修饰count变量那么 count++ 操作就不是原子性的。
而AtomicInteger类提供的atomic方法可以让这种操作具有原子性如getAndIncrement()方法会原子性的进行增量操作把当前值加一，其它数据类型和引用变量也可以进行相似操作。

63、可以直接调用Thread类的run ()方法么？
当然可以。但是如果我们调用了Thread的run()方法，它的行为就会和普通的方法一样，会在当前线程中执行。为了在新的线程中执行我们的代码，必须使用Thread.start()方法。

64、如何让正在运行的线程暂停一段时间？
我们可以使用Thread类的Sleep()方法让线程暂停一段时间。需要注意的是，这并不会让线程终止，一旦从休眠中唤醒线程，线程的状态将会被改变为Runnable，并且根据线程调度，它将得到执行。

65、你对线程优先级的理解是什么？
每一个线程都是有优先级的，一般来说，高优先级的线程在运行时会具有优先权，但这依赖于线程调度的实现，这个实现是和操作系统相关的(OS dependent)。我们可以定义线程的优先级，但是这并不能保证高优先级的线程会在低优先级的线程前执行。线程优先级是一个int变量(从1-10)，1代表最低优先级，10代表最高优先级。
java的线程优先级调度会委托给操作系统去处理，所以与具体的操作系统优先级有关，如非特别需要，一般无需设置线程优先级。

66、什么是线程调度器(Thread Scheduler)和时间分片(Time Slicing )？
线程调度器是一个操作系统服务，它负责为Runnable状态的线程分配CPU时间。一旦我们创建一个线程并启动它，它的执行便依赖于线程调度器的实现。
同上一个问题，线程调度并不受到Java虚拟机控制，所以由应用程序来控制它是更好的选择（也就是说不要让你的程序依赖于线程的优先级）。
时间分片是指将可用的CPU时间分配给可用的Runnable线程的过程。分配CPU时间可以基于线程优先级或者线程等待的时间。

67、你如何确保main()方法所在的线程是Java 程序最后结束的线程？
我们可以使用Thread类的join()方法来确保所有程序创建的线程在main()方法退出前结束。

68、线程之间是如何通信的？
当线程间是可以共享资源时，线程间通信是协调它们的重要的手段。Object类中wait()\notify()\notifyAll()方法可以用于线程间通信关于资源的锁的状态。

69、为什么线程通信的方法wait(), notify()和notifyAll()被定义在Object 类里？
Java的每个对象中都有一个锁(monitor，也可以成为监视器) 并且wait()，notify()等方法用于等待对象的锁或者通知其他线程对象的监视器可用。在Java的线程中并没有可供任何对象使用的锁和同步器。这就是为什么这些方法是Object类的一部分，这样Java的每一个类都有用于线程间通信的基本方法。

70、为什么wait(), notify()和notifyAll ()必须在同步方法或者同步块中被调用？
当一个线程需要调用对象的wait()方法的时候，这个线程必须拥有该对象的锁，接着它就会释放这个对象锁并进入等待状态直到其他线程调用这个对象上的notify()方法。同样的，当一个线程需要调用对象的notify()方法时，它会释放这个对象的锁，以便其他在等待的线程就可以得到这个对象锁。由于所有的这些方法都需要线程持有对象的锁，这样就只能通过同步来实现，所以他们只能在同步方法或者同步块中被调用。

71、为什么Thread类的sleep()和yield ()方法是静态的？
Thread类的sleep()和yield()方法将在当前正在执行的线程上运行。所以在其他处于等待状态的线程上调用这些方法是没有意义的。这就是为什么这些方法是静态的。它们可以在当前正在执行的线程中工作，并避免程序员错误的认为可以在其他非运行线程调用这些方法。

72、如何确保线程安全？
在Java中可以有很多方法来保证线程安全——同步，使用原子类(atomic concurrent classes)，实现并发锁，使用volatile关键字，使用不变类和线程安全类。

73、同步方法和同步块，哪个是更好的选择？
同步块是更好的选择，因为它不会锁住整个对象（当然你也可以让它锁住整个对象）。同步方法会锁住整个对象，哪怕这个类中有多个不相关联的同步块，这通常会导致他们停止执行并需要等待获得这个对象上的锁。
同步块更要符合开放调用的原则，只在需要锁住的代码块锁住相应的对象，这样从侧面来说也可以避免死锁。

74、如何创建守护线程？
使用Thread类的setDaemon(true)方法可以将线程设置为守护线程，需要注意的是，需要在调用start()方法前调用这个方法，否则会抛出IllegalThreadStateException异常。

75、什么是Java Timer 类？如何创建一个有特定时间间隔的任务？
java.util.Timer是一个工具类，可以用于安排一个线程在未来的某个特定时间执行。Timer类可以用安排一次性任务或者周期任务。
java.util.TimerTask是一个实现了Runnable接口的抽象类，我们需要去继承这个类来创建我们自己的定时任务并使用Timer去安排它的执行。
目前有开源的Qurtz可以用来创建定时任务。
---------------------------------------------------------------------------------------------------------------
------------------------------------------concurrent basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------db basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 外模式、模式、内模式
（1）模式：是数据库中全体数据的中间层，描述了数据的逻辑结构和特征，是所有用户的公共数据视图。DDL语言可用来描述模式中的逻辑，针对一个DB，只存在一个模式。
（2）外模式：是指数据库对外界的应用程序、外界用户呈现出来的一种视图，它并不代表真正的逻辑结构，仅仅是一种映像。如果应用程序不同、用户不同，则外模式就不同。
（3）内模式：又称存储模式，一个数据库只有一个存储模式。由于DBMS管理员在建立数据库模式的时候，并不关心底层细节，只关心逻辑通顺与否，所以这里需要构建一个内模式用来将逻辑模式和物理存储方式对应起来。当然，内模式也不仅仅是逻辑和存储的对应，还包括索引、压缩、加密等等。这里就有数据结构里提到的数据库的索引方法，B+树，用来加速数据库查询速度，当然也有hash索引，这种速度更快，但是对内存的消耗还是很大的。

2 关系数据库
（1）主键： 能够唯一地标识一个元组的属性或属性组称为关系的键或候选键。 若一个关系有多个候选键则可选其一作为主键(Primary key)。
（2）外键：如果一个关系的一个或一组属性引用(参照)了另一个关系的主键，则称这个或这组属性为外码或外键(Foreign key)。
（3）关系数据库： 依照关系模型建立的数据库称为关系数据库。 它是在某个应用领域的所有关系的集合。
（4）关系模式： 简单地说，关系模式就是对关系的型的定义， 包括关系的属性构成、各属性的数据类型、 属性间的依赖、 元组语义及完整性约束等。 关系是关系模式在某一时刻的状态或内容， 关系模型是型， 关系是值， 关系模型是静态的、 稳定的， 而关系是动态的、随时间不断变化的，因为关系操作在不断地更新着数据库中的数据。
（5）实体完整性：用于标识实体的唯一性。它要求基本关系必须要有一个能够标识元组唯一性的主键，主键不能为空，也不可取重复值。
（6）参照完整性： 用于维护实体之间的引用关系。 它要求一个关系的外键要么为空， 要么取与被参照关系对应的主键值，即外键值必须是主键中已存在的值。
（7）用户定义的完整性：就是针对某一具体应用的数据必须满足的语义约束。包括非空、 唯一和布尔条件约束三种情况。

3 数据库的安全性
1）在进入数据库时有用户名和密码登录，这个是用户身份鉴定
2） 定义用户权限，其中一种是满足计算机安全性等级C2的自助存取控制DAC：它是指不同的用户对数据库中的对象有不同的权限，且同一用户对不同的数据库对象有不同的权限，权限分为查看、更改和删除等等。另一种满足更高的安全等级B1，即对整个数据库中的对象都进行密级划分，只有满足一定级别权限的用户才能访问这些对象，否则不可以。用户权限的定义里最典型的就是应用程序可以访问的视图，以及DBMS管理员可以访问的模式。也就是说，外界用户只能查看外模式，只有管理员才可以访问修改逻辑模式。在SQL语言中，集成了DCL，所以安排了GRANT和REVOKE两个动词语句来实现对数据库对象的授权和撤回。
3） 审计，这是一种监测手段，类似于摄像头，DBMS提供监视操作，将所有的用户和应用程序对数据库的修改、查看等信息全部记录在审计log中，这样就可以对审计日志进行分析，找出哪些非法用户在何时操作了哪些数据。SQL里提供了AUDIT动词法语。
4）再有一个方法就是数据加密，加密技术应用广泛，尤其是在通信中，使用了对称非对称的加密算法，一般对于机密性非常高的数据，以及要在网路上传输的数据才会使用加密技术，因为加密的代价比较大，时间和空间的压力都比较大。
	
4 查询优化
（1） 查询处理是数据库的核心操作，主要分为查询分析、查询检查、查询优化、查询执行几个阶段。
（2） 查询分析：对语句进行词法、语法分析
（3） 查询检查：是指对语句中的数据对象进行检查，比如说要查询的表存在与否，属性是否存在，查询条件是否符合要求。检查通过后，就把SQL语句转换为等价的关系代数表达式
	（一般都是查询树、语法分析树），DBMS会处理这个关系代数表达式。
（4） 查询优化：即代数优化（优化关系代数表达式，即等价变换）和物理优化（基于存取路径的优化）。
（5） 在数据库优化中，主要是指选择SELECT的优化 和连接优化
（6）数据库选择SELECT方法主要有以下几种：
1）全表扫描查询：耗时，简单粗暴。当然如果数量比较小还是比较有效的。
2）索引、散列查询：建立在B+数和哈希表基础上，时间复杂度大大降低，数据量越大越有效。但是索引并不是一定就能够优化，在数据量比较小的时候，构建一颗索引树的时间和空间代价也是比较大的，尤其是当数据库更新频繁的时候，索引树需要经过旋转、增添删改等平衡化操作，而且如果树保存在外存上，读取外存的时间和空间都是很大的开销，散列更是如此。所以，在数据量超级庞大的情况下，再考虑建树，当然了，这些问题DBMS都已经做过优化了。
3） 嵌套循环：简单粗暴耗时。
4）排序-合并方法：依然是采用有序的表来进行表的连接，效率也是大大增加。

5 数据库故障恢复
1） 系统故障（DBMS运行的OS出现故障）、物理故障（磁盘掉磁）、病毒木马（恶意篡改数据）是非事务故障，也就是说，单个DBMS自己无法解决的，DBMS可以克服的、机制最复杂的就是事务故障。
2） 故障解决办法
1）数据转储：即备份。静态转储即转储其间不允许别的事务插手进来，比如网站团队半夜维护网站；而动态转储允许转储过程中事务进来操作，此时就需要建立事务日志log，记录到底哪些数据动过了。另外，如果数据量太大，还需要增量转储，也就是只转储改变的那一部分。转储技术不仅仅是克服故障的好办法，同样也是实现分布式的手段，分布式不仅仅可以克服故障，还能在存取效率上有很大的提升。现在已经可以实现DBMS自动把刚刚接收到的数据修改记录立即传送到数据转储的镜像上的功能，即数据库镜像。
2）登记日志文件：这是数据库故障恢复的核心，比如说磁盘掉磁了，登记日志文件都没了，那就没什么好说的了，损失已经形成，时光不能倒流。具有检查点的恢复技术其根本也是登记日志文件，只不过需要在检查点附近讨论到底哪些事务需要恢复，哪些事务不需要。

6 事务并发
1） 数据库中建立了封锁技术，和OS中的线程锁类似，确保事务的一致性。
2）排他锁：写锁，在增删数据库数据的时候不允许其它事务进来。
3） 共享锁：读锁，如果一个事务在读取数据，那么其它事务也可以进来读数据，但是不能写数据。
4） 尽管有了锁技术，但是还是会出现各种各样的错误和问题，比如活锁，解决活锁的方法是设置排队队列。而死锁则可以采用预防、诊断、检测等方法来处理，和OS处理死锁的方法一样。
同样地，加锁技术还会出现惊群现象，这个也是靠排队队列来解决。
5） 在处理并发的过程中，为确保事务的一致性和隔离性，还需要采用可串行化调度保证数据的正确性。基于此需求，诞生了两段锁协议：
在事务读写之前，首先要申请锁；在事务处理完成释放封锁之后，不允许再申请锁。这是一个很强的条件，充分条件。
6） 为了提高事务处理效率，需要进行多粒度封锁，其含义就是把所有的数据库的对象分为不同的粒度，库级别最高，模式次之，表再次之，最后是一个个的元组。
如果一个事务想要申请锁，那么就需要从多粒度树的头结点开始询问，数据库有没有被加锁？表有没有被加锁？如果都没有被加锁，则可以对自己想要操作的数据加锁。
意向锁则是对多粒度加锁协议的一种改进，避免访问过多的对象，提高加锁效率。
7） 上述技术DBMS都已经广泛实现，也就是说，我们如果非必须只需要使用，而不需要知道其内涵到底是什么。
8） 现阶段DBMS对应用程序的并行支持最高效的形式就是构建DBMS进程池，这样可以提高应用程序和DBMS之间的协调性。








二、ms相关
1口述oracle和mysql分页的写法？
SELECT * FROM 
(
SELECT A.*, ROWNUM RN 
FROM (SELECT * FROM TABLE_NAME) A 
WHERE ROWNUM <= 40
)
WHERE RN >= 21
Limit后的两个参数中，参数m是起始下标，它从0开始；参数n是返回的记录数。我们需要分页的话指定这两个值即可

2 SQL优化的思路？
1）.对查询进行优化，要尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。
2）.应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如：
    select id from t where num is null  
最好不要给数据库留NULL，尽可能的使用 NOT NULL填充数据库.
3）.应尽量避免在 where 子句中使用 != 或 <> 操作符，否则将引擎放弃使用索引而进行全表扫描。
4）.应尽量避免在 where 子句中使用 or 来连接条件，如果一个字段有索引，一个字段没有索引，将导致引擎放弃使用索引而进行全表扫描，如：
    select id from t where num=10 or Name = 'admin'  
可以这样查询： select id from t where num = 10 union allselect id from t where Name = 'admin'  
5）.in和 not in 也要慎用，否则会导致全表扫描，如：
6）.下面的查询也将导致全表扫描：
select id from t where name like ‘%abc%’  
若要提高效率，可以考虑全文检索。
7）.如果在 where 子句中使用参数，也会导致全表扫描。因为SQL只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然 而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描：
select id from t where num = @num  
可以改为强制查询使用索引： select id from t with(index(索引名)) where num = @num  
8）.应尽量避免在 where子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如：
    select id from t where num/2 = 100  
应改为:
    select id from t wherenum = 100*2  
9）.应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如：
    select id from t where substring(name,1,3) = ’abc’       -–name以abc开头的id  
    select id from t where datediff(day,createdate,’2005-11-30′) = 0    -–‘2005-11-30’    --生成的id  
应改为:
    select id from t where name like 'abc%'  
    select id from t where createdate >= '2005-11-30' and createdate < '2005-12-1'  
10）.不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。
11）.在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。
12）.不要写一些没有意义的查询，如需要生成一个空表结构：
    select col1,col2 into #t from t where 1=0  
13）.Update 语句，如果只更改1、2个字段，不要Update全部字段，否则频繁调用会引起明显的性能消耗，同时带来大量日志。
14）.对于多张大数据量（这里几百条就算大了）的表JOIN，要先分页再JOIN，否则逻辑读会很高，性能很差。
15）.select count(*) from table；这样不带任何条件的count会引起全表扫描，并且没有任何业务意义，是一定要杜绝的。
16）.索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有 必要。
17）.应尽可能的避免更新 clustered 索引数据列，因为 clustered 索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新 clustered 索引数据列，那么需要考虑是否应将该索引建为 clustered 索引。
18）.尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连 接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。
19）.尽可能的使用 varchar/nvarchar代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。
20）.任何地方都不要使用 select * from t ，用具体的字段列表代替“*”，不要返回用不到的任何字段。
21）.尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。
22）. 避免频繁创建和删除临时表，以减少系统表资源的消耗。临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件， 最好使用导出表。
23）.在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert。
24）.如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。
25）.尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。
26）.使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。
27）.与临时表一样，游标并不是不可使用。对小型数据集使用 FAST_FORWARD 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时 间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。
28）.在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON ，在结束时设置 SET NOCOUNT OFF 。无需在执行存储过程和触发器的每个语句后向客户端发送 DONE_IN_PROC 消息。
29）.尽量避免大事务操作，提高系统并发能力。
30）.尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。


3 sql函数decode和case when用法什么区别？ 
　１，DECODE  Oracle 特有;
　２，CASE WHEN  Oracle ,  SQL Server,  MySQL 都可用;
　３，DECODE 只能用做相等判断,但是可以配合sign函数进行大于，小于，等于的判断,CASE 　可用于=,>=,<,<=,<>,is null,is not null 等的判断;
  ４，DECODE 使用其来比较简洁，CASE 虽然复杂但更为灵活;


4索引什么优缺点？
（1）创建索引可以大大提高系统的性能:
第一，通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。 
第二，可以大大加快数据的检索速度，这也是创建索引的最主要的原因。 
第三，可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。 
第四，在使用分组和排序 子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。 
第五，通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。 

（2）增加索引也有许多不利的方面:
第一，创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。 
第二，索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。 
第三，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。


5建立索引规则，什么情况应该建立，什么情况不应该？
数据库建立索引常用的规则如下： 
1、表的主键、外键必须有索引； 
2、数据量超过300的表应该有索引； 
3、经常与其他表进行连接的表，在连接字段上应该建立索引； 
4、经常出现在Where子句中的字段，特别是大表的字段，应该建立索引； 
5、索引应该建在选择性高的字段上； 
6、索引应该建在小字段上，对于大的文本字段甚至超长字段，不要建索引； 
7、复合索引的建立需要进行仔细分析；尽量考虑用单字段索引代替： 
  A、正确选择复合索引中的主列字段，一般是选择性较好的字段； 
  B、复合索引的几个字段是否经常同时以AND方式出现在Where子句中？单字段查询是否 极少甚至没有？如果是，则可以建立复合索引；否则考虑单字段索引； 
  C、如果复合索引中包含的字段经常单独出现在Where子句中，则分解为多个单字段索引； 
  D、如果复合索引所包含的字段超过3个，那么仔细考虑其必要性，考虑减少复合的字段； 
  E、如果既有单字段索引，又有这几个字段上的复合索引，一般可以删除复合索引； 
8、频繁进行数据操作的表，不要建立太多的索引； 
9、删除无用的索引，避免对执行计划造成负面影响； 
10、BLOB，CLOB字段肯定也不适合建索引。
11、索引不会包含有NULL值的列
12、般情况下不鼓励使用like操作，如果非使用不可，如何使用也是一个问题。like “a%” 不会使用索引而like “aaa%”可以使用索引。


6 redis备份机制有哪2种？有什么区别？
RDB是在某个时间点将数据写入一个临时文件，持久化结束后，用这个临时文件替换上次持久化的文件，达到数据恢复。
优点：使用单独子进程来进行持久化，主进程不会进行任何IO操作，保证了redis的高性能
缺点：RDB是间隔一段时间进行持久化，如果持久化间redis发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候
这里说的这个执行数据写入到临时文件的时间点是可以通过配置来自己确定的，通过配置redis在n秒内如果超过m个key被修改这执行一次RDB操作。
这个操作就类似于在这个时间点来保存一次Redis的所有数据，一次快照数据。所有这个持久化方法也通常叫做snapshots。

Append-only file，将“操作 + 数据”以格式化指令的方式追加到操作日志文件的尾部，在append操作返回后(已经写入到文件或者即将写入)，才进行实际的数据变更，
“日志文件”保存了历史所有的操作过程；当server需要数据恢复时，可以直接replay此日志文件，即可还原所有的操作过程。AOF相对可靠，它和mysql中bin.log、
apache.log、zookeeper中txn-log简直异曲同工。AOF文件内容是字符串，非常容易阅读和解析。
优点：可以保持更高的数据完整性，如果设置追加file的时间是1s，如果redis发生故障，最多会丢失1s的数据；且如果日志写入不完整支持redis-check-aof来进行日志
修复；AOF文件没被rewrite之前（文件过大时会对命令进行合并重写），可以删除其中的某些命令（比如误操作的flushall）。
缺点：AOF文件比RDB文件大，且恢复速度慢。
我们可以简单的认为AOF就是日志文件，此文件只会记录“变更操作”(例如：set/del等)，如果server中持续的大量变更操作，将会导致AOF文件非常的庞大，意味着server失效后，
数据恢复的过程将会很长；事实上，一条数据经过多次变更，将会产生多条AOF记录，其实只要保存当前的状态，历史的操作记录是可以抛弃的；因为AOF持久化模式还伴生了“AOF rewrite”。
AOF的特性决定了它相对比较安全，如果你期望数据更少的丢失，那么可以采用AOF模式。如果AOF文件正在被写入时突然server失效，有可能导致文件的最后一次记录是不完整，你
可以通过手工或者程序的方式去检测并修正不完整的记录，以便通过aof文件恢复能够正常；同时需要提醒，如果你的redis持久化手段中有aof，那么在server故障失效后再次启动
前，需要检测aof文件的完整性。


7事物的传播特性有哪些，隔离级别有哪些？
事务的第一个方面是传播行为。传播行为定义关于客户端和被调用方法的事务边界。Spring定义了7中传播行为。 
传播行为	意义
PROPAGATION_MANDATORY	表示该方法必须运行在一个事务中。如果当前没有事务正在发生，将抛出一个异常
PROPAGATION_NESTED	表示如果当前正有一个事务在进行中，则该方法应当运行在一个嵌套式事务中。被嵌套的事务可以独立于封装事务进行提交或回滚。如果封装事务不存在，行为就像PROPAGATION_REQUIRES一样。
PROPAGATION_NEVER	表示当前的方法不应该在一个事务中运行。如果一个事务正在进行，则会抛出一个异常。
PROPAGATION_NOT_SUPPORTED	表示该方法不应该在一个事务中运行。如果一个现有事务正在进行中，它将在该方法的运行期间被挂起。
PROPAGATION_SUPPORTS	表示当前方法不需要事务性上下文，但是如果有一个事务已经在运行的话，它也可以在这个事务里运行。
PROPAGATION_REQUIRES_NEW	表示当前方法必须在它自己的事务里运行。一个新的事务将被启动，而且如果有一个现有事务在运行的话，则将在这个方法运行期间被挂起。
PROPAGATION_REQUIRES	表示当前方法必须在一个事务中运行。如果一个现有事务正在进行中，该方法将在那个事务中运行，否则就要开始一个新事务。

隔离级别
声明式事务的第二个方面是隔离级别。隔离级别定义一个事务可能受其他并发事务活动活动影响的程度。另一种考虑一个事务的隔离级别的方式，是把它想象为那个事务对于事物处理数据的自私程度。
在一个典型的应用程序中，多个事务同时运行，经常会为了完成他们的工作而操作同一个数据。并发虽然是必需的，但是会导致一下问题：
脏读（Dirty read）-- 脏读发生在一个事务读取了被另一个事务改写但尚未提交的数据时。如果这些改变在稍后被回滚了，那么第一个事务读取的数据就会是无效的。 
不可重复读（Nonrepeatable read）-- 不可重复读发生在一个事务执行相同的查询两次或两次以上，但每次查询结果都不相同时。这通常是由于另一个并发事务在两次查询之间更新了数据。 
幻影读（Phantom reads）-- 幻影读和不可重复读相似。当一个事务（T1）读取几行记录后，另一个并发事务（T2）插入了一些记录时，幻影读就发生了。在后来的查询中，第一个事务（T1）就会发现一些原来没有的额外记录。 
在理想状态下，事务之间将完全隔离，从而可以防止这些问题发生。然而，完全隔离会影响性能，因为隔离经常牵扯到锁定在数据库中的记录（而且有时是锁定完整的数据表）。侵占性的锁定会阻碍并发，要求事务相互等待来完成工作。
考虑到完全隔离会影响性能，而且并不是所有应用程序都要求完全隔离，所以有时可以在事务隔离方面灵活处理。因此，就会有好几个隔离级别
隔离级别	含义
ISOLATION_DEFAULT 	使用后端数据库默认的隔离级别。
ISOLATION_READ_UNCOMMITTED 	允许读取尚未提交的更改。可能导致脏读、幻影读或不可重复读。
ISOLATION_READ_COMMITTED 	允许从已经提交的并发事务读取。可防止脏读，但幻影读和不可重复读仍可能会发生。
ISOLATION_REPEATABLE_READ 	对相同字段的多次读取的结果是一致的，除非数据被当前事务本身改变。可防止脏读和不可重复读，但幻影读仍可能发生。
ISOLATION_SERIALIZABLE 	完全服从ACID的隔离级别，确保不发生脏读、不可重复读和幻影读。这在所有隔离级别中也是最慢的，因为它通常是通过完全锁定当前事务所涉及的数据表来完成的。



8列举几种表连接方式,有什么区别？
（1）SQL几种常用连接方式（旧式写法）
一、NATURAL JOIN（自然连接）
    两张表通过NATURAL JOIN连接的时候，相当于有个隐含的WHERE子句，对两张表中同名的对应列相比较看是否相等。 
SQL> select * from emp natural join dept;
返回14行数据 相当于select * from emp , dept where emp.depno = dept.depno;
二、CROSS JOIN（创建笛卡尔积） 
    对两张表通过交叉联合产生第三张返回结果集的表。相当于普通的连接。如下返回56行=14*4
select * from emp cross join dept;
三、INNER JOIN（内连接）
   内连接就相当于普通的CROSS JOIN，只是格式不一样，INNER JOIN在后面有一个ON子句（相当于WHERE）的搜索条件，用于过滤返回的行。
四、OUTER JOIN （外连接） 
   select * from ta outer join tb on (ta.c1=tb.c1) 
    outer join告诉DBMS生成结果表，在此表中不仅带有相关(ta.c1=tb.c1)行对，而且还有来自两个源表中任一表的不匹配的行。 
五、LEFT OUTER JOIN（左连接） RIGHT OUTER JOIN（右连接） 
    select * from ta left outer join  tb on (ta.c1=tb.c1) 
      select * from ta right outer join tb on (ta.c1=tb.c1) 
      left outer join(left join) 告诉DBMS生成包括联合行和任何不匹配的行的结果表，但是不匹配的行系来自查询的FROM子句中LEFT OUTER JOIN关键词左边的表中。
    right outer join(right join)与left outer join(left join)刚好相反。
	
（2）Oracle中常用新式写法
1. 相等连接
SELECT * FROM EMP,DEPT WHERE EMP.DEPTNO = DEPT.DEPTNO;
2. 外连接
◆左条件(+) = 右条件;
代表除了显示匹配相等连接条件的信息之外,还显示右条件所在的表中无法匹配相等连接条件的信息。
此时也称为"右外连接".另一种表示方法是:
SELECT ... FROM 表1 RIGHT OUTER JOIN 表2 ON 连接条件
◆左条件 = 右条件(+);
代表除了显示匹配相等连接条件的信息之外,还显示左条件所在的表中无法匹配相等连接条件的信息。
此时也称为"左外连接".
SELECT ... FROM 表1 LEFT OUTER JOIN 表2 ON 连接条件
3. 不等连接
两个表中的相关的两列进行不等连接,比较符号一般为>,<,...,BETWEEN.. AND..
SELECT EMPNO,ENAME,SAL,GRADE FROM SALGRADE,EMP
WHERE EMP.SAL BETWEEN LOSAL AND HISAL;
4. 自连接
自连接是数据库中经常要用的连接方式，使用自连接可以将自身表的一个镜像当作另一个表来对待，从而能够得到一些特殊的数据。



9 union和union all有什么不同?
UNION和UNION ALL关键字都是将两个结果集合并为一个，但这两者从使用和效率上来说都有所不同。
1、对重复结果的处理：UNION在进行表链接后会筛选掉重复的记录，Union All不会去除重复记录。
2、对排序的处理：Union将会按照字段的顺序进行排序；UNION ALL只是简单的将两个结果合并后就返回。
从效率上说，UNION ALL 要比UNION快很多，所以，如果可以确认合并的两个结果集中不包含重复数据且不需要排序时的话，那么就使用UNION ALL。


10 truncate与 delete区别？
TRUNCATE TABLE 在功能上与不带 WHERE 子句的 DELETE 语句相同：
二者均删除表中的全部行。但 TRUNCATE TABLE 比 DELETE 速度快，且使用的系统和事务日志资源少。 
DELETE 语句每次删除一行，并在事务日志中为所删除的每行记录一项。 
TRUNCATE,DELETE,DROP放在一起比较：
TRUNCATE TABLE：删除内容、释放空间但不删除定义。
DELETE TABLE:删除内容不删除定义，不释放空间。
DROP TABLE：删除内容和定义，释放空间。


11在一个字符串中搜索指定的字符,返回发现指定的字符的位置用什么函数？
INSTR(string,set[,start [,occurrence ] ] ) 如果指定start，oracle则跳过前面所有字符串到该位置开始搜索，occurence，
是强迫instr跳过前几次与字符串匹配，给出下一次匹配的位置，如果occurence指定3,那就是匹配第三次的位置了。 
例 instr('ABACAAA','A',2,2) 从ABACAAA中匹配A这个字符串，从2个位置开始匹配，匹配第2次A所在的位置。PS：
如果set中不止有一个字符而是有几个字符组成的，则INSTR给出该字符集中的第一个字符的位置。


12 exists和in用法？
mysql中的in语句是把外表和内表作hash 连接，而exists语句是对外表作loop循环，每次loop循环再对内表进行查询。一直大家都认为exists比in语句的效率要高，这种说法其实是不准确的。这个是要区分环境的。
如果查询的两个表大小相当，那么用in和exists差别不大。 
如果两个表中一个较小，一个是大表，则子查询表大的用exists，子查询表小的用in： 
例如：表A（小表），表B（大表）
1：
select * from A where cc in (select cc from B) 效率低，用到了A表上cc列的索引；
select * from A where exists(select cc from B where cc=A.cc) 效率高，用到了B表上cc列的索引。 
相反的
 
2：
select * from B where cc in (select cc from A) 效率高，用到了B表上cc列的索引；
select * from B where exists(select cc from A where cc=B.cc) 效率低，用到了A表上cc列的索引。
not in 和not exists如果查询语句使用了not in 那么内外表都进行全表扫描，没有用到索引；而not extsts 的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。 
in 与 =的区别 
select name from student where name in ('zhang','wang','li','zhao'); 
与 
select name from student where name='zhang' or name='li' or name='wang' or name='zhao' 
的结果是相同的。


13 MYSQL复制原理及其流程？
1）在Slave 服务器上执行sart slave命令开启主从复制开关，开始进行主从复制。
2）此时，Slave服务器的IO线程会通过在master上已经授权的复制用户权限请求连接master服务器，并请求从执行binlog日志文件的指定位置（日志文件名和位置就是在配置主从复制服务时执行change master命令指定的）之后开始发送binlog日志内容
3）Master服务器接收到来自Slave服务器的IO线程的请求后，二进制转储IO线程会根据Slave服务器的IO线程请求的信息分批读取指定binlog日志文件指定位置之后的binlog日志信息，然后返回给Slave端的IO线程。返回的信息中除了binlog日志内容外，还有在master服务器端记录的新的binlog文件名称，以及在新的binlog中的下一个指定更新位置。
4）当Slave服务器的IO线程获取到Master服务器上IO线程发送的日志内容、日志文件及位置点后，会将binlog日志内容依次写到Slave端自身的Relay Log（即中继日志）文件（MySQL-relay-bin.xxx）的最末端，并将新的binlog文件名和位置记录到master-info文件中，以便下一次读取master端新binlog日志时能告诉Master服务器从新binlog日志的指定文件及位置开始读取新的binlog日志内容
5）Slave服务器端的SQL线程会实时检测本地Relay Log 中IO线程新增的日志内容，然后及时把Relay LOG 文件中的内容解析成sql语句，并在自身Slave服务器上按解析SQL语句的位置顺序执行应用这样sql语句，并在relay-log.info中记录当前应用中继日志的文件名和位置点


14 MyISAM和innodb 的区别有哪些？
1. InnoDB支持事务，MyISAM不支持，对于InnoDB每一条SQL语言都默认封装成事务，自动提交，这样会影响速度，所以最好把多条SQL语言放在begin和commit之间，组成一个事务；  
2. InnoDB支持外键，而MyISAM不支持。对一个包含外键的InnoDB表转为MYISAM会失败；  
3. InnoDB是聚集索引，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而MyISAM是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。 
4. InnoDB不保存表的具体行数，执行select count(*) from table时需要全表扫描。而MyISAM用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快；  
5. Innodb不支持全文索引，而MyISAM支持全文索引，查询效率上MyISAM要高；



15 单个索引、联合索引、主键索引有何不同？
@ 索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。
普通索引(由关键字KEY或INDEX定义的索引)的唯一任务是加快对数据的访问速度。

@ 普通索引允许被索引的数据列包含重复的值。如果能确定某个数据列将只包含彼此各不相同的值，在为这个数据列创建索引的时候就应该用关键字UNIQUE把它定义为一个唯一索引。也就是说，唯一索引可以保证数据记录的唯一性。

@ 主键，是一种特殊的唯一索引，在一张表中只能定义一个主键索引，主键用于唯一标识一条记录，使用关键字 PRIMARY KEY 来创建。
索引可以覆盖多个数据列，如像INDEX(columnA, columnB)索引，这就是联合索引。

@ 主键分为复合主键和联合主键
复合主键就是指你表的主键含有一个以上的字段组成 。
例如；
create table test 
( 
   name varchar(19), 
   id number, 
   value varchar(10), 
   primary key (id,name) 
) 
上面的id和name字段组合起来就是你test表的复合主键 （若其一为单索引字段时，左边的id才会有索引）
它的出现是因为你的name字段可能会出现重名，所以要加上ID字段这样就可以保证你记录的唯一性 
一般情况下，主键的字段长度和字段数目要越少越好 

@ 联合主键，顾名思义就是多个主键联合形成一个主键组合，体现在联合。
(主键原则上是唯一的，别被唯一值所困扰。) 
索引可以极大的提高数据的查询速度，但是会降低插入、删除、更新表的速度，因为在执行这些写操作时，还要操作索引文件。


16 MySql的存储引擎的不同？
1. MyISAM  : 是旧版本mysql的默认引擎，现在默认引擎是InnoDB。MyISAM引擎的主要特点就是快，没有事务处理操作，也不支持外键操作。适合于多读取插入，少更新删除的操作表。存储数据分成三个文件：.frm(存储表定义) .MYD(存储数据)  .MYI(存储索引)
用法： engine=myisam default charset=utf-8 ;
2.InnoDB  ：是新版本mysql的默认引擎，支持事务处理和外键，但是其缺点几就是慢了些。存储方式分为两种：1.共享表空间存储。[.frm(表结构) 和 innodb_data_home(数据)和innodb_data_file_path(索引)]   2.多表空间存储。 [.frm(表结构) 和 .idb（数据）  ]。
适用于对于事务由较高要求的表的创建。
用法：engine=innodb default charset=utf-8 ;
3.MEMORY： 数据访问非常快的引擎，存储格式同一放在内存中的一个磁盘文件中格式是.frm 。默认使用hash索引。一旦服务器关闭表中的数据就会丢失。数据大小有限制。
用法：engine=memory ;
4.MERGE：本身是融合的意思，实质是MyISUM表的融合，这些融合的表必须结构完全相同。MERGE本身是没有数据的。插入操作可以是first或者是last。删除只是删除MERGE表定义，并不删除真正表的数据。存储方式：.frm(文件存储表定义信息)  .MRG(描述组合表的信息，比如由哪些表组成，插入时的依据)。
适用于：将一系列等同的MyISAM表逻辑方式组合在一起，作为一个对象引用它们。
用法：engine=merge union=(__,__) insert_method=last/first ;


17 Mysql怎么分表，以及分表后如果想按条件分页查询怎么办？
一、分表概述 
1.如果只是为了分页，可以考虑这种分表，就是表的id是范围性的，且id是连续的，比如第一张表id是1到10万，第二张是10万到20万，这样分页应该没什么问题。
2.如果是其他的分表方式，建议用sphinx先建索引，然后查询分页，我们公司现在就是这样干的
Mysql分库分表方案
1.为什么要分表：
当一张表的数据达到几千万时，你查询一次所花的时间会变多，如果有联合查询的话，我想有可能会死在那儿了。分表的目的就在于此，减小数据库的负担，缩短查询时间。
mysql中有一种机制是表锁定和行锁定，是为了保证数据的完整性。表锁定表示你们都不能对这张表进行操作，必须等我对表操作完才行。行锁定也一样，别的sql必须等我对这条数据操作完了，才能对这条数据进行操作。
2. mysql proxy：amoeba
做mysql集群,利用amoeba。
从上层的java程序来讲，不需要知道主服务器和从服务器的来源，即主从数据库服务器对于上层来讲是透明的。可以通过amoeba来配置。
3.大数据量并且访问频繁的表，将其分为若干个表
比如对于某网站平台的数据库表-公司表，数据量很大，这种能预估出来的大数据量表，我们就事先分出个N个表，这个N是多少，根据实际情况而定。
某网站现在的数据量至多是5000万条，可以设计每张表容纳的数据量是500万条，也就是拆分成10张表，
那么如何判断某张表的数据是否容量已满呢？可以在程序段对于要新增数据的表，在插入前先做统计表记录数量的操作，当<500万条数据，就直接插入，当已经到达阀值，可以在程序段新创建数据库表（或者已经事先创建好），再执行插入操作。
4. 利用merge存储引擎来实现分表
如果要把已有的大数据量表分开比较痛苦，最痛苦的事就是改代码，因为程序里面的sql语句已经写好了。用merge存储引擎来实现分表, 这种方法比较适合.
举例子：

二、数据库架构
1、简单的MySQL主从复制:
MySQL的主从复制解决了数据库的读写分离，并很好的提升了读的性能，其图如下：
其主从复制的过程如下图所示：
但是，主从复制也带来其他一系列性能瓶颈问题：
1. 写入无法扩展
2. 写入无法缓存
3. 复制延时
4. 锁表率上升
5. 表变大，缓存率下降
那问题产生总得解决的，这就产生下面的优化方案，一起来看看。
2、MySQL垂直分区
如果把业务切割得足够独立，那把不同业务的数据放到不同的数据库服务器将是一个不错的方案，而且万一其中一个业务崩溃了也不会影响其他业务的正常进行，并且也起到了负载分流的作用，大大提升了数据库的吞吐能力。经过垂直分区后的数据库架构图如下：
然而，尽管业务之间已经足够独立了，但是有些业务之间或多或少总会有点联系，如用户，基本上都会和每个业务相关联，况且这种分区方式，也不能解决单张表数据量暴涨的问题，因此为何不试试水平分割呢？
3、MySQL水平分片（Sharding）
这是一个非常好的思路，将用户按一定规则（按id哈希）分组，并把该组用户的数据存储到一个数据库分片中，即一个sharding，这样随着用户数量的增加，只要简单地配置一台服务器即可，原理图如下：


三、分页方案 
要是整体的分页显示那就更简单了
1、每个表的记录数是已知的，应在每次发生变化时记录到目录表中
2、无论是否排序（如果排序只是表的次序不同）至多会 union 两个分表

如假定共3个分表，记录数分别为 90，120，80 总记录数为 290
设分页是每页显示40条，则 
第1页 表一的 1 到 40
第2页 表一的 41 到 80
第3页 表一的 81 到 90 + 表二的 1 到 30
第4页 表二的 31 到 70
第5页 表二的 71 到 110
第6页 表二的 111 到 120 +  表三的 1 到 30


18 MySql的主从实时备份同步的配置，以及原理(从库读主库的binlog)，读写分离？
一、主从同步概述
Mysql的Replication(复制)是一个异步的复制过程，从一个 Mysql instance(我们称之为 Master)复制到另一个Mysql instance(我们称之 Slave)。在 Master 与 Slave之间的实现整个复制过程主要由三个线程来完成，其中两个线程(Sql线程和IO线程)在 Slave 端，另外一个线程(IO线程)在Master端。
要实现 MySQL 的 Replication ，首先必须打开 Master 端的BinaryLog(mysql-bin.xxxxxx)功能，否则无法实现。因为整个复制过程实际上就是Slave从Master端获取该日志然后再在自己身上完全顺序的执行日志中所记录的各种操作。打开 MySQL 的 Binary Log 可以通过在启动 MySQL Server 的过程中使用“—log-bin” 参数选项，或者在 my.cnf 配置文件中的 mysqld 参数组([mysqld]标识后的参数部分)增加“log-bin” 参数项。

二、主从同步过程
MySQL 复制的基本过程如下：
1.Slave上面的IO线程连接上Master，并请求从指定日志文件的指定位置(或者从最开始的日志)之后的日志内容;
2.Master接收到来自Slave的IO线程的请求后，通过负责复制的IO线程根据请求信息读取指定日志指定位置之后的日志信息，返回给Slave端的 IO线程。返回信息中除了日志所包含的信息之外，还包括本次返回的信息在Master端的Binary Log文件的名称以及在Binary Log中的位置;
3.Slave的IO线程接收到信息后，将接收到的日志内容依次写入到 Slave 端的RelayLog文件(mysql-relay-bin.xxxxxx)的最末端，并将读取到的Master端的bin-log的文件名和位置记录到master-info文件中，以便在下一次读取的时候能够清楚的告诉Master“我需要从某个bin-log的哪个位置开始往后的日志内容，请发给我”。
4.Slave的SQL线程检测到Relay Log中新增加了内容后，会马上解析该Log文件中的内容成为在Master 端真实执行时候的那些可执行的Query语句，并在自身执行这些Query。这样，实际上就是在Master端和Slave端执行了同样的Query，所以两端的数据是完全一样的。

三、 风险和性能
实际上，在老版本中，MySQL 的复制实现在 Slave 端并不是由 SQL 线程和 IO线程这两个线程共同协作而完成的，而是由单独的一个线程来完成所有的工作。但是 MySQL的工程师们很快发现，这样做存在很大的风险和性能问题，主要如下：
1.首先，如果通过一个单一的线程来独立实现这个工作的话，就使复制 Master 端的，BinaryLog日志，以及解析这些日志，然后再在自身执行的这个过程成为一个串行的过程，性能自然会受到较大的限制，这种架构下的Replication 的延迟自然就比较长了。
3.其次，Slave 端的这个复制线程从 Master 端获取 Binary Log 过来之后，需要接着解析这些内容，还原成Master 端所执行的原始 Query，然后在自身执行。在这个过程中，Master端很可能又已经产生了大量的变化并生成了大量的Binary Log 信息。如果在这个阶段 Master端的存储系统出现了无法修复的故障，那么在这个阶段所产生的所有变更都将永远的丢失，无法再找回来。这种潜在风险在Slave端压力比较大的时候尤其突出，因为如果 Slave压力比较大，解析日志以及应用这些日志所花费的时间自然就会更长一些，可能丢失的数据也就会更多。
所以，在后期的改造中，新版本的 MySQL 为了尽量减小这个风险，并提高复制的性能，将 Slave端的复制改为两个线程来完成，也就是前面所提到的 SQL 线程和 IO线程。最早提出这个改进方案的是Yahoo!的一位工程师“JeremyZawodny”。通过这样的改造，这样既在很大程度上解决了性能问题，缩短了异步的延时时间，同时也减少了潜在的数据丢失量。
当然，即使是换成了现在这样两个线程来协作处理之后，同样也还是存在 Slave数据延时以及数据丢失的可能性的，毕竟这个复制是异步的。只要数据的更改不是在一个事务中，这些问题都是存在的。

四、读写分离简介
对于很多大型网站（pv值百万、千万）来说，在所处理的业务中，其中有70%的业务是查询（select）相关的业务操作（新闻网站，插入一条新闻。查询操作），剩下的则是写（insert、update、delete，只要能对MySQL的数据造成更改的操作都叫写操作）操作。在使用负载均衡集群之后，可以很大程度的提升网站的整体性能，但是最终的数据处理的压力还是会落到MySQL数据库上，所有很有必要使用一些技术来提升MySQL的负载能力。（读写分离）
写专门交给写服务器处理（一般网站来说写是比较少的 读写比 4:1） 那么需要把读的任务分配多台服务器来完成的架构，就叫做读写分离。

五、读写分离实现方式
第一种：php程序上自己做逻辑判断，写php代码的时候，自己在程序上做逻辑判读写匹配。select，insert、update、delete做正则匹配，根据结果选择写服务器（主服务器）。如果是select操作则选择读服务器（从服务器器） mysql_connect('读写的区分')
第二种：MySQL- Proxy是实现"读写分离(Read/Write Splitting)"的一个软件（MySQL官方提供 ，也叫中间件），基本的原理是让主数据库处理写操作（insert、update、delete），而从数据库处理查询操作（select）。而数据库的一致性则通过主从复制来实现。所以说主从复制是读写分离的基础。
注意：MySQL-proxy它能实现读写语句的区分主要依靠的是内部一个lua脚本（能实现读写语句的判断）。
注意：如果只在主服务器（写服务器）上完成数据的写操作话；这个时候从服务器上没有执行写操作，是没有数据的。这个时候需要使用另外一个技术来实现主从服务器的数据一致性，这个技术叫做 主从复制技术。所以说主从复制是读写分离的基础。 


19 索引的数据结构，B+树？
一、数据库索引
是数据库管理系统中一个排序的数据结构以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。
在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。
为表设置索引要付出代价的：一是增加了数据库的存储空间，二是在插入和修改数据时要花费较多的时间(因为索引也要随之变动)。

二、索引的优点
第一，通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。
第二，可以大大加快数据的检索速度，这也是创建索引的最主要的原因。
第三，可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。
第四，在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。
第五，通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。 

三、索引的缺点
第一，创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。
第二，索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。
第三，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。

四、应该在这些列上创建索引
1、在经常需要搜索的列上，可以加快搜索的速度；
2、在作为主键的列上，强制该列的唯一性和组织表中数据的排列结构；
3、在经常用在连接的列上，这些列主要是一些外键，可以加快连接的速度；
4、在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，其指定的范围是连续的；
5、在经常需要排序的列上创建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间；
6、在经常使用在WHERE子句中的列上面创建索引，加快条件的判断速度。

五、不应该创建索引的的这些列具有下列特点
1、对于那些在查询中很少使用或者参考的列不应该创建索引。这是因为，既然这些列很少使用到，因此有索引或者无索引，并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。
2、对于那些只有很少数据值的列也不应该增加索引。这是因为，由于这些列的取值很少，例如人事表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比例，即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度。
3、对于那些定义为text, image和bit数据类型的列不应该增加索引。这是因为，这些列的数据量要么相当大，要么取值很少。
4、当修改性能远远大于检索性能时，不应该创建索引。这是因为，修改性能和检索性能是互相矛盾的。当增加索引时，会提高检索性能，但是会降低修改性能。当减少索引时，会提高修改性能，降低检索性能。因此，当修改性能远远大于检索性能时，不应该创建索引。

六、B-树的特性
1.关键字集合分布在整颗树中；
2.任何一个关键字出现且只出现在一个结点中；
3.搜索有可能在非叶子结点结束；
4.其搜索性能等价于在关键字全集内做一次二分查找；
5.自动层次控制；
B-树的搜索，从根结点开始，对结点内的关键字（有序）序列进行二分查找，如果命中则结束，否则进入查询关键字所属范围的儿子结点；重复，直到所对应的儿子指针为空，或已经是叶子结点。

七、B+树的特性：
1.所有关键字都出现在叶子结点的链表中（稠密索引），且链表中的关键字恰好是有序的；
2.不可能在非叶子结点命中；
3.非叶子结点相当于是叶子结点的索引（稀疏索引），叶子结点相当于是存储（关键字）数据的数据层；
4.更适合文件索引系统。
在B+Tree的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的B+Tree。做这个优化的目的是为了提高区间访问的性能。　
B+树有2个头指针，一个是树的根节点，一个是最小关键码的叶节点。
所以 B+树有两种搜索方法：
一种是按叶节点自己拉起的链表顺序搜索。
一种是从根节点开始搜索，和B树类似，不过如果非叶节点的关键码等于给定值，搜索并不停止，而是继续沿右指针，一直查到叶节点上的关键码。所以无论搜索是否成功，都将走完树的所有层。
B+ 树中，数据对象的插入和删除仅在叶节点上进行。

八、这两种处理索引的数据结构的不同之处：
1、B-树中同一键值不会出现多次，并且它有可能出现在叶结点，也有可能出现在非叶结点中。而B+树的键一定会出现在叶结点中，并且有可能在非叶结点中也有可能重复出现，以维持B+树的平衡。
2、因为B-树键位置不定，且在整个树结构中只出现一次，虽然可以节省存储空间，但使得在插入、删除操作复杂度明显增加。B+树相比来说是一种较好的折中。
3、B-树的查询效率与键在树中的位置有关，最大时间复杂度与B+树相同(在叶结点的时候)，最小时间复杂度为1(在根结点的时候)。而B+树的时候复杂度对某建成的树是固定的。

九、为什么选用B+、B-树
索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。
内存读取，内存是由一系列的存储单元组成的，每个存储单元存储固定大小的数据，且有一个唯一地址。当需要读内存时，将地址信号放到地址总线上传给内存，内存解析信号并定位到存储单元，然后把该存储单元上的数据放到数据总线上，回传。
写内存时，系统将要写入的数据和单元地址分别放到数据总线和地址总线上，内存读取两个总线的内容，做相应的写操作。
内存存取效率，跟次数有关，先读取A数据还是后读取A数据不会影响存取效率。而磁盘存取就不一样了，磁盘I/O涉及机械操作。磁盘是由大小相同且同轴的圆形盘片组成，磁盘可以转动(各个磁盘须同时转动)。磁盘的一侧有磁头支架，磁头支架固定了一组磁头，每个磁头负责存取一个磁盘的内容。磁头不动，磁盘转动，但磁臂可以前后动，用于读取不同磁道上的数据。磁道就是以盘片为中心划分出来的一系列同心环(如图标红那圈)。磁道又划分为一个个小段，叫扇区，是磁盘的最小存储
磁盘读取时，系统将数据逻辑地址传给磁盘，磁盘的控制电路会解析出物理地址，即哪个磁道哪个扇区。于是磁头需要前后移动到对应的磁道，消耗的时间叫寻道时间，然后磁盘旋转将对应的扇区转到磁头下，消耗的时间叫旋转时间。所以，适当的操作顺序和数据存放可以减少寻道时间和旋转时间。
为了尽量减少I/O操作，磁盘读取每次都会预读，大小通常为页的整数倍。即使只需要读取一个字节，磁盘也会读取一页的数据(通常为4K)放入内存，内存与磁盘以页为单位交换数据。因为局部性原理认为，通常一个数据被用到，其附近的数据也会立马被用到。



20 事务的四个特性，以及各自的特点（原子、隔离）等等，项目怎么解决这些问题？
一．什么是事务
事务是应用程序中一系列严密的操作，所有操作必须成功完成，否则在每个操作中所作的所有更改都会被撤消。也就是事务具有原子性，一个事务中的一系列的操作要么全部成功，要么一个都不做。
事务的结束有两种，当事务中的所以步骤全部成功执行时，事务提交。如果其中一个步骤失败，将发生回滚操作，撤消撤消之前到事务开始时的所以操作。

二．事务的 ACID
事务具有四个特征：原子性（ Atomicity ）、一致性（ Consistency ）、隔离性（ Isolation ）和持续性（ Durability ）。这四个特性简称为 ACID 特性。
1 、原子性
事务是数据库的逻辑工作单位，事务中包含的各操作要么都做，要么都不做
2 、一致性
事 务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。因此当数据库只包含成功事务提交的结果时，就说数据库处于一致性状态。如果数据库系统 运行中发生故障，有些事务尚未完成就被迫中断，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于一种不正确的状态，或者说是 不一致的状态。
3 、隔离性
一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰。
4 、持续性
也称永久性，指一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的。接下来的其它操作或故障不应该对其执行结果有任何影响。 

三、解决高并发锁的问题
1. 版本检查
在数据库中保留“版本”字段，跟随数据同时读写，以此判断数据版本。版本可能是时间戳或状态字段。
下例中的 WHERE 子句就实现了简单的版本检查：
UPDATE table SET status = 1 WHERE id=1 AND status = 0;
版本检查能够作为“乐观锁”，解决更新丢失的问题。

2. 锁
2.1 共享锁与排它锁
共享锁（Shared locks, S-locks）
共享锁又称读锁，是读取操作创建的锁。其他用户可以并发读取数据，但任何事务都不能对数据进行修改（获取数据上的排他锁），直到已释放所有共享锁。
能给未加锁和添加了S锁的对象添加S锁。对象可以接受添加多把S锁。
如果事务T对数据A加上共享锁后，则其他事务只能对A再加共享锁，不能加排他锁。获准共享锁的事务只能读数据，不能修改数据。
用法：
SELECT ... LOCK IN SHARE MODE;
在查询语句后面增加LOCK IN SHARE MODE，Mysql会对查询结果中的每行都加共享锁，当没有其他线程对查询结果集中的任何一行使用排他锁时，可以成功申请共享锁，否则会被阻塞。其他线程也可以读取使用了共享锁的表，而且这些线程读取的是同一个版本的数据。

排它锁（Exclusive locks, X-locks）
排他锁又称写锁，如果事务T对数据A加上排他锁后，则其他事务不能再对A加任任何类型的封锁。获得排他锁的事务既能读数据，又能修改数据。
只能给未加锁的对象添加X锁。对象只能接受一把X锁。加X锁的对象不能再加任何锁。
用法：
SELECT ... FOR UPDATE;
在查询语句后面增加FOR UPDATE，Mysql会对查询结果中的每行都加排他锁，当没有其他线程对查询结果集中的任何一行使用排他锁时，可以成功申请排他锁，否则会被阻塞。

对于insert、update、delete，InnoDB会自动给涉及的数据加排他锁（X）；对于一般的Select语句，InnoDB不会加任何锁，事务可以通过以下语句给显示加共享锁或排他锁。
共享锁：SELECT ... LOCK IN SHARE MODE;
排他锁：SELECT ... FOR UPDATE;

2.2 意向锁
InnoDB还有两个表锁：
意向共享锁（IS）：表示事务准备给数据行加入共享锁，也就是说一个数据行加共享锁前必须先取得该表的IS锁。
意向排他锁（IX）：类似上面，表示事务准备给数据行加入排他锁，说明事务在一个数据行加排他锁前必须先取得该表的IX锁。
意向锁是InnoDB自动加的，不需要用户干预。

2.3 临时锁与持续锁
锁的时效性，指明了加锁生效期是到当前语句结束还是当前事务结束。

2.4 表级锁与行级锁
锁的粒度，指明了加锁的对象是当前表还是当前行。

2.5 悲观锁与乐观锁

悲观锁（Pessimistic Locking）
悲观锁假定当前事务操纵数据资源时，肯定还会有其他事务同时访问该数据资源，为了避免当前事务的操作受到干扰，先锁定资源。悲观锁需使用数据库的锁机制实现，如使用行级排他锁或表级排它锁。
尽管悲观锁能够防止丢失更新和不可重复读这类问题，但是它非常影响并发性能，因此应该谨慎使用。

乐观锁（Optimistic Locking）
乐观锁假定当前事务操纵数据资源时，不会有其他事务同时访问该数据资源，因此不在数据库层次上的锁定。乐观锁使用由程序逻辑控制的技术来避免可能出现的并发问题。
唯一能够同时保持高并发和高可伸缩性的方法就是使用带版本检查的乐观锁。
乐观锁不能解决脏读的问题，因此仍需要数据库至少启用“读已提交”的事务隔离级别。

3. 三级加锁协议
三级加锁协议也称为三级封锁协议,是为了保证正确的调度事务的并发操作,事务在对数据库对象加锁,解锁是必须遵守的一种规则。
3.1 一级加锁协议
事务在修改数据前必须加X锁，直到事务结束（事务结束包括正常结束(COMMIT)和非正常结束(ROLLBACK)）才可释放；如果仅仅是读数据，不需要加锁。
如下例：
SELECT xxx FOR UPDATE;
UPDATE xxx;
一级封锁协议可以防止丢失修改，并保证事务T是可恢复的。使用一级封锁协议可以解决丢失修改问题。
在一级封锁协议中，如果仅仅是读数据不对其进行修改，是不需要加锁的，它不能保证可重复读和不读“脏”数据。

3.2 二级加锁协议
满足一级加锁协议，且事务在读取数据之前必须先加S锁，读完后即可释放S锁。
二级封锁协议除防止了丢失修改，还可以进一步防止读“脏”数据。但在二级封锁协议中，由于读完数据后即可释放S锁，所以它不能保证可重复读。

3.3 三级加锁协议
满足一级加锁协议，且事务在读取数据之前必须先加S锁，直到事务结束才释放。
三级封锁协议除防止了丢失修改和不读“脏”数据外，还进一步防止了不可重复读。

上述三级协议的主要区别在于什么操作需要申请封锁，以及何时释放。

4. 两段锁协议（2-phase locking）
两段锁协议是指每个事务的执行可以分为两个阶段：生长阶段（加锁阶段）和衰退阶段（解锁阶段）。
加锁阶段：在该阶段可以进行加锁操作。在对任何数据进行读操作之前要申请并获得S锁，在进行写操作之前要申请并获得X锁。加锁不成功，则事务进入等待状态，直到加锁成功才继续执行。
解锁阶段：当事务释放了一个封锁以后，事务进入解锁阶段，在该阶段只能进行解锁操作不能再进行加锁操作。

若并发执行的所有事务均遵守两段锁协议，则对这些事务的任何并发调度策略都是可串行化的。
遵循两段锁协议的事务调度处理的结果是可串行化的充分条件，但是可串行化并不一定遵循两段锁协议。

两段锁协议和防止死锁的一次封锁法的异同之处，一次封锁法要求每个事务必须一次将所有要使用的数据全部加锁，否则就不能继续执行，因此一次封锁法遵守两段锁协议；但是两段锁协议并不要求事务必须一次将所有要使用的数据全部加锁，因此遵守两段锁协议的事务可能发生死锁。



21 数据库的锁：行锁，表锁；乐观锁，悲观锁？
一、乐观锁
乐观锁不是数据库自带的，需要我们自己去实现。乐观锁是指操作数据库时(更新操作)，想法很乐观，认为这次的操作不会导致冲突，在操作数据时，并不进行任何其他的特殊处理（也就是不加锁），而在进行更新后，再去判断是否有冲突了。
通常实现是这样的：在表中的数据进行操作时(更新)，先给数据表加一个版本(version)字段，每操作一次，将那条记录的版本号加1。也就是先查询出那条记录，获取出version字段,如果要对那条记录进行操作(更新),则先判断此刻version的值是否与刚刚查询出来时的version的值相等，如果相等，则说明这段期间，没有其他程序对其进行操作，则可以执行更新，将version字段的值加1；如果更新时发现此刻的version值与刚刚获取出来的version的值不相等，则说明这段期间已经有其他程序对其进行操作了，则不进行更新操作。
举例：
下单操作包括3步骤：
1.查询出商品信息
select (status,status,version) from t_goods where id=#{id}
2.根据商品信息生成订单
3.修改商品status为2
update t_goods 
set status=2,version=version+1
where id=#{id} and version=#{version};
除了自己手动实现乐观锁之外，现在网上许多框架已经封装好了乐观锁的实现，如hibernate，需要时，可能自行搜索"hiberate 乐观锁"试试看。

二、悲观锁
与乐观锁相对应的就是悲观锁了。悲观锁就是在操作数据时，认为此操作会出现数据冲突，所以在进行每次操作时都要通过获取锁才能进行对相同数据的操作，这点跟java中的synchronized很相似，所以悲观锁需要耗费较多的时间。另外与乐观锁相对应的，悲观锁是由数据库自己实现了的，要用的时候，我们直接调用数据库的相关语句就可以了。
说到这里，由悲观锁涉及到的另外两个锁概念就出来了，它们就是共享锁与排它锁。共享锁和排它锁是悲观锁的不同的实现，它俩都属于悲观锁的范畴。
共享锁
共享锁指的就是对于多个不同的事务，对同一个资源共享同一个锁。相当于对于同一把门，它拥有多个钥匙一样。就像这样，你家有一个大门，大门的钥匙有好几把，你有一把，你女朋友有一把，你们都可能通过这把钥匙进入你们家，进去啪啪啪啥的，一下理解了哈，没错，这个就是所谓的共享锁。
刚刚说了，对于悲观锁，一般数据库已经实现了，共享锁也属于悲观锁的一种，那么共享锁在mysql中是通过什么命令来调用呢。通过查询资料，了解到通过在执行语句后面加上lock in share mode就代表对某些资源加上共享锁了。
比如，我这里通过mysql打开两个查询编辑器，在其中开启一个事务，并不执行commit语句
city表DDL如下：
[plain] view plain copy
CREATE TABLE `city` (  
`id` bigint(20) NOT NULL AUTO_INCREMENT,  
`name` varchar(255) DEFAULT NULL,  
`state` varchar(255) DEFAULT NULL,  
PRIMARY KEY (`id`)  
) ENGINE=InnoDB AUTO_INCREMENT=18 DEFAULT CHARSET=utf8;  
begin;
SELECT * from city where id = "1"  lock in share mode;
然后在另一个查询窗口中，对id为1的数据进行更新
update  city set name="666" where id ="1";
此时，操作界面进入了卡顿状态，过几秒后，也提示错误信息
[SQL]update  city set name="666" where id ="1";
[Err] 1205 - Lock wait timeout exceeded; try restarting transaction
那么证明，对于id=1的记录加锁成功了，在上一条记录还没有commit之前，这条id=1的记录被锁住了，只有在上一个事务释放掉锁后才能进行操作，或用共享锁才能对此数据进行操作。
再实验一下：
update city set name="666" where id ="1" lock in share mode;
[Err] 1064 - You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'lock in share mode' at line 1
加上共享锁后，也提示错误信息了，通过查询资料才知道，对于update,insert,delete语句会自动加排它锁的原因
于是，我又试了试SELECT * from city where id = "1" lock in share mode;
这下成功了。

三、排它锁
排它锁与共享锁相对应，就是指对于多个不同的事务，对同一个资源只能有一把锁。
与共享锁类型，在需要执行的语句后面加上for update就可以了

四、行锁
行锁，由字面意思理解，就是给某一行加上锁，也就是一条记录加上锁。
比如之前演示的共享锁语句
SELECT * from city where id = "1"  lock in share mode; 
由于对于city表中,id字段为主键，就也相当于索引。执行加锁时，会将id这个索引为1的记录加上锁，那么这个锁就是行锁。

五、表锁
表锁，和行锁相对应，给这个表加上锁。
MyISAM引擎里有的，暂时研究了

六、共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。

七、排他锁（X)：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。另外，为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁。

八、意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。

九、意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。
	



22 存储过程与函数的区别？
本质上没区别，执行的本质都一样。
只是函数有如：只能返回一个变量的限制。而存储过程可以返回多个。　　
函数是可以嵌入在sql中使用的,可以在select中调用，而存储过程要让sql的query 可以执行， 需要把 mysql_real_connect 的最后一个参数设置为CLIENT_MULTI_STATEMENTS。
函数限制比较多，比如不能用临时表，只能用表变量．还有一些函数都不可用等等．而存储过程的限制相对就比较少。 


23 索引类型有哪些？
@ 从数据结构角度
1、B+树索引(O(log(n)))：关于B+树索引，可以参考 MySQL索引背后的数据结构及算法原理
2、hash索引：
a 仅仅能满足"=","IN"和"<=>"查询，不能使用范围查询
b 其检索效率非常高，索引的检索可以一次定位，不像B-Tree 索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问，所以 Hash 索引的查询效率要远高于 B-Tree 索引
c 只有Memory存储引擎显示支持hash索引
3、FULLTEXT索引（现在MyISAM和InnoDB引擎都支持了）
4、R-Tree索引（用于对GIS数据类型创建SPATIAL索引）

@从物理存储角度
1、聚集索引（clustered index）
2、非聚集索引（non-clustered index）

@从逻辑角度
1、主键索引：主键索引是一种特殊的唯一索引，不允许有空值
2、普通索引或者单列索引
3、多列索引（复合索引）：复合索引指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用复合索引时遵循最左前缀集合
4、唯一索引或者非唯一索引
5、空间索引：空间索引是对空间数据类型的字段建立的索引，MYSQL中的空间数据类型有4种，分别是GEOMETRY、POINT、LINESTRING、POLYGON。
MYSQL使用SPATIAL关键字进行扩展，使得能够用于创建正规索引类型的语法创建空间索引。创建空间索引的列，必须将其声明为NOT NULL，空间索引只能在存储引擎为MYISAM的表中创建
CREATE TABLE table_name[col_name data type]
[unique|fulltext|spatial][index|key][index_name](col_name[length])[asc|desc]

24 数据库三范式是什么?
◆ 第一范式（1NF）：强调的是列的原子性，即列不能够再分成其他几列。
◆ 第二范式（2NF）：首先是 1NF，另外包含两部分内容，一是表必须有一个主键；二是没有包含在主键中的列必须完全依赖于主键，而不能只依赖于主键的一部分。 
◆ 第三范式（3NF）：首先是 2NF，另外非主键列必须直接依赖于主键，不能存在传递依赖。即不能存在：非主键列 A 依赖于非主键列 B，非主键列 B 依赖于主键的情况。
25 行转列、列换行怎么转？
一、场景
在生成报表的时候，很多时候对某列取值固定或者有限的几个值时，进行转列分析。如下：
facility列取值只有四种，每种一列，遇到相同facility求和。如下图：


二、实现方式
1 DECODE
利用DECODE函数、聚合函数SUM、GROUP BY分组实现。
    WITH CO_ORDER AS(      
      SELECT 'DOM1' Customer, 'ZHA01' facility , 4000 TEU FROM dual UNION ALL      
      SELECT 'DOM1' Customer, 'ZHA01' facility , 5000 TEU FROM dual UNION ALL      
      SELECT 'DOM1' Customer, 'ZHA02' facility , 9000 TEU FROM dual UNION ALL     
      SELECT 'DOM1' Customer, 'ZHA03' facility , 9000 TEU FROM dual UNION ALL    
      SELECT 'DOM1' Customer, 'ZHA04' facility , 4000 TEU FROM dual UNION ALL    
      SELECT 'DOM2' Customer, 'ZHA01' facility , 6500 TEU FROM dual UNION ALL      
      SELECT 'DOM2' Customer, 'ZHA02' facility , 6000 TEU FROM dual UNION ALL      
      SELECT 'DOM2' Customer, 'ZHA03' facility , 5000 TEU FROM dual UNION ALL      
      SELECT 'DOM2' Customer, 'ZHA04' facility , 3000 TEU FROM dual       
    )  
    SELECT t.Customer, SUM(decode(t.facility, 'ZHA01', t.teu)) AS ZHA01,  
           SUM(decode(t.facility, 'ZHA02', t.teu)) AS ZHA02,  
           SUM(decode(t.facility, 'ZHA03', t.teu)) AS ZHA03,  
           SUM(decode(t.facility, 'ZHA04', t.teu)) AS ZHA04  
      FROM CO_ORDER t  
      GROUP BY t.Customer;  

该方式简单直观，当然每列具体要标示出来，所以只能处理固定种类的，不易程序后期扩展。

2 case
case函数的写法相对比较简洁，如下
    WITH CO_ORDER AS(        
      SELECT 'DOM1' Customer, 'ZHA01' facility , 4000 TEU FROM dual UNION ALL        
      SELECT 'DOM1' Customer, 'ZHA01' facility , 5000 TEU FROM dual UNION ALL        
      SELECT 'DOM1' Customer, 'ZHA02' facility , 9000 TEU FROM dual UNION ALL       
      SELECT 'DOM1' Customer, 'ZHA03' facility , 9000 TEU FROM dual UNION ALL      
      SELECT 'DOM1' Customer, 'ZHA04' facility , 4000 TEU FROM dual UNION ALL      
      SELECT 'DOM2' Customer, 'ZHA01' facility , 6500 TEU FROM dual UNION ALL        
      SELECT 'DOM2' Customer, 'ZHA02' facility , 6000 TEU FROM dual UNION ALL        
      SELECT 'DOM2' Customer, 'ZHA03' facility , 5000 TEU FROM dual UNION ALL        
      SELECT 'DOM2' Customer, 'ZHA04' facility , 3000 TEU FROM dual         
    )   
    SELECT Customer,  
        sum (CASE WHEN facility = 'ZHA01' THEN TEU ELSE 0 END) AS ZHA01,   
        sum (CASE WHEN facility = 'ZHA02' THEN TEU ELSE 0 END) AS ZHA02,  
        sum (CASE WHEN facility = 'ZHA03' THEN TEU ELSE 0 END) AS ZHA03,  
        sum (CASE WHEN facility = 'ZHA04' THEN TEU ELSE 0 END) AS ZHA04  
    FROM CO_ORDER GROUP BY Customer ORDER BY Customer ASC;  

值得注意的是 case函数只返回第一个符合条件的值，剩下的Case部分将会被自动忽略

3 PIVOT
直接使用Oracle 关键字PIVOT。
    WITH CO_ORDER AS(      
      SELECT 'DOM1' Customer, 'ZHA01' facility , 4000 TEU FROM dual UNION ALL      
      SELECT 'DOM1' Customer, 'ZHA01' facility , 5000 TEU FROM dual UNION ALL      
      SELECT 'DOM1' Customer, 'ZHA02' facility , 9000 TEU FROM dual UNION ALL     
      SELECT 'DOM1' Customer, 'ZHA03' facility , 9000 TEU FROM dual UNION ALL    
      SELECT 'DOM1' Customer, 'ZHA04' facility , 4000 TEU FROM dual UNION ALL    
      SELECT 'DOM2' Customer, 'ZHA01' facility , 6500 TEU FROM dual UNION ALL      
      SELECT 'DOM2' Customer, 'ZHA02' facility , 6000 TEU FROM dual UNION ALL      
      SELECT 'DOM2' Customer, 'ZHA03' facility , 5000 TEU FROM dual UNION ALL      
      SELECT 'DOM2' Customer, 'ZHA04' facility , 3000 TEU FROM dual       
    )  
      
    SELECT * FROM (  
    SELECT t.Customer, t.facility, SUM(TEU) EU FROM CO_ORDER t  
    GROUP BY t.Customer, t.facility  
    ) t pivot(SUM(t.EU) FOR facility IN ('ZHA01', 'ZHA02', 'ZHA03', 'ZHA04'));  

改方式更加的简便，最重要的是，分列条件是动态的，不需要考虑取值的可能性，利于扩展。不过，PIVOT是Oracle 11g后才出现的，所以使用时要注意环境。
另外，列名是动态的，所以在select中写列名报错，这点不知道怎么解决，有高手的话帮忙看下。


4 多列求和
转列之后，很多时候需要对同一行中某些列求和。
    WITH CO_ORDER AS(      
      SELECT 'DOM1' Customer, 'ZHA01' facility , 4000 TEU FROM dual UNION ALL      
      SELECT 'DOM1' Customer, 'ZHA01' facility , 5000 TEU FROM dual UNION ALL      
      SELECT 'DOM1' Customer, 'ZHA02' facility , 9000 TEU FROM dual UNION ALL     
      SELECT 'DOM1' Customer, 'ZHA03' facility , 9000 TEU FROM dual UNION ALL    
      SELECT 'DOM1' Customer, 'ZHA04' facility , 4000 TEU FROM dual UNION ALL    
      SELECT 'DOM2' Customer, 'ZHA01' facility , 6500 TEU FROM dual UNION ALL      
      SELECT 'DOM2' Customer, 'ZHA02' facility , 6000 TEU FROM dual UNION ALL      
      SELECT 'DOM2' Customer, 'ZHA03' facility , 5000 TEU FROM dual UNION ALL      
      SELECT 'DOM2' Customer, 'ZHA04' facility , 3000 TEU FROM dual       
    )  
    select Customer,ZHA01,ZHA02,ZHA03,ZHA04,ZHA01+ZHA02+ZHA03 +ZHA04 as TOTAL from (  
    SELECT t.Customer, sum(decode(t.facility, 'ZHA01', t.teu)) AS ZHA01,  
           sum(decode(t.facility, 'ZHA02', t.teu)) AS ZHA02,  
           sum(decode(t.facility, 'ZHA03', t.teu)) AS ZHA03,  
           sum(decode(t.facility, 'ZHA04', t.teu)) AS ZHA04   
      FROM CO_ORDER t  
      group by t.Customer);  

5 WM_CONCAT
该函数用于把列值以逗号分隔显示成一行。如下：
    WITH CO_ORDER AS(      
      SELECT 'DOM1' Customer, 'ZHA01' facility , 4000 TEU FROM dual UNION ALL      
      SELECT 'DOM1' Customer, 'ZHA01' facility , 5000 TEU FROM dual UNION ALL      
      SELECT 'DOM1' Customer, 'ZHA02' facility , 9000 TEU FROM dual UNION ALL     
      SELECT 'DOM1' Customer, 'ZHA03' facility , 9000 TEU FROM dual UNION ALL    
      SELECT 'DOM1' Customer, 'ZHA04' facility , 4000 TEU FROM dual UNION ALL    
      SELECT 'DOM2' Customer, 'ZHA01' facility , 6500 TEU FROM dual UNION ALL      
      SELECT 'DOM2' Customer, 'ZHA02' facility , 6000 TEU FROM dual UNION ALL      
      SELECT 'DOM2' Customer, 'ZHA03' facility , 5000 TEU FROM dual UNION ALL      
      SELECT 'DOM2' Customer, 'ZHA04' facility , 3000 TEU FROM dual       
    )  
    SELECT Customer,WM_CONCAT(facility) ALL_FACILITY FROM CO_ORDER GROUP BY Customer;  


6 去重
例子中，(wb_id, reply, addre) 作为表的unique key， 如果(wb_id, reply, addre) 相同，保留字段TEU 最大值的记录。删除其他记录。
    WITH tt AS (  
      SELECT 'DOM1' wb_id, 'ZHA01' reply ,  'ZHA01' addre ,4000 TEU FROM dual UNION ALL        
      SELECT 'DOM1' wb_id, 'ZHA01' reply ,  'ZHA01' addre ,5000 TEU FROM dual UNION ALL  --- (wb_id, reply, addre)与上条记录相同，不过 TEU 更大，保留。  
      SELECT 'DOM1' wb_id, 'ZHA02' reply ,  'ZHA01' addre ,9000 TEU FROM dual UNION ALL       
      SELECT 'DOM2' wb_id, 'ZHA01' reply ,  'ZHA01' addre ,9000 TEU FROM dual UNION ALL      
      SELECT 'DOM2' wb_id, 'ZHA04' reply ,  'ZHA01' addre ,4000 TEU FROM dual UNION ALL      
      SELECT 'DOM2' wb_id, 'ZHA01' reply ,  'ZHA01' addre ,6500 TEU FROM dual           --- (wb_id, reply, addre)与第四条记录相同，不过 TEU 小，删除。  
    )  
      
    -- 选出待删除的数据集合  
    SELECT *  FROM tt  
    WHERE (wb_id, reply,addre) IN (SELECT wb_id, reply, addre FROM tt GROUP BY wb_id, reply, addre HAVING count(1) > 1)  
    AND (wb_id, reply,reply, TEU) NOT IN (SELECT wb_id, reply, addre, max(TEU) FROM tt group by wb_id, reply, addre)  
    ;  


7 列转行
上面说到用 PRIVOT 进行行转列，现在看下 UNPRIVOT 操作。从名字上看，就是 PRIVOT 加前缀 UN，意义不言而喻，就是进行列转行。先看例子。
    WITH CO_ORDER2 AS(        
      SELECT 'DOM1' Customer, 'office1'  ZHA02, 'office1' ZHA03, 'office2' ZHA04 FROM dual UNION ALL        
      SELECT 'DOM1' Customer, 'office2'  ZHA02, 'office3' ZHA03, 'office2' ZHA04 FROM dual UNION ALL          
      SELECT 'DOM2' Customer, 'office4'  ZHA02, 'office1' ZHA03, 'office2' ZHA04 FROM dual UNION ALL        
      SELECT 'DOM2' Customer, 'office3'  ZHA02, 'office1' ZHA03, 'office1' ZHA04 FROM dual         
    )  
    --SELECT * FROM CO_ORDER2   
    SELECT Customer, offcs, facility FROM CO_ORDER2 UNPIVOT (offcs FOR facility IN ( ZHA02, ZHA03, ZHA04) );    

首先数据原始结构如下：


而利用 UNPRIVOT 处理后，结果如下：
UNPRIVOT 帮我们生成了两个新列，一列用于存放 office1 之类的值，另一个新列存的是 这个数据来源于之前那个原始列名。
其实它做的很简单，就是对每行原始数据的指定列的每个格子进行遍历，生成一条条数据。将原有的结构进行打平。因此，
处理后数据的行数 = 原始数据行数  * 指定列数

因此上面 产生 了 12 条数据。

不过这也不是绝对的，当某个数据为空是，最终生成的数据会被 UNPRIVOT 给删除。看下面：
    WITH CO_ORDER2 AS(        
      SELECT 'DOM1' Customer, 'office1'  ZHA02, 'office1' ZHA03, 'office2' ZHA04 FROM dual UNION ALL        
      SELECT 'DOM1' Customer, 'office2'  ZHA02, '' ZHA03, 'office2' ZHA04 FROM dual UNION ALL          
      SELECT 'DOM2' Customer, 'office4'  ZHA02, 'office1' ZHA03, 'office2' ZHA04 FROM dual UNION ALL        
      SELECT 'DOM2' Customer, null  ZHA02, 'office1' ZHA03, 'office1' ZHA04 FROM dual         
    )  
    --SELECT * FROM CO_ORDER2   
    SELECT Customer, offcs, facility FROM CO_ORDER2 UNPIVOT (offcs FOR facility IN ( ZHA02, ZHA03, ZHA04) );   

此时下面只产生了 10 行数据。
在上面的 数据中，我们 给其中两个格子里面，一个为 空字符串，一个是 null。最终这两条数据没出现在结果集中。


26 mysql支持事务吗？
在缺省模式下，MYSQL是autocommit模式的，所有的数据库更新操作都会即时提交，所以在缺省情况下，mysql是不支持事务的。
但是如果你的MYSQL表类型是使用InnoDB Tables 或 BDB tables的话，你的MYSQL就可以使用事务处理,使用SET AUTOCOMMIT=0就可以使MYSQL允许在非autocommit模式，
在非autocommit模式下，你必须使用COMMIT来提交你的更改，或者用ROLLBACK来回滚你的更改。示例如下：
START TRANSACTION;


27 mysql 与其他数据库比较的特点？
MySQL是一个小型关系型数据库管理系统，开发者为瑞典MySQL AB公司，现在已经被Sun公司收购，支持FreeBSD、Linux、MAC、Windows等多种操作系统与其他的大型数据库例如Oracle、DB2、SQL Server等相比功能稍弱一些。其特点有：
1、可以处理拥有上千万条记录的大型数据；
2、支持常见的SQL语句规范；
3、可移植行高，安装简单小巧；
4、良好的运行效率，有丰富信息的网络支持；
5、调试、管理，优化简单（相对其他大型数据库）。


28 innodb中四种事务的隔离级别？
隔离级别	脏读（Dirty Read）	不可重复读（NonRepeatable Read）	幻读（Phantom Read）
未提交读（Read uncommitted）	可能	可能	可能
已提交读（Read committed）	不可能	可能	可能
可重复读（Repeatable read）	不可能	不可能	可能
可串行化（SERIALIZABLE）	不可能	不可能	不可能
脏读 :一个事务读取到另一事务未提交的更新数据
不可重复读 : 在同一事务中,多次读取同一数据返回的结果有所不同, 换句话说, 后续读取可以读到另一事务已提交的更新数据. 相反, “可重复读”在同一事务中多次读取数据时, 能够保证所读数据一样, 也就是后续读取不能读到另一事务已提交的更新数据。
幻读 :一个事务读到另一个事务已提交的insert数据


29 NVL与NVL2两个函数的使用方法和差别？
NVL2(expr1,expr2,expr3) 
功能：如果参数表达式expr1值为NULL，则NVL2()函数返回参数表达式expr3的值；如果参数表达式expr1值不为NULL，则NVL2()函数返回参数表达式expr2的值。
需要注意的是value1和value2要保持字段类型相同。

NVL( string1, replace_with) 
功能：如果string1为NULL，则NVL函数返回replace_with的值，否则返回string1的值，如果两个参数都为NULL ，则返回NULL。
需要注意的是参数value2 value3可以是除了LONG类型之外的任意数据类型


30 对字符串操作的函数?
一、字符转换函数
1、ASCII()
返回字符表达式最左端字符的ASCII 码值。在ASCII（）函数中，纯数字的字符串可不用‘’括起来，但含其它字符的字符串必须用‘’括起来使用，否则会出错。
2、CHAR()
将ASCII 码转换为字符。如果没有输入0 ~ 255 之间的ASCII 码值，CHAR（） 返回NULL 。
3、LOWER()和UPPER()
LOWER()将字符串全部转为小写；UPPER()将字符串全部转为大写。
4、STR()
把数值型数据转换为字符型数据。
STR (<float_expression>[，length[， <decimal>]])
length 指定返回的字符串的长度，decimal 指定返回的小数位数。如果没有指定长度，缺省的length 值为10， decimal 缺省值为0。
当length 或者decimal 为负值时，返回NULL；
当length 小于小数点左边（包括符号位）的位数时，返回length 个*；
先服从length ，再取decimal ；
当返回的字符串位数小于length ，左边补足空格。

二、去空格函数
1、LTRIM() 把字符串头部的空格去掉。
2、RTRIM() 把字符串尾部的空格去掉。

三、取子串函数
1、left()
LEFT (<character_expression>， <integer_expression>)
返回character_expression 左起 integer_expression 个字符。
2、RIGHT()
RIGHT (<character_expression>， <integer_expression>)
返回character_expression 右起 integer_expression 个字符。
3、SUBSTRING()
SUBSTRING (<expression>， <starting_ position>， length)
返回从字符串左边第starting_ position 个字符起length个字符的部分。

四、字符串比较函数
1、CHARINDEX()
返回字符串中某个指定的子串出现的开始位置。
CHARINDEX (<’substring_expression’>， <expression>)
其中substring _expression 是所要查找的字符表达式，expression 可为字符串也可为列名表达式。如果没有发现子串，则返回0 值。
此函数不能用于TEXT 和IMAGE 数据类型。
2、PATINDEX()
返回字符串中某个指定的子串出现的开始位置。
PATINDEX (<’%substring _expression%’>， <column_ name>)其中子串表达式前后必须有百分号“%”否则返回值为0。
与CHARINDEX 函数不同的是，PATINDEX函数的子串中可以使用通配符，且此函数可用于CHAR、 VARCHAR 和TEXT 数据类型。

五、字符串操作函数
1、QUOTENAME()
返回被特定字符括起来的字符串。
QUOTENAME (<’character_expression’>[， quote_ character]) 其中quote_ character 标明括字符串所用的字符，缺省值为“[]”。
2、REPLICATE()
返回一个重复character_expression 指定次数的字符串。
REPLICATE (character_expression integer_expression) 如果integer_expression 值为负值，则返回NULL 。
3、REVERSE()
将指定的字符串的字符排列顺序颠倒。
REVERSE (<character_expression>) 其中character_expression 可以是字符串、常数或一个列的值。
4、REPLACE()
返回被替换了指定子串的字符串。
REPLACE (<string_expression1>， <string_expression2>， <string_expression3>) 用string_expression3 替换在string_expression1 中的子串string_expression2。
4、SPACE()
返回一个有指定长度的空白字符串。
SPACE (<integer_expression>) 如果integer_expression 值为负值，则返回NULL 。
5、STUFF()
用另一子串替换字符串指定位置、长度的子串。
STUFF (<character_expression1>， <start_ position>， <length>，<character_expression2>)
如果起始位置为负或长度值为负，或者起始位置大于character_expression1 的长度，则返回NULL 值。
如果length 长度大于character_expression1 中 start_ position 以右的长度，则character_expression1 只保留首字符。

六、数据类型转换函数
1、CAST()
CAST (<expression> AS <data_ type>[ length ])
2、CONVERT()
CONVERT (<data_ type>[ length ]， <expression> [， style])
1）data_type为SQL Server系统定义的数据类型，用户自定义的数据类型不能在此使用。
2）length用于指定数据的长度，缺省值为30。
3）把CHAR或VARCHAR类型转换为诸如INT或SAMLLINT这样的INTEGER类型、结果必须是带正号或负号的数值。
4）TEXT类型到CHAR或VARCHAR类型转换最多为8000个字符，即CHAR或VARCHAR数据类型是最大长度。
5）IMAGE类型存储的数据转换到BINARY或VARBINARY类型，最多为8000个字符。
6）把整数值转换为MONEY或SMALLMONEY类型，按定义的国家的货币单位来处理，如人民币、美元、英镑等。
7）BIT类型的转换把非零值转换为1，并仍以BIT类型存储。
8）试图转换到不同长度的数据类型，会截短转换值并在转换值后显示“+”，以标识发生了这种截断。
9）用CONVERT（） 函数的style 选项能以不同的格式显示日期和时间。style 是将DATATIME 和SMALLDATETIME 数据转换为字符串时所选用的由SQL Server 系统提供的转换样式编号，不同的样式编号有不同的输出格式。

七、日期函数
1、day(date_expression)
返回date_expression中的日期值
2、month(date_expression)
返回date_expression中的月份值
3、year(date_expression)
返回date_expression中的年份值
4、DATEADD()
DATEADD (<datepart>， <number>， <date>)
返回指定日期date 加上指定的额外日期间隔number 产生的新日期。参数“datepart” 取值如下：
5、DATEDIFF()
DATEDIFF (<datepart>， <date1>， <date2>)
返回两个指定日期在datepart 方面的不同之处，即date2 超过date1的差距值，其结果值是一个带有正负号的整数值。
6、DATENAME()
DATENAME (<datepart>， <date>)
以字符串的形式返回日期的指定部分此部分。由datepart 来指定。
7、DATEPART()
DATEPART (<datepart>， <date>)
以整数值的形式返回日期的指定部分。此部分由datepart 来指定。
DATEPART (dd， date) 等同于DAY (date)
DATEPART (mm， date) 等同于MONTH (date)
DATEPART (yy， date) 等同于YEAR (date)
8、GETDATE()
以DATETIME 的缺省格式返回系统当前的日期和时间 


31 对于精通的数据库系统描述其数据一致性的保证机制,包括lock,事务一致性等？
对oracle 系统而言,描述sga的结构; 后台pmon,ckpt、lgwr,smon等进程的功能;表空间的分配策略; 回滚段的结构
oracle的sga（系统全局区）包括的主要区有：数据库缓存区，重做日志缓存区，共享池（数据字典缓存和库缓存），大池等。数据库缓存区用来存放最近使用过的数据块主要和后台进程中的数据库写进程(DBWR)以及数据文件发生关系；重做日志缓存区用于存放操作数据库数据所产生的重做日志信息，与之合作的有重做日志写进程(LGWR)和重做日志文件；共享池主要缓存SQL/PLSQL，资源锁，控制信息等，其中的库缓存主要缓存被解析执行过的SQL/PLSQL库缓存可分为共享SQL和私有SQL两个区，共享SQL用于存放SQL语句的语法分析结果和执行计划，私有SQL则用来存放与具体SQL语句执行有关的绑定变量，会话参数等。
ORACLE实例的另外一个重要部分就是其后台进程，主要的后台进程有：数据库写进程（DBWR），重做日志写进程（LGWR），系统监视器（SMON），进程监视器（PMON），检查点进程（CKPT）。DBWR主要是对数据库缓存区中的脏冷数据进行写入数据文件操作；LGWR主要是将对数据库数据操作所产生的重做日志信息写入到重做日志文件中；SMON完成由于非正常关闭数据库的情况下重起数据库时对数据库的恢复；PMON用来恢复失败的用户进程和服务进程，并释放其所占的系统资源；CKPT可以表示数据库在此出处于完整状态。
逻辑存储结构：数据块BLOCK，区EXTENT，段SEGMENT，表空间TABLESPACE
物理存储空间：表空间，数据文件，控制文件，日志文件，数据字典
软件体系结构就是上边对SGA和后台进程的描述。


32 一张表有10万条记录，如何删除其中的任意20条记录?请用SQL语句进行操作？
delete from ACT_EVT_LOG order by rand() limit 2 


33 介绍一下oracle的体系结构?
Oracle的体系结构中有这么几个概念：实例、表空间、数据文件、用户、表。
Oracle数据库不同其他数据库，Oracle可以理解为一个大的数据库，就只有这一个。你所操作的“多个数据库”都是Oracle数据库下的不同的实例。安装Oracle的时候会默认给你创建一个实例orcl。
表空间是一个逻辑概念，一个数据库实例可以有多个表空间。可以说表空间是对这个数据库实例物理磁盘内存上的划分，也许你平时使用的时候并没有创建表空间，因为这个时候使用的是系统默认的表空间，后面详说。一个表空间会创建多个数据文件，这是个一对多的关系。
数据文件是用来存储数据的，这个顾名思义。是什么数据？平时接触最多的是我们平时创建的表，create table...但是表的概念还不能从这里引出。先说用户。
我看有的理解是一个表空间下有很多个用户，这个理解可以说是勉强正确。因为我觉得用户和表空间并不是上司与下属的关系，算是同级吧，都是隶属于数据库实例的。只不过在创建用户的时候都要给用户指定一个表空间，授权该用户可以访问的表空间，他们的关系是多对一，多个用户可以访问一个表空间，但一个用户只能访问一个表空间。（总感觉这句话逻辑不顺）如果没有指明表空间，则是默认表空间users表空间。而表只能由用户来创建，用户将这个表放入与用户绑定的表空间，但最后管理表的存放的确是这个表空间，表空间随机的将表存放到它所在的一个或多个数据文件中。
需要特别指出的是：
在创建用户时是只能指明一个默认表空间和一个默认临时表空间，你后续create table都是在这个默认表空间中，但是可以更改。
alter user xx default tablespace xxxx
说到这差不多结构已经出来了，不知道你有没有晕，画个图梳理一下吧。


34 谈谈对oracle的row_ id是否理解?请简述?
ORACLE的row_id是一个伪列，其个是为18个字节可将这18个字节用6363来划分，分别表示段编号，数据文件编号，数据块编号和记录编号。
Row_id表示的是一个记录的物理存储地址。

35 如何判断游标已经到最后一行?
open my_cursor;
fetch my_cursor into last_row;
while my_cursor%found loop
      fetch my_cursor into current_row;
      if my_cursor%notfound then
         无条件插入last_row;
      else
         编辑last_row,插入;
         last_row := current_row;
      end if;
end loop;
close my_cursor;


36 简述Oracle的归档与不归档工作模式，分别说明。
1） 归档模式和非归档模式
在DBA部署数据库之初，必须要做出的最重要决定之一就是选择归档模式（ARCHIVELOG）或者非 归档模式（NOARCHIVELOG ）下运行数据库。我们知道，Oracle 数据库需要至少两组联机日志，每当一组 联机日志写满后会发生日志切换，继续向下一组联机日志写入。如果是归档模式，日志切换会触发归档进程 （ARCn）进行归档，生成归档日志。Oracle 保证归档完成前，联机日志不会被覆盖，如果是非归档模式， 则不会触发归档动作。
原文地址：http://blog.sunansheng.com/2016/04/29/archivelog-noarchivelog/

2） 归档模式的优缺点
归档日志文件中保留了数据库的改动信息。
在这种模式下可以获得如下好处:
可以进行完全、不完全恢复：由于对数据库所做的全部改动都记录在日志文件中，如果发生硬盘故 障等导致数据文件丢失的话，则可以利用物理备份和归档日志完全恢复数据库，不会丢失任何数据。
可以进行联机热备：所谓联机热备，就是在数据库运行状态下，对数据库进行备份。备份时用户对 数据库的使用不受任何影响。
可以实施 Data Guard：可以部署 1 个或多个备用数据库，从而最大限度地提供灾难保护手段。
可以实施 Stream：利用 Stream 技术，可以实现最简单的单向复制到复杂的双向复制、多向复制， 提供更加灵活的数据冗余方案。
表空间可以脱机：可以备份部分数据库，比如重要的表空间。
能够增量备份：只需做一次完全备份，以后只备份发生改变的数据，可以提高备份速度。
更多的优化选项：随着 Oracle 版本升级，在联机热备方面不断有新的优化策略出现。
使用归档模式的缺点在于：
需要更多的磁盘空间保存归档日志；
DBA 会有更多的管理工作，包括维护归档空间、备份归档日志。

3） 非归档模式的优缺点
非归档模式不生成归档日志，从数据安全角度来说，这种模式缺点是主要的，而优点可以忽略不计。
非归档模式的缺点包括：
只能进行脱机备份，也就是所谓的“ 冷备份”，和联机备份的“ 热备份” 相对应，数据库必须完全 关闭后备份，在备份过程中数据库不可用；
必须备份整个数据库，不能只备份部分数据库；
不能增量备份，对于 TB 级数据库（VLDB） ，这是一个非常大的缺点；
只能部分恢复，如果数据文件丢失需要恢复，DBA 只能恢复最后一次的完全备份，而之后的所有 数据库改变全部丢失。
非归档模式的优点包括：
DBA 的管理工作减少，因为非归档模式不产生归档日志，因此 DBA 不用考虑对归档的管理；

4） 性能会有提升。
非归档模式转换成归档模式
数据库创建过程中需要指定归档和非归档模式，如果选择的是非归档模式，可以在数据库创建完成后 手工改变成归档模式，具体操作步骤如下。
（1 ）关闭数据库：
shutdown immediate; 
（2 ）启动数据库到 mount 状态：
startup mount; 
（3 ）修改数据库归档模式：
alter database archivelog; 
（4 ）启动数据库：
alter database open; 
（5 ）定义归档位置，也就是归档日志保存路径：
alter syste set log_archive_dest_1="location=d:\oradata\example\archive" scope=both; 
（6 ）确认配置生效：
archive log list; 
---------------------------------------------------------------------------------------------------------------
------------------------------------------db basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------desingerpattern basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 设计模式（Design pattern）
一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了可重用代码、让代码更容易被他人理解、保证代码可靠性。 毫无疑问，设计模式于己于他人于系统都是多赢的，设计模式使代码编制真正工程化，设计模式是软件工程的基石，如同大厦的一块块砖石一样。项目中合理的运用设计模式可以完美的解决很多问题，每种模式在现在中都有相应的原理来与之对应，每一个模式描述了一个在我们周围不断重复发生的问题，以及该问题的核心解决方案，这也是它能被广泛应用的原因。
  健壮性：功能准确前提下，是否考虑兼容空指针/数据异常/违法检查/边界值？
  稳定性：
  性能性：如果数据量很大是否能够支撑，并发性高是否考虑？多表连接的索引是否建立？是否可以改变方案使性能最大化？
  安全性：接口是否有身份校验和数据加密？
  可读性：
  可扩展：如果需求改变了或者新增了是否好扩展，还是要全部推翻重来？
  可伸缩：面向接口,
  可复用：系统是否存在这样的工具类？会不会多个方法出现一样的代码？
  可维护：核心代码注释是否齐全，模块之间是否松耦合？
  可配置：是否能够动态配置，改变值可以不用修改代码？
高内聚低耦合：尽量使不同模块间少关联，即一个模块明确完成一个功能。但是一个模块内部又有许多子系统，子系统中的类之间不关联是不可能的，一个模块下的子系统要少用继承多用组合（使用组合时，就会使子系统的不同类之间产生关联）——总结一句话就是：模块之间要实现低耦合，模块下的类之间要多用组合少用继承。

2 继承（is a）
继承是Is a 的关系，比如说Student继承Person,则说明Student is a Person。继承的优点是子类可以重写父类的方法来方便地实现对父类的扩展。
继承的缺点有以下几点：
1：父类的内部细节对子类是可见的。
2：子类从父类继承的方法在编译时就确定下来了，所以无法在运行期间改变从父类继承的方法的行为。
3：子类与父类是一种高耦合，违背了面向对象思想。
4 ：继承关系最大的弱点是打破了封装，子类能够访问父类的实现细节，子类与父类之间紧密耦合，子类缺乏独立性，从而影响了子类的可维护性。
5：不支持动态继承。在运行时，子类无法选择不同的父类。

3 组合（has a）
电脑和显卡，不能说电脑继承了显卡，而是说显卡是计算机的组成部分之一，这就是组合。
1：不破坏封装，整体类与局部类之间松耦合，彼此相对独立。
2：具有较好的可扩展性。
3：支持动态组合。在运行时，整体对象可以选择不同类型的局部对象。


4 工厂方法模式
创建型模式，一个接口，几个实现类，一个接口工厂类，根据不同的参数创建不同的实例。但是增加子类需要修改工厂类。
应用实例： 1、您需要一辆汽车，可以直接从工厂里面提货，而不用去管这辆汽车是怎么做出来的，以及这个汽车里面的具体实现。 2、Hibernate 换数据库只需换方言和驱动就可以。

5 抽象工厂模式
创建型模式，一个接口，几个实现类，多个接口工厂类，工厂类各自产生自己的实例，增加子类不需要修改工厂类，只需要扩展子类实现类和子类工厂类即可。做到了开闭原则。
工厂方法模式有一个问题就是，类的创建依赖工厂类，也就是说，如果想要拓展程序，必须对工厂类进行修改，这违背了闭包原则，所以，从设计角度考虑，有一定的问题，如何解决？就用到抽象工厂模式，创建多个工厂类，这样一旦需要增加新的功能，直接增加新的工厂类就可以了，不需要修改之前的代码。

6 单例模式
（1）创建型模式，枚举创建单例模式线程安全的，一个jvm保证只有一个实例，对于一些大型的对象，这是一笔很大的系统开销，省去了new操作符，降低了系统内存的使用频率，减轻GC压力。有些类如交易所的核心交易引擎，控制着交易流程，如果该类可以创建多个的话，系统完全乱了。
单例模式和多例模式：有些系统层级的实例保证一个就够了，业务数据需要多个。
关键代码：构造函数是私有的。
应用实例： 1、一个党只能有一个主席。 2、Windows 是多进程多线程的，在操作一个文件的时候，就不可避免地出现多个进程或线程同时操作一个文件的现象，所以所有文件的处理必须通过唯一的实例来进行。 3、一些设备管理器常常设计为单例模式，比如一个电脑有两台打印机，在输出的时候就要处理不能两台打印机打印同一个文件。
优点： 1、在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例（比如管理学院首页页面缓存）。 2、避免对资源的多重占用（比如写文件操作）。
缺点：没有接口，不能继承，与单一职责原则冲突，一个类应该只关心内部逻辑，而不关心外面怎么样来实例化。
（2）实现方式
1）、懒汉式，线程不安全
是否 Lazy 初始化：是
是否多线程安全：否
实现难度：易
描述：这种方式是最基本的实现方式，这种实现最大的问题就是不支持多线程。因为没有加锁 synchronized，所以严格意义上它并不算单例模式。
这种方式 lazy loading 很明显，不要求线程安全，在多线程不能正常工作。
代码实例：
public class Singleton {  
    private static Singleton instance;  
    private Singleton (){}  
  
    public static Singleton getInstance() {  
    if (instance == null) {  
        instance = new Singleton();  
    }  
    return instance;  
    }  
}  
接下来介绍的几种实现方式都支持多线程，但是在性能上有所差异。
2）、懒汉式，线程安全
是否 Lazy 初始化：是
是否多线程安全：是
实现难度：易
描述：这种方式具备很好的 lazy loading，能够在多线程中很好的工作，但是，效率很低，99% 情况下不需要同步。
优点：第一次调用才初始化，避免内存浪费。
缺点：必须加锁 synchronized 才能保证单例，但加锁会影响效率。
getInstance() 的性能对应用程序不是很关键（该方法使用不太频繁）。
代码实例：
public class Singleton {  
    private static Singleton instance;  
    private Singleton (){}  
    public static synchronized Singleton getInstance() {  
    if (instance == null) {  
        instance = new Singleton();  
    }  
    return instance;  
    }  
} 
3）、饿汉式
是否 Lazy 初始化：否
是否多线程安全：是
实现难度：易
描述：这种方式比较常用，但容易产生垃圾对象。
优点：没有加锁，执行效率会提高。
缺点：类加载时就初始化，浪费内存。
它基于 classloder 机制避免了多线程的同步问题，不过，instance 在类装载时就实例化，虽然导致类装载的原因有很多种，在单例模式中大多数都是调用 getInstance 方法， 但是也不能确定有其他的方式（或者其他的静态方法）导致类装载，这时候初始化 instance 显然没有达到 lazy loading 的效果。
代码实例：
public class Singleton {  
    private static Singleton instance = new Singleton();  
    private Singleton (){}  
    public static Singleton getInstance() {  
    return instance;  
    }  
}  
4）、双检锁/双重校验锁（DCL，即 double-checked locking）
JDK 版本：JDK1.5 起
是否 Lazy 初始化：是
是否多线程安全：是
实现难度：较复杂
描述：这种方式采用双锁机制，安全且在多线程情况下能保持高性能。
getInstance() 的性能对应用程序很关键。
代码实例：
public class Singleton {  
    private volatile static Singleton singleton;  
    private Singleton (){}  
    public static Singleton getSingleton() {  
    if (singleton == null) {  
        synchronized (Singleton.class) {  
        if (singleton == null) {  
            singleton = new Singleton();  
        }  
        }  
    }  
    return singleton;  
    }  
}  
5）、登记式/静态内部类
是否 Lazy 初始化：是
是否多线程安全：是
实现难度：一般
描述：这种方式能达到双检锁方式一样的功效，但实现更简单。对静态域使用延迟初始化，应使用这种方式而不是双检锁方式。这种方式只适用于静态域的情况，双检锁方式可在实例域需要延迟初始化时使用。
这种方式同样利用了 classloder 机制来保证初始化 instance 时只有一个线程，它跟第 3 种方式不同的是：第 3 种方式只要 Singleton 类被装载了，那么 instance 就会被实例化（没有达到 lazy loading 效果），而这种方式是 Singleton 类被装载了，instance 不一定被初始化。因为 SingletonHolder 类没有被主动使用，只有显示通过调用 getInstance 方法时，才会显示装载 SingletonHolder 类，从而实例化 instance。想象一下，如果实例化 instance 很消耗资源，所以想让它延迟加载，另外一方面，又不希望在 Singleton 类加载时就实例化，因为不能确保 Singleton 类还可能在其他的地方被主动使用从而被加载，那么这个时候实例化 instance 显然是不合适的。这个时候，这种方式相比第 3 种方式就显得很合理。
代码实例：
public class Singleton {  
    private static class SingletonHolder {  
    private static final Singleton INSTANCE = new Singleton();  
    }  
    private Singleton (){}  
    public static final Singleton getInstance() {  
    return SingletonHolder.INSTANCE;  
    }  
}   
6） 通过enum关键字来实现枚举，在枚举中需要注意的有：
1. 序列化后可以保持单例 
2. 枚举中可以和java类一样定义方法
3. 枚举中的构造方法必须是私有的
4. 枚举默认是线程安全的 
	package com.hiya.dp.creator.singleton;
public class EnumSingleton
{
    public static EnumSingleton getSigleInstance()
    {
        return SigleInstance.INSTANCE.instance;
    }
    
    public enum SigleInstance
    {
        INSTANCE;
        private EnumSingleton instance;

        SigleInstance()
        {
            instance = new EnumSingleton();
        }
        public EnumSingleton getInstance()
        {
            return instance;
        }
    }
}
上面的类Resource是我们要应用单例模式的资源，具体可以表现为网络连接，数据库连接，线程池等等。 
获取资源的方式很简单，只要 SomeThing.INSTANCE.getInstance() 即可获得所要实例。下面我们来看看单例是如何被保证的： 


7 建造者模式（Builder）
建造者模式：是将一个复杂的对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。
工厂类模式提供的是创建单个类的模式，而建造者模式则是将各种产品集中起来进行管理，用来创建复合对象，所谓复合对象就是指某个类具有不同的属性，其实建造者模式就是前面抽象工厂模式和最后的Test结合起来得到的。
应用实例：
1、台式机，笔记本，平板各自有构建主机，构建输入输出，构建连接线的步骤产生对象。 
2、JAVA 中的 StringBuilder。
使用场景： 
1、需要生成的对象具有复杂的内部结构。 
2、需要生成的对象内部属性本身相互依赖。
与工厂模式的区别是：建造者模式更加关注与零件装配的顺序。

8 原型模式（Prototype）
在Java中原型模式变成clone()方法的使用，由于Java的纯洁的面向对象特性，使得在Java中使用设计模式变得很自然，两者已经几乎是浑然一体了。
（1）为了获取对象的一份拷贝，我们可以利用Object类的clone()方法。 
（2）在派生类中覆盖基类的clone()方法，并声明为public。 
（3）在派生类的clone()方法中，调用super.clone()。 
（4）在派生类中实现Cloneable接口。
在Java中，clone()方法是浅复制。
浅复制（浅克隆） ：被复制对象的所有变量都含有与原来的对象相同的值，而所有的对其他对象的引用仍然指向原来的对象。换言之，浅复制仅仅复制所考虑的对象，而不复制它所引用的对象。
深复制（深克隆）：被复制对象的所有变量都含有与原来的对象相同的值，除去那些引用其他对象的变量。那些引用其他对象的变量将指向被复制过的新对象，而不再是原有的那些被引用的对象。换言之，深复制把要复制的对象所引用的对象都复制了一遍。可以利用串行化来做深复制，所谓对象序列化就是将对象的状态转换成字节流，以后可以通过这些值再生成相同状态的对象

9 适配器模式
结构型模式, 在不修改原来两个模块代码的情况下,将两个不兼容的类融合在一起,有点像粘合剂,通过转换使得他们能够协作起来, 符合了开闭原则.将某个类的接口转换成客户端期望的另一个接口表示，目的是消除由于接口不匹配所造成的类的兼容性问题。主要分为三类：类的适配器模式、对象的适配器模式、接口的适配器模式。
类适配器通过继承,是静态的定义方式，当希望将一个类转换成满足另一个新接口的类时，可以使用类的适配器模式，创建一个新类，继承原有的类，实现新的接口即可
对象适配器通过代理,是动态组合的方式。当希望将一个对象转换成满足另一个新接口的对象时，可以创建一个Wrapper类，持有原类的一个实例，在Wrapper类的方法中，调用实例的方法就行。
接口配器，当不希望实现一个接口中所有的方法时，可以创建一个抽象类Wrapper，实现所有方法，我们写别的类的时候，继承抽象类即可。

10 桥接模式
桥接（Bridge）是用于把抽象化与实现化解耦，使得二者可以独立变化。这种类型的设计模式属于结构型模式，它通过提供抽象化和实现化之间的桥接结构，来实现二者的解耦。两个维度变化。
使用场景： 
1、如果一个系统需要在构件的抽象化角色和具体化角色之间增加更多的灵活性，避免在两个层次之间建立静态的继承联系，通过桥接模式可以使它们在抽象层建立一个关联关系。 
2、对于那些不希望使用继承或因为多层次继承导致系统类的个数急剧增加的系统，桥接模式尤为适用。 
3、一个类存在两个独立变化的维度，且这两个维度都需要进行扩展。
注意事项：对于两个独立变化的维度，使用桥接模式再适合不过了。
当一个维度平等关系用接口（邮件/短信/系统消息），另外一个维度递进后者依赖的用抽象类（普通/紧急/特急）

11 过滤器模式
过滤器模式（Filter Pattern）或标准模式（Criteria Pattern）是一种设计模式，这种模式允许开发人员使用不同的标准来过滤一组对象，通过逻辑运算以解耦的方式把它们连接起来。这种类型的设计模式属于结构型模式，它结合多个标准来获得单一标准

12 组合模式
组合模式（Composite Pattern），又叫部分整体模式，是用于把一组相似的对象当作一个单一的对象。组合模式依据树形结构来组合对象，用来表示部分以及整体层次。这种类型的设计模式属于结构型模式，它创建了对象组的树形结构。
关键代码：树枝内部组合该接口，并且含有内部属性 List，里面放 Component。

13 装饰器模式
相似的模式，拦截方法增加前后的逻辑
装饰模式就是给一个对象增加一些新的功能，而且是动态。
装饰器模式（Decorator Pattern）允许向一个现有的对象添加新的功能，同时又不改变其结构。这种类型的设计模式属于结构型模式，它是作为现有的类的一个包装。
这种模式创建了一个装饰类，用来包装原有的类，并在保持类方法签名完整性的前提下，提供了额外的功能。
使用场景： 1、扩展一个类的功能。 2、动态增加功能，动态撤销。
注意事项：可代替继承。

14 外观模式
外观模式（Facade Pattern）隐藏系统的复杂性，并向客户端提供了一个客户端可以访问系统的接口。这种类型的设计模式属于结构型模式，它向现有的系统添加一个接口，来隐藏系统的复杂性。
这种模式涉及到一个单一的类，该类提供了客户端请求的简化方法和对现有系统类方法的委托调用。
主要解决：降低访问复杂系统的内部子系统时的复杂度，简化客户端与之的接口。客户端不需要知道系统内部的复杂联系，整个系统只需提供一个"接待员"即可。
应用实例： 1、去医院看病，可能要去挂号、门诊、划价、取药，让患者或患者家属觉得很复杂，如果有提供接待人员，只让接待人员来处理，就很方便。
优点： 1、减少系统相互依赖。 2、提高灵活性。 3、提高了安全性。
缺点：不符合开闭原则，如果要改东西很麻烦，继承重写都不合适。
使用场景： 1、为复杂的模块或子系统提供外界访问的模块。 2、子系统相对独立。 3、预防低水平人员带来的风险。

15 享元模式
享元模式（Flyweight Pattern）主要用于减少创建对象的数量，以减少内存占用和提高性能。这种类型的设计模式属于结构型模式，它提供了减少对象数量从而改善应用所需的对象结构的方式。
享元模式尝试重用现有的同类对象，如果未找到匹配的对象，则创建新对象。我们将通过创建 5 个对象来画出 20 个分布于不同位置的圆来演示这种模式。由于只有 5 种可用的颜色，所以 color 属性被用来检查现有的 Circle 对象。
何时使用： 1、系统中有大量对象。 2、这些对象消耗大量内存。 3、这些对象的状态大部分可以外部化。 4、这些对象可以按照内蕴状态分为很多组，当把外蕴对象从对象中剔除出来时，每一组对象都可以用一个对象来代替。 5、系统不依赖于这些对象身份，这些对象是不可分辨的。
如何解决：用唯一标识码判断，如果在内存中有，则返回这个唯一标识码所标识的对象。
关键代码：用 HashMap 存储这些对象。
应用实例： 1、JAVA 中的 String，如果有则返回，如果没有则创建一个字符串保存在字符串缓存池里面。 2、数据库的数据池。3、int和Integer 
优点：大大减少对象的创建，降低系统的内存，使效率提高。
缺点：提高了系统的复杂度，需要分离出外部状态和内部状态，而且外部状态具有固有化的性质，不应该随着内部状态的变化而变化，否则会造成系统的混乱。

16代理模式
（1）静态代理
在代理模式（Proxy Pattern）中，一个类代表另一个类的功能。这种类型的设计模式属于结构型模式。
在代理模式中，我们创建具有现有对象的对象，以便向外界提供功能接口。
意图：为其他对象提供一种代理以控制对这个对象的访问。
主要解决：在直接访问对象时带来的问题，比如说：要访问的对象在远程的机器上。在面向对象系统中，有些对象由于某些原因（比如对象创建开销很大，或者某些操作需要安全控制，或者需要进程外的访问），直接访问会给使用者或者系统结构带来很多麻烦，我们可以在访问此对象时加上一个对此对象的访问层。
应用实例： 1、Windows 里面的快捷方式。 2、猪八戒去找高翠兰结果是孙悟空变的，可以这样理解：把高翠兰的外貌抽象出来，高翠兰本人和孙悟空都实现了这个接口，猪八戒访问高翠兰的时候看不出来这个是孙悟空，所以说孙悟空是高翠兰代理类。 3、买火车票不一定在火车站买，也可以去代售点。 4、一张支票或银行存单是账户中资金的代理。支票在市场交易中用来代替现金，并提供对签发人账号上资金的控制。 5、spring aop。 
和装饰器模式的区别：装饰器模式为了增强功能，而代理模式是为了加以控制或者增强。
（2）静态代理和动态代理 
静态代理通常用于对原有业务逻辑的扩充。比如持有二方包的某个类，并调用了其中的某些方法。然后出于某种原因，比如记录日志、打印方法执行时间，但是又不好将这些逻辑写入二方包的方法里。
所以可以创建一个代理类实现和二方方法相同的方法，通过让代理类持有真实对象，然后在原代码中调用代理类方法，来达到添加我们需要业务逻辑的目的。
这其实也就是代理模式的一种实现，通过对真实对象的封装，来实现扩展性。
（3）动态代理
搞清楚静态代理的缺点十分重要，因为动态代理的目的就是为了解决静态代理的缺点。通过使用动态代理，我们可以通过在运行时，动态生成一个持有RealObject、并实现代理接口的Proxy，
同时注入我们相同的扩展逻辑。哪怕你要代理的RealObject是不同的对象，甚至代理不同的方法，都可以动过动态代理，来扩展功能。
public class DynamicProxyHandler implements InvocationHandler 
{
    private Object realObject;
    public DynamicProxyHandler(Object realObject) {
        this.realObject = realObject;
    }
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        //代理扩展逻辑
        System.out.println("proxy do");
        return method.invoke(realObject, args);
    }
}
这个Handler中的invoke方法中实现了代理类要扩展的公共功能。
到这里，需要先看一下这个handler的用法：
public static void main(String[] args) {
        RealObject realObject = new RealObject();
        Action proxy = 
(Action) Proxy.newProxyInstance(ClassLoader.getSystemClassLoader(), new Class[]{Action.class}, new DynamicProxyHandler(realObject));
        proxy.doSomething();
}
Proxy.newProxyInstance 传入的是一个ClassLoader， 一个代理接口，和我们定义的handler，返回的是一个Proxy的实例。
仔细体会这个过程，其实有点类似我们在静态代理中提到的方案一，生成了一个包含我们扩展功能，持有RealObject引用，实现Action接口的代理实例Proxy。只不过这个Proxy不是我们自己写的，而是java帮我们生成的，有没有一点动态的味道。

17 责任链模式
顾名思义，责任链模式（Chain of Responsibility Pattern）为请求创建了一个接收者对象的链。这种模式给予请求的类型，对请求的发送者和接收者进行解耦。这种类型的设计模式属于行为型模式。
在这种模式中，通常每个接收者都包含对另一个接收者的引用。如果一个对象不能处理该请求，那么它会把相同的请求传给下一个接收者，依此类推。
关键代码：Handler 里面聚合它自己，在 HanleRequest 里判断是否合适，如果没达到条件则向下传递，向谁传递之前 set 进去。
应用实例： activiti的下一步 
使用场景： 1、有多个对象可以处理同一个请求，具体哪个对象处理该请求由运行时刻自动确定。 2、在不明确指定接收者的情况下，向多个对象中的一个提交一个请求。 3、可动态指定一组对象处理请求。
注意事项：在 JAVA WEB 中遇到很多应用。

18 命令模式
命令模式（Command Pattern）是一种数据驱动的设计模式，它属于行为型模式。请求以命令的形式包裹在对象中，并传给调用对象。调用对象寻找可以处理该命令的合适的对象，并把该命令传给相应的对象，该对象执行命令。
主要解决：在软件系统中，行为请求者与行为实现者通常是一种紧耦合的关系，但某些场合，比如需要对行为进行记录、撤销或重做、事务等处理时，这种无法抵御变化的紧耦合的设计就不太合适。
何时使用：在某些场合，比如要对行为进行"记录、撤销/重做、事务"等处理，这种无法抵御变化的紧耦合是不合适的。在这种情况下，如何将"行为请求者"与"行为实现者"解耦？将一组行为抽象为对象，可以实现二者之间的松耦合。
适用情况
1.系统需要将请求调用者和请求接收者解耦，使得调用者和接收者不直接交互。
2.系统需要在不同的时间指定请求、将请求排队和执行请求。
3.系统需要支持命令的撤销(Undo)操作和恢复(Redo)操作。
4.系统需要将一组操作组合在一起，即支持宏命令。
角色
Command
定义命令的接口，声明执行的方法。
ConcreteCommand
命令接口实现对象，是“虚”的实现；通常会持有接收者，并调用接收者的功能来完成命令要执行的操作。
Receiver
接收者，真正执行命令的对象。任何类都可能成为一个接收者，只要它能够实现命令要求实现的相应功能。
Invoker
要求命令对象执行请求，通常会持有命令对象，可以持有很多的命令对象。这个是客户端真正触发命令并要求命令执行相应操作的地方，也就是说相当于使用命令对象的入口。
Client
创建具体的命令对象，并且设置命令对象的接收者。注意这个不是我们常规意义上的客户端，而是在组装命令对象和接收者，或许，把这个Client称为装配者会更好理解，因为真正使用命令的客户端是从Invoker来触发执行。

19 解释器模式
解释器模式（Interpreter Pattern）提供了评估语言的语法或表达式的方式，它属于行为型模式。这种模式实现了一个表达式接口，该接口解释一个特定的上下文。这种模式被用在 SQL 解析、符号处理引擎等。
意图：给定一个语言，定义它的文法表示，并定义一个解释器，这个解释器使用该标识来解释语言中的句子。
主要解决：对于一些固定文法构建一个解释句子的解释器。
何时使用：如果一种特定类型的问题发生的频率足够高，那么可能就值得将该问题的各个实例表述为一个简单语言中的句子。这样就可以构建一个解释器，该解释器通过解释这些句子来解决该问题。
如何解决：构件语法树，定义终结符与非终结符。
关键代码：构件环境类，包含解释器之外的一些全局信息，一般是 HashMap。
应用实例：编译器、运算表达式计算。
优点： 1、可扩展性比较好，灵活。 2、增加了新的解释表达式的方式。 3、易于实现简单文法。
缺点： 1、可利用场景比较少。 2、对于复杂的文法比较难维护。 3、解释器模式会引起类膨胀。 4、解释器模式采用递归调用方法。
使用场景： 1、可以将一个需要解释执行的语言中的句子表示为一个抽象语法树。 2、一些重复出现的问题可以用一种简单的语言来进行表达。 3、一个简单语法需要解释的场景。
注意事项：可利用场景比较少，JAVA 中如果碰到可以用 expression4J 代替。

20 迭代器模式
迭代器模式（Iterator Pattern）是 Java 和 .Net 编程环境中非常常用的设计模式。这种模式用于顺序访问集合对象的元素，不需要知道集合对象的底层表示。
迭代器模式属于行为型模式。
意图：提供一种方法顺序访问一个聚合对象中各个元素, 而又无须暴露该对象的内部表示。
如何解决：把在元素之间游走的责任交给迭代器，而不是聚合对象。
关键代码：定义接口：hasNext, next。
应用实例：JAVA 中的 iterator。
注意事项：迭代器模式就是分离了集合对象的遍历行为，抽象出一个迭代器类来负责，这样既可以做到不暴露集合的内部结构，又可让外部代码透明地访问集合内部的数据。

21 中介者模式
中介者模式（Mediator Pattern）是用来降低多个对象和类之间的通信复杂性。这种模式提供了一个中介类，该类通常处理不同类之间的通信，并支持松耦合，使代码易于维护。中介者模式属于行为型模式。
主要解决：对象与对象之间存在大量的关联关系，这样势必会导致系统的结构变得很复杂，同时若一个对象发生改变，我们也需要跟踪与之相关联的对象，同时做出相应的处理。
应用实例： 1、中国加入 WTO 之前是各个国家相互贸易，结构复杂，现在是各个国家通过 WTO 来互相贸易。 2、机场调度系统。 3、MVC 框架，其中C（控制器）就是 M（模型）和 V（视图）的中介者。
优点： 1、降低了类的复杂度，将一对多转化成了一对一。 2、各个类之间的解耦。 3、符合迪米特原则。
中介者就是一个处于众多对象中间，并恰当地处理众多对象之间相互之间的联系的角色。以上代码中只有两个参与者类，但是这些我们都可以根据中介者模式的宗旨进行适当地扩展，即增加参与者类，然后中介者就得担负更加重的任务了，我们看到上面具体中介者类Mediator中的方法比较多而且有点乱。 所以，在解耦参与者类之间的联系的同时，中介者自身也不免任务过重，因为几乎所有的业务逻辑都交代到中介者身上了，可谓是“万众期待”的一个角色了。这就是中介者模式的不足之处了。此外，上面这个代码例子的参与者的属性和方法都是一样的，我们可以抽取一个抽象类出来，减少代码，但是有时候我们根本抽取不了多个“参与者”之间的共性来形成一个抽象类，这也大大增加了中介者模式的使用难度。 
 
22 备忘录模式
备忘录模式（Memento Pattern）保存一个对象的某个状态，以便在适当的时候恢复对象。备忘录模式属于行为型模式。
主要解决：所谓备忘录模式就是在不破坏封装的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，这样可以在以后将对象恢复到原先保存的状态。
何时使用：很多时候我们总是需要记录一个对象的内部状态，这样做的目的就是为了允许用户取消不确定或者错误的操作，能够恢复到他原先的状态，使得他有"后悔药"可吃。
如何解决：通过一个备忘录类专门存储对象状态。
关键代码：客户不与备忘录类耦合，与备忘录管理类耦合。
应用实例： 1、后悔药。 2、打游戏时的存档。 3、Windows 里的 ctri + z。 4、IE 中的后退。 4、数据库的事务管理。
优点： 1、给用户提供了一种可以恢复状态的机制，可以使用户能够比较方便地回到某个历史的状态。 2、实现了信息的封装，使得用户不需要关心状态的保存细节。
缺点：消耗资源。如果类的成员变量过多，势必会占用比较大的资源，而且每一次保存都会消耗一定的内存。
使用场景： 1、需要保存/恢复数据的相关状态场景。 2、提供一个可回滚的操作。
注意事项： 1、为了符合迪米特原则，还要增加一个管理备忘录的类。 2、为了节约内存，可使用原型模式+备忘录模式。

23 观察者模式
当对象间存在一对多关系时，则使用观察者模式（Observer Pattern）。比如，当一个对象被修改时，则会自动通知它的依赖对象。观察者模式属于行为型模式。
意图：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。
主要解决：一个对象状态改变给其他对象通知的问题，而且要考虑到易用和低耦合，保证高度的协作。
应用实例： 1、拍卖的时候，拍卖师观察最高标价，然后通知给其他竞价者竞价。 2、西游记里面悟空请求菩萨降服红孩儿，菩萨洒了一地水招来一个老乌龟，这个乌龟就是观察者，他观察菩萨洒水这个动作。
使用场景： 1、有多个子类共有的方法，且逻辑相同。 2、重要的、复杂的方法，可以考虑作为模板方法。
注意事项： 1、JAVA 中已经有了对观察者模式的支持类。 2、避免循环引用。 3、如果顺序执行，某一观察者错误会导致系统卡壳，一般采用异步方式。

24 状态模式
在状态模式（State Pattern）中，类的行为是基于它的状态改变的。这种类型的设计模式属于行为型模式。在状态模式中，我们创建表示各种状态的对象和一个行为随着状态对象改变而改变的 context 对象。
意图：允许对象在内部状态发生改变时改变它的行为，对象看起来好像修改了它的类。
主要解决：对象的行为依赖于它的状态（属性），并且可以根据它的状态改变而改变它的相关行为。
何时使用：代码中包含大量与对象状态有关的条件语句。
如何解决：将各种具体的状态类抽象出来。
关键代码：通常命令模式的接口中只有一个方法。而状态模式的接口中有一个或者多个方法。而且，状态模式的实现类的方法，一般返回值，或者是改变实例变量的值。也就是说，状态模式一般和对象的状态有关。实现类的方法有不同的功能，覆盖接口中的方法。状态模式和命令模式一样，也可以用于消除 if...else 等条件选择语句。
应用实例： 1、打篮球的时候运动员可以有正常状态、不正常状态和超常状态。 2、曾侯乙编钟中，'钟是抽象接口','钟A'等是具体状态，'曾侯乙编钟'是具体环境（Context）。

25 空对象模式
在空对象模式（Null Object Pattern）中，一个空对象取代 NULL 对象实例的检查。Null 对象不是检查空值，而是反应一个不做任何动作的关系。这样的 Null 对象也可以在数据不可用的时候提供默认的行为。在空对象模式中，我们创建一个指定各种要执行的操作的抽象类和扩展该类的实体类，还创建一个未对该类做任何实现的空对象类，该空对象类将无缝地使用在需要检查空值的地方。

26 策略模式
在策略模式（Strategy Pattern）中，一个类的行为或其算法可以在运行时更改。这种类型的设计模式属于行为型模式。在策略模式中，我们创建表示各种策略的对象和一个行为随着策略对象改变而改变的 context 对象。策略对象改变 context 对象的执行算法。
意图：定义一系列的算法,把它们一个个封装起来, 并且使它们可相互替换。
主要解决：在有多种算法相似的情况下，使用 if...else 所带来的复杂和难以维护。
策略模式是对算法的包装，是把使用算法的责任和算法本身分割开来，委派给不同的对象管理。策略模式通常把一个系列的算法包装到一系列的策略类里面，作为一个抽象策略类的子类。用一句话来说，就是：“准备一组算法，并将每一个算法封装起来，使得它们可以互换”。
　　●　环境(Context)角色：持有一个Strategy的引用。
　　●　抽象策略(Strategy)角色：这是一个抽象角色，通常由一个接口或抽象类实现。此角色给出所有的具体策略类所需的接口。
　　●　具体策略(ConcreteStrategy)角色：包装了相关的算法或行为

27 模板模式
在模板模式（Template Pattern）中，一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。这种类型的设计模式属于行为型模式。
意图：定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。
应用实例： 1、在造房子的时候，地基、走线、水管都一样，只有在建筑的后期才有加壁橱加栅栏等差异。 2、西游记里面菩萨定好的 81 难，这就是一个顶层的逻辑骨架。 3、spring 中对 Hibernate 的支持，将一些已经定好的方法封装起来，比如开启事务、获取 Session、关闭 Session 等，程序员不重复写那些已经规范好的代码，直接丢一个实体就可以保存。
优点： 1、封装不变部分，扩展可变部分。 2、提取公共代码，便于维护。 3、行为由父类控制，子类实现。

28 访问者模式
在访问者模式（Visitor Pattern）中，我们使用了一个访问者类，它改变了元素类的执行算法。通过这种方式，元素的执行算法可以随着访问者改变而改变。这种类型的设计模式属于行为型模式。根据模式，元素对象已接受访问者对象，这样访问者对象就可以处理元素对象上的操作。
意图：主要将数据结构与数据操作分离。
主要解决：稳定的数据结构和易变的操作耦合问题。
何时使用：需要对一个对象结构中的对象进行很多不同的并且不相关的操作，而需要避免让这些操作"污染"这些对象的类，使用访问者模式将这些封装到类中。
如何解决：在被访问的类里面加一个对外提供接待访问者的接口。
关键代码：在数据基础类里面有一个方法接受访问者，将自身引用传入访问者。
应用实例：您在朋友家做客，您是访问者，朋友接受您的访问，您通过朋友的描述，然后对朋友的描述做出一个判断，这就是访问者模式。
优点： 1、符合单一职责原则。 2、优秀的扩展性。 3、灵活性。
缺点： 1、具体元素对访问者公布细节，违反了迪米特原则。 2、具体元素变更比较困难。 3、违反了依赖倒置原则，依赖了具体类，没有依赖抽象。
使用场景： 1、对象结构中对象对应的类很少改变，但经常需要在此对象结构上定义新的操作。 2、需要对一个对象结构中的对象进行很多不同的并且不相关的操作，而需要避免让这些操作"污染"这些对象的类，也不希望在增加新操作时修改这些类。
注意事项：访问者可以对功能进行统一，可以做报表、UI、拦截器与过滤器。





二、ms相关
1．接口是什么？为什么要使用接口而不是直接使用具体类？
接口用于定义 API。它定义了类必须得遵循的规则。同时，它提供了一种抽象，因为客户端只使用接口，这样可以有多重实现，如 List 接口，你可以使用可随机访问的 ArrayList，也可以使用方便插入和删除的 LinkedList。接口中不允许写代码，以此来保证抽象，但是 Java 8 中你可以在接口声明静态的默认方法，这种方法是具体的。

2.java中，抽象类与接口之间有什么区别？
1）.一个类可以实现多个接口 ，但却只能继承最多一个抽象类。
2）.抽象类可以包含具体的方法 ， 接口的所有方法都是抽象的。
3）.抽象类可以声明和使用字段 ，接口则不能，但接口可以创建静态的final常量。
4）.接口的方法都是public的，抽象类的方法可以是public，protected，private或者默认的package；
5）.抽象类可以定义构造函数，接口却不能。

3.除了单例模式，你在生产环境中还用过什么设计模式？
这需要根据你的经验来回答。一般情况下，你可以说依赖注入，工厂模式，装饰模式或者观察者模式，随意选择你使用过的一种即可。不过你要准备回答接下的基于你选择的模式的问题。

4.什么是里氏替换原则？
1）开闭原则（Open Close Principle）
开闭原则就是说对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。所以一句话概括就是：为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类，后面的具体设计中我们会提到这点。
2）里氏代换原则（Liskov Substitution Principle）
里氏代换原则(Liskov Substitution Principle LSP)面向对象设计的基本原则之一。 里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。 LSP是继承复用的基石，只有当衍生类可以替换掉基类，软件单位的功能不受到影响时，基类才能真正被复用，而衍生类也能够在基类的基础上增加新的行为。里氏代换原则是对“开-闭”原则的补充。实现“开-闭”原则的关键步骤就是抽象化。而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。—— From Baidu 百科
3）依赖倒转原则（Dependence Inversion Principle）
这个是开闭原则的基础，具体内容：真对接口编程，依赖于抽象而不依赖于具体。
4）接口隔离原则（Interface Segregation Principle）
这个原则的意思是：使用多个隔离的接口，比使用单个接口要好。还是一个降低类之间的耦合度的意思，从这儿我们看出，其实设计模式就是一个软件的设计思想，从大型软件架构出发，为了升级和维护方便。所以上文中多次出现：降低依赖，降低耦合。
5）迪米特法则（最少知道原则）（Demeter Principle）
为什么叫最少知道原则，就是说：一个实体应当尽量少的与其他实体之间发生相互作用，使得系统功能模块相对独立。
6）合成复用原则（Composite Reuse Principle）
原则是尽量使用合成/聚合的方式，而不是使用继承

5.什么情况下会违反迪米特法则？为什么会有这个问题？
迪米特法则建议“只和朋友说话，不要陌生人说话”，以此来减少类之间的耦合。

6.适配器模式是什么？什么时候使用？
适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁。这种类型的设计模式属于结构型模式，它结合了两个独立接口的功能。适配器模式提供对接口的转换。如果你的客户端使用某些接口，但是你有另外一些接口，你就可以写一个适配去来连接这些接口。

7.适配器模式与装饰器模式有什么区别？
虽然适配器模式和装饰器模式的结构类似，但是每种模式的出现意图不同。适配器模式被用于桥接两个接口，而装饰模式的目的是在不修改类的情况下给类增加新的功能。
装饰者模式：动态地将责任附加到对象上，若要扩展功能，装饰者模提供了比继承更有弹性的替代方案。
通俗的解释：装饰模式就是给一个对象增加一些新的功能，而且是动态的，要求装饰对象和被装饰对象实现同一个接口，装饰对象持有被装饰对象的实例。
适配器模式：将一个类的接口，转换成客户期望的另一个接口。适配器让原本接口不兼容的类可以合作无间。
适配器模式有三种：类的适配器模式、对象的适配器模式、接口的适配器模式。
通俗的说法：适配器模式将某个类的接口转换成客户端期望的另一个接口表示，目的是消除由于接口不匹配所造成的类的兼容性问题。
举例如下：
1）适配器模式
FileInputStream fileInput = new FileInputStream(file);
InputStreamReader inputStreamReader = new InputStreamReader(fileInput);
以上就是适配器模式的体现，FileInputStream是字节流，而并没有字符流读取字符的一些api，因此通过InputStreamReader将其转为Reader子类，因此有了可以操作文本的文件方法。
2）装饰者模式
BufferedReader bufferedReader=new BufferedReader(inputStreamReader);构造了缓冲字符流，将FileInputStream字节流包装为BufferedReader过程就是装饰的过程，刚开始的字节流FileInputStream只有read一个字节的方法，包装为inputStreamReader后，就有了读取一个字符的功能，在包装为BufferedReader后，就拥有了read一行字符的功能。

8.适配器模式和代理模式之间有什么不同？
这个问题与前面的类似，适配器模式和代理模式的区别在于他们的意图不同。由于适配器模式和代理模式都是封装真正执行动作的类，因此结构是一致的，但是适配器模式用于接口之间的转换，而代理模式则是增加一个额外的中间层，以便支持分配、控制或智能访问。

9.什么是模板方法模式？
模板方法提供算法的框架，你可以自己去配置或定义步骤。例如，你可以将排序算法看做是一个模板。它定义了排序的步骤，但是具体的比较，可以使用 Comparable 或者其语言中类似东西，具体策略由你去配置。列出算法概要的方法就是众所周知的模板方法。

10.什么时候使用访问者模式？
访问者模式用于解决在类的继承层次上增加操作，但是不直接与之关联。这种模式采用双派发的形式来增加中间层。

11.什么时候使用组合模式？
组合模式使用树结构来展示部分与整体继承关系。它允许客户端采用统一的形式来对待单个对象和对象容器。当你想要展示对象这种部分与整体的继承关系时采用组合模式。

12.继承和组合之间有什么不同？
虽然两种都可以实现代码复用，但是组合比继承共灵活，因为组合允许你在运行时选择不同的实现。用组合实现的代码也比继承测试起来更加简单。

13.描述Java中的重载与重写？什么时候用重载，什么时候用重写？
重载和重写都允许你用相同的名称来实现不同的功能，但是重载是编译时活动，而重写是运行时活动。你可以在同一个类中重载方法，但是只能在子类中重写方法。重写必须要有继承。
对有经验的Java设计师来说，这是一个相当简单的问题。如果你看到一个类的不同实现有着不同的方式来做同一件事，那么就应该用重写（overriding），而重载（overloading）是用不同的输入做同一件事。在Java中，重载的方法签名不同，而重写并不是。

14.Java中，嵌套公共静态类与顶级类有什么不同？
类的内部可以有多个嵌套公共静态类，但是一个 Java 源文件只能有一个顶级公共类，并且顶级公共类的名称与源文件名称必须一致。

15.OOP中的组合、聚合和关联有什么区别？
如果两个对象彼此有关系，就说他们是彼此相关联的。组合和聚合是面向对象中的两种形式的关联。组合是一种比聚合更强力的关联。组合中，一个对象是另一个的拥有者，而聚合则是指一个对象使用另一个对象。如果对象 A 是由对象 B 组合的，则 A 不存在的话，B一定不存在，但是如果 A 对象聚合了一个对象 B，则即使 A 不存在了，B 也可以单独存在。

16.给我一个符合开闭原则的设计模式的例子？
开闭原则要求你的代码对扩展开放，对修改关闭。这个意思就是说，如果你想增加一个新的功能，你可以很容易的在不改变已测试过的代码的前提下增加新的代码。有好几个设计模式是基于开闭原则的，如策略模式，如果你需要一个新的策略，只需要实现接口，增加配置，不需要改变核心逻辑。一个正在工作的例子是 Collections.sort() 方法，这就是基于策略模式，遵循开闭原则的，你不需为新的对象修改 sort() 方法，你需要做的仅仅是实现你自己的 Comparator 接口。

17.使用工厂模式最主要的好处是什么？你在哪里使用？
工厂模式的最大好处是增加了创建对象时的封装层次。如果 你使用工厂来创建对象，之后你可以使用更高级和更高性能的实现来替换原始的产品实现或类，这不需要在调用层做任何修改。可以看我的文章工厂模式得更详细的解释和和了解更多的好处。

18.工厂模式与抽象工厂模式的区别？
首先来看看这两者的定义区别：
工厂模式：定义一个用于创建对象的借口，让子类决定实例化哪一个类
抽象工厂模式：为创建一组相关或相互依赖的对象提供一个接口，而且无需指定他们的具体类
个人觉得这个区别在于产品，如果产品单一，最合适用工厂模式，但是如果有多个业务品种、业务分类时，通过抽象工厂模式产生需要的对象是一种非常好的解决方式。再通俗深化理解下：工厂模式针对的是一个产品等级结构 ，抽象工厂模式针对的是面向多个产品等级结构的。
再来看看工厂方法模式与抽象工厂模式对比：
工厂方法模式
抽象工厂模式
针对的是一个产品等级结构
针对的是面向多个产品等级结构
一个抽象产品类
多个抽象产品类
可以派生出多个具体产品类
每个抽象产品类可以派生出多个具体产品类
一个抽象工厂类，可以派生出多个具体工厂类
一个抽象工厂类，可以派生出多个具体工厂类
每个具体工厂类只能创建一个具体产品类的实例
每个具体工厂类可以创建多个具体产品类的实例

19.什么时候使用享元模式？
享元模式通过共享对象来避免创建太多的对象。为了使用享元模式，你需要确保你的对象是不可变的，这样你才能安全的共享。JDK 中 String 池、Integer 池以及 Long 池都是很好的使用了享元模式的例子。

20 什么是设计模式？你是否在你的代码里面使用过任何设计模式？
设计模式是世界上各种各样程序员用来解决特定设计问题的尝试和测试的方法。设计模式是代码可用性的延伸。

21 你可以说出几个在JDK库中使用的设计模式吗？
装饰器设计模式（Decorator design pattern）被用于多个Java IO类中。单例模式（Singleton pattern）用于Runtime，Calendar和其他的一些类中。工厂模式（Factory pattern）被用于各种不可变的类如Boolean，像Boolean.valueOf，观察者模式（Observer pattern）被用于Swing和很多的事件监听中。

22.Java中什么是单例设计模式？用Java写出线程安全的单例
单例对象（Singleton）是一种常用的设计模式。在Java应用中，单例对象能保证在一个JVM中，该对象只有一个实例存在。这样的模式有几个好处：
1）某些类创建比较频繁，对于一些大型的对象，这是一笔很大的系统开销。
2）省去了new操作符，降低了系统内存的使用频率，减轻GC压力。
3）有些类如交易所的核心交易引擎，控制着交易流程，如果该类可以创建多个的话，系统完全乱了。（比如一个军队出现了多个司令员同时指挥，肯定会乱成一团），所以只有使用单例模式，才能保证核心交易服务器独立控制整个流程。
单例模式重点在于在整个系统上共享一些创建时较耗资源的对象。整个应用中只维护一个特定类实例，它被所有组件共同使用。Java.lang.Runtime是单例模式的经典例子。你可以在我的文章Java单例模式的10个问题看到更多的问题和讨论。从Java 5开始你可以使用枚举（enum）来实现线程安全的单例。

23 在Java中，什么叫观察者设计模式（observer design pattern）？
观察者模式是基于对象的状态变化和观察者的通讯，以便他们作出相应的操作。简单的例子就是一个天气系统，当天气变化时必须在展示给公众的视图中进行反映。这个视图对象是一个主体，而不同的视图是观察者。可以在这篇文章中看到Java观察者模式的完整例子。

24 什么是责任链设计模式？
责任链模式（Chain of Responsibility Pattern）为请求创建了一个接收者对象的链。这种模式给予请求的类型，对请求的发送者和接收者进行解耦。这种类型的设计模式属于行为型模式。在这种模式中，通常每个接收者都包含对另一个接收者的引用。如果一个对象不能处理该请求，那么它会把相同的请求传给下一个接收者，依此类推。


---------------------------------------------------------------------------------------------------------------
------------------------------------------desingerpattern basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------docker basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 什么是Docker?
Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从Apache2.0协议开源。可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）,更重要的是容器性能开销极低。Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。
Docker是基于Go语言实现的云开源项目，诞生于2013年初，最初发起者是dotCloud公司。Docker自开源后就受到广泛的关注和讨论，目前已有多个相关项目，逐渐形成了围绕Docker的生态体系。dotCloud公司后来也改名为Docker Inc，专注于Docker相关技术和产品的开发。

现在主流的Linux操作系统都已经支持Docker。例如，Redhat RHEL 6.5/ CentOS 6.5往上的操作系统、Ubuntu 14.04操作系统，都已经默认带有Docker软件包。Google公司宣称在其PaaS平台及服务产品中广泛应用了Docker。微软公司宣布和 Docker公司合作，以加强其云平台Azure对Docker的支持。公有云提供商亚马逊也推出了AWS EC2 Container，提供对Docker的支持。

Docker的英文本意是“搬运工”，在程序员的世界里，Docker搬运的是集装箱（Container），集装箱里装的是任意类型的App，开发者通过Docker可以将App变成一种标准化的、可移植的、自管理的组件，可以在任何主流系统中开发、调试和运行。最重要的是，它不依赖于任何语言、框架或系统。不久前Docker 1.0的发布，意味着Docker自身已经转变为一个分发应用的开放平台。如今的Docker已经备受青睐，云服务提供商，包括微软、 IBM 、 Rackspace 、 Google 以及其他主要的 Linux 提供商如 Canonical 和 Red Hat ，都已经开始支持 Docker 。

2 Docker 的优点
（1）简化程序
Docker 让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，便可以实现虚拟化。Docker改变了虚拟化的方式，使开发者可以直接将自己的成果放入Docker中进行管理。方便快捷已经是 Docker的最大优势，过去需要用数天乃至数周的 任务，在Docker容器的处理下，只需要数秒就能完成。
（2）避免选择恐惧症
如果你有选择恐惧症，还是资深患者。Docker 帮你 打包你的纠结！比如 Docker 镜像；Docker 镜像中包含了运行环境和配置，所以 Docker 可以简化部署多种应用实例工作。比如 Web 应用、后台应用、数据库应用、大数据应用比如 Hadoop 集群、消息队列等等都可以打包成一个镜像部署。
（3）节省开支
一方面，云计算时代到来，使开发者不必为了追求效果而配置高额的硬件，Docker 改变了高性能必然高价格的思维定势。Docker 与云的结合，让云空间得到更充分的利用。不仅解决了硬件管理的问题，也改变了虚拟化的方式。
1、Docker 容器的启动可以在秒级实现，这相比传统的虚拟机方式要快得多
2、Docker 对系统资源的利用率很高，一台主机上可以同时运行数千个 Docker 容器。
3、更快速的交付和部署、更轻松的迁移和扩展

3 Docker 组件与元素
Docker有三个组件和三个基本元素，读者可以快速浏览下面这个视频来了解这些组建和元素，以及它们的关系。
（1）三个组件分别是：
    Docker Client 是用户界面，它支持用户与Docker Daemon之间通信。
    Docker Daemon运行于主机上，处理服务请求。
    Docker Index是中央registry，支持拥有公有与私有访问权限的Docker容器镜像的备份。

（2）三个基本要素分别是：
    Docker Containers负责应用程序的运行，包括操作系统、用户添加的文件以及元数据。
    Docker Images是一个只读模板，用来运行Docker容器。
    DockerFile是文件指令集，用来说明如何自动创建Docker镜像。

4 Docker与虚拟机比较
作为一种轻量级的虚拟化方式Docker在运行应用上跟传统的虚拟机方式相比有显著优势：
@Docker容器很快，启动和停止可以在秒级实现，这相比传统的虚拟机方式要快得多。
@Docker容器对系统资源需求很少，一台主机上可以同时运行数千个Docker容器。
@Docker通过类似Git的操作来方便用户获取、分发和更新应用镜像，指令简明，学习成本较低。
@Docker通过Dockerfile配置文件来支持灵活的自动化创建和部署机制，提高工作效率。

5 Docker 架构
Docker 镜像(Images)	Docker 镜像是用于创建 Docker 容器的模板。 
Docker 容器(Container)	容器是独立运行的一个或一组应用。
Docker 客户端(Client)	Docker 客户端通过命令行或者其他工具使用 Docker API (https://docs.docker.com/reference/api/docker_remote_api) 与 Docker 的守护进程通信。
Docker 主机(Host)	一个物理或者虚拟的机器用于执行 Docker 守护进程和容器。
Docker 仓库(Registry) 	Docker 仓库用来保存镜像，可以理解为代码控制中的代码仓库。
Docker Hub(https://hub.docker.com) 提供了庞大的镜像集合供使用。
Docker Machine	Docker Machine是一个简化Docker安装的命令行工具，通过一个简单的命令行即可在相应的平台上安装Docker，比如VirtualBox、 Digital Ocean、Microsoft Azure。

6 Docker 命令大全
1） 容器生命周期管理
    run
    start/stop/restart
    kill
    rm
    pause/unpause
    create
    exec
2） 容器操作
    ps
    inspect
    top
    attach
    events
    logs
    wait
    export
    port
3） 容器rootfs命令
    commit
    cp
    diff
4） 镜像仓库
    login
    pull
    push
    search
5）本地镜像管理
    images
    rmi
    tag
    build
    history
    save
    import
6） info|version
    info
    version




二、ms相关
1、什么是Docker？
Docker是一个容器化平台，它以容器的形式将你的应用程序及所有的依赖项打包在一起，以确保你的应用程序在任何环境中无缝运行。

2、什么是Docker镜像？
Docker镜像是Docker容器的源代码，Docker镜像用于闯将容器，使用Build命令创建镜像。

3、什么是Docker容器？
Docker容器包括应用程序及所有的依赖项，作为操作系统的独立进程运行。

4、Docker容器有几种状态？
四种状态：运行、已停止、重新启动、已退出。

5、DockerFile中最常见的指定是什么?
指令	备注
FROM	指定基础镜像
LABEL	功能为镜像指定标签
RUN	运行指定命令
CMD	容器启动时要运行的命令

6、DockerFile中的命令COPY和ADD命令有什么区别？
COPY和ADD的区别时COPY的SRC只能是本地文件，其他用法一致。

7、Docker的常用命令？
命令	备注
docker pull	拉去或更新指定的镜像
docker push	将镜像推送到远程仓库
docker rm	删除容器
docker rmi	删除镜像
docker images	列出所有镜像
docker ps	列出所有容器

8、容器与主机之间的数据拷贝命令？
Docker cp命令用于穷奇与主机之间的数据拷贝
主机到哦容器：docker cp /www 96f7f14e99ab:/www/
容器到主机：docker cp 96f7f14e99ab:/www /tmp

9、启动nginx容器（随机端口映射），并挂载本地文件目录到容器html的命令？
        Docker run -d -p --name nginx2 -v /home/nginx:/usr/share/nginx/html nginx

10、解释一下dockerfile的ONBUILD指令？
当镜像用作另一个镜像构建的基础时，ONBUILD指令像镜像添加将在稍后执行的触发指令。如果要构建将用作构建其他镜像的基础的镜像（例如，可以使用特定于用户的配置自定义的应用程序构建环境或守护程序），这将非常有用。

11、什么是docker Swarm?
Docker Swarm是docker的本地群集。它将docker主机池转变为单个虚拟docker主机。Docjer Swarm提供标准的docker API，任何已经与docker守护进程通信的工具都可以使用Swarm透明地扩展到多个主机。

12、如何在生产中监控docker？
Docker提供docker:stats和docker事件等工具来监控生产中的docker。我们可以使用这些命令获取重要统计数据的报告。
Docker统计数据：当我们使用容器ID调用docker stats时，我们获得容器的CPU，内存使用情况等。它类似于Linux中的top命令。
Docker事件：docker事件是一个命令，用于查看docker守护程序中正在进行的活动流。一些常见的docker事件是：attach，commit，die，detach，rename，destroy等。我们还可以使用各种选项来限制或过滤我们感性其的事件。

13、Docker如何在非Linux系统中运行容器？
通过添加到Linux内核版本2.6.24的名称空间功能，可以实现容器的概念。容器将其ID添加到每个进程，并向每个系统调用添加新的访问控制检查。它由clone（）系统调用访问，该调用允许创建先前全局命名空间的单独实例。
如果由于Linux内核中可用的功能而可以使用容器，那么显而易见的问题是非Linux系统如何运行容器。Docker for Mac和Windows都使用Linux VM来运行容器。Docker Toolbox用于在Virtual Box VM中运行容器。但是，罪行的docker早Windows中使用Hyper-V，在MAC中使用Hypervisor.framework。

14、如何批量清理临时镜像文件？
可以使用sudo docker rmi $(sudo docker images -q -f danging=true)命令

15、如何查看镜像支持的环境变量？
使用sudo docker run IMAGE env

16、本地的镜像文件都存放在哪里？
于docker相关的本地资源存在/var/lib/docker/目录下，其中container目录存放容器信息，graph目录存放镜像信息，aufs目录下存放具体的镜像底层文件。

17、构建docker镜像应该遵循哪些原则？
整体原则上，尽量保持镜像功能的明确和内容的精简，要点包括:
尽量选取满足需求但较小的基础系统镜像，建议选择debian:wheezy镜像，仅有86MB大小。
清理编译生成文件、安装包的缓存等临时文件。
安装哥哥软件时候要指定准确的版本号，并避免引入不需要的依赖。
从安全的角度考虑，应用尽量使用系统的库和依赖。
使用dockerfile创建镜像时候要添加.dockerignore文件或使用干净的工作目录。

18、容器退出后，通过docker ps命令查看不到，数据会丢失么？
容器退出后会处于终止（exited）状态，此时可以通过docker ps -a查看，其中数据不会丢失，还可以通过docker start来启动，只要删除容器才会清除数据。

19、如何停止所有正在运行的容器？
        docker kill $(sudo docker ps -q)

20、如何清理批量后台停止容器？
        docker rm$(sudo docker ps -a -q)

21、如何临时退出一个正在交互的容器的终端，而不终止它？
按Ctrl+p，后按Ctrl+q，如果按Ctrl+c会使容器内的应用进程终止，进而会使容器终止。

22、很多应用容器都是默认后台运行的，怎么查看他们的输出和日志信息？
使用docker logs，后面跟容器的名称或者ID信息

23、使用docker port命令映射容器的端口时，系统报错Error：NO public port ‘80’ published for …,是什么意思？
创建镜像时dockerfile要指定正确的EXPOSE的端口，容器启动时指定PublishAllport=true

24、可以在一个容器中同时运行多个应用进程吗？
一般不推荐在用以容器内运行多个应用进程，如果有类似需求，可以用过额外的进程管理机制，比如supervisord来管理所运行的进程。

25、如何控制容器占用系统资源（CPU，内存）的份额？
在使用docker create命令创建容器或使用docker run 创建并运行容器的时候，可以使用-c|-spu-shares[=0]参数来调整同期使用SPU的权重，使用-m|-memory参数来调整容器使用内存的大小。

26、仓库（Repository）、注册服务器（Registry）、注册 索引（Index）有和关系？
首先，仓库事存放一组关联镜像的集合，比如同一个应用的不同版本的镜像，注册服务器时存放实际的镜像的地方，注册索引则负责维护用户的账号、权限、搜索、标签等管理。注册服务器利用注册索引来实现认证等管理。

27、从非官方仓库（如：dl.dockerpool.com）下载镜像的时候，有时候会提示”Error:Invaild registry endpoint https://dl.docker.com:5000/v1/…”?
Docker自1.3.0版本往后以来，加强了对镜像安全性的验证，需要手动添加对非官方仓库的信任。DOCKER_ORTS=”-insecure-registry dl.dockerpool.com:5000”重启docker服务。

28、Docker的配置文件放在那里。如何修改配置？
Ubuntu系统下Docker的配置文件是/etc/default/docker,CentOS系统配置文件存放在/etc/sysconfig/docker。

29、如何更改docker的默认存储设置？
Docker的默认存放位置是/var/lib/docker，如果希望将docker的本地文件存储到其他分区，可以使用Linux软连接的方式来做。

30、docker与LXC（Linux Container）有何不同？
LXC利用Linux上相关技术实现容器，docker则在如下的几个方面进行了改进:
容器特性	备注
移植性	通过抽象容器配置，容器可以实现一个平台移植到另一个平台
镜像系统	基于AUFS的镜像系统为容器的分发带来了很多的便利，通是共同的镜像层只需要存储一份，实现高效率的存储
版本管理	类似于GIT的版本管理理念，用户可以更方便的创建、管理镜像文件
仓库系统	仓库系统大大降低了镜像的分发和管理的成本
周边工具	各种现有的工具（配置管理、云平台）对docker的支持，以及基于docker的pass、Cl等系统，让docker的应用更加方便和多样

31、Docker于Vagrant有何不同？
两者的定位完全不同
Vagrant类似于Boot2Docker（一款运行Docker的最小内核），是一套虚拟机的管理环境，Vagrant可以在多种系统上和虚拟机软件中运行，可以在Windows、Mac等非Linux平台上为Docker支持，自身具有较好的包装性和移植性。原生Docker自身只能运行在Linux平台上，但启动和运行的性能比虚拟机要快，往往更适合快速开发和部署应用的场景。

32、开发环境中Docker与Vagrant该如何选择？
Docker不是虚拟机，而是进程隔离，对于资源的消耗很少，单一开发环境下Vagrant是虚拟机上的封装，虚拟机本身会消耗资源.

33、如何将一台宿主机的docker环境迁移到另外一台宿主机？
停止docker服务，将整个docker存储文件复制到另外一太宿主机上，然后调整另外一台宿主机的配置即可。

34、Docker容器创建后，删除了/var/run/netns目录下的网络名字空间文件，可以手动恢复它：
查看容器进程ID，比如1234
        Sudo docker inspect --format=’{{. State.pid}}’ $container_id 1234
到proc目录下，把对应的网络名字空间文字链接到/var/run/netns，然后通过正常的系统命令查看操作容器的名字空间
---------------------------------------------------------------------------------------------------------------
------------------------------------------docker basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------dubbo basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 Dubbo
一款分布式服务框架，高性能和透明化的RPC远程服务调用方案，SOA服务治理方案。每天为2千多个服务提供大于30亿次访问量支持，并被广泛应用于阿里巴巴集团的各成员站点以及别的公司的业务中。
Dubbo是Alibaba开源的分布式服务框架，它最大的特点是按照分层的方式来架构，使用这种方式可以使各个层之间解耦合（或者最大限度地松耦合）。
从服务模型的角度来看，Dubbo采用的是一种非常简单的模型，要么是提供方提供服务，要么是消费方消费服务，所以基于这一点可以抽象出服务提供方（Provider）和服务消费方（Consumer）两个角色。

2 核心部分
@远程通讯: 提供对多种基于长连接的NIO框架抽象封装，包括多种线程模型，序列化，以及“请求-响应”模式的信息交换方式。
@集群容错: 提供基于接口方法的透明远程过程调用，包括多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。
@自动发现: 基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，使服务提供方可以平滑增加或减少机器。

3 组成结构
Provider: 暴露服务的服务提供方。
Consumer: 调用远程服务的服务消费方。
Registry: 服务注册与发现的注册中心。
Monitor: 统计服务的调用次数和调用时间的监控中心。

4 调用流程
0）.服务容器负责启动，加载，运行服务提供者。
1）.服务提供者在启动时，向注册中心注册自己提供的服务。
2）.服务消费者在启动时，向注册中心订阅自己所需的服务。
3）.注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。
4）.服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。
5）.服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心

5 Dubbo注册中心
对于服务提供方，需要发布服务，由于应用系统的复杂性，服务的数量、类型也不断膨胀；
对于服务消费方，如何获取到它所需要的服务，面对复杂的应用系统需要管理大量服务调用。
而且，对于服务提供方和服务消费方来说，他们还有可能兼具这两种角色，即既需要提供服务，有需要消费服务。
通过将服务统一管理起来，可以有效地优化内部应用对服务发布/使用的流程和管理。服务注册中心可以通过特定协议来完成服务对外的统一。
Dubbo提供的注册中心有如下几种类型可供选择：
Multicast注册中心
Zookeeper注册中心
Redis注册中心
Simple注册中心

6 Dubbo优缺点
优点：透明化的远程方法调用；像调用本地方法一样调用远程方法，没有任何API侵入；
软负载均衡及容错机制；可在内网替代nginx lvs等硬件负载均衡器；服务注册中心自动注册 & 配置管理;不需要写死服务提供者地址，注册中心基于接口名自动查询提供者ip；使用类似zookeeper等分布式协调服务作为服务注册中心，可以将绝大部分项目配置移入zookeeper集群。服务接口监控与治理Dubbo-admin与Dubbo-monitor提供了完善的服务接口管理与监控功能，针对不同应用的不同接口，可以进行 多版本，多协议，多注册中心管理。
缺点：只支持JAVA语言

7 集群容错：
<dubbo:service cluster="failsafe" />
<dubbo:reference cluster="failsafe" />
failover：失败自动切换，重试其它服务器
failfast：快速失败，只发起一次调用，失败立即报错，非幂等操作
failsafe：失败安全，忽略异常，
failback：失败自动恢复，后台记录失败请求，定时重发，
forking：同时调用多个服务器，只要一个返回成功即可，应用于实时性高的操作
broadcast：广播所有服务器，逐个调用，任意一台报错，则报错，服务更新提供者缓存应用

8 负载均衡：
服务端 服务端方法级 客户端 客户端方法级
random：按权重设置随机概率，碰撞概率
roundrobin：公约后的权重设置轮训概率，慢提供者积累请求问题。
leastactive：慢的提供者收到更少的请求
consistenthash：相同参数请求发送到同一提供者，
缺省只对第一个参数 Hash，如果要修改，请配置 <dubbo:parameter key="hash.arguments" value="0,1" />
缺省用 160 份虚拟节点，如果要修改，请配置 <dubbo:parameter key="hash.nodes" value="320" />
 
9 十层架构
（1）服务接口层（Service）：该层是与实际业务逻辑相关的，根据服务提供方和服务消费方的业务设计对应的接口和实现。
（2）配置层（Config）：对外配置接口，以ServiceConfig和ReferenceConfig为中心，可以直接new配置类，也可以通过spring解析配置生成配置类。
（3）服务代理层（Proxy）：服务接口透明代理，生成服务的客户端Stub和服务器端Skeleton，以ServiceProxy为中心，扩展接口为ProxyFactory。
（4）服务注册层（Registry）：封装服务地址的注册与发现，以服务URL为中心，扩展接口为RegistryFactory、Registry和RegistryService。可能没有服务注册中心，此时服务提供方直接暴露服务。
（5）集群层（Cluster）：封装多个提供者的路由及负载均衡，并桥接注册中心，以Invoker为中心，扩展接口为Cluster、Directory、Router和LoadBalance。将多个服务提供方组合为一个服务提供方，实现对服务消费方来透明。
（6）监控层（Monitor）：RPC调用次数和调用时间监控，以Statistics为中心，扩展接口为MonitorFactory、Monitor和MonitorService。
（7）远程调用层（Protocol）：封将RPC调用，以Invocation和Result为中心，扩展接口为Protocol、Invoker和Exporter。Protocol是服务域，它是Invoker暴露和引用的主功能入口，它负责Invoker的生命周期管理。Invoker是实体域，它是Dubbo的核心模型，其它模型都向它靠扰，或转换成它，它代表一个可执行体，可向它发起invoke调用，它有可能是一个本地的实现，也可能是一个远程的实现，也可能一个集群实现。
（8）信息交换层（Exchange）：封装请求响应模式，同步转异步，以Request和Response为中心，扩展接口为Exchanger、ExchangeChannel、ExchangeClient和ExchangeServer。
（9）网络传输层（Transport）：抽象mina和netty为统一接口，以Message为中心，扩展接口为Channel、Transporter、Client、Server和Codec。
（10）数据序列化层（Serialize）：可复用的一些工具，扩展接口为Serialization、 ObjectInput、ObjectOutput和ThreadPool。

10 协议支持
Dubbo支持多种协议,在通信过程中，不同的服务等级一般对应着不同的服务质量，那么选择合适的协议便是一件非常重要的事情。你可以根据你应用的创建来选择。
例如，使用RMI协议，一般会受到防火墙的限制，所以对于外部与内部进行通信的场景就不要使用RMI协议，而是基于HTTP协议或者Hessian协议。
Dubbo协议
Hessian协议
HTTP协议
RMI协议
WebService协议
Thrift协议
Memcached协议
Redis协议
Rest协议

11 dubbo-monitor计数监控
1） MonitorFilter向DubboMonitor发送数据
DubboMonitor将数据进行聚合后（默认聚合1min中的统计数据）暂存到ConcurrentMap<Statistics, AtomicReference<long[]>> statisticsMap，然后使用一个含有3个线程（线程名字：DubboMonitorSendTimer）的线程池每隔1min钟，调用SimpleMonitorService遍历发送statisticsMap中的统计数据，每发送完毕一个，就重置当前的Statistics的AtomicReference<long[]>
SimpleMonitorService将这些聚合数据塞入BlockingQueue<URL> queue中（队列大写为100000）
SimpleMonitorService使用一个后台线程（线程名为：DubboMonitorAsyncWriteLogThread）将queue中的数据写入文件（该线程以死循环的形式来写）
SimpleMonitorService还会使用一个含有1个线程（线程名字：DubboMonitorTimer）的线程池每隔5min钟，将文件中的统计数据画成图表
2） SimpleMonitorService理解为一个服务提供者；
provider和consumer都是一个服务消费者，所以二者的DubboMonitor中的MonitorService实例都是一个代理实例。dubbo-monitor计数监控不支持异步调用下的数据监控
3） dubbo-monitor使用
在配置文件中添加：
<dubbo:monitor address="10.211.55.5:9090" />
4）问题解析
（1）问题报错
com.alibaba.dubbo.rpc.RpcException: Forbid consumer 10.10.50.156 access service com.alibaba.dubbo.monitor.MonitorService from registry 10.10.50.134:2181 use dubbo version 2.8.4, Please check registry access list (whitelist/blacklist).
        at com.alibaba.dubbo.registry.integration.RegistryDirectory.doList(RegistryDirectory.java:579)
        at com.alibaba.dubbo.rpc.cluster.directory.AbstractDirectory.list(AbstractDirectory.java:73)
        at com.alibaba.dubbo.rpc.cluster.support.AbstractClusterInvoker.list(AbstractClusterInvoker.java:260)
        at com.alibaba.dubbo.rpc.cluster.support.AbstractClusterInvoker.invoke(AbstractClusterInvoker.java:219)
        at com.alibaba.dubbo.rpc.cluster.support.wrapper.MockClusterInvoker.invoke(MockClusterInvoker.java:72)
        at com.alibaba.dubbo.rpc.proxy.InvokerInvocationHandler.invoke(InvokerInvocationHandler.java:52)
        at com.alibaba.dubbo.common.bytecode.proxy1.collect(proxy1.java)
        at com.alibaba.dubbo.monitor.dubbo.DubboMonitor.send(DubboMonitor.java:113)
        at com.alibaba.dubbo.monitor.dubbo.DubboMonitor$1.run(DubboMonitor.java:70)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
（2）原因分析
没有服务提供者造成，没有一个项目注册了监控中心。
（3）解决措施
任意一台使用dubbo的项目配置 
<dubbo:monitor address="10.211.55.5:9090" />




二、ms相关
1 服务上线怎么不影响旧版本？
采用多版本开发（dubbo:service配置version），不影响旧版本。

2 Dubbo如何做负载均衡？
<dubbo:service interface="..."loadbalance="random"/>
<dubbo:reference interface="..."loadbalance=" random "/>
Dubbo内置了4种负载均衡策略:
1）RandomLoadBalance随机负载均衡：是Dubbo的默认负载均衡策略。
2）RoundRobinLoadBalance轮询负载均衡：轮询依次。
3）LeastActiveLoadBalance最少活跃调用数：相同活跃数的随机。活跃数指调用前后计数差。使慢的 Provider 收到更少请求，因为越慢的 Provider 的调用前后计数差会越大。
4）ConsistentHashLoadBalance一致性哈希负载均衡：相同参数的请求总是落在同一台机器上。

3 Dubbo如何做限流降级？
1）dubbo提供了mock配置，可以很好的实现dubbo服务降级
<dubbo:reference id="xxxService" interface="com.x..service.xxxxService" check="false" mock="return fail" />
2）整合Sentinel

4 Dubbo如何优雅停机？
线上服务不要轻易的kill -9,可进行kill触发应用的钩子程序,做相关的资源清理，如果一直关闭不掉，最终可以通过kill -9执行。
Dubbo 可以通过 JDK 的 ShutdownHook 来完成优雅停机的，使用Kill pid命令干掉进程。

5 Dubbo如何实现异步调用的？
1）api注入时添加异步调用标示
@Reference(interfaceClass=xxx.class, async-true)
2）启动类开启异步调用
@EnableAsycn
3）异步调用的接口添加异步调用代码
RpcContext.getContext.future()

6 Dubbo 和 Spring Cloud 有什么区别?
Dubbo底层是使用Netty的NIO框架，是基于TCP协议传输的，配合以Hession序列化完成RPC通信。
SpringCloud是基于Http协议+rest接口调用远程过程的通信。
Http请求会有更大的报文，占的带宽也会更多。
REST相比RPC更为灵活，不存在代码级别的强依赖。
Dubbo	SpringCloud
服务注册中心	Zookeeper　	Spring Cloud Netfix Eureka
服务调用方式	RPC　	REST API
服务监控	Dubbo-monitor	Spring Boot Admin
熔断器	不完善	Spring Cloud Netflix Hystrix
服务网关	无	Spring Cloud Netflix Zuul
分布式配置	无	Spring Cloud Config
服务跟踪	无	Spring Cloud Sleuth
数据流	无	Spring Cloud Stream
批量任务	无	Spring Cloud Task
信息总线	无	Spring Cloud Bus

7 dubbo都支持什么协议，推荐用哪种？
dubbo（推荐）：单一长连接、NIO 异步通讯，适合于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况
hessian：短连接，http，适合于页面传输，文件传输，或与原生hessian服务互操作
Http：适用于需同时给应用程序和浏览器 JS 使用的服务
WebService：适用于系统集成，跨语言调用
RMI 协议：适用于常规远程服务方法调用，与原生RMI服务互操作

8 Dubbo需要 Web 容器吗？
不需要，dubbo服务容器是一个standalone的启动程序，因为后台服务不需要Tomcat或JBoss等Web容器的功能，如果硬要用Web容器去加载服务提供方，增加复杂性，也浪费资源。 

9 Dubbo内置了哪几种服务容器？
 Spring Container  Jetty Container  Log4j Container

10 Dubbo里面有哪些角色？
registry：注册中心
consumer：消费者
provider：服务提供者
container：容器
monitor：监控

11 Dubbo默认使用什么注册中心，还有别的选择吗？
zookeeper，还有 Redis、Multicast、Simple 注册中心，但不推荐

12 在 Provider 上可以配置的 Consumer 端的属性有哪些？
1）timeout：调用超时
2）retries：失败重试次数（默认重试 2 次 ）
3）loadbalance：负载均衡算法，默认随机
4）actives 消费者端，最大并发调用限制

13 Dubbo启动时如果依赖的服务不可用会怎样？
Dubbo 缺省会在启动时检查依赖的服务是否可用，不可用时会抛出异常，阻止 Spring 初始化完成，默认 check="true"，可以通过 check="false" 关闭检查。

14 Dubbo推荐使用什么序列化框架，你知道的还有哪些？
推荐使用Hessian，还有Duddo、FastJson、Java自带序列化。

15 Dubbo默认使用的是什么通信框架，还有别的选择吗？
Dubbo 默认使用 Netty 框架（推荐），另外内容还集成有Mina、Grizzly

16 Dubbo有哪几种集群容错方案，默认是哪种？
1）Failover Cluster默认
失败自动切换，当出现失败，重试其它服务器（retries 重试次数）。通常用于读操作，但重试会带来更长延迟。
2）Failfast Cluster
快速失败，只发起一次调用，失败立即报错，通常用于写操作。
3）Failsafe Cluster
失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。
4）Failback Cluster
失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。
5）Forking Cluster
并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks="2" 来设置最大并行数。
6）Broadcast Cluster
广播调用所有提供者，逐个调用，任意一台报错则报错 [2]。通常用于通知所有提供者更新缓存或日志等本地资源信息。

17 Dubbo可以对结果进行缓存吗？
<dubbo:reference cache="true" />

18 Dubbo服务之间的调用是阻塞的吗？
默认是阻塞的，可以异步调用。

19 Dubbo的管理控制台能做什么？
路由规则，动态配置，服务降级，访问控制，权重调整，负载均衡，等管理功能。

20 说说 Dubbo 服务暴露的过程
Dubbo 会在 Spring 实例化完 bean 之后，在刷新容器最后一步发布 ContextRefreshEvent 事件的时候，通知实现了 ApplicationListener 的 ServiceBean 类进行回调 onApplicationEvent 事件方法。Dubbo 会在这个方法中调用 ServiceBean 父类 ServiceConfig 的 export 方法，而该方法真正实现了服务的发布。

21 同一个服务多个注册的情况下可以直连某一个服务吗？
可以通过修改配置点对点直连，也可以通过 telnet 直接某个服务。
---------------------------------------------------------------------------------------------------------------
------------------------------------------dubbo basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------elk basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识


1 Elasticsearch
面向文档(document oriented) 
这意味着它可以存储整个对象或文档(document)。然而它不仅仅是存储，还会索引(index)每个文档的内容使之可以被搜索。在Elasticsearch中，你可以对文档（而非成行成列的数据）进行索引、搜索、排序、过滤。这种理解数据的方式与以往完全不同，这也是Elasticsearch能够执行复杂的全文搜索的原因之一。我们来看一个实际的例子，假设有如下的数据：
这里每一行是一个document。每个document都有一个docid。那么给这些document建立的倒排索引就是：
可以看到，倒排索引是per field的，一个字段由一个自己的倒排索引。18,20这些叫做 term，而[1,3]就是posting list。Posting list就是一个int的数组，存储了所有符合某个term的文档id。

2 ELK=elasticsearch+Logstash+kibana 
elasticsearch：后台分布式存储以及全文检索 
logstash: 日志加工、“搬运工” 
kibana：数据可视化展示。 
ELK架构为数据分布式存储、可视化查询和日志解析创建了一个功能强大的管理链。 三者相互配合，取长补短，共同完成分布式大数据处理工作。

3 思考：大规模数据如何检索？
如：当系统数据量上了10亿、100亿条的时候，我们在做系统架构的时候通常会从以下角度去考虑问题： 
1）用什么数据库好？(mysql、sybase、oracle、mongodb、hbase…) 
2）如何解决单点故障；(lvs、F5、A10、Zookeep、MQ) 
3）如何保证数据安全性；(热备、冷备、异地多活) 
4）如何解决检索难题；(数据库代理中间件：mysql-proxy、Cobar、MaxScale等;) 
5）如何解决统计分析问题；(离线、近实时)

4 传统数据库的应对解决方案
对于关系型数据，我们通常采用以下或类似架构去解决查询瓶颈和写入瓶颈： 
解决要点： 
1）通过主从备份解决数据安全性问题； 
2）通过数据库代理中间件心跳监测，解决单点故障问题； 
3）通过代理中间件将查询语句分发到各个slave节点进行查询，并汇总结果 

5 非关系型数据库的解决方案~~~~~~
对于Nosql数据库，以mongodb为例，其它原理类似： 
解决要点： 
1）通过副本备份保证数据安全性； 
2）通过节点竞选机制解决单点问题； 
3）先从配置库检索分片信息，然后将请求分发到各个节点，最后由路由节点合并汇总结果

6 为解决以上问题，从源头着手分析，通常会从以下方式来寻找方法： 
1、存储数据时按有序存储； 
2、将数据和索引分离； 
3、压缩数据； 
这就引出了Elasticsearch。

7  Elasticsearch基本概念
ES=elaticsearch简写， Elasticsearch是一个开源的高扩展的分布式全文检索引擎，它可以近乎实时的存储、检索数据；本身扩展性很好，可以扩展到上百台服务器，处理PB级别的数据。 Elasticsearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。
1）Lucene只是一个库。想要使用它，你必须使用Java来作为开发语言并将其直接集成到你的应用中，更糟糕的是，Lucene非常复杂，你需要深入了解检索的相关知识来理解它是如何工作的。
2）Elasticsearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。
可以把es看做是面向文档的数据库，它与关系型数据库的名词对照关系如下：
Relational DB => Databases => Tables => Rows => Columns 
Elasticsearch => Index=> doc Types => Documents => Fields
（1）Index 索引
索引（index）是Elasticsearch对逻辑数据的逻辑存储，所以它可以分为更小的部分。你可以把索引看成关系型数据库的表。Elasticsearch可以把索引存放在一台机器或者分散在多台服务器上，每个索引有一或多个分片（shard），每个分片可以有多个副本（replica）。

（2）doc Types 文档类型
在Elasticsearch中，一个索引对象可以存储很多不同用途的对象。例如，一个博客应用程序可以保存文章和评论。文档类型让我们轻易地区分单个索引中的不同对象。每个文档可以有不同的结构，但在实际部署中，将文件按类型区分对数据操作有很大帮助。

（3） Document 文档
存储在Elasticsearch中的主要实体叫文档（document）。用关系型数据库来类比的话，一个文档相当于数据库表中的一行记录。从客户端的角度看，文档是一个JSON对象。每个文档存储在一个索引中并有一个Elasticsearch自动生成的唯一标识符和文档类型。

（4）field
文档由多个field组成，从客户端的角度看，就是json对象中的多个kv节点。

（5）Cluster：集群。
ES可以作为一个独立的单个搜索服务器。不过，为了处理大型数据集，实现容错和高可用性，ES可以运行在许多互相合作的服务器上。这些服务器的集合称为集群。

（6）Node：节点。
形成集群的每个服务器称为节点。

（7）Shard：分片。
当有大量的文档时，由于内存的限制、磁盘处理能力不足、无法足够快的响应客户端的请求等，一个节点可能不够。这种情况下，数据可以分为较小的分片。每个分片放到不同的服务器上。 当你查询的索引分布在多个分片上时，ES会把查询发送给每个相关的分片，并将结果组合在一起，而应用程序并不知道分片的存在。即：这个过程对用户来说是透明的。

（8）Replia：副本。
为提高查询吞吐量或实现高可用性，可以使用分片副本。 副本是一个分片的精确复制，每个分片可以有零个或多个副本。ES中可以有许多相同的分片，其中之一被选择更改索引操作，这种特殊的分片称为主分片。 当主分片丢失时，如：该分片所在的数据不可用时，集群将副本提升为新的主分片。

（9）全文检索。
全文检索就是对一篇文章进行索引，可以根据关键字搜索，类似于mysql里的like语句。 全文索引就是把内容根据词的意义进行分词，然后分别创建索引，例如”你们的激情是因为什么事情来的” 可能会被分词成：“你们“，”激情“，“什么事情“，”来“ 等token，这样当你搜索“你们” 或者 “激情” 都会把这句搜出来。


8 基本架构
（1）shard分片 
实际上，index仅仅只是一个命名空间来指向一个或多个实际的物理分片(shard)。具体的物理分布粒度关系如下：
一个Elasticsearch Index相当于一个MySQL里的表，不同Index的数据是物理上隔离开来的。Elasticsearch的Index会分成多个Shard存储，一部分Shard是Replica备份。一个Shard是一份本地的存储（一个本地磁盘上的目录），也就是一个Lucene的Index。不同的Shard可能会被分配到不同的主机节点上。一个Lucene Index会存储很多的doc，为了好管理，Lucene把Lucene Index再拆成了Segment存储（子目录）。Segment内的doc数量上限是2的31次方，这样doc id就只需要一个int就可以存储。Segment对应了一些列文件存储索引（倒排表等）和主存储（DocValues等），这些文件内部又分为小的Block进行压缩。

一个shard实际上是一个Lucene实例，在它的能力范围内拥有完整的搜索功能(在处理它自己拥有的数据时有所有的功能)。我们所有文档的索引indexed(动词)和存储工作都是在shard上，但这是透明的，我们不需要直接和shard通信，而是和我们创建的index(名词)通信。

shards是ES将数据分布式在你的集群的关键。想象下shards是数据的容器，文档存储在shards里，而shards被分配在集群的每一个节点Node里。当你的集群规模增长和降低时，ES会自动的在Nodes间迁移shards以保持集群的负载均衡。

（2）备份
shard可分为primary shard和replica shard。 在一个index里的每一个文档都属于一个单独的primary shard，所以primary shard的数量决定了你最大能存储的数据量(对应于一个index)。
注意：shard是归属与index的，而不是cluster的。
replica shard是primary shard的拷贝。replica有两个作用： 1.冗余容灾 2.提供读请求服务，例如搜索或读取文档primary shard的数量在索引创建时确定后不能修改，replica可以在任何时候修改。

（3）Shards文档路由
当你对一个文档建立索引时，它仅存储在一个primary shard上。ES是怎么知道一个文档应该属于哪个shard？当你创建一个新的文档时，ES是怎么知道应该把它存储至shard1还是shard2？ 这个过程不能随机无规律的，因为以后我们还要将它取出来。它的路由算法是：
shard = hash(routing) % numberofprimary_shards routing的值可以是文档的id，也可以是用户自己设置的一个值。hash将会根据routing算出一个数值然后%primaryshards的数量。这也是为什么primary_shards在index创建时就不能修改的原因。我们可以向这个集群的任何一台NODE发送请求，每一个NODE都有能力处理请求。每一个NODE都知道每一个文档所在的位置所以可以直接将请求路由过去。下面的例子，我们将所有的请求都发送到NODE1。

（4）写操作
创建、索引、删除文档都是写操作，这些操作必须在primary shard完全成功后才能拷贝至其对应的replicas上。


1）.客户端向Node1发送写操作的请求。
2）.Node1使用文档的_id来决定这个文档属于shard0，然后将请求路由至NODE3，P0所在的位置。
3）.Node3在P0上执行了请求。如果请求成功，则将请求并行的路由至NODE1 NODE2的R0上。当所有的replicas报告成功后，NODE3向请求的node(NODE1)发送成功报告，NODE1再报告至Client。当客户端收到执行成功后，操作已经在Primary shard和所有的replica shards上执行成功了。当然，有一些请求参数可以修改这个逻辑。见原文。

（5）读操作
一个文档可以在primary shard和所有的replica shard上读取。

读操作步骤：

1）.客户端发送Get请求到NODE1。
2）.NODE1使用文档的_id决定文档属于shard 0.shard 0的所有拷贝存在于所有3个节点上。这次，它将请求路由至NODE2。
3）.NODE2将文档返回给NODE1，NODE1将文档返回给客户端。 对于读请求，请求节点(NODE1)将在每次请求到来时都选择一个不同的replica。
shard来达到负载均衡。使用轮询策略轮询所有的replica shards。

（6）更新操作
更新操作，结合了以上的两个操作：读、写。
步骤：
1）.客户端发送更新操作请求至NODE1
2）.NODE1将请求路由至NODE3，Primary shard所在的位置
3）.NODE3从P0读取文档，改变source字段的JSON内容，然后试图重新对修改后的数据在P0做索引。如果此时这个文档已经被其他的进程修改了，那么它将重新执行3步骤，这个过程如果超过了retryon_conflict设置的次数，就放弃。
4）.如果NODE3成功更新了文档，它将并行的将新版本的文档同步到NODE1和NODE2的replica shards重新建立索引。一旦所有的replica
shards报告成功，NODE3向被请求的节点(NODE1)返回成功，然后NODE1向客户端返回成功。

（7）查询操作


9 ES 搜索类型[query type]
（1）分布式搜索背景
ES天生就是为分布式而生，但分布式有分布式的缺点。比如要搜索某个单词，但是数据却分别在5个分片（Shard)上面，这5个分片可能在5台主机上面。因为全文搜索天生就要排序（按照匹配度进行排名）,但数据却在5个分片上，如何得到最后正确的排序呢？ES是这样做的，大概分两步。
step1、ES客户端会将这个搜索词同时向5个分片发起搜索请求，这叫Scatter,
step2、这5个分片基于本Shard独立完成搜索，然后将符合条件的结果全部返回，这一步叫Gather。
客户端将返回的结果进行重新排序和排名，最后返回给用户。也就是说，ES的一次搜索，是一次scatter/gather过程（这个跟mapreduce也很类似）.
 
（2）然而这其中有两个问题。
第一、数量问题。比如，用户需要搜索"双黄连"，要求返回最符合条件的前10条。但在5个分片中，可能都存储着双黄连相关的数据。所以ES会向这5个分片都发出查询请求，并且要求每个分片都返回符合条件的10条记录。当ES得到返回的结果后，进行整体排序，然后取最符合条件的前10条返给用户。这种情况，ES5个shard最多会收到10*5=50条记录，这样返回给用户的结果数量会多于用户请求的数量。
第二、排名问题。上面搜索，每个分片计算分值都是基于自己的分片数据进行计算的。计算分值使用的词频率和其他信息都是基于自己的分片进行的，而ES进行整体排名是基于每个分片计算后的分值进行排序的，这就可能会导致排名不准确的问题。如果我们想更精确的控制排序，应该先将计算排序和排名相关的信息（词频率等）从5个分片收集上来，进行统一计算，然后使用整体的词频率去每个分片进行查询。
 
（3）这两个问题，估计ES也没有什么较好的解决方法，最终把选择的权利交给用户，方法就是在搜索的时候指定query type。
1）、query and fetch
向索引的所有分片（shard）都发出查询请求，各分片返回的时候把元素文档（document）和计算后的排名信息一起返回。这种搜索方式是最快的。因为相比下面的几种搜索方式，这种查询方法只需要去shard查询一次。但是各个shard返回的结果的数量之和可能是用户要求的size的n倍。
2）、query then fetch（默认的搜索方式）
如果你搜索时，没有指定搜索方式，就是使用的这种搜索方式。这种搜索方式，大概分两个步骤，第一步，先向所有的shard发出请求，各分片只返回排序和排名相关的信息（注意，不包括文档document)，然后按照各分片返回的分数进行重新排序和排名，取前size个文档。然后进行第二步，去相关的shard取document。这种方式返回的document与用户要求的size是相等的。
3）、DFS query and fetch
这种方式比第一种方式多了一个初始化散发(initial scatter)步骤，有这一步，据说可以更精确控制搜索打分和排名。
4）、DFS query then fetch
比第2种方式多了一个初始化散发(initial scatter)步骤。
DSF是什么缩写？初始化散发是一个什么样的过程？从es的官方网站我们可以指定，初始化散发其实就是在进行真正的查询之前，先把各个分片的词频率和文档频率收集一下，然后进行词搜索的时候，各分片依据全局的词频率和文档频率进行搜索和排名。显然如果使用DFS_QUERY_THEN_FETCH这种查询方式，效率是最低的，因为一个搜索，可能要请求3次分片。但，使用DFS方法，搜索精度应该是最高的。至于DFS是什么缩写，没有找到相关资料，这个D可能是Distributed，F可能是frequency的缩写，至于S可能是Scatter的缩写，整个单词可能是分布式词频率和文档频率散发的缩写。
总结一下，从性能考虑QUERY_AND_FETCH是最快的，DFS_QUERY_THEN_FETCH是最慢的。从搜索的准确度来说，DFS要比非DFS的准确度更高。


10 更新文档（类似mysql update操作）
http://localhost:9200/blog/ariticle/1/_update/ POST 
{“script”:”ctx._source.content = \”new version 2.0 20160714\”“}
更新后结果显示： 
{
“_index”: “blog”,
“_type”: “ariticle”,
“_id”: “1”,
“_version”: 2,
“_shards”: { 
”total”: 2,
“successful”: 1,
“failed”: 0
}
}

查询&验证更新后结果：（对比可知，版本号已经更新完毕） 
http://localhost:9200/blog/ariticle/1/
{
- "_index": "blog",
- "_type": "ariticle",
- "_id": "1",
- "_version": 2,
- "found": true,
- "_source": {
    - "title": "New version of Elasticsearch released!",
    - "content": "new version 2.0 20160714",
    - "tags": [
        - "announce"
        - ,
        - "elasticsearch"
        - ,
        - "release"
    - ]
- }
}
注意更新文档需要在elasticsearch_win\config\elasticsearch.yml下新增以下内容：
script.groovy.sandbox.enabled: true 
script.engine.groovy.inline.search: on 
script.engine.groovy.inline.update: on 
script.inline: on 
script.indexed: on 
script.engine.groovy.inline.aggs: on 
index.mapper.dynamic: true

11 删除文档（类似mysql delete操作）
http://localhost:9200/blog/ariticle/8/回结果
{
- "found": true,
- "_index": "blog",
- "_type": "ariticle",
- "_id": "8",
- "_version": 2,
- "_shards": {
    - "total": 2,
    - "successful": 1,
    - "failed": 0
- }
}

12 ES-Hadoop简介
连接快速查询和大数据分析的桥梁，它能够无间隙的在hadoop和ElasticSearch上移动数据。ES Hadoop索引Hadoop数据到Elasticsearch，充分利用其查询速度，大量聚合能力来使它比以往更快，同时可以使用HDFS作为Elasticsearch长期存档。ES-Hadoop可以本地集成Hadoop生态系统上的很多流行组件，比如Spark、Hive、Pig、Storm、MapReduce等。官方有张图可以很好说明。

13 Logstash
logstash是一个数据分析软件，主要目的是分析log日志。整一套软件可以当作一个MVC模型，logstash是controller层，Elasticsearch是一个model层，kibana是view层。首先将数据传给logstash，它将数据进行过滤和格式化（转成JSON格式），然后传给Elasticsearch进行存储、建搜索的索引，kibana提供前端的页面再进行搜索和图表可视化，它是调用Elasticsearch的接口返回的数据进行可视化。logstash和Elasticsearch是用Java写的，kibana使用node.js框架。Logstash是一个接收，处理，转发日志的工具。支持系统日志，webserver日志，错误日志，应用日志，总之包括所有可以抛出来的日志类型。


14 配置总结
（1）配置的组成
Inputs,Outputs,Codecs,Filters构成了Logstash的核心配置项。Logstash通过建立一条事件处理的管道，从你的日志提取出数据保存到Elasticsearch中，为高效的查询数据提供基础。为了让你快速的了解Logstash提供的多种选项，让我们先讨论一下最常用的一些配置。更多的信息，请参考 Logstash事件管道 。

（2）Inputs
input 及输入是指日志数据传输到Logstash中。其中常见的配置如下：
file：从文件系统中读取一个文件，很像UNIX命令 "tail -0a"
syslog：监听514端口，按照RFC3164标准解析日志数据
redis：从redis服务器读取数据，支持channel(发布订阅)和list模式。redis一般 在Logstash消费集群中 作为"broker"角色，保存events队列共Logstash消费。
lumberjack：使用lumberjack协议来接收数据，目前已经改为 logstash-forwarder。

input {
  #file可以多次使用，也可以只写一个file而设置它的path属性配置多个文件实现多文件监控
  file {
    #type是给结果增加了一个属性叫type值为"<xxx>"的条目。这里的type，对应了ES中index中的type，即如果输入ES时，没有指定type，那么这里的type将作为ES中index的type。
    type => "apache-access" 
    path => "/apphome/ptc/Windchill_10.0/Apache/logs/access_log*"
    #start_position可以设置为beginning或者end，beginning表示从头开始读取文件，end表示读取最新的，这个也要和ignore_older一起使用。
    start_position => beginning
    #sincedb_path表示文件读取进度的记录，每行表示一个文件，每行有两个数字，第一个表示文件的inode，第二个表示文件读取到的位置（byteoffset）。默认为$HOME/.sincedb*
    sincedb_path => "/opt/logstash-2.3.1/sincedb_path/access_progress"
    #ignore_older表示了针对多久的文件进行监控，默认一天，单位为秒，可以自己定制，比如默认只读取一天内被修改的文件。
    ignore_older => 604800
    #add_field增加属性。这里使用了${HOSTNAME}，即本机的环境变量，如果要使用本机的环境变量，那么需要在启动命令上加--alow-env。
    add_field => {"log_hostname"=>"${HOSTNAME}"}
    #这个值默认是\n 换行符，如果设置为空""，那么后果是每个字符代表一个event
    delimiter => ""
    #这个表示关闭超过（默认）3600秒后追踪文件。这个对于multiline来说特别有用。... 这个参数和logstash对文件的读取方式有关，两种方式read tail，如果是read
    close_older => 3600
    coodec => multiline {
      pattern => "^\s"
      #这个negate是否定的意思，意思跟pattern相反，也就是不满足patter的意思。
#      negate => ""
      #what有两个值可选 previous和next，举例说明，java的异常从第二行以空格开始，这里就可以pattern匹配空格开始，what设置为previous意思是空格开头这行跟上一行属于同一event。另一个例子，有时候一条命令太长，当以\结尾时表示这行属于跟下一行属于同一event，这时需要使用negate=>true，what=>'next'。
      what => "previous"
      auto_flush_interval => 60
    }
  }
  file { 
    type => "methodserver-log" 
    path => "/apphome/ptc/Windchill_10.0/Windchill/logs/MethodServer-1604221021-32380.log" 
    start_position => beginning 
    sincedb_path => "/opt/logstash-2.3.1/sincedb_path/methodserver_process"
#    ignore_older => 604800
  }
}


（3）Filters
Fillters 在Logstash处理链中担任中间处理组件。他们经常被组合起来实现一些特定的行为来，处理匹配特定规则的事件流。常见的filters如下：
grok：解析无规则的文字并转化为有结构的格式。Grok 是目前最好的方式来将无结构的数据转换为有结构可查询的数据。有120多种匹配规则，会有一种满足你的需要。
mutate：mutate filter 允许改变输入的文档，你可以从命名，删除，移动或者修改字段在处理事件的过程中。
drop：丢弃一部分events不进行处理，例如：debug events。
clone：拷贝 event，这个过程中也可以添加或移除字段。
geoip：添加地理信息(为前台kibana图形化展示使用)

filter{
  #执行ruby程序，下面例子是将日期转化为字符串赋予daytag
  ruby {
    code => "event['daytag'] = event.timestamp.time.localtime.strftime('%Y-%m-%d')"
  }
  # if [path] =~ "access" {} else if [path] =~ "methodserver" {} else if [path] =~ "servermanager" {} else {} 注意语句结构
  if [path] =~ "MethodServer" { #z这里的=~是匹配正则表达式
    grok {
      patterns_dir => ["/opt/logstash-2.3.1/patterns"] #自定义正则匹配
#      Tue 4/12/16 14:24:17: TP-Processor2: hirecode---->77LS
      match => { "message" => "%{DAY:log_weekday} %{DATE_US:log_date} %{TIME:log_time}: %{GREEDYDATA:log_data}"}
    }
    #mutage是做转换用的
    mutate { 
      replace => { "type" => "apache" } #替换属性值
      convert => { #类型转换
        "bytes" => "integer" #例如还有float
        "duration" => "integer"
        "state" => "integer"
      }
    #date主要是用来处理文件内容中的日期的。内容中读取的是字符串，
通过date将它转换为@timestamp。参考https://www.elastic.co/guide/en/logstash/current/plugins-filters-date.html#plugins-filters-date-match
#    date {
#      match => [ "logTime" , "dd/MMM/yyyy:HH:mm:ss Z" ]
#    }
  }else if [type] in ['tbg_qas','mbg_pre'] { # if ... else if ... else if ... else结构
  }else {
    drop{} # 将event丢弃
  }
}


（4）Outputs
outputs是logstash处理管道的最末端组件。一个event可以在处理过程中经过多重输出，但是一旦所有的outputs都执行结束，这个event也就完成生命周期。一些常用的outputs。

elasticsearch：如果你计划将高效的保存数据，并且能够方便和简单的进行查询...Elasticsearch是一个好的方式。
file：将event数据保存到文件中。
graphite：将event数据发送到图形化组件中，一个很流行的开源存储图形化展示的组件。 http://graphite.wikidot.com/ 。
statsd：statsd是一个统计服务，比如技术和时间统计，通过udp通讯，聚合一个或者多个后台服务，如果你已经开始使用statsd，该选项对你应该很有用。

output {
  stdout{ codec=>rubydebug} # 直接输出，调试用起来方便
  # 输出到redis
  redis {
    host => '10.120.20.208'
    data_type => 'list'
    key => '10.99.201.34:access_log_2016-04'
  }
  # 输出到ES
  elasticsearch {
    hosts =>"192.168.0.15:9200"
    index => "%{sysid}_%{type}"
    document_type => "%{daytag}"
  }
}

（5）Codecs
codecs 是基于数据流的过滤器，它可以作为input，output的一部分配置。Codecs可以帮助你轻松的分割发送过来已经被序列化的数据。流行的codecs包括 json,msgpack,plain(text)。
json：使用json格式对数据进行编码/解码
multiline：将汇多个事件中数据汇总为一个单一的行。比如：java异常信息和堆栈信息


14 Kinaba
Kibana是一个开源的分析与可视化平台
设计出来用于和Elasticsearch一起使用的。你可以用kibana搜索、查看、交互存放在Elasticsearch索引里的数据，使用各种不同的图表、表格、地图等kibana能够很轻易地展示高级数据分析与可视化。Kibana让我们理解大量数据变得很容易。它简单、基于浏览器的接口使你能快速创建和分享实时展现Elasticsearch查询变化的动态仪表盘。安装Kibana非常快，你可以在几分钟之内安装和开始探索你的Elasticsearch索引数据—-—-不需要写任何代码，没有其他基础软件依赖。（注意：这里只介绍Kibana如何使用，更多关于Kibana 4.3版本更新查看https://www.elastic.co/guide/en/kibana/current/releasenotes.html）


15 Kinaba一些基础
@基础：
metrics 度量
Y轴 平均数 最大值 最小值 总数 唯一的数量 百分比
出现多列 则统计多个值，下面有table形式
Search可以搜索关键字筛选，筛选出的结果集进行聚合 
buckets 桶 X-Axis X轴一般是时间，柱状图也可以是terms 
一般统计的是所有的频道，如果要分开：
Split Series:按照系列切分，一个图表出现多条线。
Split Chart:按照图表切分，分为行和列，行切分出现三行图表，每个设备独占一个。
行切分出现三列图表，每个设备独占一个。

@Line线图,area 图：
多条线：
可以是统计所有设备的CPU平均律，内存平均律，2条线
可以是统计各个设备的CPU平均律，3条线
可以是统计各个设备的CPU平均律，内存平均律  一共6条线

16 Heatbeat
1） HA概念
(high available)高可用，又被叫做双机热备，用于关键性业务。简单理解就是，有2台机器 A 和 B，正常是 A 提供服务，B 待命闲置，当 A 宕机或服务宕掉，会切换至B机器继续提供服务。常见的实现高可用的开源软件有 heartbeat 和 keepalived。这样，一台 web 服务器一天24小时提供web服务，难免会存在 web 服务挂掉或服务器宕机宕机的情况，那么用户就访问不了服务了，这当然不是我们期望的。如果这样，有2台服务器，A对外提供 web 服务，B作为备用，如果A挂掉，那么B立刻替代A的位置去提供 web 服务，这样对用户来说是透明的。但是有个问题，服务器A的 ip 是 10.0.0.100，服务器B的 ip 是 10.0.0.101，显然向用户提供A或B的ip地址是不可行的，因为用户总不能去切换ip来访问的吧。这时heartbeat或keepalived可以提供一个虚拟IP：10.0.0.102，用户只需要访问 10.0.0.102，当A提供服务时，VIP 会设置在A服务器上，当B提供服务时，VIP会设置在B服务器上，这样就可以让用户通过访问 10.0.0.102 来获取web服务，即使A或B服务器切换也不影响用户的正常访问。下面我们使用 heartbeat 来做 HA 集群，并且把 nginx 服务作为 HA 对应的服务。
2） Heartbaet 
一款开源高可用（Highly-Available）服务的软件，通过heartbeat,  可以将资源（ip及程序服务等资源）从一台已故障的计算机快速转移到另一台正常运转的机器上继续提供服务，一般称之为高可用服务。在实际成产应用场景中，heartbeat的功能和另一个高可用开源软件keeplived有很多相同之处，但在生产中，对应实际的业务应用也是有区别的，例如：keeplived主要是控制ip的漂移，配置、应用简单，而hearbeat则不但可以控制ip的漂移，更擅长对资源服务的控制（mysql的重启），配置，应用比较复杂。
3） Heartbeat工作原理
keeplived和heartbeat高可用是操作系统级别的，不是（软件级别的），可以通过简单的脚本，实现软件级别的高可用。
heartbeat的主备模式 ，通过修改heatbeat软件的配置文件，可以指定那一台heartbeat服务器为主服务器，则另一台将自动成为热备服务器。然后再热备服务器上配置Heartbeat守护程序来监听自服务器的心跳信息。如果热备服务器在指定时间内未监听到来自主服务器的心跳，就会启动故障转移程序，并取得主服务器的相关资源服务的权限，接替主服务器继续不间断的提供服务，从而达到资源及服务高可用性的目的。
heartbeat还支持主主模式（可以针对不同的业务），及两台服务器互为主备，这时他们之间会相互发送报文来告诉对方自己的当前的状态，如果在指定的时间内未收到对方发送的心跳报文，那么一方就会认为对方实效或者宕机，这时美个运行正常的主机就会启动自身的资源接管模块来接管运行在对方主机上的资源或者服务，继续为用户提供服务。一般情况下，可以较好的实现一台主机故障后，企业服务仍能够不间断的持续运行。注意，所谓的业务不间断，在故障转移期间也是需要切换时间的（例如：停止数据库及存储服务等），heartbeat的主备高可用的切换时间一般是在5-20秒左右（服务器的宕机比人工切换服务快）。

17 Filebeat 
1 Filebeat简介
是一个日志文件托运工具，在你的服务器上安装客户端后，filebeat会监控日志目录或者指定的日志文件，追踪读取这些文件（追踪文件的变化，不停的读），并且转发这些信息到elasticsearch或者logstarsh中存放。以下是filebeat的工作流程：当你开启filebeat程序的时候，它会启动一个或多个探测器（prospectors）去检测你指定的日志目录或文件，对于探测器找出的每一个日志文件，filebeat启动收割进程（harvester），每一个收割进程读取一个日志文件的新内容，并发送这些新的日志数据到处理程序（spooler），处理程序会集合这些事件，最后filebeat会发送集合的数据到你指定的地点。filebeat是一个轻量级的logstash，当你需要收集信息的机器配置或资源并不是特别多时，使用filebeat来收集日志。日常使用中，filebeat十分稳定，笔者没遇到过宕机。




二、ms相关
1.ELK 是什么？
ELK 其实并不是一款软件，而是一整套解决方案，是三个软件产品的首字母缩写
Elasticsearch：负责日志检索和储存
Logstash：负责日志的收集和分析、处理
Kibana：负责日志的可视化
这三款软件都是开源软件，通常是配合使用，而且又先后归于 Elastic.co 公司名下，
故被简称为 ELK。加入 Beats 系列组件后，官方名称就变为了 Elastic Stack

2.ELK 能做什么？
ELK 组件在海量日志系统的运维中，可用于解决：
分布式日志数据集中式查询和管理、系统监控，包含系统硬件和应用各个组件的监控、
故障排查、安全信息和事件管理、报表功能等等

3.简要概述 Elasticsearch？
ElasticSearch 是一个基于 Lucene 的搜索服务器。它提供了一个分布式多用户能力的
全文搜索引擎，基于 RESTful API 的 web 接口。
Elasticsearch 是用 Java 开发的，并作为 Apache 许可条款下的开放源码发布，是当前
流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装
使用方便

4.Elasticsearch 主要特点
1.实时分析
2.分布式实时文件存储，并将每一个字段都编入索引
3.文档导向，所有的对象全部是文档
4.高可用性，易扩展，支持集群（Cluster）、分片和复制（Shards 和 Replicas）
接口友好，支持 JSON

5.ES 相关概念
Node： 装有一个 ES 服务器的节点。
Cluster： 有多个 Node 组成的集群
Document： 一个可被搜素的基础信息单元
Index： 拥有相似特征的文档的集合
Type： 一个索引中可以定义一种或多种类型
Filed： 是 ES 的最小单位，相当于数据的某一列
Shards： 索引的分片，每一个分片就是一个 Shard
Replicas： 索引的拷贝

6.什么是分词器
分词是将文本转换成一系列单词（Term or Token）的过程，也可以叫文本分析，在 ES
里面称为 Analysis
分词器是 ES 中专门处理分词的组件，英文为 Analyzer，它的组成如下：
Character Filters：针对原始文本进行处理，比如去除 html 标签
Tokenizer：将原始文本按照一定规则切分为单词
Token Filters：针对 Tokenizer 处理的单词进行再加工，比如转小写、删除或增新等
处理
ES 提供了一个可以测试分词的 API 接口，方便验证分词效果，endpoint 是_analyze
ES 也提供了很多内置的分析器。

7.elasticsearch 的倒排索引是什么？
正排索引是以文档的 ID 为关键字，表中记录文档中每个字的位置信息，查找时扫描表
中每个文档中字的信息直到找出所有包含查询关键字的文档。
而倒排索引，是通过分词策略，形成了词和文章的映射关系表，这种词典+映射表即为
倒排索引。
有了倒排索引，就能实现 o（1）时间复杂度的效率检索文章了，极大的提高了检索效
率。
所以总的来说，正排索引是从文档到关键字的映射（已知文档求关键字），倒排索引是
从关键字到文档的映射（已知关键字求文档）。

8.Elasticsearch 是如何实现 Master 选举的？
采用 Bully 算法，它假定所有节点都有一个唯一的 ID，使用该 ID 对节点进行排序。
Elasticsearch 的选主是 ZenDiscovery 模块负责的，主要包含 Ping（节点之间通过这个 RPC
来发现彼此）和 Unicast（单播模块包含一个主机列表以控制哪些节点需要 ping 通）这两
部分；
对所有可以成为 master 的节点（node.master: true）根据 nodeId 字典排序，每次选
举每个节点都把自己所知道节点排一次序，然后选出第一个（第 0 位）节点，暂且认为它是
master 节点。
如果对某个节点的投票数达到一定的值（可以成为 master 节点数 n/2+1）并且该节点
自己也选举自己，那这个节点就是 master。否则重新选举一直到满足上述条件。
补充：master 节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；
data 节点可以关闭 http 功能。
7.X 之后的 ES，采用一种新的选主算法，实际上是 Raft 的实现，但并非严格按照 Raft
论文实现，而是做了一些调整。Raft 是工程上使用较为广泛分布式共识协议，是多个节点
对某个事情达成一致的看法，即使是在部分节点故障、网络延时、网络分区的情况下。

9.Elasticsearch 如何避免脑裂？
ES 集群中的节点（比如共 20 个），其中的 10 个选了一个 master，另外 10 个选了另一
个 master，怎么办？
当集群 master 候选数量不小于 3 个时，可以通过设置最少投票通过数量
（discovery.zen.minimum_master_nodes）超过所有候选节点一半以上来解决脑裂问题；
当候选数量为两个时，只能修改为唯一的一个 master 候选，其他作为 data 节点，避免
脑裂问题。
在 Elasticsearch 7.0 里重新设计并重建了的集群协调子系统，移除
minimum_master_nodes 参数，转而由集群自主控制。

10.详细描述一下 Elasticsearch 索引文档的过程
协调节点默认使用文档 ID 参与计算（也支持通过 routing），以便为路由提供合适的
分片。
shard = hash(document_id) % (num_of_primary_shards)
当分片所在的节点接收到来自协调节点的请求后，会将请求写入到 Memory Buffer，然
后定时（默认是每隔 1 秒）写入到 Filesystem Cache，这个从 Momery Buffer 到 Filesystem
Cache 的过程就叫做 refresh；
当然在某些情况下，存在 Momery Buffer 和 Filesystem Cache 的数据可能会丢失，ES
是通过 translog 的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写
入到 translog 中，当 Filesystem cache 中的数据写入到磁盘中时，才会清除掉，这个过程
叫做 flush； 在 flush 过程中，内存中的缓冲将被清除，内容被写入一个新段，段的 fsync 将创建一
个新的提交点，并将内容刷新到磁盘，旧的 translog 将被删除并开始一个新的 translog。
flush 触发的时机是定时触发（默认 30 分钟）或者 translog 变得太大（默认为 512M）
时；

11.请概述 Elasticsearch 搜索的过程？
搜索拆解为“query then fetch” 两个阶段。
query 阶段的目的：定位到位置，但不取。
步骤拆解如下：
1）假设一个索引数据有 5 主+1 副本 共 10 分片，一次请求会命中（主或者副本分片中）
的一个。
2）每个分片在本地进行查询，结果返回到本地有序的优先队列中。
3）第 2）步骤的结果发送到协调节点，协调节点产生一个全局的排序列表。
fetch 阶段的目的：取数据。
路由节点获取所有文档，返回给客户端。
---------------------------------------------------------------------------------------------------------------
------------------------------------------elk basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------flume basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 Flume
Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。当前Flume有两个版本Flume 0.9X版本的统称Flume-og，Flume1.X版本的统称Flume-ng。由于Flume-ng经过重大重构，与Flume-og有很大不同，使用时请注意区分。
分布式的日志收集系统，它将各个服务器中的数据收集起来并送到指定的地方去，比如说送到图中的HDFS，简单来说flume就是收集日志的。

2 flume架构介绍 
flume之所以这么神奇，是源于它自身的一个设计，这个设计就是agent，agent本身是一个java进程，运行在日志收集节点—所谓日志收集节点就是服务器节点。 
agent里面包含3个核心的组件：source—->channel—–>sink,类似生产者、仓库、消费者的架构。 
source：source组件是专门用来收集数据的，可以处理各种类型、各种格式的日志数据,包括avro、thrift、exec、jms、spooling directory、netcat、sequence generator、syslog、http、legacy、自定义。 
channel：source组件把数据收集来以后，临时存放在channel中，即channel组件在agent中是专门用来存放临时数据的——对采集到的数据进行简单的缓存，可以存放在memory、jdbc、file等等。 
sink：sink组件是用于把数据发送到目的地的组件，目的地包括hdfs、logger、avro、thrift、ipc、file、null、hbase、solr、自定义。
 
3 flume的运行机制 
flume的核心就是一个agent，这个agent对外有两个进行交互的地方，一个是接受数据的输入——source，一个是数据的输出sink，sink负责将数据发送到外部指定的目的地。source接收到数据之后，将数据发送给channel，chanel作为一个数据缓冲区会临时存放这些数据，随后sink会将channel中的数据发送到指定的地方—-例如HDFS等，注意：只有在sink将channel中的数据成功发送出去之后，channel才会将临时数据进行删除，这种机制保证了数据传输的可靠性与安全性。 



二、ms相关
1 Flume 采集数据会丢失吗?
不会，Channel 存储可以存储在 File 中，数据传输自身有事务。
不会，因为 channel 可以存储在 file 中，而且 flume 本身是有事务的。
可以做 sink 组，一个坏掉了，就用另一个。

2 Flume 与 Kafka 的选取？
采集层主要可以使用 Flume、Kafka 两种技术。
Flume：Flume 是管道流方式，提供了很多的默认实现，让用户通过参数部署，及扩展 API。
Kafka：Kafka 是一个可持久化的分布式的消息队列。
Kafka 是一个非常通用的系统。你可以有许多生产者和很多的消费者共享多个主题Topics。相比之下，Flume 是一个专用工具被设计为旨在往 HDFS，HBase 发送数据。它对HDFS 有特殊的优化，并且集成了 Hadoop 的安全特性。所以，Cloudera 建议如果数据被多个系统消费的话，使用 kafka；如果数据被设计给 Hadoop 使用，使用 Flume。正如你们所知 Flume 内置很多的 source 和 sink 组件。然而，Kafka 明显有一个更小的生产消费者生态系统，并且 Kafka 的社区支持不好。希望将来这种情况会得到改善，但是目前：使用 Kafka 意味着你准备好了编写你自己的生产者和消费者代码。如果已经存在的 Flume Sources 和 Sinks 满足你的需求，并且你更喜欢不需要任何开发的系统，请使用 Flume。Flume 可以使用拦截器实时处理数据。这些对数据屏蔽或者过量是很有用的。Kafka 需要外部的流处理系统才能做到。
Kafka 和 Flume 都是可靠的系统,通过适当的配置能保证零数据丢失。然而，Flume 不支持副本事件。于是，如果 Flume 代理的一个节点奔溃了，即使使用了可靠的文件管道方式，你也将丢失这些事件直到你恢复这些磁盘。如果你需要一个高可靠行的管道，那么使用Kafka 是个更好的选择。
Flume 和 Kafka 可以很好地结合起来使用。如果你的设计需要从 Kafka 到 Hadoop 的流数据，使用 Flume 代理并配置 Kafka 的 Source 读取数据也是可行的：你没有必要实现自己的消费者。你可以直接利用Flume 与HDFS 及HBase 的结合的所有好处。你可以使用ClouderaManager 对消费者的监控，并且你甚至可以添加拦截器进行一些流处理。

3 数据怎么采集到 Kafka，实现方式？
使用官方提供的 flumeKafka 插件，插件的实现方式是自定义了 flume 的 sink，将数据从channle 中取出，通过 kafka 的producer 写入到 kafka 中，可以自定义分区等。

4 flume 管道内存，flume 宕机了数据丢失怎么解决？
1）Flume 的 channel 分为很多种，可以将数据写入到文件。
2）防止非首个 agent 宕机的方法数可以做集群或者主备。

5 flume 和 kafka 采集日志区别，采集日志时中间停了，怎么记录之前的日志？
Flume 采集日志是通过流的方式直接将日志收集到存储层，而 kafka 是将缓存在 kafka集群，待后期可以采集到存储层。
Flume 采集中间停了，可以采用文件的方式记录之前的日志，而 kafka 是采用 offset 的方式记录之前的日志。

6 flume 有哪些组件，flume 的 source、channel、sink 具体是做什么的？
1）source：用于采集数据，Source 是产生数据流的地方，同时 Source 会将产生的数据
流传输到 Channel，这个有点类似于 Java IO 部分的 Channel。
2）channel：用于桥接 Sources 和 Sinks，类似于一个队列。
3）sink：从 Channel 收集数据，将数据写到目标源(可以是下一个 Source，也可以是 HDFS
或者 HBase)。
source ：搜集数据
channel ：数据缓存
sink ：把数据发送到目的地
常用 source 类型 ：
1、 监控文件 ：exec
2、监控目录 ：spooldir

7 为什么使用Flume？
1）Flume可以将应用产生的数据存储到任何集中存储器中，比如HDFS,HBase
2）当收集数据的速度超过将写入数据的时候，也就是当收集信息遇到峰值时，这时候收集的信息非常大，甚至超过了系统的写入数据能力，
   这时候，Flume会在数据生产者和数据收容器间做出调整，保证其能够在两者之间提供平稳的数据.
3）提供上下文路由特征
4）Flume的管道是基于事务，保证了数据在传送和接收时的一致性.
5）Flume是可靠的，容错性高的，可升级的，易管理的,并且可定制的。

8 Flume组成架构？
关于flume事务
flume要尽可能的保证数据的安全性，其在source推送数据到channel以及sink从channel拉取数据时都是以事务方式进行的。因为在agent内的两次数据传递间都会涉及到数据的传送、从数据上游删除数据的问题；就比如sink从channel拉取数据并提交到数据下游之后需要从channel中删除已获取到的批次数据，其中跨越了多个原子事件，故而需要以事务的方式将这些原子事件进一步绑定在一起，以便在其中某个环节出错时进行回滚防止数据丢失。所以在选用file channel时一般来说是不会丢失数据的。
channel ： 是位于 source 和 sink 之间的缓冲区。
1）flume 自带两种缓冲区，file channel 和 memory channel
2）file channel ： 硬盘缓冲区，性能低，但是安全。系统宕机也不会丢失数据。
3）memory channel ：内存缓冲区，性能高，但是有可能丢数据，在不关心数据有可能丢失的情况下使用。
put 事务流程 ： 源将数据给管道
1）doPut ：把数据写入临时缓冲区 putList 。
2）doCommit ：检查 channel 内存队列是否足够合并。
3）doRollBack ： 如果 channel 不行，我们就回滚数据。
take 事务流程 ：
1）先将数据取到临时缓冲区 takeList。
2）doCommit ：如果数据全部发送成功，就清除临时缓冲区。
3）doRollBack ：如果数据发送过程中出现异常，doRollBack 将临时缓冲区的数据还给 channel 队列

9 FlumeAgent内部原理？
Flume Agent中包含了三个重要的组件，Source，Channel，Sink。
1）.Source
Source是从其他生产数据的应用中接受数据的组件。Source可以监听一个或者多个网络端口，用于接受数据或者从本地文件系统中读取数据，每个Source必须至少连接一个Channel。当然一个Source也可以连接多个Channnel，这取决于系统设计的需要。
2）.Channel
Channel主要是用来缓冲Agent以及接受，但尚未写出到另外一个Agent或者存储系统的数据。Channel的行为比较像队列，Source写入到他们，Sink从他们中读取数据。多个Source可以安全的写入到同一Channel中，并且多个Sink可以从同一个Channel中读取数据。可是一个Sink只能从一个Channel读取数据，如果多个Sink从相同的Channel中读取数据，系统可以保证只有一个Sink会从Channel读取一个特定的事件。
3）.Sink
Sink会连续轮训各自的Channel来读取和删除事件。Sink将事件推送到下一阶段（RPC Sink的情况下），或者到达最终目的地。一旦在下一阶段或者其目的地中数据是安全的,Sink通过事务提交通知Channel，可以从Channel中删除这一事件。

10 Flume Event 是数据流的基本单元。
它由一个装载数据的字节数组(byte payload)和一系列可选的字符串属性来组成(可选头部)。

11 Flume agent
Flume source 消耗从类似于 web 服务器这样的外部源传来的 events.
外部数据源以一种 Flume source 能够认识的格式发送 event 给 Flume source.
Flume source 组件可以处理各种类型、各种格式的日志数据，包括 avro、thrift、exec、jms、spooling directory、netcat、sequence generator、syslog、http、legacy.
flume source 是负责接收数据到 Flume Agent 的组件

12 Flume channel
当 Flume source 接受到一个 event 的时, Flume source 会把这个 event 存储在一个或多个 channel 中.
Channel 是连接Source和Sink的组件, 是位于 Source 和 Sink 之间的数据缓冲区。
Flume channel 使用被动存储机制. 它存储的数据的写入是靠 Flume source 来完成的, 数据的读取是靠后面的组件 Flume sink 来完成的.
Channel 是线程安全的，可以同时处理几个 Source 的写入操作和几个 Sink 的读取操作。
Flume 自带两种 Channel：
Memory Channel
Memory Channel是内存中的队列。
Memory Channel在不需要关心数据丢失的情景下适用。
如果需要关心数据丢失，那么Memory Channel就不应该使用，因为程序死亡、机器宕机或者重启都会导致数据丢失。
File Channel
File Channel将所有事件写到磁盘。
因此在程序关闭或机器宕机的情况下不会丢失数据。
还可以有其他的 channel: 比如 JDBC channel。

13 Flume sink
Sink 不断地轮询 Channel 中的事件且批量地移除它们，并将这些事件批量写入到存储或索引系统、或者发送到另一个Flume Agent。
Sink 是完全事务性的。
在从 Channel 批量删除数据之前，每个 Sink 用 Channel 启动一个事务。批量事件一旦成功写出到存储系统或下一个Flume Agent，Sink 就利用 Channel 提交事务。事务一旦被提交，该 Channel 从自己的内部缓冲区删除事件。如果写入失败，将缓冲区takeList中的数据归还给Channel。
Sink组件目的地包括hdfs、logger、avro、thrift、ipc、file、null、HBase、solr、自定义。

14 你是如何实现Flume数据传输的监控的
使用第三方框架Ganglia实时监控Flume。

15 flume 调优
1）source ：
增加 source 个数，可以增大 source 读取能力。
具体做法 ： 如果一个目录下生成的文件过多，可以将它拆分成多个目录。每个目录都配置一个 source 。
增大 batchSize ： 可以增大一次性批处理的 event 条数，适当调大这个参数，可以调高
2）source 搬运数据到 channel 的性能。
channel ：
memory ：性能好，但是，如果发生意外，可能丢失数据。
使用 file channel 时，dataDirs 配置多个不同盘下的目录可以提高性能。
transactionCapacity 需要大于 source 和 sink 的 batchSize 参数
3）sink ：
增加 sink 个数可以增加消费 event 能力

16 flume 选择器
包括两种 ：
1）每个通道都复制一份文件，replicating 。
2）选择性发往某个通道，Multiplexing 。


---------------------------------------------------------------------------------------------------------------
------------------------------------------flume basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------front basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 前端优化
1） 减少http请求，合理设置 HTTP缓存
2） 使用浏览器缓存， 使用浏览器缓存策略的网站在更新静态资源时，应采用逐量更新的方法，比如需要更新10个图标文件，不宜把10个文件一次全部更新，而是应该一个文件一个文件逐步更新，并有一定的间隔时间，以免用户浏览器忽然大量缓存失效，集中更新缓存，造成服务器负载骤增、网络堵塞的情况。
3） 启用压缩
4） CSS Sprites合并 CSS图片，减少请求数的又一个好办法。
5） CSS放在页面最上部，javascript放在页面最下面
6） 异步请求Callback（就是将一些行为样式提取出来，慢慢的加载信息的内容）
7） 减少cookie传输
8） CDN加速 CDN（contentdistribute network，内容分发网络）的本质仍然是一个缓存，而且将数据缓存在离用户最近的地方，使用户以最快速度获取数据

2 浏览器内核
1）、Trident内核代表产品Internet Explorer，又称其为IE内核。Trident（又称为MSHTML），是微软开发的一种排版引擎。使用Trident渲染引擎的浏览器包括：IE、傲游、世界之窗浏览器、Avant、腾讯TT、Netscape 8、NetCaptor、Sleipnir、GOSURF、GreenBrowser和KKman等。
2）、Gecko内核代表作品Mozilla FirefoxGecko是一套开放源代码的、以C++编写的网页排版引擎。Gecko是最流行的排版引擎之一，仅次于Trident。使用它的最著名浏览器有Firefox、Netscape6至9。
3）、WebKit内核代表作品Safari、Chromewebkit 是一个开源项目，包含了来自KDE项目和苹果公司的一些组件，主要用于Mac OS系统，它的特点在于源码结构清晰、渲染速度极快。缺点是对网页代码的兼容性不高，导致一些编写不标准的网页无法正常显示。主要代表作品有Safari和Google的浏览器Chrome。
4）、Presto内核代表作品OperaPresto是由Opera Software开发的浏览器排版引擎，供Opera 7.0及以上使用。它取代了旧版Opera 4至6版本使用的Elektra排版引擎，包括加入动态功能，例如网页或其部分可随着DOM及Script语法的事件而重新排版。

3、web x.0
@Web1.0    
是以编辑为特征，网站提供给用户的内容是网站编辑进行编辑处理后提供的，用户阅读网站提供的内容。这个过程是网站到用户的单向行为，web1.0时代的代表站点为新浪，搜狐，网易三大门户。   	
@Web2.0  
更注重用户的交互作用，用户既是网站内容的消费者（浏览者），也是网站内容的制造者。（微博、天涯社区、自媒体）是以加强了网站与用户之间的互动，网站内容基于用户提供，网站的诸多功能也由用户参与建设，实现了网站与用户双向的交流与参与；用户在web2.0网站系统内拥有自己的数据。并完全基于WEB，所有功能都能通过浏览器完成。   	
3） web1.0与web2.0的不同之处  
1）：在web2.0之中个人不再是互联网信息被动的接收者,而是作为一个主动者参与到了互联网的发展之中!用户不再是一个单纯的浏览者而是成为了互联网这块大网的编织者,使用者与传播者! 
2）：web2.0不同于web1.0的最大之处在于它的交互性。这个时期的典型代表有：博客中国、亿友交友、联络家等。   
4） Web3.0  
@Web3.0则完全不一样，其特点可归纳为  
1） 网站内的信息可以直接和其他网站相关信息进行交互和倒腾，能通过第三方信息平台同 时对多家网站的信息进行整合使用；  
2）用户在互联网上拥有自己的数据，并能在不同网站上使用;    
3） 完全基于WEB，用浏览器即可以实现复杂的系统程序才具有的功能,比如即时通聊天等 等就可以直接在网页完成，无需下载任何软件。

4 软件设计的两种架构
1 B/S（Browse/Server）：指浏览器和服务器端，客户端只需有浏览器，就可以实现与服务器端通信的程序结构。（瘦客户端）
2 C/S（Client/Server）：指客户机和服务器，在客户机端必须装客户端软件及相应环境后，才能访问服务器（胖客户端）
3 B/S特点：（客户端维护成本低，可跨平台，但服务器负担重，缺点是客户端功能较简单，用户体验不如C/S。）
4 C/S特点：（客户端功能强大，可以减轻服务器端压力，但是客户端维护开发成本高。）

5 Web程序设计所涉及的技术
1 前端：HTML[超文本标记语言]（结构）+CSS（表现）+ javascript（行为）由浏览器负责解释执行
2 后台：ASP、PHP、JSP由服务器负责解释执行
3 静态网页：由前端技术实现（扩展名：.htm或.html）
4 动态网页：由前端和后台（服务器端）技术共同实现（扩展名：.asp或.php或.jsp）


二、ms相关
1 用过哪些前端框架？
Jquery, bootstrap,angularjs,extjs,easy ui

2 Ext和jquery有何特点和不同？如何解决ext的性能问题？
ExtJS是个html的UI库,以其漂亮的UI和强大的交互功能著称,为html提供了大量的控件支持,而且很优美
缺点:操作DOM对象的能力和灵活度不够
jQuery从名字可知,就是简化对DOM操作,以其精简灵活的语法著称,比如,要获取页面所有div对象,只要一行代码就可以了即$("div"),
缺点:UI设计不够强大，但是支持第三方的UI插件
1 减少要加载的东西不要动不动就ext-all.js，extjs是可以定制的，如果你用不到tree，就不要包含这个组件了。ExtJs的官网上有详细的定制方法和工具。
2 动态加载，参考使用ExtJs开发MIS系统（2）：Js的动态加载
3 内存泄露 Ext性能调优方案
4 将JS进行合并压缩。使用yahoo的yui-compress.jar进行压缩JS，去掉过多的空格和注释，并合并，减少IO的支出。 
5 压缩ext 

3 闭包用在那些场景，有什么特点？
闭包就是由函数创造的一个词法作用域，里面创建的变量被引用后，可以在这个词法环境之外自由使用。闭包通常用来创建内部变量，使得这些变量不能被外部随意修改，同时又可以通过指定的函数接口来操作。
保护函数内的变量安全：如迭代器、生成器。在内存中维持变量：如果缓存数据、柯里化。


4 js实现继承有几种方式？原型链prototype有何特点？
第一种，prototype的方式
第二种，apply的方式：
第三种，call+prototype的方式


5 js深度复制和浅度复制有什么区别？
 1  在谈javascript的浅复制和深复制之前，我们有必要在来讨论下js的数据类型。我们都知道有Number，Boolean，String，Null，Undefined，Object五种类型。
 而Object又包含Function，Array和Object自身。前面的五种类型叫做基本类型，而Object是引用类型。

 2 js中基本类型的赋值为深复制，而引用类型的赋值为浅复制。
 浅复制：就是把数据的地址赋值给对应变量，而没有把具体的数据复制给变量，变量会随数据值的变化而变化。
 深复制：就是把数据赋值给对应的变量，从而产生一个与源数据不相干的新数据(数据地址已变化)

  var a = "dengkunming";
  var a1 = a;
  alert(a1);//dengkunming
  a="abc";
  alert(a1);//dengkunming;


  var a = [0,1,2,3];
  var a1= a;
  alert(a1);//[0,1,2,3]
  a[1]="变";
  alert(a1);//[0,"变",2,3]

 3  浅复制不会随着存储数据地址的变化而变化，只会随着数据值的变化而变化。
 var a = {w1:2,w2:3}
 var a1= a;
 alert(a1);//{w1:2,w2:3}
 var a={x1:7,x2:8}
 alert(a1);//{w1:2,w2:3}

 按照我们上面的理论来讲，这里是浅复制。a1应该随着a的变化而变化呀，可在这里为什么会事与愿违了？这就是引用类型惹的祸了。对象赋值其实都是引用传值，传递的是一个地址。
 那么实验五中的第四行其实就是把变量a指向了一个新的地址。而a1还是指向的原来那个地址，原来地址中的值没变，所以a1就不会变。所以请记住：浅复制不会随着存储数据地址的
 变化而变化，只会随着数据值的变化而变化。


6 JSON和xml比较？
    （1）可读性方面：基本相同，XML的可读性比较好；
　　（2）可扩展性方面：都具有良好的扩展性；
　　（3）编码难度方面：相对而言，JSON的编码比较容易；
　　（4）解码难度：JSON的解码难度基本为零，XML需要考虑子节点和父节点；
　　（5）数据体积方面：JSON相对于XML来讲，数据体积小，传递的速度比较快；
　　（6）数据交互方面：JSON与javascript的交互更加方便，更容易解析处理，更好的数据交互；
　　（7）数据描述方面：XML对数据描述性比较好；
（8）传输速度方面：JSON的速度远远快于XML。


7 this的用法有哪些？
1. 指向window全局变量
alert(this) //返回 [object Window]
function sayHello(){
  alert(this);
}
sayHello();

2. 指向该对象（在全局里面this指向window,在某个对象里面this指向该对象，在闭包里面this指向window）
var user="the Window";
var box={
  user:'the box',
  getThis:function(){
    return this.user;
  },
  getThis2:function(){
    return function (){
      return this.user;
    }
  }
};
alert(this.user);//the Window
alert(box.getThis());//the box
alert(box.getThis2()());
//the Window （由于使用了闭包，这里的this指向window）
alert(box.getThis2().call(box));
//the box 对象冒充（这里的this指向box对象）

3. 用apply,call改变函数的this指向
function sum(num1, num2){
  return num1+num2;
}
function box(num1, num2){
  return sum.apply(this, [num1, num2]);
  //this 表示window的作用域 box冒充sum来执行
}
console.log(box(10,10)); //20

4. new 对象
function Person(){
   console.log(this) //将 this 指向一个新建的空对象
}
var p = new Person();


8外边距内边距用CSS什么属性 ？
margin是指从自身边框到另一个容器边框之间的距离，就是容器外距离。
padding是指自身边框到自身内部另一个容器边框之间的距离，就是容器内距离。


9 jquery循环数组什么function?
$(array).each(function (idx)
{
   var obj = this;
   if(obj.name == 'eee')
   {
      return false;
   }
   return true;
});

10 怎么理解ext的mvc模式？
1，每个应用都有一个实体，就是Application对象，而每个应用同样采用单一入口结构，有个快捷函数就是Ext.application({config})，创建一个Application对象实例，并且运行它。Application在创建之初，会去加载Controller类
2，Application在lunch的时候，会创建一个Viewport实例，这个东西就像一个骨架一样，上面可以拼装各种View，具体说，就是各种布局形式和窗体控件，可以说是view界面的载体，一个页面只能有一个Viewport实例。
 
3，View纯粹是一个界面组件，或者说窗体控件的集合（比如form,grid和window）。它其实就是利用窗体控件panel,grid或form等进行用户界面展示,表格可以通过Ext.grid.GridPanel的getView()函数获取当前表格使用的视图实例,当我们希望在创建Gridview初始化一些参数可以使用Ext.grid.GridPanel的viewConfig参数,具体属性可以查看api.
 通过Store来加载数据并且展现到界面上，界面控件的响应都写在Controller里面，View对Controller的存在全无所知，也没有代码上的依赖。
4，Controller的角色完全是个粘合剂，它在加载之初，会帮忙加载跟其有关的Model，Store，View类，而其真正的作用，是通过一系列的事件处理函数(比如点击保存按钮)，确定了每个View上面界面组件对用户交互行为的响应方法，可以说是一堆事件处理器函数的集合；这里面主要通过一个control成员函数来进行事件绑定，通过另一个叫ComponentQuery的组件，使用类似css selector的语法来定位界面上的组件，并为其绑定事件处理器。
5，Model是对抽象数据的具体化，简单理解就是数据库里面的一行记录。
6，Store是对通过网络加载数据的过程的一个抽象，Store通过data发送请求(一般为ajax请求)到后台获取数据(一般返回json格式)，Store依赖于Model，通过关联的Model对象才知道如何将取回的数据对象化。
 不管是grid(表格),tree(树),form(表单)都可以通过model格式化字段,这样就可以把后台字段转化为Ext想要的字段,有时需要用到mapping属性

 a.Model模型：模型是字段和它们的数据的集合，例如User模型带有username和password字段，模型知道如何持久化自己的数据，并且可以和其他模型关联，模型跟Ext  JS 3 中的Record类有点像（区别是，Record只是单纯的扁平结构，而Model可以nest），通常都用在Store中去展示grid和其他组件的数据。
 Store就是多个model实例的集合。这里的model实例相当于 Java中的对象，Model就相当于Class
 Store如果看成是 一张数据库表，
 record(s)就是 表中的记录 （行），
 Model 代表（封装）了表的字段信息（属性）。
 Ext.define('FWY.store.Students', {
  extend: 'Ext.data.Store',
  fields: ['id','name', 'age','sex'],
  data: [
   {id:1,name: '张三',    age: 30,sex:'男'},
   {id:2,name: '李四',    age: 20,sex:'女'}
  ]
 });
 
 Ext.define('FWY.model.Student', {
    extend: 'Ext.data.Model',
    fields: ['id','name','age','sex']
 });


 b.View视图：视图是组件的一种，专注于界面展示 – grid, tree, panel 都是view。
 Ext.define('FWY.view.student.List' ,{
    extend: 'Ext.grid.Panel',
    alias : 'widget.studentlist',
    title : '学生信息列表',
    initComponent: function() {
        this.store = {
            fields: ['id','name', 'age','sex'],
            data  : [
                {id:1,name: 'zhangsan',    age: 18,sex:'boy'},
                {id:2,name: 'lishi',    age: 20,sex:'girl'}
        ]};
        this.columns = [
            {header: '编号',  dataIndex: 'id',  flex: 1},
            {header: '姓名',  dataIndex: 'name',  flex: 1},
            {header: '年龄', dataIndex: 'age', flex: 1},
            {header: '性别', dataIndex: 'sex', flex: 1}
        ];
        this.callParent(arguments);
  }
 });

 c.Controllers控制器：一个安放所有使你的app正确工作的代码的位置，具体一点应该是所有动作，例如如何渲染view，如何初始化model，和app的其他逻辑。
    ExtJS 4 应用都遵循一个统一的目录结构，每个应有都相同 控制器是应用的粘合剂，它们所作的事情就是监听事件并执行动作，继续我们的应用，创建一个控制器。创建app/controller/Students.js这个文件，并添加如下代码Ext.define('FWY.controller.Students', {
  extend: 'Ext.app.Controller',
  views: 
  [
   'student.List',
         'student.Edit'
  ],
  stores: ['Students'],//加载store
  model: 'FWY.model.Student',
  init: function() {
   this.control({
    'viewport > panel': {
     render: this.onPanelRendered
    }
   });
  },
   editStudent: function(grid, record) {
        console.log('Double clicked on ' + record.get('name'));
    }
 });
 
 MVC中，所有类都放在app目录里面，这个目录可以有子目录，代表的是命名空间（一个子目录对应一个命名空间），使用不同的目录存放views,models,controllers,stores。当我们完成例子的时候，目录结构应该和下图一样
 
11 AngularJS有什么特性？解决什么问题？
A:四大特点：
　（1）MVC模式：
　　　　Model:数据,其实就是angular变量($scope.XX,$rootScope.XX);
　　　　View:数据的呈现,Html+Directive(指令);
　　　　Controller:操作数据,就是function,数据的增删改查;

　（2）双向绑定:
　　　　方向一:Model--->View
　　　　　　　　{{Model数据}} 或<XXX ng-xxx="Model数据">  Model变View跟着变;
　　　　方向二:View--->Model
　　　　　　　　<表单控件 ng-model="Model数据名">   View变Model跟着变;

　（3）依赖注入:
    依赖注入(Dependency Injection,简称DI)是一种设计模式, 指某个对象依赖的其他对象无需手工创建，只需要“吼一嗓子”，则此对象在创建时，其依赖的对象由框架来自动创建并注入进来,其实就是最少知识法则;模块中所有的service和provider两类对象，都可以根据形参名称实现DI.
   
   myModule.factory('$alert', function($window) {
 return {
  alert: function(text) {
  $window.alert(text);
   }
  };
 });

 var myController = function($scope, $alert) {
  $scope.message = function(msg) {
   console.log(msg);
   $alert.alert(msg);
  };
 };
 myController.$inject = ['$scope', '$alert'];
 


　（4）模块化设计:高内聚低耦合法则
　　1)官方提供的模块           ng、ngRoute、ngAnimate、ngTouch
 2)用户自定义的模块        angular.module('模块名',[ ])
  
  
 B:优点集合 
 1 AngularJS是一套完整的框架，angular有自带的数据绑定、render渲染、angularUI库,过滤器,directive(模板),服务q(defer),http，inject(依赖注入),
   factory,provider……，等等一系列工具，基本上只要你在做web开发用过的东西，它都有一个。但是这些东西React自身都没有。
 2 angularjs的架构清晰，分工明确，扩展性良好，model，view，controller谁在什么时候做什么事情说的很清楚，angular能够让程序员真正专注于业务逻辑，
   而且因为对html侵入不大，非常易于和designer协作。整个框架充满了DI的思路，耦合性非常低，对象都是被inject的，也就是说每个对象都可以轻易被替换而
   不影响其他对象。
 3 Angular生产效率高，单向数据流什么的想法非常好，但是写起来太麻烦！我只想变更个很简单的数据还要经过action、dispatcher、reduce、view四步
   ，angular里一行代码就搞定的事情在react里却如此麻烦


 C：缺点集合
 1 性能 ，双向数据绑定是一把双刃剑。
  随着组件增加，项目越来越复杂，双向数据绑定带来性能问题。双向数据绑定是如何影响性能的？在JavaScript（ES5）中，并没有实现当变量或对象改变时发出通知的功能，Angular的实现方法被叫做“Dirty-checking（脏检查机制），通过跟踪数据的改变再动态更新用户界面（UI）。在Angular的作用域中任何操作的执行都会引发Dirty-checking，随着绑定数量的增加性能就会越低。
 2 Angular 2.0推翻重做使得目前不宜采用此框架 
    Angular 1.x版本其实是个比较旧的东西了，现在看来有些理念过时了，比如依赖注入、自己独特的模块化，这些东西其实在ES6下已经很好地被解决了。 
 Angular的2.0几乎是一个推翻重做的框架，估计不会有1.X的upgrade方案。所以如果现在新开始的项目采用Angular的话，会是一个很尴尬的时机。同样，如此大的改动似乎也反面印证了1.X并不是那么好。




12 什么是模块化？AMD和CMD的区别？
    1 模块化
 随着浏览器功能越来越完善，前端已经不仅仅是切图做网站，前端在某些方面已经媲美桌面应用。越来越庞大的前端项目，越来越复杂的代码，前端开发者们对于模块化的需求空前强烈。随着浏览器功能越来越完善，前端已经不仅仅是切图做网站，前端在某些方面已经媲美桌面应用。越来越庞大的前端项目，越来越复杂的代码，前端开发者们对于模块化的需求空前强烈。
 后来node出现了，跟随node出现的还有commonjs，这是一种js模块化解决方案，像Node.js主要用于服务器的编程，加载的模块文件一般都已经存在本地硬盘，所以加载起来比较快，不用考虑
 异步加载的方式，CommonJS 加载模块是同步的，所以只有加载完成才能执行后面的操作。但是浏览器环境不同于Node，浏览器中获取一个资源必须要发送http请求，从服务器端获取，采用同
 步模式必然会阻塞浏览器进程出现假死现象。在这方面dojo曾经做了伟大尝试，早期dojo便是采用xhr+eval的方式，结果可想而知，阻塞现象是必然的。后来出现无阻塞加载脚本方式在开发
 中广泛应用，在此基础结合commonjs规范，前端模块化迎来了两种方案：AMD、CMD. 异步和管理依赖。
 AMD 是 RequireJS 在推广过程中对模块定义的规范化产出，CMD是SeaJS 在推广过程中被广泛认知。
 2 AMD
 Asynchronous Module Definition，用白话文讲就是 异步模块定义，对于 JSer 来说，异步是再也熟悉不过的词了，所有的模块将被异步加载，模块加载不影响后面语句运行
 。所有依赖某些模块的语句均放置在回调函数中。AMD规范定义了一个自由变量或者说是全局变量 define 的函数。
 第一个参数 id 为字符串类型，表示了模块标识，为可选参数。若不存在则模块标识应该默认定义为在加载器中被请求脚本的标识。如果存在，那么模块标识必须为顶层的或者一个绝对的标识。
 第二个参数，dependencies ，是一个当前模块依赖的，已被模块定义的模块标识的数组字面量。
 第三个参数，factory，是一个需要进行实例化的函数或者一个对象。
 创建模块标识为 alpha 的模块，依赖于 require， export，和标识为 beta 的模块  
 3 CMD
 通用模块定义（CMD）是Common Module Definition的缩写，是SeaJS 在推广过程中对模块定义的规范化产出。
 RequireJS 和 SeaJS 都是模块化框架的代表，AMD和CMD，是他们各自定义模块化的方式，大同小异，主要是代码风格和API不同。


13 seajs和requirejs 区别？
（1）两者定位有差异。RequireJS 想成为浏览器端的模块加载器，同时也想成为 Rhino / Node 等环境的模块加载器。SeaJS 则专注于 Web 浏览器端，同时通过 Node 扩展的方式可以很方便跑在 Node 服务器端
 （2）两者遵循的标准有差异。RequireJS 遵循的是 AMD（异步模块定义）规范，SeaJS 遵循的是 CMD （通用模块定义）规范。规范的不同，导致了两者 API 的不同。SeaJS 更简洁优雅。
 （3）两者社区理念有差异。RequireJS 在尝试让第三方类库修改自身来支持 RequireJS，目前只有少数社区采纳。SeaJS 不强推，而采用自主封装的方式来“海纳百川”，目前已有较成熟的封装策略。
 （4）两者代码质量有差异。RequireJS 是没有明显的 bug，SeaJS 是明显没有 bug。
 （5）两者对调试等的支持有差异。SeaJS 通过插件，可以实现 Fiddler 中自动映射的功能，还可以实现自动 combo 等功能，非常方便便捷。RequireJS 无这方面的支持。
 （6）两者的插件机制有差异。RequireJS 采取的是在源码中预留接口的形式，源码中留有为插件而写的代码。SeaJS 采取的插件机制则与 Node 的方式一致：开放自身.


14 对nodejs的理解？
nodejs是一个基于Chrome V8 引擎的JS运行环境，也就是让javascript运行在服务器（server）端，
NodeJS使用了一个事件驱动，非阻塞式的I/O模型，使得其轻量又高效。
Nodejs包管理器npm是全球最大的开源生态系统。
nodejs是服务端的js平台。
npm grunt express 等强大的代码与项目管理应用在nodeJS上。
关于NodeJS与传统服务器处理平台（Apache）的区别
Apache的多线程高并发模式

Apache是一种多线程处理并发，但是在一些大型的web应用上也会发生阻塞。
线程和进程

线程是可以独立运行的最小的CPU单位。
线程可以在同一个进程中并发运行，并共享该进程下的内存地址空间。

进程可以支持多个线程，它们看似同时执行，但是相互之间并不同步。
一个进程中的多个线程共享相同的内存地址空间，意味着可以访问相同的变量和对象，并且从同一堆中分配对象。

这样让线程之间共享信息变得容易，但是也要确保他们不会妨碍同一进程中想的其他线程。
NodeJS的异步I/O原理

用数据库的调用举例：
Apache，执行到第一个线程的时候会等待query返回结果，一方面会导致线程长期阻塞等待，另一方面会为了新请求不断增加线程，会浪费大量的资源，同时线程增加会占用大量的CPU时间来处理内存上下文切换。

NodeJS是异步单线程的，应用的是异步回调的方法，也就是异步的I/O。
解释：当进程执行的时候，不会等待结果的返回，而是直接执行下面的语句，直到进入事件循环，当数据库执行返回结果的时候会将事件发送到事件队列，等线程进入事件循环之后才会调用之前的回调函数。
也就是nodejs的工作原理其实就是事件循环。每一条nodejs的逻辑都是写在回调函数里面的，而回调函数都是返回之后才异步执行的。

NodeJS也会发生阻塞，但是阻塞发生在自己的单个线程当中，不是发生在后续回调的流程当中。

与php区别
用node来做网站开应用的是分块加载的模式，不用像php那样把所有的数据一次性加载到客户端。

NodeJS相比于php和Apache开的新线程来讲，节省了CPU内存和上下文切换的时间。
NodeJS的应用场景
NodeJs适合应用在具有大量的细小的http请求环境下，例如web的即时聊天程序，或者上万人同时在线的游戏服务器。不用考虑http请求次数过多的问题。


15 请你谈谈Cookie的弊端?
优点：
1.通过良好的编程，控制保存在cookie中的session对象的大小。
2.通过加密和安全传输技术（SSL），减少cookie被破解的可能性。
3.只在cookie中存放不敏感数据，即使被盗也不会有重大损失。
4.控制cookie的生命期，使之不会永远有效。偷盗者很可能拿到一个过期的cookie。

缺点：
1.`Cookie`数量和长度的限制。每个domain最多只能有20条cookie，每个cookie长度不能超过4KB，否则会被截掉。
2.安全性问题。如果cookie被人拦截了，那人就可以取得所有的session信息。即使加密也与事无补，因为拦截者并不需要知道cookie的意义，他只要原样转发cookie就可以达到目的了。
3.有些状态不可能保存在客户端。例如，为了防止重复提交表单，我们需要在服务器端保存一个计数器。如果我们把这个计数器保存在客户端，那么它起不到任何作用。


16 谈谈浏览器本地存储？
1)      Cookie ：   广泛应用，局限明显。支持数据存储量相对较少，每个 domain 最多只能有 20 条 cookie ，每个 cookie 长度不能超过 4KB ，否则会被截掉；同时，存在安全性问题，如果被拦截，就可以取得所有的 session 信息。
2)      Flash SharedObject ：使用的是 kissy 的 store 模块来调用 Flash SharedObject 。
优点：容量适中，基本上不存在兼容性问题
缺点：要在页面中引入特定的 Flash 和 JS ，增加额外负担，处理繁琐；还是有部分机子没有 flash 运行环境。
3)      Google Gears ：  Google 的离线方案，已经停止更新，官方推荐使用 HTML5 的 localStorage 方案。
4)      User Data ：   是微软为 IE 专门在系统中开辟的一块存储空间，只支持 Windows+IE 的组合。单个文件的大小限制是 128KB ，一个域名下总共可以保存 1024KB 的文件，文件个数应该没有限制。在受限站点里这两个值分别是 64KB 和 640KB 。
（所以如果考虑到各种情况的话，单个文件最好能控制 64KB 以下。）
（实际测试 2000 （ IE5.5 ）、 XP （ IE6 、 IE7 ）， Vista （ IE7 ）下都是可正常使用。）
5)      Web Storage
在较高版本的浏览器中， JS 提供了 sessionStorage 和 globalStorage 。
在 HTML5 中提供了 sessionStorage 和 localStorage 。
sessionStorage 用于本地存储一个会话（ session ）中的数据，这些数据只有在同一个会话中的页面才能访问，会话结束后数据随之销毁。因此 sessionStorage 不是一种持久化的本地存储，仅仅是会话级别的存储。
globalStorage 跨越会话存储数据。有特定访问限制，要指定哪些域可访问该数据。
localStorage 用于持久化的本地存储，除非主动删除数据，否则数据是永远不会过期的。不能给 localStorage 指定任何规则，要访问同一个 localStorage ，页面必须使用同一个域名，使用同一种协议，在同一个端口上。
优点：容量大、易用、强大、原生支持
缺点： a) 兼容性差（ Chrome,  Safari, Firefox,Opera,IE8+ 支持 ， IE8 以下版本不支持）
b) 安全性差（所以请勿使用 localStorage 保存敏感信息）



17 web storage和cookie的区别？
        1、cookie数据始终在同源的http请求中携带(即使不需要)，即cookie在浏览器和服务器间来回传递
        2、cookie数据还有路径（path）的概念，可以限制。cookie只属于某个路径下、
        3、存储大小限制也不同，cookie数据不能超过4K，同时因为每次http请求都会携带cookie，所以cookie只适合保存很小的数据，如回话标识
        4、webStorage虽然也有存储大小的限制，但是比cookie大得多，可以达到5M或更大
        5、数据的有效期不同
  sessionStorage：仅在当前的浏览器窗口关闭有效；
  localStorage：始终有效，窗口或浏览器关闭也一直保存，因此用作持久数据；
  cookie：只在设置的cookie过期时间之前一直有效，即使窗口和浏览器关闭
        6、作用域不同
  sessionStorage：不在不同的浏览器窗口中共享，即使是同一个页面；
  localStorage：在所有同源窗口都是共享的；
  cookie：也是在所有同源窗口中共享的
        7、webStorage支持事件通知机制，可以将数据更新的通知发生给监听者
        8、webStorage的API借口使用更方便 。setItem  getItem clearItem
        window。sessionStorage/window。 localStorage
        setItem（key,val）设置
        getItem（key）获取
        webStorage。removeItem（key）删除单个
        webStorage.clear（）清除所有
        webStorage只能操作字符串对象，所有的存储值都会为字符串数据


18 display:none和visibility:hidden的区别？
display:none;会让元素完全从渲染树中消失，渲染的时候不占据任何空间；
visibility: hidden;不会让元素从渲染树消失，渲染师元素继续占据空间，只是内容不可见
display: none;是非继承属性，子孙节点消失由于元素从渲染树消失造成，通过修改子孙节点属性无法显示；  
visibility: hidden;是继承属性，子孙节点消失由于继承了hidden，通过设置visibility: visible;可以让子孙节点显示；  
修改常规流中元素的display通常会造成文档重排。修改visibility属性只会造成本元素的重绘。  
读屏器不会读取display: none;元素内容；会读取visibility: hidden;元素内容  


19 position的值， relative和absolute分别是相对于谁进行定位的？
1、static（静态定位）：默认值。没有定位，元素出现在正常的流中（忽略 top, bottom, left, right 或者 z-index 声明）。
2、relative（相对定位）：生成相对定位的元素，通过top,bottom,left,right的设置相对于其正常（原先本身）位置进行定位。可通过z-index进行层次分级。　　
3、absolute（绝对定位）：生成绝对定位的元素，相对于 static 定位以外的第一个父元素进行定位。元素的位置通过 "left", "top", "right" 以及 "bottom" 属性进行规定。可通过z-index进行层次分级。
4、fixed（固定定位）：生成绝对定位的元素，相对于浏览器窗口进行定位。元素的位置通过 "left", "top", "right" 以及 "bottom" 属性进行规定。可通过z-index进行层次分级


20 如何实现浏览器内多个标签页之间的通信?
本题主要考察数据存储的知识，数据存储有本地和服务器存储两种方式，对于前端开发来讲，只需要讲解用本地存储的方式来解决就好。当然也能知道服务器端的方式更好。本题的难易程度一般，只要能够说出思路就可以，至少说两种解决方法。 

方法一：使用localStorage
使用localStorage.setItem(key,value);添加内容
使用storage事件监听添加、修改、删除的动作   
    window.addEventListener("storage",function(event){  
            $("#name").val(event.key+”=”+event.newValue);  
    });  
       

方法二、使用cookie+setInterval
HTML代码
    <inputidinputid="name"><input type="button" id="btnOK"value="发送">  

JS代码-页面1   
    $(function(){  
           $("#btnOK").click(function(){  
               varname=$("#name").val();  
               document.cookie="name="+name;  
           });  
       });  

JS代码-页面2
    //获取Cookie天的内容  
    function getKey(key) {  
        return JSON.parse("{\""+ document.cookie.replace(/;\s+/gim,"\",\"").replace(/=/gim, "\":\"") +"\"}")[key];  
    }  
    //每隔1秒获取Cookie的内容  
    setInterval(function(){  
        console.log(getKey("name"));  
     },1000);


21 请说出三种减少页面加载时间的方法？
1、减少http请求（合并文件、合并图片）
2、优化图片文件，减小其尺寸，特别是缩略图，一定要按尺寸生成缩略图然后调用，不要在网页中用resize方法实现，虽然这样看到的图片外形小了，但是其加载的数据量一点也没减少。曾经见过有人在网页中加载的缩略图，其真实尺寸有10M之巨…普通图像、icon也要尽可能压缩后，可以采用web图像保存、减少颜色数等等方法实现。
3、图像格式的选择（GIF：提供的颜色较少，可用在一些对颜色要求不高的地方）
4、 压缩Javascript、CSS代码：一般js、css文件中存在大量的空格、换行、注释，这些利于阅读，如果能够压缩掉，将会很有利于网络传输。这方面的工具也有很多，可以在百度里搜索一下关键字“css代码压缩”，或者“js代码压缩”将会发现有很多网站都提供这样的功能，当然了你也可以自己写程序来做这个工作，如果你会的话。就拿我们这个网站来说吧。刚开始上传这个网站的时候，我的很多Css代码都没有压缩，后面发现了这个问题，我就上网找了相关的网站的压缩代码的功能，最后就把很多CSS文件都压缩了。这个压缩比率还是比较高的，一般都有百分五十左右。这个代码压缩对于网页的加载还是很有用的。
5、 服务器启用gzip压缩功能：将要传输的文件压缩后传输到客户端再解压，在网络传输 数据量会大幅减小。在服务器上的Apache、Nginx可直接启用，也可用代码直接设置传输文件头，增加gzip的设置，也可从 负载均衡设备直接设置。不过需要留意的是，这个设置会略微增加服务器的负担。服务器性能不是很好的网站，要慎重考虑。
6.标明高度和宽度（如果浏览器没有找到这两个参数，它需要一边下载图片一边计算大小，如果图片很多，浏览器需要不断地调整页面。这不但影响速度，也影响浏览体验。 当浏览器知道了高度和宽度参数后，即使图片暂时无法显示，页面上也会腾出图片的空位，然后继续加载后面的内容。从而加载时间快了，浏览体验也更好了。）
7、网址后面加上“/”:对服务器而言，不加斜杠服务器会多一次判断的过程，加斜杠就会直接返回网站设置的存放在网站根目录下的默认页面。




22 null和undefined的区别？
undefined表示变量声明但未初始化时的值，
null表示准备用来保存对象，还没有真正保存对象的值。从逻辑角度看，null值表示一个空对象指针。
JavaScript（ECMAScript标准）里共有5种基本类型：Undefined, Null, Boolean, Number, String，和一种复杂类型Object。可以看到null和undefined分属不同的类型，未初始化定义的值用typeof检测出来是"undefined"(字符串)，而null值用typeof检测出来是"object"（字符串）。
任何时候都不建议显式的设置一个变量为undefined，但是如果保存对象的变量还没有真正保存对象，应该设置成null。
实际上，undefined值是派生自null值的，ECMAScript标准规定对二者进行相等性测试要返回true，即 
alert(null==undefined);  // true


23 如何解决跨域问题?
1、JSONP：
使用方式就不赘述了，但是要注意JSONP只支持GET请求，不支持POST请求。
利用<script>标签没有跨域限制的“漏洞”（历史遗迹啊）来达到与第三方通讯的目的。当需要通讯时，本站脚本创建一个<script>元素，地址指向第三方的API网址，形如：    
 <script src="http://www.example.net/api?param1=1&param2=2"></script>     
 并提供一个回调函数来接收数据（函数名可约定，或通过地址参数传递）。     
第三方产生的响应为json数据的包装（故称之为jsonp，即json padding），形如：     
callback({"name":"hax","gender":"Male"})     
这样浏览器会调用callback函数，
并传递解析后json对象作为参数。本站脚本可在callback函数里处理所传入的数据。
2、代理：
例如www.123.com/index.html需要调用www.456.com/server.php，可以写一个接口www.123.com/server.php，由这个接口在后端去调用www.456.com/server.php并拿到返回值，然后再返回给index.html，这就是一个代理的模式。相当于绕过了浏览器端，自然就不存在跨域问题。
3、PHP端修改header（XHR2方式）
在php接口脚本中加入以下两句即可：
header('Access-Control-Allow-Origin:*');//允许所有来源访问
header('Access-Control-Allow-Method:POST,GET');//允许访问的方式  


24 call() 和 apply() 的区别和作用？
JavaScript中的每一个Function对象都有一个apply()方法和一个call()方法，它们的语法分别为：
function.apply(thisObj[, argArray]);   
function.call(thisObj[, arg1[, arg2[, [,...argN]]]]);

它们各自的定义：
apply：调用一个对象的一个方法，用另一个对象替换当前对象。例如：B.apply(A, arguments);即A对象应用B对象的方法。
call：调用一个对象的一个方法，用另一个对象替换当前对象。例如：B.call(A, args1,args2);即A对象调用B对象的方法。

它们的共同之处：
都“可以用来代替另一个对象调用一个方法，将一个函数的对象上下文从初始的上下文改变为由thisObj指定的新对象”。
它们的不同之处：
apply：最多只能有两个参数——新this对象和一个数组argArray。如果给该方法传递多个参数，则把参数都写进这个数组里面，当然，即使只有一个参数，也要写进数组里。如果argArray不是一个有效的数组或arguments对象，那么将导致一个TypeError。如果没有提供argArray和thisObj任何一个参数，那么Global对象将被用作thisObj，并且无法被传递任何参数。
call：它可以接受多个参数，第一个参数与apply一样，后面则是一串参数列表。这个方法主要用在js对象各方法相互调用的时候，使当前this实例指针保持一致，或者在特殊情况下需要改变this指针。如果没有提供thisObj参数，那么 Global 对象被用作thisObj。

25 你遇到过比较难的技术问题是？你是如何解决的？
略过

26 WEB应用从服务器主动推送Data到客户端有那些方式？
通常情况下,打开网页或app去查询或者刷新时，客户端向服务器发出请求然后返回数据,客户端与服务端对应的模式是: 客户端请求--服务端响应, 而在有些情况下,服务端会主动推送一些信息到客户端,例如:新闻的订阅,
天气的提醒等等,那么在这样的模式下,会有些问题值得思考:
1.应用服务器如何确定每一个应用所在的设备
2.服务端把消息推到哪，客户端又不像服务器有一个固定的地址
服务端主动推送到客户端是怎么一个过程?
结合一个实际问题分析下:
问题提出: 外卖app, 商家在商家后台需要实时的获取到有没有新订单，有的话是几个；这个需求类似与日常中使用QQ或者微信时的新信息提醒一样，只要有新信息就需要提醒
最近工作中遇到一个场景，商家在商家后台需要实时的获取到有没有新订单，有的话是几个；这个需求类似与日常中使用QQ或者微信时的新信息提醒一样，只要有新信息就需要提醒；商家基本在PC上使用，各式浏览器都有:如 IE系列（7.0，8.0，9.0及以上），chrome内核，firefox等；功能所属的部署在Tomcat 6.0上，如果技术需要可以部署到 Tomcat 7.0上;
我们先做做技术调研，这种浏览器与服务器实时通信的方式有哪些方式。

（1）AJAX轮询
这是我们最自然想到的。 采用常规AJAX轮询的方式，每10s或者30s轮询一次，既可以判断出有有多少个新订单进入，且这种时间间隔对于消息提醒也是可以接受的。这种技术方式实现起来非常简单，目前的机器都是可以机器的，前端浏览器也都支持。
但是这种方式会有非常严重的问题，就是需要不断的向服务器发送消息询问，如果有1w个商家打开了浏览器，采用10s轮询的方式，则服务器则会承担1000 的QPS，这1w个商家可能只有10个有订单通知；这种方式会对服务器造成极大的性能浪费。
还有一个类似的轮询是使用JSONP跨域请求的方式轮询，在实现起来有差别，但基本原理都是相同的，都是客户端不断的向服务器发起请求。
优点实现简单。
缺点这是通过模拟服务器发起的通信，不是实时通信，不顾及应用的状态改变而盲目检查更新，导致服务器资源的浪费，且会加重网络负载，拖累服务器。

（2）comet
Comet是一种用于Web的推送技术，能使服务器实时地将更新的信息传送到客户端，而无须客户端发出请求，目前有两种实现方式：
长轮询（long polling)
长轮询 (long polling) 是在打开一条连接以后保持，等待服务器推送来数据再关闭，可以采用HTTP长轮询和XHR长轮询两种方式。
HTTP 和JSONP方式的长轮询
把 script 标签附加到页面上以让脚本执行。服务器会挂起连接直到有事件发生，接着把脚本内容发送回浏览器，然后重新打开另一个 script 标签来获取下一个事件，从而实现长轮询的模型。
XHR长轮询
这种方式是使用比较多的长轮询模式。
客户端打开一个到服务器端的 AJAX 请求然后等待响应；服务器端需要一些特定的功能来允许请求被挂起，只要一有事件发生，服务器端就会在挂起的请求中送回响应并关闭该请求。客户端 JavaScript 响应处理函数会在处理完服务器返回的信息后，再次发出请求，重新建立连接；如此循环。
现在浏览器已经支持CROS的跨域方式请求，因此HTTP和JSONP的长轮询方式是慢慢被淘汰的一种技术，建议采用XHR长轮询。
长轮询优缺点
优点客户端很容易实现良好的错误处理系统和超时管理，实现成本与Ajax轮询的方式类似。
缺点需要服务器端有特殊的功能来临时挂起连接。当客户端发起的连接较多时，服务器端会长期保持多个连接，具有一定的风险。

（3）iframe
iframe 是很早就存在的一种 HTML 标记， 通过在 HTML 页面里嵌入一个隐蔵帧，然后将这个隐蔵帧的 SRC 属性设为对一个长连接的请求，服务器端就能源源不断地往客户端输入数据。
优点：这种方式每次数据传送不会关闭连接，连接只会在通信出现错误时，或是连接重建时关闭（一些防火墙常被设置为丢弃过长的连接， 服务器端可以设置一个超时时间， 超时后通知客户端重新建立连接，并关闭原来的连接）。
缺点IE、Morzilla Firefox 下端的进度栏都会显示加载没有完成，而且 IE 上方的图标会不停的转动，表示加载正在进行。
Google 的天才们使用一个称为“htmlfile”的 ActiveX 解决了在 IE 中的加载显示问题，并将这种方法用到了 gmail+gtalk 产品中。Alex Russell 在 “What else is burried down in the depth’s of Google’s amazing JavaScript?”文章中介绍了这种方法。Zeitoun 网站提供的 comet-iframe.tar.gz，封装了一个基于 iframe 和 htmlfile 的 JavaScript comet 对象，支持 IE、Mozilla Firefox 浏览器，可以作为参考。
我们常用的网页版的gtalk就是这种实现方式,Google的开发人员使使用一个称为“htmlfile”的 ActiveX 解决了在 IE 中的加载显示问题。

（4）Comet实现框架
CometD
CometD 框架是基于 HTTP 的事件驱动通信解决方案，使用了Bayeux通信协议，提供了一个 Java 服务器部件和一个 Java 客户端部件，还有一个基于 jQuery 和 Dojo 的 JavaScript 客户端库。
Bayeux 通信协议主要是基于 HTTP，提供了客户端与服务器之间的响应性双向异步通信。Bayeux 协议基于通道进行通信，通过该通道从客户端到服务器、从服务器到客户端或从客户端到客户端（但是是通过服务器）路由和发送消息。Bayeux 是一种 “发布- 订阅” 协议。
CometD 与三个传输协议绑定在一起：JSON、JSONP 和 WebSocket。他们都依赖于 Jetty Continuations 和 Jetty WebSocket API。在默认情况下，可以在 Jetty 6、Jetty 7、和 Jetty 8 中以及其他所有支持 Servlet 3.0 Specification 的服务中使用 CometD。

（5）服务器和内部构件
Atmosphere框架
Atmosphere提供了一个通用 API，以便使用许多 Web 服务器（包括 Tomcat、Jetty、GlassFish、Weblogic、Grizzly、JBossWeb、JBoss 和 Resin）的 Comet 和 WebSocket 特性。它支持任何支持 Servlet 3.0 Specification 的 Web 服务器。
Atmosphere 提供了一个 jQuery 客户端库，该库可以使连接设置变得更容易，它能够自动检测可以使用的最佳传输协议（WebSockets 或 CometD）。Atmosphere 的 jQuery 插件的用法与 HTML5 WebSockets API 相似。

（6）Pushlet
Pushlet 使用了观察者模型：客户端发送请求，订阅感兴趣的事件；服务器端为每个客户端分配一个会话 ID 作为标记，事件源会把新产生的事件以多播的方式发送到订阅者的事件队列里。
Pushlet 最后更新于2010年2月5号，之后至今没有再更新。

（7）websocket
WebSocket是HTML5开始提供的一种在单个 TCP 连接上进行全双工通讯的协议。WebSocket通讯协议于2011年被IETF定为标准RFC 6455，WebSocketAPI被W3C定为标准。在WebSocket API中，浏览器和服务器只需要做一个握手的动作，然后，浏览器和服务器之间就形成了一条快速通道。两者之间就直接可以数据互相传送。
浏览器支持
浏览器  版本支持
Chrome  4+
Firefox  4+
IE  10+
Opera  10+
Safari  5+

总结下来长轮询不是一个很好的方案，而且对于服务器而言是有风险的；另外支持WebSocket协议的浏览器都比较新，特比是IE需要10以上的版本；而我们的业务是面向于商家端，商家的浏览器版本相对较低，很多对WebSocket都不支持；相对而言Comet的方式比较适合，也有相应的实现框架，实现成本最低；因此最后我们还是决定使用Comet的方式来实现，后面上线运行一段时间之后再来给大家介绍。


27 你有哪些性能优化的方法？
（1） 减少http请求次数：CSS Sprites, JS、CSS源码压缩、图片大小控制合适；网页Gzip，CDN托管，data缓存，图片服务器。
（2） 前端模板 JS+数据，减少由于HTML标签导致的带宽浪费，前端用变量保存AJAX请求结果，每次操作本地变量，不用请求，减少请求次数
（3） 用innerHTML代替DOM操作，减少DOM操作次数，优化javascript性能。
（4） 当需要设置的样式很多时设置className而不是直接操作style。
（5） 少用全局变量、缓存DOM节点查找的结果。减少IO读取操作。
（6） 避免使用CSS Expression（css表达式)又称Dynamicproperties(动态属性)。
（7） 图片预加载，将样式表放在顶部，将脚本放在底部  加上时间戳。


28 一个页面从输入 URL 到页面加载显示完，此过程中都发生了什么？
分为4个步骤：
（1），当发送一个URL请求时，不管这个URL是Web页面的URL还是Web页面上每个资源的URL，浏览器都会开启一个线程来处理这个请求，同时在远程DNS服务器上启动一个DNS查询。这能使浏览器获得请求对应的IP地址。
（2）， 浏览器与远程Web服务器通过TCP三次握手协商来建立一个TCP/IP连接。该握手包括一个同步报文，一个同步-应答报文和一个应答报文，这三个报文在 浏览器和服务器之间传递。该握手首先由客户端尝试建立起通信，而后服务器应答并接受客户端的请求，最后由客户端发出该请求已经被接受的报文。
（3），一旦TCP/IP连接建立，浏览器会通过该连接向远程服务器发送HTTP的GET请求。远程服务器找到资源并使用HTTP响应返回该资源，值为200的HTTP响应状态表示一个正确的响应。
（4），此时，Web服务器提供资源服务，客户端开始下载资源。
请求返回后，便进入了我们关注的前端模块
简单来说，浏览器会解析HTML生成DOM Tree，其次会根据CSS生成CSS Rule Tree，而javascript又可以根据DOM API操作DOM


29 怎么理解sql注入原理和预防？
1.永远不要信任用户的输入，要对用户的输入进行校验，可以通过正则表达式，或限制长度，对单引号和双"-"进行转换等。
2.永远不要使用动态拼装SQL，可以使用参数化的SQL或者直接使用存储过程进行数据查询存取。
3.永远不要使用管理员权限的数据库连接，为每个应用使用单独的权限有限的数据库连接。
4.不要把机密信息明文存放，请加密或者hash掉密码和敏感的信息。
5.应用的异常信息应该给出尽可能少的提示，最好使用自定义的错误信息对原始错误信息进行包装，把异常信息存放在独立的表中。


30 请解释一下 JavaScript 的同源策略？
一、同源策略的产生
JS可以读取/修改网页的值。
一个浏览器中，打开一个银行网站和一个恶意网站，如果恶意网站能够对银行网站进行修改，那么就会很危险。
你打开了恶意网站和另一个网站，如果没有同源限制，该恶意网站就可以构造AJAX请求频繁在另一个网站发广告帖。
同源策略就是为了解决这类问题而出现的。

二、什么是同源策略（举例）
同源策略，即拥有相同的协议（protocol），端口（如果指定），主机（域名）的两个页面是属于同一个源。
然而在IE中比较特殊，IE中没有将端口号加入同源的条件中，因此上图中端口不同那一项，在IE中是算同源的

三、不遵循同源策略的标签
<script>  <img>  <iframe>中的src，href都可以任意链接网络资源，相当于对所要求的源进行了一次请求。

四、源继承
来自about:blank，javascript:和data:URLs中的内容，继承了将其载入的文档所指定的源，因为它们的URL本身未指定任何关于自身源的信息。

五、变更源
假设在 http://store.company.com/dir/other.html 中的一个脚本执行了下列语句：
document.domain = "company.com";
这条语句执行之后，页面将会成功地通过对 http://company.com/dir/page.html 的同源检测。而同理，company.com不能设置 document.domain 为 othercompany.com.


31 什么是 “use strict”? 使用它的好处和坏处分别是什么？
ECMAscript 5添加了第二种运行模式："严格模式"（strict mode）。顾名思义，这种模式使得Javascript在更严格的条件下运行。
设立"严格模式"的目的，主要有以下几个：
1. 消除Javascript语法的一些不合理、不严谨之处，减少一些怪异行为;
2. 消除代码运行的一些不安全之处，保证代码运行的安全；
3. 提高编译器效率，增加运行速度；
4. 为未来新版本的Javascript做好铺垫。
注：经过测试 IE6,7,8,9 均不支持严格模式。
缺点：现在网站的 JS 都会进行压缩，一些文件用了严格模式，而另一些没有。这时这些本来是严格模式的文件，被 merge 后，这个串就到了文件的中间，不仅没有指示严格模式，反而在压缩后浪费了字节。
32 哪些地方会出现css阻塞，哪些地方会出现js阻塞？
    js 的阻塞特性：所有浏览器在下载 JS 的时候，会阻止一切其他活动，比如其他资源的下载，内容的呈现等等。直到 JS 下载、解析、执行完毕后才开始继续并行下载其他资源并呈现内容。为了提高用户体验，新一代浏览器都支持并行下载 JS，但是 JS 下载仍然会阻塞其它资源的下载(例如.图片，css文件等)。
　　由于浏览器为了防止出现 JS 修改 DOM 树，需要重新构建 DOM 树的情况，所以就会阻塞其他的下载和呈现。
　　嵌入 JS 会阻塞所有内容的呈现，而外部 JS 只会阻塞其后内容的显示，2 种方式都会阻塞其后资源的下载。也就是说外部样式不会阻塞外部脚本的加载，但会阻塞外部脚本的执行。
　　CSS 怎么会阻塞加载了?CSS 本来是可以并行下载的，在什么情况下会出现阻塞加载了(在测试观察中，IE6 下 CSS 都是阻塞加载)
　　当 CSS 后面跟着嵌入的 JS 的时候，该 CSS 就会出现阻塞后面资源下载的情况。而当把嵌入 JS 放到 CSS 前面，就不会出现阻塞的情况了。
　　根本原因：因为浏览器会维持 html 中 css 和 js 的顺序，样式表必须在嵌入的 JS 执行前先加载、解析完。而嵌入的 JS 会阻塞后面的资源加载，所以就会出现上面 CSS 阻塞下载的情况。
　　嵌入JS应该放在什么位置?
　　1. 放在底部，虽然放在底部照样会阻塞所有呈现，但不会阻塞资源下载。
　　2. 如果嵌入JS放在head中，请把嵌入JS放在CSS头部。
　　3. 使用 defer(只支持IE)
　　4. 不要在嵌入的JS中调用运行时间较长的函数，如果一定要用，可以用 setTimeout 来调用
　　Javascript无阻塞加载具体方式：
　　1. 将脚本放在底部。还是放在head中，用以保证在js加载前，能加载出正常显示的页面。
    <script>
        var script=document.createElement("script");
        script.type="text/javascript";
        script.src="file.js";
        document.getElementsByTagName("head")[0].appendChild(script);
    </script>
　　此技术的重点在于：无论在何处启动下载，文件额下载和运行都不会阻塞其他页面处理过程，即使在head里（除了用于下载文件的 http 链接）。
33 Javascript无阻塞加载具体方式有哪些？
1、将脚本放在底部
<link>还是在head中，用以保证在js加载前，能加载出正常显示的页面。
<script>放在</body>前。

2、成组脚本
由于每个<script>标签下载时阻塞页面解析过程，所以限制页面的<script>总数也可以改善性能。适用于内联脚本和外部脚本。

3、非阻塞脚本
等页面完成加载后，再加载js代码。也就是，在window.load事件发出后开始下载代码。
（1）defer属性：支持IE4和fierfox3.5更高版本浏览器
<script defer>...</script>
内联和外部文件
带defer属性的<script>可出现在文档的任何位置，对应的js文件将在<script>被解析时启动下载，但代码不会执行，直到DOM加载完毕（在onload事件句柄被调用之前）。所以实现了和也卖弄其他资源一起并行下载。

（2）动态脚本元素
文档对象模型（DOM）允许你使用js动态创建HTML的几乎全部文档内容。
复制代码 代码如下:
var script=document.createElement("script");
script.type="text/javascript";
script.src="file.js";
document.getElementByTagName_r("head")[0].appendChild(script);
此技术的重点在于：无论在何处启动下载，文件额下载和运行都不会阻塞其他页面处理过程。即使在head里（除了用于下载文件的http链接）。

（3）The YUI3 approach
理念：用一个很小的初始代码，下载其余的功能代码，先引入文件：
复制代码 代码如下:
<script type="text/javascript src=http://files.jb51.net/file_images/article/201306/yuanma/combo.js></script>

此种子文件大约10KB，
使用：
复制代码 代码如下:
YUI().use("dom",function(Y){
　　Y.Dom.addclass(...)
})
当所有代码可用时，回调函数被调用，YUI实例作为参数传入，就可以立即使用新下载的功能。
The LazyLoad library
使用：先引入：lazyload-min.js

(4)
复制代码 代码如下:
LazyLoad.js("a.js",function(){
Appliction.init();
})

多个文件：
复制代码 代码如下:
LazyLoad.js(["a.js","b.js"],function(){
Application.init();
})

(5)The LABjs library
先引入：lab.js
复制代码 代码如下:
$LAB.script("a.js").wait(function(){
Application.init();
})

多个文件，就链式写法
他的独特之处在于能够管理依赖关系。
可以通过wait()函数指定哪些文件应该等待其他文件。
例如：b.js的代码保不在a.js之前运行
复制代码 代码如下:
$LAB.script("a.js").wait().script("b.js").wait(function(){
Application.init();
})

这样，虽然两个文件是并行下载的，却能保证a.js能在b.js之前执行

34 事件、IE与火狐的事件机制有什么区别？ 如何阻止冒泡？
1.事件流描述的是从页面中接受事件的顺序，分为冒泡流和捕获流；
2.事件冒泡是指事件从最具体的元素接收，然后逐级向上传播，直到不具体的节点（通常指文档节点）；而事件捕获相反，它是从不具体的节点开始，逐步到最具体的节点；
3.IE的事件流是冒泡流，而火狐同时支持冒泡流和捕获流；
4.阻止事件冒泡：e.stopPropagation()，IE则是使用e.cancelBubble = true；


35 说说TCP传输的三次握手策略？

首先由Client发出请求连接即 SYN=1 ACK=0  (请看头字段的介绍), TCP规定SYN=1时不能携带数据，但要消耗一个序号,因此声明自己的序号是 seq=x
然后 Server 进行回复确认，即 SYN=1 ACK=1 seq=y, ack=x+1, 再然后 Client 再进行一次确认，但不用SYN 了，这时即为 ACK=1, seq=x+1, ack=y+1.
然后连接建立，为什么要进行三次握手呢（两次确认）。 
建立三次握手主要是因为A发送了再一次的确认，那么A为什么会再确认一次呢，主要是为了防止已失效的连接请求报文段又突然传送给B，从而产生了错误。所谓“已失效的连接请求报文”是这样产生的，正常情况下，A发出连接请求，但是因为连接报文请求丢失而未收到确认，于是A再重传一次连接请求，后来收到了请求，并收到了确认，建立了连接，数据传输完毕后，就释放链接，A共发送了两次连接请求报文段，其中第一个丢失，第二个到达了B，没有“已失效的连接请求报文段”，但是还有异常情况下，A发送的请求报文连接段并没有丢失，而是在某个网络节点滞留较长时间，以致延误到请求释放后的某个时间到达B，本来是一个早已失效的报文段，但是B收到了此失效连接请求报文段后，就误以
为A又重新发送的连接请求报文段，并发送确认报文段给A，同意建立连接，如果没有三次握手，那么B发送确认后，连接就建立了，而此时A没有发送建立.
连接的请求报文段，于是不理会B的确认，也不会给B发送数据，而B却一直等待A发送数据，因此B的许多资源就浪费了，采用三次握手的方式就可以防止这.
种事情发生，例如刚刚，A不理会B，就不会给B发送确认，B收不到A的确认，就知道A不要求建立连接，就不会白白浪费资源.


36 Javascript垃圾回收方法？
一、垃圾回收的必要性
　　由于字符串、对象和数组没有固定大小，所有当他们的大小已知时，才能对他们进行动态的存储分配。JavaScript程序每次创建字符串、数组或对象时，解释器都必须分配内存来存储那个实体。只要像这样动态地分配了内存，最终都要释放这些内存以便他们能够被再用，否则，JavaScript的解释器将会消耗完系统中所有可用的内存，造成系统崩溃。
　　这段话解释了为什么需要系统需要垃圾回收，JS不像C/C++，他有自己的一套垃圾回收机制（Garbage Collection）。JavaScript的解释器可以检测到何时程序不再使用一个对象了，当他确定了一个对象是无用的时候，他就知道不再需要这个对象，可以把它所占用的内存释放掉了。例如：
var a = "before";
var b = "override a";
var a = b; //重写a
　　这段代码运行之后，“before”这个字符串失去了引用（之前是被a引用），系统检测到这个事实之后，就会释放该字符串的存储空间以便这些空间可以被再利用。

二、垃圾回收原理浅析
　　现在各大浏览器通常用采用的垃圾回收有两种方法：标记清除、引用计数。
1、标记清除
　　这是javascript中最常用的垃圾回收方式。当变量进入执行环境是，就标记这个变量为“进入环境”。从逻辑上讲，永远不能释放进入环境的变量所占用的内存，因为只要执行流进入相应的环境，就可能会用到他们。当变量离开环境时，则将其标记为“离开环境”。
　　垃圾收集器在运行的时候会给存储在内存中的所有变量都加上标记。然后，它会去掉环境中的变量以及被环境中的变量引用的标记。而在此之后再被加上标记的变量将被视为准备删除的变量，原因是环境中的变量已经无法访问到这些变量了。最后。垃圾收集器完成内存清除工作，销毁那些带标记的值，并回收他们所占用的内存空间。

关于这一块，建议读读Tom大叔的几篇文章，关于作用域链的一些知识详解，读完差不多就知道了，哪些变量会被做标记。

2、引用计数
　　另一种不太常见的垃圾回收策略是引用计数。引用计数的含义是跟踪记录每个值被引用的次数。当声明了一个变量并将一个引用类型赋值给该变量时，则这个值的引用次数就是1。相反，如果包含对这个值引用的变量又取得了另外一个值，则这个值的引用次数就减1。当这个引用次数变成0时，则说明没有办法再访问这个值了，因而就可以将其所占的内存空间给收回来。这样，垃圾收集器下次再运行时，它就会释放那些引用次数为0的值所占的内存。
        
但是用这种方法存在着一个问题，下面来看看代码：
复制代码

function problem() {
    var objA = new Object();
    var objB = new Object();

    objA.someOtherObject = objB;
    objB.anotherObject = objA;
}

　　在这个例子中，objA和objB通过各自的属性相互引用；也就是说这两个对象的引用次数都是2。在采用引用计数的策略中，由于函数执行之后，这两个对象都离开了作用域，函数执行完成之后，objA和objB还将会继续存在，因为他们的引用次数永远不会是0。这样的相互引用如果说很大量的存在就会导致大量的内存泄露。
        
　　我们知道，IE中有一部分对象并不是原生JavaScript对象。例如，其BOM和DOM中的对象就是使用C++以COM（Component Object 
Model，组件对象）对象的形式实现的，而COM对象的垃圾回收器就是采用的引用计数的策略。因此，即使IE的Javascript引擎使用标记清除的策略来实现的，但JavaScript访问的COM对象依然是基于引用计数的策略的。说白了，只要IE中涉及COM对象，就会存在循环引用的问题。看看下面的这个简单的例子：

var element = document.getElementById("some_element");
var myObj =new Object();
myObj.element = element;
element.someObject = myObj;

　　上面这个例子中，在一个DOM元素(element)与一个原生JavaScript对象(myObj)之间建立了循环引用。其中，变量myObj有一个名为element的属性指向element；而变量element有一个名为someObject的属性回指到myObj。由于循环引用，即使将例子中的DOM从页面中移除，内存也永远不会回收。
        
　　不过上面的问题也不是不能解决，我们可以手动切断他们的循环引用。

myObj.element = null;
element.someObject =null;

这样写代码的话就可以解决循环引用的问题了，也就防止了内存泄露的问题。


37 什么是Etag？
在HTTP1.1规范中，新增了一个HTTP头信息：ETag。对Web开发者来说，它是一个非常重要的信息。它是用作缓存使
用的两个主要的头信息之一 (另一个是Expires)。除此之外，在REST架构中，它还可以用于控制并发操作(上节中已经大
致介绍AtomPub中控制并发的流程)。那么ETag是什么？它又几种类型？强ETag与弱ETag之间有什么区别。？如何计算
ETag值?它与Last-Modified头信息在使用上有什么区别？本节主要围绕这几个方面叙述一下自己的理解。


38 关于Http 2.0 你怎么理解？
1、什么是HTTP 2.0
HTTP/2（超文本传输协议第2版，最初命名为HTTP 2.0），是HTTP协议的的第二个主要版本，使用于万维网。HTTP/2是HTTP协议自1999年HTTP 1.1发布后的首个更新，主要基于SPDY协议（是Google开发的基于TCP的应用层协议，用以最小化网络延迟，提升网络速度，优化用户的网络使用体验）。

2、与HTTP 1.1相比，主要区别包括
HTTP/2采用二进制格式而非文本格式
HTTP/2是完全多路复用的，而非有序并阻塞的——只需一个连接即可实现并行
使用报头压缩，HTTP/2降低了开销
HTTP/2让服务器可以将响应主动“推送”到客户端缓存中


---------------------------------------------------------------------------------------------------------------
------------------------------------------front basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------go basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 Go基础
一个开源的编程语言，它能让构造简单、可靠且高效的软件变得容易。
Go是从2007年末由Robert Griesemer, Rob Pike, Ken Thompson主持开发，后来还加入了Ian Lance Taylor, Russ Cox等人，并最终于2009年11月开源，在2012年早些时候发布了Go 1稳定版本。现在Go的开发已经是完全开放的，并且拥有一个活跃的社区。

2 第一个 Go 程序
hello.go 文件
package main
import "fmt"
func main() {
    fmt.Println("Hello, World!")
}

3 Go 语言最主要的特性：
自动垃圾回收
更丰富的内置类型
函数多返回值
错误处理
匿名函数和闭包
类型和接口
并发编程
反射
语言交互性


4 环境安装
安装包下载地址为：https://golang.org/dl/。
如果打不开可以使用这个地址：https://golang.google.cn/dl/。
操作系统	包名
Windows	go1.4.windows-amd64.msi
Linux	go1.4.linux-amd64.tar.gz
Mac	go1.4.darwin-amd64-osx10.8.pkg
FreeBSD	go1.4.freebsd-amd64.tar.gz
（1）linux安装
tar -C /usr/local -xzf go1.4.linux-amd64.tar.gz
export PATH=$PATH:/usr/local/go/bin
我们可以编辑 ~/.bash_profile 或者 /etc/profile，并将以下命令添加该文件的末尾，这样就永久生效了：
export PATH=$PATH:/usr/local/go/bin
添加后需要执行：
source ~/.bash_profile
（2）Windows 系统下安装
Windows 下可以使用 .msi 后缀(在下载列表中可以找到该文件，如go1.4.2.windows-amd64.msi)的安装包来安装。
默认情况下 .msi 文件会安装在 c:\Go 目录下。你可以将 c:\Go\bin 目录添加到 Path 环境变量中。添加后你需要重启命令窗口才能生效。
创建工作目录 C:\>Go_WorkSpace。

test.go 文件代码：
package main
import "fmt"
func main() {
   fmt.Println("Hello, World!")
}

使用 go 命令执行以上代码输出结果如下：
C:\Go_WorkSpace>go run test.go
Hello, World!

5 Go 语言的基础组成有以下几个部分：
包声明
引入包
函数
变量
语句 & 表达式
注释

6 结构体
type struct_variable_type struct {
   member definition
   member definition
   ...
   member definition
}

package main
import "fmt"
type Books struct {
   title string
   author string
   subject string
   book_id int
}
func main() {
    // 创建一个新的结构体
    fmt.Println(Books{"Go 语言", "www.runoob.com", "Go 语言教程", 6495407})
    // 也可以使用 key => value 格式
    fmt.Println(Books{title: "Go 语言", author: "www.runoob.com", subject: "Go 语言教程", book_id: 6495407})
    // 忽略的字段为 0 或 空
   fmt.Println(Books{title: "Go 语言", author: "www.runoob.com"})
}

7 Go 并发
Go 语言支持并发，我们只需要通过 go 关键字来开启 goroutine 即可。
goroutine 是轻量级线程，goroutine 的调度是由 Golang 运行时进行管理的。




二、ms相关
1 说说go语言的main函数
(1) main函数不能带参数。
(2) main函数不能定义返回值。
(3) main函数所在的包必须为main包。
(4) main函数中可以使用flag包来获取和解析命令行参数。

2 在go语言中，new和make的区别？
new函数是内建函数，函数定义为
func new(Type) *Type 
1
new 的作用是初始化一个指向类型的指针(*Type )，使用new函数来分配空间。传递给new 函数的是一个类型，不是一个值。返回值是 指向这个新分配的零值的指针。
make函数是内建函数，函数定义为
func make(t Type, size ...IntegerType) Type
1
make 的作用是为 slice，map 或 chan 初始化并返回引用(Type)。 第一个参数是一个类型，第二个参数是长度。
make(T, args)函数的目的与new(T)不同。它仅仅用于创建 Slice, Map 和 Channel，并且返回类型是 T（不是T*）的一个初始化的（不是零值）的实例。

3 说说go语言中的switch语句？
单个case中，可以出现多个结果选项。
只有在case中明确添加fallthrough关键字，才会继续执行紧跟的下一个case

4 说说go语言中的for循环？
for循环支持continue和break来控制循环，但是它提供了一个更高级的break，可以选择中断哪一个循环。
for循环不支持以逗号为间隔的多个赋值语句，必须使用平行赋值的方式来初始化多个变量 。

5 go语言中指针运算有哪些？
(1) 可以通过“&”取指针的地址。
(2) 可以通过“*”取指针指向的数据。

6 说说go语言中的协程？
(1) 协程和线程都可以实现程序的并发执行；
(2) 通过channel来进行协程间的通信；
(3) 只需要在函数调用前添加go关键字即可实现go的协程，创建并发任务；
(4) 关键字go并非执行并发任务，而是创建一个并发任务单元；

7 ’go语言中的引用类型包含哪些？
数组切片 字典(map) 通道（channel） 接口（interface）

8 说说go语言中的init函数？
(1) 一个包中，可以包含多个init函数
(2) 程序编译时，先执行导入包的init函数，再执行本包内的init函数

9  说说go语言的同步锁？
(1) 当一个goroutine获得了Mutex后，其他goroutine就只能乖乖的等待，除非该goroutine释放这个Mutex
(2) RWMutex在读锁占用的情况下，会阻止写，但不阻止读
(3) RWMutex在写锁占用情况下，会阻止任何其他goroutine（无论读和写）进来，整个锁相当于由该goroutine独占

10 说说go语言的关于go vendor？
(1) 基本思路是将引用的外部包的源代码放在当前工程的vendor目录下面
(2) 编译go代码会优先从vendor目录先寻找依赖包
(3) 有了vendor目录后，打包当前的工程代码到其他机器的$GOPATH/src下都可以通过编译

11 说说go语言的channel特性？
(1) 给一个 nil channel 发送数据，造成永远阻塞
(2)  从一个 nil channel 接收数据，造成永远阻塞
(3)  给一个已经关闭的 channel 发送数据，引起 panic
(4) 从一个已经关闭的 channel 接收数据，如果缓冲区中为空，则返回一个零值
(5) 无缓冲的channel是同步的，而有缓冲的channel是非同步的

12 说说go语言的select机制？
(1) select机制用来处理异步IO问题
(2) select机制最大的一条限制就是每个case语句里必须是一个IO操作
(3) golang在语言级别支持select关键字

13 说说go语言的goconvey框架？
(1) goconvey是一个支持golang的单元测试框架
(2) goconvey能够自动监控文件修改并启动测试，并可以将测试结果实时输出到web界面
(3) goconvey提供了丰富的断言简化测试用例的编写

14 协程，线程，进程的区别？
进程
进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位。每个进程都有自己的独立内存空间，不同进程通过进程间通信来通信。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈 寄存器 虚拟内存 文件句柄等）比较大，但相对比较稳定安全。
线程
线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。
协程
协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。

15  Golang的内存模型，为什么小对象多了会造成gc压力。
通常小对象过多会导致GC三色法消耗过多的GPU。优化思路是，减少对象分配.

16 并发编程概念是什么？
并行是指两个或者多个事件在同一时刻发生；并发是指两个或多个事件在同一时间间隔发生。
发偏重于多个任务交替执行，而多个任务之间有可能还是串行的。而并行是真正意义上的“同时执行”
并发编程是指在一台处理器上“同时”处理多个任务。并发是在同一实体上的多个事件。多个事件在同一时间间隔发生。并发编程的目标是充分的利用处理器的每一个核，以达到最高的处理性能。

17 读写锁或者互斥锁读的时候能写吗?
Go中读写锁包括读锁和写锁，多个读线程可以同时访问共享数据；写线程必须等待所有读线程都释放锁以后，才能取得锁；同样的，读线程必须等待写线程释放锁后，才能取得锁，也就是说读写锁要确保的是如下互斥关系，可以同时读，但是读-写，写-写都是互斥的。

18 Log包线程安全吗？
Golang的标准库提供了log的机制，但是该模块的功能较为简单（看似简单，其实他有他的设计思路）。在输出的位置做了线程安全的保护。

19 主协程如何等其余协程完再操作？
使用channel进行通信，context,select。

20 slice，len，cap，共享，扩容
append函数，因为slice底层数据结构是，由数组 len cap组成，所以，在使用append扩容时，会查看数组后面有没有连续内存快，有就在后面添加，没有就重新生成一个大的素组。

21 map如何顺序读取
map不能顺序读取，是因为他是无序的，想要有序读取，首先的解决的问题就是，把ｋｅｙ变为有序，所以可以把key放入切片，对切片进行排序，遍历切片，通过key取值。

22 context包的用途
Context通常被译作上下文，它是一个比较抽象的概念，其本质，是【上下上下】存在上下层的传递，上会把内容传递给下。在Go语言中，程序单元也就指的是Goroutine。

---------------------------------------------------------------------------------------------------------------
------------------------------------------go basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------hadoop basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 Apache Hadoop 
一个由 Apache 基金会所开发的分布式系统基础架构。
可以让用户在不了解分布式底层细节的情况下，开发出可靠、可扩展的分布式计算应用。Apache Hadoop框架，允许用户使用简单的编程模型来实现计算机集群的大型数据集的分布式处理。它的目的是支持从单一服务器到上千台机器的扩展，充分利用了每台机器所提供本地计算和存储，而不是依靠硬件来提供高可用性。其本身被设计成在应用层检测和处理故障的库，对于计算机集群来说，其中每台机器的顶层都被设计成可以容错的，以便提供一个高度可用的服务。

2 Apache Hadoop 的框架最核心的设计就是：
HDFS 和 MapReduce。HDFS 为海量的数据提供了存储，而 MapReduce 则为海量的数据提供了计算。

3 发展历程 
Apache Hadoop 的雏形开始于2002年的 Apache 的 Nutch。Nutch 是一个开源 Java 实现的搜索引擎。它提供了我们运行自己的搜索引擎所需的全部工具，包括全文搜索和 Web 爬虫。随后在 2003 年 Google 发表了一篇技术学术论文关于 Google 文件系统（GFS）。GFS 也就是 Google File System，是 Google 公司为了存储海量搜索数据而设计的专用文件系统。
2004年 Nutch 创始人 Doug Cutting（同时也是 Apache Lucene 的创始人） 基于 Google 的 GFS 论文实现了分布式文件存储系统名为 NDFS。
2004年 Google 又发表了一篇技术学术论文，向全世界介绍了 MapReduce。2005年 Doug Cutting 又基于 MapReduce，在 Nutch 搜索引擎实现了该功能。
2006年，Yahoo! 雇用了 Doug Cutting，Doug Cutting 将 NDFS 和MapReduce 升级命名为 Hadoop。Yahoo! 开建了一个独立的团队给 Goug Cutting 专门研究发展 Hadoop。
2008年1月，Hadoop 成为了 Apache 顶级项目。之后 Hadoop 被成功的应用在了其他公司，其中包括 Last.fm、Facebook、《纽约时报》等。
2008年2月，Yahoo! 宣布其搜索引擎产品部署在一个拥有1万个内核的 Hadoop 集群上。
2008年4月，Hadoop 打破世界记录，称为最快排序1TB数据的系统。有关该报道的记录，可以参阅《Apache Hadoop Wins Terabyte Sort Benchmark》（见 
截止目前，Apache Hadoop 的最新版本为 2.7.3。

4 Apache Hadoop 优点 
（1）高可靠性。Hadoop 按位存储和处理数据的能力值得人们信赖。
（2）高扩展性。Hadoop 是在可用的计算机集簇间分配数据并完成计算任务的，这些集簇可以方便地扩展到数以千计的节点中。
（3）高效性。Hadoop 能够在节点之间动态地移动数据，并保证各个节点的动态平衡，因此处理速度非常快。
（4）高容错性。Hadoop 能够自动保存数据的多个副本，并且能够自动将失败的任务重新分配。
（5）低成本。Hadoop 是开源的，项目的软件成本因此会大大降低。

5 Apache Hadoop 包含以下模块： 
（1）Hadoop Common：常见实用工具，用来支持其他 Hadoop 模块。
（2）Hadoop Distributed File System（HDFS）：分布式文件系统，它提供对应用程序数据的高吞吐量访问。
（3）Hadoop YARN：一个作业调度和集群资源管理框架。
（4）Hadoop MapReduce：基于 YARN 的大型数据集的并行处理系统。

6 其他与 Apache Hadoop 的相关项目包括：
（1）Ambari：一个基于Web 的工具，用于配置、管理和监控的 Apache Hadoop 集群，其中包括支持 Hadoop HDFS、Hadoop MapReduce、Hive、HCatalog、HBase、ZooKeeper、Oozie、Pig 和 Sqoop。Ambari 还提供了仪表盘查看集群的健康，如热图，并能够以用户友好的方式来查看的 MapReduce、Pig 和 Hive 应用，方便诊断其性能。
（2）Avro：数据序列化系统。
（3）Cassandra：可扩展的、无单点故障的多主数据库。
（4）Chukwa：数据采集系统，用于管理大型分布式系统。
（5）HBase：一个可扩展的分布式数据库，支持结构化数据的大表存储。(有关 HBase 的内容，会在后面章节讲述) 
（6）Hive：数据仓库基础设施，提供数据汇总以及特定的查询。
（7）Mahout：一种可扩展的机器学习和数据挖掘库。
（8）Pig：一个高层次的数据流并行计算语言和执行框架。
（9）Spark：Hadoop 数据的快速和通用计算引擎。Spark 提供了简单和强大的编程模型用以支持广泛的应用，其中包括 ETL、机器学习、流处理和图形计算。(有关 Spark 的内容，会在后面章节讲述)
（10）TEZ：通用的数据流编程框架，建立在 Hadoop YARN 之上。它提供了一个强大而灵活的引擎来执行任意 DAG 任务，以实现批量和交互式数据的处理。TEZ 正在被 Hive、Pig 和 Hadoop 生态系统中其他框架所采用，也可以通过其他商业软件（例如 ETL 工具），以取代的 Hadoop MapReduce 作为底层执行引擎。
（11）ZooKeeper：一个高性能的分布式应用程序协调服务。

7 Hadoop Common
1） org.apache.hadoop.conf
配置相关类，配置类在Hadoop中一直都是一个比较基本类，很多配置设置的数据都需要从配置文件中去读取。Hadoop中配置文件还挺多的，HDFS和MapReduce各一个，还会用用户自定义的配置文件。系统开放了许多的get/set方法来获取和设置其中的属性。
2） org.apache.hadoop.fs
Hadoop文件系统，从Hadoop的文件系统中，也许你会看到Linux文件系统的影子，里面包括了很多文件File的各种基本操作，还有很多在文件中特殊的操作实现，比如权限控制，目录，文件通过什么来组织，Hadoop文件系统搞了一个和VFS虚拟文件系统非常像的一个抽象文件系统，基于这个Hadoop抽象文件系统，派生了很多具体拥有各个功能的文件子系统，比如内存文件系统，校验和系统。
3） org.apache.hadoop.io
Hadoop I/O系统，输入输出系统在任何一个系统都是非常重要的设计，同样在Hadoop中，在此上面实现了一个特有的序列化系统，不同于java自带的序列化实现，Hadoop的序列化机制具有快速，紧凑的特点，非常适合于Hadoop的使用场景。还有1个就是Hadoop的在I/O中的解压缩的设计，里面还可以通过JNI的形式调用第三方的比较优秀的压缩算法，比如Google的Snappy框架。
4） org.apache.hadoop.ipc
Hadoop远程过程调用的实现，这个模块的设计是有很多值得学习的好地方，java的RPC最直接的体现就是RMI的实现，RMI的实现就是一个简陋版本的远程过程调用，但是由于JMI的不可定制性，所以Hadoop根据自己系统特点，重新设计了一套独有的RPC体系，在java NIO的基础上，用了java动态代理的思想，RPC的服务端和客户端都是通过代理获得方式取得。
5） org.apache.hadoop.log
日志帮助类，实现估值的检测和恢复
6） org.apache.hadoop.metrics
用于度量统计用的，主要用于分析的
7） org.apache.hadoop.http、org.apache.hadoop.net
Hadoop对网络层次相关的封装
8） org.apache.hadoop.util
就是在Common中的公共方法类，checkSum校验和的验证方法就包含于此。

8 HDFS
HDFS（Hadoop Distributed File System）是Hadoop的核心子项目，是一个可以运行在普通硬件设备上的分布式文件系统，是分布式计算中数据存储和管理的基础，是基于流数据模式访问和处理超大文件的需求而开发的。它所具有的高容错、高可靠性、高可扩展性、高吞吐率等特征为海量数据提供了不怕故障的存储，给超大数据集（Large Data  Set） 的应用处理带来了很多便利。Hadoop分布式文件系统或HDFS是基于Java的分布式文件系统，允许您在Hadoop集群中的多个节点上存储大量数据。因此，如果您安装Hadoop，您将HDFS作为底层存储系统来存储分布式环境中的数据。
举个例子来理解它。想象一下，你有十台机器或十台电脑，每台机器上有1TB的硬盘。现在，HDFS表示，如果您将Hadoop作为平台安装在这十台机器上，您将获得HDFS作为存储服务。Hadoop分布式文件系统以这样的方式分发，即每台机器都有自己的存储空间来存储任何类型的数据。

9 Hadoop YARN
（1）Hadoop 原 MapReduce 架构
1）首先用户程序 (JobClient) 提交了一个 job，job 的信息会发送到 Job Tracker 中，Job Tracker 是 Map-reduce 框架的中心，他需要与集群中的机器定时通信 (heartbeat), 需要管理哪些程序应该跑在哪些机器上，需要管理所有 job 失败、重启等操作。
2）TaskTracker 是 Map-reduce 集群中每台机器都有的一个部分，他做的事情主要是监视自己所在机器的资源情况。
3）TaskTracker 同时监视当前机器的 tasks 运行状况。TaskTracker 需要把这些信息通过 heartbeat 发送给 JobTracker，JobTracker 会搜集这些信息以给新提交的 job 分配运行在哪些机器上。上图虚线箭头就是表示消息的发送 - 接收的过程。

（2）MRv1主要的问题
1）JobTracker 是 Map-reduce 的集中处理点，存在单点故障。
2） JobTracker 完成了太多的任务，造成了过多的资源消耗，当 map-reduce job 非常多的时候，会造成很大的内存开销，潜在来说，也增加了 JobTracker fail 的风险，这也是业界普遍总结出老 Hadoop 的 Map-Reduce 只能支持 4000 节点主机的上限。
3）在 TaskTracker 端，以 map/reduce task 的数目作为资源的表示过于简单，没有考虑到 cpu/ 内存的占用情况，如果两个大内存消耗的 task 被调度到了一块，很容易出现 OOM。
4）在 TaskTracker 端，把资源强制划分为 map task slot 和 reduce task slot, 如果当系统中只有 map task 或者只有 reduce task 的时候，会造成资源的浪费，也就是前面提过的集群资源利用的问题。
5）源代码层面分析的时候，会发现代码非常的难读，常常因为一个 class 做了太多的事情，代码量达 3000 多行，，造成 class 的任务不清晰，增加 bug 修复和版本维护的难度。
6）从操作的角度来看，现在的 Hadoop MapReduce 框架在有任何重要的或者不重要的变化 ( 例如 bug 修复，性能提升和特性化 ) 时，都会强制进行系统级别的升级更新。更糟的是，它不管用户的喜好，强制让分布式集群系统的每一个用户端同时更新。这些更新会让用户为了验证他们之前的应用程序是不是适用新的 Hadoop 版本而浪费大量时间。 

（3）新 Hadoop Yarn （MRv2）框架原理及运作机制
将资源调度和任务调度分开。资源管理器ResourceManager全局管理所有应用程序计算资源的分配，每一个job的ApplicationMaster负责相应任务的调度和协调。
1）ResourceManager做的事情是负责协调集群上计算资源的分配。调度、启动每一个 Job 所属的 ApplicationMaster、另外监控 ApplicationMaster 的存在情况。
2）NodeManager 功能比较专一，根据要求启动和监视集群中机器的计算容器container。负责 Container 状态的维护，并向 RM 保持心跳汇报该节点资源使用情况。
3）ApplicationMaster 负责一个 Job 生命周期内的所有工作。注意每一个Job都有一个 ApplicationMaster。它和MapReduce任务一样在容器中运行。AM通过与RM交互获取资源，然后然后通过与NM交互，启动计算任务。
4）容器是由ResourceManager进行统一管理和分配的。有两类container：一类是AM运行需要的container；另一类是AP为执行任务向RM申请的。

（4）新旧方案对比
1）这个设计大大减小了 JobTracker（也就是现在的 ResourceManager）的资源消耗，并且让监测每一个 Job 子任务 (tasks) 状态的程序分布式化了，更安全、更优美。
2）在新的 Yarn 中，ApplicationMaster 是一个可变更的部分，用户可以对不同的编程模型写自己的 AppMst，让更多类型的编程模型能够跑在 Hadoop 集群中，可以参考 hadoop Yarn 官方配置模板中的 mapred-site.xml 配置。
3）对于资源的表示以内存为单位 ( 在目前版本的 Yarn 中，没有考虑 cpu 的占用 )，比之前以剩余 slot 数目更合理。
4）老的框架中，JobTracker 一个很大的负担就是监控 job 下的 tasks 的运行状况，现在，这个部分就扔给 ApplicationMaster 做了，而 ResourceManager 中有一个模块叫做 ApplicationsMasters( 注意不是 ApplicationMaster)，它是监测 ApplicationMaster 的运行状况，如果出问题，会将其在其他机器上重启。
5）Container 是 Yarn 为了将来作资源隔离而提出的一个框架。这一点应该借鉴了 Mesos 的工作，目前是一个框架，仅仅提供 java 虚拟机内存的隔离 ,hadoop 团队的设计思路应该后续能支持更多的资源调度和控制 , 既然资源表示成内存量，那就没有了之前的 map slot/reduce slot 分开造成集群资源闲置的尴尬情况。
所以yarn解决了扩展性差，单点故障以及只能局限于MR计算框架等的问题。

（5）YARN中提交job的详细流程
1）RunJar里面的Conf的配置引用决定了是在本地还是集群运行。是提交到集群yarn_provider还是本地运行local_provider。配置conf决定了是访问远程rpc还是本地rpc。
步骤2中的staging_dir存放的是作业Jar、配置信息和分片信息；这个staging_dir默认是在HDFS上。步骤5是ResourceManager将任务添加到任务队列中。然后，ResourceManager将随机挑选一个NodeManager管理下的Container分配给ApplicationMaster进程，作为MRAppMaster任务调度中心。MRAppMaster会对作业初始化，接受任务的进度和完成报告；接受HDFS中存放的客户端计算的输入分片信息，对每一个分片创建一个map任务对象和由mapreduce.job.reduces确定的reduce对象。
2）ApplicationMaster会为该作业所有的map和reduce任务向ResourceManager请求容器（包括内存资源和CPU资源）；附着心跳信息的请求包括map任务的本地化信息，如输入分片所在的主机和机架信息。ResourceManager根据这些信息完成分配决策，理想情况会将任务分配给数据本地化的节点。
3）ResourceManager为任务分配了容器后，ApplicationMaster就通过节点间通信来启动NodeManager中的容器，任务由容器中的YarnChild应用程序执行。在任务执行前，容器将任务需要的资源本地化，包括staging_dir中的作业Jar、配置和文件资源。
4）ApplicationMaster负责启动map和reduce任务，监控。并在所有任务完成后，向ResourceManager注销自己，清理工作状态。在实际运行中，NodeManager节点会随机被指定MRAppMaster进程，然后在任务节点出现yarnChild进程。yarnChild进程执行完map或reduce任务后会消失，MRAppMaster进程执行完这个job后会消失。

（6）YARN框架的通用性
资源管理框架ResourceMnager可以为MapReduce、Spark、Storm等计算框架实现资源调度。但是这些计算框架需要实现一个接口，AppMaster；资源管理器才能启动这个AppMaster执行计算任务。比如只需要MR实现MRAppMaster，Spark也需要实现SparkAppMaster

（7）YARN的HA
Yarn的Ha只能保证，在一个节点失效时，另一台能提供服务。但是不能像HDFS一样智能。Application在执行一半时ResourceManager宕机，另一个ResourceManager不能继续提供任务的执行服务，因为中间数据太多，Hadoop未实现这种任务调度的切换。而HDFS的HA可以保证杀掉active状态的NameNode，文件依然能够上传成功。

10 MapReduce
MapReduce是一种处理技术和程序模型基于Java的分布式计算。 MapReduce算法包含了两项重要任务，即Map 和 Reduce。Map采用了一组数据，并将其转换成另一组数据，其中，各个元件被分解成元组(键/值对)。其次，减少任务，这需要从Map 作为输入并组合那些数据元组成的一组小的元组输出。作为MapReduce暗示的名称的序列在Map作业之后执行reduce任务。
MapReduce主要优点是，它很容易大规模数据处理在多个计算节点。下面MapReduce模型中，数据处理的原语被称为映射器和减速器。分解数据处理应用到映射器和减速器有时是普通的。但是编写MapReduce形式的应用，扩展应用程序运行在几百，几千，甚至几万机集群中的仅仅是一个配置的更改。这个简单的可扩展性是吸引了众多程序员使用MapReduce模型。
MapReduce是一种分布式计算模型，是Google提出的，主要用于搜索领域，解决海量数据的计算问题。
MR有两个阶段组成：Map和Reduce，用户只需实现map()和reduce()两个函数，即可实现分布式计算。

11 MapReduce算法原理 
（1）通常MapReduce范例是基于向发送计算机数据的位置！
（2）MapReduce计划分三个阶段执行，即映射阶段，shuffle阶段，并减少阶段。
1）映射阶段：映射或映射器的工作是处理输入数据。一般输入数据是在文件或目录的形式，并且被存储在Hadoop的文件系统（HDFS）。输入文件被传递到由线映射器功能线路。映射器处理该数据，并创建数据的若干小块。
2）减少阶段，这个阶段是：Shuffle阶段和Reduce阶段的组合。减速器的工作是处理该来自映射器中的数据。处理之后，它产生一组新的输出，这将被存储在HDFS。
3）在一个MapReduce工作，Hadoop的发送Map和Reduce任务到集群的相应服务器。
框架管理数据传递例如发出任务的所有节点之间的集群周围的详细信息，验证任务完成，和复制数据。大部分的计算发生在与在本地磁盘上，可以减少网络通信量数据的节点。给定的任务完成后，将群集收集并减少了数据，以形成一个合适的结果，并且将其发送回Hadoop服务器。


12 MapReduce的执行步骤
（1）Map任务处理
　　1.1 读取HDFS中的文件。每一行解析成一个<k,v>。每一个键值对调用一次map函数。                <0,hello you>   <10,hello me>                    
　　1.2 覆盖map()，接收1.1产生的<k,v>，进行处理，转换为新的<k,v>输出。　　　　　　　　　　<hello,1> <you,1> <hello,1> <me,1>
　　1.3 对1.2输出的<k,v>进行分区。默认分为一个区。详见《Partitioner》
　　1.4 对不同分区中的数据进行排序（按照k）、分组。分组指的是相同key的value放到一个集合中。　排序后：<hello,1> <hello,1> <me,1> <you,1>  分组后：<hello,{1,1}><me,{1}><you,{1}>
　　1.5 （可选）对分组后的数据进行归约。详见《Combiner》

（2）Reduce任务处理
　　2.1 多个map任务的输出，按照不同的分区，通过网络copy到不同的reduce节点上。（shuffle）详见《shuffle过程分析》
　　2.2 对多个map的输出进行合并、排序。覆盖reduce函数，接收的是分组后的数据，实现自己的业务逻辑，　<hello,2> <me,1> <you,1>处理后，产生新的<k,v>输出。
2.3 对reduce输出的<k,v>写到HDFS中。

13 MapReduce容错机制
MapReduce的第一阶段是Map，运行的实例叫Map Task，第二阶段是Reduce，运行的实例叫Reduce Task。第二阶段Reduce要等第一阶段Map上的Map Task完成之后才能开始。如果Map Task运行失败，如何处理？
这时候就要启动mapreduce的容错机制了，它允许整个执行过程中TaskTracker中间出现宕机，发生故障，JVM发生重启等等这些情况，允许它出错。处理的方式：
1）重复执行
有可能是job本身问题，硬件问题，数据的问题都有可能，默认会重新执行，如果重新执行4次都失败就放弃执行。
2）.推测执行
由于要Map端所有任务执行完才会执行reduce任务，可能存在某个节点完成的特别慢，JobTracker发现它很慢的时候，说明它出现了问题，另外找一台TaskTrack执行同一任务，哪个先完成就取该结果，结束另一个TaskTracker。

14 Hadoop序列化--Writable
序列化就是将内存当中的数据序列化到字节流中，
他实现了WritableComparable 接口，并继承了Writable（Write和ReadFile需要被实现）和Compare接口
特点：
1 ）紧凑：高校使用存储空间
2 ）快速：读写数据的额外开销小
3 ）可扩展：可透明的读取老格式的数据
4 ）互操作：支持多语言的交互
说明：JAVA 的序列化对继承等的结构都保存了，而对hadoop用不着，只需要存储字符就可以，所以有自己的机制。

15 Hadoop 1.0和Hadoop 2.0
（1）Hadoop 1.0 
Hadoop1.0即第一代Hadoop，由分布式存储系统HDFS和分布式计算框架MapReduce组成，其中，HDFS由一个NameNode和多个DataNode组成，MapReduce由一个JobTracker和多个TaskTracker组成，对应Hadoop版本为Apache Hadoop 0.20.x、1.x、0.21.X、0.22.x和CDH3。
（2）Hadoop 2.0 
Hadoop 2.0即第二代Hadoop，为克服Hadoop 1.0中HDFS和MapReduce存在的各种问题而提出的。针对Hadoop 1.0中的单NameNode制约HDFS的扩展性问题，提出了HDFS Federation，它让多个NameNode分管不同的目录进而实现访问隔离和横向扩展，同时它彻底解决了NameNode 单点故障问题；针对Hadoop 1.0中的MapReduce在扩展性和多框架支持等方面的不足，它将JobTracker中的资源管理和作业控制功能分开，分别由组件ResourceManager和ApplicationMaster实现，其中，ResourceManager负责所有应用程序的资源分配，而ApplicationMaster仅负责管理一个应用程序，进而诞生了全新的通用资源管理框架YARN。基于YARN，用户可以运行各种类型的应用程序（不再像1.0那样仅局限于MapReduce一类应用），从离线计算的MapReduce到在线计算（流式处理）的Storm等。Hadoop 2.0对应Hadoop版本为Apache Hadoop 0.23.x、2.x和CDH4。




二、ms相关
1.hdfs写流程
1）客户端跟namenode通信请求上传文件，namenode检查目标文件是否已存在，父目录是否存在，用户是否有权限等
2）namenode返回是否可以上传
3）client请求第一个 block该传输到哪些datanode服务器上
4）namenode返回3个datanode服务器ABC
5）client请求3台dn中的一台A上传数据（本质上是一个RPC调用，建立pipeline），A收到请求会继续调用B，然后B调用C，将整个pipeline建立完成，逐级返回客户端
6）client开始往A上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位，A收到一个packet就会传给B，B传给C；A每传一个packet会放入一个应答队列等待应答
7）当一个block传输完成之后，client再次请求namenode上传第二个block的服务器。

2.hdfs读流程
1）client跟namenode通信查询元数据，namenode通过查询元数据，找到文件块所在的datanode服务器
2）挑选一台datanode（就近原则，然后随机）服务器，请求建立socket流
3）datanode开始发送数据（从磁盘里面读取数据放入流，以packet为单位来做校验，大小为64k）
4）客户端以packet为单位接收，现在本地缓存，然后写入目标文件
HDFS读写流程

3.hdfs的体系结构
hdfs有namenode、secondraynamenode、datanode组成。为n+1模式
NameNode负责管理和记录整个文件系统的元数据
DataNode负责管理用户的文件数据块，文件会按照固定的大小（blocksize）切成若干块后分布式存储在若干台datanode上，每一个文件块可以有多个副本，并存放在不同的datanode上，
Datanode会定期向Namenode汇报自身所保存的文件block信息，而namenode则会负责保持文件的副本数量
HDFS的内部工作机制对客户端保持透明，客户端请求访问HDFS都是通过向namenode申请来进行
secondraynamenode负责合并日志

4.一个datanode 宕机,怎么一个流程恢复
Datanode宕机了后，如果是短暂的宕机，可以实现写好脚本监控，将它启动起来。如果是长时间宕机了，那么datanode上的数据应该已经被备份到其他机器了，
那这台datanode就是一台新的datanode了，删除他的所有数据文件和状态文件，重新启动。
 
5.hadoop 的 namenode 宕机,怎么解决
先分析宕机后的损失，宕机后直接导致client无法访问，内存中的元数据丢失，但是硬盘中的元数据应该还存在，如果只是节点挂了，重启即可，
如果是机器挂了，重启机器后看节点是否能重启，不能重启就要找到原因修复了。但是最终的解决方案应该是在设计集群的初期就考虑到这个问题，做namenode的HA。
 
6.namenode对元数据的管理
namenode对数据的管理采用了三种存储形式：
内存元数据(NameSystem)
磁盘元数据镜像文件(fsimage镜像)
数据操作日志文件（可通过日志运算出元数据）(edit日志文件)


7.元数据的checkpoint
每隔一段时间，会由secondary namenode将namenode上积累的所有edits和一个最新的fsimage下载到本地，并加载到内存进行merge（这个过程称为checkpoint）
namenode和secondary namenode的工作目录存储结构完全相同，所以，当namenode故障退出需要重新恢复时，可以从secondary namenode的工作目录中将fsimage拷贝到namenode的工作目录，以恢复namenode的元数据

8.yarn资源调度流程 
1）用户向YARN 中提交应用程序， 其中包括ApplicationMaster 程序、启动ApplicationMaster 的命令、用户程序等。
2）ResourceManager 为该应用程序分配第一个Container， 并与对应的NodeManager 通信，要求它在这个Container 中启动应用程序的ApplicationMaster。
3）ApplicationMaster 首先向ResourceManager 注册， 这样用户可以直接通过ResourceManage 查看应用程序的运行状态，然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束，即重复步骤4~7。
4）ApplicationMaster 采用轮询的方式通过RPC 协议向ResourceManager 申请和领取资源。
5）一旦ApplicationMaster 申请到资源后，便与对应的NodeManager 通信，要求它启动任务。
6）NodeManager 为任务设置好运行环境（包括环境变量、JAR 包、二进制程序等）后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务。
7）各个任务通过某个RPC 协议向ApplicationMaster 汇报自己的状态和进度，以让ApplicationMaster 随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。在应用程序运行过程中，用户可随时通过RPC 向ApplicationMaster 查询应用程序的当前运行状态。
8）应用程序运行完成后，ApplicationMaster 向ResourceManager 注销并关闭自己。

9.hadoop中combiner和partition的作用
combiner是发生在map的最后一个阶段，父类就是Reducer，意义就是对每一个maptask的输出进行局部汇总，以减小网络传输量，缓解网络传输瓶颈，提高reducer的执行效率。
partition的主要作用将map阶段产生的所有kv对分配给不同的reducer task处理，可以将reduce阶段的处理负载进行分摊

10.用mapreduce怎么处理数据倾斜问题？
/reduce程序执行时，reduce节点大部分执行完毕，但是有一个或者几个reduce节点运行很慢，导致整个程序的处理时间很长，这是因为某一个key的条数比其他key多很多（有时是百倍或者千倍之多），
这条key所在的reduce节点所处理的数据量比其他节点就大很多，从而导致某几个节点迟迟运行不完，此称之为数据倾斜。
（1）局部聚合加全局聚合。
第一次在 map 阶段对那些导致了数据倾斜的 key 加上 1 到 n 的随机前缀，这样本来相
同的 key 也会被分到多个 Reducer 中进行局部聚合，数量就会大大降低。
第二次 mapreduce，去掉 key 的随机前缀，进行全局聚合。
思想：二次 mr，第一次将 key 随机散列到不同 reducer 进行处理达到负载均衡目的。第
二次再根据去掉 key 的随机前缀，按原 key 进行 reduce 处理。
这个方法进行两次 mapreduce，性能稍差。
（2）增加 Reducer，提升并行度
JobConf.setNumReduceTasks(int)
（3）实现自定义分区
根据数据分布情况，自定义散列函数，将 key 均匀分配到不同 Reducer


11.shuffle 阶段,你怎么理解的
shuffle过程包括在Map和Reduce两端中。 
在Map端的shuffle过程是对Map的结果进行分区（partition）、排序（sort）和分割（spill），然后将属于同一个划分的输出合并在一起
（merge）并写在硬盘上，同时按照不同的划分将结果发送给对应的Reduce（Map输出的划分与Reduce的对应关系由JobTracker确定）。
Reduce端又会将各个Map送来的属于同一个划分的输出进行合并（merge），然后对merge的结果进行排序，最后交给Reduce处理。通俗的讲，就是对Map输出结果先进行分区（partition），如“aaa”经过Partitioner后返回0，也就是这对值应当交由第一个reducer来处理。接下来，
需要将数据写入内存缓冲区中，缓冲区的作用是批量收集map结果，减少磁盘IO的影响。我们的key/value对以及Partition的结果都会被写
入缓冲区。当然写入之前，key与value值都会被序列化成字节数组。这个内存缓冲区是有大小限制的，默认是100MB。当map task的输出结果
很多时，需要在一定条件下将缓冲区中的数据临时写入磁盘，然后重新利用这块缓冲区。这个从内存往磁盘写数据的过程被称为Spill。
Spill可以认为是一个包括Sort和Combiner（Combiner是可选的，用户如果定义就有）的过程。先进行sort可以把缓冲区中一段范围key的数据排在一起，（如果数据多的时候，多次刷新往内存缓冲区中写入的数据可能会有属于相同范围的key，也就是说，多个spill文件中可能会
有统一范围的key，这就是需要下面Map端merge的原因），这里有点绕，具体的介绍可以看下面的详细过程，执行过sort之后，如果用户定义了combiner就会执行combine，然后执行merge操作，接着就是Reduce端。

12.Mapreduce 的 map 数量 和 reduce 数量是由什么决定的 ,怎么配置？
map的数量由输入切片的数量决定，128M切分一个切片，只要是文件也分为一个切片，有多少个切片就有多少个map Task。
reduce数量自己配置。

13.MapReduce优化经验
设置合理的map和reduce的个数。合理设置blocksize
避免出现数据倾斜
combine函数
对数据进行压缩
小文件处理优化：事先合并成大文件，combineTextInputformat，在hdfs上用mapreduce将小文件合并成SequenceFile大文件（key:文件名，value：文件内容）
参数优化

14.分别举例什么情况要使用 combiner，什么情况不使用？
求平均数的时候就不需要用combiner，因为不会减少reduce执行数量。在其他的时候，可以依据情况，使用combiner，来减少map的输出数量，
减少拷贝到reduce的文件，从而减轻reduce的压力，节省网络开销，提升执行效率

15.MR运行流程解析
1）一个mr程序启动的时候，最先启动的是MRAppMaster，MRAppMaster启动后根据本次job的描述信息，计算出需要的maptask实例数量，然后向集群申请机器启动相应数量的maptask进程
2）maptask进程启动之后，根据给定的数据切片范围进行数据处理，主体流程为：
利用客户指定的inputformat来获取RecordReader读取数据，形成输入KV对
将输入KV对传递给客户定义的map()方法，做逻辑运算，并将map()方法输出的KV对收集到缓存
将缓存中的KV对按照K分区排序后不断溢写到磁盘文件
3）MRAppMaster监控到所有maptask进程任务完成之后，会根据客户指定的参数启动相应数量的reducetask进程，并告知reducetask进程要处理的数据范围（数据分区）
4）Reducetask进程启动之后，根据MRAppMaster告知的待处理数据所在位置，从若干台maptask运行所在机器上获取到若干个maptask输出结果文件，并在本地进行重新归并排序，
然后按照相同key的KV为一个组，调用客户定义的reduce()方法进行逻辑运算，并收集运算输出的结果KV，然后调用客户指定的outputformat将结果数据输出到外部存储

16.简单描述一下HDFS的系统架构，怎么保证数据安全?
存储在HDFS系统上的文件，会分割成128M大小的block存储在不同的节点上，block的副本数默认3份，也可配置成更多份；
第一个副本一般放置在与client（客户端）所在的同一节点上（若客户端无datanode，则随机放），第二个副本放置到与第一个副本同一机架的不同节点，第三个副本放到不同机架的datanode节点，当取用时遵循就近原则；
datanode已block为单位，每3s报告心跳状态，做10min内不报告心跳状态则namenode认为block已死掉，namonode会把其上面的数据备份到其他一个datanode节点上，保证数据的副本数量；
datanode会默认每小时把自己节点上的所有块状态信息报告给namenode；
采用safemode模式：datanode会周期性的报告block信息。Namenode会计算block的损坏率，当阀值<0.999f时系统会进入安全模式，HDFS只读不写。HDFS元数据采用secondaryname备份或者HA备份
 
17.在通过客户端向hdfs中写数据的时候，如果某一台机器宕机了，会怎么处理
在写入的时候不会重新重新分配datanode。如果写入时，一个datanode挂掉，会将已经写入的数据放置到queue的顶部，并将挂掉的datanode移出pipline，将数据写入到剩余的datanode，在写入结束后， namenode会收集datanode的信息，发现此文件的replication没有达到配置的要求（default=3）,然后寻找一个datanode保存副本。

18.Hadoop优化有哪些方面
（0）HDFS 小文件影响
1）影响 NameNode 的寿命，因为文件元数据存储在 NameNode 的内存中
2）影响计算引擎的任务数量，比如每个小的文件都会生成一个 Map 任务
（1）数据输入小文件处理：
1）合并小文件：对小文件进行归档（Har）、自定义 Inputformat 将小文件存储成SequenceFile 文件。
2）采用 ConbinFileInputFormat 来作为输入，解决输入端大量小文件场景。
3）对于大量小文件 Job，可以开启 JVM 重用。
（2）Map 阶段
1）增大环形缓冲区大小。由 100m 扩大到 200m
2）增大环形缓冲区溢写的比例。由 80%扩大到 90%
3）减少对溢写文件的 merge 次数。（10 个文件，一次 20 个 merge）
4）不影响实际业务的前提下，采用 Combiner 提前合并，减少 I/O。
（3）Reduce 阶段
1）合理设置 Map 和 Reduce 数：两个都不能设置太少，也不能设置太多。太少，会导致 Task 等待，延长处理时间；太多，会导致 Map、Reduce 任务间竞争资源，造成处理超时等错误。
2）设置 Map、Reduce 共存：调整 slowstart.completedmaps 参数，使 Map 运行到一定程度后，Reduce 也开始运行，减少 Reduce 的等待时间。
3）规避使用 Reduce，因为 Reduce 在用于连接数据集的时候将会产生大量的网络消耗。
4）增加每个 Reduce 去 Map 中拿数据的并行数
5）集群性能可以的前提下，增大 Reduce 端存储数据内存的大小。
（4）IO 传输
1）采用数据压缩的方式，减少网络 IO 的的时间。安装 Snappy 和 LZOP 压缩编码器。
2）使用 SequenceFile 二进制文件
（5）整体
1）MapTask 默认内存大小为 1G，可以增加 MapTask 内存大小为 4-5g
2）ReduceTask 默认内存大小为 1G，可以增加 ReduceTask 内存大小为 4-5g
3）可以增加 MapTask 的 cpu 核数，增加 ReduceTask 的 CPU 核数
4）增加每个 Container 的 CPU 核数和内存大小
5）调整每个 Map Task 和 Reduce Task 最大重试次数
 
19.大量数据求topN(写出mapreduce的实现思路）
高效topN实现思路如下 :
我们将整个电影Bean放在Map的key的位置, 在MR内部是默认按照Key进行排序 , Key分区 , Key分组的!所以如果我们将Bean放在KEY的位置需要做一下三件事
自定义的类要序列化和可排序 实现接口  WritableComparable
自定义分区器 , 按照自定义Bean的执行的属性分区 , 按照电影Id分区,保证同一部电影被同一个ReduceTask处理
自定义分区器 , 保证同一部电影分配到同一个迭代器中聚合操作

20.列出正常工作的hadoop集群中hadoop都分别启动哪些进程以及他们的作用
1）.NameNode它是hadoop中的主服务器，管理文件系统名称空间和对集群中存储的文件的访问，保存有metadate。
2）.SecondaryNameNode它不是namenode的冗余守护进程，而是提供周期检查点和清理任务。帮助NN合并editslog，减少NN启动时间。
3）.DataNode它负责管理连接到节点的存储（一个集群中可以有多个节点）。每个存储数据的节点运行一个datanode守护进程。
4）.ResourceManager（JobTracker）JobTracker负责调度DataNode上的工作。每个DataNode有一个TaskTracker，它们执行实际工作。
5）.NodeManager（TaskTracker）执行任务
6）.DFSZKFailoverController高可用时它负责监控NN的状态，并及时的把状态信息写入ZK。它通过一个独立线程周期性的调用NN上的一个特定接口来获取NN的健康状态。FC也有选择谁作为Active NN的权利，因为最多只有两个节点，目前选择策略还比较简单（先到先得，轮换）。
7）.JournalNode 高可用情况下存放namenode的editlog文件.

21.Hadoop总job和Tasks之间的区别是什么？
Job是我们对一个完整的mapreduce程序的抽象封装
Task是job运行时，每一个处理阶段的具体实例，如map task，reduce task，maptask和reduce task都会有多个并发运行的实例

22.Hadoop高可用HA模式
HDFS高可用原理：
Hadoop HA（High Available）通过同时配置两个处于Active/Passive模式的Namenode来解决上述问题，状态分别是Active和Standby. Standby Namenode作为热备份，从而允许在机器发生故障时能够快速进行故障转移，同时在日常维护的时候使用优雅的方式进行Namenode切换。Namenode只能配置一主一备，不能多于两个Namenode。
主Namenode处理所有的操作请求（读写），而Standby只是作为slave，维护尽可能同步的状态，使得故障时能够快速切换到Standby。为了使Standby Namenode与Active Namenode数据保持同步，两个Namenode都与一组Journal Node进行通信。当主Namenode进行任务的namespace操作时，都会确保持久会修改日志到Journal Node节点中。Standby Namenode持续监控这些edit，当监测到变化时，将这些修改同步到自己的namespace。
当进行故障转移时，Standby在成为Active Namenode之前，会确保自己已经读取了Journal Node中的所有edit日志，从而保持数据状态与故障发生前一致。
为了确保故障转移能够快速完成，Standby Namenode需要维护最新的Block位置信息，即每个Block副本存放在集群中的哪些节点上。为了达到这一点，Datanode同时配置主备两个Namenode，并同时发送Block报告和心跳到两台Namenode。
确保任何时刻只有一个Namenode处于Active状态非常重要，否则可能出现数据丢失或者数据损坏。当两台Namenode都认为自己的Active Namenode时，会同时尝试写入数据（不会再去检测和同步数据）。为了防止这种脑裂现象，Journal Nodes只允许一个Namenode写入数据，内部通过维护epoch数来控制，从而安全地进行故障转移。

23.简要描述安装配置一个hadoop集群的步骤
使用root账户登录。
修改IP。
修改Host主机名。
配置SSH免密码登录。
关闭防火墙。
安装JDK。
上传解压Hadoop安装包。
配置Hadoop的核心配置文件hadoop-evn.sh，core-site.xml，mapred-site.xml，hdfs-site.xml，yarn-site.xml
配置hadoop环境变量
格式化hdfs # bin/hadoop  namenode  -format
启动节点start-all.sh

24.fsimage和edit的区别
fsimage：filesystem image 的简写，文件镜像。
客户端修改文件时候，先更新内存中的metadata信息,只有当对文件操作成功的时候，才会写到editlog。
fsimage是文件meta信息的持久化的检查点。secondary namenode会定期的将fsimage和editlog合并dump成新的fsimage

25.yarn的三大调度策略
1）FIFO Scheduler把应用按提交的顺序排成一个队列，这是一个先进先出队列，在进行资源分配的时候，先给队列中最头上的应用进行分配资源，待最头上的应用需求满足后再给下一个分配，以此类推。
2）Capacity（容量）调度器，有一个专门的队列用来运行小任务，但是为小任务专门设置一个队列会预先占用一定的集群资源，这就导致大任务的执行时间会落后于使用FIFO调度器时的时间。
3）在Fair（公平）调度器中，我们不需要预先占用一定的系统资源，Fair调度器会为所有运行的job动态的调整系统资源。当第一个大job提交时，只有这一个job在运行，此时它获得了所有集群资源；当第二个小任务提交后，Fair调度器会分配一半资源给这个小任务，让这两个任务公平的共享集群资源。
  需要注意的是，在下图Fair调度器中，从第二个任务提交到获得资源会有一定的延迟，因为它需要等待第一个任务释放占用的Container。小任务执行完成之后也会释放自己占用的资源，大任务又获得了全部的系统资源。最终的效果就是Fair调度器即得到了高的资源利用率又能保证小任务及时完成。

26.hadoop的shell命令用的多吗?,说出一些常用的
-ls
-put 
-get
-getmerge
-mkdir
-rm

27.用mr实现用户pv的top10？
map输入数据，将数据转换成（用户，访问次数）的键值对，然后reduce端实现聚合，并且将结果写入用户、访问次数的实体类，并且实现排序，最后的结果做一个top10的筛选
---------------------------------------------------------------------------------------------------------------
------------------------------------------hadoop basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------hbase basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------

一、基础知识
1 HBase简介
HBase 是 BigTable 的开源（源码使用 Java 编写）版本。是 Apache Hadoop 的数据库，是建 立在 HDFS 之上，被设计用来提供高可靠性、高性能、列存储、可伸缩、多版本的 NoSQL 的分布式数据存储系统，实现对大型数据的实时、随机的读写访问。
HBase 依赖于 HDFS 做底层的数据存储，BigTable依赖 Google GFS 做数据存储
HBase 依赖于 MapReduce 做数据计算，BigTabl依赖 Google MapReduce 做数据计算
HBase 依赖于 ZooKeeper 做服务协调，BigTable 依赖 Google Chubby 做服务协调
NoSQL = NO SQL
NoSQL = Not Only SQL：会有一些把 NoSQL 数据的原生查询语句封装成 SQL，比如 HBase 就有 Phoenix 工具

存在亿万条记录的数据库，只有千万或者百万条记录使用RDBMS更加合适确保你的应用不需要使用RDBMS的高级特性（第二索引，事务机制，高级查询语言等）足够的硬件配置，即节点数，HDFS在少于5个节点时并不会表现得很好，HBase也存在相同情况。

2 HBase这个NoSQL 数据库的要点
① 它介于 NoSQL 和 RDBMS 之间，仅能通过主键(rowkey)和主键的 range 来检索数据
② HBase 查询数据功能很简单，不支持 join 等复杂操作
③ 不支持复杂的事务，只支持行级事务(可通过 hive 支持来实现多表 join 等复杂操作)。
④ HBase 中支持的数据类型：byte[]（底层所有数据的存储都是字节数组）
⑤ 主要用来存储结构化和半结构化的松散数据。

3 结构化、半结构化和非结构化
（1）结构化：数据结构字段含义确定，清晰，典型的如数据库中的表结构
（2）半结构化：具有一定结构，但语义不够确定，典型的如 HTML 网页，有些字段是确定的(title)， 有些不确定(table)
（3）非结构化：杂乱无章的数据，很难按照一个概念去进行抽取，无规律性.与 Hadoop 一样，HBase 目标主要依靠横向扩展，通过不断增加廉价的商用服务器，来增加 计算和存储能力。
	
4 HBase 中的表特点
1）、大：一个表可以有上十亿行，上百万列
2）、面向列：面向列(族)的存储和权限控制，列(簇)独立检索。
3）、稀疏：对于为空(null)的列，并不占用存储空间，因此，表可以设计的非常稀疏。
4）、无模式：每行都有一个可排序的主键和任意多的列，列可以根据需要动态的增加，同一 张表中不同的行可以有截然不同的列

5 HBase表结构逻辑视图
（1）Rowkey的概念
Rowkey的概念和mysql中的主键是完全一样的，Hbase使用Rowkey来唯一的区分某一行的数据。
由于Hbase只支持3中查询方式：
1）、基于Rowkey的单行查询
2）、基于Rowkey的范围扫描
3）、全表扫描
因此，Rowkey对Hbase的性能影响非常大，Rowkey的设计就显得尤为的重要。设计的时候要兼顾基于Rowkey的单行查询也要键入Rowkey的范围扫描。具体Rowkey要如何设计后续会整理相关的文章做进一步的描述。这里大家只要有一个概念就是Rowkey的设计极为重要。
rowkey 行键可以是任意字符串(最大长度是 64KB，实际应用中长度一般为 10-100bytes)，最好是 16。在 HBase 内部，rowkey 保存为字节数组。HBase 会对表中的数据按照 rowkey 排序 (字典顺序)
（2）Column的概念
列，可理解成MySQL列。
（3）ColumnFamily的概念
列族, HBase引入的概念。
Hbase通过列族划分数据的存储，列族下面可以包含任意多的列，实现灵活的数据存取。就像是家族的概念，我们知道一个家族是由于很多个的家庭组成的。列族也类似，列族是由一个一个的列组成（任意多）
Hbase表的创建的时候就必须指定列族。就像关系型数据库创建的时候必须指定具体的列是一样的。
Hbase的列族不是越多越好，官方推荐的是列族最好小于或者等于3。我们使用的场景一般是1个列族。
（4）TimeStamp的概念
TimeStamp对Hbase来说至关重要，因为它是实现Hbase多版本的关键。在Hbase中使用不同的timestame来标识相同rowkey行对应的不通版本的数据。HBase 中通过 rowkey 和 columns 确定的为一个存储单元称为 cell。每个 cell 都保存着同一份 数据的多个版本。版本通过时间戳来索引。时间戳的类型是 64 位整型。时间戳可以由 hbase(在数据写入时自动)赋值，此时时间戳是精确到毫秒的当前系统时间。时间戳也可以由 客户显式赋值。如果应用程序要避免数据版本冲突，就必须自己生成具有唯一性的时间戳。 每个 cell 中，不同版本的数据按照时间
倒序排序，即最新的数据排在最前面。为了避免数据存在过多版本造成的的管理 (包括存贮和索引)负担，hbase 提供了两种数据版 本回收方式：
@保存数据的最后 n 个版本
@保存最近一段时间内的版本（设置数据的生命周期 TTL）。
用户可以针对每个列簇进行设置。 
（5）单元格（Cell）
由{rowkey, column( = + ), version} 唯一确定的单元。 Cell 中的数据是没有类型的，全部是字节码形式存贮。

6 HBase体系架构
（1）Client
包含访问HBase的接口并维护cache来加快HBase的访问
（2）Zookeeper
@保证任何时候， 集群中只有一个master.体现了服务高可用， 一旦挂了一个，将会启动一个。
@存保证集群中有且只有一个HMaster为Active
@存储hbase:meta，即所有Region的位置信息
@存储HBase中表格的元数据信息
@监控RegionServer状态，将RS的上下线情况汇报给HMaster
@ZooKeeper集群本身使用一致性协议(PAXOS协议)保证每个节点状态的一致性
（3）HMaster,表的元数据信息都存在Zookeeper， HMaster相当于一个领导
为RegionServer分配Region
新来的一个Region，我要将他放在哪个Region
负责RegionServer的负载均衡
当创建一个表，生成一个Region， 持续向表中插入数据，达到了阈值， 将分裂成2个Region, 数据再增加，将会分裂成3、4、…100个。不能让这100个Region在这一个HRegionServer, 而其他RegionServer中没有Region, 为了数据均衡， 将部分Region迁移到其他的HRegionServer.相当于工作的分配，一个员工的工作过多，将分配她的任务给其他人。
发现失效的RegionServer并重新分配其上的Region
管理用户对table的增删操作
（4）HRegionServer
响应client的读写请求，进行I/O操作（直接绕过HMaster）
与HDFS交互，管理table数据
当Region的大小到达阀值时切分Region
维护Region,处理对这些Region的IO请求
负责切分在运行过程中变的过大的Region
当RegionServer中的Region过多，HMaster将会做一个负载均衡。


7 HBase的数据模型
（1）Region
当创建一个表，生成一个Region， 持续向表中插入数据，达到了阈值， 将分裂成2个Region, 数据再增加，将会分裂成3、4、…100个。
当表中的行不断增多，就会有越来越多的Region，在HMaster的调度写，使一个表被保存在多个RegionServer上。
（2）Memstore与storefile
一个Region由多个store组成，一个store对应一个CF(列族)
store包括位于内存中的memstore和位于磁盘中的storefile.写操作：先写入memstore,但memstore中的数据达到阈值， HRegionServer会启动flashcache进程系写入storefile, 每次写入形成一个单独的storefile。
当storefile文件增长到一定阈值后， 系统会进行合并（minor,majar compcation）, 在合并中进行版本合并和删除工作（majar）,形成更大的storefile.
当一个Region所有的storefile的大小和超过一个阈值后， 会把当前的Region分割成两个，并通过HMaster的调度， 分配到相应的HRegionServer中， 实现负载均衡。
客户端检索数据，现在memstore找， 找不到载找storefile.
（3）storefile 以HFile格式保存在HDFS上。
（4）Hlog也是存在HDFS上。


8 存储结构
（1）在HBase中创建的一张表可以分布在多个Hregion，也就说一张表可以被拆分成多块，每一块称我们呼为一个Hregion。每个Hregion会保 存一个表里面某段连续的数据，用户创建的那个大表中的每个Hregion块是由Hregion服务器提供维护，访问Hregion块是要通过 Hregion服务器，而一个Hregion块对应一个Hregion服务器，一张完整的表可以保存在多个Hregion 上。HRegion Server 与Region的对应关系是一对多的关系。每一个HRegion在物理上会被分为三个部分：Hmemcache(缓存)、Hlog(日志)、HStore(持久层)。
上述这些关系在我脑海中的样子，如图所示：
（2）HRegionServer、HRegion、Hmemcache、Hlog、HStore之间的关系，如图所示：
（3）HBase表中的数据与HRegionServer的分布关系，如图所示：
（4）HBase读数据
HBase读取数据优先读取HMemcache中的内容，如果未取到再去读取Hstore中的数据，提高数据读取的性能。
1、客户端通过 ZooKeeper 以及-ROOT-表和.META.表找到目标数据所在的 RegionServer(就是 数据所在的 Region 的主机地址) 
2、联系 RegionServer 查询目标数据 
3、RegionServer 定位到目标数据所在的 Region，发出查询请求 
4、Region 先在 Memstore 中查找，命中则返回 
5、如果在 Memstore 中找不到，则在 Storefile 中扫描 为了能快速的判断要查询的数据在不在这个 StoreFile 中，应用了 BloomFilter
（5）HBase写数据
HBase写入数据会写到HMemcache和Hlog中，HMemcache建立缓存，Hlog同步Hmemcache和Hstore的事务日志，发起Flush Cache时，数据持久化到Hstore中，并清空HMemecache。
1、Client 先根据 RowKey 找到对应的 Region 所在的 RegionServer 
2、Client 向 RegionServer 提交写请求 
3、RegionServer 找到目标 Region 
4、Region 检查数据是否与 Schema 一致 
5、如果客户端没有指定版本，则获取当前系统时间作为数据版本 
6、将更新写入 WAL Log 
7、将更新写入 Memstore 
8、判断 Memstore 的是否需要 flush 为 StoreFile 文件。
（6）客户端访问这些数据的时候通过Hmaster ，每个 Hregion 服务器都会和Hmaster 服务器保持一个长连接，Hmaster 是HBase分布式系统中的管理者，他的主要任务就是要告诉每个Hregion 服务器它要维护哪些Hregion。用户的这些都数据可以保存在Hadoop 分布式文件系统上。 如果主服务器Hmaster死机，那么整个系统都会无效。下面我会考虑如何解决Hmaster的SPFO的问题，这个问题有点类似Hadoop的SPFO 问题一样只有一个NameNode维护全局的DataNode，HDFS一旦死机全部挂了，也有人说采用Heartbeat来解决这个问题，但我总想找出 其他的解决方案，多点时间，总有办法的。
假如系统中有一个User表，如果按照传统的RDBMS的话，User表中的列是固定的，比如schema 定义了name,age,sex等属性，User的属性是不能动态增加的。但是如果采用列存储系统，比如Hbase，那么我们可以定义User表，然后定义info 列族，User的数据可以分为：info:name = zhangsan,info:age=30,info:sex=male等，如果后来你又想增加另外的属性，这样很方便只需要info:newProperty就可以了。

9 物理存储
1）、Table 中的所有行都按照 RowKsey 的字典序排列。
2）、Table 在行的方向上分割为多个 HRegion。
3）、HRegion 按大小分割的(默认 10G)，每个表一开始只有一个 HRegion，随着数据不断插入 表，HRegion 不断增大，当增大到一个阀值的时候，HRegion 就会等分会两个新的 HRegion。 当表中的行不断增多，就会有越来越多的 HRegion。
4）、HRegion 是 Hbase 中分布式存储和负载均衡的最小单元。最小单元就表示不同的 HRegion 可以分布在不同的 HRegionserver 上。但一个 HRegion 是不会拆分到多个 server 上的。
5）、HRegion 虽然是负载均衡的最小单元，但并不是物理存储的最小单元。事实上，HRegion 由一个或者多个 Store 组成，每个 Store 保存一个 Column Family。每个 Strore 又由一个 memStore 和 0 至多个 StoreFile 组成

10 Region 寻址机制
既然读写都在 RegionServer 上发生，我们前面有讲到，每个 RegionSever 为一定数量的 Region 服务，那么 Client 要对某一行数据做读写的时候如何能知道具体要去访问哪个 RegionServer 呢？那就是接下来我们要讨论的问题
（1）老的 Region 寻址方式
第 1 步：Client 请求 ZooKeeper 获得-ROOT-所在的 RegionServer 地址
第 2 步：Client 请求-ROOT-所在的 RS 地址，获取.META.表的地址，Client 会将-ROOT-的相关 信息 cache 下来，以便下一次快速访问 
第 3 步：Client 请求.META.表的 RegionServer 地址，获取访问数据所在 RegionServer 的地址， Client 会将.META.的相关信息 cache 下来，以便下一次快速访问
第 4 步：Client 请求访问数据所在 RegionServer 的地址，获取对应的数据
从上面的路径我们可以看出，用户需要 3 次请求才能直到用户 Table 真正的位置，这在一定 程序带来了性能的下降。在 0.96 之前使用 3 层设计的主要原因是考虑到元数据可能需要很 大。但是真正集群运行，元数据的大小其实很容易计算出来。在 BigTable 的论文中，每行 METADATA 数据存储大小为 1KB 左右，如果按照一个 Region 为 128M 的计算，3 层设计可以支持的 Region 个数为 2^34 个，采用 2 层设计可以支持 2^17（131072）。那么 2 层设计的情 况下一个集群可以存储 4P 的数据。这仅仅是一个 Region 只有 128M 的情况下。如果是 10G 呢? 因此，通过计算，其实 2 层设计就可以满足集群的需求。因此在 0.96 版本以后就去掉 了-ROOT-表了。

（2）新的 Region 寻址方式
第 1 步：Client 请求 ZooKeeper 获取.META.所在的 RegionServer 的地址。
第 2 步：Client 请求.META.所在的 RegionServer 获取访问数据所在的 RegionServer 地址，Client 会将.META.的相关信息 cache 下来，以便下一次快速访问。
第 3 步：Client 请求数据所在的 RegionServer，获取所需要的数据。
总结去掉-ROOT-的原因有如下 2 点：
　　其一：提高性能
　　其二：2 层结构已经足以满足集群的需求

	
11 RegionServer 工作机制
（1）Region 分配
任何时刻，一个 Region 只能分配给一个 RegionServer。master 记录了当前有哪些可用的 RegionServer。以及当前哪些 Region 分配给了哪些 RegionServer，哪些 Region 还没有分配。 当需要分配的新的 Region，并且有一个 RegionServer 上有可用空间时，Master 就给这个 RegionServer 发送一个装载请求，把 Region 分配给这个 RegionServer。RegionServer 得到请 求后，就开始对此 Region 提供服务。
（2）RegionServer 上线
Master 使用 zookeeper 来跟踪 RegionServer 状态。当某个 RegionServer 启动时，会首先在 ZooKeeper 上的 server 目录下建立代表自己的 znode。由于 Master 订阅了 server 目录上的变 更消息，当 server 目录下的文件出现新增或删除操作时，Master 可以得到来自 ZooKeeper 的实时通知。因此一旦 RegionServer 上线，Master 能马上得到消息。
（3）RegionServer 下线
当 RegionServer 下线时，它和 zookeeper 的会话断开，ZooKeeper 而自动释放代表这台 server 的文件上的独占锁。Master 就可以确定：
1、RegionServer 和 ZooKeeper 之间的网络断开了。
2、RegionServer 挂了。
无论种情况，RegionServer都无法继续为它的Region提供服务了，此时Master会删除server 目录下代表这台 RegionServer 的 znode 数据，并将这台 RegionServer 的 Region 分配给其它还 活着的同志。

12 Master 工作机制
（1）Master 上线
Master 启动进行以下步骤:
1）从 ZooKeeper 上获取唯一一个代表 Active Master 的锁，用来阻止其它 Master 成为 Master。
2）扫描 ZooKeeper 上的 server 父节点，获得当前可用的 RegionServer 列表。
3）和每个 RegionServer 通信，获得当前已分配的 Region 和 RegionServer 的对应关系。
4）扫描.META. Region 的集合，计算得到当前还未分配的 Region，将他们放入待分配 Region 列表。
（2）Master 下线
由于 Master 只维护表和 Region 的元数据，而不参与表数据 IO 的过程，Master 下线仅 导致所有元数据的修改被冻结(无法创建删除表，无法修改表的 schema，无法进行 Region 的负载均衡，无法处理 Region 上下线，无法进行 Region 的合并，唯一例外的是 Region 的 split 可以正常进行，因为只有 RegionServer 参与)，表的数据读写还可以正常进行。因此 Master 下线短时间内对整个 hbase 集群没有影响。从上线过程可以看到，Master 保存的信息全是可以冗余信息（都可以从系统其它地方 收集到或者计算出来）。因此，一般 HBase 集群中总是有一个 Master 在提供服务，还有一个以上的 Master 在等 待时机抢占它的位置。


二、ms相关
1.Hbase调优
见《Hbase调优》

2.hbase的rowkey怎么创建好？列族怎么创建比较好？
HBase-Rowkey设计
一个列族在数据底层是一个文件，所以将经常一起查询的列放到一个列族中，列族尽量少，减少文件的寻址时间。

3.hbase过滤器实现用途
同《布隆过滤器》

4.HBase宕机如何处理
答：宕机分为HMaster宕机和HRegisoner宕机，如果是HRegisoner宕机，HMaster会将其所管理的region重新分布到其他活动的RegionServer上，由于数据和日志都持久在HDFS中，该操作不会导致数据丢失。所以数据的一致性和安全性是有保障的。
如果是HMaster宕机，HMaster没有单点问题，HBase中可以启动多个HMaster，通过Zookeeper的Master Election机制保证总有一个Master运行。即ZooKeeper会保证总会有一个HMaster在对外提供服务。

5.hive跟hbase的区别是？
1）定义
Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，默认情况下可以将sql语句转换为MapReduce任务进行运行
HBase是Hadoop的数据库，一个分布式、可扩展、大数据的存储
2）区别
HiveSql默认情况下会转换成MapReduce进行计算，所以比较慢，只能做离线数据分析，不能做实时查询
HBase是NoSql数据库，是物理表，不是逻辑表，虽然数据是存储在hdfs，但是读写速度非常快，适合做大数据量的即时查询
3）联系
这两种大数据框架在整个ETL过程中所处的位置及承载的作用是不一样的，一般来说，Hive清洗处理后的数据有可能会被写入HBase，供需求方实时查询，
所以很多时候，这两种框架是需要同时使用的，发挥各自的价值。如下图：
4）应用场景
Hive一般是做大数据量的离线数据分析，比如日志数据分析，但是不能做实时查询，因为需要很长时间才能返回结果。
HBase适合用来对数据量很大的明细数据进行实时查询,如订单数据，用户画像数据

6.hbase写流程
1/ 客户端要连接zookeeper, 从zk的/hbase节点找到hbase:meta表所在的regionserver（host:port）;
2/ regionserver扫描hbase:meta中的每个region的起始行健，对比r000001这条数据在那个region的范围内；
3/ 从对应的 info:server key中存储了region是有哪个regionserver(host:port)在负责的；
4/ 客户端直接请求对应的regionserver；
5/ regionserver接收到客户端发来的请求之后，就会将数据写入到region中

7.hbase读流程
1/ 首先Client连接zookeeper, 找到hbase:meta表所在的regionserver;
2/ 请求对应的regionserver，扫描hbase:meta表，根据namespace、表名和rowkey在meta表中找到r00001所在的region是由那个regionserver负责的；
3/找到这个region对应的regionserver
4/ regionserver收到了请求之后，扫描对应的region返回数据到Client
(先从MemStore找数据，如果没有，再到BlockCache里面读；BlockCache还没有，再到StoreFile上读(为了读取的效率)；
如果是从StoreFile里面读取的数据，不是直接返回给客户端，而是先写入BlockCache，再返回给客户端。)
 
8.hbase数据flush过程
1）当MemStore数据达到阈值（默认是128M，老版本是64M），将数据刷到硬盘，将内存中的数据删除，同时删除HLog中的历史数据；
2）并将数据存储到HDFS中；
3）在HLog中做标记点。

9.数据合并过程
当数据块达到4块，hmaster将数据块加载到本地，进行合并
当合并的数据超过256M，进行拆分，将拆分后的region分配给不同的hregionserver管理
当hregionser宕机后，将hregionserver上的hlog拆分，然后分配给不同的hregionserver加载，修改.META.
注意：hlog会同步到hdfs
 
10.Hmaster和Hgionserver职责
Hmaster
1）、管理用户对Table的增、删、改、查操作；
2）、记录region在哪台Hregion server上
3）、在Region Split后，负责新Region的分配；
4）、新机器加入时，管理HRegion Server的负载均衡，调整Region分布
5）、在HRegion Server宕机后，负责失效HRegion Server 上的Regions迁移。
Hgionserver
HRegion Server主要负责响应用户I/O请求，向HDFS文件系统中读写数据，是HBASE中最核心的模块。
HRegion Server管理了很多table的分区，也就是region。

11.HBase列族和region的关系？
HBase有多个RegionServer，每个RegionServer里有多个Region，一个Region中存放着若干行的行键以及所对应的数据，一个列族是一个文件夹，如果经常要搜索整个一条数据，
列族越少越好，如果只有一部分的数据需要经常被搜索，那么将经常搜索的建立一个列族，其他不常搜索的建立列族检索较快。

12.请简述Hbase的物理模型是什么
1）HRegion
HBase中表在行的方向上分割为多个Hregion。
HRegion按大小分割的，每个表一开始只有一个region，随着数据不断插入表，HRegion不断增大，当增大到一个阀值的时候，HRegion就会等分会两个新的HRegion，当table中的行不断增多，就会有越来越多的Hregion。
HRegion是HBase中分布式存储和负载均衡的最小单元。最小单元就表示不同的HRegion可以分布在不同的HRegion Server上,但一个HRegion是不会拆分到多个server上的。
HRegion虽然是分布式存储的最小单元，但并不是存储的最小单元。事实上，HRegion由一个或者多个Store组成，每个store保存一个columns family。每个Strore又由一个memStore和0至多个StoreFile组成。
2）HFile
StoreFile以HFile格式保存在HDFS上。HFile的格式为：
HFile分为六个部分：
Data Block段：保存表中的数据，这部分可以被压缩。
Meta Block段（可选的）：保存用户自定义的键值对，可以被压缩。
File Info段：Hfile的元信息，不被压缩，用户也可以在这一部分添加自己的元信息。
Data Block Index段：Data Block的索引，每条索引的key是被索引的Block的第一条记录的key。采用LRU机制淘汰。
Meta Block Index段（可选的）：Meta Block的索引。
Trailer段：这一段是定长的，保存了每一 段的偏移量。
读取一个HFile时，会首先读取Trailer，Trailer保存了每个段的起始位置（段的Magic Number用来做安全检查）；然后，Data Block Index会被读取到内存中，这样，当检索某个key时，不需要扫描整个HFile，而只需从内存中找到Key所在的Block，通过一次磁盘io将整个 Block读取到内存中，再找到所需要的key。
HFile的Data Block，Meta Block通常采用压缩方式存储，压缩之后可以大大减少网络IO和磁盘IO，相应的需要花费CPU进行压缩和解压缩。
目前HFile的压缩支持两种方式：Gzip、Lzo。
3）HLog(WAL log)
分布式系统环境中，无法避免系统出错或者宕机，因此一旦HRegionServer 意外退出，MemStore 中的内存数据将会丢失，这就需要引入HLog 了。

13.请问如果使用Hbase做即席查询，如何设计二级索引
1）为什么需要创建二级索引
HBase对于多条件组合查询这种应用场景是非常不占优势的，甚至可以说就是其短板，一般情况下，我们有两种方式查询Hbase中的数据
通过Rowkey查询数据，Rowkey里面会组合固定查询条件，但是需要把多组合查询的字段都拼接在Rowkey中，这是不可能的。
通过Scan全部扫描符合条件的数据，这样的效率是非常低的
所以这时候我们就需要用建立二级索引的方法来解决这个问题
2）二级索引原理
如上图所示，Hbase表中的字段为Rowkey，age，sex，username，phone，目前的需求是需要按照age，sex，username，phone随机组合查询符合条件的数据。
这时候我们就需要用ES来建立二级索引了，原始数据存在HBase中，索引存在ES中，如下图所示：
将原始数据存入HBase
将需要查询的条件字段及Rowkey存入ES
客户端发送请求会根据组合查询条件去ES中查找到对应的RowKey
ES返回RowKey给客户端
客户端根据ES返回的结果(RowKey)查询HBase数据
HBase返回符合条件的数据给客户端

14.如何避免读、写HBaes时访问热点问题？
（1）因为HBase中的行是按照Rowkey的字典顺序排序的，这种设计使得Scan操作更为方便，但是也容易出现热点问题。
热点问题是大量的客户端只访问集群的一个或少数节点，大量访问请求会使该台机器的负载很高，直接导致性能下降，甚至Region不可用，而集群的其他节点却处于相对空闲的状态。
（2）Rowkey设计原则
1）长度
Rowkey可以使任意字符串，最大长度64kb，建议越短越好，最好不要超过16个字节，原因如下:目前操作系统都是64位系统，内存8字节对齐，控制在16字节，8字节的整数倍利用了操作系统的最佳特性。
Hbase将部分数据加载到内存当中，如果Rowkey太长，内存的有效利用率就会下降。
2）唯一
Rowkey必须保证是唯一的，如果不唯一的话，同一版本同一个Rowkey插入Hbase中会更新之前的数据，与需求不符
3）散列
加盐：在Rowkey的前面增加随机数，散列之后的Rowkey就会根据随机生成的前缀分散到各个Region上，可以有效的避免热点问题。加盐这种方式增加了写的吞吐，但是使得读数据更加困难
Hash：Hash算法包含了MD5等算法，可以直接取Rowkey的MD5值作为Rowkey，或者取MD5值拼接原始Rowkey，组成新的rowkey，由于Rowkey设计不应该太长，所以可以对MD5值进行截取拼接
字符串反转：时间戳反转、手机号反转； 

15.布隆过滤器在HBASE中的应用
1）布隆过滤器
布隆是个人，发明了布隆算法，基于布隆算法实现的组件，称为布隆过滤器！这个组件一般是用作过滤！
过滤功能： 在海量数据中，用非常高的效率和性能，判断一个数据是否在集合中存在！
作用： 布隆过滤器只能判断一个数据要么一定在集合中不存在，要么在集合中可能存在！
误判： 布隆过滤器判断数据可能存在，实际扫描后，发现不存在，这种情况有存在的几率！
2）HBase支持两种布隆过滤器： ROW | ROWCOL
ROW: 布隆过滤器在计算时，使用每行的rowkey作为参数，进行判断！
举例：
info-----------info1
info storefile1: (r1,info:age,20) ,(r2,info:age,20)
info1 storefile2: (r3,info1:age,20) ,(r4,info1:age,20)
查询r1时，如果命中，判断storefile2中一定没有r1的数据，在storefile1中可能有！
ROWCOL: 布隆过滤器在计算时，使用每行的rowkey和column一起作为参数，进行判断！
举例：
info------------info1
info storefile1: (r1,info:age,20) ,(r2,info:age,20)
info1 storefile2: (r3,info1:age,20) ,(r4,info1:age,20)
查询rowkey=r1，只查info:age=20 列时，如果命中，判断storefile2中一定没有此数据，在storefile1中可能有！
3）注意：
旧版本，只有get操作，才会用到布隆过滤器，scan用不到！
1.x之后，scan也可用用布隆过滤器，稍微起点作用！
启用布隆过滤器后，会占用额外的内存，布隆过滤器通常是在blockcache和memstore中！
举例：
执行 get ‘t1’,‘r1’
①扫描r1所在region的所有列族的memstore，扫memstore时，先通过布隆过滤器判断r1是否存在，如果不存在，就不扫！可能存在，再扫描！
②扫描Storefile时，如果storefile中,r1所在的block已经缓存在blockcache中，直接扫blockcache，在扫描blockcache时，先使用布隆过滤器判断r1是否存在，如果不存在，就不扫！可能存在，再扫描！

16.Hbase是用来干嘛的?什么样的数据会放到hbase
1）定义
Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，默认情况下可以将sql语句转换为MapReduce任务进行运行
HBase是Hadoop的数据库，一个分布式、可扩展、大数据的存储
2）区别
HiveSql默认情况下会转换成MapReduce进行计算，所以比较慢，只能做离线数据分析，不能做实时查询
HBase是NoSql数据库，是物理表，不是逻辑表，虽然数据是存储在hdfs，但是读写速度非常快，适合做大数据量的即时查询
3）联系
这两种大数据框架在整个ETL过程中所处的位置及承载的作用是不一样的，一般来说，Hive清洗处理后的数据有可能会被写入HBase，供需求方实时查询，
所以很多时候，这两种框架是需要同时使用的，发挥各自的价值。如下图：
4）应用场景
Hive一般是做大数据量的离线数据分析，比如日志数据分析，但是不能做实时查询，因为需要很长时间才能返回结果。
HBase适合用来对数据量很大的明细数据进行实时查询,如订单数据，用户画像数据

17.HBase应该如何优化？
（1）HBase高可用
在HBase中Hmaster负责监控RegionServer的生命周期，均衡RegionServer的负载，如果Hmaster挂掉了，那么整个HBase集群将陷入不健康的状态，此时的工作状态并不会维持太久。所以需要配置hbase的高可用
（2）预分区
每一个region维护着startRow与endRowKey，如果加入的数据符合某个region维护的rowKey范围，则该数据交给这个region维护。那么依照这个原则，我们可以将数据所要投放的分区提前大致的规划好，以提高HBase性能。
1）手动设定预分区
hbase> create 'user','info','partition1',SPLITS => ['a','c','f','h']
2）生成16进制序列预分区
create 'user2','info','partition2',{NUMREGIONS => 15, SPLITALGO => 'HexStringSplit'}
3）按照文件中设置的规则预分区
创建splits.txt文件内容如下：
10
20
30
40
然后执行：
create 'user3','partition3',SPLITS_FILE => 'splits.txt'
4）
使用JavaAPI创建预分区
//自定义算法，产生一系列Hash散列值存储在二维数组中
byte[][] splitKeys = 某个散列值函数
//创建HBaseAdmin实例
HBaseAdmin hAdmin = new HBaseAdmin(HBaseConfiguration.create());
//创建HTableDescriptor实例
HTableDescriptor tableDesc = new HTableDescriptor(tableName);
//通过HTableDescriptor实例和散列值二维数组创建带有预分区的HBase表
hAdmin.createTable(tableDesc, splitKeys);
（3）优化rowkey设计(防止热点)
1）长度
Rowkey可以使任意字符串，最大长度64kb，建议越短越好，最好不要超过16个字节，原因如下:
目前操作系统都是64位系统，内存8字节对齐，控制在16字节，8字节的整数倍利用了操作系统的最佳特性。
Hbase将部分数据加载到内存当中，如果Rowkey太长，内存的有效利用率就会下降。
2）唯一
 Rowkey必须保证是唯一的，如果不唯一的话，同一版本同一个Rowkey插入Hbase中会更新之前的数据，与需求不符
3）散列
加盐：在Rowkey的前面增加随机数，散列之后的Rowkey就会根据随机生成的前缀分散到各个Region上，可以有效的避免热点问题 加盐这种方式增加了写的吞吐，但是使得读数据更加困难
Hash：Hash算法包含了MD5等算法，可以直接取Rowkey的MD5值作为Rowkey，或者取MD5值拼接原始Rowkey，组成新的rowkey，由于Rowkey设计不应该太长，所以可以对MD5值进行截取拼接
字符串反转：时间戳反转，手机号反转
（4）内存优化
HBase操作过程中需要大量的内存开销，毕竟Table是可以缓存在内存中的，一般会分配整个可用内存的70%给HBase的Java堆。
但是不建议分配非常大的堆内存，因为GC过程持续太久会导致RegionServer处于长期不可用状态，一般16~48G内存就可以了，如果因为框架占用内存过高导致系统内存不足，框架一样会被系统服务拖死。
（5）压缩
生产系统应使用其ColumnFamily定义进行压缩。
压缩会缩小磁盘上的数据。当它在内存中（例如，在MemStore中）或在线上（例如，在RegionServer和Client之间传输）时，它会膨胀。
因此，虽然使用ColumnFamily压缩是最佳做法，但它不会完全消除过大的Keys，过大的ColumnFamily名称或过大的列名称的影响。
（6）Column数控制
Hbase中的每个列，都归属于某个列簇，列簇是表的schema的一部分(列不是),必须在使用之前定义
HBase 目前对于两列族或三列族以上的任何项目都不太合适，因此请将模式中的列族数量保持在较低水平。
目前，flushing 和 compactions 是按照每个区域进行的，所以如果一个列族承载大量数据带来的 flushing，即使所携带的数据量很小，也会 flushing 相邻的列族。当许多列族存在时，flushing 和 compactions 相互作用可能会导致一堆不必要的 I/O（要通过更改 flushing 和 compactions 来针对每个列族进行处理）。
（7）开启布隆过滤器
当我们随机读get数据时，如果采用hbase的块索引机制，hbase会加载很多块文件。
采用布隆过滤器后，它能够准确判断该HFile的所有数据块中是否含有我们查询的数据，从而大大减少不必要的块加载，增加吞吐，降低内存消耗，提高性能
在读取数据时，hbase会首先在布隆过滤器中查询，根据布隆过滤器的结果，再在MemStore中查询，最后再在对应的HFile中查询。

18.Hbase中的region server发生故障后的处理方法(zk-->WAL)
Hbase检测宕机是通过 Zookeeper实现的，正常情况下 Regionserver会周期性向 Zookeeper发送心跳，一旦发生宕机，心跳就会停止，超过一定时间( Sessi ontimeout) Zookeeper就会认为 Regionserver宕机离线，并将该消息通知给 Master0一台 Regionserver只有一个Hog文件，然后，将og按照
Region进行分组，切分到每个 regionserver中，因此在回放之前首先需要将og按照 Region进行分组，每个 Region的日志数据放在一起，方便后面按照 Region进行回放。这个分组的过程就称为HLog切分。然后再对 region重新分配，并对其中的Hog进行回放将数据写入 memstore刷写到磁盘，完成最终数据恢复。
---------------------------------------------------------------------------------------------------------------
------------------------------------------hbase basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------hive basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 Hive
一个数据仓库基础工具在Hadoop中用来处理结构化数据。
它架构在Hadoop之上，总归为大数据，并使得查询和分析方便。并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。术语“大数据”是大型数据集，其中包括体积庞大，高速，以及各种由与日俱增的数据的集合。使用传统的数据管理系统，它是难以加工大型数据。因此，Apache软件基金会推出了一款名为Hadoop的解决大数据管理和处理难题的框架。
Hive是一个数据仓库基础工具在Hadoop中用来处理结构化数据。它架最初，Hive是由Facebook开发，后来由Apache软件基金会开发，并作为进一步将它作为名义下Apache Hive为一个开源项目。它用在好多不同的公司。例如，亚马逊使用它在 Amazon Elastic MapReduce。

2 有多种方法来执行MapReduce作业：
传统的方法是使用Java MapReduce程序结构化，半结构化和非结构化数据。
针对MapReduce的脚本的方式，使用Pig来处理结构化和半结构化数据。
Hive查询语言（HiveQL或HQL）采用Hive为MapReduce的处理结构化数据。
	
3 Hive 不是一个关系数据库
  不是一个设计用于联机事务处理（OLTP）
  不是实时查询和行级更新的语言

4 Hive架构
用户接口/界面	Hive是一个数据仓库基础工具软件，可以创建用户和HDFS之间互动。用户界面，Hive支持是Hive的Web UI，Hive命令行，HiveHD洞察（在Windows服务器）。
元存储	Hive选择各自的数据库服务器，用以储存表，数据库，列模式或元数据表，它们的数据类型和HDFS映射。
HiveQL处理引擎	HiveQL类似于SQL的查询上Metastore模式信息。这是传统的方式进行MapReduce程序的替代品之一。相反，使用Java编写的MapReduce程序，可以编写为MapReduce工作，并处理它的查询。
执行引擎	HiveQL处理引擎和MapReduce的结合部分是由Hive执行引擎。执行引擎处理查询并产生结果和MapReduce的结果一样。它采用MapReduce方法。
HDFS 或 HBASE	Hadoop的分布式文件系统或者HBASE数据存储技术是用于将数据存储到文件系统。

5 Hive工作原理
Step No.	操作
1	Execute Query 
Hive接口，如命令行或Web UI发送查询驱动程序（任何数据库驱动程序，如JDBC，ODBC等）来执行。
2	Get Plan 
在驱动程序帮助下查询编译器，分析查询检查语法和查询计划或查询的要求。
3	Get Metadata 
编译器发送元数据请求到Metastore（任何数据库）。
4	Send Metadata 
Metastore发送元数据，以编译器的响应。
5	Send Plan 
编译器检查要求，并重新发送计划给驱动程序。到此为止，查询解析和编译完成。
6	Execute Plan 
驱动程序发送的执行计划到执行引擎。
7	Execute Job 
在内部，执行作业的过程是一个MapReduce工作。执行引擎发送作业给JobTracker，在名称节点并把它分配作业到TaskTracker，这是在数据节点。在这里，查询执行MapReduce工作。
7.1	Metadata Ops 
与此同时，在执行时，执行引擎可以通过Metastore执行元数据操作。
8	Fetch Result 
执行引擎接收来自数据节点的结果。
9	Send Results 
执行引擎发送这些结果值给驱动程序。
10	Send Results 
驱动程序将结果发送给Hive接口。

6 hbase和hive的对比
1）、hbase与hive都是架构在hadoop之上的，都是用hadoop作为底层存储。
2）、Hive是建立在Hadoop之上为了减少MapReduce jobs编写工作的批处理系统，HBase是为了支持弥补Hadoop对实时操作的缺陷的项目 。
3）、在操作RMDB数据库，如果是全表扫描，就用Hive+Hadoop，如果是索引访问，就用HBase+Hadoop 。
4）、Hive query就是MapReduce jobs可以从5分钟到数小时不止，HBase是非常高效的，肯定比Hive高效的多。
 5）、Hive本身不存储和计算数据，它完全依赖于HDFS和MapReduce，Hive中的表纯逻辑。
6）、hive借用hadoop的MapReduce来完成一些hive中的命令的执行。
7）、hbase是物理表，不是逻辑表，提供一个超大的内存hash表，搜索引擎通过它来存储索引，方便查询操作。
8）、hbase是列存储。
9）、hdfs作为底层存储，hdfs是存放文件的系统，而Hbase负责组织文件。
10）、hive需要用到hdfs存储文件，需要用到MapReduce计算框架。

7 Hadoop生态上几个技术的关系与区别：hive、pig、hbase 关系与区别
（1）Pig
一种操作hadoop的轻量级脚本语言，最初又雅虎公司推出，不过现在正在走下坡路了。当初雅虎自己慢慢退出pig的维护之后将它开源贡献到开源社区由所有爱好者来维护。不过现在还是有些公司在用，不过我认为与其使用pig不如使用hive。：）
Pig是一种数据流语言，用来快速轻松的处理巨大的数据。
Pig包含两个部分：Pig Interface,Pig Latin。
Pig可以非常方便的处理HDFS和HBase的数据，和Hive一样,Pig可以非常高效的处理其需要做的，通过直接操作Pig查询可以节省大量的劳动和时间。当你想在你的数据上做一些转换，并且不想编写MapReduce jobs就可以用Pig.
（2）Hive
不想用程序语言开发MapReduce的朋友比如DB们，熟悉SQL的朋友可以使用Hive开离线的进行数据处理与分析工作。注意Hive现在适合在离线下进行数据的操作，就是说不适合在挂在真实的生产环境中进行实时的在线查询或操作，因为一个字“慢”。相反起源于FaceBook,Hive在Hadoop中扮演数据仓库的角色。建立在Hadoop集群的最顶层，对存储在Hadoop群上的数据提供类SQL的接口进行操作。你可以用 HiveQL进行select,join,等等操作。如果你有数据仓库的需求并且你擅长写SQL并且不想写MapReduce jobs就可以用Hive代替。
（3）HBase
HBase作为面向列的数据库运行在HDFS之上，HDFS缺乏随即读写操作，HBase正是为此而出现。HBase以Google BigTable为蓝本，以键值对的形式存储。项目的目标就是快速在主机内数十亿行数据中定位所需的数据并访问它。
HBase是一个数据库，一个NoSql的数据库，像其他数据库一样提供随即读写功能，Hadoop不能满足实时需要，HBase正可以满足。如果你需要实时访问一些数据，就把它存入HBase。
你可以用Hadoop作为静态数据仓库，HBase作为数据存储，放那些进行一些操作会改变的数据。
（4）Pig VS Hive
Hive更适合于数据仓库的任务，Hive主要用于静态的结构以及需要经常分析的工作。Hive与SQL相似促使 其成为Hadoop与其他BI工具结合的理想交集。Pig赋予开发人员在大数据集领域更多的灵活性，并允许开发简洁的脚本用于转换数据流以便嵌入到较大的 应用程序。Pig相比Hive相对轻量，它主要的优势是相比于直接使用Hadoop Java APIs可大幅削减代码量。正因为如此，Pig仍然是吸引大量的软件开发人员。Hive和Pig都可以与HBase组合使用，Hive和Pig还为HBase提供了高层语言支持，使得在HBase上进行数据统计处理变的非常简单
（5）Hive VS HBase
Hive是建立在Hadoop之上为了减少MapReduce jobs编写工作的批处理系统，HBase是为了支持弥补Hadoop对实时操作的缺陷的项目 。想象你在操作RMDB数据库，如果是全表扫描，就用Hive+Hadoop,如果是索引访问，就用HBase+Hadoop 。Hive query就是MapReduce jobs可以从5分钟到数小时不止，HBase是非常高效的，肯定比Hive高效的多。

8 内置函数
返回类型	签名	描述
BIGINT	round(double a)	返回BIGINT最近的double值。
BIGINT	floor(double a)	返回最大BIGINT值等于或小于double。
BIGINT	ceil(double a)	它返回最小BIGINT值等于或大于double。
double	rand(), rand(int seed)	它返回一个随机数，从行改变到行。
string	concat(string A, string B,...)	它返回从A后串联B产生的字符串
string	substr(string A, int start)	它返回一个起始，从起始位置的子字符串，直到A.结束
string	substr(string A, int start, int length)	返回从给定长度的起始start位置开始的字符串。
string	upper(string A)	它返回从转换的所有字符为大写产生的字符串。
string	ucase(string A)	和上面的一样
string	lower(string A)	它返回转换B的所有字符为小写产生的字符串。
string	lcase(string A)	和上面的一样
string	trim(string A)	它返回字符串从A.两端修剪空格的结果
string	ltrim(string A)	它返回A从一开始修整空格产生的字符串(左手侧)
string	rtrim(string A)	rtrim(string A)，它返回A从结束修整空格产生的字符串(右侧)
string	regexp_replace(string A, string B, string C)	它返回从替换所有子在B结果配合C.在Java正则表达式语法的字符串
int	size(Map<K.V>)	它返回在映射类型的元素的数量。
int	size(Array<T>)	它返回在数组类型元素的数量。
value of <type>	cast(<expr> as <type>)	它把表达式的结果expr<类型>如cast('1'作为BIGINT)代表整体转换为字符串'1'。如果转换不成功，返回的是NULL。
string	from_unixtime(int unixtime)	转换的秒数从Unix纪元(1970-01-0100:00:00 UTC)代表那一刻，在当前系统时区的时间戳字符的串格式："1970-01-01 00:00:00"
string	to_date(string timestamp)	返回一个字符串时间戳的日期部分：to_date("1970-01-01 00:00:00") = "1970-01-01"
int	year(string date)	返回年份部分的日期或时间戳字符串：year("1970-01-01 00:00:00") = 1970, year("1970-01-01") = 1970
int	month(string date)	返回日期或时间戳记字符串月份部分：month("1970-11-01 00:00:00") = 11, month("1970-11-01") = 11
int	day(string date)	返回日期或时间戳记字符串当天部分：day("1970-11-01 00:00:00") = 1, day("1970-11-01") = 1
string	get_json_object(string json_string, string path)	提取从基于指定的JSON路径的JSON字符串JSON对象，并返回提取的JSON字符串的JSON对象。如果输入的JSON字符串无效，返回NULL。

9 HiveQL 查询
1） SELECT ... FROM 语句 
hive> SELECT name,salary FROM employees;    --普通查询
hive>SELECT e.name, e.salary FROM employees e;  --也支持别名查询
hive> SELECT name,subordinates FROM employees;   显示  John Doe ["Mary Smith","Todd Jones"]  数组类型的显示 
hive>SELECT name,deductions FROM employees;   显示  John Doe {"Federal Taxes":0.2,"State Taxes":0.05}  MAP 输出
hive>SELECT name,adress FROM employees;     显示  John Doe {"street":"1 Michigan Ave.","city":"Chicago","state":"IL"}  address 列是一个 STRUCT
hive> SELECT name,subordinates[0] FROM employees;  查看数组中的第1个元素,如果不存在元素将返回 NULL
hive>SELECT name,deductions["State Taxes"] FROM employees;  查询MAP 元素
hive>SELECT name,adress.city FROM employees;  查询STRUCT 中的一个元素，可以用 . 符号

以上三种查询 在 where 子句中同样可以使用这些方式；
hive>SELECT symbol, `price.*` FROM stocks;   用正则表达戒严 选择我们想要的列，本句是查 symbol 列和所有列名以 price 作为前缀的列；
hive>SELECT upper(name), salary, deductions["Federal Taxes"], round(salary * (1 - deductions["Federal Taxes"])) FROM employees;  使用 round() 方法返回一个 Double 类型的最近整数。
 
Hive 中所支持的运算符：
A + B 、A - B、A * B、A / B、A % B [求余]、A & B [按位与]、A | B [按位或]、A ^ B [按位取异或]、~A [按位取反]
hive> SET hive.map.aggr=true;   --设置这个属性为 true 来提高聚合的性能
hive>SELECT count(*), avg(salary) FROM employees;   --这个设置会触发在 map 阶段进行的“顶级”聚合过程，（非顶级聚合过程将会在执行一个 GROUP BY 后进行），不过这个设置将需要更多的内存。
hive>SELECT count(DISTINCT symbol) FROM stocks;  多个函数还可以接受像 DISTINCT 这个表达式，来进行排重；v如果 symbol 是分区列时会返回 0.。。。是个bug；
hive>SELECT count(DISTINCT ymd),  count(DISTINCT volume) FROM stocks;  官方不允许这样查，但实际可以这样查；
 
表生成函数：与聚合函数相反的一类函数不是所谓的表生成函数，基可以将单列扩展成多列或者多行;
hive> SELECT explode (subordinates) AS sub FROM employees;   本语句将 employees 表中每行记录中 subordinates 字段内容转换成 0  个或者多个新的记录行,如果 subordinates 字段内容为空的话，那么将不会产生新的记录，如果不为空的话，那么这个数组的每个元素都将产生一行新记录；AS sub 子句定义了列别名 sub。当全用表生成函数时，Hive 要求使用列别名。【具体在13章中会详细介绍】
 
hive> SELECT upper(name), salary, deductions["Federal Taxes"],  round(salary *(1 - deductions["Federal Taxes"])) FROM employees LIMIT 2; 
LIMIT 子句用于限制返回的行数；
 
hive> SELECT upper(name), salary, deductions["Federal Taxes"] as fed_taxes,  round(salary *(1 - deductions["Federal Taxes"])) as salary_minus_fed FROM employees LIMIT 2;    fed_taxes、 salary_minus_fed  给新查出的结果的两个列起个别名；
 
hive> FROM (upper(name), salary, deductions["Federal Taxes"] as fed_taxes,  round(salary *(1 - deductions["Federal Taxes"])) as salary_minus_fed FROM employees) e SELECT e.name,  e.salary_minus_fed_taxes WHERE e.salary_minus_fed_taxes >7000;   SELECT 的嵌套查询
 
CASE ... WHEN ... THEN 句式例子：
hive>SELECT name,salary, CASE
    WHEN salary < 5000 THEN 'low'
    WHEN salary >= 5000 AND salary <7000 THEN 'middle'
    WHEN salary>=7000 AND salary < 100000 THEN 'high'
ELSE 'very high' END  AS bracket FROM  employees;
 
Hive 大多数情况下查询都会触发一个 MapReduce 任务，Hive 中本模式的查询可以不必使用 MP；如： select * from employees; 
SELECT * from employees WHERE country='us' and state='ca' limit 100;  对于 WHERE 语句中过滤条件只是分区字段这种情况（无论是否使用了 LIMT语句限制输出记录条数）也是无需MapReduce 过程的；
hive.exec.mode.local.auto=true;  如果这个值为 true Hive 还会尝试使用本地模式执行其他的操作,否则 Hive 会用 MP 来执行其他所有的查询；最好将它增加到 $HOME/.hiverc 文件中；

 
2） where 语句用于过滤查询条件 用法与 普通 SQL 一样；
谓词操作：这些词的操作同样可以用于 JION ... ON 和 HAVING 语句中
【图片取自《hive编程指南》 88-92页】
 
LIke 和 RLIKE ：LIKE是一个标准的 SQL 操作，可以让我们通过字符串的开头或结尾，以及指定特定的子字符串，或者当子字符串出现在字符串内的任何位置时进行匹配；【RLIKE 子句是 Hive中这个功能的一个扩展，其可以通过  JAVA 的正则表达式这个更强大的语言来指定匹配条件。】
 
hive>SELECT name, address.street FROM  employees WHERE address.street LIKE '%Ave.'    --查找以Ave 开头的 雇员姓名；
hive>SELECT name, address.stree FROM employees WHERE address.street RLIKE '.*(Chicago|Ontario).*';  --RLIKE 后面字符串含义：字符串中的 . 表示和任意的字符匹配，星号 * 表示重复“左边的字符串”零次到无数次，表达式（x|y）表示 和 x 或者 y 匹配；【PS：不会正则的可以百度一下去学学】
 
 
3） GROUP BY 语句，它通常会用 聚合函数一起使用，按照一个或者多个列对结果进行分组，然后对每个组执行聚合操作【用法与SQL差不多】
hive>SELECT year(ymd),avg(price_close) FROM stocks WHERE exchange='NASDAQ' AND symbol ='APPLE' GROUP BY year(ymd);  --示例
HAVING 语句：
hive>SELECT year(ymd),avg(price_close) FROM stocks 
>WHERE exchange='NASDAQ' AND symbol ='APPLE' GROUP BY year(ymd) 
>HAVING avg(price_close)>50.0;    --示例
 
 
4） JOIN 语句 
INNER JOIN 内链接，只有进行链接的两个表中都存在与连接标准相关匹配的数据才会显示【用法与SQL差不多】
hive>SELECT a.ymd,  a.price_close, b.price_close FROM stocks a JOIN STOCKS b ON a.ymd =b.ymd 
  >WHERE a.symbol ='appl' AND b.symbol='ibm'; 
 
注意：hive 中不支持的查询如下【同进也不支持在ON的子句中的谓词间使用 OR，可以支持 AND 】：
hive>SELECT a.ymd,  a.price_close, b.price_close FROM stocks a JOIN STOCKS b ON a.ymd<=b.ymd  >WHERE a.symbol ='appl' AND b.symbol='ibm'; 
多张表的链接：
hive>SELECT a.ymd,  a.price_close, b.price_close,c.price_close
       > FROM stocks a JOIN stocks b ON a.ymd=b.ymd 
       >                          JOIN stocks c ON a.ymd = c.ymd
       >WHERE a.symbol ='appl' AND b.symbol='ibm' AND c.symbol='ge';
大多数情况下，Hive 会对每个 JOIN 链接对象启动一个 MapReduce 任务，上面例子中会首先启动一个 MapReduce job 对表 a 和表 b 进行连接操作，然后会再启动一个 MapReduce job 将第一个 MapReduce job 的输出和和 c 进行连接操作；【hive 都是从左向右运顺序执行的】
 
【提示】
对于3个或者更多表进行 JOIN 链接时，如果每个 ON 子句都使用相同的链接键的话，那么只会产生一个 MapReduce；Hive 同时假定查询中最后一个表是最大的那个表，在对每行记录进行链接操时，它会尝将其他表缓存起来，然后扫描最后那个大表进计算，因此我们需要保证连续查询中的表的大小从左到右是依次增加的；
 
LEFT OUTER JOIN 左外链接【与SQL用法类似】
hive> SELECT s.ymd,  s.symbol, s.price_close,  d.dividend FROM stocks s LEFT OUTER JION dividends d ON 
>s.ydm AND s.symbol=d.symbol WHERE s.symbol='aapl' ; 
在左外链接操作中， JOIN 操作符左边表中符合 WHERE 子句的所有记录将会被返回，右边表中没有符合 ON 后面的链接记录时，会返回 null; 
【提示】WHERE 语句在连接操作执行后才会执行，因此 WHERE 语句应该只用于过滤那些非null值的列，同时，ON 语句中的分区过滤条件外链接（OUTER JOIN）中是无效的，不过在内链接中是有效的；
 
RIGHT OUTER JOIN 右外链接：会返回右边表所有符合 WHERE 语句的记录，左表中没有匹配的字段值用 NULL 代替；
FULL OUTER JOIN 完全链接：将会返回所有表中符合 where 语句条件的所有记录；
LEFT SEMI JOIN 左半开链接：会返回左边表的记录，前提是其他记录对于右边表满足ON语句中的判断条件;【不支持右关开链接】
hive>SELECT s.ymd, s.symbol, s.price_close FROM stocks s LEFT SEMI JOIN dividends d ON s.ymd=d.ymd AND s.symbol=d.symbol;
 
Hive 不支持的查询：
hive>SELECT s.ymd, s.symbol, s.price_close FROM stocks s WHERE s.ymd,s.symbol IN(SELECT * FROM dividends d); 
 
JOIN 笛卡尔积：左边链接的行数乘以右边表的行数等于返回结果集的大小；
hive> SELECT * FROM stocks JOIN dividends; 
如果使用此方法查询，MapReduce 任何方式都无法法进行优化；
set hive.mapred.mode=strict 会禁止 笛卡尔积的查询；
 
map-side JOIN：如果所有表中只有一张表是小表，那么可以在最大的表通过 mapper 的时候将小表完全放到内存中，Hive可以在 map 端执行链接过程（称为 map-side JOIN）; 因为 Hive 可以和内存中的小表进行逐一匹配，从而省略掉常规连接操作所需要的 reduce 过程 ，即使对于很小的数据庥，这个优化也明显要快于常规的连接操作，不仅减少了 reduce 过程 ，而且有时还可以同时减少 map 过程的执行步骤；
 
hive>set hive.auto.conver.JOIN=true;  从0.7版本开始需要设置此属性才可以生效
hive>set hive.mapjoin.smalltable.filesize=25000000;  配置能够使用这个优化的小表的大小；（单位：字节）
右外链接、全外链接不支持上面的优化；
 
分桶表，对于大表，在特定的情况下也可以使用这个优化，但表中的数据必须是按照ON 语句中的键进行分桶的，而且其中一张表的分桶的个数必须是另一张表分桶个数的若干倍，这样才可以按照分桶数据进行链接；hive>set hive.optimize.bucketmapJOIN=true; 也需要设置，默认是关闭的；
 
 
5） ORDER BY 和 SORT BY  
Hive 的 ORDER BY 语句和其他的 SQL 语言的定义都是一样。会对查询结果一个全局排序。也就是说会有一个所有的数据都通过一个 reducer 进行处理的过程，如果有大数据集，过程可能会消耗太过漫长的时间来执行；
 
Hive 还有一种排序 SORT BY ，其会在每个 reducer 中对数据进行排序，也就是会执行一个局部排序过程 ，这可以保证每个 reducer 的输出数据都是有序的（但不是全局有序）这样可以提高全局排序的效率；
SELECT s.ymd, s.symbol,  s.price_close FROM stocks s ORDER BY s.ymd ASC , s.symbol DESC;  

SELECT s.ymd, s.symbol,  s.price_close FROM stocks s SORT BY s.ymd ASC , s.symbol DESC;  
注意：因为 ORDER BY 操作可能会导致运行时间过长，如果属性 hvie.mapred.mode=strict 的话，那么 hive 要求这样的语句必须加 LIMIT 语句进行限制，默认情况下 属性是 nonstrict；
 
 
6） SORT BY 与 DISTRIBUTE BY
distribute by 控制 map 的输出在 reducer 中是如何划分的。
假设我们希望具有相同股票交易码的数据在一起处理，那么我们可以使用 distribute by 来保证具有相同股票交易码的记录会分发到同一个 reducer 中进行处理，然后使用 SOTR BY 来按照我们的期望对数据进行排序：
hive>SELECT s.ymd, s.symbol, s.price_close FROM stocks s DISTRIBUTE BY s.symbol SORT BY s.symbol ASC, s.ymd ASC; 
 
DISTRIBUTE BY 和 GROUP BY  在其控制着 reducer 是如何接受一行行数据进行处理这方面类似类的，而 SORT BY 则控制着 reducer 内的数据是如何进行排序的。需要注意的是 DISTRIBUTE BY 语句一定要写在 SOTR BY 语句之前；
 
7） CLUSTER BY
在上面的例子中 s.symbol 列被用在 DISTRIBUTE BY 语句中，而 s.symbol 和 s.ymd 位用 SOTR BY 语句中，如果这两个语句中涉及到的完全相同的列，而且采用的是升序的排序方式（也就是默认的排序方式）在这种情况下 cluster by 就等于前面的2个语句 ，相当于简写：
hive> SELECT s.ymd, s.symbol, s.price_close FROM  stock s CLUSTER BY s.symbol;
使用 DISTRIBUTE BY ... SOTR BY 语句或其简化版的 CLUSTER BY 语句会剥夺 SORT BY 的并行性，然而这样可以实现输出文件的数据是全局排序的；
 


10 使用了hive为什么要加mysql
metastore是hive元数据的集中存放地，默认使用内嵌的derby数据库作为储引擎。
Derby引擎的缺点：一次只能打开一个会话，Mysql作为外置存储引擎多用户同时访问。
hive只是个工具，包括它的数据分析，依赖于mapreduce，它的数据管理，依赖于外部系统。这一步其实不是必须的，因为Hive默认的metadata（元数据）是存储在Derby里面的，但是有一个弊端就是同一时间只能有一个Hive实例访问，这适合做开发程序时做本地测试。为此，需公用的，mysql。这也是为什么，在安装hive时，也需要配置mysql了。


11 Mysql作为Hive metaStore的存储数据库。里面大约有20张库表。
其中主要涉及到的表如下   
表名 	说明 	关联键
TBLS 	所有hive表的基本信息(表名，创建时间，所属者等)  	TBL_ID,SD_ID
TABLE_PARAM 	表级属性，（如是否外部表，表注释，最后修改时间等） 	TBL_ID
COLUMNS  	Hive表字段信息(字段注释，字段名，字段类型，字段序号) 	SD_ID
SDS 	所有hive表、表分区所对应的hdfs数据目录和数据格式 	SD_ID,SERDE_ID
SERDE_PARAM 	序列化反序列化信息，如行分隔符、列分隔符、NULL的表示字符等 	SERDE_ID
PARTITIONS  	Hive表分区信息（所属表，分区值） 	PART_ID,SD_ID,TBL_ID
PARTITION_KEYS 	Hive分区表分区键（即分区字段）  	TBL_ID
PARTITION_KEY_VALS 	Hive表分区名(键值) 	PART_ID

12 hiveServer/HiveServer2区别
两者都允许远程客户端使用多种编程语言，通过HiveServer或者HiveServer2，客户端可以在不启动CLI的情况下对Hive中的数据进行操作，连这个和都允许远程客户端使用多种编程语言如java，python等向hive提交请求，取回结果（从hive0.15起就不再支持hiveserver了），但是在这里我们还是要说一下hiveserver。
HiveServer或者HiveServer2都是基于Thrift的，但HiveSever有时被称为Thrift server，而HiveServer2却不会。既然已经存在HiveServer，为什么还需要HiveServer2呢？这是因为HiveServer不能处理多于一个客户端的并发请求，这是由于HiveServer使用的Thrift接口所导致的限制，不能通过修改HiveServer的代码修正。因此在Hive-0.11.0版本中重写了HiveServer代码得到了HiveServer2，进而解决了该问题。HiveServer2支持多客户端的并发和认证，为开放API客户端如JDBC、ODBC提供更好的支持。



二.Hive
1.大表join小表产生的问题，怎么解决？
一句原则：把重复关联键少的表放在join前面做关联可以提高join的效率
和join相关的优化主要分为mapjoin可以解决的优化（即大表join小表）和mapjoin无法解决的优化（即大表join大表），前者相对容易解决，后者较难，比较麻烦。
首先介绍大表join小表优化。以销售明细表为例来说明大表join小表的场景。
假如供应商进行评级，比如（五星、四星、三星、二星、一星），此时因为人员希望能够分析各供应商星级的每天销售情况及其占比。

2.udf udaf udtf区别
Hive中有三种UDF:
1）用户定义函数(user-defined function)UDF；
UDF操作作用于单个数据行，并且产生一个数据行作为输出。大多数函数都属于这一类（比如数学函数和字符串函数）。返回对应值，一对一
2）用户定义聚集函数（user-defined aggregate function，UDAF）；
UDAF 接受多个输入数据行，并产生一个输出数据行。像COUNT和MAX这样的函数就是聚集函数。返回聚类值，多对一
3）用户定义表生成函数（user-defined table-generating function，UDTF）。
UDTF 操作作用于单个数据行，并且产生多个数据行-------一个表作为输出。lateral view explore()。返回拆分值，一对多

3.hive有哪些保存元数据的方式，个有什么特点。
内存数据库derby，安装小，但是数据存在内存，不稳定
mysql数据库，数据存储模式可以自己设置，持久化好，查看方便。

4.hive内部表和外部表的区别
内部表：加载数据到hive所在的hdfs目录，删除时，元数据和数据文件都删除
外部表：不加载数据到hive所在的hdfs目录，删除时，只删除表结构。
每天采集的ng日志和埋点日志,在存储的时候建议使用外部表，因为日志数据是采集程序实时采集进来的，一旦被误删，恢复起来非常麻烦。而且外部表方便数据的共享。
抽取过来的业务数据，其实用外部表或者内部表问题都不大，就算被误删，恢复起来也是很快的，如果需要对数据内容和元数据进行紧凑的管理, 那还是建议使用内部表
在做统计分析时候用到的中间表，结果表可以使用内部表，因为这些数据不需要共享，使用内部表更为合适。并且很多时候结果分区表我们只需要保留最近3天的数据，用外部表的时候删除分区时无法删除数据。

5.生产环境中为什么建议使用外部表？
因为外部表不会加载数据到Hive，减少数据传输、数据还能共享；
Hive不会修改数据，所以无需担心数据的损坏；
删除表时，只删除表结构，不删除数据。

6.insert into 和 override write区别？
insert into：将数据写到表中
override write：覆盖之前的内容。

7.hive的函数有哪些
1）数学函数
round(double d)
round(double d,int n)
floor(double d)
ceil(double d)
ceiling(double d)
rand() 
rand(int seed)
exp(double d)
ln(double d)
log10(double d)
log2(double d)
log(double base,double d)
pow(double d,double p)
power(double d,double p)
sqrt(double d)
hex(bigint i)
hex(string str)
abs(double d)
PI()
2）集合函数
size(Map<K.V>)
map_keys(Map<K.V>)
map_values(Map<K.V>)
array_contains(Array<T>, value)
sort_array(Array<T>)
3）类型转换函数
cast(expr as <type>)
4）日期函数
date_add
date_sub
next_day
last_day
from_unixtime(bigint unixtime, string format)
to_date(string timestamp)
year(string date)
month(string date)
hour(string date)
weekofyear(string date)
datediff(string enddate, string startdate)
add_months(string start_date, int num_months)
date_format(date/timestamp/string ts, string fmt)
5）条件函数
if(boolean testCondition, T valueTrue, T valueFalseOrNull)
nvl(T value, T default_value)
COALESCE(T v1, T v2, ...)
CASE a WHEN b THEN c [WHEN d THEN e]* [ELSE f] END
isnull( a )
isnotnull ( a )
6）字符函数
concat(string|binary A, string|binary B...)
concat_ws(string SEP, string A, string B...)
length(string A)
lower(string A) lcase(string A)
parse_url(string urlString, string partToExtract [, string keyToExtract])
regexp_replace(string INITIAL_STRING, string PATTERN, string REPLACEMENT)
reverse(string A)
split(string str, string pat)
substr(string|binary A, int start) substring(string|binary A, int start)
7）聚合函数
count(*)
count(expr)
count(distinct expr[,expr_.])
sum(col)
sum(distinct col)
avg(col)
avg(distinct col)
min(col)
max(col)
8）表生成函数
explode(ARRAY array)
explode(MAP map)
explode(ARRAY<TYPE> a)
json_tuple(STRING jsonStr,p1p2,…,pn)-
parse_url_tuple(url,partname1,partname2,…,partnameN)

 
8.简单描述一下HIVE的功能？用hive创建表有几种方式？hive表有几种？
hive主要是做离线分析的；
hive建表有三种方式：
直接建表法
查询建表法(通过AS 查询语句完成建表：将子查询的结果存在新表里，有数据，一般用于中间表)
like建表法(会创建结构完全相同的表，但是没有数据)
hive表有2种：内部表和外部表


9.线上业务每天产生的业务日志（压缩后>=3G），每天需要加载到hive的log表中，将每天产生的业务日志在压缩之后load到hive的log表时，最好使用的压缩算法是哪个,并说明其原因
选择lzo,因为该压缩算法可切分，压缩率比较高，解压缩速度很快，非常适合日志

10.若在hive中建立分区仍不能优化查询效率，建表时如何优化
可以重新建表为分区分桶表

11.union all和union的区别
union 去重
union all 不去重

12.如何解决hive数据倾斜的问题
见《13.hive性能优化常用的方法》

13.hive性能优化常用的方法
hive调优涉及到压缩和存储调优，参数调优，sql的调优，数据倾斜调优，小文件问题的调优等
（1）数据的压缩与存储格式
1） map阶段输出数据压缩 ，在这个阶段，优先选择一个低CPU开销的算法。
2）对最终输出结果压缩
set hive.exec.compress.output=true 
set mapred.output.compression.codec=org.apache.hadoop.io.compress.SnappyCodec
（3）合理利用分区分桶
分区是将表的数据在物理上分成不同的文件夹，以便于在查询时可以精准指定所要读取的分区目录，从来降低读取的数据量
分桶是将表数据按指定列的hash散列后分在了不同的文件中，将来查询时，hive可以根据分桶结构，快速定位到一行数据所在的分桶文件，从来提高读取效率
（4）hive参数优化
// 让可以不走mapreduce任务的，就不走mapreduce任务
hive> set hive.fetch.task.conversion=more;
// 开启任务并行执行
 set hive.exec.parallel=true;
// 解释：当一个sql中有多个job时候，且这多个job之间没有依赖，则可以让顺序执行变为并行执行（一般为用到union all的时候）
 // 同一个sql允许并行任务的最大线程数 
set hive.exec.parallel.thread.number=8;
// 设置jvm重用
// JVM重用对hive的性能具有非常大的 影响，特别是对于很难避免小文件的场景或者task特别多的场景，这类场景大多数执行时间都很短。jvm的启动过程可能会造成相当大的开销，尤其是执行的job包含有成千上万个task任务的情况。
set mapred.job.reuse.jvm.num.tasks=10; 
// 合理设置reduce的数目
// 方法1：调整每个reduce所接受的数据量大小
set hive.exec.reducers.bytes.per.reducer=500000000; （500M）
// 方法2：直接设置reduce数量
set mapred.reduce.tasks = 20
// map端聚合，降低传给reduce的数据量
set hive.map.aggr=true  
 // 开启hive内置的数倾优化机制
set hive.groupby.skewindata=true
（5）sql优化
1）where条件优化
优化前（关系数据库不用考虑会自动优化）
select m.cid,u.id from order m join customer u on( m.cid =u.id )where m.dt='20180808';
优化后(where条件在map端执行而不是在reduce端执行）
select m.cid,u.id from （select * from order where dt='20180818'） m join customer u on( m.cid =u.id);
2）union优化
尽量不要使用union （union 去掉重复的记录）而是使用 union all 然后在用group by 去重
3）count distinct优化
不要使用count (distinct  cloumn) ,使用子查询
select count(1) from (select id from tablename group by id) tmp;
4）用in 来代替join
如果需要根据一个表的字段来约束另为一个表，尽量用in来代替join . in 要比join 快
select id,name from tb1  a join tb2 b on(a.id = b.id);
select id,name from tb1 where id in(select id from tb2);
5）优化子查询
消灭子查询内的 group by 、 COUNT(DISTINCT)，MAX，MIN。可以减少job的数量。
6）join 优化
Common/shuffle/Reduce JOIN 连接发生的阶段，发生在reduce 阶段， 适用于大表 连接 大表(默认的方式)
Map join ：连接发生在map阶段 ， 适用于小表 连接 大表
（6）数据倾斜
表现：任务进度长时间维持在99%（或100%），查看任务监控页面，发现只有少量（1个或几个）reduce子任务未完成。因为其处理的数据量和其他reduce差异过大。
原因：某个reduce的数据输入量远远大于其他reduce数据的输入量
1）sql本身导致的倾斜
1）group by
如果是在group by中产生了数据倾斜，是否可以讲group by的维度变得更细，如果没法变得更细，就可以在原分组key上添加随机数后分组聚合一次，然后对结果去掉随机数后再分组聚合
在join时，有大量为null的join key，则可以将null转成随机值，避免聚集
2）count(distinct)
情形：某特殊值过多
后果：处理此特殊值的 reduce 耗时；只有一个 reduce 任务
解决方式：count distinct 时，将值为空的情况单独处理，比如可以直接过滤空值的行，
在最后结果中加 1。如果还有其他计算，需要进行 group by，可以先将值为空的记录单独处理，再和其他计算结果进行 union。
3）不同数据类型关联产生数据倾斜
情形：比如用户表中 user_id 字段为 int，log 表中 user_id 字段既有 string 类型也有 int 类型。当按照 user_id 进行两个表的 Join 操作时。
后果：处理此特殊值的 reduce 耗时；只有一个 reduce 任务
默认的 Hash 操作会按 int 型的 id 来进行分配，这样会导致所有 string 类型 id 的记录都分配
到一个 Reducer 中。
解决方式：把数字类型转换成字符串类型
select * from users a
left outer join logs b
on a.usr_id = cast(b.user_id as string)
4）mapjoin
（7）合并小文件
小文件的产生有三个地方，map输入，map输出，reduce输出，小文件过多也会影响hive的分析效率：
（8）查看sql的执行计划
explain sql 
学会查看sql的执行计划，优化业务逻辑 ，减少job的数据量。对调优也非常重要

14.简述delete，drop，truncate的区别
delet 删除数据
drop 删除表
truncate  摧毁表结构并重建

15.order by , sort by , distribute by , cluster by的区别
1）：order by
order by会对输入做全局排序，因此只有一个Reducer(多个Reducer无法保证全局有序)，然而只有一个Reducer，会导致当输入规模较大时，消耗较长的计算时间。关于order by的详细介绍请参考这篇文章：Hive Order by操作。
2）：sort by
sort by不是全局排序，其在数据进入reducer前完成排序，因此，如果用sort by进行排序，并且设置mapred.reduce.tasks>1，则sort by只会保证每个reducer的输出有序，并不保证全局有序。sort by不同于order by，它不受hive.mapred.mode属性的影响，sort by的数据只能保证在同一个reduce中的数据可以按指定字段排序。使用sort by你可以指定执行的reduce个数(通过set mapred.reduce.tasks=n来指定)，对输出的数据再执行归并排序，即可得到全部结果。
3）：distribute by
distribute by是控制在map端如何拆分数据给reduce端的。hive会根据distribute by后面列，对应reduce的个数进行分发，默认是采用hash算法。sort by为每个reduce产生一个排序文件。在有些情况下，你需要控制某个特定行应该到哪个reducer，这通常是为了进行后续的聚集操作。distribute by刚好可以做这件事。因此，distribute by经常和sort by配合使用。
注：Distribute by和sort by的使用场景
1.Map输出的文件大小不均。
2.Reduce输出文件大小不均。
3.小文件过多。
4.文件超大。
4）：cluster by
cluster by除了具有distribute by的功能外还兼具sort by的功能。但是排序只能是倒叙排序，不能指定排序规则为ASC或者DESC。
 
16.Hive 里边字段的分隔符用的什么？为什么用\t？有遇到过字段里 边有\t 的情况吗，怎么处理的？为什么不用 Hive 默认的分隔符，默认的分隔符是什么？
hive 默认的字段分隔符为 ascii 码的控制符\001（^A）,建表的时候用 fields terminated by '\001'
遇到过字段里边有\t 的情况，自定义 InputFormat，替换为其他分隔符再做后续处理

17.分区分桶的区别，为什么要分区
分区表：原来的一个大表存储的时候分成不同的数据目录进行存储。如果说是单分区表，那么在表的目录下就只有一级子目录，如果说是多分区表，那么在表的目录下有多少分区就有多少级子目录。不管是单分区表，还是多分区表，在表的目录下，和非最终分区目录下是不能直接存储数据文件的 
分桶表：原理和hashpartitioner 一样，将hive中的一张表的数据进行归纳分类的时候，归纳分类规则就是hashpartitioner。（需要指定分桶字段，指定分成多少桶）
分区表和分桶的区别除了存储的格式不同外，最主要的是作用：
分区表：细化数据管理，缩小mapreduce程序 需要扫描的数据量。
分桶表：提高join查询的效率，在一份数据会被经常用来做连接查询的时候建立分桶，分桶字段就是连接字段；提高采样的效率。

有了分区为什么还要分桶?
(1)获得更高的查询处理效率。桶为表加上了额外的结构，Hive在处理有些查询时能利用这个结构。
(2)使取样( sampling)更高效。在处理大规模数据集时，在开发和修改査询的阶段，如果能在数据集的一小部分数据上试运行查询，会带来很多方便。
分桶是相对分区进行更细粒度的划分。分桶将表或者分区的某列值进行hash值进行区分，如要安装name属性分为3个桶，就是对name属性值的hash值对3取摸，按照取模结果对数据分桶。
与分区不同的是，分区依据的不是真实数据表文件中的列，而是我们指定的伪列，但是分桶是依据数据表中真实的列而不是伪列

18.mapjoin的原理
Hive中的Join可分为Common Join（Reduce阶段完成join）和Map Join（Map阶段完成join）
1）Map Join作用及原理
作用简单来说，在Map阶段进行join，而不是Common Join那样在Reduce阶段按照join列进行分发后在每个Reduce节点上进行join，一来省去Shuffle这个代价昂贵的阶段，二来不需要分发也就没有倾斜的问题。
2）具体过程：
在Map 端进行join，其原理是broadcast join，即把小表作为一个完整的驱动表来进行join操作。通常情况下，要连接的各个表里面的数据会分布在不同的Map中进行处理。即同一个Key对应的Value可能存在不同的Map中。这样就必须等到 Reduce中去连接。要使MapJoin能够顺利进行，那就必须满足这样的条件：除了一份表的数据分布在不同的Map中外，其他连接的表的数据必须在每个Map中有完整的拷贝。Map Join会把小表全部读入内存中，在Map阶段直接拿另外一个表的数据和内存中表数据做匹配 (这时可以使用Distributed Cache将小表分发到各个节点上，以供Mapper加载使用)，由于在map时进行了join操作，省去了reduce运行的效率也会高很多。

19.在hive的row_number中distribute by 和 partition by的区别 
row_number() over( partition by 分组的字段  order by 排序的字段) as rank(rank 可随意定义表示排序的标识)；
row_number() over( distribute by 分组的字段  sort by 排序的字段) as rank(rank 可随意定义表示排序的标识)
注意：
partition by 只能和order by 组合使用
distribute by 只能和 sort by 使用

20.hive开发中遇到什么问题?
见《13.hive性能优化常用的方法》

21.什么时候使用内部表,什么时候使用外部表
见上面

22.hive都有哪些函数，你平常工作中用到哪些
见《7.hive的函数有哪些》

23.手写sql，连续活跃用户
1）因为每天用户登录次数可能不止一次，所以需要先将用户每天的登录日期去重。
2）再用row_number() over(partition by _ order by _)函数将用户id分组，按照登陆时间进行排序。
3）计算登录日期减去第二步骤得到的结果值，用户连续登陆情况下，每次相减的结果都相同。
4）按照id和日期分组并求和，筛选大于等于2的即为连续活跃登陆的用户。
 
24.left semi join和left join区别
1） 联系
他们都是 hive join 方式的一种，join on 属于 common join（shuffle join/reduce join），而 left semi join 则属于 map join（broadcast join）的一种变体，从名字可以看出他们的实现原理有差异。
2） 区别
LEFT SEMI JOIN 是 IN/EXISTS 子查询的一种更高效的实现。
LEFT SEMI JOIN 的限制是， JOIN 子句中右边的表只能在 ON 子句中设置过滤条件，在 WHERE 子句、SELECT 子句或其他地方都不行。
因为 left semi join 是 in(keySet) 的关系，遇到右表重复记录，左表会跳过，而 join 则会一直遍历。这就导致右表有重复值得情况下 left semi join 只产生一条，join 会产生多条，也会导致 left semi join 的性能更高。
left semi join 是只传递表的 join key 给 map 阶段，因此left semi join 中最后 select 的结果只许出现左表。因为右表只有 join key 参与关联计算了，而left  join on 默认是整个关系模型都参与计算了

25.group by为什么要排序
使用了reduce操作，shuffle自带排序操作。
因为distinct只使用一个reduce进行处理，而group by使用多个reduce进行处理，所以对于大数据（hive就是处理大数据的）能用group by的就不要使用distinct。
hive不怕数据大，就怕数据倾斜。

26.说说印象最深的一次优化场景，hive常见的优化思路
见《hive调优》

27.聊聊hive的执行引擎，spark和mr的区别？
引擎是mr，基于磁盘进行计算，比较慢
引擎是spark，基于内存进行计算，速度比较快
对于超大数据量的话，hiveOnSpark可能会有内存溢出情况

28.hive的join底层mr是如何实现的？
Hive的join底层mapreduce是如何实现的?

 
29.sql问题，连续几天活跃的用户？
《同上》

30.建好了外部表，用什么语句把数据文件加载到表里
从本地导入：load data local inpath /home/liuzc into table ods.test
从hdfs导入：load data inpath /user/hive/warehouse/a.txt into ods.test

31.Hive的执行流程？
用户提交查询等任务给Driver。
编译器获得该用户的任务Plan。
编译器Compiler根据用户任务去MetaStore中获取需要的Hive的元数据信息。
编译器Compiler得到元数据信息，对任务进行编译，先将HiveQL转换为抽象语法树，然后将抽象语法树转换成查询块，将查询块转化为逻辑的查询计划，重写逻辑查询计划，将逻辑计划转化为物理的计划（MapReduce）, 最后选择最佳的策略。
将最终的计划提交给Driver。
Driver将计划Plan转交给ExecutionEngine去执行，获取元数据信息，提交给JobTracker或者SourceManager执行该任务，任务会直接读取HDFS中文件进行相应的操作。
获取执行的结果。
取得并返回执行结果。
Hive的join底层mapreduce是如何实现的?

32.hive的元数据信息存储在哪？
内存数据库derby，安装小，但是数据存在内存，不稳定
mysql数据库，数据存储模式可以自己设置，持久化好，查看方便。

33.sql语句的执行顺序
from-where-group by-having -select-order by -limit

34.on和where的区别
left join(on&where)

35.hive和传统数据库之间的区别
1）、写时模式和读时模式
传统数据库是写时模式，在load过程中，提升了査询性能，因为预先解析之后可以对列建立索引，并压缩，但这样也会花费更多的加载时间。
Hive是读时模式，1 oad data非常迅速，因为它不需要读取数据进行解析，仅仅进行文件的复制或者移动。
2）、数据格式。Hive中没有定义专门的数据格式，由用户指定，需要指定三个属性:列分隔符，行分隔符，以及读取文件数据的方法。数据库中，存储引擎定义了自己的数据格式。所有数据都会按照一定的组织存储
3）、数据更新。Hive的内容是读多写少的，因此，不支持对数据的改写和删除，数据都在加载的时候中确定好的。数据库中的数据通常是需要经常进行修改
4）、执行延迟。Hive在查询数据的时候，需要扫描整个表(或分区)，因此延迟较高，只有在处理大数据是才有优势。数据库在处理小数据是执行延迟较低。
5）、索引。Hive比较弱，不适合实时查询。数据库有。
6）、执行。Hive是 Mapreduce，数据库是 Executor
7）、可扩展性。Hive高，数据库低
8）、数据规模。Hive大，数据库小

36.hive中导入数据的4种方式
从本地导入：load data local inpath /home/liuzc into table ods.test
从hdfs导入：load data inpath /user/hive/warehouse/a.txt into ods.test
查询导入：create table tmp_test as select * from ods.test
查询结果导入：insert into table tmp.test select * from ods.test

37 聊聊hive的执行引擎，spark和mr的区别？
mr引擎：计算模式简单，中间结果都需要进行落盘存储，比较慢，但性能稳定，配置要求低
spark引擎：采用弹性分布式数据集模型，中间结果缓存在内存中，迭代计算效率更高，DAG优化，速度比较快。
对于超大量数据的话，hiveOnSpark可能会有内存溢出的情况。

38 下述sql在hive、spark sql两种执行引擎中，执行流程分别是什么，区别是什么？
select t1.c,t2.b from t1 join t2 on t1.id = t2.id
1）hive执行流程
编译器compiler得到元数据信息，对任务进行编译，先将hql转换为抽象语法树，
然后将抽象语法树转换成查询块，
将查询块转化为逻辑的查询计划，重写逻辑查询计划，
将逻辑计划转化为物理的计划（mapreduce），最后选择最佳的策略。
2）spark sql执行流程
sql语句经过解析器Parser转换成未解析的逻辑计划，
再经过分析器Analyzer解析逻辑计划，
优化器optimizer优化逻辑计划，
经过转换器SparkPlan转换成可执行的物理计划。
3）区别：
解析流程不一样。hive默认以mapreduce作为执行引擎，sparksql以spark为执行引擎。
---------------------------------------------------------------------------------------------------------------
------------------------------------------hive basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------https basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识

1 要说清楚 HTTPS 协议的实现原理，至少需要如下几个背景知识。
大致了解几个基本术语（HTTPS、SSL、TLS）的含义
大致了解 HTTP 和 TCP 的关系（尤其是“短连接”VS“长连接”）
大致了解加密算法的概念（尤其是“对称加密与非对称加密”的区别）
大致了解 CA 证书的用途

2. “HTTP”是干嘛用滴？	
首先，HTTP 是一个网络协议，是专门用来帮你传输 Web 内容滴。关于这个协议，就算你不了解，至少也听说过吧？比如你访问俺的博客的主页，浏览器地址栏会出现如下的网址
大部分网站都是通过 HTTP 协议来传输 Web 页面、以及 Web 页面上包含的各种东东（图片、CSS 样式、JS 脚本）。超文本传输协议HTTP协议被用于在Web浏览器和网站服务器之间传递信息，HTTP协议以明文方式发送内容，不提供任何方式的数据加密，如果攻击者截取了Web浏览器和网站服务器之间的传输报文，就可以直接读懂其中的信息，因此，HTTP协议不适合传输一些敏感信息，比如：信用卡号、密码等支付信息。为了解决HTTP协议的这一缺陷，需要使用另一种协议：安全套接字层超文本传输协议HTTPS，为了数据传输的安全，HTTPS在HTTP的基础上加入了SSL协议，SSL依靠证书来验证服务器的身份，并为浏览器和服务器之间的通信加密。
HTTP：是互联网上应用最为广泛的一种网络协议，是一个客户端和服务器端请求和应答的标准（TCP），用于从WWW服务器传输超文本到本地浏览器的传输协议，它可以使浏览器更加高效，使网络传输减少。
HTTPS：是以安全为目标的HTTP通道，简单讲是HTTP的安全版，即HTTP下加入SSL层，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。
HTTPS协议的主要作用可以分为两种：一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性。

3. “SSL/TLS”是干嘛用滴？
SSL 是洋文“Secure Sockets Layer”的缩写，中文叫做“安全套接层”。它是在上世纪90年代中期，由网景公司设计的。（顺便插一句，网景公司不光发明了 SSL，还发明了很多 Web 的基础设施——比如“CSS 样式表”和“JS 脚本”）为啥要发明 SSL 这个协议捏？因为原先互联网上使用的 HTTP 协议是明文的，存在很多缺点——比如传输内容会被偷窥（嗅探）和篡改。发明 SSL 协议，就是为了解决这些问题。到了1999年，SSL 因为应用广泛，已经成为互联网上的事实标准。IETF 就在那年把 SSL 标准化。标准化之后的名称改为 TLS（是“Transport Layer Security”的缩写），中文叫做“传输层安全协议”。很多相关的文章都把这两者并列称呼（SSL/TLS），因为这两者可以视作同一个东西的不同阶段。

4. “HTTPS”是啥意思？
解释完 HTTP 和 SSL/TLS，现在就可以来解释 HTTPS 啦。咱们通常所说的 HTTPS 协议，说白了就是“HTTP 协议”和“SSL/TLS 协议”的组合。你可以把 HTTPS 大致理解为——“HTTP over SSL”或“HTTP over TLS”（反正 SSL 和 TLS 差不多）。

5. HTTP 的版本和历史
如今咱们用的 HTTP 协议，版本号是 1.1（也就是 HTTP 1.1）。这个 1.1 版本是1995年底开始起草的（技术文档是 RFC2068），并在1999年正式发布（技术文档是 RFC2616）。
在 1.1 之前，还有曾经出现过两个版本“0.9 和 1.0”，其中的 HTTP 0.9 【没有】被广泛使用，而 HTTP 1.0 被广泛使用过。另外，据说明年（2015）IETF 就要发布 HTTP 2.0 的标准了。俺拭目以待。

6 HTTP 和 TCP 之间的关系
简单地说，TCP 协议是 HTTP 协议的基石——HTTP 协议需要依靠 TCP 协议来传输数据。在网络分层模型中，TCP 被称为“传输层协议”，而 HTTP 被称为“应用层协议”。有很多常见的应用层协议是以 TCP 为基础的，比如“FTP、SMTP、POP、IMAP”等。TCP 被称为“面向连接”的传输层协议。关于它的具体细节，俺就不展开了（否则篇幅又失控了）。你只需知道：传输层主要有两个协议，分别是 TCP 和 UDP。TCP 比 UDP 更可靠。你可以把 TCP 协议想象成某个水管，发送端这头进水，接收端那头就出水。并且 TCP 协议能够确保，先发送的数据先到达（与之相反，UDP 不保证这点）。

7. HTTP 协议如何使用 TCP 连接
HTTP 对 TCP 连接的使用，分为两种方式：俗称“短连接”和“长连接”（“长连接”又称“持久连接”，洋文叫做“Keep-Alive”或“Persistent Connection”）假设有一个网页，里面包含好多图片，还包含好多【外部的】CSS 文件和 JS 文件。在“短连接”的模式下，浏览器会先发起一个 TCP 连接，拿到该网页的 HTML 源代码（拿到 HTML 之后，这个 TCP 连接就关闭了）。然后，浏览器开始分析这个网页的源码，知道这个页面包含很多外部资源（图片、CSS、JS）。然后针对【每一个】外部资源，再分别发起一个个 TCP 连接，把这些文件获取到本地（同样的，每抓取一个外部资源后，相应的 TCP 就断开）相反，如果是“长连接”的方式，浏览器也会先发起一个 TCP 连接去抓取页面。但是抓取页面之后，该 TCP 连接并不会立即关闭，而是暂时先保持着（所谓的“Keep-Alive”）。然后浏览器分析 HTML 源码之后，发现有很多外部资源，就用刚才那个 TCP 连接去抓取此页面的外部资源。

在 HTTP 1.0 版本，【默认】使用的是“短连接”（那时候是 Web 诞生初期，网页相对简单，“短连接”的问题不大）；到了1995年底开始制定 HTTP 1.1 草案的时候，网页已经开始变得复杂（网页内的图片、脚本越来越多了）。这时候再用短连接的方式，效率太低下了（因为建立 TCP 连接是有“时间成本”和“CPU 成本”滴）。所以，在 HTTP 1.1 中，【默认】采用的是“Keep-Alive”的方式。关于“Keep-Alive”的更多介绍，可以参见维基百科词条（在“这里”）

8. 啥是“加密”和“解密” 
通俗而言，你可以把“加密”和“解密”理解为某种【互逆的】数学运算。就好比“加法和减法”互为逆运算、“乘法和除法”互为逆运算。“加密”的过程，就是把“明文”变成“密文”的过程；反之，“解密”的过程，就是把“密文”变为“明文”。在这两个过程中，都需要一个关键的东东——叫做“密钥”——来参与数学运算。

9. 啥是“对称加密” 
所谓的“对称加密技术”，意思就是说：“加密”和“解密”使用【相同的】密钥。这个比较好理解。就好比你用 7zip 或 WinRAR 创建一个带密码（口令）的加密压缩包。当你下次要把这个压缩文件解开的时候，你需要输入【同样的】密码。在这个例子中，密码/口令就如同刚才说的“密钥”。

10. 啥是“非对称加密” 
所谓的“非对称加密技术”，意思就是说：“加密”和“解密”使用【不同的】密钥。这玩意儿比较难理解，也比较难想到。当年“非对称加密”的发明，还被誉为“密码学”历史上的一次革命。
由于篇幅有限，对“非对称加密”这个话题，俺就不展开了。有空的话，再单独写一篇扫盲。

11. 各自有啥优缺点 
看完刚才的定义，很显然：（从功能角度而言）“非对称加密”能干的事情比“对称加密”要多。这是“非对称加密”的优点。但是“非对称加密”的实现，通常需要涉及到“复杂数学问题”。所以，“非对称加密”的性能通常要差很多（相对于“对称加密”而言）。这两者的优缺点，也影响到了 SSL 协议的设计。

12 CA 证书的原理及用途
关于这方面，请看俺4年前写的《数字证书及CA的扫盲介绍》。这里就不再重复唠叨了，免得篇幅太长。

13 HTTPS 协议的需求是啥
花了好多口水，终于把背景知识说完了。下面正式进入正题。先来说说当初设计 HTTPS 是为了满足哪些需求？很多介绍 HTTPS 的文章一上来就给你讲实现细节。个人觉得：这是不好的做法。早在2009年开博的时候，发过一篇《学习技术的三部曲：WHAT、HOW、WHY》，其中谈到“WHY 型问题”的重要性。一上来就给你讲协议细节，你充其量只能知道 WHAT 和 HOW，无法理解 WHY。俺在前一个章节讲了“背景知识”，在这个章节讲了“需求”。

14 兼容性
因为是先有 HTTP 再有 HTTPS。所以，HTTPS 的设计者肯定要考虑到对原有 HTTP 的兼容性。这里所说的兼容性包括很多方面。比如已有的 Web 应用要尽可能无缝地迁移到 HTTPS；比如对浏览器厂商而言，改动要尽可能小基于“兼容性”方面的考虑，很容易得出如下几个结论
（1） HTTPS 还是要基于 TCP 来传输，如果改为 UDP 作传输层，无论是 Web 服务端还是浏览器客户端，都要大改，动静太大了
（2） 单独使用一个新的协议，把 HTTP 协议包裹起来
所谓的“HTTP over SSL”，实际上是在原有的 HTTP 数据外面加了一层 SSL 的封装。HTTP 协议原有的 GET、POST 之类的机制，基本上原封不动 
打个比方：如果原来的 HTTP 是塑料水管，容易被戳破；那么如今新设计的 HTTPS 就像是在原有的塑料水管之外，再包一层金属水管。一来，原有的塑料水管照样运行；二来，用金属加固了之后，不容易被戳破。

15 可扩展性
前面说了，HTTPS 相当于是“HTTP over SSL”。如果 SSL 这个协议在“可扩展性”方面的设计足够牛逼，那么它除了能跟 HTTP 搭配，还能够跟其它的应用层协议搭配。岂不美哉？
现在看来，当初设计 SSL 的人确实比较牛。如今的 SSL/TLS 可以跟很多常用的应用层协议（比如：FTP、SMTP、POP、Telnet）搭配，来强化这些应用层协议的安全性。接着刚才打的比方：如果把 SSL/TLS 视作一根用来加固的金属管，它不仅可以用来加固输水的管道，还可以用来加固输煤气的管道。

16 保密性（防泄密）
HTTPS 需要做到足够好的保密性。说到保密性，首先要能够对抗嗅探（行话叫 Sniffer）。所谓的“嗅探”，通俗而言就是监视你的网络传输流量。如果你使用明文的 HTTP 上网，那么监视者通过嗅探，就知道你在访问哪些网站的哪些页面。嗅探是最低级的攻击手法。除了嗅探，HTTPS 还需要能对抗其它一些稍微高级的攻击手法——比如“重放攻击”（后面讲协议原理的时候，会再聊）。

17 完整性（防篡改）
除了“保密性”，还有一个同样重要的目标是“确保完整性”。关于“完整性”这个概念，在之前的博文《扫盲文件完整性校验——关于散列值和数字签名》中大致提过。健忘的同学再去温习一下。在发明 HTTPS 之前，由于 HTTP 是明文的，不但容易被嗅探，还容易被篡改。
举个例子：
比如咱们天朝的网络运营商（ISP）都比较流氓，经常有网友抱怨说访问某网站（本来是没有广告的），竟然会跳出很多中国电信的广告。为啥会这样捏？因为你的网络流量需要经过 ISP 的线路才能到达公网。如果你使用的是明文的 HTTP，ISP 很容易就可以在你访问的页面中植入广告。所以，当初设计 HTTPS 的时候，还有一个需求是“确保 HTTP 协议的内容不被篡改”。

18 真实性（防假冒）
在谈到 HTTPS 的需求时，“真实性”经常被忽略。其实“真实性”的重要程度不亚于前面的“保密性”和“完整性”。
举个例子：
你因为使用网银，需要访问该网银的 Web 站点。那么，你如何确保你访问的网站确实是你想访问的网站？（这话有点绕口令）
有些天真的同学会说：通过看网址里面的域名，来确保。为啥说这样的同学是“天真的”？因为 DNS 系统本身是不可靠的（尤其是在设计 SSL 的那个年代，连 DNSSEC 都还没发明）。由于 DNS 的不可靠（存在“域名欺骗”和“域名劫持”），你看到的网址里面的域名【未必】是真实滴！

19 性能
再来说最后一个需求——性能。
引入 HTTPS 之后，【不能】导致性能变得太差。否则的话，谁还愿意用？
为了确保性能，SSL 的设计者至少要考虑如下几点 
（1） 如何选择加密算法（“对称”or“非对称”）？
（2）如何兼顾 HTTP 采用的“短连接”TCP 方式？
（SSL 是在1995年之前开始设计的，那时候的 HTTP 版本还是 1.0，默认使用的是“短连接”的 TCP 方式——默认不启用 Keep-Alive）

20 HTTPS和HTTP的区别
（1）https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。
（2）http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。
（3）http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
（4）http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。

21 HTTPS的工作原理
我们都知道HTTPS能够加密信息，以免敏感信息被第三方获取，所以很多银行网站或电子邮箱等等安全级别较高的服务都会采用HTTPS协议。
HTTP与HTTPS的区别-马海祥博客。客户端在使用HTTPS方式与Web服务器通信时有以下几个步骤，如图所示。
（1）客户使用https的URL访问Web服务器，要求与Web服务器建立SSL连接。
（2）Web服务器收到客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端。
（3）客户端的浏览器与Web服务器开始协商SSL连接的安全等级，也就是信息加密的等级。
（4）客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。
（5）Web服务器利用自己的私钥解密出会话密钥。
（6）Web服务器利用会话密钥加密与客户端之间的通信。

22、HTTPS的优点
尽管HTTPS并非绝对安全，掌握根证书的机构、掌握加密算法的组织同样可以进行中间人形式的攻击，但HTTPS仍是现行架构下最安全的解决方案，主要有以下几个好处
　　（1）使用HTTPS协议可认证用户和服务器，确保数据发送到正确的客户机和服务器；
　　（2）HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全，可防止数据在传输过程中不被窃取、改变，确保数据的完整性。
　　（3）HTTPS是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。
　　（4）谷歌曾在2014年8月份调整搜索引擎算法，并称“比起同等HTTP网站，采用HTTPS加密的网站在搜索结果中的排名将会更高”。

23、HTTPS的缺点
虽然说HTTPS有很大的优势，但其相对来说，还是存在不足之处的
　　（1）HTTPS协议握手阶段比较费时，会使页面的加载时间延长近50%，增加10%到20%的耗电；
　　（2）HTTPS连接缓存不如HTTP高效，会增加数据开销和功耗，甚至已有的安全措施也会因此而受到影响；
　　（3）SSL证书需要钱，功能越强大的证书费用越高，个人网站、小网站没有必要一般不会用。
　  （4）SSL证书通常需要绑定IP，不能在同一IP上绑定多个域名，IPv4资源不可能支撑这个消耗。
　　（5）HTTPS协议的加密范围也比较有限，在黑客攻击、拒绝服务攻击、服务器劫持等方面几乎起不到什么作用。最关键的，SSL证书的信用链体系并不安全，特别是在某些国家可以控制CA根证书的情况下，中间人攻击一样可行。

24、http切换到HTTPS
如果需要将网站从http切换到https到底该如何实现呢？这里需要将页面中所有的链接，例如js，css，图片等等链接都由http改为https。
例如：http://www.baidu.com改为https://www.baidu.com 
BTW，这里虽然将http切换为了https，还是建议保留http。所以我们在切换的时候可以做http和https的兼容，具体实现方式是，去掉页面链接中的http头部，这样可以自动匹配http头和https头。例如：将http://www.baidu.com改为//www.baidu.com。然后当用户从http的入口进入访问页面时，页面就是http，如果用户是从https的入口进入访问页面，页面即使https的。

公钥密码体制分为三个部分，公钥、私钥、加密解密算法，它的加密解密过程如下：
@加密：通过加密算法和公钥对内容(或者说明文)进行加密，得到密文。加密过程需要用到公钥。
@解密：通过解密算法和私钥对密文进行解密，得到明文。解密过程需要用到解密算法和私钥。注意，由公钥加密的内容，只能由私钥进行解密，也就是说，由公钥加密的内容，如果不知道私钥，是无法解密的。




二、ms相关
1 HTTP 和 HTTPS 的基本概念？
（1）HTTP：超文本传输协议（HTTP，HyperText Transfer Protocol）是互联网上应用最为广泛的一种网络协议。设计 HTTP 最初的目的是为了提供一种发布和接收 HTML 页面的方法。它可以使浏览器更加高效。HTTP 协议是以明文方式发送信息的，如果黑客截取了 Web 浏览器和服务器之间的传输报文，就可以直接获得其中的信息。
（2）HTTP 原理：
①  客户端的浏览器首先要通过网络与服务器建立连接，该连接是通过 TCP 来完成的，一般 TCP 连接的端口号是80。 建立连接后，客户机发送一个请求给服务器，请求方式的格式为：统一资源标识符（URI））协议版本号，后边是 MIME 信息包括请求修饰符）客户机信息和许可内容。
②  服务器接到请求后，给予相应的响应信息，其格式为一个状态行，包括信息的协议版本号）一个成功或错误的代码，后边是 MIME 信息包括服务器信息）实体信息和可能的内容。
（3）HTTPS：是以安全为目标的 HTTP 通道，是 HTTP 的安全版。HTTPS 的安全基础是 SSL。SSL 协议位于 TCP/IP 协议与各种应用层协议之间，为数据通讯提供安全支持。SSL 协议可分为两层：SSL 记录协议（SSL Record Protocol），它建立在可靠的传输协议（如TCP）之上，为高层协议提供数据封装）压缩）加密等基本功能的支持。SSL 握手协议（SSL Handshake Protocol），它建立在 SSL 记录协议之上，用于在实际的数据传输开始前，通讯双方进行身份认证）协商加密算法）交换加密密钥等。
                                             
2 HTTPS 设计目标？
(1) 数据保密性：保证数据内容在传输的过程中不会被第三方查看。就像快递员传递包裹一样，都进行了封装，别人无法获知里面装了什么  。
(2) 数据完整性：及时发现被第三方篡改的传输内容。就像快递员虽然不知道包裹里装了什么东西，但他有可能中途掉包，数据完整性就是指如果被掉包，我们能轻松发现并拒收 。
(3) 身份校验安全性：保证数据到达用户期望的目的地。就像我们邮寄包裹时，虽然是一个封装好的未掉包的包裹，但必须确定这个包裹不会送错地方，通过身份校验来确保送对了地方  。

3 HTTP 与 HTTPS  的区别？
1）HTTPS  协议需要到 CA （Certificate Authority，证书颁发机构）申请证书，一般免费证书较少，因而需要一定费用。(以前的网易官网是http，而网易邮箱是 https 。)
2）HTTP 是超文本传输协议，信息是明文传输，HTTPS 则是具有安全性的 SSL 加密传输协议。
3）HTTP 和 HTTPS 使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
4）HTTP 的连接很简单，是无状态的。HTTPS 协议是由 SSL+HTTP 协议构建的可进行加密传输）身份认证的网络协议，比 HTTP 协议安全。(无状态的意思是其数据包的发送）传输和接收都是相互独立的。无连接的意思是指通信双方都不长久的维持对方的任何信息。)

4 HTTPS 相对于 HTTP 的改进
双向的身份认证
客户端和服务端在传输数据之前，会通过基于X.509证书对双方进行身份认证 。具体过程如下：
客户端发起 SSL 握手消息给服务端要求连接。
服务端将证书发送给客户端。
客户端检查服务端证书，确认是否由自己信任的证书签发机构签发(客户端内置了所有受信任 CA 的证书)。 如果不是，将是否继续通讯的决定权交给用户选择 ( 注意，这里将是一个安全缺陷 )。如果检查无误或者用户选择继续，则客户端认可服务端的身份。
服务端要求客户端发送证书，并检查是否通过验证。失败则关闭连接，认证成功则从客户端证书中获得客户端的公钥，一般为 1024 位或者 2048 位。到此，服务器客户端双方的身份认证结束，双方确保身份都是真实可靠的。
注意：
(1) 采用 HTTPS 协议的服务器必须要有一套数字证书，可以自己制作，也可以向组织申请。区别就是自己颁发的证书需要客户端验证通过，才可以继续访问。这套证书其实就是一对公钥和私钥。
(2) 互联网有太多的服务需要使用证书来验证身份，以至于客户端（操作系统或浏览器等）无法内置所有证书，需要通过服务端将证书发送给客户端。
(3) 客户端内置的是 CA 的根证书(Root Certificate)，HTTPS 协议中服务器会发送证书链（Certificate Chain）给客户端。

5 数据传输的机密性
客户端和服务端在开始传输数据之前，会协商传输过程需要使用的加密算法。 客户端发送协商请求给服务端, 其中包含自己支持的非对成加密的密钥交换算法 ( 一般是RSA)，数据签名摘要算法 ( 一般是SHA或者MD5) ，加密传输数据的对称加密算法 ( 一般是DES)，以及加密密钥的长度。 服务端接收到消息之后，选中安全性最高的算法，并将选中的算法发送给客户端，完成协商。客户端生成随机的字符串，通过协商好的非对称加密算法，使用服务端的公钥对该字符串进行加密，发送给服务端。 服务端接收到之后，使用自己的私钥解密得到该字符串。在随后的数据传输当中，使用这个字符串作为密钥进行对称加密。

6 防止重放攻击
SSL 使用序列号来保护通讯方免受报文重放攻击。这个序列号被加密后作为数据包的负载。在整个 SSL 握手中，都有一个唯一的随机数来标记 SSL 握手。 这样防止了攻击者嗅探整个登录过程，获取到加密的登录数据之后，不对数据进行解密，而直接重传登录数据包的攻击手法。
可以看到，鉴于电子商务等安全上的需求，HTTPS 对比 HTTP 协议，在安全方面已经取得了极大的增强。总结来说，HTTPS 的改进点在于创造性的使用了非对称加密算法，在不安全的网路上，安全的传输了用来进行非对称加密的密钥，综合利用了非对称加密的安全性和对称加密的快速性。

7 HTTPS 的优点
1）使用 HTTPS 协议可认证用户和服务器，确保数据发送到正确的客户机和服务器。
2）HTTPS 协议是由SSL+HTTP 协议构建的可进行加密传输）身份认证的网络协议，要比 HTTP 协议安全，可防止数据在传输过程中不被窃取）修改，确保数据的完整性。
3）HTTPS 是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。

8 HTTPS 的缺点（对比优点）
1）HTTPS 协议握手阶段比较费时，会使页面的加载时间延长近。
2）HTTPS 连接缓存不如 HTTP 高效，会增加数据开销，甚至已有的安全措施也会因此而受到影响。
3）HTTPS 协议的安全是有范围的，在黑客攻击）拒绝服务攻击和服务器劫持等方面几乎起不到什么作用。
4）SSL 证书通常需要绑定 IP，不能在同一 IP 上绑定多个域名，IPv4 资源不可能支撑这个消耗。
5）成本增加。部署 HTTPS 后，因为 HTTPS 协议的工作要增加额外的计算资源消耗，例如 SSL 协议加密算法和 SSL 交互次数将占用一定的计算资源和服务器成本。
6）HTTPS 协议的加密范围也比较有限。最关键的，SSL 证书的信用链体系并不安全，特别是在某些国家可以控制 CA 根证书的情况下，中间人攻击一样可行。

9 HTTPS 的连接过程
① 客户端的浏览器向服务器发送请求，并传送客户端 SSL 协议的版本号，加密算法的种类，产生的随机数，以及其他服务器和客户端之间通讯所需要的各种信息。
② 服务器向客户端传送 SSL 协议的版本号，加密算法的种类，随机数以及其他相关信息，同时服务器还将向客户端传送自己的证书。
③ 客户端利用服务器传过来的信息验证服务器的合法性，服务器的合法性包括：证书是否过期，发行服务器证书的 CA 是否可靠，发行者证书的公钥能否正确解开服务器证书的 "发行者的数字签名"，服务器证书上的域名是否和服务器的实际域名相匹配。如果合法性验证没有通过，通讯将断开；如果合法性验证通过，将继续进行第四步。
④ 用户端随机产生一个用于通讯的 "对称密码"，然后用服务器的公钥（服务器的公钥从步骤②中的服务器的证书中获得）对其加密，然后将加密后的“预主密码”传给服务器。
⑤ 如果服务器要求客户的身份认证（在握手过程中为可选），用户可以建立一个随机数然后对其进行数据签名，将这个含有签名的随机数和客户自己的证书以及加密过的密钥一起传给服务器。
⑥ 如果服务器要求客户的身份认证，服务器必须检验客户证书和签名随机数的合法性，具体的合法性验证过程包括：客户的证书使用日期是否有效，为客户提供证书的 CA  是否可靠，发行 CA 的公钥能否正确解开客户证书的发行 CA 的数字签名，检查客户的证书是否在证书废止列表（CRL）中。检验如果没有通过，通讯立刻中断；如果验证通过，服务器将用自己的私钥解开加密的私钥，然后执行一系列步骤来产生主通讯密码（客户端也将通过同样的方法产生相同的主通讯密码）。
⑦ 服务器和客户端用相同的对称加密密钥，对称密钥用于 SSL 协议的安全数据通讯的加解密通讯。同时在 SSL 通讯过程中还要完成数据通讯的完整性，防止数据通讯中的任何变化。
⑧ 客户端向服务器端发出信息，指明后面的数据通讯将使用的步骤 ⑦ 中的主密码为对称密钥，同时通知服务器客户端的握手过程结束。
⑨ 服务器向客户端发出信息，指明后面的数据通讯将使用的步骤 ⑦ 中的主密码为对称密钥，同时通知客户端服务器端的握手过程结束。
⑩ SSL 的握手部分结束，SSL 安全通道的数据通讯开始，客户和服务器开始使用相同的对称密钥进行数据通讯，同时进行通讯完整性的检验。
上述的过程需要弄懂的核心思想
1）客户端解析证书
这部分工作是由客户端的 TLS 来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警告框，提示证书存在问题。如果证书没有问题，那么就生成一个对称加密密钥，
然后用公钥对该密钥进行非对称加密。
2）传送加密信息
这部分传送的是用公钥加密后的对称加密密钥，目的就是让服务端得到这个密钥，以后客户端和服务端的通信就可以通过这个密钥来进行加密解密了。
3）服务端解密信息
服务端用非对称加密算法里的私钥解密后，得到了客户端传过来的对称加密算法的私钥，然后把之后传输的内容通过该值进行对称加密。

10 为什么用非对称加密协商对称加密密钥
对称加密的特点：对称密码体制中只有一种密钥，并且是非公开的。如果要解密就得让对方知道密钥，所以想要保证其安全性就要保证密钥的安全。
非对称加密的特点：算法强度复杂）安全性依赖于算法与密钥但是由于其算法复杂，而使得加密解密速度没有对称加密解密的速度快。非对称密钥体制有两种密钥，其中一个是公开的，这样就可以不需要像对称密码那样传输对方的密钥了，这样安全性就大了很多。
非对称加密公钥和私钥的使用方法：(1) 公钥加密私钥解密。(2) 私钥做数字签名，公钥验证。

11 SSL 工作流程
服务器认证阶段：
(1) 客户端向服务器发送一个开始信息 "Hello" 以便开始一个新的会话连接；
(2) 服务器根据客户的信息确定是否需要生成新的主密钥，如需要则服务器在响应客户的 "Hello" 信息时将包含生成主密钥所需的信息；
(3) 客户根据收到的服务器响应信息，产生一个主密钥，并用服务器的公开密钥加密后传给服务器；
(4) 服务器回复该主密钥，并返回给客户一个用主密钥认证的信息，以此让客户认证服务器。

12 服务器证书(server certificates)？
 SSL 数字证书的一种形式，意指通过提交数字证书来证明您的身份或表明您有权访问在线服务。再者简单来说，通过使用服务器证书可为不同站点提供身份鉴定并保证该站点拥有高强度加密安全。是组成 Web 服务器的 SSL 安全功能的唯一的数字标识。通过相互信任的第三方组织获得，并为用户提供验证您 Web 站点身份的手段。服务器证书包含详细的身份验证信息，如服务器内容附属的组织）颁发证书的组织以及称为公开密钥的唯一的身份验证文件。

 
 
 
---------------------------------------------------------------------------------------------------------------
------------------------------------------https basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------java ee basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 struts1 流程 
1）. 服务器启动的时候读取web.xml文件，加载ActionServlet类并初始化struts-config-xxx.xml文件，把配置信息如action路径、action名称、formBean信息、全局跳转信息放到ActionMapping中，跳转路径封装为action的一个ActionFarword对象，ActionMapping包含ActionFarword。
2）. 用户在前台客户端发送HTTP请求到后台，负责接收请求的控制器是ActionServlet类，该类继承HttpServlet类，如果ActionForm实例不存在，容器也会创建一个ActionForm对象,封装所有的请求参数，
此时容器会根据配置信息决定是否需要表单验证。如果需要验证，就调用ActionForm的validate()方法。如果ActionForm的validate（）方法返回一个包含一个或多个ActionMessage的ActionErrors对象，
就表示表单验证失败，此时ActionServlet将直接把请求转发给包含用户提交表单的JSP组件。在这种情况下，不会在创建Action对象并调用Action的execute()方法。
3）. 如果返回null则表示验证成功，下一步ActionServlet把请求交付RequestProcessor类处理，该类负责进行action分发，从配置信息中找出请求路径对应的action类，如果不存在，就返回用户请求路径无效的信息。
若找到有对应的action而且没有实例，则初始化一个实例，并调用里面的execute方法，execut调用业务逻辑和数据访问层进行业务流程处理，返回一个ActionForward对象，由视图显示处理的结果，視图部份可以是HTML、JSP、Struts自定义标签、PDF文件、Excel文件、一个请求等。
4）. 四个主要类的请求顺序是：ActionMapping--ActionForm---Action---ActionForward.
5）. RequestProcessor类包含一个HashMap，作为存放所有Action实例的缓存。每个Action实例在缓存中存放的key为Action类名。在RequestProcessor类的processActionCreate()方法中，
首先检查在HashMap中是否存在Action实例，如果有直接使用，否则创建一个新的。创建Action实例的代码位于同步代码块中，以保证只有一个线程创建Action实例，然后放在HashMap中。
供其他线程使用。所以说Servlet和Struts1都是单例模式。

2 Struts1和Struts2的对比
@ 类:
Struts1要求Action类继承一个抽象基类。Struts1的一个普遍问题是使用抽象类编程而不是接口。
Struts 2 Action类可以实现一个Action接口，也可实现其他接口，使可选和定制的服务成为可能。Struts2提供一个ActionSupport基类去实现常用的接口。Action接口不是必须   的，任何有execute标识的POJO对象都可以用作Struts2的Action对象。

@ 线程模式:
Struts1 Action是单例模式并且必须是线程安全的，因为仅有Action的一个实例来处理所有的请求。单例策略限制了Struts1 Action能作的事，并且要在开发时特别小心。        Action资源必须是线程安全的或同步的。
Struts2 Action对象为每一个请求产生一个实例，因此没有线程安全问题。（实际上，servlet容器给每个请求产生许多可丢弃的对象，并且不会导致性能和垃圾回收问题）

Servlet 依赖:
Struts1 Action 依赖于Servlet API ,因为当一个Action被调用时HttpServletRequest 和 HttpServletResponse 被传递给execute方法。
Struts 2 Action不依赖于容器，允许Action脱离容器单独被测试。如果需要，Struts2 Action仍然可以访问初始的request和response。但是，其他的元素减少或者消除了直接    访问HttpServetRequest 和 HttpServletResponse的必要性。

@ 可测性:
测试Struts1 Action的一个主要问题是execute方法暴露了servlet API（这使得测试要依赖于容器）。一个第三方扩展－－Struts TestCase－－提供了一套Struts1的模拟对象（来进行测试）。
Struts 2 Action可以通过初始化、设置属性、调用方法来测试，“依赖注入”支持也使测试更容易。

@ 捕获输入:
Struts1 使用ActionForm对象捕获输入。所有的ActionForm必须继承一个基类。因为其他JavaBean不能用作ActionForm，开发者经常创建多余的类捕获输入。动态Bean（DynaBeans）可以作为创建传统ActionForm的选择，但是，开发者可能是在重新描述(创建)已经存在的JavaBean（仍然会导致有冗余的javabean）。
Struts 2直接使用Action属性作为输入属性，消除了对第二个输入对象的需求。输入属性可能是有自己(子)属性的rich对象类型。Action属性能够通过 web页面上的taglibs访问。Struts2也支持ActionForm模式。rich对象类型，包括业务对象，能够用作输入/输出对象。这种 ModelDriven 特性简化了taglib对POJO输入对象的引用。

@ 表达式语言：
Struts1 整合了JSTL，因此使用JSTL EL。这种EL有基本对象图遍历，但是对集合和索引属性的支持很弱。
Struts2可以使用JSTL，但是也支持一个更强大和灵活的表达式语言－－"Object Graph Notation Language" (OGNL).

@ 绑定值到页面（view）:
Struts 1使用标准JSP机制把对象绑定到页面中来访问。
Struts 2 使用 "ValueStack"技术，使taglib能够访问值而不需要把你的页面（view）和对象绑定起来。ValueStack策略允许通过一系列名称相同但类型不同的属性重用页面（view）。

@ 类型转换：
Struts 1 ActionForm 属性通常都是String类型。Struts1使用Commons-Beanutils进行类型转换。每个类一个转换器，对每一个实例来说是不可配置的。
Struts2 使用OGNL进行类型转换。提供基本和常用对象的转换器。

@ 校验：
Struts 1支持在ActionForm的validate方法中手动校验，或者通过Commons Validator的扩展来校验。同一个类可以有不同的校验内容，但不能校验子对象。
Struts2支持通过validate方法和XWork校验框架来进行校验。XWork校验框架使用为属性类类型定义的校验和内容校验，来支持chain校验子属性

@ Action执行的控制：
Struts1支持每一个模块有单独的Request Processors（生命周期），但是模块中的所有Action必须共享相同的生命周期。
Struts2支持通过拦截器堆栈（Interceptor Stacks）为每一个Action创建不同的生命周期。堆栈能够根据需要和不同的Action一起使用。


2 HttpServlet 
作为一个抽象类来创建用户自己的Http Servlet. Http Servlet类扩展了GenericServlet类。
HttpServlet类的子类必须至少重写doGet()和doPost()方法其中之一。
HttpServlet类提供doGet()方法处理GET请求，doPost()处理POST请求：
doGet() ：通过GenericServlet 类的service()方法来调用此方法；
doPost():  通过GenericServlet 类的service()方法来调用此方法；

3 WebServlet注解
Servlet3.0提供了注解(annotation)，使得不再需要在web.xml文件中进行Servlet的部署描述，简化开发流程。开发Servlet3的程序需要一定的环境支持。Servlet3是Java EE6规范的一部分，MyEclipse10和Tomcat7都提供了对Java EE6规范的支持。Tomcat需要Tomcat7才支持Java EE6，Tomcat7需要使用JDK6。关于注解以后有机会会专门写一博客来研究它，这里主要是@WebServlet注解的使用。

4 Servlet的线程安全问题
Servlet默认是多线程模式执行的，当有多个用户同时并发请求一个Servlet时，容器将启动多个线程调用相应的请求处理方法，此时，请求处理方法中的局部变量是安全的，但对于成员变量和共享数据是不安全的，因此这多个线程有可能同时都操作这些数据，这是需要同步处理。所以，编写代码时需要非常细致的考虑多线程的安全性问题。多数人编写Servlet时不注意多线程问题，导致少量用户访问时没有问题，但并发量大则出现莫名其妙的问题。
当多个客户端并发访问同一个Servlet时，web服务器会为每一个客户端的访问请求创建一个线程，并在这个线程上调用Servlet的service方法，因此service方法内如果访问了同一个资源的话，就有可能引发线程安全问题。

5 Jsp相关
Jsp九大内置对象：
pageContext,request,session,application,out,exception,config,page,response
Jsp四大域对象：pageContext,request,session,application
jsp三大指令：page,include,taglib 
Jsp七大动作：forward,include,param,useBean,setProperty,getProperty,plugin

6 数据库连接池
1） 数据库连接是一种关键的有限的昂贵的资源
这一点在多用户的网页应用程序中体现的尤为突出.对数据库连接的管理能显著影响到整个应用程序的伸缩性和健壮性,影响到程序的性能指标.数据库连接池正式针对这个问题提出来的.数据库连接池负责分配,管理和释放数据库连接,它允许应用程序重复使用一个现有的数据库连接,而不是重新建立一个。如下图所示：
2） 数据库连接池（Connection pooling）是程序启动时建立足够的数据库连接
并将这些连接组成一个连接池，由程序动态地对池中的连接进行申请，使用，释放。个人理解：创建数据库连接是一个很耗时的操作，也容易对数据库造成安全隐患。所以，在程序初始化的时候，集中创建多个数据库连接，并把他们集中管理，供程序使用，可以保证较快的数据库读写速度，还更加安全可靠。
3） 数据库连接池在初始化时将创建一定数量的数据库连接放到连接池中,这些数据库连接的数量是由最小数据库连接数来设定的.无论这些数据库连接是否被使用,
连接池都将一直保证至少拥有这么多的连接数量.连接池的最大数据库连接数量限定了这个连接池能占有的最大连接数,当应用程序向连接池请求的连接数超过最大连接数量时,这些请求将被加入到等待队列中.
4） 数据库连接池的最小连接数和最大连接数的设置要考虑到以下几个因素:
@最小连接数:是连接池一直保持的数据库连接,所以如果应用程序对数据库连接的使用量不大,将会有大量的数据库连接资源被浪费。
@最大连接数:是连接池能申请的最大连接数,如果数据库连接请求超过次数,后面的数据库连接请求将被加入到等待队列中,这会影响以后的数据库操作。
如果最小连接数与最大连接数相差很大:那么最先连接请求将会获利,之后超过最小连接数量的连接请求等价于建立一个新的数据库连接。
不过,这些大于最小连接数的数据库连接在使用完不会马上被释放,他将被放到连接池中等待重复使用或是空间超时后被释放。

7 数据库连接池的运行机制
（1） 程序初始化时创建连接池
（2） 使用时向连接池申请可用连接
（3） 使用完毕，将连接返还给连接池
（4） 程序退出时，断开所有连接，并释放资源

8 数据库连接池核心代码
  使用动态代理技术构建连接池中的connection
 1 proxyConn = (Connection) Proxy.newProxyInstance(this.getClass()
 2             .getClassLoader(), conn.getClass().getInterfaces(),
 3             new InvocationHandler() {
 4         //此处为内部类，当close方法被调用时将conn还回池中,其它方法直接执行
 5             public Object invoke(Object proxy, Method method,
 6                       Object[] args) throws Throwable {
 7                 if (method.getName().equals("close")) {
 8                     pool.addLast(conn);
 9                     return null;
10             }
11             return method.invoke(conn, args);
12         }
13     });






二、ms相关
1 分布式事物一致性如何保证？
在OLTP系统领域，我们在很多业务场景下都会面临事务一致性方面的需求，例如最经典的Bob给Smith转账的案例。传统的企业开发，系统往往是以单体应用形式存在的，也没有横跨多个数据库。我们通常只需借助开发平台中特有数据访问技术和框架（例如Spring、JDBC、ADO.NET），结合关系型数据库自带的事务管理机制来实现事务性的需求。关系型数据库通常具有ACID特性：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。
而大型互联网平台往往是由一系列分布式系统构成的，开发语言平台和技术栈也相对比较杂，尤其是在SOA和微服务架构盛行的今天，一个看起来简单的功能，内部可能需要调用多个“服务”并操作多个数据库或分片来实现，情况往往会复杂很多。单一的技术手段和解决方案，已经无法应对和满足这些复杂的场景了。
分布式系统的特性
对分布式系统有过研究的读者，可能听说过“CAP定律”、“Base理论”等，非常巧的是，化学理论中ACID是酸、Base恰好是碱。这里笔者不对这些概念做过多的解释，有兴趣的读者可以查看相关参考资料。CAP定律如下图：
在分布式系统中，同时满足“CAP定律”中的“一致性”、“可用性”和“分区容错性”三者是不可能的，这比现实中找对象需同时满足“高、富、帅”或“白、富、美”更加困难。在互联网领域的绝大多数的场景，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证“最终一致性”，只要这个最终时间是在用户可以接受的范围内即可。

分布式事务
提到分布式系统，必然要提到分布式事务。要想理解分布式事务，不得不先介绍一下两阶段提交协议。先举个简单但不精准的例子来说明：
第一阶段，张老师作为“协调者”，给小强和小明（参与者、节点）发微信，组织他们俩明天8点在学校门口集合，一起去爬山，然后开始等待小强和小明答复。
第二阶段，如果小强和小明都回答没问题，那么大家如约而至。如果小强或者小明其中一人回答说“明天没空，不行”，那么张老师会立即通知小强和小明“爬山活动取消”。
细心的读者会发现，这个过程中可能有很多问题的。如果小强没看手机，那么张老师会一直等着答复，小明可能在家里把爬山装备都准备好了却一直等着张老师确认信息。更严重的是，如果到明天8点小强还没有答复，那么就算“超时”了，那小明到底去还是不去集合爬山呢？
这就是两阶段提交协议的弊病，所以后来业界又引入了三阶段提交协议来解决该类问题。
两阶段提交协议在主流开发语言平台，数据库产品中都有广泛应用和实现的，下面来介绍一下XOpen组织提供的DTP模型图：
XA协议指的是TM（事务管理器）和RM（资源管理器）之间的接口。目前主流的关系型数据库产品都是实现了XA接口的。JTA(Java Transaction API)是符合X/Open DTP模型的，事务管理器和资源管理器之间也使用了XA协议。 本质上也是借助两阶段提交协议来实现分布式事务的，下面分别来看看XA事务成功和失败的模型图：
在JavaEE平台下，WebLogic、Webshare等主流商用的应用服务器提供了JTA的实现和支持。而在Tomcat下是没有实现的（其实笔者并不认为Tomcat能算是JavaEE应用服务器），这就需要借助第三方的框架Jotm、Automikos等来实现，两者均支持spring事务整合。
而在Windows .NET平台中，则可以借助ado.net中的TransactionScop API来编程实现，还必须配置和借助Windows操作系统中的MSDTC服务。如果你的数据库使用的mysql，并且mysql是部署在Linux平台上的，那么是无法支持分布式事务的。 由于篇幅关系，这里不展开，感兴趣的读者可以自行查阅相关资料并实践。
总结：这种方式实现难度不算太高，比较适合传统的单体应用，在同一个方法中存在跨库操作的情况。但分布式事务对性能的影响会比较大，不适合高并发和高性能要求的场景。

提供回滚接口
在服务化架构中，功能X，需要去协调后端的A、B甚至更多的原子服务。那么问题来了，假如A和B其中一个调用失败了，那可怎么办呢？
在笔者的工作中经常遇到这类问题，往往提供了一个BFF层来协调调用A、B服务。如果有些是需要同步返回结果的，我会尽量按照“串行”的方式去调用。如果调用A失败，则不会盲目去调用B。如果调用A成功，而调用B失败，会尝试去回滚刚刚对A的调用操作。
当然，有些时候我们不必严格提供单独对应的回滚接口，可以通过传递参数巧妙的实现。
这样的情况，我们会尽量把可提供回滚接口的服务放在前面。举个例子说明：
我们的某个论坛网站，每天登录成功后会奖励用户5个积分，但是积分和用户又是两套独立的子系统服务，对应不同的DB，这控制起来就比较麻烦了。解决思路：
把登录和加积分的服务调用放在BFF层一个本地方法中。
当用户请求登录接口时，先执行加积分操作，加分成功后再执行登录操作
如果登录成功，那当然最好了，积分也加成功了。如果登录失败，则调用加积分对应的回滚接口（执行减积分的操作）。
总结：这种方式缺点比较多，通常在复杂场景下是不推荐使用的，除非是非常简单的场景，非常容易提供回滚，而且依赖的服务也非常少的情况。
这种实现方式会造成代码量庞大，耦合性高。而且非常有局限性，因为有很多的业务是无法很简单的实现回滚的，如果串行的服务很多，回滚的成本实在太高。

本地消息表
这种实现方式的思路，其实是源于ebay，后来通过支付宝等公司的布道，在业内广泛使用。其基本的设计思想是将远程分布式事务拆分成一系列的本地事务。如果不考虑性能及设计优雅，借助关系型数据库中的表即可实现。
举个经典的跨行转账的例子来描述。
第一步伪代码如下，扣款1W，通过本地事务保证了凭证消息插入到消息表中。
第二步，通知对方银行账户上加1W了。那问题来了，如何通知到对方呢？
通常采用两种方式：
采用时效性高的MQ，由对方订阅消息并监听，有消息时自动触发事件
采用定时轮询扫描的方式，去检查消息表的数据。
两种方式其实各有利弊，仅仅依靠MQ，可能会出现通知失败的问题。而过于频繁的定时轮询，效率也不是最佳的（90%是无用功）。所以，我们一般会把两种方式结合起来使用。
解决了通知的问题，又有新的问题了。万一这消息有重复被消费，往用户帐号上多加了钱，那岂不是后果很严重？
仔细思考，其实我们可以消息消费方，也通过一个“消费状态表”来记录消费状态。在执行“加款”操作之前，检测下该消息（提供标识）是否已经消费过，消费完成后，通过本地事务控制来更新这个“消费状态表”。这样子就避免重复消费的问题。
总结：上诉的方式是一种非常经典的实现，基本避免了分布式事务，实现了“最终一致性”。但是，关系型数据库的吞吐量和性能方面存在瓶颈，频繁的读写消息会给数据库造成压力。所以，在真正的高并发场景下，该方案也会有瓶颈和限制的。

MQ（非事务消息）
通常情况下，在使用非事务消息支持的MQ产品时，我们很难将业务操作与对MQ的操作放在一个本地事务域中管理。通俗点描述，还是以上述提到的“跨行转账”为例，我们很难保证在扣款完成之后对MQ投递消息的操作就一定能成功。这样一致性似乎很难保证。
先从消息生产者这端来分析，请看伪代码：
根据上述代码及注释，我们来分析下可能的情况：
操作数据库成功，向MQ中投递消息也成功，皆大欢喜
操作数据库失败，不会向MQ中投递消息了
操作数据库成功，但是向MQ中投递消息时失败，向外抛出了异常，刚刚执行的更新数据库的操作将被回滚
从上面分析的几种情况来看，貌似问题都不大的。那么我们来分析下消费者端面临的问题：
消息出列后，消费者对应的业务操作要执行成功。如果业务执行失败，消息不能失效或者丢失。需要保证消息与业务操作一致
尽量避免消息重复消费。如果重复消费，也不能因此影响业务结果
如何保证消息与业务操作一致，不丢失？
主流的MQ产品都具有持久化消息的功能。如果消费者宕机或者消费失败，都可以执行重试机制的（有些MQ可以自定义重试次数）。
如何避免消息被重复消费造成的问题？
保证消费者调用业务的服务接口的幂等性
通过消费日志或者类似状态表来记录消费状态，便于判断（建议在业务上自行实现，而不依赖MQ产品提供该特性）
总结：这种方式比较常见，性能和吞吐量是优于使用关系型数据库消息表的方案。如果MQ自身和业务都具有高可用性，理论上是可以满足大部分的业务场景的。不过在没有充分测试的情况下，不建议在交易业务中直接使用。

MQ（事务消息）
举个例子，Bob向Smith转账，那我们到底是先发送消息，还是先执行扣款操作？
好像都可能会出问题。如果先发消息，扣款操作失败，那么Smith的账户里面会多出一笔钱。反过来，如果先执行扣款操作，后发送消息，那有可能扣款成功了但是消息没发出去，Smith收不到钱。除了上面介绍的通过异常捕获和回滚的方式外，还有没有其他的思路呢？
下面以阿里巴巴的RocketMQ中间件为例，分析下其设计和实现思路。
RocketMQ第一阶段发送Prepared消息时，会拿到消息的地址，第二阶段执行本地事物，第三阶段通过第一阶段拿到的地址去访问消息，并修改状态。细心的读者可能又发现问题了，如果确认消息发送失败了怎么办？RocketMQ会定期扫描消息集群中的事物消息，这时候发现了Prepared消息，它会向消息发送者确认，Bob的钱到底是减了还是没减呢？如果减了是回滚还是继续发送确认消息呢？RocketMQ会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。如下图：
总结：据笔者的了解，各大知名的电商平台和互联网公司，几乎都是采用类似的设计思路来实现“最终一致性”的。这种方式适合的业务场景广泛，而且比较可靠。不过这种方式技术实现的难度比较大。目前主流的开源MQ（ActiveMQ、RabbitMQ、Kafka）均未实现对事务消息的支持，所以需二次开发或者新造轮子。比较遗憾的是，RocketMQ事务消息部分的代码也并未开源，需要自己去实现。

其他补偿方式
做过支付宝交易接口的同学都知道，我们一般会在支付宝的回调页面和接口里，解密参数，然后调用系统中更新交易状态相关的服务，将订单更新为付款成功。同时，只有当我们回调页面中输出了success字样或者标识业务处理成功相应状态码时，支付宝才会停止回调请求。否则，支付宝会每间隔一段时间后，再向客户方发起回调请求，直到输出成功标识为止。
其实这就是一个很典型的补偿例子，跟一些MQ重试补偿机制很类似。
一般成熟的系统中，对于级别较高的服务和接口，整体的可用性通常都会很高。如果有些业务由于瞬时的网络故障或调用超时等问题，那么这种重试机制其实是非常有效的。
当然，考虑个比较极端的场景，假如系统自身有bug或者程序逻辑有问题，那么重试1W次那也是无济于事的。那岂不是就发生了“明明已经付款，却显示未付款不发货”类似的悲剧？
其实为了交易系统更可靠，我们一般会在类似交易这种高级别的服务代码中，加入详细日志记录的，一旦系统内部引发类似致命异常，会有邮件通知。同时，后台会有定时任务扫描和分析此类日志，检查出这种特殊的情况，会尝试通过程序来补偿并邮件通知相关人员。
在某些特殊的情况下，还会有“人工补偿”的，这也是最后一道屏障。

小结
上诉的几种方案中，笔者也大致总结了其设计思路，优势，劣势等，相信读者已经有了一定的理解。其实分布式系统的事务一致性本身是一个技术难题，目前没有一种很简单很完美的方案能够应对所有场景。具体还是要使用者根据不同的业务场景去抉择。



2 docker比linux虚拟机有什么优势？
首先，大家需要明确一点，Docker容器不是虚拟机。
2014年，当我第一次接触Docker的时候，我把它比做一种轻量级的虚拟机。这样做无可厚非，因为Docker最初的成功秘诀，正是它比虚拟机更节省内存，启动更快。Docker不停地给大家宣传，”虚拟机需要数分钟启动，而Docker容器只需要50毫秒”。
然而，Docker容器并非虚拟机，我们不妨来比较一下它们。
理解虚拟机
使用虚拟机运行多个相互隔离的应用时，如下图:

从下到上理解上图:
基础设施(Infrastructure)。它可以是你的个人电脑，数据中心的服务器，或者是云主机。
主操作系统(Host Operating System)。你的个人电脑之上，运行的可能是MacOS，Windows或者某个Linux发行版。
虚拟机管理系统(Hypervisor)。利用Hypervisor，可以在主操作系统之上运行多个不同的从操作系统。类型1的Hypervisor有支持MacOS的HyperKit，支持Windows的Hyper-V以及支持Linux的KVM。类型2的Hypervisor有VirtualBox和VMWare。
从操作系统(Guest Operating System)。假设你需要运行3个相互隔离的应用，则需要使用Hypervisor启动3个从操作系统，也就是3个虚拟机。这些虚拟机都非常大，也许有700MB，这就意味着它们将占用2.1GB的磁盘空间。更糟糕的是，它们还会消耗很多CPU和内存。
各种依赖。每一个从操作系统都需要安装许多依赖。如果你的的应用需要连接PostgreSQL的话，则需要安装libpq-dev；如果你使用Ruby的话，应该需要安装gems；如果使用其他编程语言，比如Python或者Node.js，都会需要安装对应的依赖库。
应用。安装依赖之后，就可以在各个从操作系统分别运行应用了，这样各个应用就是相互隔离的。

理解Docker容器
使用Docker容器运行多个相互隔离的应用时，如下图:

不难发现，相比于虚拟机，Docker要简洁很多。因为我们不需要运行一个臃肿的从操作系统了。

从下到上理解上图:
基础设施(Infrastructure)。
主操作系统(Host Operating System)。所有主流的Linux发行版都可以运行Docker。对于MacOS和Windows，也有一些办法”运行”Docker。
Docker守护进程(Docker Daemon)。Docker守护进程取代了Hypervisor，它是运行在操作系统之上的后台进程，负责管理Docker容器。
各种依赖。对于Docker，应用的所有依赖都打包在Docker镜像中，Docker容器是基于Docker镜像创建的。
应用。应用的源代码与它的依赖都打包在Docker镜像中，不同的应用需要不同的Docker镜像。不同的应用运行在不同的Docker容器中，它们是相互隔离的。

对比虚拟机与Docker
Docker守护进程可以直接与主操作系统进行通信，为各个Docker容器分配资源；它还可以将容器与主操作系统隔离，并将各个容器互相隔离。虚拟机启动需要数分钟，而Docker容器可以在数毫秒内启动。由于没有臃肿的从操作系统，Docker可以节省大量的磁盘空间以及其他系统资源。
说了这么多Docker的优势，大家也没有必要完全否定虚拟机技术，因为两者有不同的使用场景。虚拟机更擅长于彻底隔离整个运行环境。例如，云服务提供商通常采用虚拟机技术隔离不同的用户。而Docker通常用于隔离不同的应用，例如前端，后端以及数据库。



3 MyBatis的#和$有什么区别？
1.#将传入的数据都当成一个字符串，会对自动传入的数据加一个双引号。如：order by #user_id#，如果传入的值是111,那么解析成sql时的值为order by "111", 如果传入的值是id，则解析成的sql为order by "id".
2.$将传入的数据直接显示生成在sql中。如：order by $user_id$，如果传入的值是111,那么解析成sql时的值为order by user_id, 如果传入的值是id，则解析成的sql为order by id.
3.#方式能够很大程度防止sql注入。　
4.$方式无法防止Sql注入。 
5.$方式一般用于传入数据库对象，例如传入表名. 
6.一般能用#的就别用$. 


4 Spring bean作用域有哪些？默认是哪个？
1. singleton作用域 scope="singleton" 默认值
bean设置为该作用域时，Spring IOC容器中只会存在一个共享的bean实例，也就意味着Spring IOC容器只会创建该bean定义的唯一实例。
这个单一实例会被存储到单例缓存（singleton cache）中。
2. prototype作用域 scope="prototype"
prototype作用域部署的bean，每一次请求（将其注入到另一个bean中，或者以程序的方式调用容器的getBean()）都会产生一个新的bean
实例，相当于一个new操作。
注意：Spring不能对一个prototype bean的整个生命周期负责，容器在初始化、配置、装饰或者是装配完一个prototype实例后，将它交给客户端，
随后就对 prototype实例不闻不问了。此时清楚任何prototype作用域的对象并释放其所持有的昂贵资源，都是客户端代码的职责。
注意：request作用域、session作用域、global-session作用域使用的时候首先要在初始化web的web.xml中做以下配置
<listener>
    <listener-class>org.springframework.web.context.request.RequestContextListener</listener-class>
</listener>
3. request作用域
表示该作用域下，针对每一次HTTP请求都会产生一个新的bean，同时该bean仅在当前HTTP-request内有效
4. session作用域
session作用域表示针对每一次HTTP请求都会产生一个新的bean，同时该bean仅在当前HTTP-session内有效
5. global-session作用域
全局会话内有效


5 spring mvc的control是单例吗？怎么保证线程安全？Struts2是单例还是多例？
Spring MVC单例，struts1单例，struts2 多例 
由于Spring MVC默认是Singleton的，所以会产生一个潜在的安全隐患。根本核心是instance变量保持状态的问题。这意味着每个request过来，系统都会用原有的instance去处理，这样导致了两个结果：
一是我们不用每次创建Controller，
二是减少了对象创建和垃圾收集的时间；
由于只有一个Controller的instance，当多个线程同时调用它的时候，它里面的instance变量就不是线程安全的了，会发生窜数据的问题。
当然大多数情况下，我们根本不需要考虑线程安全的问题，比如dao,service等，除非在bean中声明了实例变量。因此，我们在使用spring mvc 的contrller时，应避免在controller中定义实例变量。 
如：

publicclassControllerextendsAbstractCommandController{
......
protectedModelAndView handle(HttpServletRequest request,HttpServletResponse response,
Object command,BindException errors)throwsException{
company =................;
}
protectedCompany company;
}


在这里有声明一个变量company，这里就存在并发线程安全的问题。
如果控制器是使用单例形式，且controller中有一个私有的变量a,所有请求到同一个controller时，使用的a变量是共用的，即若是某个请求中修改了这个变量a，则，在别的请求中能够读到这个修改的内容。。

有几种解决方法：
1、在控制器中不使用实例变量
2、将控制器的作用域从单例改为原型，即在spring配置文件Controller中声明 scope="prototype"，每次都创建新的controller
3、在Controller中使用ThreadLocal变量

这几种做法有好有坏，第一种，需要开发人员拥有较高的编程水平与思想意识，在编码过程中力求避免出现这种BUG，而第二种则是容器自动的对每个请求产生一个实例，由JVM进行垃圾回收，因此做到了线程安全。
使用第一种方式的好处是实例对象只有一个，所有的请求都调用该实例对象，速度和性能上要优于第二种，不好的地方，就是需要程序员自己去控制实例变量的状态保持问题。第二种由于每次请求都创建一个实例，所以会消耗较多的内存空间。
所以在使用spring开发web 时要注意，默认Controller、Dao、Service都是单例的


6 Dubbo支持哪些协议,有哪几种容错机制？
Dubbo支持dubbo、rmi、hessian、http、webservice、thrift、redis等多种协议。

容错机制有：
Failover Cluster
失败自动切换，当出现失败，重试其它服务器。(缺省)
通常用于读操作，但重试会带来更长延迟。
可通过retries="2"来设置重试次数(不含第一次)。正是文章刚开始说的那种情况.

Failfast Cluster
快速失败，只发起一次调用，失败立即报错。
通常用于非幂等性的写操作，比如新增记录。

Failsafe Cluster
失败安全，出现异常时，直接忽略。
通常用于写入审计日志等操作。

Failback Cluster
失败自动恢复，后台记录失败请求，定时重发。
通常用于消息通知操作。

Forking Cluster
并行调用多个服务器，只要一个成功即返回。
通常用于实时性要求较高的读操作，但需要浪费更多服务资源。
可通过forks="2"来设置最大并行数。

Broadcast Cluster
广播调用所有提供者，逐个调用，任意一台报错则报错。(2.1.0开始支持)
通常用于通知所有提供者更新缓存或日志等本地资源信息。
重试次数配置如：(failover集群模式生效)
<dubbo:serviceretries="2"/>
或：<dubbo:referenceretries="2"/>
或：<dubbo:reference>
<dubbo:methodname="findFoo"retries="2"/>
</dubbo:reference>


7 NIO和IO方面有何不同？有没使用过Netty？
下表总结了Java IO和NIO之间的主要区别：
IO	NIO
面向流	面向缓冲
阻塞IO	非阻塞IO
无	选择器
 
 
 
 


1、面向流与面向缓冲
     Java IO和NIO之间第一个最大的区别是，IO是面向流的，NIO是面向缓冲区的。 Java IO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区。 Java NIO的缓冲导向方法略有不同。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动。这就增加了处理过程中的灵活性。但是，还需要检查是否该缓冲区中包含所有您需要处理的数据。而且，需确保当更多的数据读入缓冲区时，不要覆盖缓冲区里尚未处理的数据。
2、阻塞与非阻塞IO
     Java IO的各种流是阻塞的。这意味着，当一个线程调用read() 或 write()时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了。Java NIO的非阻塞模式，使一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取，而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。 线程通常将非阻塞IO的空闲时间用于在其它通道上执行IO操作，所以一个单独的线程现在可以管理多个输入和输出通道（channel）。
3、选择器（Selectors）
     Java NIO的选择器允许一个单独的线程来监视多个输入通道，你可以注册多个通道使用一个选择器，然后使用一个单独的线程来“选择”通道：这些通道里已经有可以处理的输入，或者选择已准备写入的通道。这种选择机制，使得一个单独的线程很容易来管理多个通道。



8 怎么理解CAS原语无锁？
无锁编程 / lock-free / 非阻塞同步
无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。
实现非阻塞同步的方案称为“无锁编程算法”（ Non-blocking algorithm）。
lock-free是目前最常见的无锁编程的实现级别（一共三种级别）。
为什么要 Non-blocking sync ？
使用lock实现线程同步有很多缺点：
* 产生竞争时，线程被阻塞等待，无法做到线程实时响应。
* dead lock。
* live lock。
* 优先级翻转。
* 使用不当，造成性能下降。
 
如果在不使用 lock 的情况下，实现变量同步，那就会避免很多问题。虽然目前来看，无锁编程并不能替代 lock。
实现级别
非同步阻塞的实现可以分成三个级别：wait-free/lock-free/obstruction-free。
 
wait-free
是最理想的模式，整个操作保证每个线程在有限步骤下完成。
保证系统级吞吐（system-wide throughput）以及无线程饥饿。
截止2011年，没有多少具体的实现。即使实现了，也需要依赖于具体CPU。
 
lock-free
允许个别线程饥饿，但保证系统级吞吐。
确保至少有一个线程能够继续执行。
wait-free的算法必定也是lock-free的。
 
obstruction-free
在任何时间点，一个线程被隔离为一个事务进行执行（其他线程suspended），并且在有限步骤内完成。在执行过程中，一旦发现数据被修改（采用时间戳、版本号），则回滚。
也叫做乐观锁，即乐观并发控制(OOC)。事务的过程是：1读取，并写时间戳；2准备写入，版本校验；3校验通过则写入，校验不通过，则回滚。
lock-free必定是obstruction-free的。

CAS原语
LL/SC, atom read-modify-write
如果CPU提供了Load-Link/Store-Conditional（LL/SC）这对指令，则就可以轻松实现变量的CPU级别无锁同步。
LL [addr],dst：从内存[addr]处读取值到dst。
SC value,[addr]：对于当前线程，自从上次的LL动作后内存值没有改变，就更新成新值。
上述过程就是实现lock-free的 read-modify-write 的原子操作。
 
CAS （Compare-And-Swap）
LL/SC这对CPU指令没有实现，那么就需要寻找其他算法，比如CAS。
CAS是一组原语指令，用来实现多线程下的变量同步。
在 x86 下的指令CMPXCHG实现了CAS，前置LOCK既可以达到原子性操作。截止2013，大部分多核处理器均支持CAS。
CAS原语有三个参数，内存地址，期望值，新值。如果内存地址的值==期望值，表示该值未修改，此时可以修改成新值。否则表示修改失败，返回false，由用户决定后续操作。

Bool CAS(T* addr, T expected, T newValue) 
 { 
      if( *addr == expected ) 
     { 
          *addr =  newValue; 
           return true; 
     } 
     else 
           return false; 
 }


 
ABA 问题
thread1意图对val=1进行操作变成2，cas(*val,1,2)。
thread1先读取val=1；thread1被抢占（preempted），让thread2运行。
thread2 修改val=3，又修改回1。
thread1继续执行，发现期望值与“原值”（其实被修改过了）相同，完成CAS操作。
 
使用CAS会造成ABA问题，特别是在使用指针操作一些并发数据结构时。
 
解决方案
ABAʹ：添加额外的标记用来指示是否被修改。

语言实现
Java demo
AtomicInteger atom = new AtomicInteger(1);
boolean r = atom.compareAndSet(1, 2);
 
C# demo
int i=1;
Interlocked.Increment(ref i);


9讲下微服务？
一、单块架构的优缺点：
优点：
易于开发： 开发方式简单，IDE 支持好，方便运行和调试。
易于测试： 所有功能运行在一个进程中，一旦进程启动，便可以进行系统测试。
易于部署： 只需要将打好的一个软件包发布到服务器即可。
易于水平伸缩： 只需要创建一个服务器节点，配置好运行时环境，再将软件包发布到新服务器节点即可运行程序（当然也需要采取分发策略保证请求能有效地分发到新节点）。
缺点：
维护成本大： 当应用程序的功能越来越多、团队越来越大时，沟通成本、管理成本显著增加。当出现 bug 时，可能引起 bug 的原因组合越来越多，导致分析、定位和修复的成本增加；并且在对全局功能缺乏深度理解的情况下，容易在修复 bug 时引入新的 bug。
持续交付周期长： 构建和部署时间会随着功能的增多而增加，任何细微的修改都会触发部署流水线。
新人培养周期长： 新成员了解背景、熟悉业务和配置环境的时间越来越长。
技术选型成本高： 单块架构倾向于采用统一的技术平台或方案来解决所有问题，如果后续想引入新的技术或框架，成本和风险都很大。
可扩展性差： 随着功能的增加，垂直扩展的成本将会越来越大；而对于水平扩展而言，因为所有代码都运行在同一个进程，没办法做到针对应用程序的部分功能做独立的扩展。


二、微服务本质：
1. 服务作为组件
微服务也可以被认为是一种组件，但是跟传统组件的区别在于它可以独立部署，因此它的一个显著的优势。另外一个优点是，它在组件与组件之间定义了清晰的、语言无关、平台无关的规范接口，耦合度低，灵活性非常高。但它的不足之处是，分布式调用严重依赖于网络的可靠性和稳定性。

2. 围绕业务组织团队
在单块架构中，企业一般会根据技能划分团队，在这种组织架构下，即便是简单的需求变更都有可能需要跨团队协作，沟通成本很高。而在微服务架构中，它提倡以业务为核心，按照业务能力来组织团队，团队中的成员具有多样性的技能。

3. 关注产品而非项目
在单块架构中，应用基本上是基于“项目模式”构建的，即项目启动时从不同技能资源池中抽取相关资源组成团队，项目结束后释放所有资源。这种情况下团队成员缺乏主人翁意识和产品成就感。
在微服务架构中，提倡采用“产品模式”构建，即更倾向于让团队负责整个服务的生命周期，以便提供更优质的服务。

4. 技术多样性
微服务架构中，提倡针对不同的业务特征选择合适的技术方案，有针对性的解决具体业务问题，而不是像单块架构中采用统一的平台或技术来解决所有问题。

5. 业务数据独立
微服务架构提供自主管理其相关的业务数据，这样可以随着业务的发展提供数据接口集成，而不是以数据库的方式同其他服务集成。另外，随着业务的发展，可以方便地选择更合的工具管理或者迁移业务数据。

6. 基础设施自动化
在微服务架构的实践过程中，对持续交付和部署流水线的要求很高，将促进企业不断寻找更高效的方式完成基础设施的自动化及 DevOps 运维能力的提升。


三、微服务的挑战：
1. 分布式系统的复杂性
微服务架构是基于分布式的系统，而构建分布式系统必然会带来额外的开销。
性能： 分布式系统是跨进程、跨网络的调用，受网络延迟和带宽的影响。
可靠性： 由于高度依赖于网络状况，任何一次的远程调用都有可能失败，随着服务的增多还会出现更多的潜在故障点。因此，如何提高系统的可靠性、降低因网络引起的故障率，是系统构建的一大挑战。
异步： 异步通信大大增加了功能实现的复杂度，并且伴随着定位难、调试难等问题。
数据一致性： 要保证分布式系统的数据强一致性，成本是非常高的，需要在 C（一致性）A（可用性）P（分区容错性） 三者之间做出权衡。

2. 运维成本
运维主要包括配置、部署、监控与告警和日志收集四大方面。微服务架构中，每个服务都需要独立地配置、部署、监控和收集日志，成本呈指数级增长。

3. 自动化部署
在微服务架构中，每个服务都独立部署，交付周期短且频率高，人工部署已经无法适应业务的快速变化。因此如何有效地构建自动化部署体系，是微服务面临的另一个挑战。

4. DevOps 与组织架构
在微服务架构的实施过程中，开发人员和运维人员的角色发生了变化，开发者将承担起整个服务的生命周期的责任，包括部署和监控；而运维则更倾向于顾问式的角色，尽早考虑服务如何部署。因此，按需调整组织架构、构建全功能的团队，也是一个不小的挑战。

5. 服务间的依赖测试
单块架构中，通常使用集成测试来验证依赖是否正常。而在微服务架构中，服务数量众多，每个服务都是独立的业务单元，服务主要通过接口进行交互，如何保证依赖的正常，是测试面临的主要挑战。

6. 服务间的依赖管理
微服务架构中，服务数量众多，如何清晰有效地展示服务间的依赖关系也是个不小的挑战。



10怎么解决跨域问题？
1 JSONP
    　　JSONP是JSON with Padding的略称。它是一个非官方的协议，它允许在服务器端集成Script tags返回至客户端，通过javascript callback的形式实现跨域访问（这仅仅是JSONP简单的实现形式）。关于jsonp的使用方式，可以参考http://blog.csdn.net/alen1985/article/details/6365394，优缺点可以参考http://blog.csdn.net/z69183787/article/details/19191385　　

    2 添加响应头，允许跨域
    　　addHeader(‘Access-Control-Allow-Origin:*’);//允许所有来源访问
    　　addHeader(‘Access-Control-Allow-Method:POST,GET’);//允许访问的方式

    3 代理的方式
    服务器A的test01.html页面想访问服务器B的后台action，返回“test”字符串，此时就出现跨域请求，浏览器控制台会出现报错提示，由于跨域是浏览器的同源策略造成的，对于服务器后台不存在该问题，可以在服务器A中添加一个代理action，在该action中完成对服务器B中action数据的请求，然后在返回到test01.html页面。



11负载均衡一般几种算法？
负载均衡，英文 名称为Load Balance，指由多台服务器以对称的方式组成一个服务器集合，每台服务器都具有等价的地位，都可以单独对外提供服务而无须其他服务器的辅助。通过某种 负载分担技术，将外部发送来的请求均匀分配到对称结构中的某一台服务器上，而接收到请求的服务器独立地回应客户的请求。负载均衡能够平均分配客户请求到服 务器阵列，借此提供快速获取重要数据，解决大量并发访问服务问题，这种集群技术可以用最少的投资获得接近于大型主机的性能。
负载均衡分为软件负载均衡和硬件负载均衡，前者的代表是阿里章文嵩博士研发的LVS，后者则是均衡服务器比如F5，当然这只是提一下，不是重点。
本文讲述的是"将外部发送来的请求均匀分配到对称结构中的某一台服务器上"的各种算法，并以Java代码演示每种算法的具体实现，OK，下面进入正题，在进入正题前，先写一个类来模拟Ip列表：
1 public class IpMap
2 {
3     // 待路由的Ip列表，Key代表Ip，Value代表该Ip的权重
4     public static HashMap<String, Integer> serverWeightMap = 
5             new HashMap<String, Integer>();
6     
7     static
8     {
9         serverWeightMap.put("192.168.1.100", 1);
10         serverWeightMap.put("192.168.1.101", 1);
11         // 权重为4
12         serverWeightMap.put("192.168.1.102", 4);
13         serverWeightMap.put("192.168.1.103", 1);
14         serverWeightMap.put("192.168.1.104", 1);
15         // 权重为3
16         serverWeightMap.put("192.168.1.105", 3);
17         serverWeightMap.put("192.168.1.106", 1);
18         // 权重为2
19         serverWeightMap.put("192.168.1.107", 2);
20         serverWeightMap.put("192.168.1.108", 1);
21         serverWeightMap.put("192.168.1.109", 1);
22         serverWeightMap.put("192.168.1.110", 1);
23     }
24 }


轮询（Round Robin）法
轮询法即Round Robin法，其代码实现大致如下：
1 public class RoundRobin
2 {
3     private static Integer pos = 0;
4     
5     public static String getServer()
6     {
7         // 重建一个Map，避免服务器的上下线导致的并发问题
8         Map<String, Integer> serverMap = 
9                 new HashMap<String, Integer>();
10         serverMap.putAll(IpMap.serverWeightMap);
11         
12         // 取得Ip地址List
13         Set<String> keySet = serverMap.keySet();
14         ArrayList<String> keyList = new ArrayList<String>();
15         keyList.addAll(keySet);
16         
17         String server = null;
18         synchronized (pos)
19         {
20             if (pos > keySet.size())
21                 pos = 0;
22             server = keyList.get(pos);
23             pos ++;
24         }
25         
26         return server;
27     }
28 }
由于serverWeightMap中的地址列表是动态的，随时可能有机器上线、 下线或者宕机，因此为了避免可能出现的并发问题，方法内部要新建局部变量serverMap，现将serverMap中的内容复制到线程本地，以避免被多 个线程修改。这样可能会引入新的问题，复制以后serverWeightMap的修改无法反映给serverMap，也就是说这一轮选择服务器的过程中， 新增服务器或者下线服务器，负载均衡算法将无法获知。新增无所谓，如果有服务器下线或者宕机，那么可能会访问到不存在的地址。因此，服务调用端需要有相应的容错处理，比如重新发起一次server选择并调用。
对于当前轮询的位置变量pos，为了保证服务器选择的顺序性，需要在操作时对其加锁，使得同一时刻只能有一个线程可以修改pos的值，否则当pos变量被并发修改，则无法保证服务器选择的顺序性，甚至有可能导致keyList数组越界。
轮询法的优点在于：试图做到请求转移的绝对均衡。
轮询法的缺点在于：为了做到请求转移的绝对均衡，必须付出相当大的代价，因为为了保证pos变量修改的互斥性，需要引入重量级的悲观锁synchronized，这将会导致该段轮询代码的并发吞吐量发生明显的下降。


随机（Random）法
通过系统随机函数，根据后端服务器列表的大小值来随机选择其中一台进行访问。由概率统计理论可以得知，随着调用量的增大，其实际效果越来越接近于平均分配流量到每一台后端服务器，也就是轮询的效果。
随机法的代码实现大致如下：
1 public class Random
2 {
3     public static String getServer()
4     {
5         // 重建一个Map，避免服务器的上下线导致的并发问题
6         Map<String, Integer> serverMap = 
7                 new HashMap<String, Integer>();
8         serverMap.putAll(IpMap.serverWeightMap);
9         
10         // 取得Ip地址List
11         Set<String> keySet = serverMap.keySet();
12         ArrayList<String> keyList = new ArrayList<String>();
13         keyList.addAll(keySet);
14         
15         java.util.Random random = new java.util.Random();
16         int randomPos = random.nextInt(keyList.size());
17         
18         return keyList.get(randomPos);
19     }
20 }
整体代码思路和轮询法一致，先重建serverMap，再获取到server列表。在选取server的时候，通过Random的nextInt方法取0~keyList.size()区间的一个随机值，从而从服务器列表中随机获取到一台服务器地址进行返回。基于概率统计的理论，吞吐量越大，随机算法的效果越接近于轮询算法的效果。


源地址哈希（Hash）法
源地址哈希的思想是获取客户端访问的IP地址值，通过哈希函数计算得到一个数值，用该数值对服务器列表的大小进行取模运算，得到的结果便是要访问的服务器的序号。源地址哈希算法的代码实现大致如下：
1 public class Hash
2 {
3     public static String getServer()
4     {
5         // 重建一个Map，避免服务器的上下线导致的并发问题
6         Map<String, Integer> serverMap = 
7                 new HashMap<String, Integer>();
8         serverMap.putAll(IpMap.serverWeightMap);
9         
10         // 取得Ip地址List
11         Set<String> keySet = serverMap.keySet();
12         ArrayList<String> keyList = new ArrayList<String>();
13         keyList.addAll(keySet);
14         
15         // 在Web应用中可通过HttpServlet的getRemoteIp方法获取
16         String remoteIp = "127.0.0.1";
17         int hashCode = remoteIp.hashCode();
18         int serverListSize = keyList.size();
19         int serverPos = hashCode % serverListSize;
20         
21         return keyList.get(serverPos);
22     }
23 }
前两部分和轮询法、随机法一样就不说了，差别在于路由选择部分。通过客户端的ip也就是remoteIp，取得它的Hash值，对服务器列表的大小取模，结果便是选用的服务器在服务器列表中的索引值。
源地址哈希法的优点在于：保证了相同客户端IP地址将会被哈希到同一台后端服务器，直到后端服务器列表变更。根据此特性可以在服务消费者与服务提供者之间建立有状态的session会话。
源地址哈希算法的缺点在于：除非集群中服务器的非常稳定，基本不会上下线，否则一旦有服务器上线、下线，那么通过源地址哈希算法路由到的服务器是服务器上线、下线前路由到的服务器的概率非常低，如果是session则取不到session，如果是缓存则可能引发"雪崩"。如果这么解释不适合明白，可以看我之前的一篇文章MemCache超详细解读，一致性Hash算法部分。


加权轮询（Weight Round Robin）法
不同的服务器可能机器配置和当前系统的负载并不相同，因此它们的抗压能力也不尽相 同，给配置高、负载低的机器配置更高的权重，让其处理更多的请求，而低配置、高负载的机器，则给其分配较低的权重，降低其系统负载。加权轮询法可以很好地 处理这一问题，并将请求顺序按照权重分配到后端。加权轮询法的代码实现大致如下：
1 public class WeightRoundRobin
2 {
3     private static Integer pos;
4     
5     public static String getServer()
6     {
7         // 重建一个Map，避免服务器的上下线导致的并发问题
8         Map<String, Integer> serverMap = 
9                 new HashMap<String, Integer>();
10         serverMap.putAll(IpMap.serverWeightMap);
11         
12         // 取得Ip地址List
13         Set<String> keySet = serverMap.keySet();
14         Iterator<String> iterator = keySet.iterator();
15         
16         List<String> serverList = new ArrayList<String>();
17         while (iterator.hasNext())
18         {
19             String server = iterator.next();
20             int weight = serverMap.get(server);
21             for (int i = 0; i < weight; i++)
22                 serverList.add(server);
23         }
24         
25         String server = null;
26         synchronized (pos)
27         {
28             if (pos > keySet.size())
29                 pos = 0;
30             server = serverList.get(pos);
31             pos ++;
32         }
33         
34         return server;
35     }
36 }
与轮询法类似，只是在获取服务器地址之前增加了一段权重计算的代码，根据权重的大小，将地址重复地增加到服务器地址列表中，权重越大，该服务器每轮所获得的请求数量越多。


加权随机（Weight Random）法
与加权轮询法类似，加权随机法也是根据后端服务器不同的配置和负载情况来配置不同的权重。不同的是，它是按照权重来随机选择服务器的，而不是顺序。加权随机法的代码实现如下：
1 public class WeightRandom
2 {
3     public static String getServer()
4     {
5         // 重建一个Map，避免服务器的上下线导致的并发问题
6         Map<String, Integer> serverMap = 
7                 new HashMap<String, Integer>();
8         serverMap.putAll(IpMap.serverWeightMap);
9         
10         // 取得Ip地址List
11         Set<String> keySet = serverMap.keySet();
12         Iterator<String> iterator = keySet.iterator();
13         
14         List<String> serverList = new ArrayList<String>();
15         while (iterator.hasNext())
16         {
17             String server = iterator.next();
18             int weight = serverMap.get(server);
19             for (int i = 0; i < weight; i++)
20                 serverList.add(server);
21         }
22         
23         java.util.Random random = new java.util.Random();
24         int randomPos = random.nextInt(serverList.size());
25         
26         return serverList.get(randomPos);
27     }
28 }
这段代码相当于是随机法和加权轮询法的结合，比较好理解，就不解释了。


最小连接数（Least Connections）法
前面几种方法费尽心思来实现服务消费者请求次数分配的均衡，当然这么做是没错的，可以为后端的多台服务器平均分配工作量，最大程度地提高服务器的利用率，但是实际情况是否真的如此？实际情况中，请求次数的均衡真的能代表负载的均衡吗？这是一个值得思考的问题。
上面的问题，再换一个角度来说就是：以后端服务器的视角来观察系统的负载，而非请求发起方来观察。最小连接数法便属于此类。
最小连接数算法比较灵活和智能，由于后端服务器的配置不尽相同，对于请求的处理有 快有慢，它正是根据后端服务器当前的连接情况，动态地选取其中当前积压连接数最少的一台服务器来处理当前请求，尽可能地提高后端服务器的利用效率，将负载 合理地分流到每一台机器。由于最小连接数设计服务器连接数的汇总和感知，设计与实现较为繁琐，此处就不说它的实现了。



12 Zookeeper最少几个节点分别是什么？怎么实现选举？如何做到多个系统访问同一个资源的强一致性？如何保证挂机数据的备份一致性？
一、在zookeeper的选举过程中，为了保证选举过程最后能选出leader，就一定不能出现两台机器得票相同的僵局，所以一般的，要求zk集群的server数量一定要是奇数，也就是2n+1台，
并且，如果集群出现问题，其中存活的机器必须大于n+1台，否则leader无法获得多数server的支持，系统就自动挂掉。所以一般是3个或者3个以上节点。
群首（leader），追随者（follower），观察者（observer）。
Leader，作为整个ZooKeeper集群的主节点，负责响应所有对ZooKeeper状态变更的请求。它会将每个状态更新请求进行排序和编号，以便保证整个集群内部消息处理的FIFO。
这里补充一下ZooKeeper的请求类型。对于exists，getData，getChildren等只读请求，收到该请求的zk服务器将会在本地处理，因为由第一讲的ZAB理论可知，每个服务器看到的名字空间内容都是一致的，无所谓在哪台机器上读取数据，因此如果ZooKeeper集群的负载是读多写少，并且读请求分布得均衡的话，效率是很高的。对于create，setData，delete等有写操作的请求，则需要统一转发给leader处理，leader需要决定编号、执行操作，这个过程称为一个事务（transaction）。
事务的编号就不说了，ZAB一章中已经把zxid的格式说得很清楚，已经忘了的可以回头查阅，重点来说说事务的执行。ZooKeeper事务和关系型数据库事务相似之处是都具备原子性，即整个事务（编号+执行）要么一起成功要么一起失败。另外事务还具备幂等性，即对一个事务执行多次，结果永远都是一致的。但ZooKeeper事务不具备关系型数据库事务的回滚机制，原因是不需要，因为ZAB协议已经保证消息是严格FIFO的，并且只有一个leader实际处理事务。（回忆两阶段提交2PC，之所以需要2PC的原因，归根结底是有不止一个“主”，必须保证这么多“主”看到的结果都是一致的）
Follower，Follower的逻辑就比较简单了。除了响应本服务器上的读请求外，follower还要处理leader的提议，并在leader提交该提议时在本地也进行提交。Follower处理提议的过程已经在ZAB一章中描述过了。
另外需要注意的是，leader和follower构成ZooKeeper集群的法定人数，也就是说，只有他们才参与新leader的选举、响应leader的提议。
Observer，如果ZooKeeper集群的读取负载很高，或者客户端多到跨机房，可以设置一些observer服务器，以提高读取的吞吐量。Observer和Follower比较相似，只有一些小区别：首先observer不属于法定人数，即不参加选举也不响应提议；其次是observer不需要将事务持久化到磁盘，一旦observer被重启，需要从leader重新同步整个名字空间。

二、ZooKeeper的工作原理
Zookeeper的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议。Zab协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态。
为了保证事务的顺序一致性，zookeeper采用了递增的事务id号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上了zxid。实现中zxid是一个64位的数字，它高32位是epoch用来标识leader关系是否改变，每次一个leader被选出来，它都会有一个新的epoch，标识当前属于那个leader的统治时期。低32位用于递增计数。
每个Server在工作过程中有三种状态：
LOOKING：当前Server不知道leader是谁，正在搜寻
LEADING：当前Server即为选举出来的leader
FOLLOWING：leader已经选举出来，当前Server与之同步

三、 选主流程
当leader崩溃或者leader失去大多数的follower，这时候zk进入恢复模式，恢复模式需要重新选举出一个新的leader，让所有的Server都恢复到一个正确的状态。Zk的选举算法有两种：一种是基于basic paxos实现的，另外一种是基于fast paxos算法实现的。系统默认的选举算法为fast paxos。先介绍basic paxos流程：
1 .选举线程由当前Server发起选举的线程担任，其主要功能是对投票结果进行统计，并选出推荐的Server；
2 .选举线程首先向所有Server发起一次询问(包括自己)；
3 .选举线程收到回复后，验证是否是自己发起的询问(验证zxid是否一致)，然后获取对方的id(myid)，并存储到当前询问对象列表中，最后获取对方提议的leader相关信息(id,zxid)，并将这些信息存储到当次选举的投票记录表中；
4.  收到所有Server回复以后，就计算出zxid最大的那个Server，并将这个Server相关信息设置成下一次要投票的Server；
5.  线程将当前zxid最大的Server设置为当前Server要推荐的Leader，如果此时获胜的Server获得n/2 + 1的Server票数， 设置当前推荐的leader为获胜的Server，将根据获胜的Server相关信息设置自己的状态，否则，继续这个过程，直到leader被选举出来。
通过流程分析我们可以得出：要使Leader获得多数Server的支持，则Server总数必须是奇数2n+1，且存活的Server的数目不得少于n+1.
每个Server启动后都会重复以上流程。在恢复模式下，如果是刚从崩溃状态恢复的或者刚启动的server还会从磁盘快照中恢复数据和会话信息，zk会记录事务日志并定期进行快照，方便在恢复时进行状态恢复。选主的具体流程图如下所示：
fast paxos流程是在选举过程中，某Server首先向所有Server提议自己要成为leader，当其它Server收到提议以后，解决epoch和zxid的冲突，并接受对方的提议，然后向对方发送接受提议完成的消息，重复这个流程，最后一定能选举出Leader。其流程图如下所示：

四、强一致性如何保证
ZooKeeper是个集群，内部有多个server，每个server都可以连接多个client，每个client都可以修改server中的数据
ZooKeeper可以保证每个server内的数据完全一致，是如何实现的呢？
答：数据一致性是靠Paxos算法保证的，Paxos可以说是分布式一致性算法的鼻祖，是ZooKeeper的基础
Paxos的基本思路：(深入解读zookeeper一致性原理)
假设有一个社团，其中有团员、议员（决议小组成员）两个角色
团员可以向议员申请提案来修改社团制度
议员坐在一起，拿出自己收到的提案，对每个提案进行投票表决，超过半数通过即可生效
为了秩序，规定每个提案都有编号ID，按顺序自增
每个议员都有一个社团制度笔记本，上面记着所有社团制度，和最近处理的提案编号，初始为0
投票通过的规则：
新提案ID 
是否大于 议员本中的ID，是议员举手赞同
如果举手人数大于议员人数的半数，即让新提案生效
例如：
刚开始，每个议员本子上的ID都为0，现在有一个议员拿出一个提案：团费降为100元，这个提案的ID自增为1
每个议员都和自己ID对比，一看 
1>0，举手赞同，同时修改自己本中的ID为1
发出提案的议员一看超过半数同意，就宣布：1号提案生效
然后所有议员都修改自己笔记本中的团费为100元
以后任何一个团员咨询任何一个议员："团费是多少？"，议员可以直接打开笔记本查看，并回答：团费为100元
可能会有极端的情况，就是多个议员一起发出了提案，就是并发的情况
例如
刚开始，每个议员本子上的编号都为0，现在有两个议员（A和B）同时发出了提案，那么根据自增规则，这两个提案的编号都为1，但只会有一个被先处理
假设A的提案在B的上面，议员们先处理A提案并通过了，这时，议员们的本子上的ID已经变为了1，接下来处理B的提案，由于它的ID是1，不大于议员本子上的ID，B提案就被拒绝了，B议员需要重新发起提案
上面就是Paxos的基本思路，对照ZooKeeper，对应关系就是：
团员 -client
议员 -server
议员的笔记本 -server中的数据
提案 -变更数据的请求
提案编号 -zxid（ZooKeeper Transaction Id）
提案生效 -执行变更数据的操作
ZooKeeper中还有一个leader的概念，就是把发起提案的权利收紧了，以前是每个议员都可以发起提案，现在有了leader，大家就不要七嘴八舌了，先把提案都交给leader，由leader一个个发起提案
Paxos算法就是通过投票、全局编号机制，使同一时刻只有一个写操作被批准，同时并发的写操作要去争取选票，只有获得过半数选票的写操作才会被批准，所以永远只会有一个写操作得到批准，其他的写操作竞争失败只好再发起一轮投票

1）一致性保证
Zookeeper 是一种高性能、可扩展的服务。 Zookeeper 的读写速度非常快，并且读的速度要比写的速度更快。另外，在进行读操作的时候， ZooKeeper 依然能够为旧的数据提供服务。这些都是由于 ZooKeepe 所提供的一致性保证，它具有如下特点：
顺序一致性
客户端的更新顺序与它们被发送的顺序相一致。
原子性
更新操作要么成功要么失败，没有第三种结果。
单系统镜像
无论客户端连接到哪一个服务器，客户端将看到相同的 ZooKeeper 视图。
可靠性
一旦一个更新操作被应用，那么在客户端再次更新它之前，它的值将不会改变。。这个保证将会产生下面两种结果：
1 ．如果客户端成功地获得了正确的返回代码，那么说明更新已经成果。如果不能够获得返回代码（由于通信错误、超时等等），那么客户端将不知道更新操作是否生效。
2 ．当从故障恢复的时候，任何客户端能够看到的执行成功的更新操作将不会被回滚。
实时性
在特定的一段时间内，客户端看到的系统需要被保证是实时的（在十几秒的时间里）。在此时间段内，任何系统的改变将被客户端看到，或者被客户端侦测到。
给予这些一致性保证， ZooKeeper 更高级功能的设计与实现将会变得非常容易，例如： leader 选举、队列以及可撤销锁等机制的实现。

2）Leader选举
ZooKeeper 需要在所有的服务（可以理解为服务器）中选举出一个 Leader ，然后让这个 Leader 来负责管理集群。此时，集群中的其它服务器则成为此 Leader 的 Follower 。并且，当 Leader 故障的时候，需要 ZooKeeper能够快速地在 Follower 中选举出下一个 Leader 。这就是 ZooKeeper 的 Leader 机制，下面我们将简单介绍在ZooKeeper 中， Leader 选举（ Leader Election ）是如何实现的。
此操作实现的核心思想是：首先创建一个 EPHEMERAL 目录节点，例如“ /election ”。然后。每一个ZooKeeper 服务器在此目录下创建一个 SEQUENCE| EPHEMERAL 类型的节点，例如“ /election/n_ ”。在SEQUENCE 标志下， ZooKeeper 将自动地为每一个 ZooKeeper 服务器分配一个比前一个分配的序号要大的序号。此时创建节点的 ZooKeeper 服务器中拥有最小序号编号的服务器将成为 Leader 。
在实际的操作中，还需要保障：当 Leader 服务器发生故障的时候，系统能够快速地选出下一个 ZooKeeper 服务器作为 Leader 。一个简单的解决方案是，让所有的 follower 监视 leader 所对应的节点。当 Leader 发生故障时， Leader 所对应的临时节点将会自动地被删除，此操作将会触发所有监视 Leader 的服务器的 watch 。这样这些服务器将会收到 Leader 故障的消息，并进而进行下一次的 Leader 选举操作。但是，这种操作将会导致“从众效应”的发生，尤其当集群中服务器众多并且带宽延迟比较大的时候，此种情况更为明显。
在 Zookeeper 中，为了避免从众效应的发生，它是这样来实现的：每一个 follower 对 follower 集群中对应的比自己节点序号小一号的节点（也就是所有序号比自己小的节点中的序号最大的节点）设置一个 watch 。只有当follower 所设置的 watch 被触发的时候，它才进行 Leader 选举操作，一般情况下它将成为集群中的下一个 Leader。很明显，此 Leader 选举操作的速度是很快的。因为，每一次 Leader 选举几乎只涉及单个 follower 的操作。



13 依赖注入有什么优势？
优点
传统的代码，每个对象负责管理与自己需要依赖的对象，导致如果需要切换依赖对象的实现类时，需要修改多处地方。同时，过度耦合也使得对象难以进行单元测试。
依赖注入把对象的创造交给外部去管理,很好的解决了代码紧耦合（tight couple）的问题，是一种让代码实现松耦合（loose couple）的机制。
松耦合让代码更具灵活性，能更好地应对需求变动，以及方便单元测试。

缺点
在java语言中基本采用反射的方式来实现依赖注入，在一定程度会影响性能


14 为什么cglib可以代理class，jdk只能代理接口?
1.JDK动态代理
此时代理对象和目标对象实现了相同的接口，目标对象作为代理对象的一个属性，具体接口实现中，可以在调用目标对象相应方法前后加上其他业务处理逻辑。
代理模式在实际使用时需要指定具体的目标对象，如果为每个类都添加一个代理类的话，会导致类很多，同时如果不知道具体类的话，怎样实现代理模式呢？这就引出动态代理。
JDK动态代理只能针对实现了接口的类生成代理。

2.CGLIB代理
CGLIB（CODE GENERLIZE LIBRARY）代理是针对类实现代理，主要是对指定的类生成一个子类，覆盖其中的所有方法，所以该类或方法不能声明称final的。
如果目标对象没有实现接口，则默认会采用CGLIB代理；
如果目标对象实现了接口，可以强制使用CGLIB实现代理（添加CGLIB库，并在spring配置中加入<aop:aspectj-autoproxy proxy-target-class="true"/>）。
AOP包括切面（aspect）、通知（advice）、连接点（joinpoint），实现方式就是通过对目标对象的代理在连接点前后加入通知，完成统一的切面操作。



15 Mybatis底层执行SQL语句的过程是什么？接口实现类怎么生成的？
mybatis在java开发中已经成为主流，它有很多优点，例如
1. 易于上手和掌握。
2. sql写在xml里，便于统一管理和优化。
3. 解除sql与程序代码的耦合。
4. 提供映射标签，支持对象与数据库的orm字段关系映射
5. 提供对象关系映射标签，支持对象关系组建维护
6. 提供xml标签，支持编写动态sql。
Controller调用service
service有实现类serviceImpl
serviceImpl调用DAO
但是，不用写DAO的实现，你知道这是为什么吗？

一：配置spring集成mybatis
<bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean">
<property name="dataSource" ref="dataSource" />
<property name="configLocation" value="classpath:conf/mybatis/config.xml"/>
</bean>  

要实现对数据库的操作就要有sqlSession,而sqlSession就是有sqlSessionFactory创建的。
<bean class="org.mybatis.spring.mapper.MapperScannerConfigurer">
<property name="basePackage" value="com.lzz.aspp.**.dao,com.lzz.lsp.**.dao" />
</bean>
这段配置主要是配置映射文件的路径，这样做的好处就是不用写Dao的实现了，简单的说就是接好接口，写好映射文件 会自动映射到方法和sql语句。

二底层原理：
mybatis通过JDK的动态代理方式，在启动加载配置文件时，根据配置mapper的xml去生成Dao的实现。
session.getMapper()使用了代理，当调用一次此方法，都会产生一个代理class的instance,看看这个代理class的实现.
public class MapperProxy implements InvocationHandler { 
... 
public static <T> T newMapperProxy(Class<T> mapperInterface, SqlSession sqlSession) { 
ClassLoader classLoader = mapperInterface.getClassLoader(); 
Class<?>[] interfaces = new Class[]{mapperInterface}; 
MapperProxy proxy = new MapperProxy(sqlSession); 
return (T) Proxy.newProxyInstance(classLoader, interfaces, proxy); 
} 
public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { 
if (!OBJECT_METHODS.contains(method.getName())) { 
final Class<?> declaringInterface = findDeclaringInterface(proxy, method); 
final MapperMethod mapperMethod = new MapperMethod(declaringInterface, method, sqlSession); 
final Object result = mapperMethod.execute(args); 
if (result == null && method.getReturnType().isPrimitive()) { 
throw new BindingException("Mapper method '" + method.getName() + "' (" + method.getDeclaringClass() + ") attempted to return null from a method with a primitive return type (" +    method.getReturnType() + ")."); 
} 
return result; 
} 
return null; 
} 
这里是用到了JDK的代理Proxy。 newMapperProxy()可以取得实现interfaces 的class的代理类的实例。
当执行interfaces中的方法的时候，会自动执行invoke()方法，其中public Object invoke(Object proxy, Method method, Object[] args)中 method参数就代表你要执行的方法.
MapperMethod类会使用method方法的methodName 和declaringInterface去取 sqlMapxml 取得对应的sql，也就是拿declaringInterface的类全名加上 sqlid..



16 struts底层实现机制是什么？
一、strut2的处理流程
1、浏览器发出请求，即***.action
2、请求被核心控制器的StrutsPrepareAndExecuteFilter拦截
3、搜索struts.xml配置文件，寻找Action的属性name为***的配置信息，而后根据class属性，通过反射原理创建Action实例
actionInst
4、调用request.getParameterNames返回所有的请求参数名存入paramMap
使用循环（String paramName : paramMap.keySet()）//传入所有参数
{
//1、得到请求参数名对应的set方法
Method setter = Action类.getMethod("set"+paramName的首字母大写)
//2、获得参数名对应的参数值
String paramValue = paramMap.get(paramName)
//3、以Action实例为调用者，调用setter方法，把参数值作为参数传入
setter.invoke(actionInst , paramValue)
}
5、再次通过反射来调用method属性所指定的方法，返回一个字符串
6、根据字符串匹配struts.xml中<result>元素的属性name值，进行相对应物理视图的跳转
/**************附模拟核心控制器代码********************************/

二、底层机制
//自定义的Action类==========
1 class MyAction{
2 　　//待传值的参数
3     private String name ;
4     private String pass;
5 
6 　　//空构造函数
7     public MyAction() {
8     }
9 
10     public MyAction(String name, String pass) {
11         this.name = name;
12         this.pass = pass;
13     }
14 
15     public String getName() {
16         return name;
17     }
18 
19     public void setName(String name) {
20         this.name = name;
21     }
22 
23     public String getPass() {
24         return pass;
25     }
26 
27     public void setPass(String pass) {
28         this.pass = pass;
29     }
30 
31     public String regist(){
32         System.out.println("name----->"+name);
33         System.out.println("pass----->"+pass);
34         return "sucess";
35     }
36 }


//核心控制器==============
1 public class CoreFilter {
2 
3 
4     //模拟配置文件struts.xml
5     /**
6       <action name = "abc" class = "MyAcion" method = "regist">
7      　　<result name = "success">********.jsp</result>
8 　　　　　......
9      </action>
10      **/
11     public static void main(String[] args) throws Exception {
12         //假如控制器收到abc.action请求,通过解析structs.xml
13         String classProp = "MyAction";
14 
15         //反射原理：获取action类所对应的Class对象
16         Class actionClazz = Class.forName("test.MyAction");
17 
18         //利用Class对象得到类实例
19         Object actionInst = actionClazz.newInstance(); //此处要求action含有无参构造函数的原因
20 
21         //利用Map来模拟请求参数
22         // struct2的核心Filter用下面的代码。得到所有的请求<参数名--参数值>,组成Map
23         //Map<String , String > paramMap = request.getParamMap();
24         //相当于如下模拟过程：
25         Map <String,String> paramMap = new HashMap<String, String>();
26         paramMap.put("name","张三");
27         paramMap.put("pass","123");
28         for(String paramName : paramMap.keySet()){
29             //得到请求参数名对应的setter方法
30             //setName() and setPass()
31             Method setter = actionClazz.getMethod("set"
32                     +paramName.substring(0,1).toUpperCase()
33                     +paramName.substring(1),String.class);
34 
35             //得到请求参数对应的值
36             String paramValue = paramMap.get(paramName);
37 
38             //以Action实例为调用者，调用setter方法,吧参数值作为参数传入
39             setter.invoke(actionInst,paramValue);//主调者actionInst，参数值为paramValue
40         }
41         Method targetMethod = actionClazz.getMethod("regist");
42         String result = (String)targetMethod.invoke(actionInst);
43 
44         if(result.equals("某个result的name属性值")){
45             //request.getRequestDispatcher().forward()
46         }
47     }



17怎么保证集群中只有一个应用执行定时任务，该应用宕机了如何处理？
最近项目中，需要实现分布式的定时任务，结合项目现有的中间件和技术，设计出了2种简单分布式定时任务的实现（这里的前提是定时任务是可拆分的）
需求背景：由于DB需要通过定时任务执行数据清理，每天需要清理N个分库M张分表的线下渠道的数据。（N>20,M>=10）
所以初步设计的定时任务是拆分成了N*M个子任务，假设服务器的数量大于N*M。关键点就是如何实现分布式，让每个服务器都利用起来执行任务，以下是设计出的2种实现方案

一、基于zookeeper和redis实现的一种分布式定时任务
由于目前存在基于zookeeper开发出的支持分布式服务器的统一配置管理中间件，还有分布式redis缓存的中间件，所以设计出了基于zookeeper和redis的一种分布式定时任务。步骤如下：
1、修改任务配置
配置一个简单的定时任务，假设每天0点触发，仅由一台服务器执行任务，具体逻辑是：
修改统一配置中的归档任务文件中针对于该任务的节点内容：
[html] view plain copy
#数据清理任务  
clearArchive=【当前服务器唯一标识的信息即可】  （可以是IP+时间戳，需要保证每次任务触发的值都不一样）  
2、获取子任务
由于zookeeper的功能，修改内容会被所有的服务器监听到，此时可以进行数据清理任务的执行了。但如何保证所有服务器在N*M个子任务分配中，一台服务器仅分配一个子任务，且不会与其他服务器领取到的子任务重复呢（注意，此时属于高并发场景，所有服务器都会同时监听到）？这时就要用到分布式redis了，步骤如下：
a) 获取子任务号
遍历N*M次子任务的子任务号（由分库号+"-"+分表号+第一步获取的clearArchive对应的值构成），把该子任务号作为key,服务器ip等信息作为value进行setnx操作，若结果为0，表示已经被其他服务器获取到了，遍历下一个。若结果为1，表示获取成功，则返回此子任务号。
b) 若子任务号不为空，则表示该服务器成功领取了一个子任务了，根据该任务号，执行对应分库分表的数据清理任务。
分析：此设计方案可以保证每一台服务器仅执行一个子任务，可以达到分布式定时任务的处理效果，但缺陷是扩展性和适用性不够，若服务器的数量过小，若子任务过大，还是会存在服务器领取的子任务不均匀的现象。但在此种场景下，应该是比较适合的，目前的技术实现就是采用这种的。

二、内联MQ
1、技术背景
由于项目中存在中间件ActiveMQ消息队列和分布式缓存锁jedis，所以使用了ActiveMQ消息队列的本地通讯的实现。
2、实现步骤如下：
a) 配置一个简单的定时任务，假设每天0点触发，仅由一台服务器执行任务，发送N*M个对应不同分库号和分表号的MQ消息。
b) 集群的所有服务器进行消息的处理，根据消息里的分库号和分表号，进行对应子任务的处理，从而实现了分布式的定时任务处理。
综合来比较：内联MQ的方式相对实现简单，且仅需要配置对应的JMS和Listen即可，但缺点是服务器分布式处理的可能不均匀，有可能某台服务器处理了多条子任务，但往往能流传下来的都是简单的方式。


18 有没有开发过spring aop?什么场景？
AOP是Aspect Oriented Programing的简称，面向切面编程。AOP适合于那些具有横切逻辑的应用：如性能监测，访问控制，事务管理、缓存、对象池管理以及日志记录。AOP将这些分散在各个业务逻辑中的代码通过横向切割的方式抽取到一个独立的模块中。AOP 实现的关键就在于 AOP 框架自动创建的 AOP 代理，AOP 代理则可分为静态代理和动态代理两大类，其中静态代理是指使用 AOP 框架提供的命令进行编译，从而在编译阶段就可生成 AOP 代理类，因此也称为编译时增强；而动态代理则在运行时借助于 JDK 动态代理、CGLIB 等在内存中“临时”生成 AOP 动态代理类，因此也被称为运行时增强。
代理对象的方法 = 增强处理 + 被代理对象的方法
Spring AOP 则采用运行时生成 AOP 代理类，因此无需使用特定编译器进行处理。由于 Spring AOP 需要在每次运行时生成 AOP 代理，因此性能略差一些。

一、AOP使用场景
AOP用来封装横切关注点，具体可以在下面的场景中使用
Authentication 权限
Caching 缓存
Context passing 内容传递
Error handling 错误处理
Lazy loading 懒加载
Debugging 调试
logging, tracing, profiling and monitoring 记录跟踪 优化 校准
Performance optimization 性能优化
Persistence 持久化
Resource pooling 资源池
Synchronization 同步
Transactions 事务

二、AOP相关概念
方面（Aspect）：一个关注点的模块化，这个关注点实现可能另外横切多个对象。事务管理是J2EE应用中一个很好的横切关注点例子。方面用Spring的 Advisor或拦截器实现。
连接点（Joinpoint）: 程序执行过程中明确的点，如方法的调用或特定的异常被抛出
通知（Advice）: 在特定的连接点，AOP框架执行的动作。各种类型的通知包括“around”、“before”和“throws”通知。通知类型将在下面讨论。许多AOP框架包括Spring都是以拦截器做通知模型，维护一个“围绕”连接点的拦截器链。Spring中定义了四个advice: BeforeAdvice, AfterAdvice, ThrowAdvice和DynamicIntroductionAdvice
切入点（Pointcut）: 指定一个通知将被引发的一系列连接点的集合。AOP框架必须允许开发者指定切入点：例如，使用正则表达式。 Spring定义了Pointcut接口，用来组合MethodMatcher和ClassFilter，可以通过名字很清楚的理解， MethodMatcher是用来检查目标类的方法是否可以被应用此通知，而ClassFilter是用来检查Pointcut是否应该应用到目标类上
引入（Introduction）: 添加方法或字段到被通知的类。 Spring允许引入新的接口到任何被通知的对象。例如，你可以使用一个引入使任何对象实现 IsModified接口，来简化缓存。Spring中要使用Introduction, 可有通过DelegatingIntroductionInterceptor来实现通知，通过DefaultIntroductionAdvisor来配置Advice和代理类要实现的接口
目标对象（Target Object）: 包含连接点的对象。也被称作被通知或被代理对象。POJO
AOP代理（AOP Proxy）: AOP框架创建的对象，包含通知。 在Spring中，AOP代理可以是JDK动态代理或者CGLIB代理。
织入（Weaving）: 组装方面来创建一个被通知对象。这可以在编译时完成（例如使用AspectJ编译器），也可以在运行时完成。Spring和其他纯Java AOP框架一样，在运行时完成织入。

三、日志应用：
实现登陆和日志管理（使用Spring AOP
1）LoginService   LogService   TestMain
2）用Spring 管理  LoginService 和 LogService 的对象
3）确定哪些连接点是切入点，在配置文件中
4）将LogService封装为通知
5）将通知植入到切入点
6）客户端调用目标

<aop:config>
<aop:pointcut expression="execution(* cn.com.spring.service.impl.*.*(..))" id="myPointcut"/>
<!--将哪个-->
<aop:aspect id="dd" ref="logService">
<aop:before method="log" pointcut-ref="myPointcut"/>
</aop:aspect>
</aop:config>
execution(* * cn.com.spring.service.impl.*.*(..))
1)* 所有的修饰符
2)* 所有的返回类型
3)* 所有的类名
4)* 所有的方法名
5)* ..所有的参数名

1.ILoginService.java
package cn.com.spring.service;
public interface ILoginService {
public boolean login(String userName, String password);
}

2.LoginServiceImpl.java
package cn.com.spring.service.impl;
import cn.com.spring.service.ILoginService;
public class LoginServiceImpl implements ILoginService {
public boolean login(String userName, String password) {
System.out.println("login:" + userName + "," + password);
return true;
}
}

3.ILogService.java
package cn.com.spring.service;
import org.aspectj.lang.JoinPoint;
public interface ILogService {
//无参的日志方法
public void log();
//有参的日志方法
public void logArg(JoinPoint point);
//有参有返回值的方法
public void logArgAndReturn(JoinPoint point,Object returnObj);
}

4.LogServiceImpl.java
package cn.com.spring.service.impl;
import org.aspectj.lang.JoinPoint;
import cn.com.spring.service.ILogService;
public class LogServiceImpl implements ILogService {
@Override
public void log() {
System.out.println("*************Log*******************");
}
//有参无返回值的方法
public void logArg(JoinPoint point) {
//此方法返回的是一个数组，数组中包括request以及ActionCofig等类对象
Object[] args = point.getArgs();
System.out.println("目标参数列表：");
if (args != null) {
for (Object obj : args) {
System.out.println(obj + ",");
}
System.out.println();
}
}
//有参并有返回值的方法
public void logArgAndReturn(JoinPoint point, Object returnObj) {
//此方法返回的是一个数组，数组中包括request以及ActionCofig等类对象
Object[] args = point.getArgs();
System.out.println("目标参数列表：");
if (args != null) {
for (Object obj : args) {
System.out.println(obj + ",");
}
System.out.println();
System.out.println("执行结果是：" + returnObj);
}
}
}

5.applicationContext.java
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
xmlns:aop="http://www.springframework.org/schema/aop" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xmlns:p="http://www.springframework.org/schema/p"
xsi:schemaLocation="http://www.springframework.org/schema/beans
http://www.springframework.org/schema/beans/spring-beans-2.5.xsd
http://www.springframework.org/schema/aop
http://www.springframework.org/schema/aop/spring-aop-2.5.xsd">
<bean id="logService" class="cn.com.spring.service.impl.LogServiceImpl"></bean>
<bean id="loginService" class="cn.com.spring.service.impl.LoginServiceImpl"></bean>
<aop:config>
<!-- 切入点 -->
<aop:pointcut
expression="execution(* cn.com.spring.service.impl.LoginServiceImpl.*(..))"
id="myPointcut" />
<!-- 切面： 将哪个对象中的哪个方法，织入到哪个切入点 -->
<aop:aspect id="dd" ref="logService">
<!-- 前置通知
<aop:before method="log" pointcut-ref="myPointcut" />
<aop:after method="logArg" pointcut-ref="myPointcut">
-->
<aop:after-returning method="logArgAndReturn" returning="returnObj" pointcut-ref="myPointcut"/>
</aop:aspect>
</aop:config>
</beans>

6.TestMain.java
public class TestMain {
public static void testSpringAOP(){
ApplicationContext ctx = new ClassPathXmlApplicationContext("app*.xml");
ILoginService loginService = (ILoginService)ctx.getBean("loginService");
loginService.login("zhangsan", "12344");
}
public static void main(String[] args) {
testSpringAOP();
}
}

7.输出结果：
login:zhangsan,12344
目标参数列表：
zhangsan,
12344,
执行结果是：true
解析:1.先调用了login()方法System.out.println("login:" + userName + "," + password);



19 说说Spring boot ，有哪些好处？
优点：
1.去除了大量的xml配置文件
2.简化复杂的依赖管理
3.配合各种starter使用，基本上可以做到自动化配置
4.快速启动容器
5. 配合Maven或Gradle等构件工具打成Jar包后，Java -jar 进行部署运行还是蛮简单的，创建独立Spring应用程序，嵌入式Tomcat，Jetty容器，无需部署WAR包，简化Maven及Gradle配置，尽可能的自动化配置Spring，直接植入产品环境下的实用功能，比如度量指标、健康检查及扩展配置等，无需代码生成及XML配置。
缺点：
1.从原来的xml配置方式转换到JAVA配置方式变化有点大，不太适应
2.感觉Spring Boot 比较适合做微服务，不适合做比较大型的项目。


20 Spring transcation控制底层用什么技术实现的？
我们先来分析一下Spring事务管理机制的实现原理。由于Spring内置AOP默认使用动态代理模式实现，我们就先来分析一下动态代理模式的实现方 法。动态代理模式的核心就在于代码中不出现与具体应用层相关联的接口或者类引用，如上所说，这个代理类适用于任何接口的实现。下面我们来看一个例子。

public class TxHandler implements InvocationHandler {
private Object originalObject;
public Object bind(Object obj) {
　this.originalObject = obj;
　return Proxy.newProxyInstance(obj.getClass().getClassLoader(),obj.getClass().getInterfaces(),this);
}

public Object invoke(Object proxy, Method method, Object[] args)
throws Throwable {
　Object result = null;
　if (!method.getName().startsWith("save")) {
　　UserTransaction tx = null;
　　try {
　　　tx = (UserTransaction) (new InitialContext().lookup("java/tx"));
　　　result = method.invoke(originalObject, args);
　　　tx.commit();
　　} catch (Exception ex) {
　　　if (null != tx) {
　　　　try {
　　　　　tx.rollback();
　　　　} catch (Exception e) {
　　　}
　　}
　}
} else {
　result = method.invoke(originalObject, args);
}
return result;
}
}



下面我们来分析一下上述代码的关键所在。

首先来看一下这段代码：

return Proxy.newProxyInstance(
　obj.getClass().getClassLoader(),obj.getClass().getInterfaces(),this);
　 　java.lang.reflect.Proxy.newProxyInstance方法根据传入的接口类型 （obj.getClass.getInterfaces()）动态构造一个代理类实例返回，这也说明了为什么动态代理实现要求其所代理的对象一定要实现 一个接口。这个代理类实例在内存中是动态构造的，它实现了传入的接口列表中所包含的所有接口。

　　再来分析以下代码：


public Object invoke(Object proxy, Method method, Object[] args)
throws Throwable {
　……
　result = method.invoke(originalObject, args);
　……
　return result;
}

　 　InvocationHandler.invoke方法将在被代理类的方法被调用之前触发。通过这个方法，我们可以在被代理类方法调用的前后进行一些处 理，如代码中所示，InvocationHandler.invoke方法的参数中传递了当前被调用的方法（Method）,以及被调用方法的参数。同 时，可以通过method.invoke方法调用被代理类的原始方法实现。这样就可以在被代理类的方法调用前后写入任何想要进行的操作。
　 　Spring的事务管理机制实现的原理，就是通过这样一个动态代理对所有需要事务管理的Bean进行加载，并根据配置在invoke方法中对当前调用的 方法名进行判定，并在method.invoke方法前后为其加上合适的事务管理代码，这样就实现了Spring式的事务管理。Spring中的AOP实 现更为复杂和灵活，不过基本原理是一致的。





21对activiti流程引擎的理解，里面运用了什么设计模式？怎么部署流程？多少个表？哪个版本？里面的任务监听器？Execution和流程实例区别？怎么开发一个简单的命令模式？
一、Activiti表结构
5.18版本有23张表，支持多种关系数据库。
所有的表都以ACT_开头。 第二部分是表示表的用途的两个字母标识。 
ACT_RE_*: 'RE'表示repository。 这个前缀的表包含了流程定义和流程静态资源 （图片，规则，等等）。
ACT_RU_*: 'RU'表示runtime。 这些运行时的表，包含流程实例，任务，变量，异步任务，等运行中的数据。 Activiti只在流程实例执行过程中保存这些数据， 在流程结束时就会删除这些记录。 流程结束时会把runtime中的数据移入到history中，包括流程实例，任务，变量等。这样运行时的表可以一直很小保持在一个范围内，保证速度很快。
ACT_ID_*: 'ID'表示identity。 这些表包含身份信息，比如用户，组等等。
ACT_HI_*: 'HI'表示history。 这些表包含历史数据，比如历史流程实例， 变量，任务等等。
ACT_GE_*: 通用数据， 如存放资源文件

二、核心API
ProcessEngine 是Activiti中最核心的类，其他的类都是由他而来。
ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();
RepositoryService repositoryService =processEngine.getRepositoryService();
RuntimeService runtimeService = processEngine.getRuntimeService();
TaskService taskService =processEngine.getTaskService();

各个Service的作用：
RepositoryService	Activiti的仓库服务类。所谓的仓库指流程定义文档的两个文件：bpmn文件和流程图片
该service可以用来删除部署的流程定义。

RuntimeService	执行管理，包括启动，推进，删除流程实例等操作
TaskService	是activiti的任务服务类。可以从这个类中获取任务的相关信息，如当前正在执行的个人待办和用户组待办任务。

HistoryService	是activiti的查询历史信息的类，在一个流程执行完成后，这个对象为我们提供查询历史信息，可以跟踪流程实例对应所有待办节点的运行情况。

IdentityService	认证服务，在工作流执行过程中进行用户查询、认证等操作
FormService	Activiti表单引擎产生的用户任务表单服务


三、网关分类
1 互斥网关
只会返回一条结果。当流程执行到排他网关时，流程引擎会自动检索网关出口，从上到下检索如果发现第一条决策结果为true或者没有设置条件的(默认为成立)，则流出。如果没有任何一个出口符合条件，则抛出异常。
${stuType==1}
${stuType==2}

2 并行网关
无条件触发，不会解析条件，写了条件也会被忽略。进入和外出的数目不一定相等。分支(fork)： 并行后的所有外出顺序流，为每个顺序流都创建一个并发分支。汇聚(join)： 所有到达并行网关，在此等待的进入分支， 直到所有进入顺序流的分支都到达以后， 流程就会通过汇聚网关。
流入下一个节点可以设置条件，可以是全部子任务都完成还是50%完成。

3 包容性网关
集中了前两个网关的特点，可以定义条件，多条件执行，只要条件返回true就会执行，包含网关只会等待被选中执行了的进入顺序流。

4 事件网关
基于事件网关允许根据事件判断流向。网关的每个外出顺序流都要连接到一个中间捕获事件。 当流程到达一个基于事件网关，网关会进入等待状态：会暂停执行。 与此同时，会为每个外出顺序流创建相对的事件订阅。


四、任务分类
用户任务：指定一个人或者一个变量，设置的人 
直接指定办理人：${assignee}
任务监听器设置处理人：
TaskListenerImpl implements TaskListener
delegateTask.setAssignee("XXX"); 

脚本任务：
脚本任务是一个自动化活动。当一个流程执行到达脚本任务时，执行相应的脚本。
https://www.cnblogs.com/dengjiahai/p/6942433.html

服务任务：

public class ServiceTask implements JavaDelegate{
 @Override
public void execute(DelegateExecution execution) throws Exception 
{  业务逻辑... } }

消息任务：当流程到达这个节点处于停滞状态，程序收到一个消息之后signal 流程实例。 
runtimeService.signal(execution.getId());




五、监听器

1 全局监听器
主要使用的场景就是监控这个流程的启动和结束。流程开始的时候可以监控，流程结束的时候可以监控，这里说的是流程实例启动结束的监控
包括流程的启动和停止，线条的take监听（）
ExecutionListener定义如下：流程实例start、end、take的时候调用。take是监控连线的时候使用的。
public interface ExecutionListener extends Serializable {  
  String EVENTNAME_START = "start";  
  String EVENTNAME_END = "end";  
  String EVENTNAME_TAKE = "take";  
 void notify(DelegateExecution execution) throws Exception;  
} 

package cm.daling.ch1.listener;  
import org.activiti.engine.delegate.DelegateExecution;  
import org.activiti.engine.delegate.ExecutionListener;  
public class MyExecutionListener implements ExecutionListener {  
public void notify(DelegateExecution execution) throws Exception {  
String eventName = execution.getEventName();  
//start  
if ("start".equals(eventName)) {  
System.out.println("start=========");  
}else if ("end".equals(eventName)) {  
System.out.println("end=========");  
}  
}  
}  

2 任务节点监听器
节点监听器的定义接口org.activiti.engine.delegate.TaskListener
public class MyExecutionListener implements TaskListener {  
public void notify(DelegateTask delegateTask) {  
String eventName = delegateTask.getEventName();  
} 
} 

3 AOP式的监听器 
（1） 一般思路ACT_RE_actdef_ext表配置每个节点的处理人（变量，角色，用户组，团队），邮件通知人，回调服务等信息。
在配置文件中配置ParseHandler，启动服务器会自动为所有流程的 process(start,end); usertask(start,complete,end); sequence(take) 添加监听器,根据 配置的节点对应的信息做相应的业务逻辑处理。

  <bean id="processEngineConfiguration" class="org.activiti.spring.SpringProcessEngineConfiguration">  
        <property name="dataSource" ref="dataSource" />  
        <property name="transactionManager" ref="transactionManager" />  
        <property name="databaseSchemaUpdate" value="true" />  
        <property name="jpaHandleTransaction" value="true" />  
        <property name="jpaCloseEntityManager" value="true" />  
        <property name="jobExecutorActivate" value="false" />  
        <property name="idGenerator" ref="uuidGenerator"/>
        <!-- <property name="deploymentResources" value="classpath*:diagrams/*.*" />   -->
        <property name="customDefaultBpmnParseHandlers">
			<list>
				<bean class="com.parse.ActivitiProcessExtParseHandler" />
				<bean class="com.parse.ActivitiReceiveTaskExtParseHandler" />
				<bean class="com.parse.ActivitiSequenceFlowExtParseHandler" />
				<bean class="com.parse.ActivitiServiceTaskExtParseHandler" />
				<bean class="com.parse.ActivitiUserTaskExtParseHandler" />
			</list>
	   </property>
    </bean> 

（2）扩展Activiti流程定义文件,实现自定义节点属性 
customDefaultBpmnParseHandlers 注册各种监听器
监听器包括启动流程日志，任务完成日志，流程开始，流程结束，消息任务开始，消息任务结束，服务任务开始，服务任务结束，用户任务开始，用户任务完成等监听器。


六、命令模式和责任链模式
Activiti任务的执行 用到了设计模式中的命令模式和责任链模式。
命令模式是将行为请求者和行为实现者解耦合的方式。对命令进行封装，将命令和执行命令分隔开。请求的一方发出命令，要求执行某些操作，接受一方收到命令，执行这些操作的真正实现。请求的一方不必知道接受方的接口，以及如何被操作。 

以启动流程为例：
ProcessEngineConfigurationImpl 会初始化一系列配置和注入信息，包括  initCommandExecutors();

RuntimeServiceImpl 继承ServiceImpl ，
在初始化的时候已经注入commandExecutor命令执行器。

public class RuntimeServiceImpl extends ServiceImpl implements RuntimeService
  public ProcessInstance startProcessInstanceByKey(String processDefinitionKey, String businessKey) {
    return commandExecutor.execute(new StartProcessInstanceCmd<ProcessInstance>(processDefinitionKey, null, businessKey, null));
  }

protected void initService(Object service) 
{ 
if (service instanceof ServiceImpl) ((ServiceImpl) service).setCommandExecutor(this.commandExecutor); 
}



启动流程类StartProcessInstanceCmd实现Command接口，重写execute方法。注入CommandContext对象，commandContext可以得到流程实例，流程定义，历史数据，任务数据的API，做相应的流程逻辑处理。
以启动流程拦截器链为，一般是默认的拦截器，可以自定义before/after拦截器。 
logger拦截器-->spring事务拦截器-->CommandContext拦截器-->CommandInvoker拦截器


其中CommandContext拦截器的工作主要是设置Context：
[java] view plain copy
Context.setCommandContext(context);  
Context.setProcessEngineConfiguration(processEngineConfiguration);  
return next.execute(config, command);   

Activiti默认的拦截器：
    1. LogInterceptor日志拦截器，拦截器打印执行的日志。
    2.事务拦截器。
    3.CommandContextInterceptor 命令上下文拦截器设置Context.
     4 CommandInvoker拦截器,执行命令




22 消息队列用过什么？吞吐量多少？什么场景？
a.异步处理，提高吞吐量，减少开销   
b.应用解耦，防止接口端应用崩溃，数据阻塞丢失    
c.流量销锋,如秒杀业务中将所有请求放在消息队列中，并设置队列的长度超过则转到错误页面
d.日记处理
c.消息通讯，通过消息订阅，时间通讯收发功能

RabbitMQ 
RabbitMQ是使用Erlang编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP, STOMP，也正因如此，它非常重量级，更适合于企业级的开发。同时实现了Broker构架，这意味着消息在发送给客户端时先在中心队列排队。对路由，负载均衡或者数据持久化都有很好的支持。

Redis 
Redis是一个基于Key-Value对的NoSQL数据库，开发维护很活跃。虽然它是一个Key-Value数据库存储系统，但它本身支持MQ功能，所以完全可以当做一个轻量级的队列服务来使用。对于RabbitMQ和Redis的入队和出队操作，各执行100万次，每10万次记录一次执行时间。测试数据分为128Bytes、512Bytes、1K和10K四个不同大小的数据。实验表明：入队时，当数据比较小时Redis的性能要高于RabbitMQ，而如果数据大小超过了10K，Redis则慢的无法忍受；出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ的出队性能则远低于Redis。

ZeroMQ 
ZeroMQ号称最快的消息队列系统，尤其针对大吞吐量的需求场景。ZMQ能够实现RabbitMQ不擅长的高级/复杂的队列，但是开发人员需要自己组合多种技术框架，技术上的复杂度是对这MQ能够应用成功的挑战。ZeroMQ具有一个独特的非中间件的模式，你不需要安装和运行一个消息服务器或中间件，因为你的应用程序将扮演了这个服务角色。你只需要简单的引用ZeroMQ程序库，可以使用NuGet安装，然后你就可以愉快的在应用程序之间发送消息了。但是ZeroMQ仅提供非持久性的队列，也就是说如果down机，数据将会丢失。其中，Twitter的Storm中默认使用ZeroMQ作为数据流的传输。

ActiveMQ 
ActiveMQ是Apache下的一个子项目。 类似于ZeroMQ，它能够以代理人和点对点的技术实现队列。同时类似于RabbitMQ，它少量代码就可以高效地实现高级应用场景。

Kafka/Jafka 
Kafka是Apache下的一个子项目，是一个高性能跨语言分布式Publish/Subscribe消息队列系统，而Jafka是在Kafka之上孵化而来的，即Kafka的一个升级版。具有以下特性：快速持久化，可以在O(1)的系统开销下进行消息持久化；高吞吐，在一台普通的服务器上既可以达到10W/s的吞吐速率；完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现复杂均衡；支持Hadoop数据并行加载，对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka通过Hadoop的并行加载机制来统一了在线和离线的消息处理，这一点也是本课题所研究系统所看重的。Apache Kafka相对于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统。




23 对Lucene，Solr和ELK有了解吗？分片是什么技术？Es中的索引/类型/文档什么关系？
Cluster包含多个node，Indices不应该理解成动词索引，Indices可理解成关系数据库中的databases，Indices可包含多个Index，Index对应关系数据库中的database，它是用来存储相关文档的。
Elasticsearch与关系数据的类比对应关系如下：
Relational DB  ⇒ Databases ⇒ Tables ⇒ Rows      
ColumnsElasticsearch  ⇒ Indices   ⇒ Types ⇒ Documents ⇒ Fields
这里的document的可以理解为一个JSON序列对象。
每个document可包含多个field。

再来说说Shard，每个Index（对应Database）包含多个Shard，默认是5个，分散在不同的Node上，但不会存在两个相同的Shard存在一个Node上，这样就没有备份的意义了。Shard是一个最小的Lucene索引单元。当来一个document的时候，Elasticsearch通过对docid进行hash来确定其放在哪个shard上面，然后在shard上面进行索引存储。replicas就是备份，Elasticsearch采用的是Push Replication模式，当你往 master主分片上面索引一个文档，该分片会复制该文档(document)到剩下的所有 replica副本分片中，这些分片也会索引这个文档。我个人觉得这种模式很nice，有些时候对于一个document的进行索引可能生成很大的索引文件，会很占带宽，而只传输原始文件会好很多。当进行查询是，如果提供了查询的DocID，Elasticsearch通过hash就知道Doc存在哪个shard上面，再通过routing table查询就知道再哪个node上面，让后去node上面去取就好了。如果不提供DocID,那么Elasticsearch会在该Index（indics）shards所在的所有node上执行搜索预警，然后返回搜索结果，由coordinating node gather之后返回给用户。

配置上需要把握什么样的原则，应该去看一个ES优化方面的资料，推荐两本书ElasticSearch Server (豆瓣)，Mastering ElasticSearch (豆瓣)一个机器不应定只部署一个node，一台机器可以虚拟化出多个虚拟机(至于虚拟化出多少看性能)，每个虚拟机都可以部署一个node.尤其在云计算环境下，如果租用云虚拟主机，谁知道它们是不是在同一台机器上。。。



24 用过哪些nosql数据库？
虽然SQL数据库是非常有用的工具，但经历了15年的一支独秀之后垄断即将被打破。这只是时间问题：被迫使用关系数据库，但最终发现不能适应需求的情况不胜枚举。
但是NoSQL数据库之间的不同，远超过两 SQL数据库之间的差别。这意味着软件架构师更应该在项目开始时就选择好一个适合的 NoSQL数据库。针对这种情况，这里对 Cassandra、Mongodb、CouchDB、Redis、 Riak、Membase、Neo4j 和 HBase 进行了比较：
编注1：NoSQL：是一项全新的数据库革命性运动，NoSQL的拥护者们提倡运用非关系型的数据存储。现今的计算机体系结构在数据存储方面要求具 备庞大的水平扩 展性，而NoSQL致力于改变这一现状。目前Google的 BigTable 和Amazon 的Dynamo使用的就是NoSQL型数据库。 参见NoSQL词条。）

1. CouchDB

    所用语言： Erlang
    特点：DB一致性，易于使用
    使用许可： Apache
    协议： HTTP/REST
    双向数据复制，
    持续进行或临时处理，
    处理时带冲突检查，
    因此，采用的是master-master复制（见编注2）
    MVCC – 写操作不阻塞读操作
    可保存文件之前的版本
    Crash-only（可靠的）设计
    需要不时地进行数据压缩
    视图：嵌入式 映射/减少
    格式化视图：列表显示
    支持进行服务器端文档验证
    支持认证
    根据变化实时更新
    支持附件处理
    因此， CouchApps（独立的 js应用程序）
    需要 jQuery程序库
最佳应用场景：适用于数据变化较少，执行预定义查询，进行数据统计的应用程序。适用于需要提供数据版本支持的应用程序。
例如： CRM、CMS系统。 master-master复制对于多站点部署是非常有用的。
（编注2：master-master复制：是一种数据库同步方法，允许数据在一组计算机之间共享数据，并且可以通过小组中任意成员在组内进行数据更新。）

2. Redis
    所用语言：C/C++
    特点：运行异常快
    使用许可： BSD
    协议：类 Telnet
    有硬盘存储支持的内存数据库，
    但自2.0版本以后可以将数据交换到硬盘（注意， 2.4以后版本不支持该特性！）
    Master-slave复制（见编注3）
    虽然采用简单数据或以键值索引的哈希表，但也支持复杂操作，例如 ZREVRANGEBYSCORE。
    INCR & co （适合计算极限值或统计数据）
    支持 sets（同时也支持 union/diff/inter）
    支持列表（同时也支持队列；阻塞式 pop操作）
    支持哈希表（带有多个域的对象）
    支持排序 sets（高得分表，适用于范围查询）
    Redis支持事务
    支持将数据设置成过期数据（类似快速缓冲区设计）
    Pub/Sub允许用户实现消息机制
最佳应用场景：适用于数据变化快且数据库大小可遇见（适合内存容量）的应用程序。
例如：股票价格、数据分析、实时数据搜集、实时通讯。
（编注3：Master-slave复制：如果同一时刻只有一台服务器处理所有的复制请求，这被称为 Master-slave复制，通常应用在需要提供高可用性的服务器集群。）


3. MongoDB
    所用语言：C++
    特点：保留了SQL一些友好的特性（查询，索引）。
    使用许可： AGPL（发起者： Apache）
    协议： Custom, binary（ BSON）
    Master/slave复制（支持自动错误恢复，使用 sets 复制）
    内建分片机制
    支持 javascript表达式查询
    可在服务器端执行任意的 javascript函数
    update-in-place支持比CouchDB更好
    在数据存储时采用内存到文件映射
    对性能的关注超过对功能的要求
    建议最好打开日志功能（参数 –journal）
    在32位操作系统上，数据库大小限制在约2.5Gb
    空数据库大约占 192Mb
    采用 GridFS存储大数据或元数据（不是真正的文件系统）

最佳应用场景：适用于需要动态查询支持；需要使用索引而不是 map/reduce功能；需要对大数据库有性能要求；需要使用 CouchDB但因为数据改变太频繁而占满内存的应用程序。
例如：你本打算采用 MySQL或 PostgreSQL，但因为它们本身自带的预定义栏让你望而却步。

 

4. Riak
    所用语言：Erlang和C，以及一些Javascript
    特点：具备容错能力
    使用许可： Apache
    协议： HTTP/REST或者 custom binary
    可调节的分发及复制(N, R, W)
    用 JavaScript or Erlang在操作前或操作后进行验证和安全支持。
    使用JavaScript或Erlang进行 Map/reduce
    连接及连接遍历：可作为图形数据库使用
    索引：输入元数据进行搜索（1.0版本即将支持）
    大数据对象支持（ Luwak）
    提供“开源”和“企业”两个版本
    全文本搜索，索引，通过 Riak搜索服务器查询（ beta版）
    支持Masterless多站点复制及商业许可的 SNMP监控

最佳应用场景：适用于想使用类似 Cassandra（类似Dynamo）数据库但无法处理 bloat及复杂性的情况。适用于你打算做多站点复制，但又需要对单个站点的扩展性，可用性及出错处理有要求的情况。
例如：销售数据搜集，工厂控制系统；对宕机时间有严格要求；可以作为易于更新的 web服务器使用。


5. Membase
    所用语言： Erlang和C
    特点：兼容 Memcache，但同时兼具持久化和支持集群
    使用许可： Apache 2.0
    协议：分布式缓存及扩展
    非常快速（200k+/秒），通过键值索引数据
    可持久化存储到硬盘
    所有节点都是唯一的（ master-master复制）
    在内存中同样支持类似分布式缓存的缓存单元
    写数据时通过去除重复数据来减少 IO
    提供非常好的集群管理 web界面
    更新软件时软无需停止数据库服务
    支持连接池和多路复用的连接代理

最佳应用场景：适用于需要低延迟数据访问，高并发支持以及高可用性的应用程序
例如：低延迟数据访问比如以广告为目标的应用，高并发的 web 应用比如网络游戏（例如 Zynga）

 

6. Neo4j
    所用语言： Java
    特点：基于关系的图形数据库
    使用许可： GPL，其中一些特性使用 AGPL/商业许可
    协议： HTTP/REST（或嵌入在 Java中）
    可独立使用或嵌入到 Java应用程序
    图形的节点和边都可以带有元数据
    很好的自带web管理功能
    使用多种算法支持路径搜索
    使用键值和关系进行索引
    为读操作进行优化
    支持事务（用 Java api）
    使用 Gremlin图形遍历语言
    支持 Groovy脚本
    支持在线备份，高级监控及高可靠性支持使用 AGPL/商业许可

最佳应用场景：适用于图形一类数据。这是 Neo4j与其他nosql数据库的最显著区别
例如：社会关系，公共交通网络，地图及网络拓谱

 

7. Cassandra
    所用语言： Java
    特点：对大型表格和 Dynamo支持得最好
    使用许可： Apache
    协议： Custom, binary (节约型)
    可调节的分发及复制(N, R, W)
    支持以某个范围的键值通过列查询
    类似大表格的功能：列，某个特性的列集合
    写操作比读操作更快
    基于 Apache分布式平台尽可能地 Map/reduce
    我承认对 Cassandra有偏见，一部分是因为它本身的臃肿和复杂性，也因为 Java的问题（配置，出现异常，等等）

最佳应用场景：当使用写操作多过读操作（记录日志）如果每个系统组建都必须用 Java编写（没有人因为选用 Apache的软件被解雇）
例如：银行业，金融业（虽然对于金融交易不是必须的，但这些产业对数据库的要求会比它们更大）写比读更快，所以一个自然的特性就是实时数据分析


8. HBase
（配合 ghshephard使用）
    所用语言： Java
    特点：支持数十亿行X上百万列
    使用许可： Apache
    协议：HTTP/REST （支持 Thrift，见编注4）
    在 BigTable之后建模
    采用分布式架构 Map/reduce
    对实时查询进行优化
    高性能 Thrift网关
    通过在server端扫描及过滤实现对查询操作预判
    支持 XML, Protobuf, 和binary的HTTP
    Cascading, hive, and pig source and sink modules
    基于 Jruby（ JIRB）的shell
    对配置改变和较小的升级都会重新回滚
    不会出现单点故障
    堪比MySQL的随机访问性能
	
	



25 对hadoop,spark,elk,hive,flume,pig了解多少？
一、FLUME 介绍
Apache Flume 用于移动大规模批量流数据到 HDFS 系统。从Web服务器收集当前日志文件数据到HDFS聚集用于分析，一个常见的用例是Flume。
Flume 支持多种来源，如：
“tail”(从本地文件，该文件的管道数据和通过Flume写入 HDFS，类似于Unix命令“tail”)
系统日志
Apache log4j (允许Java应用程序通过Flume事件写入到HDFS文件)。

二、Pig简介
在Map Reduce框架，需要的程序将其转化为一系列 Map 和 Reduce阶段。 但是，这不是一种编程模型，它被数据分析所熟悉。因此，为了弥补这一差距，一个抽象概念叫 Pig 建立在 Hadoop 之上。
Pig是一种高级编程语言，分析大数据集非常有用。 Pig 是雅虎努力开发的结果
Pig 使人们能够更专注于分析大量数据集和花更少的时间来写map-reduce程序。
类似猪吃东西，Pig 编程语言的目的是可以在任何类型的数据工作。
Pig 由两部分组成：
Pig Latin，这是一种语言
运行环境，用于运行PigLatin程序
Pig Latin 程序由一系列操作或变换应用到输入数据，以产生输出。这些操作描述被翻译成可执行到数据流，由 Pig 环境执行。下面，这些转换的结果是一系列的 MapReduce 作业，程序员是不知道的。所以，在某种程度上，Pig 允许程序员关注数据，而不是执行过程。
Pig Latin 是一种相对硬挺的语言，它采用熟悉的关键字来处理数据，例如，Join, Group 和 Filter。

三、HIVE 介绍
在某种程度上数据集收集的大小并在行业用于商业智能分析正在增长，它使传统的数据仓库解决方案更加昂贵。HADOOP与MapReduce框架，被用于大型数据集分析的替代解决方案。虽然，Hadoop 地庞大的数据集上工作证明是非常有用的，MapReduce框架是非常低级别并且它需要程序员编写自定义程序，这导致难以维护和重用。 Hive 就是为程序员设计的。
Hive 演变为基于Hadoop的Map-Reduce 框架之上的数据仓库解决方案。
Hive 提供了类似于SQL的声明性语言，叫作：HiveQL, 用于表达的查询。使用 Hive-SQL，用户能够非常容易地进行数据分析。
Hive 引擎编译这些查询到 map-reduce作业中并在 Hadoop 上执行。此外，自定义 map-reduce 脚本，也可以插入查询。Hive运行存储在表中，它由基本数据类型，如数组和映射集合的数据类型的数据。

四、Hadoop和Spark
Spark是一个计算框架
Hadoop是包含计算框架MapReducehe分布式文件系统HDFS。
Spark是MapReduce的替代方案，而且兼容HDFS、Hive等分布式存储系统，可融入Hadoop生态。
Spark与Hadoop MapReduce优势如下
@中间结果输出
MapReduce的计算引擎将中间结果存储在磁盘上，进行存储和容错。
Spark将执行模型抽象为有向无环图执行计划（DAG），这可以将多个Stage的任务串联或者并行执行，而无须将Stage中间结果输出到HDFS中。
@数据格式和内存布局
MapReduce  Schema on Read处理方式会引起较大的处理开销。Spark抽象出分布式内存存储结构弹性分布式数据集RDD，进行数据的存储。RDD能支持粗粒度写操作，但是对于读取操作，RDD可以精确到每条记录，这使得RDD可以用来作分布式索引。Spark的特性是能控制数据节点上的分区，用户可以自定义分区策略，如Hash分区等。Shark 和Spark SQL在Spark的基础之上实现了列存储和列存储压缩。
@执行策略
MapReduce在数据Shuffle之前花费了大量的时间来排序，Spark则可以减轻上述问题带来的开销。因为Spark任务在Shuffle中不是所有情景都需要排序，所以支持基于Hash的分布式聚合，调度中采用更为通用的任务执行计划图（DAG），每一轮次的输出结果在内存缓存。
@任务调度开销
传统的MapReduce系统，如Hadoop，是为了运行长达数小时的批量作业而设计的，在某些极端情况下，提交一个任务的延迟非常高。
Spark采用了事件驱动的类库AKKA来启动任务，通过线程池复用线程来避免进程或线程启动和切换开销。

1、 Spark VSHadoop有哪些异同点？
Hadoop:分布式批处理计算，强调批处理，常用于数据挖掘和数据分析。
Spark:是一个基于内存计算的开源的集群计算系统，目的是让数据分析更加快速, Spark 是一种与 Hadoop 相似的开源集群计算环境，但是两者之间还存在一些不同之处，这些有用的不同之处使 Spark 在某些工作负载方面表现得更加优越，换句话说，Spark 启用了内存分布数据集，除了能够提供交互式查询外，它还可以优化迭代工作负载。
Spark 是在 Scala 语言中实现的，它将 Scala 用作其应用程序框架。与 Hadoop 不同，Spark 和 Scala 能够紧密集成，其中的 Scala 可以像操作本地集合对象一样轻松地操作分布式数据集。
尽管创建 Spark 是为了支持分布式数据集上的迭代作业，但是实际上它是对 Hadoop 的补充，可以在 Hadoop 文件系统中并行运行。通过名为Mesos的第三方集群框架可以支持此行为。
虽然 Spark 与 Hadoop 有相似之处，但它提供了具有有用差异的一个新的集群计算框架。首先，Spark 是为集群计算中的特定类型的工作负载而设计，即那些在并行操作之间重用工作数据集（比如机器学习算法）的工作负载。为了优化这些类型的工作负载，Spark 引进了内存集群计算的概念，可在内存集群计算中将数据集缓存在内存中，以缩短访问延迟。
在大数据处理方面相信大家对hadoop已经耳熟能详，基于GoogleMap/Reduce来实现的Hadoop为开发者提供了map、reduce原语，使并行批处理程序变得非常地简单和优美。Spark提供的数据集操作类型有很多种，不像Hadoop只提供了Map和Reduce两种操作。比如map,filter, flatMap,sample, groupByKey, reduceByKey, union,join, cogroup,mapValues, sort,partionBy等多种操作类型，他们把这些操作称为Transformations。同时还提供Count,collect, reduce, lookup, save等多种actions。这些多种多样的数据集操作类型，给上层应用者提供了方便。各个处理节点之间的通信模型不再像Hadoop那样就是唯一的Data Shuffle一种模式。用户可以命名，物化，控制中间结果的分区等。可以说编程模型比Hadoop更灵活。

2、Spark对于数据处理能力和效率有哪些特色？
Spark提供了高的性能和大数据处理能力，使得用户可以快速得到反馈体验更好。另一类应用是做数据挖掘，因为Spark充分利用内存进行缓存，利用DAG消除不必要的步骤，所以比较合适做迭代式的运算。而有相当一部分机器学习算法是通过多次迭代收敛的算法，所以适合用Spark来实现。
Spark配有一个流数据处理模型，与Twitter的 Storm框架相比，Spark采用了一种有趣而且独特的办法。Storm基本上是像是放入独立事务的管道，在其中事务会得到分布式的处理。相反，Spark采用一个模型收集事务，然后在短时间内（我们假设是5秒）以批处理的方式处理事件。所收集的数据成为他们自己的RDD，然后使用Spark应用程序中常用的一组进行处理。作者声称这种模式是在缓慢节点和故障情况下会更加稳健，而且5秒的时间间隔通常对于大多数应用已经足够快了。这种方法也很好地统一了流式处理与非流式处理部分

五、ELK
一般我们需要进行日志分析场景：直接在日志文件中 grep、awk 就可以获得自己想要的信息。但在规模较大的场景中，此方法效率低下，面临问题包括日志量太大如何归档、文本搜索太慢怎么办、如何多维度查询。需要集中化的日志管理，所有服务器上的日志收集汇总。常见解决思路是建立集中式日志收集系统，将所有节点上的日志统一收集，管理，访问。
一般大型系统是一个分布式部署的架构，不同的服务模块部署在不同的服务器上，问题出现时，大部分情况需要根据问题暴露的关键信息，定位到具体的服务器和服务模块，构建一套集中式日志系统，可以提高定位问题的效率。
一个完整的集中式日志系统，需要包含以下几个主要特点：
收集－能够采集多种来源的日志数据
传输－能够稳定的把日志数据传输到中央系统
存储－如何存储日志数据
分析－可以支持 UI 分析
警告－能够提供错误报告，监控机制
ELK提供了一整套解决方案，并且都是开源软件，之间互相配合使用，完美衔接，高效的满足了很多场合的应用。目前主流的一种日志系统。

ELK简介：
ELK是三个开源软件的缩写，分别表示：Elasticsearch , Logstash, Kibana , 它们都是开源软件。新增了一个FileBeat，它是一个轻量级的日志收集处理工具(Agent)，Filebeat占用资源少，适合于在各个服务器上搜集日志后传输给Logstash，官方也推荐此工具。
Elasticsearch是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。
Logstash 主要是用来日志的搜集、分析、过滤日志的工具，支持大量的数据获取方式。一般工作方式为c/s架构，client端安装在需要收集日志的主机上，server端负责将收到的各节点日志进行过滤、修改等操作在一并发往elasticsearch上去。
Kibana 也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助汇总、分析和搜索重要数据日志。
Filebeat隶属于Beats。目前Beats包含四种工具：
Packetbeat（搜集网络流量数据）
Topbeat（搜集系统、进程和文件系统级别的 CPU 和内存使用情况等数据）
Filebeat（搜集文件数据）
Winlogbeat（搜集 Windows 事件日志数据）







26 云计算包括哪三种架构？


1、软件即服务SaaS
软件即服务（SaaS）为商用软件提供基于网络的访问。您有可能已经使用过SaaS，即使您当时并不知道。SaaS的示例太多了，例如Netflix、Photoshop.com、Acrobat.com、Intuit QuickBooks Online、Gmail、Google Docs、Office Web Apps、Zoho、WebQQ、新浪微盘等等。可能不太明显的SaaS实现包括移动应用程序市场中的相当一部分。
SaaS为企业提供一种降低软件使用成本的方法 — 按需使用软件而不是为每台计算机购买许可证。尤其是考虑到大多数计算机在差不多70%的时间是空闲的，SaaS可能非常有效。企业不必为单一用户购买多个许可证，而是让许可证的使用时间尽可能接近100%，从而尽可能节省成本。

1.1 SaaS的优势
SaaS 给软件厂商提供了新的机会。尤其是，SaaS软件厂商可以通过四个因素提高 ROI（投资回报）：提高部署的速度、增加用户接受率、减少支持的需要、降低实现和升级的成本。
（1）提高部署的速度
在过去，部署传统的桌面应用程序需要很大的工作量。实际上，我曾经多次听到桌面应用程序开发人员把更新他们的应用程序称为 “部署噩梦”。正如Tariq Ahmed在Flex 4 in Action (Manning Press) 的第1章中指出的，“要想让数千甚至数万客户机同时运行软件的某一版本，后勤方面的复杂性是非常高的。”
Ahmed说，复杂性这么高，以致于大多数桌面软件开发公司甚至认为这根本不合理或不可行。过去受到这个问题困扰的开发商应该考虑部署软件的SaaS版本。但是，妨碍传统软件开发公司进入SaaS市场的最大障碍是让桌面应用程序能够作为SaaS应用程序运行。在许多情况下，这需要在某种程度上重新编写软件，一些公司觉得这么做成本太高。
这正是向云计算转移的过程比较缓慢且平缓的主要原因之一。在大多数情况下，符合逻辑的解决方案是分阶段地把软件转移到云中，首先以SaaS的形式提供原应用程序的高度简化的版本。考虑到开发商对版本控制的控制水平，这么做是很合理的。在这里，分析一下SaaS的特点会很有帮助。
您可以看出在云计算与过去的 “LAN 计算” 之间有许多相似之处。典型的LAN架构由站内的许多工作站组成，它们常常被称为哑终端，它们通过连接强大的大型机（常常由IBM 提供）运行应用程序。这种计算类型过去非常适合企业，因 IT部门能够完全控制版本，可以非常方便地多次部署更新。同样，过去妨碍桌面软件应用程序开发商进行版本控制的后勤障碍在云中也不存在，因为软件在开发公司能够直接访问的基础设施上运行。
考虑到SaaS必须能够服务的客户机数量，SaaS基础设施的规模要比LAN大得多。但是底层的概念是相同的。大型机能够驻留足够多的软件实例，从而为本地网络中连接它的所有客户机提供服务；而云由许多不同的计算机资源组成，它们共同提供计算能力，从而运行为世界各地的客户机提供服务所需的许多软件实例。 
（2）增加接受率
如果您走出企业，看看SaaS对于一般消费者的意义，就会发现以前一些软件的许可证费用太高，而现在SaaS让一般消费者能够以合理的价格使用它们。一个好例子是 Adobe 以SaaS的形式提供Adobe Photoshop。尽管这项工作是Adobe正在做的试验，但是已经取得了一些效果。例如，我注意到在需要执行简单的照片编辑任务时，在我的朋友和家庭成员中越来越多的人开始使用Photoshop.com进行基本的照片编辑，而不是启动全功能的版本。出现这种趋势的原因是，不需要完整版本中的功能的人现在可以省钱。与此同时，过去不使用Photoshop的人也开始使用Photoshop.com了，这给Adobe带来了争取新的长期客户的机会，扩大了潜在客户的范围。
SaaS提供的多种业务模型尤其有吸引力。例如，Intuit 以SaaS的形式提供QuickBooks Online，按月收取服务费。作为经常旅行的企业主，我发现这种服务非常有用，尤其是因为我的业务伙伴住在400英里外的另一个州里。同时，Adobe在Photoshop.com和Acrobat.com中应用了SaaS，以freemium服务的形式提供软件 — freemium服务是指一种基于许可证软件产品的SaaS缩略版的业务模型。
freemium SaaS基于的收入模型是，预计免费用户中的一部分最终会觉得软件很有用，他们会升级到启用了更多特性的SaaS付费版本，或者购买包含所有特性和功能的桌面版本的许可证。这种方法往往比通过 “受限制的演示” 模式试用软件更好，因为演示模式要求用户在桌面计算机上安装他们可能不会购买的应用程序。另外，如果免费用户中升级的比例低于预期，还可以通过广告进一步补充这个模型。随着云计算的发展，传统的桌面软件厂商经常使用这种方法适应市场的变化。
（3）减少支持的需要
大型客户服务中心的成本很高，不得不支持多种平台会导致支持问题增加，而SaaS可以大大缓解这些难题。首先，部署的简便性让开发人员能够在发现bug之后很快进行修复，这意味着大多数bug可以在大量用户遇到它们之前被修复，这会减少客户支持部门接到的电话数量，提高客户满意度，降低客户流失的可能性。
另外，传统桌面软件应用程序的开发商常常必须支持多种平台。例如，开发商可能必须支持Windows 7和Apple Mac OS X 10.6操作系统，添加对第二种操作系统的支持差不多会让开发成本加倍；而且，如果支持这些操作系统的许多不同版本，问题会更多。支持操作系统的多个版本还会产生限制。
例如，如果您要构建一个在Windows 7上运行的程序，但是它必须与Windows XP兼容，就必须非常小心，要确保特性和功能在这两个版本上都能够运行；否则，就必须把项目分为两个分支，为每个版本开发单独的代码，这会不可避免地降低生产力和效率，延长完成项目的预期时间。让业务执行官心跳加速的最快方法之一是，告诉他后两年的预期开发进度要减慢一半儿。另外，支持不同的操作系统和这些操作系统的不同版本会增加预算；这个问题和其他因素导致目前软件开发项目的失败率非常高。
（4）降低实现和升级的成本
SaaS推动ROI的第四个因素与第一个因素有点儿相似。但是，部署的速度是指快速、简便地部署应用程序更新所带来的好处。与之相反，降低实现和升级的成本是指开发公司由于能够控制版本和运行软件的基础设施所获得的经济利益。
因为开发商可以控制运行软件的平台（平台通常对于用户完全透明），所以他们不必负担在多个平台上测试和部署bug补丁和新特性的额外开销，这会节省大量资金。这让SaaS应用程序的升级成本更低。节省的大量时间和资金让开发商有机会更好地响应客户的请求并增强易用性，从而提高客户满意度，降低客户流失的可能性，这会带来间接的经济利益。

1.2 SaaS的用户体验设计
SaaS 应用程序代表着一种新一代应用程序设计方式。尽管在我目前看到的文档中没有明确地指出，但是看起来SaaS程序也带来了一种新的UI设计方式，这种方式与大多数其他行业中的产品设计流程更一致。这种方式包含一个称为用户体验设计 (UXD) 的流程，在这个流程中由产品团队而不是开发团队设计GUI。
UXD的主要目的是，确定哪些特性会让应用程序对于目标客户最有价值，并在设计中融入这些知识。尽管对于是否应该在所有类型的软件的开发中都执行这个流程有争议，但是在SaaS应用程序开发中这种做法非常普遍。出现这种现象的原因可能是，SaaS可以实现的业务模型与传统软件不同，需要执行UXD；而且通过开发SaaS可以节省大量时间和资金，让开发商有能力执行UXD。

1.3 SaaS使用的技术
由于SaaS层离普通用户非常接近，所以在SaaS层所使用到的技术，大多耳熟能详，下面是其中最主要的五种：
（1）HTML ：标准的Web页面技术，现在主要以HTML4为主，但是即将推出的HTML5会在很多方面推动Web页面的发展，比如视频和本地存储等方面。
（2）JavaScript ：一种用于Web页面的动态语言，通过JavaScript ，能够极大地丰富Web页面的功能，最流行的JS框架有jQuery和Prototype 。
（3）CSS ：主要用于控制Web页面的外观，而且能使页面的内容与其表现形式之间进行优雅地分离。
（4）Flash ：业界最常用的RIA（Rich Internet Applications）技术，能够在现阶段提供HTML等技术所无法提供的基于Web的富应用，而且在用户体验方面，非常不错。
（5）Silverlight ：来自业界巨擎微软的RIA技术，虽然其现在市场占有率稍逊于Flash，但由于其可以使用C#来进行编程，所以对开发者非常友好。
在SaaS层的技术选型上，首先，由于通用性和较低的学习成本，大多数云计算产品都会比较倾向HTML 、JavaScript和CSS这对黄金组合，但是在HTML5被大家广泛接受之前，RIA技术在用户体验方面，还是具有一定的优势，所以Flash和Silverlight也将会有一定的用武之地，比如VMware vCloud就采用了基于Flash的Flex技术，而微软的云计算产品肯定会在今后大量使用Silverlight技术。


2、平台即服务PaaS
平台即服务（Platform as a Service，PaaS）提供对操作系统和相关服务的访问。它让用户能够使用提供商支持的编程语言和工具把应用程序部署到云中。用户不必管理或控制底层基础架构，而是控制部署的应用程序并在一定程度上控制应用程序驻留环境的配置。PaaS的提供者包括Google App Engine、Windows Azure、Force.com、Heroku等。小企业软件工作室是非常适合使用PaaS的企业。通过使用云平台，可以创建世界级的产品，而不需要负担内部生产的开销。
通过PaaS这种模式，用户可以在一个提供SDK（Software Development Kit，即软件开发工具包）、文档、测试环境和部署环境等在内的开发平台上非常方便地编写和部署应用，而且不论是在部署，还是在运行的时候，用户都无需为服务器、 操作系统、网络和存储等资源的运维而操心，这些繁琐的工作都由PaaS云供应商负责。而且PaaS在整合率上面非常惊人，比如一台运行Google App Engine的服务器能够支撑成千上万的应用，也就是说， PaaS是非常经济的。 PaaS主要面对的用户是开发人员。

2.1 PaaS的优势
在软件开发过程中，一些东西常常会出问题。以我的经验，设置服务器环境以驻留开发团队要构建的Web应用程序可能会带来许多争吵。即使在最大的企业中，通常一位网络管理员要负责为几个开发团队服务。在不使用PaaS的情况下，设置开发或测试环境通常需要完成以下任务：
* 获取并部署服务器。
* 安装操作系统、运行时环境、源代码控制存储库和必需的所有其他中间件。
* 配置操作系统、运行时环境、存储库和其他中间件。
* 转移或复制现有的代码。
* 测试并运行代码以确保一切正常。
在很多情况下，管理员已经非常忙了，所以让他们抽出时间部署新环境会很困难。对于客户机和服务器端的web应用程序开发人员来说，另一个主要问题是在本地复制运行时环境以便执行测试。
现在，想像一下您是使用PaaS的开发团队的成员。在这种情况下，您会有一个虚拟机 (VM)，其中包含完整的服务器环境，可以把它放在USB闪存驱动器中带在身边。这无疑是非常方便的。一般来说，和现有的基于本地的开发和部署环境相比，PaaS平台主要有下面这六方面有非常大的优势：
（1）友好的开发环境：通过提供SDK和IDE（Integrated Development Environment ，集成开发环境）等工具来让用户不仅能在本地方便地进行应用的开发和测试，而且能进行远程部署。
（2）丰富的服务：PaaS平台会以API的形式将各种各样的服务提供给上层的应用。
（3）精细的管理和监控：PaaS能够提供应用层的管理和监控，比如能够观察应用运行的情况和具体数值（比如吞吐量Throughput和响应时间Response Time等）来更好地衡量应用的运行状态，还有能够通过精确计量应用使用所消耗的资源来更好地计费。
（4）伸缩性强： PaaS 平台会自动调整资源来帮助运行于其上的应用更好地应对突发流量。
（5） 多租户（Multi-Tenant）机制：许多PaaS平台都自带多租户机制，不仅能更经济地支撑庞大的用户规模，而且能提供一定的可定制性以满足用户的特殊需求。
（6）整合率和经济性：PaaS平台整合率是非常高，比如PaaS的代表Google App Engine能在一台服务器上承载成千上万的应用。

2.2 PaaS的主要成分
了解 PaaS 的最好方法可能是把它分解为主要组件：平台和服务。现在，考虑提供的服务，这称为解决方案堆。也就是说，PaaS 的两个主要成分是计算平台和解决方案堆。
为了说明这两个 “成分”，我们进一步研究一下它们的定义。按照最简单的形式，计算平台是指一个可以一致地启动软件的地方（只要代码满足平台的标准）。平台的常见示例包括 Windows、Apple Mac OS X和Linux操作系统；用于移动计算的Google Android、Windows Mobile和Apple iOS；以及作为软件框架的Adobe AIR和Microsoft .NET Framework。要记住的重点是，计算平台不是指软件本身，而是指构建并运行软件的平台。图4提供一张示意图以帮助理解这种关系。
图2-2. 云计算分类与PaaS元素之间关系的图形化解释
既然理解了计算平台的概念，现在就来看看什么是解决方案堆。解决方案堆由应用程序组成，这些应用程序有助于开发过程和应用程序部署。这些应用程序是指操作系统、运行时环境、源代码控制存储库和必需的所有其他中间件。

2.3 PaaS供应商的选择
解决方案堆也反映不同PaaS公司的差异，在决定采用PaaS之前，需要深入考察各个提供商提供的解决方案堆。在与某家PaaS提供商签约之前，您应该问几个基本问题：
* 它支持哪些框架和语言？理想情况下，PaaS应该支持基于此平台选用的语言的任何框架。
* 可以创建多少个应用程序？大多数PaaS提供商会根据您签订的计划或服务包限制可以构建的应用程序数量。要确保提供商提供的计划或服务包能够满足您的需要。
* 允许哪些内容类型？支持PaaS的基础设施通常涉及多租用者计算的概念，也就是说许多 “租用者” 分享单一服务器上的 “空间”，这些空间由系统管理程序管理的VM实例分隔。PaaS提供商可能会对要驻留的应用程序和内容的类型加以限制。
* 支持哪些数据库类型？如果您的数据要随应用程序转移，这个问题就是非常重要的。必须确保提供商提供的数据库与您想要用来导入数据的格式兼容。
* 它是否支持SSL (HTTPS)？这个问题对于确保安全性非常重要。如果您打算通过应用程序处理事务，但是发现不支持SSL，您就遇到大麻烦了。
在比较PaaS提供商时应该考虑的特性：应用程序开发框架、容易使用、业务流程建模（BPM）工具、可用性、可伸缩性、安全性、包容性、可移植性、移植工具、API等。

2.4 PaaS使用的技术
PaaS 层的技术比较多样性，下面是常见的五种：
（1）REST ：通过 REST（Representational State Transfer，表述性状态转移）技术，能够非常方便和优雅地将中间件层所支撑的部分服务提供给调用者。
（2）多租户：就是能让一个单独的应用实例可以为多个组织服务，而且能保持良好的隔离性和安全性，并且通过这种技术，能有效地降低应用的购置和维护成本。
（3）并行处理：为了处理海量的数据，需要利用庞大的x86集群进行规模巨大的并行处理，Google的MapReduce是这方面的代表之作。
（4）应用服务器：在原有的应用服务器的基础上为云计算做了一定程度的优化，比如用于Google App Engine的Jetty应用服务器。
（5）分布式缓存：通过分布式缓存技术，不仅能有效地降低对后台服务器的压力，而且还能加快相应的反应速度，最著名的分布式缓存例子莫过于Memcached 。
对于很多PaaS平台，比如用于部署Ruby应用的Heroku云平台，应用服务器和分布式缓存都是必备的，同时REST技术也常用于对外的接口，多租户技术则主要用于SaaS应用的后台，比如用于支撑Salesforce 的CRM等应用的Force.com多租户内核，而并行处理技术常被作为单独的服务推出，比如Amazon的Elastic MapReduce 。

2.5 主要的PaaS产品
（1）Force.com：Force.com是业界第一个PaaS平台，其主要通过提供完善的开发环境和强健的基础设施等来帮助企业和第三方供应商交付健壮的、可靠的和可伸缩的在线应用。还有， Force.com本身是基于Salesforce著名的多租户的架构。
（2）Google App Engine：Google App Engine提供Google的基础设施来让大家部署应用，它还提供一整套开发工具和SDK来加速应用的开发，并提供大量的免费额度来节省用户的开支。
（3）Windows Azure Platform ：它是微软推出的PaaS产品，并运行在微软数据中心的服务器和网络基础设施上的，通过公共互联网来对外提供服务，它由具有高扩展性云操作系统、数据存储网络和相关服务组成，而且服务都是通过物理或虚拟的Windows Server 2008实例提供。还有，其附带的Windows Azure SDK（软件开发包）提供了一整套开发、部署和管理Windows Azure云服务所需要的工具和API 。
（4）Heroku：是一个用于部署Ruby On Rails应用的PaaS平台，并且其底层基于Amazon EC2 的IaaS服务，而且在Ruby程序员中有非常好的口碑。


3、基础架构即服务IaaS
基础架构，或称基础设施（Infrastructure）是云的基础。它由服务器、网络设备、存储磁盘等物理资产组成。在使用IaaS时，用户并不实际控制底层基础架构，而是控制操作系统、存储和部署应用程序，还在有限的程度上控制网络组件的选择。 
通过IaaS这种模式，用户可以从供应商那里获得他所需要的计算或者存储等资源来装载相关的应用，并只需为其所租用的那部分资源进行付费，而同时这些基础设施繁琐的管理工作则交给IaaS供应商来负责。
IaaS的关键概念：
* 云爆发（cloud bursting）
* 多租户计算（multi-tenant computing）
* 资源共用（resources pooling）
* 虚拟机监控程序（hypervisor）
IaaS最与众不同的两个方面：可伸缩性和虚拟化（elasticity and virtualization）。
对于企业而言，IaaS的巨大价值通过云爆发（cloudbursting）概念实现。云爆发是指当业务瞬间增长，需要大量的计算资源时，将任务负载扩展到云环境的过程。云爆发促成的资本节约潜力巨大，因为企业无需额外投资利用率很低的服务器，那些服务器一年中只有两三次使用 70% 的容量，其余时间仅有 7-10% 的负荷。

3.1 从”基础架构即资产“到”基础架构即服务”
在过去50年之内，大量成功的公司花费大量宝贵时间和资源来构建基础架构，其目标是通过创建一个更大、更快、更强的网络来获取战胜其竞争对手的竞争优势。IT 行业中的 “基础架构即资产” 范式拥有上世纪六七十年代的 “暴力跑车（muscle cars）” 所拥有的相同或类似的低效率和不利特征。对于企业计算，这些低效率包括：
* 大量未使用的计算能力和容量，它们耗费的成本与大型、昂贵的数据中心中的硬件消耗的大量空间相关联。比如服务器一年中可能只有两三次使用70%的容量，其余时间仅有7-10%的负荷。
* 昂贵的人力资源需求，包括要求基础架构资产（服务器、路由器、交换机等）所在的数据中心的网络管理员进行24小时监控。
* 旨在应对高水平能源浪费的Green Computing计划的一个巨大障碍。
IaaS标志着从 “基础架构即资产” 到 “基础架构即服务” 的转变。云计算的其他两个类别也标志着范式转变。对于Platform as a Service (PaaS)，转变来自 “平台即资产” 范式，该范式的特征是大量采购许可。同样的转变也适用Software as a Service (SaaS)，这种转变是从 “软件以许可形式作为组织资产” 到 “软件以服务形式提供”。

3.2 IaaS的主要特征
（1）可伸缩性
可伸缩性是IaaS的首要关键特征。为了阐述可伸缩的概念，我需要您展开想象。假设云由一些粘在一起的棉花糖簇组成，这样人们就可以坐在它们上面。每个棉花糖都能承载一定数量的人，具体取决于组成云的棉花糖簇的数量和那些簇中包含的棉花糖的数量。随着越来越多的人登上棉花糖云，您可以通过粘贴更多的棉花糖来扩展棉花糖簇，增加表面面积。您可能已经明白，人代表需要计算资源的应用程序，比如承载网站并运行软件的资源。棉花糖簇代表VM集群，每个棉花糖代表一 VM。
尽管这听起来有点像Seuss博士的书中可能出现的内容，但它提供了一种方法来理解许多黑魔法（dark art）考虑的一个概念：可伸缩的集群（elastic clustering）。集群化几个物理服务器来形成一个虚拟云称为云集群（cloud clustering），如果它真是一种黑魔法，则精通程度可以通过一位艺术家的系统设计的可伸缩性来衡量。
我们来看一个例子。假设您是一位为美国政府工作的统计研究员。政府有点人手不足，您刚刚接受一个任务，需要编辑最近的美国人口统计的所有数据。您负责制定必要的统计数据，以便议会能够制定关于经济恢复资金分配和从现在起三天内的税收金额的重要决策。毋庸讳言，这是一项非常重要的工作，您的时间有点紧张。而且，您必须处理的数据量简直是个天文数字，您刚刚发现，编辑那些统计数据需要的计算资源需要IT部门三周时间才能准备好！
这种问题正是您可以使用IaaS轻松缓解的。事实上，使用IaaS，您可以在一小时之内完成全美人口普查数据分析。您首先创建一个服务器的单个实例，这个服务器包含在数据上运行查询需要的数据库软件。这个实例称为一个映像。当您部署映像并将数据导入数据库之后，就可以根据需要复制那个映像任意多次，并开始运行您的数据处理任务。当任务运行时，您可以手动或自动添加和移除资源。例如，如果计算任务的运行速度不够快，只需将更多机器实例副本添加到集群。 
（2）虚拟化
IaaS很容易定位，因为它通常是独立于平台的。IaaS有一个硬件和软件资源组合组成。IaaS软件是低级代码，独立于操作系统运行，例如虚拟机监控程序。虚拟机监控程序负责管理硬件资源的库存并根据需要分配上述资源（见图 2-3）。这个过程称为资源共用（resource pooling）。虚拟机监控程序实现的资源共用使得虚拟化成为可能，虚拟化使多租户计算（multi-tenant computing）成为可能。多租户计算概念指由几个组织共享的一个基础架构，这些组织在安全需求和遵从性问题方面有类似的兴趣。
图2-3. VMs、虚拟机监控程序和计算机之间的关系
通过 IaaS，您拥有提供处理、存储、网络和其他计算资源的能力，您可以在那里部署和运行任意软件，比如操作系统和应用程序。大多数云计算用例遵循您已经习惯的基础分层结构：一个软件解决方案堆栈或平台被部署在一个网络基础架构上，一些应用程序在那个平台之上运行。但是，虚拟化使得云范式独一无二。

3.3 IaaS的优势
IaaS服务和传统的企业数据中心相比，在很多方面都存在一定的优势，下面是最明显的五个。
（1）免维护：主要的维护工作都有IaaS云供应商负责，所以不必用户操心。
（2）非常经济：首先免去了用户前期的硬件购置成本，而且由于IaaS云大都采用虚拟化技术，所以在应用和服务器的整合率普遍在10以上，这样能有效降低使用成本。
（3）开放标准：虽然很多IaaS平台都存在一定的私有功能，但是由于OVF等应用发布协议的诞生，使得IaaS在跨平台方面稳步前进，从而使得应用能在多个IaaS云上灵活的迁移，而不会被固定在某个企业数据中心内。
（4）支持的应用：因为IaaS主要是提供虚拟机，而且普通的虚拟机能支持多种操作系统，所以IaaS所支持应用的范围是非常广泛的。
（5）伸缩性强：IaaS云只需几分钟就能提供用户一个新的计算资源，而传统的企业数据中心则往往需要几周时间，并且计算资源可以根据用户需求来调整其资源的大小。

3.4 IaaS使用的技术
在IaaS所采用的技术方面，都是一些比较底层的技术，其中有四种技术是比较常用的：
（1）虚拟化：也可以理解它为基础设施层的“多租户”，因为通过虚拟化技术，能够在一个物理服务器上生成多个虚拟机，并且能在这些虚拟机之间能实现全面的隔离， 这样不仅能减低服务器的购置成本，而且还能同时降低服务器的运维成本，成熟的x86虚拟化技术有VMware的ESX和开源的Xen 。
（2）分布式存储：为了承载海量的数据，同时也要保证这些数据的可管理性，所以需要一整套分布式的存储系统，在这方面， Google 的GFS是典范之作。
（3）关系型数据库：基本是在原有的关系型数据库的基础上做了扩展和管理等方面的优化，使其在云中更适应。
（4）NoSQL：为了满足一些关系数据库所无法满足的目标，比如支撑海量的数据等，一些公司特地设计一批不是基于关系模型的数据库，比如Google的BigTable和Facebook的Cassandra等。
现在大多数的IaaS服务都是基于Xen的，比如Amazon的EC2等，但VMware也推出了基于ESX技术的vCloud ，同时业界也有几个基于关系型数据库的云服务，比如Amazon 的RDS（Relational Database Service，关系型数据库服务）和Windows Azure SDS（SQL Data Services， SQL数据库服务）等。关于分布式存储和NoSQL，它们已经被广泛用于云平台的后端，比如Google App Engine的Datastore就是基于BigTable和GFS这两个技术之上的，而Amazon则推出基于NoSQL技术的Simple DB 。

3.5 主要的IaaS产品
最具代表性的IaaS产品有Amazon EC2、IBM Blue Cloud、Cisco UCS和Joyent。
（1）Amazon EC2。EC2主要以提供不同规格的计算资源（也就是虚拟机）为主。它基于著名的开源虚拟化技术Xen。通过Amazon的各种优化和创新， EC2不论在性能上还是在稳定性上都已经满足企业级的需求。而且它还提供完善的API和Web管理界面来方便用户使用。这种IaaS产品得到业界广泛地认可和接受，其中就包括部分大型企业，比如著名的纽约时报。
（2）IBM Blue Cloud。“蓝云”解决方案是由IBM云计算中心开发的业界第一个，同时也是在技术上比较领先的企业级云计算解决方案。该解决方案可以对企业现有的基础架构进行整合，通过虚拟化技术和自动化管理技术来构建企业自己的云计算中心，并实现对企业硬件资源和软件资源的统一管理、统一分配、统一部署、统一监控和统一备份，也打破了应用对资源的独占，从而帮助企业能享受到云计算所带来的诸多优越性。
（3）Cisco UCS。它是下一代数据中心平台，在一个紧密结合的系统中整合了计算、网络、存储与虚拟化功能。该系统包含一个低延时、无丢包和支持万兆以太网的统一网络阵列以及多台企业级x86架构刀片服务器等设备，并在一个统一的管理域中管理所有资源。用户可以通过在UCS上安装VMWare vSphere来支撑多达几千台虚拟机的运行。通过Cisco UCS，能够让企业快速在本地数据中心搭建基于虚拟化技术的云环境。
（4）Joyent。它提供基Open Solaris技术的IaaS服务。其IaaS服务中最核心的是Joyent SmartMachine。与大多数的IaaS服务不同的是，它并不是将底层硬件按照预计的额度直接分配给虚拟机，而是维护了一个大的资源池，让虚拟机上层的应用直接调用资源，并且这个资源池也有公平调度的功能，这样做的好处是优化资源的调配，并且易于应对流量突发情况，同时使用人员也无需过多关注操作系统级管理和运维。



27 并行计算和分布式计算什么区别？

1 并行计算、分布式计算、网格计算与云计算都属于高性能计算（High Performance Computing，HPC）的范畴，主要目的在于对大数据的分析与处理，但它们却存在很多差异。电子海图云服务是基于高性能计算的理论技术、通过对传统服务体系结构的改进，以实现海量电子海图数据的快速存取与处理操作，使其更好地为海洋地理信息科学领域中的计算密集型和数据密集型问题提供相应的计算和处理能力。高性能计算体系结构是海量电子海图数据存储与处理的技术基础，也是顺利进行电子海图云服务原型系统开发的保证。以下将对并行计算、分布式计算、网格计算与云计算之间的区别与联系做分析。
并行计算

2 并行计算是相对于串行计算而言的，它是指一种能够让多条指令同时进行的计算模式，可分为时间并行和空间并行。时间并行即利用多条流水线同时作业，空间并行是指使用多个处理器执行并发计算，以降低解决复杂问题所需要的时间。从程序开发人员的角度看，并行计算又可分为数据并行与功能并行，数据并行是通过对数据的分解实现相同子任务的并行作业，功能并行是通过对任务的分解实现相同数据不同任务的并行作业。相比较而言，数据并行较易实现，因此本文在并行算法研究时也将基于数据并行的原则进行设。对于并行计算的研究在上世纪70年代开始，就已有相关理论研究，如单指令多数据流（SIMD）与多指令多数据流（MIMD）的并行机制研究，到了80年代在并行体系结构方面有了很大成果，出现了利用网络组成多台计算机的并行结构与利用共享存储器组成多处理器的并行计算机，科学家利用这种并行计算结构在技术高精尖领域缩减了解决复杂问题的时间。
从以上分析可得出，早期的并行计算主要应用于科学研究领域，具有特定的应用环境，需要利用很高的技术技巧才能完成任务所需要的并行程序设计。虽然当时的并行计算离普
通大众还很遥远，但已经为复杂问题求解（如功能并行、数据并行、通信协调等）奠定了方法论基础。可以说，并行计算是云计算的初始阶段或者说是萌芽期，它为云计算的发展提供了实际而朴素的思想和基本思路。
分布式计算

3 分布式计算是一种把需要进行大量计算的工程数据分区成小块，由多台联网计算机分别处理，在上传处理结果后，将结果统一合并得出数据结论的科学。在90年代，随着TCP/IP协议的最终确定，计算机网络快速发展，Web Service等网络新技术随之而来，为基于广域网的分布式计算做好了硬件与软件基础。首先来比较下分布式计算与并行计算的异同。其相同之处都是将复杂任务化简为多个子任务，然后在多台计算机同时运算。不同之处在于分布式计算是一个比较松散的结构，实时性要求不高，可以跨越局域网在因特网部署运行，大量的公益性项目（如黑洞探索、药物研究、蛋白质结构分析等）大多采用这种方式，而并行计算是需要各节点之间通过高速网络进行较为频繁地通信，节点之间具有较强的关联性，主要部署在局域网内。在分布式计算的算法中，我们更加关注的是计算机间的通信而不是算法的步骤，因为分布式计算的通信代价比起单节点对整体性能的影响权重要大得多。
从以上分析可得出，分布式计算是网络发展的产物，是由并行计算演化出的新模式：网络并行计算。如果说并行计算为云计算奠定了理论基础，那么分布式计算则为云计算的实现打下了坚固的网络技术基石。

4 网格计算网格计算是指通过利用多个独立实体或机构中大量异构的计算机资源（处理器周期和磁盘存储），采用统一开放的标准化访问协议及接口，实现非集中控制式的资源访问与协同式的问题求解，以达到系统服务质量高于其每个网格系统成员服务质量累加的总和。
在90年代中期，分布式计算发展到一定阶段后，网格计算开始出现，其目的在于利用分散的网络资源解决密集型计算问题。当时由于高端的计算机硬件价格不菲，研究人员试图通过定义专门的协议机制以实现对分散异构且动态变化的网络资源管理，以解决高端计算机才能解决的密集型运算问题。网格计算与虚拟组织的概念由此产生，它通过定义一系列的标准协议、中间件以及工具包，以实现对虚拟组织中资源的分配和调度。它的焦点在于支持跨域计算与异构资源整合的能力，这使它与传统计算机集群或简单分布式计算相区别。为使网格计算能够成为类似于水电网的日常公共服务，Ian Foster提出应该定义一个在网络中获取计算或存储资源的标准协议，在这一理论指导下，世界各组织设计了一系列的网格系统，如OSG、ESG、EGEE等，这些网格系统能够按照设计人员的要求提供所需要的计算资存储资源甚至多种数据服务与功能服务。OASIS、OGF等国际标准组织也制定了相关标准，网格计算曾一度被认为是集群计算的市场化。然而迄今为止，商业化的网格系统仍然没有出现。过于庞大的概念、异常复杂的协议标准使得真正实现实用化的网格项目都是由国家行为推动的，如EUGrid、DataGrid、ChinaGrid、EduGrid等。然而网格计算的发展，为云计算的出现提供了基本的网络框架支持。

5 云计算
云计算是一种由大数据存储分析与资源弹性扩缩需求驱动的计算模式，它通过一个虚拟化、动态化、规模化的资源池为用户提供高可用性、高效性、弹性的计算存储资源与
数据功能服务。其具备五个关键特点：①基于分布式并行计算技术；②能够实现规模化、弹性化的计算存储；③用户服务的虚拟化与多级化；④受高性能计算与大数据存储驱动；⑤服务资源的动态化、弹性化。近年来云计算能够获得普遍关注的原因主要有以下三点：①设备存储计算能力的提升与成本的下降，多核、多处理器技术的诞生与普及；②各行业积累了越来越多的专业数据，亟需得到有效利用；③网络服务和Web2.0应用的广泛使用。
从以上分析可知，在概念层次上云计算与并行计算、集群计算、网格计算、分布式计算存在交叉，正如上一节所描述的云计算不仅是从网格计算演化来的，而且网格计算还为
云计算提供了基本的网络框架支持。网格计算的焦点在于计算与存储能力的提供，而云计算更注重于资源与服务能力的抽象，这就是网格计算向云计算的演化。与分布式计算比较，云计算是一种成熟稳定的流式商业资源，它为用户提供可量算的抽象服务就如同水电厂提供可量算的水电资源一样便捷可靠。图1.1显示了云计算与其他相关概念的关系。Web2.0诠释了面向服务的发展方向，云计算成为其中的主力；并行计算和集群计算更注重于传统面向应用的程序设计；网格计算由于其概念的庞大与这四个领域都有交叉，从广义的角度讲，分布式计算包含了整个概念域。

6 根据以上分析，我们可以得出这几个概念的关系。从计算机用户角度来讲，并行计算是由单个用户完成，分布式计算是由多用户合作完成，网格计算是由庞大的异构计算组织完成，云计算是没有用户参与由另一端的弹性服务集群完成。


28 maven package/install/deploy/build 命令，是否部署过私服Nexus？
1、maven的用途
　　maven是主要服务基于java平台的项目构建，依赖管理和项目信息管理的一个工具。项目构建包括清理，编译，测试到生成测试报告，再到打包和部署；依赖管理是maven借助于坐标来实现的。maven是跨平台的，可以在windows，linux和mac OS等系统上运行。

2、maven目录结构
（1）bin：maven运行脚本，命令。
（2）boot：包含plexus-classworlds-2.2.3.jar （plexus-classworlds是一个类加载器框架，相对于java 默认类加载器，他提供了更丰富的语法以方便配置，maven使用该框架加载自己的类库）。
（3）conf：配置文件 setting.xml，修改该文件就可以在机器上全局的制定maven的行为。但一般情况下，更倾向于复制该文件到~（用户目录）/.m2/目录下，然后修改该文件，在用户范围内制定maven的行为。
（4）lib：包含maven运行时所需要的java类库，包括第三方的依赖类库。
（5）LICENSE.txt：记录了maven使用该软件的许可证。
（6）NOTICE.txt：记录了maven包含的第三方软件。
（7）README.txt：记录了maven的简要介绍。

3、maven常用几个命令
（1）mvn help:system：该命令打印出所有的java系统属性和环境变量。
（2）mvn clean：清理输出目录默认target/。
（3）mvn clean compline：编译项目主代码，默认编译至target/classes目录下。
（4）mvn clean test：maven测试，但实际执行的命令有：clean:clean，resource:resources，compiler:compile, resources:testResources, compiler:testCompile，maven在执行test之前，会先自动执行项目主资源处理，主代码编译，测试资源处理，测试代码编译等工作，测试代码编译通过之后默认在target/test-calsses目录下生成二进制文件，紧接着surefile:test 任务运行测试，并输出测试报告，显示一共运行了多少次测试，失败成功等等。
（5）mvn celan package：maven打包，maven会在打包之前默认执行编译，测试等操作，打包成功之后默认输出在target/目录中。
（6）mvn clean install：maven安装，让其他的项目直接引用这个项目。
（7）echo %MAVEN_HOME%：查看maven安装路径。
（8）mvn：检查是否安装了maven。
（9）mvn dependency:list：查看当前项目中的已解析依赖
（10）mvn dependency:tree：查看当前项目的依赖树
（11）mvn dependency:analyse： 查看当前项目中使用未声明的依赖和已声明但未使用的依赖

4、maven的项目结构
（1）项目骨架：项目的根目录下方pom.xml
（2）项目主代码：maven认为项目的主代码是位于src/main/java目录下的，所以通常我们会在此目录下创建文件，比如…/java/com/shuyun/myweb/hello/hello.java，该java类的包名是com.shuyun.myweb.hello
（3）资源文件：maven的资源文件位于src/main/resources目录下
（4）测试文件：maven默认的测试代码目录src/test/java目录

5、Nexus简单说明
用途：指定私服的中央地址、将自己的Maven项目指定到私服地址、从私服下载中央库的项目索引、从私服仓库下载依赖组件、将第三方项目jar上传到私服供其他项目组使用
仓库：
hosted   类型的仓库，内部项目的发布仓库　
releases 内部的模块中release模块的发布仓库
snapshots 发布内部的SNAPSHOT模块的仓库　　
3rd party 第三方依赖的仓库，这个数据通常是由内部人员自行下载之后发布上去　
proxy   类型的仓库，从远程中央仓库中寻找数据的仓库
group   类型的仓库，组仓库用来方便我们开发人员进行设置的仓库


29 Mybatis的优缺点？
MyBatis 是支持定制化 SQL、存储过程以及高级映射的优秀的持久层框架。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以对配置和原生Map使用简单的 XML 或注解，将接口和 Java 的 POJOs(Plain Old Java Objects,普通的 Java对象)映射成数据库中的记录。

一、MyBatis框架的优点：
1. 与JDBC相比，减少了50%以上的代码量。
2. MyBatis是最简单的持久化框架，小巧并且简单易学。
3. MyBatis相当灵活，不会对应用程序或者数据库的现有设计强加任何影响，SQL写在XML里，从程序代码中彻底分离，降低耦合度，便于统一管理和优化，并可重用。
4. 提供XML标签，支持编写动态SQL语句。
5. 提供映射标签，支持对象与数据库的ORM字段关系映射。

二、MyBatis框架的缺点：
1. SQL语句的编写工作量较大，尤其是字段多、关联表多时，更是如此，对开发人员编写SQL语句的功底有一定要求。
2. SQL语句依赖于数据库，导致数据库移植性差，不能随意更换数据库。

三、MyBatis框架适用场合：
MyBatis专注于SQL本身，是一个足够灵活的DAO层解决方案。
对性能的要求很高，或者需求变化较多的项目，如互联网项目，MyBatis将是不错的选择。



30 AOP的切面和连接点是什么？通知有哪几类？
一、关于AOP
1. 什么是 AOP?
Aspect Orentied Programming：面向切面编程
Object Orentied Programming：面向对象编程
AOP 编程是以 OOP  为基础，OOP 侧重点是对象抽象和封装，AOP 侧重点时共通处理部分的封装和使用，用于改善共通组件。是对 OOP 的补充和完善

2. AOP 的作用
分离系统中的各种关注点，将核心关注点和横切关注点分离开来。举个例子：开发中为了调试，或在生产环境后为了对系统进行监控，需要为业务需求的实现对象添加日志记录功能，或者，业务方法的执行需要一定的权限限制。如果以面向对象的方式实现，就需要把系统中的每个业务对象都加入日志记录，加入相应的安全检查，那么，这些实现代码就会遍及所有的业务对象中。如果对这些代码进行模块化的组织，简化系统需求与实现之间的对比关系，通过某种方式在适当的时候调用这些代码，那么就不用每个业务方法里都写着相同的代码了

3. 什么时候用AOP
日志功能
安全检查
事务管理
缓存


二、AOP 相关概念
1.Joinpoint
Joinpoint 就是进行织入操作的系统执行点

2.Pointcut
是 Joinpoint的表述方式，指定了系统中符合条件的一组 Joinpoint

3.Advice
Advice 代表的是织入到 Joinpoint 的横切逻辑
分类：
Before Advice：在指定位置之前执行，可以做一些初始化工作，比如设置系统初始值，获取必要系统资源
After Advice
After returning Advice ：当 当前 Joinpoint 正常执行完后，比如方法正常返回而没有抛出异常
After throwing Advice：当 当前 Joinpoint 执行过程中抛出异常的情况下，才会执行
After Advice：不管是否正常返回，都会执行，相当于 finally 块一样
Around Advice：可以在 Joinpoint 之前 或者 之后都能执行相应的逻辑，Filter功能就是其中的一种实现。可以用来系统安全验证及检查，简单的日志记录以及系统附加行为的添加

4.Aspect
是对系统中的横切关注点逻辑进行模块化封装的 AOP 概念实体，其可以包含多个 Pointcut 以及相关 Advice定义。
如果将 Aspect 比作 OOP 中的Class，那么 Advice 就相当于 CLass 中的 Method

5.织入和织入器
AspectJ 有专门的编译器来完成织入操作，ProxyFactory 是 Spring AOP 中最通用的织入器

6.目标对象
符合 Pointcut 所指定的条件，在织入过程中被织入横切逻辑的对象



三、Spring AOP 的实现机制
1. 实现机制
spring AOP 属于第二代AOP（动态AOP），采用动态代理机制和字节码生成技术实现，与最初的 AspectJ采用编译器将横切逻辑织入目标对象不同，动态代理机制和字节码生成都是在运行期间为目标对象生成一个代理对象，而将横切逻辑织入到这个代理对象中，系统最终使用的是织入了横切逻辑的代理对象，而不是真正的目标对象

2.动态代理
一般的代理模式是有多少需要代理的对象就要写多少代理类，但是jdk 1.3 之后引入了一种称之为动态代理的机制，使用该机制，可以为指定的接口在系统运行期间动态的生成代理对象
实现：
java.lang.reflect.Proxy 类 和 java.lang.reflect.InvocatingHandler 接口。当 Proxy动态生成的代理对象上的相应的接口方法被调用时，对应的InvocationHandler就会拦截相应的方法调用，并进行相应的处理。InvocationHandler 就是实现横切逻辑的地方，是横切逻辑的载体
适用：
只能对实现了相应 Interface 的类使用。如果目标对象没有实现任何 Interface，spring AOP 会尝试使用一个称为 CGLIB 的开源的动态字节码生成类库，为目标对象生成动态的代理对象实例
3.动态字节码生成
原理：对目标对象进行继承扩展，为其生成相应的子类，而子类可以通过重写类扩展父类的行为，只要将横切逻辑的实现放到子类中，然后让系统使用扩展后的目标对象的子类，就OK了。（在系统运行期间动态为目标对象生成相应的扩展子类）



31自己开发一个线程池，有什么思路？
（队列+调度+主任务）
1 什么是线程池
线程池就是以一个或多个线程[循环执行]多个应用逻辑的线程集合.
一般而言,线程池有以下几个部分:
完成主要任务的一个或多个线程.
用于调度管理的管理线程.
要求执行的任务队列.

2 线程池的作用：
线程池作用就是限制系统中执行线程的数量。
根据系统的环境情况，可以自动或手动设置线程数量，达到运行的最佳效果；少了浪费了系统资源，多了造成系统拥挤效率不高。用线程池控制线程数量，其他线程排队等候。一个任务执行完毕，再从队列的中取最前面的任务开始执行。若队列中没有等待进程，线程池的这一资源处于等待。当一个新任务需要运行时，如果线程池中有等待的工作线程，就可以开始运行了；否则进入等待队列。

3 自己实现线程池
根据如上对线程池的理解，我们自己编写一个属于自己的简单线程池:

4 简单的线程池接口:
public interface ThreadPool<Job extends Runnable>{
//执行一个任务(Job),这个Job必须实现Runnable
void execute(Job job);
//关闭线程池
void shutdown();
//增加工作者线程，即用来执行任务的线程
void addWorkers(int num);
//减少工作者线程
void removeWorker(int num);
//获取正在等待执行的任务数量
void getJobSize();
}

客户端可以通过execute(Job)方法将Job提交入线程池来执行，客户端完全不用等待Job的执行完成。除了execute(Job)方法以外，线程池接口提供了增加/减少工作者线程以及关闭线程池的方法。每个客户端提交的Job都会进入到一个工作队列中等待工作者线程的处理。
线程池接口的默认实现
public class DefaultThreadPool<Job extends Runnable> implements ThreadPool<Job>{
// 线程池维护工作者线程的最大数量
private static final int MAX_WORKER_NUMBERS = 10;
// 线程池维护工作者线程的默认值
private static final int DEFAULT_WORKER_NUMBERS = 5;
// 线程池维护工作者线程的最小数量
private static final int MIN_WORKER_NUMBERS = 1;
// 维护一个工作列表,里面加入客户端发起的工作
private final LinkedList<Job> jobs = new LinkedList<Job>();
// 工作者线程的列表
private final List<Worker> workers = Collections.synchronizedList(new ArrayList<Worker>());
// 工作者线程的数量
private int workerNum;
// 每个工作者线程编号生成
private AtomicLong threadNum = new AtomicLong();
//生成线程池
public DefaultThreadPool() {
this.workerNum = DEFAULT_WORKER_NUMBERS;
initializeWorkers(this.workerNum);
}
public DefaultThreadPool(int num) {
if (num > MAX_WORKER_NUMBERS) {
this.workerNum =DEFAULT_WORKER_NUMBERS;
} else {
this.workerNum = num;
}
initializeWorkers(this.workerNum);
}
//初始化每个工作者线程
private void initializeWorkers(int num) {
for (int i = 0; i < num; i++) {
Worker worker = new Worker();
//添加到工作者线程的列表
workers.add(worker);
//启动工作者线程
Thread thread = new Thread(worker);
thread.start();
}
}
public void execute(Job job) {
if (job != null) {
//根据线程的"等待/通知机制"这里必须对jobs加锁
synchronized (jobs) {
jobs.addLast(job);
jobs.notify();
}
}
}
//关闭线程池即关闭每个工作者线程
public void shutdown() {
for (Worker w : workers) {
w.shutdown();
}
}
//增加工作者线程
public void addWorkers(int num) {
//加锁，防止该线程还么增加完成而下个线程继续增加导致工作者线程超过最大值
synchronized (jobs) {
if (num + this.workerNum > MAX_WORKER_NUMBERS) {
num = MAX_WORKER_NUMBERS - this.workerNum;
}
initializeWorkers(num);
this.workerNum += num;
}
}
//减少工作者线程
public void removeWorker(int num) {
synchronized (jobs) {
if(num>=this.workerNum){
throw new IllegalArgumentException("超过了已有的线程数量");
}
for (int i = 0; i < num; i++) {
Worker worker = workers.get(i);
if (worker != null) {
//关闭该线程并从列表中移除
worker.shutdown();
workers.remove(i);
}
}
this.workerNum -= num;
}
}
public int getJobSize() {
// TODO Auto-generated method stub
return workers.size();
}
//定义工作者线程
class Worker implements Runnable {
// 表示是否运行该worker
private volatile boolean running = true;
public void run() {
while (running) {
Job job = null;
//线程的等待/通知机制
synchronized (jobs) {
if (jobs.isEmpty()) {
try {
jobs.wait();//线程等待唤醒
} catch (InterruptedException e) {
//感知到外部对该线程的中断操作，返回
Thread.currentThread().interrupt();
return;
}
}
// 取出一个job
job = jobs.removeFirst();
}
//执行job
if (job != null) {
job.run();
}
}
}
// 终止该线程
public void shutdown() {
running = false;
}
}
}

从线程池的实现中可以看出，当客户端调用execute(Job)方法时，会不断地向任务列表jobs中添加Job，而每个工作者线程会不读的从jobs上获取Job来执行，当jobs为空时，工作者线程进入WAITING状态。
当添加一个Job后，对工作队列jobs调用其notify()方法来唤醒一个工作者线程。此处我们不调用notifyAll(),避免将等待队列中的线程全部移动到阻塞队列中而造成资源浪费。
线程池的本质就是使用了一个线程安全的工作队列连接工作者线程和客户端线程。客户端线程把任务放入工作队列后便返回，而工作者线程则不端的从工作队列中取出工作并执行。当工作队列为空时，
工作者线程进入WAITING状态，当有客户端发送任务过来后会通过任意一个工作者线程，随着大量任务的提交，更多的工作者线程被唤醒。




32什么是开闭原则？
　   软件开发之所以会有这些原则，就是因为复杂多变且不可预料的需求。并不是说在实际项目开发中对这六大原则中的每一条都遵循到极致，而是说在项目开发的过程中，
     根据项目的实际需求尽量的去遵守这些原则。当然要做到这些肯定是不容易的，能真正做到并且做好的恐怕也只能是有经验之人。
    （1）Single Responsibility Principle　 : 单一职责原则，应该有且只有一个原因引起类的变更。换句话说就是一个接口只做一件事，即一个职责一个接口。但是困难的是划分职责时并没有一个标准，最终都是需要从实际的
	 项目去考虑。我们在设计的时候，尽量单一，然后对于其实现类就要多方面的考虑。不能死套单一职责原则，否则会增加很多类，给维护带来不便。
　　（2）Liskov Substitution Principle     : 里氏替换原则，里氏替换原则简单易懂一点的定义就是只要父类出现的地方子类就可以出现，且替换成子类也不会出现任何错误或者异常。(但是反过来，有子类出现的地方，父类不一定可以适用)。
　　（3）Dependence Inversion Principle ：依赖倒置原则，精简的定义就是面向接口编程。在Java语言中的表现就是为以下的三点
　　　　① 模块间的依赖关系通过接口和抽象类产生，实体类之间不直接发生依赖关系。
　      ②接口和抽象类不依赖于实现类。
　　    ③实现类依赖接口或者抽象类。
　　（4）Interface Segregation Principle  : 接口隔离原则， 建立单一接口，不要建立臃肿庞大的接口。即接口尽量细化，同时接口中的方法尽量少。在这里提一下单一职责和接口隔离原则的区别。首先两个侧重点是不一样的，单一职责要求类和接口，或者方法的职责单一，侧重点在职责，这是根据业务逻辑进行划分的。而接口隔离原则要接口中的方法尽量少。比如，一个接口或者一个中有十个方法，不同的方法做不同的事情，但是这个接口总体就是处理一件事情，然后具体细分成了10个方法。不同的模块根据不同的权限进行访问，这是符单一职责原则的。但是按照接口隔离的原则是要求接口接口中的方法尽量少，落实到这个实例就是要求尽量多几个专门的接口供不同的模块使用，而不是只有一个臃肿的接口，依据权限去限制不同模块可以访问的方法。
　　（5）Law of Demeter　　　　           : 迪米特法则，迪米特法则也叫做最少知识原则(Least Knowledge Principle,LKP)，即一个对象应该对其他对象有最少的了解，也就是说一个类要对自己需要耦合或者调用的类知道的最少。我只知道你有多少public方法可以供我调用，而其他的一切都与我无关。
　　（6）Open Closed Principle               : 开闭原则，开闭原则是Java里最基础的设计原则。具体的定义是：一个软件实体，比如类，模块，函数应该对扩展开放，对修改关闭。说的通熟易懂一些就是一个软件实体应该通过扩展来实现变化，而不是通过修改已有的代码来实现改变。

　

33工厂方法模式和抽象工厂设计模式有什么区别？
开闭原则：对扩展开放，对修改封闭。静态工厂增加需要是修改源代码，对修改不封闭，不符合开闭原则。

一、Simple Factory 简单工厂模式（静态工厂）
1）Simple Factory模式属于创建型模式
2）简单工厂模式是由一个工厂（注意是一个！）对象决定创建出哪一种产品类的实例（例如你到肯德基说你要鸡腿，要薯条，要饮料还是其他的，这时肯德基是一个工厂，客户端只需要点明自己要什么就行）
3）实现方式的实质：由一个工厂类根据传入的参数，动态决定应该创建哪一个产品类（这些产品类继承自一个父类或接口）的实例。
UML类图如下：
这里写图片描述
分析：
工厂角色：被客户端直接调用，根据客户端指定传入的参数，动态创建客户端需要的对象；
抽象产品角色：所有对象的父类（接口）；
具体产品角色：即工厂的创建目标，工厂创建的对象就是这些具体类的对象。
可以看出，客户端只面对工厂，不用管产品的具体细节，客户只需向工厂要求你需要什么，其他的事情都交给工厂了。
优点：
通过使用工厂类,外界可以从直接创建具体产品对象的尴尬局面摆脱出来,仅仅需要负责“消费”对象就可以了。而不必管这些对象究竟如何创建及如何组织的．明确了各自的职责和权利。（简单地说，你到肯德基去只需要说你要鸡腿还是鸡翅就行了，不需要去管鸡腿和鸡翅是怎么做出来的，工厂为你提供了这样一个界面）。
不足：
由于工厂类集中了所有实例的创建逻辑，违反了高内聚责任分配原则，将全部创建逻辑集中到了一个工厂类中；它所能创建的类只能是事先考虑到的，如果需要添加新的类，则就需要改变工厂类了。
当系统中的具体产品类不断增多时候，可能会出现要求工厂类根据不同条件创建不同实例的需求．这种对条件的判断和对具体产品类型的判断交错在一起，很难避免模块功能的蔓延，对系统的维护和扩展非常不利；
使用场景
工厂类负责创建的对象比较少； 　　
客户只知道传入工厂类的参数，对于如何创建对象（逻辑）不关心； 　
由于简单工厂很容易违反高内聚责任分配原则，因此一般只在很简单的情况下应用。
从上面的例子也可以看出来，工厂类往往是用反射机制来产生具体对象的。（因为不同类都继承自同一接口），故其扩展性很有限，产品种类必须是事先就知道的哪几种，什么时候你想要添加一个不是公共接口下的具体类就不行了。
另外，如果你不用反射机制，也不要公共接口，在工厂中使用其他逻辑（例如判断传入的字符串）来根据用户参数创建对象也行，那样扩展性也是很糟糕的，逻辑和添加只会越来多。
工厂方法模式
这个和简单工厂有区别，简单工厂模式只有一个工厂，工厂方法模式对每一个产品都有相应的工厂。
好处：增加一个运算类（例如N次方类），只需要增加运算类和相对应的工厂，两个类，不需要修改工厂类。
缺点：增加运算类，会修改客户端代码，工厂方法只是把简单工厂的内部逻辑判断移到了客户端进行。

二、Abstract Factory 抽象工厂
UML类图如下：
这里写图片描述
参与者
AbstractFactory——声明一个创建抽象产品对象的操作接口
ConcreteFactory——实现创建具体产品对象的操作
AbstractProduct——为一类产品对象声明一个接口
ConcreteProduct
① 定义一个将被相应的具体工厂创建的产品对象
② 实现AbstractProduct接口
Client
① 仅使用由AbstractFactory和AbstractProduct类声明的接口
协作
① 通常在运行时刻创建一个ConcreteFactory类的实例。这一具体的工厂创建具有特定实现的产品对象。为创建不同的产品对象，客户应适用不同的具体工厂。
②AbstractFactory将产品对象的创建延迟到它的ConcreteFactory子类。


三、工厂方法模式：
① 一个抽象产品类，可以派生出多个具体产品类。
② 一个抽象工厂类，可以派生出多个具体工厂类。
③ 每个具体工厂类只能创建一个具体产品类的实例。
抽象工厂模式：
① 多个抽象产品类，每个抽象产品类可以派生出多个具体产品类。
② 一个抽象工厂类，可以派生出多个具体工厂类。
③ 每个具体工厂类可以创建多个具体产品类的实例。
区别：
① 工厂方法模式只有一个抽象产品类，而抽象工厂模式有多个。
② 工厂方法模式的具体工厂类只能创建一个具体产品类的实例，而抽象工厂模式可以创建多个。 


34 nginx静态代理怎么理解，应用什么场景？
github 中很多项目都有一个 readme 文件，很多人喜欢在文件中添加自己的创作或封面图片，比如 substack 为他的每个项目绘制了一个 logo。这些图片在 github 中能直接在页面中显示出来，不过 url 被替换成了 github 自己的。比如在 browserify 项目中，logo 的链接变成了
https://camo.githubusercontent.com/e19e230a9371a44a2eeb484b83ff4fcf8c824cf7/687474703a2f2f737562737461636b2e6e65742f696d616765732f62726f777365726966795f6c6f676f2e706e67

而我们通过查看 raw 能发现原 url 是
http://substack.net/images/browserify_logo.png

这样做的一个好处是防止因为在 https 网站中出现 http 链接，否则在客户端会得到一个风险警告。github 在细节上真是考虑的十分周到。
既然有需求，我们就来实现它。通常的做法是写一个应用去抓取远程的静态资源，然后反馈给前端，这就是一个简单地反向代理了。但是这样做比较繁琐，效率也未见得高，其实我们可以直接通过 nginx 来代理这些静态文件。
nginx 的 proxy_pass 支持填写任意地址，并且支持 dns 解析。所以我的思路是，将原 url 加密转成网站自身的 url。比如上面的
http://substack.net/images/browserify_logo.png
可以加密成
764feebffb1d3f877e9e0d0fadcf29b85e8fe84ae4ce52f7dc4ca4b3e05bf1718177870a996fe5804a232fcae5b893ea (加密和序列化算法网上有很多，在此就不赘述了)

然后放在我们自己的域名下：
https://ssl.youdomain.com/camo/764feebffb1d3f877e9e0d0fadcf29b85e8fe84ae4ce52f7dc4ca4b3e05bf1718177870a996fe5804a232fcae5b893ea

解密的步骤用 nginx 会比较难实现，所以当用户通过上述链接请求时，先讲请求传递给解密程序，这里有一个 coffeescript 版本的例子：

express = require 'express'
app = express()
app.get '/camo/:eurl', (req, res) ->
  {eurl} = req.params
  {camoSecret} = config  # 这里使用自己的密钥
  rawUrl = util.decrypt eurl, camoSecret
  return res.status(403).end('INVALID URL') unless rawUrl
  res.set 'X-Origin-Url', rawUrl
  res.set 'X-Accel-Redirect', '/remote'
  res.end()
app.listen 3000

然后写入 X-Accel-Redirect 响应头做内部跳转，下面的步骤就由 nginx 完成了。
下面是一个完整的 nginx 配置文件例子：

server {
    listen 80;
    server_name ssl.youdomain.com;
    location /camo/ {
        proxy_pass http://localhost:3000;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header Host $http_host;
        proxy_set_header X-NginX-Proxy true;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "Upgrade";
        proxy_redirect off;
        break;
    }
    location /remote {
        internal;
        resolver 192.168.0.21;  # 必须加上 dns 服务器地址，否则 nginx 无法解析域名
        set $origin_url $upstream_http_x_origin_url;
        proxy_pass $origin_url;
        add_header Host "file.local.com";
        break;
    }
}

nginx 的 upstream 模块会把所有的响应头加上 $upstream_http_ 前缀当成一个变量保存，所以在上面的例子中我们将原 url 放在 X-Origin-Url 响应头中，在 nginx 就变成了 $upstream_http_x_origin_url 变量，但是在 proxy_pass 中不能直接引用，非要通过 set 来设置才能引用，这个我不是很理解，希望有高手能解答。
这样下来，每次当用户请求
https://ssl.youdomain.com/camo/764feebffb1d3f877e9e0d0fadcf29b85e8fe84ae4ce52f7dc4ca4b3e05bf1718177870a996fe5804a232fcae5b893ea

时，nginx 就会去抓取
http://substack.net/images/browserify_logo.png
的内容返回给用户。我们还可以在 nginx 之前加上 varnish，用以缓存静态文件的内容。这样就跟 githubusercontent 的做法更加一致了。



35 kafka怎么防止数据丢失？吞吐量所少？
Kafka到底会不会丢数据(data loss)? 通常不会，但有些情况下的确有可能会发生。下面的参数配置及Best practice列表可以较好地保证数据的持久性(当然是trade-off，牺牲了吞吐量)。笔者会在该列表之后对列表中的每一项进行讨论，有兴趣的同学可以看下后面的分析。
    block.on.buffer.full = true
    acks = all
    retries = MAX_VALUE
    max.in.flight.requests.per.connection = 1
    使用KafkaProducer.send(record, callback)
    callback逻辑中显式关闭producer：close(0) 
    unclean.leader.election.enable=false
    replication.factor = 3 
    min.insync.replicas = 2
    replication.factor > min.insync.replicas
    enable.auto.commit=false
    消息处理完成之后再提交位移
给出列表之后，我们从两个方面来探讨一下数据为什么会丢失：

1. Producer端
　　目前比较新版本的Kafka正式替换了Scala版本的old producer，使用了由Java重写的producer。新版本的producer采用异步发送机制。KafkaProducer.send(ProducerRecord)方法仅仅是把这条消息放入一个缓存中(即RecordAccumulator，本质上使用了队列来缓存记录)，同时后台的IO线程会不断扫描该缓存区，将满足条件的消息封装到某个batch中然后发送出去。显然，这个过程中就有一个数据丢失的窗口：若IO线程发送之前client端挂掉了，累积在accumulator中的数据的确有可能会丢失。
　　Producer的另一个问题是消息的乱序问题。假设客户端代码依次执行下面的语句将两条消息发到相同的分区
producer.send(record1);
producer.send(record2);

如果此时由于某些原因(比如瞬时的网络抖动)导致record1没有成功发送，同时Kafka又配置了重试机制和max.in.flight.requests.per.connection大于1(默认值是5，本来就是大于1的)，那么重试record1成功后，record1在分区中就在record2之后，从而造成消息的乱序。很多某些要求强顺序保证的场景是不允许出现这种情况的。
　　鉴于producer的这两个问题，我们应该如何规避呢？？对于消息丢失的问题，很容易想到的一个方案就是：既然异步发送有可能丢失数据， 我改成同步发送总可以吧？比如这样：

producer.send(record).get();

这样当然是可以的，但是性能会很差，不建议这样使用。因此特意总结了一份配置列表。个人认为该配置清单应该能够比较好地规避producer端数据丢失情况的发生：(特此说明一下，软件配置的很多决策都是trade-off，下面的配置也不例外：应用了这些配置，你可能会发现你的producer/consumer 吞吐量会下降，这是正常的，因为你换取了更高的数据安全性)

    block.on.buffer.full = true  尽管该参数在0.9.0.0已经被标记为“deprecated”，但鉴于它的含义非常直观，所以这里还是显式设置它为true，使得producer将一直等待缓冲区直至其变为可用。否则如果producer生产速度过快耗尽了缓冲区，producer将抛出异常
    acks=all  很好理解，所有follower都响应了才认为消息提交成功，即"committed"
    retries = MAX 无限重试，直到你意识到出现了问题:)
    max.in.flight.requests.per.connection = 1 限制客户端在单个连接上能够发送的未响应请求的个数。设置此值是1表示kafka broker在响应请求之前client不能再向同一个broker发送请求。注意：设置此参数是为了避免消息乱序
    使用KafkaProducer.send(record, callback)而不是send(record)方法   自定义回调逻辑处理消息发送失败
    callback逻辑中最好显式关闭producer：close(0) 注意：设置此参数是为了避免消息乱序
    unclean.leader.election.enable=false   关闭unclean leader选举，即不允许非ISR中的副本被选举为leader，以避免数据丢失
    replication.factor >= 3   这个完全是个人建议了，参考了Hadoop及业界通用的三备份原则
    min.insync.replicas > 1 消息至少要被写入到这么多副本才算成功，也是提升数据持久性的一个参数。与acks配合使用
    保证replication.factor > min.insync.replicas  如果两者相等，当一个副本挂掉了分区也就没法正常工作了。通常设置replication.factor = min.insync.replicas + 1即可

2. Consumer端
　　consumer端丢失消息的情形比较简单：如果在消息处理完成前就提交了offset，那么就有可能造成数据的丢失。由于Kafka consumer默认是自动提交位移的，所以在后台提交位移前一定要保证消息被正常处理了，因此不建议采用很重的处理逻辑，如果处理耗时很长，则建议把逻辑放到另一个线程中去做。为了避免数据丢失，现给出两点建议：
    enable.auto.commit=false  关闭自动提交位移
    在消息被完整处理之后再手动提交位移




36 Java 内存模型中的可见性、原子性和有序性怎么理解？
Java内存模型是围绕着在并发过程中如何处理原子性、可见性和有序性这3个特征来建立的。
    原子性（Atomicity）：由Java内存模型来直接保证的原子性变量操作包括read、load、use、assign、store、write，我们大致可以认为基本数据类型的访问读写是具备原子性的。
    如果需要一个更大范围的原子性操作，Java内存模型提供了lock和unlock操作来满足这种需求，尽管虚拟机未把lock和unlock操作直接开放给用户使用，但是却提供了更高层次的字节码指令monitorenter和monitorexit来隐式地使用这两个操作，这两个字节码指令反应到Java代码中就是同步块---synchronized关键字，所以在synchronized块之间的操作也具备原子性。
    可见性（Visibility）：可见性是指当一个线程修改了共享变量的值，其他线程能够立即得知这个修改。volatile、synchronized、final都可以实现可见性，synchronized可见性是由对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操作）这条规则获得的，        而final关键字的可见性是指：被final修饰的字段在构造器中一旦被初始化完成，并且构造器没有把this的引用传递出去，那在其他线程中就能见final字段的值。
    有序性（Ordering）：Java程序中天然的有序性可以总结为一句话：如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句是指线程内表现为串行的语义（within-Thread  AS-if-Serial Semantics），后半句是指指令重排序现象和工作内存和猪呢从同步延迟现象。
    Java语言提供了volatile和synchronized两个关键字来保证线程之间操作的有序性，volatile关键字本身就包含了禁止指令重排序的语义，而synchronized则是由一个变量在同一时刻只允许一条线程对其进行lock做这条规则获得的，这条规则决定了持有同一个锁的两个同步块只能串行的进入。
    先行发生原则（happens-before）是针对于内存模型中的有序性来说的。先行发生是java内存模型中定义的两项操作之间的偏序关系。

以下是java内存模型下一些天然的先行发生关系，这些先行发生关系无须任何同步器协助就已经存在，可以在编码中直接使用，如果通过下面关系无法确定顺序性，虚拟机可以对其随意地进行重排序。
    程序次序规则（Program  Order  Rule）：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确地说，应该是控制流顺序而不是程序代码顺序，因为考虑分支、循环等结构。
    管程锁定规则（Monitor Lock Rule）：一个unlock操作先行发生于后面对同一个锁的lock操作，这里必须强调的是同一个多，而“后面”是指时间上的先后顺序。
    volatile变量规则（Volatile  Variable Rule）：对一个volatile变量的写操作先行发生于后面对这个变量的读操作，“后面”是指时间上的先后顺序。
    线程启动规则（Thread Start  Rule）：Thread对象的start（）方法先行发生于此线程的每一个动作。
    线程终止规则（Thread Termination Rule）：线程中的所有操作都先行发生于对此线程的终止检测，可以通过Thread.join()方法结束、Thread.isAlive()的返回值等手段检测到线程已经终止执行。
    线程中断规则（Thread  Interruption Rule）：对线程interrupt（）方法的调用先行发生于被中断线程的代码检测到中断时间的发生，可以通过Thread.interrupted()方法检测到是否有中断发生。
    对象终结规则（Finalizer  Rule）：一个对象的初始化完成（构造函数执行结束）先行发生于它的finalize（）方法的开始。
    传递性（Transitivity）：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。
时间先后顺序与先行发生原则之间基本没有太大的关系，所以衡量并发安全问题的时候不要受到时间顺序的干扰，一切必须以先行发生原则为准。



37 有没使用过thread dump和heap dump？
一.dump基本概念
        在故障定位(尤其是out of memory)和性能分析的时候，经常会用到一些文件来帮助我们排除代码问题。这些文件记录了JVM运行期间的内存占用、线程执行等情况，这就是我们常说的dump文件。常用的有heap dump和thread dump（也叫javacore，或java dump）。我们可以这么理解：heap dump记录内存信息的，thread dump是记录CPU信息的。
        heap dump：
        heap dump文件是一个二进制文件，它保存了某一时刻JVM堆中对象使用情况。HeapDump文件是指定时刻的Java堆栈的快照，是一种镜像文件。Heap Analyzer工具通过分析HeapDump文件，哪些对象占用了太多的堆栈空间，来发现导致内存泄露或者可能引起内存泄露的对象。
        thread dump：
        thread dump文件主要保存的是java应用中各线程在某一时刻的运行的位置，即执行到哪一个类的哪一个方法哪一个行上。thread dump是一个文本文件，打开后可以看到每一个线程的执行栈，以stacktrace的方式显示。通过对thread dump的分析可以得到应用是否“卡”在某一点上，即在某一点运行的时间太长，如数据库查询，长期得不到响应，最终导致系统崩溃。单个的thread dump文件一般来说是没有什么用处的，因为它只是记录了某一个绝对时间点的情况。比较有用的是，线程在一个时间段内的执行情况。
两个thread dump文件在分析时特别有效，困为它可以看出在先后两个时间点上，线程执行的位置，如果发现先后两组数据中同一线程都执行在同一位置，则说明此处可能有问题，因为程序运行是极快的，如果两次均在某一点上，说明这一点的耗时是很大的。通过对这两个文件进行分析，查出原因，进而解决问题。
 
二.利用JDK自带的工具获取thread dump文件和heap dump文件
        使用的JDK工具在JDK_HOME/bin/目录下，使用到jmap和jstack这两个命令。
1.获取heap dump文件
        windows下切换到JDK_HOME/bin/，执行以下命令：jmap -dump:format=b,file=heap.hprof 2576 
        linux下切换到JDK_HOME/bin/，执行以下命令：./jmap -dump:format=b,file=heap.hprof 2576
        这样就会在当前目录下生成heap.hprof文件，这就是heap dump文件。
2.获取thread dump文件
        windows下执行：jstack 2576 > thread.txt
        linux下执行：./jstack 2576 > thread.txt
        windows/linux则会将命令执行结果转储到thread.txt，这就是thread dump文件。有了dump文件后，我们就能借助性能分析工具获取dump文件中的信息。
3.如果我们只需要将dump中存活的对象导出，那么可以使用:live参数
jmap -dump:live,format=b,file=heapLive.hprof 2576   

        执行完后，我们在当前目录C:\Java\jdk1.6.0_27\bin下看到刚生成的三个文件，如下所示：

        说明：如上实例的2576是我当前需要分析的java进程PID，关于Windows下如何获得指定的JAVA时空程PID可参考：http://bijian1013.iteye.com/blog/2221238
 
三.使用工具分析java heap dump文件
        现在我们使用一些图形化工具，来帮助我们分析文件中的信息，有效地定位问题。
1.使用JDK自带的jhat命令
        jhat是用来分析java堆的命令，可以将堆中的对象以html的形式显示出来，包括对象的数量，大小等等，并支持对象查询语言。
jhat -port 5000 heap.hrof
        当服务启动完成后，我们就可以在浏览器中，通过http://localhost:5000/进行访问，如下所示：

2.使用eclipse MAT工具
        一般来说，应用程序的dump文件都是很大的，jdk自带命令难以分析这些大文件。在实际的生产环境下，我们必须要借助第三方工具，才能快速打开这些大文件，进行分析定位。eclipse memory analyzer是一款优秀的heap分析工具，能够帮我们快速定位内存泄露问题。




38 tomcat给你你怎样去调优? 
Tomcat 的缺省配置是不能稳定长期运行的，也就是不适合生产环境，它会死机，让你不断重新启动，甚至在午夜时分唤醒你。对于操作系统优化来说，是尽可能的增大可使用的内存容量、提高CPU 的频率，保证文件系统的读写速率等。经过压力测试验证，在并发连接很多的情况下，CPU 的处理能力越强，系统运行速度越快。
Tomcat 的优化不像其它软件那样，简简单单的修改几个参数就可以了，它的优化主要有三方面，分为系统优化，Tomcat 本身的优化，Java 虚拟机（JVM）调优。系统优化就不在介绍了，接下来就详细的介绍一下 Tomcat 本身与 JVM 优化，以 Tomcat 7 为例。

一、Tomcat 本身优化
Tomcat 的自身参数的优化，这块很像 ApacheHttp Server。修改一下 xml 配置文件中的参数，调整最大连接数，超时等。此外，我们安装 Tomcat 是，优化就已经开始了。

1、工作方式选择
为了提升性能，首先就要对代码进行动静分离，让 Tomcat 只负责 jsp 文件的解析工作。如采用 Apache 和 Tomcat 的整合方式，他们之间的连接方案有三种选择，JK、http_proxy 和 ajp_proxy。相对于 JK 的连接方式，后两种在配置上比较简单的，灵活性方面也一点都不逊色。但就稳定性而言不像JK 这样久经考验，所以建议采用 JK 的连接方式。 

2、Connector 连接器的配置
之前文件介绍过的 Tomcat 连接器的三种方式： bio、nio 和 apr，三种方式性能差别很大，apr 的性能最优， bio 的性能最差。而 Tomcat 7 使用的 Connector  默认就启用的 Apr 协议，但需要系统安装 Apr 库，否则就会使用 bio 方式。

3、配置文件优化
配置文件优化其实就是对 server.xml 优化，可以提大大提高 Tomcat 的处理请求的能力，下面我们来看 Tomcat 容器内的优化。
默认配置下，Tomcat 会为每个连接器创建一个绑定的线程池（最大线程数 200），服务启动时，默认创建了 5 个空闲线程随时等待用户请求。
首先，打开 ${TOMCAT_HOME}/conf/server.xml，搜索【<Executor name="tomcatThreadPool"】，开启并调整为

<Executor name="tomcatThreadPool" namePrefix="catalina-exec-"
maxThreads="500" minSpareThreads="20" maxSpareThreads="50" maxIdleTime="60000"/>
注意， Tomcat 7 在开启线程池前，一定要安装好 Apr 库，并可以启用，否则会有错误报出，shutdown.sh 脚本无法关闭进程。
然后，修改<Connector …>节点，增加 executor 属性，搜索【port="8080"】，调整为

<Connector executor="tomcatThreadPool"
port="8080" protocol="HTTP/1.1"
URIEncoding="UTF-8"
connectionTimeout="30000"
enableLookups="false"
disableUploadTimeout="false"
connectionUploadTimeout="150000"
acceptCount="300"
keepAliveTimeout="120000"
maxKeepAliveRequests="1"
compression="on"
compressionMinSize="2048"
compressableMimeType="text/html,text/xml,text/javascript,text/css,text/plain,image/gif,image/jpg,image/png" 
redirectPort="8443" />
maxThreads :Tomcat 使用线程来处理接收的每个请求，这个值表示 Tomcat 可创建的最大的线程数，默认值是 200
minSpareThreads：最小空闲线程数，Tomcat 启动时的初始化的线程数，表示即使没有人使用也开这么多空线程等待，默认值是 10。
maxSpareThreads：最大备用线程数，一旦创建的线程超过这个值，Tomcat 就会关闭不再需要的 socket 线程。
上边配置的参数，最大线程 500（一般服务器足以），要根据自己的实际情况合理设置，设置越大会耗费内存和 CPU，因为 CPU 疲于线程上下文切换，没有精力提供请求服务了，最小空闲线程数 20，线程最大空闲时间 60 秒，当然允许的最大线程连接数还受制于操作系统的内核参数设置，设置多大要根据自己的需求与环境。当然线程可以配置在“tomcatThreadPool”中，也可以直接配置在“Connector”中，但不可以重复配置。
URIEncoding：指定 Tomcat 容器的 URL 编码格式，语言编码格式这块倒不如其它 WEB 服务器软件配置方便，需要分别指定。
connnectionTimeout： 网络连接超时，单位：毫秒，设置为 0 表示永不超时，这样设置有隐患的。通常可设置为 30000 毫秒，可根据检测实际情况，适当修改。
enableLookups： 是否反查域名，以返回远程主机的主机名，取值为：true 或 false，如果设置为false，则直接返回IP地址，为了提高处理能力，应设置为 false。
disableUploadTimeout：上传时是否使用超时机制。
connectionUploadTimeout：上传超时时间，毕竟文件上传可能需要消耗更多的时间，这个根据你自己的业务需要自己调，以使Servlet有较长的时间来完成它的执行，需要与上一个参数一起配合使用才会生效。
acceptCount：指定当所有可以使用的处理请求的线程数都被使用时，可传入连接请求的最大队列长度，超过这个数的请求将不予处理，默认为100个。
keepAliveTimeout：长连接最大保持时间（毫秒），表示在下次请求过来之前，Tomcat 保持该连接多久，默认是使用 connectionTimeout 时间，-1 为不限制超时。
maxKeepAliveRequests：表示在服务器关闭之前，该连接最大支持的请求数。超过该请求数的连接也将被关闭，1表示禁用，-1表示不限制个数，默认100个，一般设置在100~200之间。
compression：是否对响应的数据进行 GZIP 压缩，off：表示禁止压缩；on：表示允许压缩（文本将被压缩）、force：表示所有情况下都进行压缩，默认值为off，压缩数据后可以有效的减少页面的大小，一般可以减小1/3左右，节省带宽。
compressionMinSize：表示压缩响应的最小值，只有当响应报文大小大于这个值的时候才会对报文进行压缩，如果开启了压缩功能，默认值就是2048。
compressableMimeType：压缩类型，指定对哪些类型的文件进行数据压缩。
noCompressionUserAgents="gozilla, traviata"： 对于以下的浏览器，不启用压缩。
如果已经对代码进行了动静分离，静态页面和图片等数据就不需要 Tomcat 处理了，那么也就不需要配置在 Tomcat 中配置压缩了。
以上是一些常用的配置参数属性，当然还有好多其它的参数设置，还可以继续深入的优化，HTTP Connector 与 AJP Connector 的参数属性值，可以参考官方文档的详细说明：
https://tomcat.apache.org/tomcat-7.0-doc/config/http.html
https://tomcat.apache.org/tomcat-7.0-doc/config/ajp.html


二、JVM 优化
Tomcat 启动命令行中的优化参数，就是 JVM 的优化 。Tomcat 首先跑在 JVM 之上的，因为它的启动其实也只是一个 java 命令行，首先我们需要对这个 JAVA 的启动命令行进行调优。不管是 YGC 还是 Full GC，GC 过程中都会对导致程序运行中中断，正确的选择不同的 GC 策略，调整 JVM、GC 的参数，可以极大的减少由于 GC 工作，而导致的程序运行中断方面的问题，进而适当的提高 Java 程序的工作效率。但是调整 GC 是以个极为复杂的过程，由于各个程序具备不同的特点，如：web 和 GUI 程序就有很大区别（Web可以适当的停顿，但GUI停顿是客户无法接受的），而且由于跑在各个机器上的配置不同（主要 cup 个数，内存不同），所以使用的 GC 种类也会不同。

1、JVM 参数配置方法
Tomcat 的启动参数位于安装目录 ${JAVA_HOME}/bin目录下，Linux 操作系统就是 catalina.sh 文件。JAVA_OPTS，就是用来设置 JVM 相关运行参数的变量，还可以在 CATALINA_OPTS 变量中设置。关于这 2 个变量，还是多少有些区别的：
JAVA_OPTS：用于当 Java 运行时选项“start”、“stop”或“run”命令执行。
CATALINA_OPTS：用于当 Java 运行时选项“start”或“run”命令执行。
为什么有两个不同的变量？它们之间都有什么区别呢？
首先，在启动 Tomcat 时，任何指定变量的传递方式都是相同的，可以传递到执行“start”或“run”命令中，但只有设定在 JAVA_OPTS 变量里的参数被传递到“stop”命令中。对于 Tomcat 运行过程，可能没什么区别，影响的是结束程序，而不是启动程序。
第二个区别是更微妙，其他应用程序也可以使用 JAVA_OPTS 变量，但只有在 Tomcat 中使用 CATALINA_OPTS 变量。如果你设置环境变量为只使用 Tomcat，最好你会建议使用 CATALINA_OPTS 变量，而如果你设置环境变量使用其它的 Java 应用程序，例如 JBoss，你应该把你的设置放在JAVA_OPTS 变量中。

2、JVM 参数属性
32 位系统下 JVM 对内存的限制：不能突破 2GB ，那么这时你的 Tomcat 要优化，就要讲究点技巧了，而在 64 位操作系统上无论是系统内存还是 JVM 都没有受到 2GB 这样的限制。
针对于 JMX 远程监控也是在这里设置，以下为 64 位系统环境下的配置，内存加入的参数如下：
CATALINA_OPTS="
-server 
-Xms6000M 
-Xmx6000M 
-Xss512k 
-XX:NewSize=2250M 
-XX:MaxNewSize=2250M 
-XX:PermSize=128M
-XX:MaxPermSize=256M  
-XX:+AggressiveOpts 
-XX:+UseBiasedLocking 
-XX:+DisableExplicitGC 
-XX:+UseParNewGC 
-XX:+UseConcMarkSweepGC 
-XX:MaxTenuringThreshold=31 
-XX:+CMSParallelRemarkEnabled 
-XX:+UseCMSCompactAtFullCollection 
-XX:LargePageSizeInBytes=128m 
-XX:+UseFastAccessorMethods 
-XX:+UseCMSInitiatingOccupancyOnly
-Duser.timezone=Asia/Shanghai 
-Djava.awt.headless=true"
为了看着方便，将每个参数单独写一行。上面参数好多啊，可能有人写到现在都没见过一个在 Tomcat 的启动命令里加了这么多参数，当然，这些参数只是我机器上的，不一定适合你，尤其是参数后的 value（值）是需要根据你自己的实际情况来设置的。
上述这样的配置，基本上可以达到：
系统响应时间增快；
JVM回收速度增快同时又不影响系统的响应率；
JVM内存最大化利用；
线程阻塞情况最小化。

JVM 常用参数详解：
-server：一定要作为第一个参数，在多个 CPU 时性能佳，还有一种叫 -client 的模式，特点是启动速度比较快，但运行时性能和内存管理效率不高，通常用于客户端应用程序或开发调试，在 32 位环境下直接运行 Java 程序默认启用该模式。Server 模式的特点是启动速度比较慢，但运行时性能和内存管理效率很高，适用于生产环境，在具有 64 位能力的 JDK 环境下默认启用该模式，可以不配置该参数。
-Xms：表示 Java 初始化堆的大小，-Xms 与-Xmx 设成一样的值，避免 JVM 反复重新申请内存，导致性能大起大落，默认值为物理内存的 1/64，默认（MinHeapFreeRatio参数可以调整）空余堆内存小于 40% 时，JVM 就会增大堆直到 -Xmx 的最大限制。
-Xmx：表示最大 Java 堆大小，当应用程序需要的内存超出堆的最大值时虚拟机就会提示内存溢出，并且导致应用服务崩溃，因此一般建议堆的最大值设置为可用内存的最大值的80%。如何知道我的 JVM 能够使用最大值，使用 java -Xmx512M -version 命令来进行测试，然后逐渐的增大 512 的值,如果执行正常就表示指定的内存大小可用，否则会打印错误信息，默认值为物理内存的 1/4，默认（MinHeapFreeRatio参数可以调整）空余堆内存大于 70% 时，JVM 会减少堆直到-Xms 的最小限制。
-Xss：表示每个 Java 线程堆栈大小，JDK 5.0 以后每个线程堆栈大小为 1M，以前每个线程堆栈大小为 256K。根据应用的线程所需内存大小进行调整，在相同物理内存下，减小这个值能生成更多的线程，但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在 3000~5000 左右。一般小的应用， 如果栈不是很深， 应该是128k 够用的，大的应用建议使用 256k 或 512K，一般不易设置超过 1M，要不然容易出现out ofmemory。这个选项对性能影响比较大，需要严格的测试。
-XX:NewSize：设置新生代内存大小。
-XX:MaxNewSize：设置最大新生代新生代内存大小
-XX:PermSize：设置持久代内存大小
-XX:MaxPermSize：设置最大值持久代内存大小，永久代不属于堆内存，堆内存只包含新生代和老年代。
-XX:+AggressiveOpts：作用如其名（aggressive），启用这个参数，则每当 JDK 版本升级时，你的 JVM 都会使用最新加入的优化技术（如果有的话）。
-XX:+UseBiasedLocking：启用一个优化了的线程锁，我们知道在我们的appserver，每个http请求就是一个线程，有的请求短有的请求长，就会有请求排队的现象，甚至还会出现线程阻塞，这个优化了的线程锁使得你的appserver内对线程处理自动进行最优调配。
-XX:+DisableExplicitGC：在 程序代码中不允许有显示的调用“System.gc()”。每次在到操作结束时手动调用 System.gc() 一下，付出的代价就是系统响应时间严重降低，就和关于 Xms，Xmx 里的解释的原理一样，这样去调用 GC 导致系统的 JVM 大起大落。
-XX:+UseConcMarkSweepGC：设置年老代为并发收集，即 CMS gc，这一特性只有 jdk1.5
后续版本才具有的功能，它使用的是 gc 估算触发和 heap 占用触发。我们知道频频繁的 GC 会造面 JVM
的大起大落从而影响到系统的效率，因此使用了 CMS GC 后可以在 GC 次数增多的情况下，每次 GC 的响应时间却很短，比如说使用了 CMS
GC 后经过 jprofiler 的观察，GC 被触发次数非常多，而每次 GC 耗时仅为几毫秒。
-XX:+UseParNewGC：对新生代采用多线程并行回收，这样收得快，注意最新的 JVM 版本，当使用 -XX:+UseConcMarkSweepGC 时，-XX:UseParNewGC 会自动开启。因此，如果年轻代的并行 GC 不想开启，可以通过设置 -XX：-UseParNewGC 来关掉。
-XX:MaxTenuringThreshold：设置垃圾最大年龄。如果设置为0的话，则新生代对象不经过 Survivor 区，直接进入老年代。对于老年代比较多的应用（需要大量常驻内存的应用），可以提高效率。如果将此值设置为一 个较大值，则新生代对象会在 Survivor 区进行多次复制，这样可以增加对象在新生代的存活时间，增加在新生代即被回收的概率，减少Full GC的频率，这样做可以在某种程度上提高服务稳定性。该参数只有在串行 GC 时才有效，这个值的设置是根据本地的 jprofiler 监控后得到的一个理想的值，不能一概而论原搬照抄。
-XX:+CMSParallelRemarkEnabled：在使用 UseParNewGC 的情况下，尽量减少 mark 的时间。
-XX:+UseCMSCompactAtFullCollection：在使用 concurrent gc 的情况下，防止 memoryfragmention，对 live object 进行整理，使 memory 碎片减少。
-XX:LargePageSizeInBytes：指定 Java heap 的分页页面大小，内存页的大小不可设置过大， 会影响 Perm 的大小。
-XX:+UseFastAccessorMethods：使用 get，set 方法转成本地代码，原始类型的快速优化。
-XX:+UseCMSInitiatingOccupancyOnly：只有在 oldgeneration 在使用了初始化的比例后 concurrent collector 启动收集。
-Duser.timezone=Asia/Shanghai：设置用户所在时区。
-Djava.awt.headless=true：这个参数一般我们都是放在最后使用的，这全参数的作用是这样的，有时我们会在我们的 J2EE 工程中使用一些图表工具如：jfreechart，用于在 web 网页输出 GIF/JPG 等流，在 winodws 环境下，一般我们的 app server 在输出图形时不会碰到什么问题，但是在linux/unix 环境下经常会碰到一个 exception 导致你在 winodws 开发环境下图片显示的好好可是在 linux/unix 下却显示不出来，因此加上这个参数以免避这样的情况出现。
-Xmn：新生代的内存空间大小，注意：此处的大小是（eden+ 2 survivor space)。与 jmap -heap 中显示的 New gen 是不同的。整个堆大小 = 新生代大小 + 老生代大小 + 永久代大小。在保证堆大小不变的情况下，增大新生代后，将会减小老生代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的 3/8。
-XX:CMSInitiatingOccupancyFraction：当堆满之后，并行收集器便开始进行垃圾收集，例如，当没有足够的空间来容纳新分配或提升的对象。对于 CMS 收集器，长时间等待是不可取的，因为在并发垃圾收集期间应用持续在运行（并且分配对象）。因此，为了在应用程序使用完内存之前完成垃圾收集周期，CMS 收集器要比并行收集器更先启动。因为不同的应用会有不同对象分配模式，JVM 会收集实际的对象分配（和释放）的运行时数据，并且分析这些数据，来决定什么时候启动一次 CMS 垃圾收集周期。这个参数设置有很大技巧，基本上满足(Xmx-Xmn)*(100-CMSInitiatingOccupancyFraction)/100 >= Xmn 就不会出现 promotion failed。例如在应用中 Xmx 是6000，Xmn 是 512，那么 Xmx-Xmn 是 5488M，也就是老年代有 5488M，CMSInitiatingOccupancyFraction=90 说明老年代到 90% 满的时候开始执行对老年代的并发垃圾回收（CMS），这时还 剩 10% 的空间是 5488*10% = 548M，所以即使 Xmn（也就是新生代共512M）里所有对象都搬到老年代里，548M 的空间也足够了，所以只要满足上面的公式，就不会出现垃圾回收时的 promotion failed，因此这个参数的设置必须与 Xmn 关联在一起。
-XX:+CMSIncrementalMode：该标志将开启 CMS 收集器的增量模式。增量模式经常暂停 CMS 过程，以便对应用程序线程作出完全的让步。因此，收集器将花更长的时间完成整个收集周期。因此，只有通过测试后发现正常 CMS 周期对应用程序线程干扰太大时，才应该使用增量模式。由于现代服务器有足够的处理器来适应并发的垃圾收集，所以这种情况发生得很少，用于但 CPU情况。
-XX:NewRatio：年轻代（包括 Eden 和两个 Survivor 区）与年老代的比值（除去持久代），-XX:NewRatio=4 表示年轻代与年老代所占比值为 1:4，年轻代占整个堆栈的 1/5，Xms=Xmx 并且设置了 Xmn 的情况下，该参数不需要进行设置。
-XX:SurvivorRatio：Eden 区与 Survivor 区的大小比值，设置为 8，表示 2 个 Survivor 区（JVM 堆内存年轻代中默认有 2 个大小相等的 Survivor 区）与 1 个 Eden 区的比值为 2:8，即 1 个 Survivor 区占整个年轻代大小的 1/10。
-XX:+UseSerialGC：设置串行收集器。
-XX:+UseParallelGC：设置为并行收集器。此配置仅对年轻代有效。即年轻代使用并行收集，而年老代仍使用串行收集。
-XX:+UseParallelOldGC：配置年老代垃圾收集方式为并行收集，JDK6.0 开始支持对年老代并行收集。
-XX:ConcGCThreads：早期 JVM 版本也叫-XX:ParallelCMSThreads，定义并发 CMS 过程运行时的线程数。比如 value=4 意味着 CMS 周期的所有阶段都以 4 个线程来执行。尽管更多的线程会加快并发 CMS 过程，但其也会带来额外的同步开销。因此，对于特定的应用程序，应该通过测试来判断增加 CMS 线程数是否真的能够带来性能的提升。如果还标志未设置，JVM 会根据并行收集器中的 -XX:ParallelGCThreads 参数的值来计算出默认的并行 CMS 线程数。
-XX:ParallelGCThreads：配置并行收集器的线程数，即：同时有多少个线程一起进行垃圾回收，此值建议配置与 CPU 数目相等。
-XX:OldSize：设置 JVM 启动分配的老年代内存大小，类似于新生代内存的初始大小 -XX:NewSize。
以上就是一些常用的配置参数，有些参数是可以被替代的，配置思路需要考虑的是 Java 提供的垃圾回收机制。虚拟机的堆大小决定了虚拟机花费在收集垃圾上的时间和频度。收集垃圾能够接受的速度和应用有关，应该通过分析实际的垃圾收集的时间和频率来调整。假如堆的大小很大，那么完全垃圾收集就会很慢，但是频度会降低。假如您把堆的大小和内存的需要一致，完全收集就很快，但是会更加频繁。调整堆大小的的目的是最小化垃圾收集的时间，以在特定的时间内最大化处理客户的请求。在基准测试的时候，为确保最好的性能，要把堆的大小设大，确保垃圾收集不在整个基准测试的过程中出现。
假如系统花费很多的时间收集垃圾，请减小堆大小。一次完全的垃圾收集应该不超过 3-5 秒。假如垃圾收集成为瓶颈，那么需要指定代的大小，检查垃圾收集的周详输出，研究垃圾收集参数对性能的影响。当增加处理器时，记得增加内存，因为分配能够并行进行，而垃圾收集不是并行的。

3、设置系统属性
之前说过，Tomcat 的语言编码，配置起来很慢，要经过多次设置才可以了，否则中文很有可能出现乱码情况。譬如汉字“中”，以 UTF-8 编码后得到的是 3 字节的值 %E4%B8%AD，然后通过 GET 或者 POST 方式把这 3 个字节提交到 Tomcat 容器，如果你不告诉 Tomcat 我的参数是用 UTF-8编码的，那么 Tomcat 就认为你是用 ISO-8859-1 来编码的，而 ISO8859-1（兼容 URI 中的标准字符集 US-ASCII）是兼容 ASCII 的单字节编码并且使用了单字节内的所有空间，因此 Tomcat 就以为你传递的用 ISO-8859-1 字符集编码过的 3 个字符，然后它就用 ISO-8859-1 来解码。
设置起来不难使用“ -D<名称>=<值> ”来设置系统属性：
-Djavax.servlet.request.encoding=UTF-8
-Djavax.servlet.response.encoding=UTF-8 
-Dfile.encoding=UTF-8 
-Duser.country=CN 
-Duser.language=zh

4、常见的 Java 内存溢出有以下三种
（1） java.lang.OutOfMemoryError: Java heap space —-JVM Heap（堆）溢出
JVM 在启动的时候会自动设置 JVM Heap 的值，其初始空间（即-Xms）是物理内存的1/64，最大空间（-Xmx）不可超过物理内存。可以利用 JVM提供的 -Xmn -Xms -Xmx 等选项可进行设置。Heap 的大小是 Young Generation 和 Tenured Generaion 之和。在 JVM 中如果 98％ 的时间是用于 GC，且可用的 Heap size 不足 2％ 的时候将抛出此异常信息。
解决方法：手动设置 JVM Heap（堆）的大小。  
（2） java.lang.OutOfMemoryError: PermGen space  —- PermGen space溢出。
PermGen space 的全称是 Permanent Generation space，是指内存的永久保存区域。为什么会内存溢出，这是由于这块内存主要是被 JVM 存放Class 和 Meta 信息的，Class 在被 Load 的时候被放入 PermGen space 区域，它和存放 Instance 的 Heap 区域不同，sun 的 GC 不会在主程序运行期对 PermGen space 进行清理，所以如果你的 APP 会载入很多 CLASS 的话，就很可能出现 PermGen space 溢出。
解决方法： 手动设置 MaxPermSize 大小
（3） java.lang.StackOverflowError   —- 栈溢出
栈溢出了，JVM 依然是采用栈式的虚拟机，这个和 C 与 Pascal 都是一样的。函数的调用过程都体现在堆栈和退栈上了。调用构造函数的 “层”太多了，以致于把栈区溢出了。通常来讲，一般栈区远远小于堆区的，因为函数调用过程往往不会多于上千层，而即便每个函数调用需要 1K 的空间（这个大约相当于在一个 C 函数内声明了 256 个 int 类型的变量），那么栈区也不过是需要 1MB 的空间。通常栈的大小是 1－2MB 的。
通常递归也不要递归的层次过多，很容易溢出。



39 分布式系统含义是什么？要解决什么问题？
一、三个步骤完成华丽转身——任意软件变为“分布式”
分布式——一个高大上的名词，是计算机软件设计中人民群众喜闻乐见的“逼格满满”、“不明觉厉”的几个名词之一。但很可惜，这玩意儿一点也不复杂，甚至有些“简单”。不信？你只要遵循下述步骤即可将任何一个软件拆分为“分布式”的：
将你的整个软件视为一个系统（不管它有多复杂）
将整个系统分割为一系列的 Process（进程）， 每个 Process 完成一定的功能
将这些 Process 分散到不同的机器上。分散后，选择若干种（没错一种可能不够）通信协议把他们连接起来
蹬蹬蹬蹬～大功告成。哈哈别打我，这真的是很严肃的通用型三步骤大杀器，对付任何软件，是任何软件都可以的。接下来我当然要解释清楚为什么。

二、跳出误区——分布式不等于并行计算
人们常常把分布式系统自然而然的和并行计算联系起来。然而这并不正确。实际上，分布式系统并不一定是并行的，举个简单的例子就能理解——
某软件，功能如下：
提示用户输入两个数 A 和 B
在内部，对 A 和 B 执行某数学运算，获得 C
输出 C
很简单吧？这三个步骤是无法并行的。它们需要被依次执行。但是这个软件依然可以被改为分布式的，方法就是用前面提到的方法，把步骤 2 的计算过程独立为一个 Process 移动到另外一台计算机上完成。
如果我们从整个系统流程的观点来看，并没有什么并行。整个过程都是顺序执行的。只不过执行时出现了“跨设备”的现象而已。可见，分布式本身就只如其字面意思所指，指的仅仅是从结构角度的分散而已。
当然啊，现实世界中，我们更多的时候钟情于分布式，还是因为它与并行之间可以相互配合。例如实现既是分布同时也是并行的系统。
好了，理解这一点之后就不难解释为什么我会说前文提到的三步骤是万用大法了。接下来我们继续讨论分布式本身。

三、拆分+连接是分布式系统的本质
所谓分布式，无非就是”将一个系统拆分成多个子系统并散布到不同设备“的过程而已。
本质上而言，实现一个分布式系统，最核心的部分无非有两点：
如何拆分——可以有很多方式，核心依据一是业务需求，二是成本限制。这是实践中构建分布式系统时最主要的设计依据。
如何连接——光把系统拆开成 Process 还不够，关键是拆开后的 Process 之间还要能通信，因此涉及通信协议设计的问题，需要考虑的因素很多，好消息是这部分其实成熟方案很多

四、为什么你要使用分布式？
分布式系统并非灵丹妙药，解决问题的关键还是看你对问题本身的了解。通常我们需要使用分布式的常见理由是：
为了性能扩展——系统负载高，单台机器无法承载，希望通过使用多台机器来提高系统的负载能力
为了增强可靠性——软件不是完美的，网络不是完美的，甚至机器本身也不可能是完美的，随时可能会出错，为了避免故障，需要将业务分散开保留一定的冗余度
在以提供 Service 为主的服务端软件开发过程中常常遇到这些问题。

五、一些分布式方案能解决你的问题，另一些却不能，要学会的其实是选择
笼统的讨论分布式没有太大的意义，就如我刚才所谈的，实际上分布式很容易实现。真正难的地方在于如何选择正确的分布方案。
例如，当你想要建立一个分布式的数据管理系统的时候，你就必须得面对“一致性”问题。如果你对数据一致性要求很高，你就不得不容忍一些缺陷例如规模伸缩困难；而如果你放弃它，你可以轻松伸缩规模，但你必须解决好由此带来的一系列数据不一致导致的问题。（CAP 问题）
于是你会意识到，有许多种分布方案，为了正确解决你的问题，你需要对每一个方案都进行了解，并评估，选择不同的方案有时候区别不大，有时候却会深刻的影响整个系统中其他部分的工作方式，甚至影响用户界面中用户操作时的流程。这是我们学习分布式系统的重点所在。

六、分布式学习入门——基础知识要点
如我前面所讲，分布式入门不难。主要包含如下知识点：
Process（进程）。在分布式系统中，进程是基本单元
通信协议。Process 间需要相互配合才能完成工作，因此通信协议是最基本要解决的问题。这部分其实挺复杂，牵涉面光，不过核心还是抓住两方面，一是存在哪些需求，二是各个协议如何满足这些需求
命名法。两个 Process 要通信，必须相互知道对方的名字，名字可以是数字，也可以是结构化的字符串。例如众所周知域名系统就是一种命名方案，但是方案还有很多，各有特点
协作。上面都在谈 Process 之间的通信，可是为什么要通信？因为要协作。协作是个复杂的主题，其中最基本最基本的一个问题就是同步问题。而聊同步问题必然要聊“锁”……知识点就这么展开了
上面几点是最基础的知识。了解了这些其实就算入门了。可是如何进阶呢？那么必然要开始学习下面的问题：
一致性。数据存储时，最基本的问题。其实也是实际设计系统时常常需要反复考虑的问题
容错。冗余是容错的基础，但并不是全部，分布式本身为实现容错提供了一些便利，这也是实际设计系统时常常需要考虑的问题
好了，如果这些你都学的差不多了，那咱们“纸上谈兵”也就告一段落了。接下来进入实战演练。

七、实战演练？其实你已经开发过分布式系统了
你有没有开发过简单的增删改查软件？这类软件通常都需要搭配一个独立的数据库管理系统共同完成功能。实际上，只要你开发过这么简单的软件，那么你就已经开发过分布式系统了。
“什么，基于数据库管理系统开发出来的软件就可以算分布式呀？我做了很多这类软件，怎么我从来没听过这种说法？
真的，我没开玩笑。还记得我们前面提到的吗，什么是分布式？不就是一个大系统拆分成多个小系统分散到不同的设备上吗。回想一下，当你写一个简单的增删改查软件时，只要用到数据库管理系统，是不是具有如下特点：
整个系统中，你写的代码跑在 A 进程里，而数据库管理系统则跑在另外一个进程 B 里
A 进程与 B 进程通过某种通信协议连接
既可以使 A 进程与 B 进程运行在同一台机器上，也可以将它们分开运行于不同的机器上，并且系统依然可以照常运行



40如何理解微服务的熔断和隔离，限流？
一、为什么需要做服务隔离与熔断
微服务是当前业界的一个趋势，其原理是将职责单一的功能独立化成子服务，一个后台服务依赖多个微服务。假设某服务由30个微服务组成，每个微服务的可用性是99.99%，那么99.99%的30次方≈99.7%，也就是说有0.3%的请求会失败，若有一亿次请求则有300000次失败。
微服务间通过RPC来进行数据交换，所以我们可以做一个假设：在IO型服务中，假设服务A依赖服务B和服务C，而B服务和C服务有可能继续依赖其他的服务，继续下去会使得调用链路过长，技术上称1->N扇出。如果在A的链路上某个或几个被调用的子服务不可用或延迟较高，则会导致调用A服务的请求被堵住，堵住的请求会消耗占用掉系统的线程、io等资源，当该类请求越来越多，占用的计算机资源越来越多的时候，会导致系统瓶颈出现，造成其他的请求同样不可用，最终导致业务系统崩溃，又称：雪崩效应。

二、解决或缓解服务雪崩的方案
一般情况对于服务依赖的保护主要有3中解决方案：
（1）熔断模式：这种模式主要是参考电路熔断，如果一条线路电压过高，保险丝会熔断，防止火灾。放到我们的系统中，如果某个目标服务调用慢或者有大量超时，此时，熔断该服务的调用，对于后续调用请求，不在继续调用目标服务，直接返回，快速释放资源。如果目标服务情况好转则恢复调用。
（2）隔离模式：这种模式就像对系统请求按类型划分成一个个小岛的一样，当某个小岛被火少光了，不会影响到其他的小岛。例如可以对不同类型的请求使用线程池来资源隔离，每种类型的请求互不影响，如果一种类型的请求线程资源耗尽，则对后续的该类型请求直接返回，不再调用后续资源。这种模式使用场景非常多，例如将一个服务拆开，对于重要的服务使用单独服务器来部署，再或者公司最近推广的多中心。
（3）限流模式：上述的熔断模式和隔离模式都属于出错后的容错处理机制，而限流模式则可以称为预防模式。限流模式主要是提前对各个类型的请求设置最高的QPS阈值，若高于设置的阈值则对该请求直接返回，不再调用后续资源。这种模式不能解决服务依赖的问题，只能解决系统整体资源分配问题，因为没有被限流的请求依然有可能造成雪崩效应。

三、熔断设计
熔断的设计主要参考了hystrix的做法。其中最重要的是三个模块：熔断请求判断算法、熔断恢复机制、熔断报警
（1）熔断请求判断机制算法：使用无锁循环队列计数，每个熔断器默认维护10个bucket，每1秒一个bucket，每个blucket记录请求的成功、失败、超时、拒绝的状态，默认错误超过50%且10秒内超过20个请求进行中断拦截。
（2）熔断恢复：对于被熔断的请求，每隔5s允许部分请求通过，若请求都是健康的（RT<250ms）则对请求健康恢复。
（3）熔断报警：对于熔断的请求打日志，异常请求超过某些设定则报警

四、超时机制设计
超时分两种，一种是请求的等待超时，一种是请求运行超时。
等待超时：在任务入队列时设置任务入队列时间，并判断队头的任务入队列时间是否大于超时时间，超过则丢弃任务。
运行超时：直接可使用线程池提供的get方法。


41 简单的谈一下SpringMVC的工作流程？
在整个Spring MVC框架中，DispatcherServlet处于核心位置，它负责协调和组织不同组件完成请求处理并返回响应的工作。具体流程为：
1）客户端发送http请求，web应用服务器接收到这个请求，如果匹配DispatcherServlet的映射路径（在web.xml中配置），web容器将请求转交给DispatcherServlet处理；
2）DispatcherServlet根据请求的信息及HandlerMapping的配置找到处理该请求的Controller；
3）Controller完成业务逻辑处理后，返回一个ModelAndView给DispatcherServlet；
4）DispatcherServlet借由ViewResolver完成ModelAndView中逻辑视图名到真实视图对象View的解析工作；
5）DispatcherServlet根据ModelAndView中的数据模型对View对象进行视图渲染，最终客户端得到的响应消息可能是一个普通的html页面，也可能是一个xml或json串，甚至是一张图片或一个PDF文档等不同的媒体形式。



42 SpringMVC与Struts2的主要区别？
区别1：
Struts2 的核心是基于一个Filter即StrutsPreparedAndExcuteFilter
SpringMvc的核心是基于一个Servlet即DispatcherServlet(前端控制器)

区别2：
Struts2是基于类开发的，传递的参数是通过类的属性传递(属性驱动和模型驱动),所以只能设计成多例prototype
SpringMvc是基于类中的方法开发的，也就是一个url对应一个方法，传递参数是传到方法的形参上面，所以既可以是单例模式也可以是多例模式singiton

区别3：
Struts2采用的是值栈存储请求以及响应数据，OGNL存取数据
SpringMvc采用request来解析请求内容，然后由其内部的getParameter给方法中形参赋值，再把后台处理过的数据通过ModelAndView对象存储，Model存储数据，View存储返回的页面，再把对象通过request传输到页面去。


43 Spring 4.0新特性有哪些？
2004年Spring框架首次发布，然后陆续发布了一些重要的版本：Spring2.0提供XML命名空间和AspectJ的支持；Spring2.5包含了注释驱动配置；Spring3.0在框架基础代码中引入了强大的Java5+，并且提供诸如基于Java的@Configuration模式。
4.0版本是Spring框架最新发布的主版本，并且首次完全支持Java8的功能。你依然可以使用较早的Java版本，但是现在所需的最小的版本已经被提升的Java SE6。同时还利用主版本发布的机会删除了很多废弃的类和方法。
在Spring框架的GitHub Wiki上提供了升级到Spring4.0的指南。

1. 入门体验的改善
新的spring.io网站提供完整的入门指南系列来帮助初学者。在本文档的第一章Spring入门中，你可以读到更多的有关这个指南的信息。这个网站还提供很多在Spring体系下发布的其他一些工程的详细的概要。
如果你是一个Maven用户，那么你可能还要关注与每个Spring框架版本一起发布的资料清单（POM）。

2. 被删除的废弃的包和方法
所有被废弃的包和很多被废弃的类和方法已经从4.0版中删除，如果从Spring之前的发布版本中升级，要确保修正那些对被废弃的内容的调用，以免使用过期的API。
对于全部改变内容，可查阅API差异报告。
注意，那些可选的第三方依赖已经被升级到2010/2011以后的版本（也就是说Spring 4只支持2010年以后释放的版本）：尤其是Hibernate3.6+、EhCache2.1+、Quartz1.8+、Groovy1.8+、和Joda-Time2.0+。一个例外的规则是：目前Spring4要求最近的Hibernate验证器4.3+，并且支持的Jackson已经聚焦到2.0+（在Spring3.2中保留的对Jackson1.8/1.9的支持，现在已经过时了）。

3. Java 8（包括6和7）
Spring框架4.0提供了对几个Java 8功能的支持。你可以通过Spring的回调接口来使用lambda表达式和方法引用。 首先支持的类是java.time(JSR-310)和几个已经被改造成@Repeatable的既存标注。你还可以使用Java8 的参数名称发现机制（-parameters编译标记）来对调试信息的使用进行选择性编译。
Spring保留了跟Java和JDK较早版本的兼容性：具体的是Java SE6（JDK 6最小的版本级别要升级到18，这是2010年2月释放的版本）及以上的版本依然是完全支持的。但是基于Spring4最新开发的项目，我们推荐使用Java7或8。

4. Java EE 6和7
Spring框架4使用Java EE 6或以上的版本来作为基线，同时包含了相关的JPA2.0和Servlet3.0的规范。为了保留跟Google App引擎和旧的应用服务的兼容性，可能要把Spring 4应用程序部署到Servlet 2.5的环境中。但是在安装了Spring的测试和模拟包的开发环境中，强烈推荐使用Servlet3.0+。
提示：如果你是WebSphere 7的用户，要确保安装JPA2.0的补丁包。在WebLogic 10.3.3或更高的版本中带有JAP2.0的补丁包。这样就会把与Spring 4兼容的部署环境带到这两类服务器中。
前面介绍了当前Spring 框架 4.0支持的Java EE 7的应用程序规范级别，包括：JMS 2.0、JTA 1.2、JPA2.1、Bean Validation 1.1和JSR-236 Concurrency Utilities。通常这种支持只是关注这些规范的独立使用，如在Tomcat或独立的环境中。同样当把Spring应用程序部署到Java EE 7服务上时它的工作方式也是一样的。
注意，Hibernate 4.3是JPA2.1的提供器，因此只在Spring 框架4.0中支持。同样Hibernate Validator 5.0作为Bean Validation提供器也适用于这个约束。这两者都没有提供官方的对Spring框架3.2的支持。

5. 使用Groovy的DSL（DomainSpecific Languages）来定义 Bean
从Spring框架4.0开始，可以使用Groovy的 DSL来定义外部的bean配置。这有点类似使用XML Bean定义的概念，但是它允许使用更加简洁的语法。使用Groovy也允许更加容易的把bean定义嵌入到你的应用程序的启动代码中，如：

6. 内核容器方面的改善
以下是对核心容器的几个方面的常规改善：
A. 现在Spring可以在注入Bean的时候处理修饰样式的的泛型。例如，如果要使用Spring的数据资源库（Repository），就可以很容易的注入一个特定的实现：@AutowiredRepository<Customer> customerRepository。
B. 如果使用Spring的元注解支持，那么现在可以开发暴露来自源注解中的特定属性的个性化注解。
C. 现在列表和数组中的bean是可以被排序的，它同时支持@Order注解和ordered接口。
D. 现在在注入点可以使用@Lazy注解，跟@Bean定义一样。
E. 引入了@Description注解，方便开发者使用基于Java的配置。
F. 通过@Conditional注解来作为条件过滤bean的常用模式。这有点类似@Profile支持，但它允许用户给开发的程序定义一些策略。
G. 基于CGLIB的代理类不再需要默认的构造器，它通过被重新包装在内部的objenesis类库来提供支持，这个类库是作为Spring框架的一部分来发布。使用这种策略，不再有用于代理示例调用的构造器了。
H. 通过框架提供管理时区的支持，如LocaleContext。

7. 常用的Web方面的改善
部署到Servlet 2.5依然是一个可选项，但当前的Spring 框架4.0主要关注Servlet3.0+环境。如果你是在使用Spring的MVC测试框架，那么就需要确保在测试的类路径中有与Servlet3.0兼容的JAR包。
另外，稍后会介绍WebSocket，下面是Spring的Web模块常规改善：
A. 你可以在Spring的MVC应用程序中使用新的@RestController注解，不再需要给每个@RequestMapping方法添加@ResponseBody。
B. 添加了AsyncRestTemplate类，它允许在开发REST客户端时支持非阻塞的异步支持。
C. 在开发Spring MVC应用程序时，Spring提供了全面的时区支持。

8. WebSocket、SockJS、和STOMP消息
新的spring-websocket模块提供了全面的基于WebSocket的支持，在Web应用程序的客户端和服务端之间有两种通信方式。它跟JSR-356兼容，用于浏览器的Java的WebSocket API和额外提供的基于SockJS的回退选项（如WebSocket模拟器）依然不支持WebSocket协议（如IE以前的版本）。
新的spring-messaging模块添加了对WebSocket的子协议STOMP的支持，它在应用程序中跟注解编程模式一起用于路由和处理来自WebSocket客户端的STOMP消息。现在一个@Controller就能够包含处理HTTP请求和来自被连接的WebSocket客户端的@RequestMapping和@MessageMapping方法的结果。这个模块还包含了来自Spring集成项目的关键抽象原型，如Message、MessageChannel、MessageHandler以及其他的基于消息的应用的基础服务。
更多的信息，请看第25章---WebSocket支持

9. 测试的改善
Spring框架4.0中删除了spring-test模块中的废弃代码，还引入了几个用于单元和集成测试的新功能：
A. 在spring-test模块中几乎所有的注解（如@ContextConfiguration、@WebAppConfiguration、@ContextHierarchy、@ActiveProfiles等）都可以使用元注解来创建个性化的组合注解并减少跨测试单元的配置成本。
B. 通过简单的编程实现个性化的ActiveProfilesResolver接口，并使用@ActiveProfiles的resolver属性就可以激活bean定义的配置。
C. 在spring-core模块中引入了新的SocketUtils类，它确保你可以扫描到本地主机上的闲置的TCP和UDP服务端口。这个功能不是专门提供给测试的，但是在编写需要使用套接字的集成测试代码是就非常有用，例如，测试内存中启动的SMTP服务、FTP服务、Servlet容器等。
D. 在Spring4.0的org.springframework.mock.web包中，有一组基于Servlet3.0 API的模仿器。此外，还增强了几个Servlet的API模仿器（如MockHttpServletRequest、MockServletContext等）的功能，并改善了可配置性。 


44 weblogic 负载均衡的原理和集群的配置？
一、 Cluster的概念及优势
Weblogic支持集群技术，即让一组Server指向同一域名一起工作从而提供一个更强大、更可靠的应用平台。对于客户端而言，无论Cluster中有几个Server在工作，看上去都是一个。集群技术有两个最明显的特色：
(1)可伸缩性：Cluster对加入其中的Server在性能上没有限制，为了提高性能，当客户端的请求大幅增加时，可以动态地向Cluster中添加Server。并且，配置Cluster当一台机器的资源没有被完全利用时，可以在同一机器上启动多个Server，但要求每一个Server使用不同的IP，而不能用同一IP的不同端口。
(2)高可用性：由于在Cluster中同一service在多个Server上同时存放或放在一个共享文件系统中，因此相同的请求可以有多个Server提供，并且Server间还可以复制状态信息。这样，当其中某一Server宕机或无法响应请求时，其它的Server会立即接管它的任务，从而把应用和客户端完全隔离开来。

二、Cluster的工作机制
每一个Clustered service,在每一个server上都会有一个instance，即一个replica，这些replicas集合在一起形成一个replica-aware stub。这些stubs负责客户端与相关的服务器段对象的通信，当客户端请求该service时，实际上是向stub发出请求，stub根据不同的算法调用集合中某一replica，如果调用失败，stub会检测到错误并重新调用其它的replica。Cluster支持多种算法：随机、轮循、基于性能的负载均衡的轮循(Weight-based round-robin)、根据参数值调用(Parameter-based routing)。
Weblogic Cluster通过负载均衡和容错最大程度的实现了它的可伸缩性和可用性。
为了提高Cluster的可伸缩性，必须保证充分利用每一个Server。Weblogic可以在不同平台、不同性能的机器上安装Server并进行Cluster,然后采用Weight-based round-robin算法达到负载均衡，从而使每一个Server都得到充分的利用。
为了使Cluster具有高可用性，必须具备故障恢复的能力，这一点可以通过replica-aware stub的容错功能来实现。Stub 主要是通过在检测到错误信息时重新进行调用的方式实现容错。当重新调用不会导致错误的结果时(如stub确认failed server不能接收到请求)，容错功能自动实现。而有些情况下，重新调用可能会导致某一service被请求了多次的错误结果。例如：客户端C请求Clustered购物车服务中的additem()方法，replica-aware stub接收到请求，根据算法调用Server1上的service,Server1响应请求并返回结果，但在结果成功到达客户端之前，Server1出现错误。此时stub接收到错误信息，因此重新调用Server2上的这一方法，但实际上Server1已经将item加入购物车，这样就造成重复。为了解决这种问题，可以为服务添加一个唯一标识，如上述的additem()方法中可添加一个参数——序列号。每一个item有一个唯一的sequence,相同sequence的item不能被重复添加。

三、 Cluster的命名服务
在Weblogic Server中使用命名服务时，客户端通过JNDI存取service，JNDI tree上绑定了Server提供的所有的公共服务。Server提供一个新的service时，是将service以某一名称绑定到JNDI tree上，客户端和Server建立连接并按照名称获取相应的stub。
Custer扩展了Server的这种命名服务机制，它不仅包含了每一个Server上的非Clustered的stub,而且包含了多个Server间的Clustered 的replica-aware stub。

四、 Cluster的服务类型
在Weblogic中，有多种服务可以进行cluster，如：RMI对象、EJB、Servlets、Jsp、Web Application。
（1）RMI和EJB Clustering
RMI和EJB对象在Cluster过程中使用JNDI命名服务机制。RMI和EJB对象发送remote stubs到客户端，客户端获取的这些stubs可以是已经clustered的，也可以是没有clustered的。对于Clustered的服务，Stubs根据负载均衡和容错的不同需求调用Cluster中合适的Server；而对没有Clustered的服务，所有对此stub的调用只能由提供此服务的Server来处理。
有些有状态的RMI和EJB对象是不可以进行clustered的，因为客户端必须总是和同一个Server上的对象实例相联系。所有的EJB都是clusterable，虽然EJB也有有状态的，但是EJB home interface 都是无状态的，可以进行clustered，这样就可以从JNDI tree上获取 Clusterable EJB 的home stub 对象。然后通过home stub的方法创建或检索相应的EJB bean,若为stateful session bean 或entity bean，那么此时得到的stub就是不可clusterable。为了使有状态的对象可以更好的cluster，可以将一些操作作为一个事务来执行，如果工作中的Server出现意外，可以重新获取此对象并进行事务操作。
RMI和EJB不同，RMI没有定义有状态和无状态分类，因此必须特意绑定一个有状态的RMI对象到Server上。可以仿效EJB home interface的方式即客户端从JNDI tree上获取一个clusterable factory method,然后factory method 可以调用集群中的任意一台Server,但是被调用的Server上必须有由此factory调用的对象。
（2）Clustered Servlets
Servlets也是可以进行Cluster的。对于Servlets，它用replica-aware proxy替代了replica-aware。这个proxy接受web server上所有请求，并转给集群中的某一Server。Proxy对cluster的所有请求进行负载均衡，并且当请求失败时会进行恢复处理。Proxy还可以在cluster中特别是Server没有正常完成请求响应时保持session状态。当session初始化时，proxy按照负载均衡算法选择一台Server保存session，此后，所有与此session相关的请求都由这同一台Server处理。为了避免当此Server出错时，无法保存客户端状态信息，所以session会被复制下来，并且session的所有变化都会在备份中进行及时更新，这样，当原有Server在响应请求过程中失败时，proxy会立即获取session的备份，并由此继续响应客户端请求，同时做新的复制。
(3)JDBC clustering
为了利用Weblogic Server cluster的负载均衡和容错的性能，Weblogic JDBC连接池也可以在replicated naming tree上注册。通常情况下，cluster中的每一个Server都进行连接池属性配置来访问同一个后端的DBMS实例，即对相同数据库的访问，每一个Server都有一个连接池。然后通过在配置文件中定义一个DataSource属性来在naming tree 上注册连接池。客户端使用Weblogic JDBC/RMI JDBC 驱动程序从cluster中获取数据库连接，即客户端按照DataSource name获取连接池，然后按照负载均衡的算法选择相应的Weblogic Server来响应请求。

五、集群配置
Weblogic域是一个服务器/集群的管理组，用户可以通过某个中央位置来管理、监控整个服务器域，这个中心就是管理服务器，相对的，受控服务器或者叫被管服务器是指域中除了管理服务器以外的所有的服务器。
       Weblogic集群是一个weblogic Server组，在一个集群中的服务器可以获得集群范围的命名服务、负载平衡以及容错等功能。
       所以，一个weblogic域可以同时管理多个集群以及多个服务器实例。
       另外，还有一个节点管理器的概念，节点管理器是指在物理的机器上运行的一个守护进程，通过它，管理服务器可以获得诸如在控制台中强制重启远程机器上的server等功能（没有节点管理器的情况下也是可以强制关闭远程服务器的，但是不能重启）。
       除此之外，据说节点管理器还可以自动检查自己机器上的server实例（健康检查），当发现某个实例出现故障的时候，可以自动进行重启，这个没试过。
注意事项
1. 本文的weblogic均配置在linux环境下
2. 集群中管理服务器和被管服务器之间有用到ip组播UDP，所以这些服务器之间必须是UDP可以到达的。
3. 好像动态ip的机器不能用于集群当中
4. 最佳实践说：请不要把管理服务器设置在集群当中
5. 本文所配置的集群只是实现了web层次上的负载平衡和容错，也就是servlet和jsp，其他的j2ee组件如ejb，jdbc，jms等都可以集群化。


45 Nginx+Tomcat+Redis实现负载均衡、资源分离、session共享？
一、准备工作 
CentOS安装Nginx
http://centoscn.com/CentosServer/www/2013/0910/1593.html
CentOS安装Tomcat
http://blog.csdn.net/zhuying_linux/article/details/6583096
CentOS安装Redis
http://www.cnblogs.com/zhuhongbao/archive/2013/06/04/3117997.html
多个Tomcat负载均衡实例：可在服务器上复制出多个Tomcat分别修改Tomcat的
http访问端口（默认为8080端口）
Shutdown端口（默认为8005端口）
JVM启动端口（默认为8009端口）

二、Nginx实现多Tomcat负载均衡
Tomcat服务
192.168.1.177:8001
192.168.1.177:8002
192.168.1.177:8003
Nginx配置
upstream mytomcats {  
server 192.168.1.177:8001;  
server 192.168.1.177:8002;  
server 192.168.1.177:8003;  
}
server {  
listen 80;  
server_name www.iu14.com;
location ~* \.(jpg|gif|png|swf|flv|wma|wmv|asf|mp3|mmf|zip|rar)$ {  
root /web/www/html/;  
}  
location / {  
proxy_pass http://mytomcats;  
proxy_redirect off;  
proxy_set_header Host $host;  
proxy_set_header X-Real-IP $remote_addr;  
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;  
client_max_body_size 10m;  
client_body_buffer_size 128k;  
proxy_connect_timeout 90;  
proxy_send_timeout 90;  
proxy_read_timeout 90;  
proxy_buffer_size 4k;  
proxy_buffers 4 32k;  
proxy_busy_buffers_size 64k;  
proxy_temp_file_write_size 64k;
}
}
upstream指定负载均衡组，指定其Tomcat成员
location ~* \.(jpg|gif|……实现了静态资源分离。ps：在location指令使用正则表达式后再用alias指令，Nginx是不支持的。

三、Nginx实现静态资源分离
Tomcat服务
192.168.1.177:8000
Nginx配置
server {  
listen 80;  
server_name www.iu14.com;  
root /web/www/html;
location /img/ {  
alias /web/www/html/img/;  
}
location ~ (\.jsp)|(\.do)$ {  
proxy_pass http://192.168.1.177:8000;  
proxy_redirect off;  
proxy_set_header Host $host;  
proxy_set_header X-Real-IP $remote_addr;  
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;  
client_max_body_size 10m;  
client_body_buffer_size 128k;  
proxy_connect_timeout 90;  
proxy_send_timeout 90;  
proxy_read_timeout 90;  
proxy_buffer_size 4k;  
proxy_buffers 4 32k;  
proxy_busy_buffers_size 64k;  
proxy_temp_file_write_size 64k;  
}   
}
第一个location指令将/web/www/html/img/目录下的静态文件交给Nginx来完成。最后一个location指令将所有以.jsp、.do结尾的文件都交给Tomcat服务器的8080端口来处理。

四、Nginx+Tomcat+Redis实现session共享
Redis服务
192.168.1.178:6379
Tomcat服务
192.168.1.177:8001
192.168.1.177:8002
192.168.1.177:8003
Nginx服务
192.168.1.179
配置Tomcat让其session保存到redis上，在context.xml配置(Value标签一定要在Manager标签前面)：
配置Nginx
upstream mytomcats {  
server 192.168.1.177:8001;  
server 192.168.1.177:8002;  
server 192.168.1.177:8003;  
}
log_format www_iu14_com '$remote_addr - $remote_user [$time_local] $request ' '"$status" $body_bytes_sent "$http_referer"'  '"$http_user_agent" "$http_x_forwarded_for"';  
server {
listen  80;  
server_name www.iu14.com;   
location / {  
proxy_pass http:// mytomcats;  
proxy_set_header Host $host;  
proxy_set_header X-Real-IP $remote_addr;  
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;  
}  
access_log /usr/tmp/logs/redis.iu14.log www_iu14_com;  
}  
依次启动Redis、Tomcat、Nginx，访问Nginx




46 nginx配置文件详解——nginx.conf？
######Nginx配置文件nginx.conf中文详解#####

#定义Nginx运行的用户和用户组
user www www;

#nginx进程数，建议设置为等于CPU总核心数。
worker_processes 8;
 
#全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]
error_log /usr/local/nginx/logs/error.log info;

#进程pid文件
pid /usr/local/nginx/logs/nginx.pid;

#指定进程可以打开的最大描述符：数目
#工作模式与连接数上限
#这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。
#现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。
#这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。
worker_rlimit_nofile 65535;


events
{
    #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型
    #是Linux 2.6以上版本内核中的高性能网络I/O模型，linux建议epoll，如果跑在FreeBSD上面，就用kqueue模型。
    #补充说明：
    #与apache相类，nginx针对不同的操作系统，有不同的事件模型
    #A）标准事件模型
    #Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll
    #B）高效事件模型
    #Kqueue：使用于FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X.使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。
    #Epoll：使用于Linux内核2.6版本及以后的系统。
    #/dev/poll：使用于Solaris 7 11/99+，HP/UX 11.22+ (eventport)，IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。
    #Eventport：使用于Solaris 10。 为了防止出现内核崩溃的问题， 有必要安装安全补丁。
    use epoll;

    #单个进程最大连接数（最大连接数=连接数*进程数）
    #根据硬件调整，和前面工作进程配合起来用，尽量大，但是别把cpu跑到100%就行。每个进程允许的最多连接数，理论上每台nginx服务器的最大连接数为。
    worker_connections 65535;

    #keepalive超时时间。
    keepalive_timeout 60;

    #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。
    #分页大小可以用命令getconf PAGESIZE 取得。
    #[root@web001 ~]# getconf PAGESIZE
    #4096
    #但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。
    client_header_buffer_size 4k;

    #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。
    open_file_cache max=65535 inactive=60s;

    #这个是指多长时间检查一次缓存的有效信息。
    #语法:open_file_cache_valid time 默认值:open_file_cache_valid 60 使用字段:http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息.
    open_file_cache_valid 80s;

    #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。
    #语法:open_file_cache_min_uses number 默认值:open_file_cache_min_uses 1 使用字段:http, server, location  这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如果使用更大的值,文件描述符在cache中总是打开状态.
    open_file_cache_min_uses 1;
    
    #语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件是记录cache错误.
    open_file_cache_errors on;
}
 
 
 
#设定http服务器，利用它的反向代理功能提供负载均衡支持
http
{
    #文件扩展名与文件类型映射表
    include mime.types;

    #默认文件类型
    default_type application/octet-stream;

    #默认编码
    #charset utf-8;

    #服务器名字的hash表大小
    #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小.
    server_names_hash_bucket_size 128;

    #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。
    client_header_buffer_size 32k;

    #客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。
    large_client_header_buffers 4 64k;

    #设定通过nginx上传文件的大小
    client_max_body_size 8m;

    #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。
    #sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。
    sendfile on;

    #开启目录列表访问，合适下载服务器，默认关闭。
    autoindex on;

    #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用
    tcp_nopush on;
     
    tcp_nodelay on;

    #长连接超时时间，单位是秒
    keepalive_timeout 120;

    #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。
    fastcgi_connect_timeout 300;
    fastcgi_send_timeout 300;
    fastcgi_read_timeout 300;
    fastcgi_buffer_size 64k;
    fastcgi_buffers 4 64k;
    fastcgi_busy_buffers_size 128k;
    fastcgi_temp_file_write_size 128k;

    #gzip模块设置
    gzip on; #开启gzip压缩输出
    gzip_min_length 1k;    #最小压缩文件大小
    gzip_buffers 4 16k;    #压缩缓冲区
    gzip_http_version 1.0;    #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）
    gzip_comp_level 2;    #压缩等级
    gzip_types text/plain application/x-javascript text/css application/xml;    #压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。
    gzip_vary on;

    #开启限制IP连接数的时候需要使用
    #limit_zone crawler $binary_remote_addr 10m;



    #负载均衡配置
    upstream piao.jd.com {
     
        #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。
        server 192.168.80.121:80 weight=3;
        server 192.168.80.122:80 weight=2;
        server 192.168.80.123:80 weight=3;

        #nginx的upstream目前支持4种方式的分配
        #1、轮询（默认）
        #每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。
        #2、weight
        #指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。
        #例如：
        #upstream bakend {
        #    server 192.168.0.14 weight=10;
        #    server 192.168.0.15 weight=10;
        #}
        #2、ip_hash
        #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。
        #例如：
        #upstream bakend {
        #    ip_hash;
        #    server 192.168.0.14:88;
        #    server 192.168.0.15:80;
        #}
        #3、fair（第三方）
        #按后端服务器的响应时间来分配请求，响应时间短的优先分配。
        #upstream backend {
        #    server server1;
        #    server server2;
        #    fair;
        #}
        #4、url_hash（第三方）
        #按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。
        #例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法
        #upstream backend {
        #    server squid1:3128;
        #    server squid2:3128;
        #    hash $request_uri;
        #    hash_method crc32;
        #}

        #tips:
        #upstream bakend{#定义负载均衡设备的Ip及设备状态}{
        #    ip_hash;
        #    server 127.0.0.1:9090 down;
        #    server 127.0.0.1:8080 weight=2;
        #    server 127.0.0.1:6060;
        #    server 127.0.0.1:7070 backup;
        #}
        #在需要使用负载均衡的server中增加 proxy_pass http://bakend/;

        #每个设备的状态设置为:
        #1.down表示单前的server暂时不参与负载
        #2.weight为weight越大，负载的权重就越大。
        #3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误
        #4.fail_timeout:max_fails次失败后，暂停的时间。
        #5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。

        #nginx支持同时设置多组的负载均衡，用来给不用的server来使用。
        #client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debug
        #client_body_temp_path设置记录文件的目录 可以设置最多3层目录
        #location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡
    }
     
     
     
    #虚拟主机的配置
    server
    {
        #监听端口
        listen 80;

        #域名可以有多个，用空格隔开
        server_name www.jd.com jd.com;
        index index.html index.htm index.php;
        root /data/www/jd;

        #对******进行负载均衡
        location ~ .*.(php|php5)?$
        {
            fastcgi_pass 127.0.0.1:9000;
            fastcgi_index index.php;
            include fastcgi.conf;
        }
         
        #图片缓存时间设置
        location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$
        {
            expires 10d;
        }
         
        #JS和CSS缓存时间设置
        location ~ .*.(js|css)?$
        {
            expires 1h;
        }
         
        #日志格式设定
        #$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址；
        #$remote_user：用来记录客户端用户名称；
        #$time_local： 用来记录访问时间与时区；
        #$request： 用来记录请求的url与http协议；
        #$status： 用来记录请求状态；成功是200，
        #$body_bytes_sent ：记录发送给客户端文件主体内容大小；
        #$http_referer：用来记录从那个页面链接访问过来的；
        #$http_user_agent：记录客户浏览器的相关信息；
        #通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址。
        log_format access '$remote_addr - $remote_user [$time_local] "$request" '
        '$status $body_bytes_sent "$http_referer" '
        '"$http_user_agent" $http_x_forwarded_for';
         
        #定义本虚拟主机的访问日志
        access_log  /usr/local/nginx/logs/host.access.log  main;
        access_log  /usr/local/nginx/logs/host.access.404.log  log404;
         
        #对 "/" 启用反向代理
        location / {
            proxy_pass http://127.0.0.1:88;
            proxy_redirect off;
            proxy_set_header X-Real-IP $remote_addr;
             
            #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
             
            #以下是一些反向代理的配置，可选。
            proxy_set_header Host $host;

            #允许客户端请求的最大单文件字节数
            client_max_body_size 10m;

            #缓冲区代理缓冲用户端请求的最大字节数，
            #如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。
            #无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误
            client_body_buffer_size 128k;

            #表示使nginx阻止HTTP应答代码为400或者更高的应答。
            proxy_intercept_errors on;

            #后端服务器连接的超时时间_发起握手等候响应超时时间
            #nginx跟后端服务器连接超时时间(代理连接超时)
            proxy_connect_timeout 90;

            #后端服务器数据回传时间(代理发送超时)
            #后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据
            proxy_send_timeout 90;

            #连接成功后，后端服务器响应时间(代理接收超时)
            #连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间）
            proxy_read_timeout 90;

            #设置代理服务器（nginx）保存用户头信息的缓冲区大小
            #设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小
            proxy_buffer_size 4k;

            #proxy_buffers缓冲区，网页平均在32k以下的设置
            #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k
            proxy_buffers 4 32k;

            #高负荷下缓冲大小（proxy_buffers*2）
            proxy_busy_buffers_size 64k;

            #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长
            #设定缓存文件夹大小，大于这个值，将从upstream服务器传
            proxy_temp_file_write_size 64k;
        }
         
         
        #设定查看Nginx状态的地址
        location /NginxStatus {
            stub_status on;
            access_log on;
            auth_basic "NginxStatus";
            auth_basic_user_file confpasswd;
            #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。
        }
         
        #本地动静分离反向代理配置
        #所有jsp的页面均交由tomcat或resin处理
        location ~ .(jsp|jspx|do)?$ {
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_pass http://127.0.0.1:8080;
        }
         
        #所有静态文件由nginx直接读取不经过tomcat或resin
        location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|
        pdf|xls|mp3|wma)$
        {
            expires 15d; 
        }
         
        location ~ .*.(js|css)?$
        {
            expires 1h;
        }
    }
}
######Nginx配置文件nginx.conf中文详解#####


47 高并发量网站解决方案有哪些？
一个小型的网站，可以使用最简单的html静态页面就实现了，配合一些图片达到美化效果，所有的页面均存放在一个目录下，这样的网站对系统架构、性能的要求都很简单。随着互联网业务的不断丰富，网站相关的技术经过这些年的发展，已经细分到很细的方方面面，尤其对于大型网站来说，所采用的技术更是涉及面非常广，从硬件到软件、编程语言、数据库、WebServer、防火墙等各个领域都有了很高的要求，已经不是原来简单的html静态网站所能比拟的。
大型网站，比如门户网站，在面对大量用户访问、高并发请求方面，基本的解决方案集中在这样几个环节：使用高性能的服务器、高性能的数据库、高效率的编程语言、还有高性能的Web容器。这几个解决思路在一定程度上意味着更大的投入。

1. HTML静态化
其实大家都知道，效率最高、消耗最小的就是纯静态化的html页面，所以我们尽可能使我们的网站上的页面采用静态页面来实现，这个最简单的方法其实也是最有效的方法。但是对于大量内容并且频繁更新的网站，我们无法全部手动去挨个实现，于是出现了我们常见的信息发布系统CMS，像我们常访问的各个门户站点的新闻频道，甚至他们的其他频道，都是通过信息发布系统来管理和实现的，信息发布系统可以实现最简单的信息录入自动生成静态页面，还能具备频道管理、权限管理、自动抓取等功能，对于一个大型网站来说，拥有一套高效、可管理的CMS是必不可少的。
除了门户和信息发布类型的网站，对于交互性要求很高的社区类型网站来说，尽可能的静态化也是提高性能的必要手段，将社区内的帖子、文章进行实时的静态化、有更新的时候再重新静态化也是大量使用的策略，像Mop的大杂烩就是使用了这样的策略，网易社区等也是如此。
同时，html静态化也是某些缓存策略使用的手段，对于系统中频繁使用数据库查询但是内容更新很小的应用，可以考虑使用html静态化来实现。比如论坛中论坛的公用设置信息，这些信息目前的主流论坛都可以进行后台管理并且存储在数据库中，这些信息其实大量被前台程序调用，但是更新频率很小，可以考虑将这部分内容进行后台更新的时候进行静态化，这样避免了大量的数据库访问请求。

2. 图片服务器分离
大家知道，对于Web服务器来说，不管是Apache、IIS还是其他容器，图片是最消耗资源的，于是我们有必要将图片与页面进行分离，这是基本上大型网站都会采用的策略，他们都有独立的、甚至很多台的图片服务器。这样的架构可以降低提供页面访问请求的服务器系统压力，并且可以保证系统不会因为图片问题而崩溃。
在应用服务器和图片服务器上，可以进行不同的配置优化，比如apache在配置ContentType的时候可以尽量少支持、尽可能少的LoadModule，保证更高的系统消耗和执行效率。
3. 数据库集群、库表散列
大型网站都有复杂的应用，这些应用必须使用数据库，那么在面对大量访问的时候，数据库的瓶颈很快就能显现出来，这时一台数据库将很快无法满足应用，于是我们需要使用数据库集群或者库表散列。
在数据库集群方面，很多数据库都有自己的解决方案，Oracle、Sybase等都有很好的方案，常用的MySQL提供的Master/Slave也是类似的方案，您使用了什么样的DB，就参考相应的解决方案来实施即可。
上面提到的数据库集群由于在架构、成本、扩张性方面都会受到所采用DB类型的限制，于是我们需要从应用程序的角度来考虑改善系统架构，库表散列是常用并且最有效的解决方案。
我们在应用程序中安装业务和应用或者功能模块将数据库进行分离，不同的模块对应不同的数据库或者表，再按照一定的策略对某个页面或者功能进行更小的数据库散列，比如用户表，按照用户ID进行表散列，这样就能够低成本的提升系统的性能并且有很好的扩展性。
sohu的论坛就是采用了这样的架构，将论坛的用户、设置、帖子等信息进行数据库分离，然后对帖子、用户按照板块和ID进行散列数据库和表，最终可以在配置文件中进行简单的配置便能让系统随时增加一台低成本的数据库进来补充系统性能。

4. 缓存
缓存一词搞技术的都接触过，很多地方用到缓存。网站架构和网站开发中的缓存也是非常重要。这里先讲述最基本的两种缓存。高级和分布式的缓存在后面讲述。
架构方面的缓存，对Apache比较熟悉的人都能知道Apache提供了自己的缓存模块，也可以使用外加的Squid模块进行缓存，这两种方式均可以有效的提高Apache的访问响应能力。
网站程序开发方面的缓存，Linux上提供的Memory Cache是常用的缓存接口，可以在web开发中使用，比如用Java开发的时候就可以调用MemoryCache对一些数据进行缓存和通讯共享，一些大型社区使用了这样的架构。另外，在使用web语言开发的时候，各种语言基本都有自己的缓存模块和方法，PHP有Pear的Cache模块，Java就更多了，.net不是很熟悉，相信也肯定有。（.net是System.HttpRuntime.Cache，但是前提是你必须引用System.Web.dll。这也就说明了，System.Web.Caching.Cache这个对象完全是可以脱离于System.Web这个名称空间，而作为一个独立的缓存框架而存在。）

5. 镜像
镜像是大型网站常采用的提高性能和数据安全性的方式，镜像的技术可以解决不同网络接入商和地域带来的用户访问速度差异，比如ChinaNet和EduNet之间的差异就促使了很多网站在教育网内搭建镜像站点，数据进行定时更新或者实时更新。在镜像的细节技术方面，这里不阐述太深，有很多专业的现成的解决架构和产品可选。也有廉价的通过软件实现的思路，比如Linux上的rsync等工具。

6. 负载均衡
负载均衡将是大型网站解决高负荷访问和大量并发请求采用的高端解决办法。负载均衡技术发展了多年，有很多专业的服务提供商和产品可以选择，我个人接触过一些解决方法，其中有两个架构可以给大家做参考。
（1）、硬件四层交换
第四层交换使用第三层和第四层信息包的报头信息，根据应用区间识别业务流，将整个区间段的业务流分配到合适的应用服务器进行处理。
第四层交换功能就像是虚IP，指向物理服务器。它传输的业务服从的协议多种多样，有HTTP、FTP、NFS、Telnet或其他协议。这些业务在物理服务器基础上，需要复杂的载量平衡算法。在IP世界，业务类型由终端TCP或UDP端口地址来决定，在第四层交换中的应用区间则由源端和终端IP地址、TCP和UDP端口共同决定。
在硬件四层交换产品领域，有一些知名的产品可以选择，比如Alteon、F5等，这些产品很昂贵，但是物有所值，能够提供非常优秀的性能和很灵活的管理能力。“Yahoo中国”当初接近2000台服务器，只使用了三、四台Alteon就搞定了。
(2)、软件四层交换
大家知道了硬件四层交换机的原理后，基于OSI模型来实现的软件四层交换也就应运而生，这样的解决方案实现的原理一致，不过性能稍差。但是满足一定量的压力还是游刃有余的，有人说软件实现方式其实更灵活，处理能力完全看你配置的熟悉能力。
软件四层交换我们可以使用Linux上常用的LVS来解决，LVS就是Linux Virtual Server，他提供了基于心跳线heartbeat的实时灾难应对解决方案，提高系统的强壮性，同时可供了灵活的虚拟VIP配置和管理功能，可以同时满足多种应用需求，这对于分布式的系统来说必不可少。
一个典型的使用负载均衡的策略就是，在软件或者硬件四层交换的基础上搭建squid集群，这种思路在很多大型网站包括搜索引擎上被采用，这样的架构低成本、高性能还有很强的扩张性，随时往架构里面增减节点都非常容易。
对于大型网站来说，前面提到的每个方法可能都会被同时使用到，这里介绍得比较浅显，具体实现过程中很多细节还需要大家慢慢熟悉和体会。有时一个很小的squid参数或者apache参数设置，对于系统性能的影响就会很大。

7. 最新：CDN加速技术
什么是CDN？
CDN的全称是Content Delivery Network，即内容分发网络。CDN的通俗理解就是网站加速，CPU均衡负载，可以解决跨运营商，跨地区，服务器负载能力过低，带宽过少等带来的网站打开速度慢等问题。　
CDN的基本思路是尽可能避开互联网上有可能影响数据传输速度和稳定性的瓶颈和环节，使内容传输的更快、更稳定。通过在网络各处放置节点服务器所构成的在现有的互联网基础之上的一层智能虚拟网络，CDN系统能够实时地根据网络流量和各节点的连接、负载状况以及到用户的距离和响应时间等综合信息将用户的请求重新导向离用户最近的服务节点上。其目的是使用户可就近取得所需内容，解决 Internet网络拥挤的状况，提高用户访问网站的响应速度。
CDN有别于镜像，因为它比镜像更智能，或者可以做这样一个比喻：CDN=更智能的镜像+缓存+流量导流。因而，CDN可以明显提高Internet网络中信息流动的效率。从技术上全面解决由于网络带宽小、用户访问量大、网点分布不均等问题，提高用户访问网站的响应速度。
CDN的类型特点
CDN的实现分为三类：镜像、高速缓存、专线。
镜像站点（Mirror Site），是最常见的，它让内容直接发布，适用于静态和准动态的数据同步。但是购买和维护新服务器的费用较高，还必须在各个地区设置镜像服务器，配备专业技术人员进行管理与维护。对于大型网站来说，更新所用的带宽成本也大大提高了。
高速缓存，成本较低，适用于静态内容。Internet的统计表明，超过80%的用户经常访问的是20%的网站的内容，在这个规律下，缓存服务器可以处理大部分客户的静态请求，而原始的服务器只需处理约20%左右的非缓存请求和动态请求，于是大大加快了客户请求的响应时间，并降低了原始服务器的负载。
CDN服务一般会在全国范围内的关键节点上放置缓存服务器。
专线，让用户直接访问数据源，可以实现数据的动态同步。
CDN的实例
举个例子来说，当某用户访问网站时，网站会利用全球负载均衡技术，将用户的访问指向到距离用户最近的正常工作的缓存服务器上，直接响应用户的请求。
当用户访问已经使用了CDN服务的网站时，其解析过程与传统解析方式的最大区别就在于网站的授权域名服务器不是以传统的轮询方式来响应本地DNS的解析请求，而是充分考虑用户发起请求的地点和当时网络的情况，来决定把用户的请求定向到离用户最近同时负载相对较轻的节点缓存服务器上。
通过用户定位算法和服务器健康检测算法综合后的数据，可以将用户的请求就近定向到分布在网络“边缘”的缓存服务器上，保证用户的访问能得到更及时可靠的响应。
由于大量的用户访问都由分布在网络边缘的CDN节点缓存服务器直接响应了，这就不仅提高了用户的访问质量，同时有效地降低了源服务器的负载压力。



48 平台上的图片如何防盗链？
http标准协议中有专门的字段记录referer
一来可以追溯上一个入站地址是什么
二来对于资源文件，可以跟踪到包含显示他的网页地址是什么。
因此所有防盗链方法都是基于这个Referer字段
网上比较多的2种

一种是使用apache文件FileMatch限制，在httpd.conf中增加 ( 其实也可以将把下面的语句存成一个.htaccess文件)，并放到你的网站的根目录（就是www/html目录），这样子别人就没有办法盗连你的东东了~~
SetEnvIfNoCase Referer"^http://yahoo.com/" local_ref=1
Order Allow,Deny
Allow from env=local_ref
Allow from 127.0.0.1
这种很方便禁止非允许访问URL引用各种资源文件
请大家注意，把第一句"^http://yahoo.com/"改为你的网站，比如我的网站是： http://www.linji.cn
我应该这么写的
"^http://www.linji.cn/"

第二种是使用rewrite,需要增加apache的mode_rewrite，支持.htaccess文件目录权限限制
在虚拟主机根目录增加.htaccess文件，描述从定向，把非本地地址refer的图片文件都从定向到警告图片或者警告网页上。
首先要确认你的服务器或空间的服务器解译引擎为Apache2，还有支持.htaccess客户设置文件，
如果你有自己的服务器就请先对./conf/httpd.conf 文件做以下修改
找到：#LoadModule rewrite_module modules/mod_rewrite.so
把前面的 # 给去丢
找到等一个AllowOverride None 改为 AllowOverride All
重启Apache2服务器
接下就是做一个.htaccess 文件了，其.htaccess 文件内容为
RewriteEngine on
RewriteCond %{HTTP_REFERER} !^http://aaoo.net/.*$ [NC]
RewriteCond %{HTTP_REFERER} !^http://aaoo.net$ [NC]
RewriteCond %{HTTP_REFERER} !^http://www.aaoo.net/.*$ [NC]
RewriteCond %{HTTP_REFERER} !^http://www.aaoo.net$ [NC]
RewriteRule .*.(jpg|jpeg|gif|png|bmp|rar|zip|exe)$ http://down.yoyo.com.ru/err.html [R,NC]

其中有色的地方都是要改为你的：
红色：就是改为你提供下载页面的地址，也就是只有通过这个地址才可以下载你所提供的东东。
蓝色：就是要保护文件的扩展名(以|分开)，也就是说以这些为扩展名的文件只有通过红色的地址才可以访问。
绿色：如果不是通过红色的地址访问蓝色这些为扩展名的文件时就回重定向到绿色地址上。
这个方法有个好处是，不同的虚拟主机用不同的描述定义。
接下就是怎么用.htaccess 文件来实现防盗链了。
首先要在空间上建两个目录(当然目录名随你)，一个为 web 另一个为 down ，
web 是用来放下载页面的(或下载程序)，down 当然就是放你提供的东东的啦，
把.htaccess 文件的红色部分改一下，改为http://你的域名/web。蓝色部分
改为你要保护文件的扩展名。绿色部分改为http://你的域名/web。改后保存
.htaccess 文件把它上传到 down 目录。

还有第三种：
我在解决plog禁止盗链的时候，发现个问题，也算个好方法。
plog把所有资源都自己管理起来，用resserver.php来动态显示，这样统一的入口方便添加权限操作。
同时造成上面2种方法无法使用，因为不再是apache直接访问资源文件，而是php通过文件读取。
因此只能在代码中做手脚：在读取资源文件输出之前，加如下判断代码
引用
$referer = $_SERVER['HTTP_REFERER'];
$selfurl = $_SERVER['HTTP_HOST'];
if(false == strpos($referer,$selfurl))
{
echo '非法盗链!';
exit(1);
}
这里有些偷懒，直接看引用地址中是否包含host地址，不过原理就是这样，判断referer是否是本站地址。
我们常常在下载的时候，也碰到盗链网站无法下载，报盗链的问题。要下载这类文件最简单的方法就是改referer
比方flashget中，网址下面的"引用"一栏中，直接填写下载地址就可以了




49 消息队列的原理和实现？
消息队列技术是分布式应用间交换信息的一种技术。消息队列可驻留在内存或磁盘上,队列存储消息直到它们被应用程序读走。通过消息队列，应用程序可独立地执行--它们不需要知道彼此的位置、或在继续执行前不需要等待接收程序接收此消息。
在分布式计算环境中，为了集成分布式应用，开发者需要对异构网络环境下的分布式应用提供有效的通信手段。为了管理需要共享的信息，对应用提供公共的信息交换机制是重要的。
消息队列为构造以同步或异步方式实现的分布式应用提供了松耦合方法。消息队列的API调用被嵌入到新的或现存的应用中，通过消息发送到内存或基于磁盘的队列或从它读出而提供信息交换。消息队列可用在应用中以执行多种功能，比如要求服务、交换信息或异步处理等。
中间件是一种独立的系统软件或服务程序，分布式应用系统借助这种软件在不同的技术之间共享资源，管理计算资源和网络通讯。它在计算机系统中是一个关键软件，它能实现应用的互连和互操作性，能保证系统的安全、可靠、高效的运行。中间件位于用户应用和操作系统及网络软件之间，它为应用提供了公用的通信手段，并且独立于网络和操作系统。中间件为开发者提供了公用于所有环境的应用程序接口，当应用程序中嵌入其函数调用，它便可利用其运行的特定操作系统和网络环境的功能，为应用执行通信功能。
如果没有消息中间件完成信息交换，应用开发者为了传输数据，必须要学会如何用网络和操作系统软件的功能，编写相应的应用程序来发送和接收信息，且交换信息没有标准方法，每个应用必须进行特定的编程从而和多平台、不同环境下的一个或多个应用通信。例如，为了实现网络上不同主机系统间的通信，将要求具备在网络上如何交换信息的知识（比如用TCP/IP的socket程序设计）；为了实现同一主机内不同进程之间的通讯，将要求具备操作系统的消息队列或命名管道(Pipes)等知识。

MQ的通讯模式
1) 点对点通讯：点对点方式是最为传统和常见的通讯方式，它支持一对一、一对多、多对多、多对一等多种配置方式，支持树状、网状等多种拓扑结构。
2) 多点广播：MQ适用于不同类型的应用。其中重要的，也是正在发展中的是"多点广播"应用，即能够将消息发送到多个目标站点(Destination List)。可以使用一条MQ指令将单一消息发送到多个目标站点，并确保为每一站点可靠地提供信息。MQ不仅提供了多点广播的功能，而且还拥有智能消息分发功能，在将一条消息发送到同一系统上的多个用户时，MQ将消息的一个复制版本和该系统上接收者的名单发送到目标MQ系统。目标MQ系统在本地复制这些消息，并将它们发送到名单上的队列，从而尽可能减少网络的传输量。
3) 发布/订阅(Publish/Subscribe)模式：发布/订阅功能使消息的分发可以突破目的队列地理指向的限制，使消息按照特定的主题甚至内容进行分发，用户或应用程序可以根据主题或内容接收到所需要的消息。发布/订阅功能使得发送者和接收者之间的耦合关系变得更为松散，发送者不必关心接收者的目的地址，而接收者也不必关心消息的发送地址，而只是根据消息的主题进行消息的收发。在MQ家族产品中，MQ Event Broker是专门用于使用发布/订阅技术进行数据通讯的产品，它支持基于队列和直接基于TCP/IP两种方式的发布和订阅。
4) 群集(Cluster)：为了简化点对点通讯模式中的系统配置，MQ提供Cluster(群集)的解决方案。群集类似于一个域(Domain)，群集内部的队列管理器之间通讯时，不需要两两之间建立消息通道，而是采用群集(Cluster)通道与其它成员通讯，从而大大简化了系统配置。此外，群集中的队列管理器之间能够自动进行负载均衡，当某一队列管理器出现故障时，其它队列管理器可以接管它的工作，从而大大提高系统的高可靠性。 

50 java堆，简述新生代老年代？
java堆，分新生代老年代，新生代有Eden，from surviver，to surviver三个空间，堆被所有线程共。eden内存不足时，发生一次minor GC，会把from survivor和eden的对象复制到to survivor，这次的to survivor就变成了下次的from survivor，经过多次minor GC，默认15次，达到次数的对象会从survivor进行老年代。1次new如果新生代装不下，则直接进入老年代。
堆的年轻代大则老年代小，GC少，但是每次时间会比较长。年轻代小则老年代大，会缩短每次GC的时间，但是次数频繁。可以让老年代尽量缓存常用对象，JVM默认年轻代和老年代的大小比例为1:2,。观察峰值老年代内存，不影响full GC，加大老年代可调1:1，但是要给老年代预留三分之一的空间。减少使用全局变量和大对象 ，调整新生代，老年代到最合适。


51 内存溢出可能原因和解决？
原因可能是
A，数据加载过多，如1次从数据库中取出过多数据   
B，集合类中有对对象的引用，用完后没有清空或者集合对象未置空导致引用存在等，是的JVM无法回收  
C，死循环，过多重复对象 
D，第三方软件的bug       
E，启动参数内存值设定的过小。
例如方法：修改JVM启动参数，加内存(-Xms，-Xmx)；错误日志，是否还有其他错误；代码走查



52 http是无状态通信，http的请求方式有哪些，可以自己定义新的请求方式么？
一、无状态描述
无状态是指，当浏览器发送请求给服务器的时候，服务器响应，但是同一个浏览器再发送请求给服务器的时候，他会响应，但是他不知道你就是刚才那个浏览器，简单地说，就是服务器不会去记得你，所以是无状态协议。
而DNS是有状态协议 。 
HTTP是一个属于应用层的面向对象的协议，HTTP协议一共有五大特点，
1、支持客户/服务器模式；
2、简单快速；
3、灵活；
4、无连接；
5、无状态；
“无状态”是HTTP协议的主要特点之一，以下为“无状态”的解释。
无状态：是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。  www.2cto.com  
HTTP是Hyper Text Transfer Protocol的缩写，顾名思义，这个协议支持着超文本的传输。那么什么是超文本呢？说白了就是使用HTML编写的页面。通常，我们使用客户端浏览器访问服务器的资源，最常见的URL也是以html为后缀的文件。因此，我们可以说超文本是网络上最主要的资源。

二、八种方法
HTTP/1.1协议中共定义了八种方法（有时也叫“动作”）来表明Request-URI指定的资源的不同操作方式。
  OPTIONS 返回服务器针对特定资源所支持的HTTP请求方法。也可以利用向Web服务器发送'*'的请求来测试服务器的功能性。
　HEAD 向服务器索要与GET请求相一致的响应，只不过响应体将不会被返回。这一方法可以在不必传输整个响应内容的情况下，就可以获取包含在响应消息头中的元信息。
　GET 向特定的资源发出请求。注意：GET方法不应当被用于产生“副作用”的操作中，例如在web app.中。其中一个原因是GET可能会被网络蜘蛛等随意访问。
　POST 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。
　PUT 向指定资源位置上传其最新内容。
　DELETE 请求服务器删除Request-URI所标识的资源。
　TRACE 返回显服务器收到的请求，主要用于测试或诊断。
　CONNECT HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。

详述：
    0，GET：GET可以说是最常见的了，它本质就是发送一个请求来取得服务器上的某一资源。资源通过一组HTTP头和呈现数据（如HTML文本，或者图片或者视频等）返回给客户端。GET请求中，永远不会包含呈现数据。
　　1，HEAD：HEAD和GET本质是一样的，区别在于HEAD不含有呈现数据，而仅仅是HTTP头信息。想象一个业务情景：欲判断某个资源是否存在，我们通常使用GET，但这里用HEAD则意义更加明确。
　　2，PUT：这个方法比较少见。HTML表单也不支持这个。本质上来讲， PUT和POST极为相似，都是向服务器发送数据，但它们之间有一个重要区别，PUT通常指定了资源的存放位置，而POST则没有，POST的数据存放位置由服务器自己决定。举个例子：如一个用于提交博文的URL，/addBlog。如果用PUT，则提交的URL会是像这样的”/addBlog/abc123”，其中abc123就是这个博文的地址。而如果用POST，则这个地址会在提交后由服务器告知客户端。目前大部分博客都是这样的。显然，PUT和POST用途是不一样的。具体用哪个还取决于当前的业务场景。
　　3，DELETE：删除某一个资源。基本上这个也很少见，不过还是有一些地方比如amazon的S3云服务里面就用的这个方法来删除资源。
　　4，POST：向服务器提交数据。这个方法用途广泛，几乎目前所有的提交操作都是靠这个完成。
　　5，OPTIONS：这个方法很有趣，但极少使用。它用于获取当前URL所支持的方法。若请求成功，则它会在HTTP头中包含一个名为“Allow”的头，值是所支持的方法，如“GET, POST”。
　　其实还有一个TRACE方法，不过这个基本上不会用到，这里就不介绍了。以上的六种方法，我们可以跟数据库的CRUD增删改查操作对应起来：
　　CREATE ：PUT
　　READ：GET
　　UPDATE：POST
　　DELETE：DELETE 





53 socket通信，以及长连接，分包，连接异常断开的处理？
一、一些概念
1 短连接： 
连接->传输数据->关闭连接 
   HTTP是无状态的，浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接。 
   也可以这样说：短连接是指SOCKET连接后发送后接收完数据后马上断开连接。 

2 长连接： 
连接->传输数据->保持连接 -> 传输数据-> 。。。 ->关闭连接。 
长连接指建立SOCKET连接后不管是否使用都保持连接，但安全性较差。 

之所以出现粘包和半包现象,是因为TCP当中,只有流的概念,没有包的概念. 

3 半包 
指接受方没有接受到一个完整的包，只接受了部分，这种情况主要是由于TCP为提高传输效率，将一个包分配的足够大，导致接受方并不能一次接受完。（在长连接和短连接中都会出现）。 

4 粘包与分包 
指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。出现粘包现象的原因是多方面的，它既可能由发送方造成，也可能由接收方造成。发送方引起的粘包是由TCP协议本身造成的，TCP为提高传输效率，发送方往往要收集到足够多的数据后才发送一包数据。若连续几次发送的数据都很少，通常TCP会根据优化算法把这些数据合成一包后一次发送出去，这样接收方就收到了粘包数据。接收方引起的粘包是由于接收方用户进程不及时接收数据，从而导致粘包现象。这是因为接收方先把收到的数据放在系统接收缓冲区，用户进程从该缓冲区取数据，若下一包数据到达时前一包数据尚未被用户进程取走，则下一包数据放到系统接收缓冲区时就接到前一包数据之后，而用户进程根据预先设定的缓冲区大小从系统接收缓冲区取数据，这样就一次取到了多包数据。分包是指在出现粘包的时候我们的接收方要进行分包处理。（在长连接中都会出现） 

5 什么时候需要考虑半包的情况? 
从备注中我们了解到Socket内部默认的收发缓冲区大小大概是8K，但是我们在实际中往往需要考虑效率问题，重新配置了这个值，来达到系统的最佳状态。 
一个实际中的例子：用mina作为服务器端，使用的缓存大小为10k，这里使用的是短连接，所有不用考虑粘包的问题。 

6 问题描述：在并发量比较大的情况下，就会出现一次接受并不能完整的获取所有的数据。 
处理方式： 
1.通过包头+包长+包体的协议形式，当服务器端获取到指定的包长时才说明获取完整。 
2.指定包的结束标识，这样当我们获取到指定的标识时，说明包获取完整。 

7 什么时候需要考虑粘包的情况? 
@当时短连接的情况下，不用考虑粘包的情况 
@如果发送数据无结构，如文件传输，这样发送方只管发送，接收方只管接收存储就ok，也不用考虑粘包 
@如果双方建立连接，需要在连接后一段时间内发送不同结构数据 
处理方式： 
接收方创建一预处理线程，对接收到的数据包进行预处理，将粘连的包分开 
注：粘包情况有两种，一种是粘在一起的包都是完整的数据包，另一种情况是粘在一起的包有不完整的包 

备注: 
一个包没有固定长度，以太网限制在46－1500字节，1500就是以太网的MTU，超过这个量，TCP会为IP数据报设置偏移量进行分片传输，现在一般可允许应用层设置8k（NTFS系）的缓冲区，8k的数据由底层分片，而应用看来只是一次发送。windows的缓冲区经验值是4k,Socket本身分为两种，流(TCP)和数据报(UDP)，你的问题针对这两种不同使用而结论不一样。甚至还和你是用阻塞、还是非阻塞Socket来编程有关。 
1、通信长度，这个是你自己决定的，没有系统强迫你要发多大的包，实际应该根据需求和网络状况来决定。对于TCP，这个长度可以大点，但要知道，Socket内部默认的收发缓冲区大小大概是8K，你可以用SetSockOpt来改变。但对于UDP，就不要太大，一般在1024至10K。注意一点，你无论发多大的包，IP层和链路层都会把你的包进行分片发送，一般局域网就是1500左右，广域网就只有几十字节。分片后的包将经过不同的路由到达接收方，对于UDP而言，要是其中一个分片丢失，那么接收方的IP层将把整个发送包丢弃，这就形成丢包。显然，要是一个UDP发包佷大，它被分片后，链路层丢失分片的几率就佷大，你这个UDP包，就佷容易丢失，但是太小又影响效率。最好可以配置这个值，以根据不同的环境来调整到最佳状态。 
send()函数返回了实际发送的长度，在网络不断的情况下，它绝不会返回(发送失败的)错误，最多就是返回0。对于TCP你可以字节写一个循环发送。当send函数返回SOCKET_ERROR时，才标志着有错误。但对于UDP，你不要写循环发送，否则将给你的接收带来极大的麻烦。所以UDP需要用SetSockOpt来改变Socket内部Buffer的大小，以能容纳你的发包。明确一点，TCP作为流，发包是不会整包到达的，而是源源不断的到，那接收方就必须组包。而UDP作为消息或数据报，它一定是整包到达接收方。 
2、关于接收，一般的发包都有包边界，首要的就是你这个包的长度要让接收方知道，于是就有个包头信息，对于TCP，接收方先收这个包头信息，然后再收包数据。一次收齐整个包也可以，可要对结果是否收齐进行验证。这也就完成了组包过程。UDP，那你只能整包接收了。要是你提供的接收Buffer过小，TCP将返回实际接收的长度，余下的还可以收，而UDP不同的是，余下的数据被丢弃并返回WSAEMSGSIZE错误。注意TCP，要是你提供的Buffer佷大，那么可能收到的就是多个发包，你必须分离它们，还有就是当Buffer太小，而一次收不完Socket内部的数据，那么Socket接收事件(OnReceive)，可能不会再触发，使用事件方式进行接收时，密切注意这点。这些特性就是体现了流和数据包的区别。 


二、现象：服务器端等待客户断连接，当socket连接建立后，如果客户端异常断开，服务器会抛出异常，从而导致程序运行中断
目标：希望服务器一直等待连接，客户端中断后程序不退出，而客户端重新恢复后可以继续保持连接
代码：
public class Receive
{
public static byte[] buffer= new byte[1024];

public static ManualResetEvent socketEvent = new ManualResetEvent(false);
public static Socket sListener = new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp);
public static Socket handler = null;
public static string ClientBroken = "An connection was forcibly closed by the remote host";

public static void receive()
{
try
{
Console.WriteLine("Main ThreadID:" + AppDomain.GetCurrentThreadId());
byte[] bytes = new byte[1024];

IPAddress ipAddr = IPAddress.Parse("127.0.0.1");

int Port = 10001;

IPEndPoint EPServer = new IPEndPoint(ipAddr, Port);

//Binding a socket
sListener.Bind(EPServer);

//Start listening
sListener.Listen(10);

while(true)
{
if (handler==null)
{
//first must make a connect
Console.WriteLine("waiting for a connection...");
//asychronous function for accepting connections
sListener.BeginAccept(new AsyncCallback(AcceptCallback), sListener);
socketEvent.WaitOne();
handler.BeginReceive(buffer,0,buffer.Length,0,new AsyncCallback(ReceiveCallback),handler);
socketEvent.WaitOne();
}
else
{
Console.WriteLine("waiting next message...");
socketEvent.Reset();
handler.BeginReceive(buffer,0,buffer.Length,0,new AsyncCallback(ReceiveCallback),handler);
socketEvent.WaitOne();
}
}
Console.ReadLine();
}
catch (Exception e)
{
Console.WriteLine(e.ToString());
}
Console.ReadLine();
}


public static void AcceptCallback(IAsyncResult ar)
{
try
{
Console.WriteLine("AcceptCallback Thread ID:" + AppDomain.GetCurrentThreadId());
Socket listener = (Socket)ar.AsyncState;
//new socket
handler = listener.EndAccept(ar);
handler.BeginReceive(buffer,0,buffer.Length,0,new AsyncCallback(ReceiveCallback),handler);
}
catch (Exception e)
{
Console.WriteLine(e.ToString());
}
}


public static void ReceiveCallback(IAsyncResult ar)
{
string err_message=null;
try
{
Console.WriteLine("ReceiveCallback Thread ID:" + AppDomain.GetCurrentThreadId());

string content = String.Empty;
handler = (Socket)ar.AsyncState;

int bytesRead = handler.EndReceive(ar);

//if there is some data...
if (bytesRead>0)
{
//append it to the main string
content += Encoding.ASCII.GetString(buffer,0,bytesRead);

//if we encounter the end of message character
if (content.IndexOf((char)3)> -1 || content.IndexOf((char)16)>-1)
{
Console.WriteLine("Read "+content.Length+" bytes from socket. /n Data:"+content);
socketEvent.Set();
}
else
{
//otherwise receive the remaining data
handler.BeginReceive(buffer,0,buffer.Length,0,new AsyncCallback(ReceiveCallback),handler);
}
}

}
catch(Exception e)
{
err_message = e.Message;
if (err_message.IndexOf("An existing connection was forcibly closed by the remote host")> -1)
{
Console.WriteLine("An existing connection was forcibly closed by the remote host");
//handler.Shutdown(SocketShutdown.Both);
//handler.Close();

Console.WriteLine("waiting for a connection...");
//asychronous function for accepting connections
sListener.BeginAccept( new AsyncCallback(AcceptCallback), sListener);
}
else
{
Console.WriteLine(e.ToString());
}
}
}
}
说明：关键在于最后这段的异常处理，接收中断后，服务器端重新等待接收。

现象：客户端与服务器连接，当socket连接建立后，如果服务器端异常断开，客户端会抛出异常，从而导致程序运行中断
目标：希望客户端出现提示，服务器端中断后程序不退出，而服务器端重新恢复后可以继续保持连接
代码：
public class AsyncComm
{
public static string theResponse = "";
public static byte[] buffer = new byte[1024];

public static ManualResetEvent socketEvent = new ManualResetEvent(false);
public static Socket sClient= new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp);
public static IPEndPoint EPServer = new IPEndPoint(IPAddress.Parse("127.0.0.1"), 10001);

public static void send(string data)
{
byte[] byteData=null;
byteData = Encoding.ASCII.GetBytes(data);

try
{
if (!sClient.Connected)
{
Console.WriteLine(System.DateTime.Now.ToString("yyyy-MM-dd HH:mm:ss:ffff")+" "+"Connect begining......");
sClient.BeginConnect(EPServer, new AsyncCallback(ConnectCallback),sClient);
socketEvent.WaitOne();
}
sClient.BeginSend(byteData,0,byteData.Length,0,new AsyncCallback(SendCallback),sClient);
socketEvent.WaitOne();
}
catch (Exception e)
{
Console.WriteLine("Server side is broken...");
socketEvent.Reset();
return;
}
}

         public static void ConnectCallback(IAsyncResult ar)
{
try
{
Thread thr = Thread.CurrentThread;
Console.WriteLine("ConnectCallback Thread State:" + AppDomain.GetCurrentThreadId());

Socket sClient = (Socket)ar.AsyncState;
sClient.EndConnect(ar);
Console.WriteLine("Socket connected to " + sClient.RemoteEndPoint.ToString());
socketEvent.Set();
}
catch (Exception ex)
{
Console.WriteLine(System.DateTime.Now.ToString("yyyy-MM-dd HH:mm:ss:ffff")+"||"+AppDomain.GetCurrentThreadId()+"||3--Level 3 Server connection is broken, waiting for Level 3 Server connection......");
sClient= new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp);
socketEvent.Set();
}
}

receive函数相同，可以参照写出
说明：
在每次发送或接收时检测当前socket是否连接，如果没有连接，就启动连接，并阻塞线程等待ConnectCallback的返回


54 socket通信模型的使用，AIO和NIO？
客户端:创建套接字，连接服务器，然后不停的发送和接收数据。 
比较容易想到的一种服务器模型就是采用一个主线程，负责监听客户端的连接请求，当接收到某个客户端的连接请求后，创建一个专门用于和该客户端通信的套接字和一个辅助线程。以后该客户端和服务器的交互都在这个辅助线程内完成。这种方法比较直观，程序非常简单而且可移植性好，但是不能利用平台相关的特性。例如，如果连接数增多的时候（成千上万的连接），那么线程数成倍增长，操作系统忙于频繁的线程间切换，而且大部分线程在其生命周期内都是处于非活动状态的，这大大浪费了系统的资源。所以，如果你已经知道你的代码只会运行在Windows平台上，建议采用Winsock I/O模型。

一.Select模型: 轮询fd_set集合
利用select函数，实现对I/O 的管理。最初设计该模型时，主要面向的是某些使用UNIX操作系统的计算机，它们采用的是Berkeley套接字方案。Select模型已集成到 Winsock 1.1中，它使那些想避免在套接字调用过程中被无辜“锁定”的应用程序，采取一种有序的方式，同时进行对多个套接字的管理。
int select(
int nfds,
fd_set* readfds,
fd_set* writefds,
fd_set* exceptfds,
const struct timeval* timeout
);
nfds：本参数忽略，仅起到兼容作用。
readfds：（可选）指针，指向一组等待可读性检查的套接口。
writefds：（可选）指针，指向一组等待可写性检查的套接口。
exceptfds：（可选）指针，指向一组等待错误检查的套接口。
timeout：select()最多等待时间，对阻塞操作则为NULL。
FD_CLR(s,*set)：从集合set中删除描述字s。
FD_ISSET(s,*set)：若s为集合中一员，非零；否则为零。
FD_SET(s,*set)：向集合添加描述字s。
FD_ZERO(*set)：将set初始化为空集NULL。
timeout参数控制select()完成的时间。若timeout参数为空指针，则select()将一直阻塞到有一个描述字满足条件。否则的话，timeout指向一个timeval结构，其中指定了select()调用在返回前等待多长时间。如果timeval为{0,0}，则 select()立即返回，这可用于探询所选套接口的状态。
服务器来轮询查看某个套接字是否仍然处于读集中，如果是，则接收数据。如果接收的数据长度为0，或者发生WSAECONNRESET错误，则表示客户端套接字主动关闭，这时需要将服务器中对应的套接字所绑定的资源释放掉，然后调整我们的套接字数组（将数组中最后一个套接字挪到当前的位置上） 
除了需要有条件接受客户端的连接外，还需要在连接数为0的情形下做特殊处理，因为如果读集中没有任何套接字，select函数会立刻返回。
当调用非阻塞模式时，可以说socket在select上设置超时时间阻塞应用。
select 会在超时时间测试fd_set集合是否可用，如果超时/没有数据可读了会清除当前集合成员。

二.异步选择 
应用程序可以在一个套接字上接收以WINDOWS消息为基础的网络事件通知。该模型的实现方法是通过调用WSAAsynSelect函数 自动将套接字设置为非阻塞模式，并向WINDOWS注册一个或多个网络时间，并提供一个通知时使用的窗口句柄。当注册的事件发生时，对应的窗口将收到一个基于消息的通知。

三.事件选择 
Winsock 提供了另一个有用的异步I/O模型。和WSAAsyncSelect模型类似的是，它也允许应用程序在一个或多个套接字上，接收以事件为基础的网络事件通知。
基本思想是将每个套接字都和一个WSAEVENT对象对应起来，并且在关联的时候指定需要关注的哪些网络事件。一旦在某个套接字上发生了我们关注的事件（FD_READ和FD_CLOSE），与之相关联的WSAEVENT对象被Signaled。

四.重叠I/O模型 
readfile或者writefile的调用马上就会返回，这时候你可以去做你要做的事，系统会自动替你完成readfile或者writefile,在你调用了readfile或者writefile后，你继续做你的事，系统同时也帮你完成readfile或writefile的操作，这就是所谓的重叠。
1.用事件通知方式实现的重叠I/O模型 
异步I/O函数WSARecv。在调用WSARecv时，指定一个 WSAOVERLAPPED结构，这个调用不是阻塞的，也就是说，它会立刻返回。一旦有数据到达的时候，被指定的WSAOVERLAPPED结构中的 hEvent被Signaled。使得与该套接字相关联的WSAEVENT对象也被Signaled，所以WSAWaitForMultipleEvents的调用操作成功返回。
2.用完成例程方式实现的重叠I/O模型 
WSARecv时传递CompletionROUTINE指针，回调函数，当IO请求完成时调用该回调函数完成我们需要处理的工作，在这个模型中，主线程只用不停的接受连接即可；辅助线程判断有没有新的客户端连接被建立，如果有，就为那个客户端套接字激活一个异步的WSARecv操作，然后调用SleepEx使线程处于一种可警告的等待状态，以使得I/O完成后 CompletionROUTINE可以被内核调用。如果辅助线程不调用SleepEx，则内核在完成一次I/O操作后，无法调用完成例程（因为完成例程的运行应该和当初激活WSARecv异步操作的代码在同一个线程之内）。
Windows提供了四种异步IO技术，机制几乎是相同的，区别在于通知结果的方式不同：
1、使一个设备内核对象变为有信号
Windows将设备句柄看作可同步的对象，即它可以处于有信号或处于无信号状态，当创建设备句柄、以异步的方式发送IO请求时，该句柄处于无信号状态，当异步IO完成之后，该句柄受信，通过WaitForSingleobject或WatiForMultipleObjects函数可以判断设备操作合适完成。该技术只能用于一个设备只发送一个IO请求，否则，若一个设备对应多个操作，当句柄受信时无法判断是该设备的那个操作完成。
2、使一个事件内核对象变为有信号
针对每个I/O操作绑定一个内核事件对象，并将等待事件等待函数等待该事件的受信，当I/O操作完成后系统使得与该操作绑定的事件受信，从而判断那个操作完成。该技术解决了使一个设备内核对象变为有信号技术中一个设备只能对应一个操作的不足。
3、警告I/O
在该技术中，当发出设备IO请求时，同时要求我们传递一个被称为完成例程的回调函数，当IO请求完成时调用该回调函数完成我们需要处理的工作。该技术允许单个设备同时进行多个I/O请求。
4、完成端口
完成端口技术多用于处理大规模的请求，通过内在的进程池技术可以达到很高的性能。
-

五.完成端口模型 
只有在你的应用程序需要同时管理数百乃至上千个套接字的时候，而且希望随着系统内安装的CPU数量的增多，应用程序的性能也可以线性提升，才应考虑采用“完成端口”模型。
完成端口内部提供了线程池的管理，可以避免反复创建线程的开销，同时可以根据CPU的个数灵活的决定线程个数，而且可以让减少线程调度的次数从而提高性能。
首先要创建一个 I / O完成端口对象
HANDLE CreateIoCompletionPort (
HANDLE FileHandle,              // handle to file
HANDLE ExistingCompletionPort,  // handle to I/O completion port
ULONG_PTR CompletionKey,        // completion key
DWORD NumberOfConcurrentThreads // number of threads to execute concurrently
);
我们深入探讨其中的各个参数之前，首先要注意该函数实际用于两个明显有别的目的：
■ 用于创建一个完成端口对象。
■ 将一个句柄同完成端口关联到一起。
最开始创建一个完成端口时，唯一感兴趣的参数便是 NumberOfConcurrentThreads（并发
线程的数量）；前面三个参数都会被忽略。NumberOfConcurrentThreads参数的特殊之处在于，它定义了在一个完成端口上，同时允许执行的线程数量。理想情况下，我们希望每个处理器各自负责一个线程的运行，为完成端口提供服务，避免过于频繁的线程“场景”切换。若将该参数设为0，表明系统内安装了多少个处理器，便允许同时运行多少个线程！可用下述代码创建一个I / O完成端口：
CreateIoCompletionPort(INVALID_HANDLE_VALUE, NULL, 0, 0)
该语句的作用是返回一个句柄，在为完成端口分配了一个套接字句柄后，用来对那个端
口进行标定（引用）。
工作者线程调用 GetQueuedCompletionStatus 来轮询完成端口队列
如果你想在Windows平台上构建服务器应用，那么I/O模型是你必须考虑的。Windows操作系统提供了
选择（Select）、异步选择（WSAAsyncSelect）、事件选择（WSAEventSelect）、重叠I/O（Overlapped I/O）和完成端口（Completion Port)
共五种I/O模型。每一种模型均适用于一种特定的应用场景。程序员应该对自己的应用需求非常明确，而且综合考虑到程序的扩展性和可移植性
等因素，作出自己的选择。


第一点，NIO少了1次从内核空间到用户空间的拷贝。
ByteBuffer.allocateDirect()分配的内存使用的是本机内存而不是Java堆上的内存，和网络或者磁盘交互都在操作系统的内核空间中发生。allocateDirect()的区别在于这块内存不由java堆管理, 但仍然在同一用户进程内。
第二点，NIO以块处理数据，IO以流处理数据
第三点，非阻塞，NIO1个线程可以管理多个输入输出通道


55 HTTP协议、  HTTPS协议，SSL协议及完整交互过程；
1.        安全套接字（Secure Socket Layer，SSL）协议是Web浏览器与Web服务器之间安全交换信息的协议。
2.    SSL协议的三个特性
Ø  保密：在握手协议中定义了会话密钥后，所有的消息都被加密。
Ø  鉴别：可选的客户端认证，和强制的服务器端认证。
Ø  完整性：传送的消息包括消息完整性检查（使用MAC）。
3.    SSL的位置

HTTPS
1.     HTTPS基于SSL的HTTP协议。
2.     HTTPS使用与HTTP不同的端口(，一个加密、身份验证层（HTTP与TCP之间）)。
3.     提供了身份验证与加密通信方法，被广泛用于互联网上安全敏感的通信。
交互过程
客户端在使用HTTPS方式与Web服务器通信时有以下几个步骤，如图所示。

1)    客户端请求建立SSL连接，并将自己支持的一套加密规则发送给网站。
2)    网站从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，加密公钥，以及证书的颁发机构等信息
3)    获得网站证书之后浏览器要做以下工作：
Ø  验证证书的合法性
Ø  如果证书受信任，浏览器会生成一串随机数的密码，并用证书中提供的公钥加密。
Ø  使用约定好的HASH计算握手消息，
Ø  使用生成的随机数对消息进行加密，最后将之前生成的所有信息发送给网站。
4)    网站接收浏览器发来的数据之后要做以下的操作：
Ø  使用自己的私钥将信息解密取出密码
Ø  使用密码解密浏览器发来的握手消息，并验证HASH是否与浏览器发来的一致。
Ø  使用密码加密一段握手消息，发送给浏览器
5)    浏览器解密并计算握手消息的HASH，如果与服务端发来的HASH一致，此时握手结束。
6)    使用随机密码和对称加密算法对传输的数据加密，传输。
4.     密与HASH算法如下：
1)     非对称加密算法：RSA，DSA/DSS，用于在握手过程中加密生成的密码。
2)     对称加密算法：AES，RC4，3DES，用于对真正传输的数据进行加密。
3)     HASH算法：MD5，SHA1，SHA256，验证数据的完整性。
5.     HTTP与HTTPS的区别：
1)     https协议需要申请证书。
2)     http是超文本传输协议，明文传输；https使用的是具有安全性的SSL加密传输协议。
3)     http端口80,；https端口443。
4)     http连接简单无状态；https由SSL+HTTP协议构件的可进行加密传输、身份验证的网络协议。


56 假如你的项目出现性能瓶颈了，你觉得可能会是哪些方面，怎么解决问题？
1、 引言
QoS(Quality of Service，服务质量)控制技术作为下一代网络的核心技术之一，越来越成为计算机网络中研究与开发的热点问题。QoS控制的基本目标是为Internet应用提供性能保证和区分服务。随着Internet上Web应用的爆炸性增长和电子商务的飞速发展，如何为用户提供满意的服务性能保证成了一个新的研究课题，由于传统的Web服务器无法为Web应用提供服务区分和性能保证，因此，随着QoS技术研究和应用的深入，Web QoS作为QoS技术的一个新的重要研究领域应运而生。这种面向Web客户和Http请求的技术，是属于应用层的QoS，是企业对企业交易的一个重要条件，也是Web服务器中的一个必要元素，它度量的是用户在与Web站点进行交互时所感受到的服务性能，如：交易时间，交易的可靠性等等。在Web服务应用程序的实现中需要满足各种QoS属性，比如：可用性、可访问性、完整性、性能、可靠性、常规性和安全性等[1]
。
目前，Web QoS控制研究已经越来越受到国内外学界和业界的重视并取得了一定的成果。概括起来，实现Web QoS控制技术可以分为这样几大类：Web请求的分类机制、Web服务器软件的QoS控制机制、操作系统的Web QoS控制机制以及Web服务器集群的QoS控制机制。本文主要研究一个Web服务的性能瓶颈，并对其进行分析，提出相应的策略。


2、 Http对Web QoS的影响及对策
由于底层消息传递和传输协议的局限性，Web服务会遇到性能瓶颈。然而，对公众普遍接受的协议（例如 HTTP 和SOAP）的依赖却使它们成了必须承担的永久的负担。因此，本文对其加以分析并得出相应的解决措施。
2.1、 Http成为制约Web服务性能的一个瓶颈
Http是一种尽力而为的传输服务，是一个无状态的数据转发机制，它不保证数据包会被传输到目的地，而且不保证数据包到达的顺序。因而产生一个可怕的问题：在没有可用带宽的情况下，数据包就会被简单地丢弃。这样，许多服务级别高的付费用户就无得到服务级别的保证。比如：企业和企业之间的交易就比一般的浏览需要更可靠的服务保证，一个股票在线交易就比普通的下载更加需要实时保障。所以，随着运行在网络上的用户和数据量的增加和电子商务的飞速发展，在有限带宽和网络资源的条件下，Http显然是一个制约Web服务性能的一个瓶颈，Http协议无法为Web服务器提供区分服务和性能保证。
虽然可以使用新设计的协议如“可靠 HTTP”（Reliable HTTP，HTTPR）、“块可扩展交换协议”（Blocks Extensible Exchange Protocol，BEEP）和“直接因特网消息封装”（Direct Internet Message Encapsulation，DIME） [2]
,但这些用于 Web 服务传输的新协议（如 HTTPR 和 BEEP）的广泛采用还需要一些时间。因此，使用 Web 服务的应用程序设计人员在设计系统时应该理解 Web 服务的性能问题，比如延迟和可用性。下面给出了一些改善 Web 服务性能的策略来解决这个问题。
2.2四解决策略
2 .1.1使用异步消息队列
习惯上，许多应用程序使用同步消息传递，当在自己的计算机上运行应用程序时，同步的消息传递是没什么问题的；组件通信的延迟以几毫秒计。但是，对于 Web 服务来说，它们是通过因特网进行通信，这意味着延迟要以几十、几百甚至几千微秒计。
依赖远程 Web 服务的应用程序可以使用消息排队来改善可靠性，但要以响应时间为代价。 一个企业内的应用程序和Web 服务可以使用消息排队如“Java 消息传递服务”（Java Messaging Service，JMS）或 IBM MQSeries 进行 Web服务调用[2]
。企业消息传递为整个企业内的关键数据异步交换提供可靠、灵活的服务。 消息队列有两个主要优势：
(1)它是异步的：一个消息传递服务提供者可以在消息到达时向请求者传递消息，请求者不必为接收消息而请求消息。
(2)它是可靠的：消息传递服务可以确保一条消息被传递一次，且仅传递一次。
将来，因特网上的发布和订阅消息传递系统如 alphaWorks 上的 Utility Services 包可以用于 Web 服务调用[3]
。
2.1.2对到来的Http请求进行分类
实现Web QoS的一个重要环节是对到来的Http请求进行分类，在传统的Web服务中 HTTP的请求是直接由工作进程侦听的,它对于所有的请求均采用先到先服务的处理方式，显然这种方法忽略了客户的优先级别。现在通常使用一种用连接管理模块，可以对不同的请求进行分类，并设定其优先级，这样就可以实现对不同用户的差别服务。请求分类是实现Web差别服务的核心模块，它对不同的请求设定不同的优先级并将其放入相应的队列。分类的方法有很多，可以根据实际的需要进行选择，目前常用的方法可以分为以下几类：
（1） 根据不同的用户分类
要对客户进行分类，客户可以按服务器的要求输入一定的信息，服务器以此来判断客户的身份。一种方法是用客户的IP地址来区分客户，这种方法是在QoS Web服务器模型中，服务器可以对客户的服务请求设定不同的服务等级，按照预先定义的资源分配策略对客户的服务请求作出响应[4]
。这种方法具有占用带宽小，容易实现，客户等等时延小的优点。但缺点是客户端的IP地址经常会被代理服务器或者防火墙所屏蔽，因此它的应用也受到限制。
另外一种方法是基于Http Cookie的分类，它是将Web Cookie嵌入Http请求内，以表明客户所属的类别。HTTP请求中的Cookie是可以由服务器发送给浏览器的唯一标识符，它可以内嵌在HTTP请求中，用来表示不同的服务级别。服务商可以给某个特定的服务提供一个永久的Cookie以供给用户使用。这样，就可以为付费用户和免费用户设置不同的优先级，利用cookie 来识别用户信息,记录下用户在一段时间内的访问倾向,例如经常浏览哪一类的网页,或者常常购买哪一类的商品;并将有相同兴趣的用户归类分组。当用户访问网站时,服务器可以根据他们的兴趣倾向推荐他们可能接受的网页,而且可以预测用户将来可能的行为,以此来提高服务质量。
和基于Http Cookie的分类相似，基于浏览器plug-in的分类是将特定的标识符嵌入Http请求内以表明客户所属的类别。浏览器中的plug-in插件是内嵌在客户端的又一种标识方法，购买了某种优先级服务的用户可以从服务器端下载特定的插件，把它放入HTTP的请求中。这些方法可以对客户进行分组，从而对高级别的客户提供更好的Web QoS保证。
以上这些方法虽然很准确，但是比较繁琐，增加了客户的等待时延，同时也为判断客户的身份占用了额外的带宽。
（2） 根据请求的目标分类
根据请求的目标所特有的一些属性和特点，我们可以对客户进行分类。我们都知道，由于URL请求类型或文件名路径可以区分不同请求，以及若多个站点访问同一Web服务器节点的时候，服务器可以识别其IP。所以可以用基于URL请求类型或请求的文件路径的分类和基于目标IP或端口的分类两种方法来实现Web QoS控制。这种分类方法同样也可以为高级别用户提供优先服务。较好地消除由于在网络少量较大时，由Http协议而产生的瓶颈[5]
。
不同的URL请求类型或者不同的请求文件路径表明了请求的不同的重要程度，在这种情况下请求的重要性与发送者是无关的。它侧重于对于不同的请求动作和请求目的进行分类。按照其重要程度，一般可以将请求分为紧急的 (Mission-critical) 、对时延敏感(delay-sensitive)的、和尽力而为(best-effort)传送3种。 例如,在电子商务应用中，购买商品的用户显然应当比仅仅浏览的用户获取更高的优先级目的地的IP地址，如果在同一个网络节点中架设多个Web站点，那么就要用目的地址来区分请求的重要性。
（3） 利用其他网络参数
Web服务器也可以将传输和路由中对数据包分级的参数集成到自己的连接管理模块中。例如,在因特网的差分服务体系中,IP数据报头的TOS域常被用作包的优先级标识,Web服务器可直接从IP头取出TOS域中的数据作为请求的优先级[5]
。这样，也可以达到高级别用户服务的保证。
2.1.3、通过备份使服务平滑降级
在每个服务器上存储多份不同质量的Web 内容。当服务器超载时,可以使服务器有选择地为客户提供适宜质量的Web 内容,即以体面的方式为低优先级客户提供平滑的服务降级[6]
,而保证高优先级的客户不会受到降级服务。这样就可以在服务器过载的情况下自适应地提供连续的内容降级服务而不是简单地拒绝请求,从而能够更好地为用户提供Web QoS。
2.1.4、其它的保证Web Qos的方法
除了上文中所述的方法之外，我们还可以提供主动Web服务 QoS 的方法，如服务请求的高速缓存和负载平衡，服务提供者可以主动向服务请求者提供很高的 QoS。在Web服务器级别上和 Web 应用程序服务器级别上都可以完成高速缓存和负载平衡。负载平衡区分各种类型通信的优先次序，并确保适当地按照每个请求所表现出的价值对待它。

3、 结论和展望
随着Web 服务的广泛扩大,服务质量QoS 将变成一个判定服务提供者是否成功的重要因素。QoS 决定服务的可用性和实用性, 本文所列出的消除Http对于Web服务性能瓶颈的方法针对性强，易于实现。随着Web QoS研究技术的发展，基于中间件技术和Web服务器集群的QoS控制机制必将给Web提供更可靠的服务保障，有待我们进行更深入的研究。




57 如果出现大面积并发，在不增加服务器的基础上，如何解决服务器响应不及时问?
58 如果有一个特别大的访问量，到数据库上，怎么做优化？
（DB设计，DBIO，SQL优化，Java优化）
一、数据库结构的设计
如果不能设计一个合理的数据库模型，不仅会增加客户端和服务器段程序的编程和维护的难度，而且将会影响系统实际运行的性能。所以，在一个系统开始实施之前，完备的数据库模型的设计是必须的。
在一个系统分析、设计阶段，因为数据量较小，负荷较低。我们往往只注意到功能的实现，而很难注意到性能的薄弱之处，等到系统投入实际运行一段时间后，才发现系统的性能在降低，这时再来考虑提高系统性能则要花费更多的人力物力，而整个系统也不可避免的形成了一个打补丁工程。
所以在考虑整个系统的流程的时候，我们必须要考虑，在高并发大数据量的访问情况下，我们的系统会不会出现极端的情况。（例如：对外统计系统在7月16日出现的数据异常的情况，并发大数据量的的访问造成，数据库的响应时间不能跟上数据刷新的速度造成。具体情况是：在日期临界时（00：00：00），判断数据库中是否有当前日期的记录，没有则插入一条当前日期的记录。在低并发访问的情况下，不会发生问题，但是当日期临界时的访问量相当大的时候，在做这一判断的时候，会出现多次条件成立，则数据库里会被插入多条当前日期的记录，从而造成数据错误。），数据库的模型确定下来之后，我们有必要做一个系统内数据流向图，分析可能出现的瓶颈。
为了保证数据库的一致性和完整性，在逻辑设计的时候往往会设计过多的表间关联，尽可能的降低数据的冗余。（例如用户表的地区，我们可以把地区另外存放到一个地区表中）如果数据冗余低，数据的完整性容易得到保证，提高了数据吞吐速度，保证了数据的完整性，清楚地表达数据元素之间的关系。而对于多表之间的关联查询（尤其是大数据表）时，其性能将会降低，同时也提高了客户端程序的编程难度，因此，物理设计需折衷考虑，根据业务规则，确定对关联表的数据量大小、数据项的访问频度，对此类数据表频繁的关联查询应适当提高数据冗余设计但增加了表间连接查询的操作，也使得程序的变得复杂，为了提高系统的响应时间，合理的数据冗余也是必要的。设计人员在设计阶段应根据系统操作的类型、频度加以均衡考虑。
另外，最好不要用自增属性字段作为主键与子表关联。不便于系统的迁移和数据恢复。对外统计系统映射关系丢失（******************）。
原来的表格必须可以通过由它分离出去的表格重新构建。使用这个规定的好处是，你可以确保不会在分离的表格中引入多余的列，所有你创建的表格结构都与它们的实际需要一样大。应用这条规定是一个好习惯，不过除非你要处理一个非常大型的数据，否则你将不需要用到它。（例如一个通行证系统，我可以将USERID，USERNAME，USERPASSWORD，单独出来作个表，再把USERID作为其他表的外键）
表的设计具体注意的问题：

1、数据行的长度不要超过8020字节，如果超过这个长度的话在物理页中这条数据会占用两行从而造成存储碎片，降低查询效率。

2、能够用数字类型的字段尽量选择数字类型而不用字符串类型的（电话号码），这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接回逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。

3、对于不可变字符类型char和可变字符类型varchar 都是8000字节,char查询快，但是耗存储空间，varchar查询相对慢一些但是节省存储空间。在设计字段的时候可以灵活选择，例如用户名、密码等长度变化不大的字段可以选择CHAR，对于评论等长度变化大的字段可以选择VARCHAR。

4、字段的长度在最大限度的满足可能的需要的前提下，应该尽可能的设得短一些，这样可以提高查询的效率，而且在建立索引的时候也可以减少资源的消耗。


二、查询的优化 
保证在实现功能的基础上，尽量减少对数据库的访问次数；通过搜索参数，尽量减少对表的访问行数,最小化结果集，从而减轻网络负担；能够分开的操作尽量分开处理，提高每次的响应速度；在数据窗口使用SQL时，尽量把使用的索引放在选择的首列；算法的结构尽量简单；在查询时，不要过多地使用通配符如SELECT * FROM T1语句，要用到几列就选择几列如：SELECT COL1,COL2 FROM T1；在可能的情况下尽量限制尽量结果集行数如：SELECT TOP 300 COL1,COL2,COL3 FROM T1,因为某些情况下用户是不需要那么多的数据的。   
在没有建索引的情况下，数据库查找某一条数据，就必须进行全表扫描了，对所有数据进行一次遍历，查找出符合条件的记录。在数据量比较小的情况下，也许看不出明显的差别，但是当数据量大的情况下，这种情况就是极为糟糕的了。
SQL语句在SQL SERVER中是如何执行的，他们担心自己所写的SQL语句会被SQL SERVER误解。比如： 
select * from table1 where name='zhangsan' and tID > 10000 
和执行: 
select * from table1 where tID > 10000 and name='zhangsan' 
一些人不知道以上两条语句的执行效率是否一样，因为如果简单的从语句先后上看，这两个语句的确是不一样，如果tID是一个聚合索引，那么后一句仅仅从表的10000条以后的记录中查找就行了；而前一句则要先从全表中查找看有几个name='zhangsan'的，而后再根据限制条件条件tID>10000来提出查询结果。 
事实上，这样的担心是不必要的。SQL SERVER中有一个“查询分析优化器”，它可以计算出where子句中的搜索条件并确定哪个索引能缩小表扫描的搜索空间，也就是说，它能实现自动优化。虽然查询优化器可以根据where子句自动的进行查询优化，但有时查询优化器就会不按照您的本意进行快速查询。 
在查询分析阶段，查询优化器查看查询的每个阶段并决定限制需要扫描的数据量是否有用。如果一个阶段可以被用作一个扫描参数（SARG），那么就称之为可优化的，并且可以利用索引快速获得所需数据。 
SARG的定义：用于限制搜索的一个操作，因为它通常是指一个特定的匹配，一个值的范围内的匹配或者两个以上条件的AND连接。形式如下： 
列名 操作符 <常数 或 变量> 或 <常数 或 变量> 操作符 列名 
列名可以出现在操作符的一边，而常数或变量出现在操作符的另一边。如： 
Name=’张三’ 
价格>5000 
5000<价格 
Name=’张三’ and 价格>5000 
如果一个表达式不能满足SARG的形式，那它就无法限制搜索的范围了，也就是SQL SERVER必须对每一行都判断它是否满足WHERE子句中的所有条件。所以一个索引对于不满足SARG形式的表达式来说是无用的。 
所以，优化查询最重要的就是，尽量使语句符合查询优化器的规则避免全表扫描而使用索引查询。
具体要注意的：

1.应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如：
select id from t where num is null
可以在num上设置默认值0，确保表中num列没有null值，然后这样查询：
select id from t where num=0

2.应尽量避免在 where 子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描。优化器将无法通过索引来确定将要命中的行数,因此需要搜索该表的所有行。
3.应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如：
select id from t where num=10 or num=20
可以这样查询：
select id from t where num=10
union all
select id from t where num=20

4.in 和 not in 也要慎用，因为IN会使系统无法使用索引,而只能直接搜索表中的数据。如：
select id from t where num in(1,2,3)
对于连续的数值，能用 between 就不要用 in 了：
select id from t where num between 1 and 3

5.尽量避免在索引过的字符数据中，使用非打头字母搜索。这也使得引擎无法利用索引。 
见如下例子： 
SELECT * FROM T1 WHERE NAME LIKE ‘%L%’ 
SELECT * FROM T1 WHERE SUBSTING(NAME,2,1)=’L’ 
SELECT * FROM T1 WHERE NAME LIKE ‘L%’ 
即使NAME字段建有索引，前两个查询依然无法利用索引完成加快操作，引擎不得不对全表所有数据逐条操作来完成任务。而第三个查询能够使用索引来加快操作。

6.必要时强制查询优化器使用某个索引，如在 where 子句中使用参数，也会导致全表扫描。因为SQL只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描：
select id from t where num=@num
可以改为强制查询使用索引：
select id from t with(index(索引名)) where num=@num

7.应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如：
SELECT * FROM T1 WHERE F1/2=100 
应改为: 
SELECT * FROM T1 WHERE F1=100*2
SELECT * FROM RECORD WHERE SUBSTRING(CARD_NO,1,4)=’5378’ 
应改为: 
SELECT * FROM RECORD WHERE CARD_NO LIKE ‘5378%’
SELECT member_number, first_name, last_name FROM members 
WHERE DATEDIFF(yy,datofbirth,GETDATE()) > 21 
应改为: 
SELECT member_number, first_name, last_name FROM members 
WHERE dateofbirth < DATEADD(yy,-21,GETDATE()) 
即：任何对列的操作都将导致表扫描，它包括数据库函数、计算表达式等等，查询时要尽可能将操作移至等号右边。
8.应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如：
select id from t where substring(name,1,3)='abc'--name以abc开头的id
select id from t where datediff(day,createdate,'2005-11-30')=0--‘2005-11-30’生成的id
应改为:
select id from t where name like 'abc%'
select id from t where createdate>='2005-11-30' and createdate<'2005-12-1'

9.不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。
10.在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。

11.很多时候用 exists是一个好的选择：
elect num from a where num in(select num from b)
用下面的语句替换：
select num from a where exists(select 1 from b where num=a.num)
SELECT SUM(T1.C1)FROM T1 WHERE( 
(SELECT COUNT(*)FROM T2 WHERE T2.C2=T1.C2>0) 
SELECT SUM(T1.C1) FROM T1WHERE EXISTS( 
SELECT * FROM T2 WHERE T2.C2=T1.C2) 
两者产生相同的结果，但是后者的效率显然要高于前者。因为后者不会产生大量锁定的表扫描或是索引扫描。
如果你想校验表里是否存在某条纪录，不要用count(*)那样效率很低，而且浪费服务器资源。可以用EXISTS代替。如： 
IF (SELECT COUNT(*) FROM table_name WHERE column_name = 'xxx') 
可以写成： 
IF EXISTS (SELECT * FROM table_name WHERE column_name = 'xxx')
经常需要写一个T_SQL语句比较一个父结果集和子结果集，从而找到是否存在在父结果集中有而在子结果集中没有的记录，如： 
SELECT a.hdr_key FROM hdr_tbl a---- tbl a 表示tbl用别名a代替 
WHERE NOT EXISTS (SELECT * FROM dtl_tbl b WHERE a.hdr_key = b.hdr_key) 
SELECT a.hdr_key FROM hdr_tbl a 
LEFT JOIN dtl_tbl b ON a.hdr_key = b.hdr_key WHERE b.hdr_key IS NULL 
SELECT hdr_key FROM hdr_tbl 
WHERE hdr_key NOT IN (SELECT hdr_key FROM dtl_tbl) 
三种写法都可以得到同样正确的结果，但是效率依次降低。
12.尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。
13.避免频繁创建和删除临时表，以减少系统表资源的消耗。
14.临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件，最好使用导出表。
15.在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert。
16.如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。 
17.在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON ，在结束时设置 SET NOCOUNT OFF 。无需在执行存储过程和触发器的每个语句后向客户端发送 DONE_IN_PROC 消息。
18.尽量避免大事务操作，提高系统并发能力。
19.尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。 

20. 避免使用不兼容的数据类型。例如float和int、char和varchar、binary和varbinary是不兼容的。数据类型的不兼容可能使优化器无法执行一些本来可以进行的优化操作。例如: 
SELECT name FROM employee WHERE salary > 60000 
在这条语句中,如salary字段是money型的,则优化器很难对其进行优化,因为60000是个整型数。我们应当在编程时将整型转化成为钱币型,而不要等到运行时转化。

21.充分利用连接条件，在某种情况下，两个表之间可能不只一个的连接条件，这时在 WHERE 子句中将连接条件完整的写上，有可能大大提高查询速度。 
例： 
SELECT SUM(A.AMOUNT) FROM ACCOUNT A,CARD B WHERE A.CARD_NO = B.CARD_NO 
SELECT SUM(A.AMOUNT) FROM ACCOUNT A,CARD B WHERE A.CARD_NO = B.CARD_NO AND A.ACCOUNT_NO=B.ACCOUNT_NO 
第二句将比第一句执行快得多。

22、使用视图加速查询 
把表的一个子集进行排序并创建视图，有时能加速查询。它有助于避免多重排序 操作，而且在其他方面还能简化优化器的工作。例如：
SELECT cust.name，rcvbles.balance，……other columns 
FROM cust，rcvbles 
WHERE cust.customer_id = rcvlbes.customer_id 
AND rcvblls.balance>0 
AND cust.postcode>“98000” 
ORDER BY cust.name
如果这个查询要被执行多次而不止一次，可以把所有未付款的客户找出来放在一个视图中，并按客户的名字进行排序： 
CREATE VIEW DBO.V_CUST_RCVLBES 
AS 
SELECT cust.name，rcvbles.balance，……other columns 
FROM cust，rcvbles 
WHERE cust.customer_id = rcvlbes.customer_id 
AND rcvblls.balance>0 
ORDER BY cust.name 
然后以下面的方式在视图中查询： 
SELECT ＊ FROM V_CUST_RCVLBES 
WHERE postcode>“98000” 
视图中的行要比主表中的行少，而且物理顺序就是所要求的顺序，减少了磁盘I/O，所以查询工作量可以得到大幅减少。

23、能用DISTINCT的就不用GROUP BY 
SELECT OrderID FROM Details WHERE UnitPrice > 10 GROUP BY OrderID 
可改为： 
SELECT DISTINCT OrderID FROM Details WHERE UnitPrice > 10

24.能用UNION ALL就不要用UNION 
UNION ALL不执行SELECT DISTINCT函数，这样就会减少很多不必要的资源 
35.尽量不要用SELECT INTO语句。 
SELECT INOT 语句会导致表锁定，阻止其他用户访问该表。
上面我们提到的是一些基本的提高查询速度的注意事项,但是在更多的情况下,往往需要反复试验比较不同的语句以得到最佳方案。最好的方法当然是测试，看实现相同功能的SQL语句哪个执行时间最少，但是数据库中如果数据量很少，是比较不出来的，这时可以用查看执行计划，即：把实现相同功能的多条SQL语句考到查询分析器，按CTRL+L看查所利用的索引，表扫描次数（这两个对性能影响最大），总体上看询成本百分比即可。 

三、算法的优化
尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。.使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。与临时表一样，游标并不是不可使用。对小型数据集使用 FAST_FORWARD 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。
游标提供了对特定集合中逐行扫描的手段，一般使用游标逐行遍历数据，根据取出的数据不同条件进行不同的操作。尤其对多表和大表定义的游标（大的数据集合）循环很容易使程序进入一个漫长的等特甚至死机。 
在有些场合，有时也非得使用游标，此时也可考虑将符合条件的数据行转入临时表中，再对临时表定义游标进行操作，可时性能得到明显提高。
（例如：对内统计第一版）
封装存储过程
四、建立高效的索引
创建索引一般有以下两个目的：维护被索引列的唯一性和提供快速访问表中数据的策略。大型数据库有两种索引即簇索引和非簇索引，一个没有簇索引的表是按堆结构存储数据，所有的数据均添加在表的尾部，而建立了簇索引的表，其数据在物理上会按照簇索引键的顺序存储，一个表只允许有一个簇索引，因此，根据B树结构，可以理解添加任何一种索引均能提高按索引列查询的速度，但会降低插入、更新、删除操作的性能，尤其是当填充因子（Fill Factor）较大时。所以对索引较多的表进行频繁的插入、更新、删除操作，建表和索引时因设置较小的填充因子，以便在各数据页中留下较多的自由空间，减少页分割及重新组织的工作。 
索引是从数据库中获取数据的最高效方式之一。95% 的数据库性能问题都可以采用索引技术得到解决。作为一条规则，我通常对逻辑主键使用唯一的成组索引，对系统键（作为存储过程）采用唯一的非成组索引，对任何外键列[字段]采用非成组索引。不过，索引就象是盐，太多了菜就咸了。你得考虑数据库的空间有多大，表如何进行访问，还有这些访问是否主要用作读写。 
实际上，您可以把索引理解为一种特殊的目录。微软的SQL SERVER提供了两种索引：聚集索引（clustered index，也称聚类索引、簇集索引）和非聚集索引（nonclustered index，也称非聚类索引、非簇集索引）。下面，我们举例来说明一下聚集索引和非聚集索引的区别： 
其实，我们的汉语字典的正文本身就是一个聚集索引。比如，我们要查“安”字，就会很自然地翻开字典的前几页，因为“安”的拼音是“an”，而按照拼音排序汉字的字典是以英文字母“a”开头并以“z”结尾的，那么“安”字就自然地排在字典的前部。如果您翻完了所有以“a”开头的部分仍然找不到这个字，那么就说明您的字典中没有这个字；同样的，如果查“张”字，那您也会将您的字典翻到最后部分，因为“张”的拼音是“zhang”。也就是说，字典的正文部分本身就是一个目录，您不需要再去查其他目录来找到您需要找的内容。 
我们把这种正文内容本身就是一种按照一定规则排列的目录称为“聚集索引”。 
如果您认识某个字，您可以快速地从自动中查到这个字。但您也可能会遇到您不认识的字，不知道它的发音，这时候，您就不能按照刚才的方法找到您要查的字，而需要去根据“偏旁部首”查到您要找的字，然后根据这个字后的页码直接翻到某页来找到您要找的字。但您结合“部首目录”和“检字表”而查到的字的排序并不是真正的正文的排序方法，比如您查“张”字，我们可以看到在查部首之后的检字表中“张”的页码是672页，检字表中“张”的上面是“驰”字，但页码却是63页，“张”的下面是“弩”字，页面是390页。很显然，这些字并不是真正的分别位于“张”字的上下方，现在您看到的连续的“驰、张、弩”三字实际上就是他们在非聚集索引中的排序，是字典正文中的字在非聚集索引中的映射。我们可以通过这种方式来找到您所需要的字，但它需要两个过程，先找到目录中的结果，然后再翻到您所需要的页码。 
我们把这种目录纯粹是目录，正文纯粹是正文的排序方式称为“非聚集索引”。 
进一步引申一下，我们可以很容易的理解：每个表只能有一个聚集索引，因为目录只能按照一种方法进行排序。

（一）何时使用聚集索引或非聚集索引 
下面的表总结了何时使用聚集索引或非聚集索引（很重要）。 
动作描述 使用聚集索引 使用非聚集索引 
列经常被分组排序 应 应 
返回某范围内的数据 应 不应 
一个或极少不同值 不应 不应 
小数目的不同值 应 不应 
大数目的不同值 不应 应 
频繁更新的列 不应 应 
外键列 应 应 
主键列 应 应 
频繁修改索引列 不应 应
事实上，我们可以通过前面聚集索引和非聚集索引的定义的例子来理解上表。如：返回某范围内的数据一项。比如您的某个表有一个时间列，恰好您把聚合索引建立在了该列，这时您查询2004年1月1日至2004年10月1日之间的全部数据时，这个速度就将是很快的，因为您的这本字典正文是按日期进行排序的，聚类索引只需要找到要检索的所有数据中的开头和结尾数据即可；而不像非聚集索引，必须先查到目录中查到每一项数据对应的页码，然后再根据页码查到具体内容。

（二）结合实际，谈索引使用的误区
理论的目的是应用。虽然我们刚才列出了何时应使用聚集索引或非聚集索引，但在实践中以上规则却很容易被忽视或不能根据实际情况进行综合分析。下面我们将根据在实践中遇到的实际问题来谈一下索引使用的误区，以便于大家掌握索引建立的方法。 
1、主键就是聚集索引 
这种想法笔者认为是极端错误的，是对聚集索引的一种浪费。虽然SQL SERVER默认是在主键上建立聚集索引的。 
通常，我们会在每个表中都建立一个ID列，以区分每条数据，并且这个ID列是自动增大的，步长一般为1。我们的这个办公自动化的实例中的列Gid就是如此。此时，如果我们将这个列设为主键，SQL SERVER会将此列默认为聚集索引。这样做有好处，就是可以让您的数据在数据库中按照ID进行物理排序，但笔者认为这样做意义不大。 
显而易见，聚集索引的优势是很明显的，而每个表中只能有一个聚集索引的规则，这使得聚集索引变得更加珍贵。 
从我们前面谈到的聚集索引的定义我们可以看出，使用聚集索引的最大好处就是能够根据查询要求，迅速缩小查询范围，避免全表扫描。在实际应用中，因为ID号是自动生成的，我们并不知道每条记录的ID号，所以我们很难在实践中用ID号来进行查询。这就使让ID号这个主键作为聚集索引成为一种资源浪费。其次，让每个ID号都不同的字段作为聚集索引也不符合“大数目的不同值情况下不应建立聚合索引”规则；当然，这种情况只是针对用户经常修改记录内容，特别是索引项的时候会负作用，但对于查询速度并没有影响。 
在办公自动化系统中，无论是系统首页显示的需要用户签收的文件、会议还是用户进行文件查询等任何情况下进行数据查询都离不开字段的是“日期”还有用户本身的“用户名”。 
通常，办公自动化的首页会显示每个用户尚未签收的文件或会议。虽然我们的where语句可以仅仅限制当前用户尚未签收的情况，但如果您的系统已建立了很长时间，并且数据量很大，那么，每次每个用户打开首页的时候都进行一次全表扫描，这样做意义是不大的，绝大多数的用户1个月前的文件都已经浏览过了，这样做只能徒增数据库的开销而已。事实上，我们完全可以让用户打开系统首页时，数据库仅仅查询这个用户近3个月来未阅览的文件，通过“日期”这个字段来限制表扫描，提高查询速度。如果您的办公自动化系统已经建立的2年，那么您的首页显示速度理论上将是原来速度8倍，甚至更快。
2、只要建立索引就能显著提高查询速度 
事实上，我们可以发现上面的例子中，第2、3条语句完全相同，且建立索引的字段也相同；不同的仅是前者在fariqi字段上建立的是非聚合索引，后者在此字段上建立的是聚合索引，但查询速度却有着天壤之别。所以，并非是在任何字段上简单地建立索引就能提高查询速度。
从建表的语句中，我们可以看到这个有着1000万数据的表中fariqi字段有5003个不同记录。在此字段上建立聚合索引是再合适不过了。在现实中，我们每天都会发几个文件，这几个文件的发文日期就相同，这完全符合建立聚集索引要求的：“既不能绝大多数都相同，又不能只有极少数相同”的规则。由此看来，我们建立“适当”的聚合索引对于我们提高查询速度是非常重要的。
3、把所有需要提高查询速度的字段都加进聚集索引，以提高查询速度 
上面已经谈到：在进行数据查询时都离不开字段的是“日期”还有用户本身的“用户名”。既然这两个字段都是如此的重要，我们可以把他们合并起来，建立一个复合索引（compound index）。 
很多人认为只要把任何字段加进聚集索引，就能提高查询速度，也有人感到迷惑：如果把复合的聚集索引字段分开查询，那么查询速度会减慢吗？带着这个问题，我们来看一下以下的查询速度（结果集都是25万条数据）：（日期列fariqi首先排在复合聚集索引的起始列，用户名neibuyonghu排在后列） 
我们可以看到如果仅用聚集索引的起始列作为查询条件和同时用到复合聚集索引的全部列的查询速度是几乎一样的，甚至比用上全部的复合索引列还要略快（在查询结果集数目一样的情况下）；而如果仅用复合聚集索引的非起始列作为查询条件的话，这个索引是不起任何作用的。当然，语句1、2的查询速度一样是因为查询的条目数一样，如果复合索引的所有列都用上，而且查询结果少的话，这样就会形成“索引覆盖”，因而性能可以达到最优。同时，请记住：无论您是否经常使用聚合索引的其他列，但其前导列一定要是使用最频繁的列。

（三）其他注意事项 
“水可载舟，亦可覆舟”，索引也一样。索引有助于提高检索性能，但过多或不当的索引也会导致系统低效。因为用户在表中每加进一个索引，数据库就要做更多的工作。过多的索引甚至会导致索引碎片。 
所以说，我们要建立一个“适当”的索引体系，特别是对聚合索引的创建，更应精益求精，以使您的数据库能得到高性能的发挥



59 集群如何同步会话状态?
在做了web集群后，你肯定会首先考虑session同步问题，因为通过负载均衡后，同一个IP访问同一个页面会被分配到不同的服务器上，如果session不同步的话，一个登录用户，一会是登录状态，一会又不是登录状态。所以本文就根据这种情况给出三种不同的方法来解决这个问题： 

一，利用数据库同步session
在做多服务器session同步时我没有用这种方法，如果非要用这种方法的话，我想过二种方法：
1，用一个低端电脑建个数据库专门存放web服务器的session，或者，把这个专门的数据库建在文件服务器上，用户访问web服务器时，会去这个专门的数据库check一下session的情况，以达到session同步的目的。
2，这种方法是把存放session的表和其他数据库表放在一起，如果mysql也做了集群了话，每个mysql节点都要有这张表，并且这张session表的数据表要实时同步。
说明：用数据库来同步session，会加大数据库的负担，数据库本来就是容易产生瓶颈的地方，如果把session还放到数据库里面，无疑是雪上加霜。上面的二种方法，第一点方法较好，把放session的表独立开来，减轻了真正数据库的负担

二，利用cookie同步session
session是文件的形势存放在服务器端的，cookie是文件的形势存在客户端的，怎么实现同步呢？方法很简单，就是把用户访问页面产生的session放到cookie里面，就是以cookie为中转站。你访问web服务器A，产生了session把它放到cookie里面了，你访问被分配到web服务器B，这个时候，web服务器B先判断服务器有没有这个session，如果没有，在去看看客户端的cookie里面有没有这个session，如果也没有，说明session真的不存，如果cookie里面有，就把cookie里面的sessoin同步到web服务器B，这样就可以实现session的同步了。
说明：这种方法实现起来简单，方便，也不会加大数据库的负担，但是如果客户端把cookie禁掉了的话，那么session就无从同步了，这样会给网站带来损失；cookie的安全性不高，虽然它已经加了密，但是还是可以伪造的。

三，利用memcache同步session
memcache可以做分布式，如果没有这功能，他也不能用来做session同步。他可以把web服务器中的内存组合起来，成为一个"内存池"，不管是哪个服务器产生的sessoin都可以放到这个"内存池"中，其他的都可以使用。
优点：以这种方式来同步session，不会加大数据库的负担，并且安全性比用cookie大大的提高，把session放到内存里面，比从文件中读取要快很多。
缺点：memcache把内存分成很多种规格的存储块，有块就有大小，这种方式也就决定了，memcache不能完全利用内存，会产生内存碎片，如果存储块不足，还会产生内存溢出。

四，总结
上面三种方法都是可行的
第一种方法，最影响系统速度的那种，不推荐使用；
第二种方法，效果不错，不过安全隐患一样的存在；
第三种方法，个人觉得第三种方法是最好的，推荐大家使用



60 负载均衡的原理?
不能狭义地理解为分配给所有实际服务器一样多的工作量，因为多台服务器的承载能力各不相同，这可能体现在硬件配置、网络带宽的差异，也可能因为某台服务器身兼多职，我们所说的“均衡”，也就是希望所有服务器都不要过载，
并且能够最大程序地发挥作用。

一、http重定向
当http代理（比如浏览器）向web服务器请求某个URL后，web服务器可以通过http响应头信息中的Location标记来返回一个新的URL。这意味着HTTP代理需要继续请求这个新的URL，完成自动跳转。
性能缺陷：
1、吞吐率限制
主站点服务器的吞吐率平均分配到了被转移的服务器。现假设使用RR（Round Robin）调度策略，子服务器的最大吞吐率为1000reqs/s，那么主服务器的吞吐率要达到3000reqs/s才能完全发挥三台子服务器的作用，那么如果有100台子服务器，那么主服务器的吞吐率可想而知得有大？相反，如果主服务的最大吞吐率为6000reqs/s，那么平均分配到子服务器的吞吐率为2000reqs/s，而现子服务器的最大吞吐率为1000reqs/s，因此就得增加子服务器的数量，增加到6个才能满足。
2、重定向访问深度不同
有的重定向一个静态页面，有的重定向相比复杂的动态页面，那么实际服务器的负载差异是不可预料的，而主站服务器却一无所知。因此整站使用重定向方法做负载均衡不太好。
我们需要权衡转移请求的开销和处理实际请求的开销，前者相对于后者越小，那么重定向的意义就越大，例如下载。你可以去很多镜像下载网站试下，会发现基本下载都使用了Location做了重定向。

二、DNS负载均衡
DNS负责提供域名解析服务，当访问某个站点时，实际上首先需要通过该站点域名的DNS服务器来获取域名指向的IP地址，在这一过程中，DNS服务器完成了域名到IP地址的映射，同样，这样映射也可以是一对多的，这时候，DNS服务器便充当了负载均衡调度器，它就像http重定向转换策略一样，将用户的请求分散到多台服务器上，但是它的实现机制完全不同。
使用dig命令来看下"baidu"的DNS设置
可见baidu拥有三个A记录
相比http重定向，基于DNS的负载均衡完全节省了所谓的主站点，或者说DNS服务器已经充当了主站点的职能。但不同的是，作为调度器，DNS服务器本身的性能几乎不用担心。因为DNS记录可以被用户浏览器或者互联网接入服务商的各级DNS服务器缓存，只有当缓存过期后才会重新向域名的DNS服务器请求解析。也说是DNS不存在http的吞吐率限制，理论上可以无限增加实际服务器的数量。
特性:
1、可以根据用户IP来进行智能解析。DNS服务器可以在所有可用的A记录中寻找离用记最近的一台服务器。
2、动态DNS：在每次IP地址变更时，及时更新DNS服务器。当然，因为缓存，一定的延迟不可避免。
不足：
1、没有用户能直接看到DNS解析到了哪一台实际服务器，加服务器运维人员的调试带来了不便。
2、策略的局限性。例如你无法将HTTP请求的上下文引入到调度策略中，而在前面介绍的基于HTTP重定向的负载均衡系统中，调度器工作在HTTP层面，它可以充分理解HTTP请求后根据站点的应用逻辑来设计调度策略，比如根据请求不同的URL来进行合理的过滤和转移。
3、如果要根据实际服务器的实时负载差异来调整调度策略，这需要DNS服务器在每次解析操作时分析各服务器的健康状态，对于DNS服务器来说，这种自定义开发存在较高的门槛，更何况大多数站点只是使用第三方DNS服务。
4、DNS记录缓存，各级节点的DNS服务器不同程序的缓存会让你晕头转向。
5、基于以上几点，DNS服务器并不能很好地完成工作量均衡分配，最后，是否选择基于DNS的负载均衡方式完全取决于你的需要。

三、反向代理负载均衡
这个肯定大家都有所接触，因为几乎所有主流的Web服务器都热衷于支持基于反向代理的负载均衡。它的核心工作就是转发HTTP请求。
相比前面的HTTP重定向和DNS解析，反向代理的调度器扮演的是用户和实际服务器中间人的角色：
1、任何对于实际服务器的HTTP请求都必须经过调度器
2、调度器必须等待实际服务器的HTTP响应，并将它反馈给用户（前两种方式不需要经过调度反馈，是实际服务器直接发送给用户）
特性：
1、调度策略丰富。例如可以为不同的实际服务器设置不同的权重，以达到能者多劳的效果。
2、对反向代理服务器的并发处理能力要求高，因为它工作在HTTP层面。
3、反向代理服务器进行转发操作本身是需要一定开销的，比如创建线程、与后端服务器建立TCP连接、接收后端服务器返回的处理结果、分析HTTP头部信息、用户空间和内核空间的频繁切换等，虽然这部分时间并不长，但是当后端服务器处理请求的时间非常短时，转发的开销就显得尤为突出。例如请求静态文件，更适合使用前面介绍的基于DNS的负载均衡方式。
4、反向代理服务器可以监控后端服务器，比如系统负载、响应时间、是否可用、TCP连接数、流量等，从而根据这些数据调整负载均衡的策略。
5、反射代理服务器可以让用户在一次会话周期内的所有请求始终转发到一台特定的后端服务器上（粘滞会话），这样的好处一是保持session的本地访问，二是防止后端服务器的动态内存缓存的资源浪费。

四、IP负载均衡(LVS-NAT)
因为反向代理服务器工作在HTTP层，其本身的开销就已经严重制约了可扩展性，从而也限制了它的性能极限。那能否在HTTP层面以下实现负载均衡呢？
NAT服务器:它工作在传输层，它可以修改发送来的IP数据包，将数据包的目标地址修改为实际服务器地址。
从Linux2.4内核开始，其内置的Neftilter模块在内核中维护着一些数据包过滤表，这些表包含了用于控制数据包过滤的规则。可喜的是，Linux提供了iptables来对过滤表进行插入、修改和删除等操作。更加令人振奋的是，Linux2.6.x内核中内置了IPVS模块，它的工作性质类型于Netfilter模块，不过它更专注于实现IP负载均衡。
想知道你的服务器内核是否已经安装了IPVS模块，可以
有输出意味着IPVS已经安装了。IPVS的管理工具是ipvsadm，它为提供了基于命令行的配置界面，可以通过它快速实现负载均衡系统。这就是大名鼎鼎的LVS(Linux Virtual Server，Linux虚拟服务器)。
1、打开调度器的数据包转发选项
echo 1 > /proc/sys/net/ipv4/ip_forward
2、检查实际服务器是否已经将NAT服务器作为自己的默认网关，如果不是，如添加
route add default gw xx.xx.xx.xx
3、使用ipvsadm配置
ipvsadm -A -t 111.11.11.11:80 -s rr  
添加一台虚拟服务器，-t 后面是服务器的外网ip和端口，-s rr是指采用简单轮询的RR调度策略（这属于静态调度策略，除此之外，LVS还提供了系列的动态调度策略，比如最小连接（LC）、带权重的最小连接（WLC），最短期望时间延迟（SED）等）
ipvsadm -a -t 111.11.11.11:80 -r 10.10.120.210:8000 -m  
ipvsadm -a -t 111.11.11.11:80 -r 10.10.120.211:8000 -m  
添加两台实际服务器（不需要有外网ip），-r后面是实际服务器的内网ip和端口，-m表示采用NAT方式来转发数据包
运行ipvsadm -L -n可以查看实际服务器的状态。这样就大功告成了。
实验证明使用基于NAT的负载均衡系统。作为调度器的NAT服务器可以将吞吐率提升到一个新的高度，几乎是反向代理服务器的两倍以上，这大多归功于在内核中进行请求转发的较低开销。但是一旦请求的内容过大时，不论是基于反向代理还是NAT，负载均衡的整体吞吐量都差距不大，这说明对于一睦开销较大的内容，使用简单的反向代理来搭建负载均衡系统是值考虑的。
这么强大的系统还是有它的瓶颈，那就是NAT服务器的网络带宽，包括内部网络和外部网络。当然如果你不差钱，可以去花钱去购买千兆交换机或万兆交换机，甚至负载均衡硬件设备，但如果你是个屌丝，咋办？
一个简单有效的办法就是将基于NAT的集群和前面的DNS混合使用，比如５个100Mbps出口宽带的集群，然后通过DNS来将用户请求均衡地指向这些集群，同时，你还可以利用DNS智能解析实现地域就近访问。这样的配置对于大多数业务是足够了，但是对于提供下载或视频等服务的大规模站点，NAT服务器还是不够出色。

五、直接路由(LVS-DR)
NAT是工作在网络分层模型的传输层（第四层），而直接路由是工作在数据链路层（第二层），貌似更屌些。它通过修改数据包的目标MAC地址（没有修改目标IP），将数据包转发到实际服务器上，不同的是，实际服务器的响应数据包将直接发送给客户羰，而不经过调度器。
1、网络设置
这里假设一台负载均衡调度器，两台实际服务器，购买三个外网ip，一台机一个，三台机的默认网关需要相同，最后再设置同样的ip别名，这里假设别名为10.10.120.193。这样一来，将通过10.10.120.193这个IP别名来访问调度器，你可以将站点的域名指向这个IP别名。
2、将ip别名添加到回环接口lo上
这是为了让实际服务器不要去寻找其他拥有这个IP别名的服务器，在实际服务器中运行：
另外还要防止实际服务器响应来自网络中针对IP别名的ARP广播，为此还要执行：
echo "1" > /proc/sys/net/ipv4/conf/lo/arp_ignore
echo "2" > /proc/sys/net/ipv4/conf/lo/arp_announce
echo "1" > /proc/sys/net/ipv4/conf/all/arp_ignore
echo "1" > /proc/sys/net/ipv4/conf/all/arp_announce
配置完了就可以使用ipvsadm配置LVS-DR集群了
ipvsadm -A -t 10.10.120.193:80 -s rr  
ipvsadm -a -t 10.10.120.193:80 -r 10.10.120.210:8000 -g  
ipvsadm -a -t 10.10.120.193:80 -r 10.10.120.211:8000 -g  
-g 就意味着使用直接路由的方式转发数据包
LVS-DR 相较于LVS-NAT的最大优势在于LVS-DR不受调度器宽带的限制，例如假设三台服务器在WAN交换机出口宽带都限制为10Mbps，只要对于连接调度器和两台实际服务器的LAN交换机没有限速，那么，使用LVS-DR理论上可以达到20Mbps的最大出口宽带，因为它的实际服务器的响应数据包可以不经过调度器而直接发往用户端啊，所以它与调度器的出口宽带没有关系，只能自身的有关系。而如果使用LVS-NAT，集群只能最大使用10Mbps的宽带。所以，越是响应数据包远远超过请求数据包的服务，就越应该降低调度器转移请求的开销，也就越能提高整体的扩展能力，最终也就越依赖于WAN出口宽带。
总的来说，LVS-DR适合搭建可扩展的负载均衡系统，不论是Web服务器还是文件服务器，以及视频服务器，它都拥有出色的性能。前提是你必须为实际器购买一系列的合法IP地址。

六、IP隧道(LVS-TUN)
基于IP隧道的请求转发机制：将调度器收到的IP数据包封装在一个新的IP数据包中，转交给实际服务器，然后实际服务器的响应数据包可以直接到达用户端。目前Linux大多支持，可以用LVS来实现，称为LVS-TUN，与LVS-DR不同的是，实际服务器可以和调度器不在同一个WANt网段，调度器通过IP隧道技术来转发请求到实际服务器，所以实际服务器也必须拥有合法的IP地址。
总体来说，LVS-DR和LVS-TUN都适合响应和请求不对称的Web服务器，如何从它们中做出选择，取决于你的网络部署需要，因为LVS-TUN可以将实际服务器根据需要部署在不同的地域，并且根据就近访问的原则来转移请求，所以有类似这种需求的，就应该选择LVS-TUN。


61高并发情况下，我们系统是如何支撑大量的请求的?
1尽量使用缓存，包括用户缓存，信息缓存等，多花点内存来做缓存，可以大量减少与数据库的交互，提高性能。
    2用jprofiler等工具找出性能瓶颈，减少额外的开销。
    3优化数据库查询语句，减少直接使用hibernate等工具的直接生成语句（仅耗时较长的查询做优化）。
    4优化数据库结构，多做索引，提高查询效率。
    5统计的功能尽量做缓存，或按每天一统计或定时统计相关报表，避免需要时进行统计的功能。
    6能使用静态页面的地方尽量使用，减少容器的解析（尽量将动态内容生成静态html来显示）。
    7解决以上问题后，使用服务器集群来解决单台的瓶颈问题。

	
	
---------------------------------------------------------------------------------------------------------------
------------------------------------------java ee basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------java se basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 元注解	
元注解是可以注解到注解上的注解，或者说元注解是一种基本注解，但是它能够应用到其它的注解上面。如果难于理解的话，你可以这样理解。元注解也是一张标签，但是它是一张特殊的标签，它的作用和目的就是给其他普通的标签进行解释说明的。
元标签有 @Retention、@Documented、@Target、@Inherited、@Repeatable 5 种。

（1）@Retention
Retention 的英文意为保留期的意思。当 @Retention 应用到一个注解上的时候，它解释说明了这个注解的的存活时间。
它的取值如下：
- RetentionPolicy.SOURCE 注解只在源码阶段保留，在编译器进行编译时它将被丢弃忽视。
- RetentionPolicy.CLASS 注解只被保留到编译进行的时候，它并不会被加载到 JVM 中。
- RetentionPolicy.RUNTIME 注解可以保留到程序运行的时候，它会被加载进入到 JVM 中，所以在程序运行时可以获取到它们。
我们可以这样的方式来加深理解，@Retention 去给一张标签解释的时候，它指定了这张标签张贴的时间。@Retention 相当于给一张标签上面盖了一张时间戳，时间戳指明了标签张贴的时间周期。

@Retention(RetentionPolicy.RUNTIME)
public @interface TestAnnotation {
}
上面的代码中，我们指定 TestAnnotation 可以在程序运行周期被获取到，因此它的生命周期非常的长。

（2）@Documented
顾名思义，这个元注解肯定是和文档有关。它的作用是能够将注解中的元素包含到 Javadoc 中去。

（3）@Target
Target 是目标的意思，@Target 指定了注解运用的地方。
你可以这样理解，当一个注解被 @Target 注解时，这个注解就被限定了运用的场景。
类比到标签，原本标签是你想张贴到哪个地方就到哪个地方，但是因为 @Target 的存在，它张贴的地方就非常具体了，比如只能张贴到方法上、类上、方法参数上等等。@Target 有下面的取值
    ElementType.ANNOTATION_TYPE 可以给一个注解进行注解
    ElementType.CONSTRUCTOR 可以给构造方法进行注解
    ElementType.FIELD 可以给属性进行注解
    ElementType.LOCAL_VARIABLE 可以给局部变量进行注解
    ElementType.METHOD 可以给方法进行注解
    ElementType.PACKAGE 可以给一个包进行注解
    ElementType.PARAMETER 可以给一个方法内的参数进行注解
    ElementType.TYPE 可以给一个类型进行注解，比如类、接口、枚举

（4）@Inherited
Inherited 是继承的意思，但是它并不是说注解本身可以继承，而是说如果一个超类被 @Inherited 注解过的注解进行注解的话，那么如果它的子类没有被任何注解应用的话，那么这个子类就继承了超类的注解。说的比较抽象。代码来解释。
@Inherited
	@Retention(RetentionPolicy.RUNTIME)
	@interface Test {}

	@Test
	public class A {}
public class B extends A {}
注解 Test 被 @Inherited 修饰，之后类 A 被 Test 注解，类 B 继承 A,类 B 也拥有 Test 这个注解。可以这样理解：老子非常有钱，所以人们给他贴了一张标签叫做富豪。老子的儿子长大后，只要没有和老子断绝父子关系，虽然别人没有给他贴标签，但是他自然也是富豪。老子的孙子长大了，自然也是富豪。这就是人们口中戏称的富一代，富二代，富三代。虽然叫法不同，好像好多个标签，但其实事情的本质也就是他们有一张共同的标签，也就是老子身上的那张富豪的标签。

（5）@Repeatable
Repeatable 自然是可重复的意思。@Repeatable 是 Java 1.8 才加进来的，所以算是一个新的特性。什么样的注解会多次应用呢？通常是注解的值可以同时取多个。举个例子，一个人他既是程序员又是产品经理,同时他还是个画家。

@interface Persons {
    Person[]  value();
}

@Repeatable(Persons.class)
@interface Person{
    String role default "";
}

@Person(role="artist")
@Person(role="coder")
@Person(role="PM")
public class SuperMan{

}
注意上面的代码，@Repeatable 注解了 Person。而 @Repeatable 后面括号中的类相当于一个容器注解。什么是容器注解呢？就是用来存放其它注解的地方。它本身也是一个注解。
我们再看看代码中的相关容器注解。
@interface Persons {
    Person[]  value();
}

按照规定，它里面必须要有一个 value 的属性，属性类型是一个被 @Repeatable 注解过的注解数组，注意它是数组。如果不好理解的话，可以这样理解。Persons 是一张总的标签，上面贴满了 Person 这种同类型但内容不一样的标签。把 Persons 给一个 SuperMan 贴上，相当于同时给他贴了程序员、产品经理、画家的标签。我们可能对于 @Person(role=”PM”) 括号里面的内容感兴趣，它其实就是给 Person 这个注解的 role 属性赋值为 PM ，大家不明白正常，马上就讲到注解的属性这一块。




2 Java 预置的注解
1） @Deprecated
这个元素是用来标记过时的元素，想必大家在日常开发中经常碰到。编译器在编译阶段遇到这个注解时会发出提醒警告，告诉开发者正在调用一个过时的元素比如过时的方法、过时的类、过时的成员变量。
public class Hero {
    @Deprecated
    public void say(){
        System.out.println("Noting has to say!");
    }

    public void speak(){
        System.out.println("I have a dream!");
    }
}
定义了一个 Hero 类，它有两个方法 say() 和 speak() ，其中 say() 被 @Deprecated 注解。然后我们在 IDE 中分别调用它们。可以看到，say() 方法上面被一条直线划了一条，这其实就是编译器识别后的提醒效果。

2） @Override
这个大家应该很熟悉了，提示子类要复写父类中被 @Override 修饰的方法

3） @SuppressWarnings
阻止警告的意思。之前说过调用被 @Deprecated 注解的方法后，编译器会警告提醒，而有时候开发者会忽略这种警告，他们可以在调用的地方通过 @SuppressWarnings 达到目的。
@SuppressWarnings("deprecation")
public void test1(){
    Hero hero = new Hero();
    hero.say();
    hero.speak();
}

4） @SafeVarargs
参数安全类型注解。它的目的是提醒开发者不要用参数做一些不安全的操作,它的存在会阻止编译器产生 unchecked 这样的警告。它是在 Java 1.7 的版本中加入的。

5） @SafeVarargs // Not actually safe!
    static void m(List<String>... stringLists) {
    Object[] array = stringLists;
    List<Integer> tmpList = Arrays.asList(42);
    array[0] = tmpList; // Semantically invalid, but compiles without warnings
    String s = stringLists[0].get(0); // Oh no, ClassCastException at runtime!
}
上面的代码中，编译阶段不会报错，但是运行时会抛出 ClassCastException 这个异常，所以它虽然告诉开发者要妥善处理，但是开发者自己还是搞砸了。
Java 官方文档说，未来的版本会授权编译器对这种不安全的操作产生错误警告。

6） @FunctionalInterface
函数式接口注解，这个是 Java 1.8 版本引入的新特性。函数式编程很火，所以 Java 8 也及时添加了这个特性。函数式接口 (Functional Interface) 就是一个具有一个方法的普通接口。
@FunctionalInterface
public interface Runnable {
    /**
     * When an object implementing interface <code>Runnable</code> is used
     * to create a thread, starting the thread causes the object's
     * <code>run</code> method to be called in that separately executing
     * thread.
     * <p>
     * The general contract of the method <code>run</code> is that it may
     * take any action whatsoever.
     *
     * @see     java.lang.Thread#run()
     */
    public abstract void run();
}
我们进行线程开发中常用的 Runnable 就是一个典型的函数式接口，上面源码可以看到它就被 @FunctionalInterface 注解。可能有人会疑惑，函数式接口标记有什么用，这个原因是函数式接口可以很容易转换为 Lambda 表达式。这是另外的主题了，有兴趣的同学请自己搜索相关知识点学习。


3 数组和集合的区别
（1）数组是大小固定的，并且同一个数组只能存放类型一样的数据（基本类型/引用类型）
（2）JAVA集合可以存储和操作数目不固定的一组数据。 (3)若程序时不知道究竟需要多少对象，需要在空间不足时自动扩增容量，则需要使用容器类库，array不适用。
（3）联系：使用相应的toArray()和Arrays.asList()方法可以回想转换。

4 编码规范~云移
@健壮性：功能准确前提下，是否考虑兼容空指针/数据异常/违法检查/边界值？
@稳定性：模块之间是否松耦合？代码在各种环境各种操作下是否保证运行正确？
@性能性：如果数据量很大是否能够支撑，并发性高是否考虑？多表连接的索引是否建立？是否可以改变方案使性能最大化？
@安全性：接口调用是否有身份校验？敏感数据是否加密？
@可扩展：如果需求改变了或者新增了是否好扩展，还是要全部推翻重来？
@可复用：系统是否存在这样的工具类？会不会多个方法出现一样的代码？
@可维护：代码是否按照编码规范编写？核心代码注释是否齐全？设计是否满足开闭原则？
@可配置：是否能够动态配置，改变值可以不用修改代码？
@高内聚低耦合：一个模块之内明确完成一个功能实现高内聚，模块之间要低耦合，模块下的类之间要多用组合少用继承。

5 ArrayList类特点
1）元素可以重复；
2）非同步的集合类；
3）实现了ICollection和List接口；
4）容量可以动态增加和减少，大小可变，初始容联为10；
5）插入、删除效率低下，查询效率高。
ArrayList<E>是一个可动态调整大小的数组，允许null类型的元素。我们知道，Java中的数组大小在初始化时就必须确定下来，而且一旦确定就不能改变，这会使得在很多场景下不够灵活。ArrayList<E>很好地帮我们解决了这个问题，当我们需要一个能根据包含元素的多少来动态收缩伸张的数组时，那么ArrayList<E>正是我们所需要的。

6 LinkList类特点
1）插入、删除元素比较快，查询效率低；
2）元素可以为null；
3）双向链表、堆栈、队列；
4）非同步的集合类。

7 Set（无序、不能重复）
Set里存放的对象是无序，不能重复的，集合中的对象不按特定的方式排序，只是简单地把对象加入集合中。

8 Map（键值对、键唯一、值不唯一）
Map集合中存储的是键值对，键不能重复，值可以重复。根据键得到值，对map集合遍历时先得到键的set集合，对set集合进行遍历，得到相应的值。
1） HashMap 
HashMap是最常用的Map，它根据键的HashCode值存储数据，根据键可以直接获取它的值，具有很快的访问速度，遍历时，取得数据的顺序是完全随机的。因为键对象不可以重复，所以HashMap最多只允许一条记录的键为Null，允许多条记录的值为Null，是非同步的
2） Hashtable
Hashtable与HashMap类似，是HashMap的线程安全版，它支持线程的同步，即任一时刻只有一个线程能写Hashtable，因此也导致了Hashtale在写入时会比较慢，它继承自Dictionary类，不同的是它不允许记录的键或者值为null，同时效率较低。
3） ConcurrentHashMap
线程安全，并且锁分离。ConcurrentHashMap内部使用段(Segment)来表示这些不同的部分，每个段其实就是一个小的hash table，它们有自己的锁。只要多个修改操作发生在不同的段上，它们就可以并发进行。
4） LinkedHashMap
LinkedHashMap保存了记录的插入顺序，在用Iteraor遍历LinkedHashMap时，先得到的记录肯定是先插入的，在遍历的时候会比HashMap慢，有HashMap的全部特性。
5） TreeMap
TreeMap实现SortMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序（自然顺序），也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。不允许key值为空，非同步的；

9 Vector和ArrayList
（1）vector是线程同步的，所以它也是线程安全的，而arraylist是线程异步的，是不安全的。如果不考虑到线程的安全因素，一般用arraylist效率比较高。
（2）如果集合中的元素的数目大于目前集合数组的长度时，vector增长率为目前数组长度的100%，而arraylist增长率为目前数组长度的50%。如果在集合中使用数据量比较大的数据，用vector有一定的优势。
（3）如果查找一个指定位置的数据，vector和arraylist使用的时间是相同的，如果频繁的访问数据，这个时候使用vector和arraylist都可以。而如果移动一个指定位置会导致后面的元素都发生移动，这个时候就应该考虑到使用linklist,因为它移动一个指定位置的数据时其它元素不移动。
ArrayList 和Vector是采用数组方式存储数据，此数组元素数大于实际存储的数据以便增加和插入元素，都允许直接序号索引元素，但是插入数据要涉及到数组元素移动等内存操作，所以索引数据快，插入数据慢，Vector由于使用了synchronized方法（线程安全）所以性能上比ArrayList要差，LinkedList使用双向链表实现存储，按序号索引数据需要进行向前或向后遍历，但是插入数据时只需要记录本项的前后项即可，所以插入数度较快。

10 arraylist和linkedlist
（1）ArrayList是实现了基于动态数组的数据结构，LinkedList基于链表的数据结构。
（2）对于随机访问get和set，ArrayList觉得优于LinkedList，因为LinkedList要移动指针。
（3）对于新增和删除操作add和remove，LinkedList比较占优势，因为ArrayList要移动数据。 这一点要看实际情况的。若只对单条数据插入或删除，ArrayList的速度反而优于LinkedList。但若是批量随机的插入删除数据，LinkedList的速度大大优于ArrayList. 因为ArrayList每插入一条数据，要移动插入点及之后的所有数据。

11 HashMap与TreeMap
（1） HashMap通过hashcode对其内容进行快速查找，而TreeMap中所有的元素都保持着某种固定的顺序，如果你需要得到一个有序的结果你就应该使用TreeMap（HashMap中元素的排列顺序是不固定的）。
（2）在Map 中插入、删除和定位元素，HashMap是最好的选择。但如果您要按自然顺序或自定义顺序遍历键，那么TreeMap会更好。使用HashMap要求添加的键类明确定义了hashCode()和 equals()的实现。
两个map中的元素一样，但顺序不一样，导致hashCode()不一样。同样做测试：
在HashMap中，同样的值的map,顺序不同，equals时，false;
而在treeMap中，同样的值的map,顺序不同,equals时，true，说明，treeMap在equals()时是整理了顺序了的。

12 HashTable与HashMap
（1）同步性:Hashtable是线程安全的，也就是说是同步的，而HashMap是线程序不安全的，不是同步的。
（2）HashMap允许存在一个为null的key，多个为null的value 。
（3）hashtable的key和value都不允许为null。

13  enum 关键字
隐含了所创建的类型都是 java.lang.Enum 类的子类（java.lang.Enum 是一个抽象类）。枚举类型符合通用模式 Class Enum<E extends Enum<E>>，而 E 表示枚举类型的名称。枚举类型的每一个值都将映射到 protected Enum(String name, int ordinal) 构造函数中，在这里，每个值的名称都被转换成一个字符串，并且序数设置表示了此设置被创建的顺序。
注意 ：枚举set,枚举map

14 异常
1）运行时异常：都是RuntimeException类及其子类异常，如NullPointerException运行时异常：都是RuntimeException类及其子类异常，如NullPointerException(空指针异常)、IndexOutOfBoundsException(下标越界异常)等，这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生。运行时异常的特点是Java编译器不会检查它，也就是说，当程序中可能出现这类异常，即使没有用try-catch语句捕获它，也没有用throws子句声明抛出它，也会编译通过。
2）非运行时异常 （编译异常）：是RuntimeException以外的异常，类型上都属于Exception类及其子类。从程序语法角度讲是必须进行处理的异常，如果不处理，程序就不能编译通过。如IOException、SQLException等以及用户自定义的Exception异常，一般情况下不自定义检查异常。

15 泛型表示
K 表示键(Key)
V 表示值（Value）
T 表示类型(Type)
E 表示集合元素类型（Entity）
? 表示不确定的类型 
<? super T> 表示包括T在内的任何T的父类
<? extends T> 表示包括T在内的任何T的子类

16 反射机制用途
反射被广泛地用于那些需要在运行时检测或修改程序行为的程序中。这是一个相对高级的特性，只有那些语言基础非常扎实的开发者才应该使用它。如果能把这句警示时刻放在心里，那么反射机制就会成为一项强大的技术，可以让应用程序做一些几乎不可能做到的事情。
springmvc ,servlet ;

17 反射机制缺点
（1）性能第一 Performance Overhead
反射包括了一些动态类型，所以 JVM 无法对这些代码进行优化。因此，反射操作的效率要比那些非反射操作低得多。我们应该避免在经常被 执行的代码或对性能要求很高的程序中使用反射。
（2）安全限制 Security Restrictions
使用反射技术要求程序必须在一个没有安全限制的环境中运行。如果一个程序必须在有安全限制的环境中运行，如 Applet，那么这就是个问题了。
（3）内部暴露 Exposure of Internals
由于反射允许代码执行一些在正常情况下不被允许的操作（比如访问私有的属性和方法），所以使用反射可能会导致意料之外的副作用－－代码有功能上的错误，降低可移植性。反射代码破坏了抽象性，因此当平台发生改变的时候，代码的行为就有可能也随着变化。

18 序列化的用途
（1）对象持久化（persistence）
　　对象持久化是指延长对象的存在时间。通常状况下，当程序结束时，程序中的对象不再存在。如果通过序列化功能，将对象保存到文件中，就可以延长对象的存在时间，在下次程序运行是再恢复该对象。序列化将对象保存在文件中，是实现对象持久化的一种方式。持久化还有很多种方式，比如Hibernate框架就提供了一整套对象持久化的方案。 
（2）对象复制
　　通过序列化，将对象保存在内存中，可以再通过此数据得到多个对象的副本。 
（3）对象传输
　　通过序列化，将对象转化字节流后，可以通过网络发送给另外的Java程序。




二、ms相关
1、面向对象的特征有哪些方面？
答：面向对象的特征主要有以下几个方面：
- 抽象：抽象是将一类对象的共同特征总结出来构造类的过程，包括数据抽象和行为抽象两方面。抽象只关注对象有哪些属性和行为，并不关注这些行为的细节是什么。
- 继承：继承是从已有类得到继承信息创建新类的过程。提供继承信息的类被称为父类（超类、基类）；得到继承信息的类被称为子类（派生类）。继承让变化中的软件系统有了一定的延续性，
同时继承也是封装程序中可变因素的重要手段（如果不能理解请阅读阎宏博士的《Java与模式》或《设计模式精解》中关于桥梁模式的部分）。
- 封装：通常认为封装是把数据和操作数据的方法绑定起来，对数据的访问只能通过已定义的接口。面向对象的本质就是将现实世界描绘成一系列完全自治、封闭的对象。我们在类中编写的
方法就是对实现细节的一种封装；我们编写一个类就是对数据和数据操作的封装。可以说，封装就是隐藏一切可隐藏的东西，只向外界提供最简单的编程接口（可以想想普通洗衣机和全自动
洗衣机的差别，明显全自动洗衣机封装更好因此操作起来更简单；我们现在使用的智能手机也是封装得足够好的，因为几个按键就搞定了所有的事情）。
- 多态性：多态性是指允许不同子类型的对象对同一消息作出不同的响应。简单的说就是用同样的对象引用调用同样的方法但是做了不同的事情。多态性分为编译时的多态性和运行时的多态性
。如果将对象的方法视为对象向外界提供的服务，那么运行时的多态性可以解释为：当A系统访问B系统提供的服务时，B系统有多种提供服务的方式，但一切对A系统来说都是透明的（就像电
动剃须刀是A系统，它的供电系统是B系统，B系统可以使用电池供电或者用交流电，甚至还有可能是太阳能，A系统只会通过B类对象调用供电的方法，但并不知道供电系统的底层实现是什么，
究竟通过何种方式获得了动力）。方法重载（overload）实现的是编译时的多态性（也称为前绑定），而方法重写（override）实现的是运行时的多态性（也称为后绑定）。运行时的多态是
面向对象最精髓的东西，要实现多态需要做两件事：1). 方法重写（子类继承父类并重写父类中已有的或抽象的方法）；2). 对象造型（用父类型引用引用子类型对象，这样同样的引用调用同样的方法就会根据子类对象的不同而表现出不同的行为）。

2、访问修饰符public,private,protected,以及不写（默认）时的区别？
答：
修饰符	当前类	同 包	子 类	其他包
public	√	√	√	√
protected	√	√	√	×
default	√	√	×	×
private	√	×	×	×
类的成员不写访问修饰时默认为default。默认对于同一个包中的其他类相当于公开（public），对于不是同一个包中的其他类相当于私有（private）。受保护（protected）对子类相当于公开，对不是同一包中的没有父子关系的类相当于私有。Java中，外部类的修饰符只能是public或默认，类的成员（包括内部类）的修饰符可以是以上四种。

3、String 是最基本的数据类型吗？
答：不是。Java中的基本数据类型只有8个：byte、short、int、long、float、double、char、boolean；除了基本类型（primitive type）和枚举类型（enumeration type），剩下的都是引用类型（reference type）。

4、float f=3.4;是否正确？
答:不正确。3.4是双精度数，将双精度型（double）赋值给浮点型（float）属于下转型（down-casting，也称为窄化）会造成精度损失，因此需要强制类型转换float f =(float)3.4; 或者写成float f =3.4F;。

5、short s1 = 1; s1 = s1 + 1;有错吗?short s1 = 1; s1 += 1;有错吗？
答：对于short s1 = 1; s1 = s1 + 1;由于1是int类型，因此s1+1运算结果也是int 型，需要强制转换类型才能赋值给short型。而short s1 = 1; s1 += 1;可以正确编译，因为s1+= 1;相当于s1 = (short)(s1 + 1);其中有隐含的强制类型转换。

6、Java有没有goto？
答：goto 是Java中的保留字，在目前版本的Java中没有使用。（根据James Gosling（Java之父）编写的《The Java Programming Language》一书的附录中给出了一个Java关键字列表，其中有goto和const，但是这两个是目前无法使用的关键字，因此有些地方将其称之为保留字，其实保留字这个词应该有更广泛的意义，因为熟悉C语言的程序员都知道，在系统类库中使用过的有特殊意义的单词或单词的组合都被视为保留字）

7、int和Integer有什么区别？
答：Java是一个近乎纯洁的面向对象编程语言，但是为了编程的方便还是引入了基本数据类型，但是为了能够将这些基本数据类型当成对象操作，Java为每一个基本数据类型都引入了对应的包装类型（wrapper class），int的包装类就是Integer，从Java 5开始引入了自动装箱/拆箱机制，使得二者可以相互转换。
Java 为每个原始类型提供了包装类型：
- 原始类型: boolean，char，byte，short，int，long，float，double
- 包装类型：Boolean，Character，Byte，Short，Integer，Long，Float，Double

    <span style="color:#333333;">class AutoUnboxingTest {  
        public static void main(String[] args) {  
            Integer a = new Integer(3);  
            Integer b = 3;                  // 将3自动装箱成Integer类型  
            int c = 3;  
            System.out.println(a == b);     // false 两个引用没有引用同一对象  
            System.out.println(a == c);     // true a自动拆箱成int类型再和c比较  
        }  
    }  
    </span>  

最近还遇到一个面试题，也是和自动装箱和拆箱有点关系的，代码如下所示：

public class Test03 {

    public static void main(String[] args) {
        Integer f1 = 100, f2 = 100, f3 = 150, f4 = 150;

        System.out.println(f1 == f2);
        System.out.println(f3 == f4);
    }
}

如果不明就里很容易认为两个输出要么都是true要么都是false。首先需要注意的是f1、f2、f3、f4四个变量都是Integer对象引用，所以下面的==运算比较的不是值而是引用。装箱的本质是什么呢？当我们给一个Integer对象赋一个int值的时候，会调用Integer类的静态方法valueOf，如果看看valueOf的源代码就知道发生了什么。

  public static Integer valueOf(int i) {
        if (i >= IntegerCache.low && i <= IntegerCache.high)
            return IntegerCache.cache[i + (-IntegerCache.low)];
        return new Integer(i);
    }

IntegerCache是Integer的内部类，其代码如下所示：
 private static class IntegerCache {
        static final int low = -128;
        static final int high;
        static final Integer cache[];

        static {
            // high value may be configured by property
            int h = 127;
            String integerCacheHighPropValue =
                sun.misc.VM.getSavedProperty("java.lang.Integer.IntegerCache.high");
            if (integerCacheHighPropValue != null) {
                try {
                    int i = parseInt(integerCacheHighPropValue);
                    i = Math.max(i, 127);
                    // Maximum array size is Integer.MAX_VALUE
                    h = Math.min(i, Integer.MAX_VALUE - (-low) -1);
                } catch( NumberFormatException nfe) {
                    // If the property cannot be parsed into an int, ignore it.
                }
            }
            high = h;

            cache = new Integer[(high - low) + 1];
            int j = low;
            for(int k = 0; k < cache.length; k++)
                cache[k] = new Integer(j++);

            // range [-128, 127] must be interned (JLS7 5.1.7)
            assert IntegerCache.high >= 127;
        }
        private IntegerCache() {}
    }

简单的说，如果整型字面量的值在-128到127之间，那么不会new新的Integer对象，而是直接引用常量池中的Integer对象，所以上面的面试题中f1==f2的结果是true，而f3==f4的结果是false。
提醒：越是貌似简单的面试题其中的玄机就越多，需要面试者有相当深厚的功力。

8、&和&&的区别？
答：&运算符有两种用法：(1)按位与；(2)逻辑与。&&运算符是短路与运算。逻辑与跟短路与的差别是非常巨大的，虽然二者都要求运算符左右两端的布尔值都是true整个表达式的值才是true。&&之所以称为短路运算是因为，如果&&左边的表达式的值是false，右边的表达式会被直接短路掉，不会进行运算。很多时候我们可能都需要用&&而不是&，例如在验证用户登录时判定用户名不是null而且不是空字符串，应当写为：username != null &&!username.equals("")，二者的顺序不能交换，更不能用&运算符，因为第一个条件如果不成立，根本不能进行字符串的equals比较，否则会产生NullPointerException异常。注意：逻辑或运算符（|）和短路或运算符（||）的差别也是如此。
补充：如果你熟悉JavaScript，那你可能更能感受到短路运算的强大，想成为JavaScript的高手就先从玩转短路运算开始吧。

9、解释内存中的栈(stack)、堆(heap)和静态区(static area)的用法。
答：通常我们定义一个基本数据类型的变量，一个对象的引用，还有就是函数调用的现场保存都使用内存中的栈空间；而通过new关键字和构造器创建的对象放在堆空间；程序中的字面量（literal）如直接书写的100、"hello"和常量都是放在静态区中。栈空间操作起来最快但是栈很小，通常大量的对象都是放在堆空间，理论上整个内存没有被其他进程使用的空间甚至硬盘上的虚拟内存都可以被当成堆空间来使用。

String str = new String("hello");

上面的语句中变量str放在栈上，用new创建出来的字符串对象放在堆上，而"hello"这个字面量放在静态区。
补充：较新版本的Java（从Java 6的某个更新开始）中使用了一项叫"逃逸分析"的技术，可以将一些局部对象放在栈上以提升对象的操作性能。

10、Math.round(11.5) 等于多少？Math.round(-11.5)等于多少？
答：Math.round(11.5)的返回值是12，Math.round(-11.5)的返回值是-11。四舍五入的原理是在参数上加0.5然后进行下取整。

11、swtich 是否能作用在byte 上，是否能作用在long 上，是否能作用在String上？
答：在Java 5以前，switch(expr)中，expr只能是byte、short、char、int。从Java 5开始，Java中引入了枚举类型，expr也可以是enum类型，从Java 7开始，expr还可以是字符串（String），但是长整型（long）在目前所有的版本中都是不可以的。

12、用最有效率的方法计算2乘以8？
答： 2 << 3（左移3位相当于乘以2的3次方，右移3位相当于除以2的3次方）。

    补充：我们为编写的类重写hashCode方法时，可能会看到如下所示的代码，其实我们不太理解为什么要使用这样的乘法运算来产生哈希码（散列码），而且为什么这个数是个素数，为什么通常选择31这个数？前两个问题的答案你可以自己百度一下，选择31是因为可以用移位和减法运算来代替乘法，从而得到更好的性能。说到这里你可能已经想到了：31 * num 等价于(num << 5) - num，左移5位相当于乘以2的5次方再减去自身就相当于乘以31，现在的VM都能自动完成这个优化。

public class PhoneNumber {
    private int areaCode;
    private String prefix;
    private String lineNumber;

    @Override
    public int hashCode() {
        final int prime = 31;
        int result = 1;
        result = prime * result + areaCode;
        result = prime * result
                + ((lineNumber == null) ? 0 : lineNumber.hashCode());
        result = prime * result + ((prefix == null) ? 0 : prefix.hashCode());
        return result;
    }

    @Override
    public boolean equals(Object obj) {
        if (this == obj)
            return true;
        if (obj == null)
            return false;
        if (getClass() != obj.getClass())
            return false;
        PhoneNumber other = (PhoneNumber) obj;
        if (areaCode != other.areaCode)
            return false;
        if (lineNumber == null) {
            if (other.lineNumber != null)
                return false;
        } else if (!lineNumber.equals(other.lineNumber))
            return false;
        if (prefix == null) {
            if (other.prefix != null)
                return false;
        } else if (!prefix.equals(other.prefix))
            return false;
        return true;
    }

}

13、数组有没有length()方法？String有没有length()方法？
答：数组没有length()方法，有length 的属性。String 有length()方法。JavaScript中，获得字符串的长度是通过length属性得到的，这一点容易和Java混淆。

14、在Java中，如何跳出当前的多重嵌套循环？
答：在最外层循环前加一个标记如A，然后用break A;可以跳出多重循环。（Java中支持带标签的break和continue语句，作用有点类似于C和C++中的goto语句，但是就像要避免使用goto一样，应该避免使用带标签的break和continue，因为它不会让你的程序变得更优雅，很多时候甚至有相反的作用，所以这种语法其实不知道更好）

15、构造器（constructor）是否可被重写（override）？
答：构造器不能被继承，因此不能被重写，但可以被重载。

16、两个对象值相同(x.equals(y) == true)，但却可有不同的hash code，这句话对不对？
答：不对，如果两个对象x和y满足x.equals(y) == true，它们的哈希码（hash code）应当相同。Java对于eqauls方法和hashCode方法是这样规定的：(1)如果两个对象相同（equals方法返回true），那么它们的hashCode值一定要相同；(2)如果两个对象的hashCode相同，它们并不一定相同。当然，你未必要按照要求去做，但是如果你违背了上述原则就会发现在使用容器时，相同的对象可以出现在Set集合中，同时增加新元素的效率会大大下降（对于使用哈希存储的系统，如果哈希码频繁的冲突将会造成存取性能急剧下降）。
 补充：关于equals和hashCode方法，很多Java程序都知道，但很多人也就是仅仅知道而已，在Joshua Bloch的大作《Effective Java》（很多软件公司，《Effective Java》、《Java编程思想》以及《重构：改善既有代码质量》是Java程序员必看书籍，如果你还没看过，那就赶紧去亚马逊买一本吧）中是这样介绍equals方法的：首先equals方法必须满足自反性（x.equals(x)必须返回true）、对称性（x.equals(y)返回true时，y.equals(x)也必须返回true）、传递性（x.equals(y)和y.equals(z)都返回true时，x.equals(z)也必须返回true）和一致性（当x和y引用的对象信息没有被修改时，多次调用x.equals(y)应该得到同样的返回值），而且对于任何非null值的引用x，x.equals(null)必须返回false。实现高质量的equals方法的诀窍包括：1. 使用==操作符检查"参数是否为这个对象的引用"；2. 使用instanceof操作符检查"参数是否为正确的类型"；3. 对于类中的关键属性，检查参数传入对象的属性是否与之相匹配；4. 编写完equals方法后，问自己它是否满足对称性、传递性、一致性；5. 重写equals时总是要重写hashCode；6. 不要将equals方法参数中的Object对象替换为其他的类型，在重写时不要忘掉@Override注解。

17、是否可以继承String类？
答：String 类是final类，不可以被继承。
补充：继承String本身就是一个错误的行为，对String类型最好的重用方式是关联关系（Has-A）和依赖关系（Use-A）而不是继承关系（Is-A）。

18、当一个对象被当作参数传递到一个方法后，此方法可改变这个对象的属性，并可返回变化后的结果，那么这里到底是值传递还是引用传递？
答：是值传递。Java语言的方法调用只支持参数的值传递。当一个对象实例作为一个参数被传递到方法中时，参数的值就是对该对象的引用。对象的属性可以在被调用过程中被改变，但对对象引用的改变是不会影响到调用者的。C++和C#中可以通过传引用或传输出参数来改变传入的参数的值。在C#中可以编写如下所示的代码，但是在Java中却做不到。
using System;
namespace CS01 {
    class Program {
        public static void swap(ref int x, ref int y) {
            int temp = x;
            x = y;
            y = temp;
        }

        public static void Main (string[] args) {
            int a = 5, b = 10;
            swap (ref a, ref b);
            // a = 10, b = 5;
            Console.WriteLine ("a = {0}, b = {1}", a, b);
        }
    }
}

    说明：Java中没有传引用实在是非常的不方便，这一点在Java 8中仍然没有得到改进，正是如此在Java编写的代码中才会出现大量的Wrapper类（将需要通过方法调用修改的引用置于一个Wrapper类中，再将Wrapper对象传入方法），这样的做法只会让代码变得臃肿，尤其是让从C和C++转型为Java程序员的开发者无法容忍。

19、String和StringBuilder、StringBuffer的区别？
答：Java平台提供了两种类型的字符串：String和StringBuffer/StringBuilder，它们可以储存和操作字符串。其中String是只读字符串，也就意味着String引用的字符串内容是不能被改变的。而StringBuffer/StringBuilder类表示的字符串对象可以直接进行修改。StringBuilder是Java 5中引入的，它和StringBuffer的方法完全相同，区别在于它是在单线程环境下使用的，因为它的所有方面都没有被synchronized修饰，因此它的效率也比StringBuffer要高。

    面试题1 - 什么情况下用+运算符进行字符串连接比调用StringBuffer/StringBuilder对象的append方法连接字符串性能更好？

    面试题2 - 请说出下面程序的输出。

class StringEqualTest {

    public static void main(String[] args) {
        String s1 = "Programming";
        String s2 = new String("Programming");
        String s3 = "Program" + "ming";
        System.out.println(s1 == s2);
        System.out.println(s1 == s3);
        System.out.println(s1 == s1.intern());
    }
}

    补充：String对象的intern方法会得到字符串对象在常量池中对应的版本的引用（如果常量池中有一个字符串与String对象的equals结果是true），如果常量池中没有对应的字符串，则该字符串将被添加到常量池中，然后返回常量池中字符串的引用。

20、重载（Overload）和重写（Override）的区别。重载的方法能否根据返回类型进行区分？
答：方法的重载和重写都是实现多态的方式，区别在于前者实现的是编译时的多态性，而后者实现的是运行时的多态性。重载发生在一个类中，同名的方法如果有不同的参数列表（参数类型不同、参数个数不同或者二者都不同）则视为重载；重写发生在子类与父类之间，重写要求子类被重写方法与父类被重写方法有相同的返回类型，比父类被重写方法更好访问，不能比父类被重写方法声明更多的异常（里氏代换原则）。重载对返回类型没有特殊的要求。
面试题：华为的面试题中曾经问过这样一个问题 - "为什么不能根据返回类型来区分重载"，快说出你的答案吧！

21、描述一下JVM加载class文件的原理机制？
答：JVM中类的装载是由类加载器（ClassLoader）和它的子类来实现的，Java中的类加载器是一个重要的Java运行时系统组件，它负责在运行时查找和装入类文件中的类。
由于Java的跨平台性，经过编译的Java源程序并不是一个可执行程序，而是一个或多个类文件。当Java程序需要使用某个类时，JVM会确保这个类已经被加载、连接（验证、准备和解析）和初始化。类的加载是指把类的.class文件中的数据读入到内存中，通常是创建一个字节数组读入.class文件，然后产生与所加载类对应的Class对象。加载完成后，Class对象还不完整，所以此时的类还不可用。当类被加载后就进入连接阶段，这一阶段包括验证、准备（为静态变量分配内存并设置默认的初始值）和解析（将符号引用替换为直接引用）三个步骤。最后JVM对类进行初始化，包括：1)如果类存在直接的父类并且这个类还没有被初始化，那么就先初始化父类；2)如果类中存在初始化语句，就依次执行这些初始化语句。
类的加载是由类加载器完成的，类加载器包括：根加载器（BootStrap）、扩展加载器（Extension）、系统加载器（System）和用户自定义类加载器（java.lang.ClassLoader的子类）。从Java 2（JDK 1.2）开始，类加载过程采取了父亲委托机制（PDM）。PDM更好的保证了Java平台的安全性，在该机制中，JVM自带的Bootstrap是根加载器，其他的加载器都有且仅有一个父类加载器。类的加载首先请求父类加载器加载，父类加载器无能为力时才由其子类加载器自行加载。JVM不会向Java程序提供对Bootstrap的引用。下面是关于几个类加载器的说明：

        Bootstrap：一般用本地代码实现，负责加载JVM基础核心类库（rt.jar）；
        Extension：从java.ext.dirs系统属性所指定的目录中加载类库，它的父加载器是Bootstrap；
        System：又叫应用类加载器，其父类是Extension。它是应用最广泛的类加载器。它从环境变量classpath或者系统属性java.class.path所指定的目录中记载类，是用户自定义加载器的默认父加载器。

22、char 型变量中能不能存贮一个中文汉字，为什么？
答：char类型可以存储一个中文汉字，因为Java中使用的编码是Unicode（不选择任何特定的编码，直接使用字符在字符集中的编号，这是统一的唯一方法），一个char类型占2个字节（16比特），所以放一个中文是没问题的。

    补充：使用Unicode意味着字符在JVM内部和外部有不同的表现形式，在JVM内部都是Unicode，当这个字符被从JVM内部转移到外部时（例如存入文件系统中），需要进行编码转换。所以Java中有字节流和字符流，以及在字符流和字节流之间进行转换的转换流，如InputStreamReader和OutputStreamReader，这两个类是字节流和字符流之间的适配器类，承担了编码转换的任务；对于C程序员来说，要完成这样的编码转换恐怕要依赖于union（联合体/共用体）共享内存的特征来实现了。

23、抽象类（abstract class）和接口（interface）有什么异同？
答：抽象类和接口都不能够实例化，但可以定义抽象类和接口类型的引用。一个类如果继承了某个抽象类或者实现了某个接口都需要对其中的抽象方法全部进行实现，否则该类仍然需要被声明为抽象类。接口比抽象类更加抽象，因为抽象类中可以定义构造器，可以有抽象方法和具体方法，而接口中不能定义构造器而且其中的方法全部都是抽象方法。抽象类中的成员可以是private、默认、protected、public的，而接口中的成员全都是public的。抽象类中可以定义成员变量，而接口中定义的成员变量实际上都是常量。有抽象方法的类必须被声明为抽象类，而抽象类未必要有抽象方法。

24、静态嵌套类(Static Nested Class)和内部类（Inner Class）的不同？
答：Static Nested Class是被声明为静态（static）的内部类，它可以不依赖于外部类实例被实例化。而通常的内部类需要在外部类实例化后才能实例化，其语法看起来挺诡异的，如下所示。

/**
 * 扑克类（一副扑克）
 * @author 骆昊
 *
 */
public class Poker {
    private static String[] suites = {"黑桃", "红桃", "草花", "方块"};
    private static int[] faces = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13};

    private Card[] cards;

    /**
     * 构造器
     * 
     */
    public Poker() {
        cards = new Card[52];
        for(int i = 0; i < suites.length; i++) {
            for(int j = 0; j < faces.length; j++) {
                cards[i * 13 + j] = new Card(suites[i], faces[j]);
            }
        }
    }

    /**
     * 洗牌 （随机乱序）
     * 
     */
    public void shuffle() {
        for(int i = 0, len = cards.length; i < len; i++) {
            int index = (int) (Math.random() * len);
            Card temp = cards[index];
            cards[index] = cards[i];
            cards[i] = temp;
        }
    }

    /**
     * 发牌
     * @param index 发牌的位置
     * 
     */
    public Card deal(int index) {
        return cards[index];
    }

    /**
     * 卡片类（一张扑克）
     * [内部类]
     * @author 骆昊
     *
     */
    public class Card {
        private String suite;   // 花色
        private int face;       // 点数

        public Card(String suite, int face) {
            this.suite = suite;
            this.face = face;
        }

        @Override
        public String toString() {
            String faceStr = "";
            switch(face) {
            case 1: faceStr = "A"; break;
            case 11: faceStr = "J"; break;
            case 12: faceStr = "Q"; break;
            case 13: faceStr = "K"; break;
            default: faceStr = String.valueOf(face);
            }
            return suite + faceStr;
        }
    }
}

测试代码：

class PokerTest {

    public static void main(String[] args) {
        Poker poker = new Poker();
        poker.shuffle();                // 洗牌
        Poker.Card c1 = poker.deal(0);  // 发第一张牌
        // 对于非静态内部类Card
        // 只有通过其外部类Poker对象才能创建Card对象
        Poker.Card c2 = poker.new Card("红心", 1);    // 自己创建一张牌

        System.out.println(c1);     // 洗牌后的第一张
        System.out.println(c2);     // 打印: 红心A
    }
}

    面试题 - 下面的代码哪些地方会产生编译错误？

class Outer {

    class Inner {}

    public static void foo() { new Inner(); }

    public void bar() { new Inner(); }

    public static void main(String[] args) {
        new Inner();
    }
}

    注意：Java中非静态内部类对象的创建要依赖其外部类对象，上面的面试题中foo和main方法都是静态方法，静态方法中没有this，也就是说没有所谓的外部类对象，因此无法创建内部类对象，如果要在静态方法中创建内部类对象，可以这样做：

            new Outer().new Inner();

25、Java 中会存在内存泄漏吗，请简单描述。
答：理论上Java因为有垃圾回收机制（GC）不会存在内存泄露问题（这也是Java被广泛使用于服务器端编程的一个重要原因）；然而在实际开发中，可能会存在无用但可达的对象，这些对象不能被GC回收，因此也会导致内存泄露的发生。例如Hibernate的Session（一级缓存）中的对象属于持久态，垃圾回收器是不会回收这些对象的，然而这些对象中可能存在无用的垃圾对象，如果不及时关闭（close）或清空（flush）一级缓存就可能导致内存泄露。下面例子中的代码也会导致内存泄露。

import java.util.Arrays;
import java.util.EmptyStackException;

public class MyStack<T> {
    private T[] elements;
    private int size = 0;

    private static final int INIT_CAPACITY = 16;

    public MyStack() {
        elements = (T[]) new Object[INIT_CAPACITY];
    }

    public void push(T elem) {
        ensureCapacity();
        elements[size++] = elem;
    }

    public T pop() {
        if(size == 0) 
            throw new EmptyStackException();
        return elements[--size];
    }

    private void ensureCapacity() {
        if(elements.length == size) {
            elements = Arrays.copyOf(elements, 2 * size + 1);
        }
    }
}

上面的代码实现了一个栈（先进后出（FILO））结构，乍看之下似乎没有什么明显的问题，它甚至可以通过你编写的各种单元测试。然而其中的pop方法却存在内存泄露的问题，当我们用pop方法弹出栈中的对象时，该对象不会被当作垃圾回收，即使使用栈的程序不再引用这些对象，因为栈内部维护着对这些对象的过期引用（obsolete reference）。在支持垃圾回收的语言中，内存泄露是很隐蔽的，这种内存泄露其实就是无意识的对象保持。如果一个对象引用被无意识的保留起来了，那么垃圾回收器不会处理这个对象，也不会处理该对象引用的其他对象，即使这样的对象只有少数几个，也可能会导致很多的对象被排除在垃圾回收之外，从而对性能造成重大影响，极端情况下会引发Disk Paging（物理内存与硬盘的虚拟内存交换数据），甚至造成OutOfMemoryError。

26、抽象的（abstract）方法是否可同时是静态的（static）,是否可同时是本地方法（native），是否可同时被synchronized修饰？
答：都不能。抽象方法需要子类重写，而静态的方法是无法被重写的，因此二者是矛盾的。本地方法是由本地代码（如C代码）实现的方法，而抽象方法是没有实现的，也是矛盾的。synchronized和方法的实现细节有关，抽象方法不涉及实现细节，因此也是相互矛盾的。

27、阐述静态变量和实例变量的区别。
答：静态变量是被static修饰符修饰的变量，也称为类变量，它属于类，不属于类的任何一个对象，一个类不管创建多少个对象，静态变量在内存中有且仅有一个拷贝；实例变量必须依存于某一实例，需要先创建对象然后通过对象才能访问到它。静态变量可以实现让多个对象共享内存。

    补充：在Java开发中，上下文类和工具类中通常会有大量的静态成员。

28、是否可以从一个静态（static）方法内部发出对非静态（non-static）方法的调用？
答：不可以，静态方法只能访问静态成员，因为非静态方法的调用要先创建对象，在调用静态方法时可能对象并没有被初始化。

29、如何实现对象克隆？
答：有两种方式：
??1). 实现Cloneable接口并重写Object类中的clone()方法；
??2). 实现Serializable接口，通过对象的序列化和反序列化实现克隆，可以实现真正的深度克隆，代码如下。

import java.io.ByteArrayInputStream;
import java.io.ByteArrayOutputStream;
import java.io.ObjectInputStream;
import java.io.ObjectOutputStream;

public class MyUtil {

    private MyUtil() {
        throw new AssertionError();
    }

    public static <T> T clone(T obj) throws Exception {
        ByteArrayOutputStream bout = new ByteArrayOutputStream();
        ObjectOutputStream oos = new ObjectOutputStream(bout);
        oos.writeObject(obj);

        ByteArrayInputStream bin = new ByteArrayInputStream(bout.toByteArray());
        ObjectInputStream ois = new ObjectInputStream(bin);
        return (T) ois.readObject();

        // 说明：调用ByteArrayInputStream或ByteArrayOutputStream对象的close方法没有任何意义
        // 这两个基于内存的流只要垃圾回收器清理对象就能够释放资源，这一点不同于对外部资源（如文件流）的释放
    }
}

下面是测试代码：

import java.io.Serializable;

/**
 * 人类
 * @author 骆昊
 *
 */
class Person implements Serializable {
    private static final long serialVersionUID = -9102017020286042305L;

    private String name;    // 姓名
    private int age;        // 年龄
    private Car car;        // 座驾

    public Person(String name, int age, Car car) {
        this.name = name;
        this.age = age;
        this.car = car;
    }

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public int getAge() {
        return age;
    }

    public void setAge(int age) {
        this.age = age;
    }

    public Car getCar() {
        return car;
    }

    public void setCar(Car car) {
        this.car = car;
    }

    @Override
    public String toString() {
        return "Person [name=" + name + ", age=" + age + ", car=" + car + "]";
    }

}



/**
 * 小汽车类
 * @author 骆昊
 *
 */
class Car implements Serializable {
    private static final long serialVersionUID = -5713945027627603702L;

    private String brand;       // 品牌
    private int maxSpeed;       // 最高时速

    public Car(String brand, int maxSpeed) {
        this.brand = brand;
        this.maxSpeed = maxSpeed;
    }

    public String getBrand() {
        return brand;
    }

    public void setBrand(String brand) {
        this.brand = brand;
    }

    public int getMaxSpeed() {
        return maxSpeed;
    }

    public void setMaxSpeed(int maxSpeed) {
        this.maxSpeed = maxSpeed;
    }

    @Override
    public String toString() {
        return "Car [brand=" + brand + ", maxSpeed=" + maxSpeed + "]";
    }

}




class CloneTest {    public static void main(String[] args) {        try {            Person p1 = new Person("Hao LUO", 33, new Car("Benz", 300));            Person p2 = MyUtil.clone(p1);   // 深度克隆            p2.getCar().setBrand("BYD");            // 修改克隆的Person对象p2关联的汽车对象的品牌属性            // 原来的Person对象p1关联的汽车不会受到任何影响            // 因为在克隆Person对象时其关联的汽车对象也被克隆了            System.out.println(p1);        } catch (Exception e) {            e.printStackTrace();        }    }}


    注意：基于序列化和反序列化实现的克隆不仅仅是深度克隆，更重要的是通过泛型限定，可以检查出要克隆的对象是否支持序列化，这项检查是编译器完成的，不是在运行时抛出异常，这种是方案明显优于使用Object类的clone方法克隆对象。让问题在编译的时候暴露出来总是优于把问题留到运行时。

30、GC是什么？为什么要有GC？
答：GC是垃圾收集的意思，内存处理是编程人员容易出现问题的地方，忘记或者错误的内存回收会导致程序或系统的不稳定甚至崩溃，Java提供的GC功能可以自动监测对象是否超过作用域从而达到自动回收内存的目的，Java语言没有提供释放已分配内存的显示操作方法。Java程序员不用担心内存管理，因为垃圾收集器会自动进行管理。要请求垃圾收集，可以调用下面的方法之一：System.gc() 或Runtime.getRuntime().gc() ，但JVM可以屏蔽掉显示的垃圾回收调用。
垃圾回收可以有效的防止内存泄露，有效的使用可以使用的内存。垃圾回收器通常是作为一个单独的低优先级的线程运行，不可预知的情况下对内存堆中已经死亡的或者长时间没有使用的对象进行清除和回收，程序员不能实时的调用垃圾回收器对某个对象或所有对象进行垃圾回收。在Java诞生初期，垃圾回收是Java最大的亮点之一，因为服务器端的编程需要有效的防止内存泄露问题，然而时过境迁，如今Java的垃圾回收机制已经成为被诟病的东西。移动智能终端用户通常觉得iOS的系统比Android系统有更好的用户体验，其中一个深层次的原因就在于Android系统中垃圾回收的不可预知性。

    补充：垃圾回收机制有很多种，包括：分代复制垃圾回收、标记垃圾回收、增量垃圾回收等方式。标准的Java进程既有栈又有堆。栈保存了原始型局部变量，堆保存了要创建的对象。Java平台对堆内存回收和再利用的基本算法被称为标记和清除，但是Java对其进行了改进，采用“分代式垃圾收集”。这种方法会跟Java对象的生命周期将堆内存划分为不同的区域，在垃圾收集过程中，可能会将对象移动到不同区域：
    - 伊甸园（Eden）：这是对象最初诞生的区域，并且对大多数对象来说，这里是它们唯一存在过的区域。
    - 幸存者乐园（Survivor）：从伊甸园幸存下来的对象会被挪到这里。
    - 终身颐养园（Tenured）：这是足够老的幸存对象的归宿。年轻代收集（Minor-GC）过程是不会触及这个地方的。当年轻代收集不能把对象放进终身颐养园时，就会触发一次完全收集（Major-GC），这里可能还会牵扯到压缩，以便为大对象腾出足够的空间。

与垃圾回收相关的JVM参数：

        -Xms / -Xmx — 堆的初始大小 / 堆的最大大小
        -Xmn — 堆中年轻代的大小
        -XX:-DisableExplicitGC — 让System.gc()不产生任何作用
        -XX:+PrintGCDetails — 打印GC的细节
        -XX:+PrintGCDateStamps — 打印GC操作的时间戳
        -XX:NewSize / XX:MaxNewSize — 设置新生代大小/新生代最大大小
        -XX:NewRatio — 可以设置老生代和新生代的比例
        -XX:PrintTenuringDistribution — 设置每次新生代GC后输出幸存者乐园中对象年龄的分布
        -XX:InitialTenuringThreshold / -XX:MaxTenuringThreshold：设置老年代阀值的初始值和最大值
        -XX:TargetSurvivorRatio：设置幸存区的目标使用率

31、String s = new String("xyz");创建了几个字符串对象？
答：两个对象，一个是静态区的"xyz"，一个是用new创建在堆上的对象。

32、接口是否可继承（extends）接口？抽象类是否可实现（implements）接口？抽象类是否可继承具体类（concrete class）？
答：接口可以继承接口，而且支持多重继承。抽象类可以实现(implements)接口，抽象类可继承具体类也可以继承抽象类。

33、一个".java"源文件中是否可以包含多个类（不是内部类）？有什么限制？
答：可以，但一个源文件中最多只能有一个公开类（public class）而且文件名必须和公开类的类名完全保持一致。

34、Anonymous Inner Class(匿名内部类)是否可以继承其它类？是否可以实现接口？
答：可以继承其他类或实现其他接口，在Swing编程和Android开发中常用此方式来实现事件监听和回调。

35、内部类可以引用它的包含类（外部类）的成员吗？有没有什么限制？
答：一个内部类对象可以访问创建它的外部类对象的成员，包括私有成员。

36、Java 中的final关键字有哪些用法？
答：(1)修饰类：表示该类不能被继承；(2)修饰方法：表示方法不能被重写；(3)修饰变量：表示变量只能一次赋值以后值不能被修改（常量）。

37、指出下面程序的运行结果。
class A {

    static {
        System.out.print("1");
    }

    public A() {
        System.out.print("2");
    }
}

class B extends A{

    static {
        System.out.print("a");
    }

    public B() {
        System.out.print("b");
    }
}

public class Hello {
    public static void main(String[] args) {
        A ab = new B();
        ab = new B();
    }
}

答：执行结果：1a2b2b。创建对象时构造器的调用顺序是：先初始化静态成员，然后调用父类构造器，再初始化非静态成员，最后调用自身构造器。
提示：如果不能给出此题的正确答案，说明之前第21题Java类加载机制还没有完全理解，赶紧再看看吧。

38、数据类型之间的转换：
- 如何将字符串转换为基本数据类型？
- 如何将基本数据类型转换为字符串？
答：
- 调用基本数据类型对应的包装类中的方法parseXXX(String)或valueOf(String)即可返回相应基本类型；
- 一种方法是将基本数据类型与空字符串（""）连接（+）即可获得其所对应的字符串；另一种方法是调用String 类中的valueOf()方法返回相应字符串

39、如何实现字符串的反转及替换？
答：方法很多，可以自己写实现也可以使用String或StringBuffer/StringBuilder中的方法。有一道很常见的面试题是用递归实现字符串反转，代码如下所示：
   public static String reverse(String originStr) {
        if(originStr == null || originStr.length() <= 1)
            return originStr;
        return reverse(originStr.substring(1)) + originStr.charAt(0);
    }

40、怎样将GB2312编码的字符串转换为ISO-8859-1编码的字符串？
答：代码如下所示：
String s1 = "你好";
String s2 = new String(s1.getBytes("GB2312"), "ISO-8859-1");

41、日期和时间：
- 如何取得年月日、小时分钟秒？
- 如何取得从1970年1月1日0时0分0秒到现在的毫秒数？
- 如何取得某月的最后一天？
- 如何格式化日期？
答：
问题1：创建java.util.Calendar 实例，调用其get()方法传入不同的参数即可获得参数所对应的值。Java 8中可以使用java.time.LocalDateTimel来获取，代码如下所示。

public class DateTimeTest {
    public static void main(String[] args) {
        Calendar cal = Calendar.getInstance();
        System.out.println(cal.get(Calendar.YEAR));
        System.out.println(cal.get(Calendar.MONTH));    // 0 - 11
        System.out.println(cal.get(Calendar.DATE));
        System.out.println(cal.get(Calendar.HOUR_OF_DAY));
        System.out.println(cal.get(Calendar.MINUTE));
        System.out.println(cal.get(Calendar.SECOND));

        // Java 8
        LocalDateTime dt = LocalDateTime.now();
        System.out.println(dt.getYear());
        System.out.println(dt.getMonthValue());     // 1 - 12
        System.out.println(dt.getDayOfMonth());
        System.out.println(dt.getHour());
        System.out.println(dt.getMinute());
        System.out.println(dt.getSecond());
    }
}

问题2：以下方法均可获得该毫秒数。

Calendar.getInstance().getTimeInMillis();
System.currentTimeMillis();
Clock.systemDefaultZone().millis(); // Java 8

问题3：代码如下所示。

Calendar time = Calendar.getInstance();
time.getActualMaximum(Calendar.DAY_OF_MONTH);

问题4：利用java.text.DataFormat 的子类（如SimpleDateFormat类）中的format(Date)方法可将日期格式化。Java 8中可以用java.time.format.DateTimeFormatter来格式化时间日期，代码如下所示。

import java.text.SimpleDateFormat;
import java.time.LocalDate;
import java.time.format.DateTimeFormatter;
import java.util.Date;

class DateFormatTest {

    public static void main(String[] args) {
        SimpleDateFormat oldFormatter = new SimpleDateFormat("yyyy/MM/dd");
        Date date1 = new Date();
        System.out.println(oldFormatter.format(date1));

        // Java 8
        DateTimeFormatter newFormatter = DateTimeFormatter.ofPattern("yyyy/MM/dd");
        LocalDate date2 = LocalDate.now();
        System.out.println(date2.format(newFormatter));
    }
}
 补充：Java的时间日期API一直以来都是被诟病的东西，为了解决这一问题，Java 8中引入了新的时间日期API，其中包括LocalDate、LocalTime、LocalDateTime、Clock、Instant等类，这些的类的设计都使用了不变模式，因此是线程安全的设计。

42、打印昨天的当前时刻。
答：
import java.util.Calendar;
class YesterdayCurrent {
    public static void main(String[] args){
        Calendar cal = Calendar.getInstance();
        cal.add(Calendar.DATE, -1);
        System.out.println(cal.getTime());
    }
}

在Java 8中，可以用下面的代码实现相同的功能。
import java.time.LocalDateTime;
class YesterdayCurrent {
    public static void main(String[] args) {
        LocalDateTime today = LocalDateTime.now();
        LocalDateTime yesterday = today.minusDays(1);
        System.out.println(yesterday);
    }
}

43、比较一下Java和JavaSciprt。
答：JavaScript 与Java是两个公司开发的不同的两个产品。Java 是原Sun Microsystems公司推出的面向对象的程序设计语言，特别适合于互联网应用程序开发；而JavaScript是Netscape公司的产品，为了扩展Netscape浏览器的功能而开发的一种可以嵌入Web页面中运行的基于对象和事件驱动的解释性语言。JavaScript的前身是LiveScript；而Java的前身是Oak语言。
下面对两种语言间的异同作如下比较：
- 基于对象和面向对象：Java是一种真正的面向对象的语言，即使是开发简单的程序，必须设计对象；JavaScript是种脚本语言，它可以用来制作与网络无关的，与用户交互作用的复杂软件。它是一种基于对象（Object-Based）和事件驱动（Event-Driven）的编程语言，因而它本身提供了非常丰富的内部对象供设计人员使用。
- 解释和编译：Java的源代码在执行之前，必须经过编译。JavaScript是一种解释性编程语言，其源代码不需经过编译，由浏览器解释执行。（目前的浏览器几乎都使用了JIT（即时编译）技术来提升JavaScript的运行效率）
- 强类型变量和类型弱变量：Java采用强类型变量检查，即所有变量在编译之前必须作声明；JavaScript中变量是弱类型的，甚至在使用变量前可以不作声明，JavaScript的解释器在运行时检查推断其数据类型。
- 代码格式不一样。
补充：上面列出的四点是网上流传的所谓的标准答案。其实Java和JavaScript最重要的区别是一个是静态语言，一个是动态语言。目前的编程语言的发展趋势是函数式语言和动态语言。在Java中类（class）是一等公民，而JavaScript中函数（function）是一等公民，因此JavaScript支持函数式编程，可以使用Lambda函数和闭包（closure），当然Java 8也开始支持函数式编程，提供了对Lambda表达式以及函数式接口的支持。对于这类问题，在面试的时候最好还是用自己的语言回答会更加靠谱，不要背网上所谓的标准答案。

44、什么时候用断言（assert）？
答：断言在软件开发中是一种常用的调试方式，很多开发语言中都支持这种机制。一般来说，断言用于保证程序最基本、关键的正确性。断言检查通常在开发和测试时开启。为了保证程序的执行效率，在软件发布后断言检查通常是关闭的。断言是一个包含布尔表达式的语句，在执行这个语句时假定该表达式为true；如果表达式的值为false，那么系统会报告一个AssertionError。断言的使用如下面的代码所示：
assert(a > 0); // throws an AssertionError if a <= 0
断言可以有两种形式：
assert Expression1;
assert Expression1 : Expression2 ;
Expression1 应该总是产生一个布尔值。
Expression2 可以是得出一个值的任意表达式；这个值用于生成显示更多调试信息的字符串消息。
要在运行时启用断言，可以在启动JVM时使用-enableassertions或者-ea标记。要在运行时选择禁用断言，可以在启动JVM时使用-da或者-disableassertions标记。要在系统类中启用或禁用断言，可使用-esa或-dsa标记。还可以在包的基础上启用或者禁用断言。
注意：断言不应该以任何方式改变程序的状态。简单的说，如果希望在不满足某些条件时阻止代码的执行，就可以考虑用断言来阻止它。

45、Error和Exception有什么区别？
答：Error表示系统级的错误和程序不必处理的异常，是恢复不是不可能但很困难的情况下的一种严重问题；比如内存溢出，不可能指望程序能处理这样的情况；Exception表示需要捕捉或者需要程序进行处理的异常，是一种设计或实现问题；也就是说，它表示如果程序运行正常，从不会发生的情况。

    面试题：2005年摩托罗拉的面试中曾经问过这么一个问题“If a process reports a stack overflow run-time error, what’s the most possible cause?”，给了四个选项a. lack of memory; b. write on an invalid memory space; c. recursive function calling; d. array index out of boundary. Java程序在运行时也可能会遭遇StackOverflowError，这是一个无法恢复的错误，只能重新修改代码了，这个面试题的答案是c。如果写了不能迅速收敛的递归，则很有可能引发栈溢出的错误，如下所示：
class StackOverflowErrorTest {
    public static void main(String[] args) {
        main(null);
    }
}
提示：用递归编写程序时一定要牢记两点：1. 递归公式；2. 收敛条件（什么时候就不再继续递归）。

46、try{}里有一个return语句，那么紧跟在这个try后的finally{}里的代码会不会被执行，什么时候被执行，在return前还是后?
答：会执行，在方法返回调用者前执行。
注意：在finally中改变返回值的做法是不好的，因为如果存在finally代码块，try中的return语句不会立马返回调用者，而是记录下返回值待finally代码块执行完毕之后再向调用者返回其值，然后如果在finally中修改了返回值，就会返回修改后的值。显然，在finally中返回或者修改返回值会对程序造成很大的困扰，C#中直接用编译错误的方式来阻止程序员干这种龌龊的事情，Java中也可以通过提升编译器的语法检查级别来产生警告或错误，Eclipse中可以在如图所示的地方进行设置，强烈建议将此项设置为编译错误。

47、Java语言如何进行异常处理，关键字：throws、throw、try、catch、finally分别如何使用？
答：Java通过面向对象的方法进行异常处理，把各种不同的异常进行分类，并提供了良好的接口。在Java中，每个异常都是一个对象，它是Throwable类或其子类的实例。当一个方法出现异常后便抛出一个异常对象，该对象中包含有异常信息，调用这个对象的方法可以捕获到这个异常并可以对其进行处理。Java的异常处理是通过5个关键词来实现的：try、catch、throw、throws和finally。一般情况下是用try来执行一段程序，如果系统会抛出（throw）一个异常对象，可以通过它的类型来捕获（catch）它，或通过总是执行代码块（finally）来处理；try用来指定一块预防所有异常的程序；catch子句紧跟在try块后面，用来指定你想要捕获的异常的类型；throw语句用来明确地抛出一个异常；throws用来声明一个方法可能抛出的各种异常（当然声明异常时允许无病呻吟）；finally为确保一段代码不管发生什么异常状况都要被执行；try语句可以嵌套，每当遇到一个try语句，异常的结构就会被放入异常栈中，直到所有的try语句都完成。如果下一级的try语句没有对某种异常进行处理，异常栈就会执行出栈操作，直到遇到有处理这种异常的try语句或者最终将异常抛给JVM。

48、运行时异常与受检异常有何异同？
答：异常表示程序运行过程中可能出现的非正常状态，运行时异常表示虚拟机的通常操作中可能遇到的异常，是一种常见运行错误，只要程序设计得没有问题通常就不会发生。受检异常跟程序运行的上下文环境有关，即使程序设计无误，仍然可能因使用的问题而引发。Java编译器要求方法必须声明抛出可能发生的受检异常，但是并不要求必须声明抛出未被捕获的运行时异常。异常和继承一样，是面向对象程序设计中经常被滥用的东西，在Effective Java中对异常的使用给出了以下指导原则：
- 不要将异常处理用于正常的控制流（设计良好的API不应该强迫它的调用者为了正常的控制流而使用异常）
- 对可以恢复的情况使用受检异常，对编程错误使用运行时异常
- 避免不必要的使用受检异常（可以通过一些状态检测手段来避免异常的发生）
- 优先使用标准的异常
- 每个方法抛出的异常都要有文档
- 保持异常的原子性
- 不要在catch中忽略掉捕获到的异常

49、列出一些你常见的运行时异常？
答：
- ArithmeticException（算术异常）
- ClassCastException （类转换异常）
- IllegalArgumentException （非法参数异常）
- IndexOutOfBoundsException （下标越界异常）
- NullPointerException （空指针异常）
- SecurityException （安全异常）

50、阐述final、finally、finalize的区别。
答：
- final：修饰符（关键字）有三种用法：如果一个类被声明为final，意味着它不能再派生出新的子类，即不能被继承，因此它和abstract是反义词。将变量声明为final，可以保证它们在使用中不被改变，被声明为final的变量必须在声明时给定初值，而在以后的引用中只能读取不可修改。被声明为final的方法也同样只能使用，不能在子类中被重写。
- finally：通常放在try…catch…的后面构造总是执行代码块，这就意味着程序无论正常执行还是发生异常，这里的代码只要JVM不关闭都能执行，可以将释放外部资源的代码写在finally块中。
- finalize：Object类中定义的方法，Java中允许使用finalize()方法在垃圾收集器将对象从内存中清除出去之前做必要的清理工作。这个方法是由垃圾收集器在销毁对象时调用的，通过重写finalize()方法可以整理系统资源或者执行其他清理工作。

51、类ExampleA继承Exception，类ExampleB继承ExampleA。
有如下代码片断：
try {
    throw new ExampleB("b")
} catch（ExampleA e）{
    System.out.println("ExampleA");
} catch（Exception e）{
    System.out.println("Exception");
}

请问执行此段代码的输出是什么？
答：输出：ExampleA。（根据里氏代换原则[能使用父类型的地方一定能使用子类型]，抓取ExampleA类型异常的catch块能够抓住try块中抛出的ExampleB类型的异常）

面试题 - 说出下面代码的运行结果。（此题的出处是《Java编程思想》一书）

class Annoyance extends Exception {}
class Sneeze extends Annoyance {}
class Human {
    public static void main(String[] args) 
        throws Exception {
        try {
            try {
                throw new Sneeze();
            } 
            catch ( Annoyance a ) {
                System.out.println("Caught Annoyance");
                throw a;
            }
        } 
        catch ( Sneeze s ) {
            System.out.println("Caught Sneeze");
            return ;
        }
        finally {
            System.out.println("Hello World!");
        }
    }
}

52、List、Set、Map是否继承自Collection接口？
答：List、Set 是，Map 不是。Map是键值对映射容器，与List和Set有明显的区别，而Set存储的零散的元素且不允许有重复元素（数学中的集合也是如此），List是线性结构的容器，适用于按数值索引访问元素的情形。

53、阐述ArrayList、Vector、LinkedList的存储性能和特性。
答：ArrayList 和Vector都是使用数组方式存储数据，此数组元素数大于实际存储的数据以便增加和插入元素，它们都允许直接按序号索引元素，但是插入元素要涉及数组元素移动等内存操作，所以索引数据快而插入数据慢，Vector中的方法由于添加了synchronized修饰，因此Vector是线程安全的容器，但性能上较ArrayList差，因此已经是Java中的遗留容器。LinkedList使用双向链表实现存储（将内存中零散的内存单元通过附加的引用关联起来，形成一个可以按序号索引的线性结构，这种链式存储方式与数组的连续存储方式相比，内存的利用率更高），按序号索引数据需要进行前向或后向遍历，但是插入数据时只需要记录本项的前后项即可，所以插入速度较快。Vector属于遗留容器（Java早期的版本中提供的容器，除此之外，Hashtable、Dictionary、BitSet、Stack、Properties都是遗留容器），已经不推荐使用，但是由于ArrayList和LinkedListed都是非线程安全的，如果遇到多个线程操作同一个容器的场景，则可以通过工具类Collections中的synchronizedList方法将其转换成线程安全的容器后再使用（这是对装潢模式的应用，将已有对象传入另一个类的构造器中创建新的对象来增强实现）。
补充：遗留容器中的Properties类和Stack类在设计上有严重的问题，Properties是一个键和值都是字符串的特殊的键值对映射，在设计上应该是关联一个Hashtable并将其两个泛型参数设置为String类型，但是Java API中的Properties直接继承了Hashtable，这很明显是对继承的滥用。这里复用代码的方式应该是Has-A关系而不是Is-A关系，另一方面容器都属于工具类，继承工具类本身就是一个错误的做法，使用工具类最好的方式是Has-A关系（关联）或Use-A关系（依赖）。同理，Stack类继承Vector也是不正确的。Sun公司的工程师们也会犯这种低级错误，让人唏嘘不已。

54、Collection和Collections的区别？
答：Collection是一个接口，它是Set、List等容器的父接口；Collections是个一个工具类，提供了一系列的静态方法来辅助容器操作，这些方法包括对容器的搜索、排序、线程安全化等等。

55、List、Map、Set三个接口存取元素时，各有什么特点？
答：List以特定索引来存取元素，可以有重复元素。Set不能存放重复元素（用对象的equals()方法来区分元素是否重复）。Map保存键值对（key-value pair）映射，映射关系可以是一对一或多对一。Set和Map容器都有基于哈希存储和排序树的两种实现版本，基于哈希存储的版本理论存取时间复杂度为O(1)，而基于排序树版本的实现在插入或删除元素时会按照元素或元素的键（key）构成排序树从而达到排序和去重的效果。

56、TreeMap和TreeSet在排序时如何比较元素？Collections工具类中的sort()方法如何比较元素？
答：TreeSet要求存放的对象所属的类必须实现Comparable接口，该接口提供了比较元素的compareTo()方法，当插入元素时会回调该方法比较元素的大小。TreeMap要求存放的键值对映射的键必须实现Comparable接口从而根据键对元素进行排序。Collections工具类的sort方法有两种重载的形式，第一种要求传入的待排序容器中存放的对象比较实现Comparable接口以实现元素的比较；第二种不强制性的要求容器中的元素必须可比较，但是要求传入第二个参数，参数是Comparator接口的子类型（需要重写compare方法实现元素的比较），相当于一个临时定义的排序规则，其实就是通过接口注入比较元素大小的算法，也是对回调模式的应用（Java中对函数式编程的支持）。
例子1：

public class Student implements Comparable<Student> {
    private String name;        // 姓名
    private int age;            // 年龄

    public Student(String name, int age) {
        this.name = name;
        this.age = age;
    }

    @Override
    public String toString() {
        return "Student [name=" + name + ", age=" + age + "]";
    }

    @Override
    public int compareTo(Student o) {
        return this.age - o.age; // 比较年龄(年龄的升序)
    }
}
import java.util.Set;
import java.util.TreeSet;

class Test01 {

    public static void main(String[] args) {
        Set<Student> set = new TreeSet<>();     // Java 7的钻石语法(构造器后面的尖括号中不需要写类型)
        set.add(new Student("Hao LUO", 33));
        set.add(new Student("XJ WANG", 32));
        set.add(new Student("Bruce LEE", 60));
        set.add(new Student("Bob YANG", 22));

        for(Student stu : set) {
            System.out.println(stu);
        }
//      输出结果: 
//      Student [name=Bob YANG, age=22]
//      Student [name=XJ WANG, age=32]
//      Student [name=Hao LUO, age=33]
//      Student [name=Bruce LEE, age=60]
    }
}

例子2：

public class Student {
    private String name;    // 姓名
    private int age;        // 年龄

    public Student(String name, int age) {
        this.name = name;
        this.age = age;
    }

    /**
     * 获取学生姓名
     */
    public String getName() {
        return name;
    }

    /**
     * 获取学生年龄
     */
    public int getAge() {
        return age;
    }

    @Override
    public String toString() {
        return "Student [name=" + name + ", age=" + age + "]";
    }

}

import java.util.ArrayList;
import java.util.Collections;
import java.util.Comparator;
import java.util.List;

class Test02 {

    public static void main(String[] args) {
        List<Student> list = new ArrayList<>();     // Java 7的钻石语法(构造器后面的尖括号中不需要写类型)
        list.add(new Student("Hao LUO", 33));
        list.add(new Student("XJ WANG", 32));
        list.add(new Student("Bruce LEE", 60));
        list.add(new Student("Bob YANG", 22));

        // 通过sort方法的第二个参数传入一个Comparator接口对象
        // 相当于是传入一个比较对象大小的算法到sort方法中
        // 由于Java中没有函数指针、仿函数、委托这样的概念
        // 因此要将一个算法传入一个方法中唯一的选择就是通过接口回调
        Collections.sort(list, new Comparator<Student> () {

            @Override
            public int compare(Student o1, Student o2) {
                return o1.getName().compareTo(o2.getName());    // 比较学生姓名
            }
        });

        for(Student stu : list) {
            System.out.println(stu);
        }
//      输出结果: 
//      Student [name=Bob YANG, age=22]
//      Student [name=Bruce LEE, age=60]
//      Student [name=Hao LUO, age=33]
//      Student [name=XJ WANG, age=32]
    }
}

57、Thread类的sleep()方法和对象的wait()方法都可以让线程暂停执行，它们有什么区别?
答：sleep()方法（休眠）是线程类（Thread）的静态方法，调用此方法会让当前线程暂停执行指定的时间，将执行机会（CPU）让给其他线程，但是对象的锁依然保持，因此休眠时间结束后会自动恢复（线程回到就绪状态，请参考第66题中的线程状态转换图）。wait()是Object类的方法，调用对象的wait()方法导致当前线程放弃对象的锁（线程暂停执行），进入对象的等待池（wait pool），只有调用对象的notify()方法（或notifyAll()方法）时才能唤醒等待池中的线程进入等锁池（lock pool），如果线程重新获得对象的锁就可以进入就绪状态。
 补充：可能不少人对什么是进程，什么是线程还比较模糊，对于为什么需要多线程编程也不是特别理解。简单的说：进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动，是操作系统进行资源分配和调度的一个独立单位；线程是进程的一个实体，是CPU调度和分派的基本单位，是比进程更小的能独立运行的基本单位。线程的划分尺度小于进程，这使得多线程程序的并发性高；进程在执行时通常拥有独立的内存单元，而线程之间可以共享内存。使用多线程的编程通常能够带来更好的性能和用户体验，但是多线程的程序对于其他程序是不友好的，因为它可能占用了更多的CPU资源。当然，也不是线程越多，程序的性能就越好，因为线程之间的调度和切换也会浪费CPU时间。时下很时髦的Node.js就采用了单线程异步I/O的工作模式。

58、线程的sleep()方法和yield()方法有什么区别？
答：
① sleep()方法给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程以运行的机会；yield()方法只会给相同优先级或更高优先级的线程以运行的机会；
② 线程执行sleep()方法后转入阻塞（blocked）状态，而执行yield()方法后转入就绪（ready）状态；
③ sleep()方法声明抛出InterruptedException，而yield()方法没有声明任何异常；
④ sleep()方法比yield()方法（跟操作系统CPU调度相关）具有更好的可移植性。

59、当一个线程进入一个对象的synchronized方法A之后，其它线程是否可进入此对象的synchronized方法B？
答：不能。其它线程只能访问该对象的非同步方法，同步方法则不能进入。因为非静态方法上的synchronized修饰符要求执行方法时要获得对象的锁，如果已经进入A方法说明对象锁已经被取走，那么试图进入B方法的线程就只能在等锁池（注意不是等待池哦）中等待对象的锁。

60、请说出与线程同步以及线程调度相关的方法。
答：
- wait()：使一个线程处于等待（阻塞）状态，并且释放所持有的对象的锁；
- sleep()：使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要处理InterruptedException异常；
- notify()：唤醒一个处于等待状态的线程，当然在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由JVM确定唤醒哪个线程，而且与优先级无关；
- notityAll()：唤醒所有处于等待状态的线程，该方法并不是将对象的锁给所有线程，而是让它们竞争，只有获得锁的线程才能进入就绪状态；
 补充：Java 5通过Lock接口提供了显式的锁机制（explicit lock），增强了灵活性以及对线程的协调。Lock接口中定义了加锁（lock()）和解锁（unlock()）的方法，同时还提供了newCondition()方法来产生用于线程之间通信的Condition对象；此外，Java 5还提供了信号量机制（semaphore），信号量可以用来限制对某个共享资源进行访问的线程的数量。在对资源进行访问之前，线程必须得到信号量的许可（调用Semaphore对象的acquire()方法）；在完成对资源的访问后，线程必须向信号量归还许可（调用Semaphore对象的release()方法）。

下面的例子演示了100个线程同时向一个银行账户中存入1元钱，在没有使用同步机制和使用同步机制情况下的执行情况。

银行账户类：
/**
 * 银行账户
 * @author 骆昊
 *
 */
public class Account {
    private double balance;     // 账户余额

    /**
     * 存款
     * @param money 存入金额
     */
    public void deposit(double money) {
        double newBalance = balance + money;
        try {
            Thread.sleep(10);   // 模拟此业务需要一段处理时间
        }
        catch(InterruptedException ex) {
            ex.printStackTrace();
        }
        balance = newBalance;
    }

    /**
     * 获得账户余额
     */
    public double getBalance() {
        return balance;
    }
}

    存钱线程类：

/**
 * 存钱线程
 * @author 骆昊
 *
 */
public class AddMoneyThread implements Runnable {
    private Account account;    // 存入账户
    private double money;       // 存入金额

    public AddMoneyThread(Account account, double money) {
        this.account = account;
        this.money = money;
    }

    @Override
    public void run() {
        account.deposit(money);
    }

}

    测试类：

import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class Test01 {

    public static void main(String[] args) {
        Account account = new Account();
        ExecutorService service = Executors.newFixedThreadPool(100);

        for(int i = 1; i <= 100; i++) {
            service.execute(new AddMoneyThread(account, 1));
        }

        service.shutdown();

        while(!service.isTerminated()) {}

        System.out.println("账户余额: " + account.getBalance());
    }
}

在没有同步的情况下，执行结果通常是显示账户余额在10元以下，出现这种状况的原因是，当一个线程A试图存入1元的时候，另外一个线程B也能够进入存款的方法中，线程B读取到的账户余额仍然是线程A存入1元钱之前的账户余额，因此也是在原来的余额0上面做了加1元的操作，同理线程C也会做类似的事情，所以最后100个线程执行结束时，本来期望账户余额为100元，但实际得到的通常在10元以下（很可能是1元哦）。解决这个问题的办法就是同步，当一个线程对银行账户存钱时，需要将此账户锁定，待其操作完成后才允许其他的线程进行操作，代码有如下几种调整方案：

    在银行账户的存款（deposit）方法上同步（synchronized）关键字

/**
 * 银行账户
 * @author 骆昊
 *
 */
public class Account {
    private double balance;     // 账户余额

    /**
     * 存款
     * @param money 存入金额
     */
    public synchronized void deposit(double money) {
        double newBalance = balance + money;
        try {
            Thread.sleep(10);   // 模拟此业务需要一段处理时间
        }
        catch(InterruptedException ex) {
            ex.printStackTrace();
        }
        balance = newBalance;
    }

    /**
     * 获得账户余额
     */
    public double getBalance() {
        return balance;
    }
}

    在线程调用存款方法时对银行账户进行同步

/**
 * 存钱线程
 * @author 骆昊
 *
 */
public class AddMoneyThread implements Runnable {
    private Account account;    // 存入账户
    private double money;       // 存入金额

    public AddMoneyThread(Account account, double money) {
        this.account = account;
        this.money = money;
    }

    @Override
    public void run() {
        synchronized (account) {
            account.deposit(money); 
        }
    }

}

    通过Java 5显示的锁机制，为每个银行账户创建一个锁对象，在存款操作进行加锁和解锁的操作

import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

/**
 * 银行账户
 * 
 * @author 骆昊
 *
 */
public class Account {
    private Lock accountLock = new ReentrantLock();
    private double balance; // 账户余额

    /**
     * 存款
     * 
     * @param money
     *            存入金额
     */
    public void deposit(double money) {
        accountLock.lock();
        try {
            double newBalance = balance + money;
            try {
                Thread.sleep(10); // 模拟此业务需要一段处理时间
            }
            catch (InterruptedException ex) {
                ex.printStackTrace();
            }
            balance = newBalance;
        }
        finally {
            accountLock.unlock();
        }
    }

    /**
     * 获得账户余额
     */
    public double getBalance() {
        return balance;
    }
}

按照上述三种方式对代码进行修改后，重写执行测试代码Test01，将看到最终的账户余额为100元。当然也可以使用Semaphore或CountdownLatch来实现同步。

61、编写多线程程序有几种实现方式？
答：Java 5以前实现多线程有两种实现方法：一种是继承Thread类；另一种是实现Runnable接口。两种方式都要通过重写run()方法来定义线程的行为，推荐使用后者，因为Java中的继承是单继承，一个类有一个父类，如果继承了Thread类就无法再继承其他类了，显然使用Runnable接口更为灵活。
补充：Java 5以后创建线程还有第三种方式：实现Callable接口，该接口中的call方法可以在线程执行结束时产生一个返回值，代码如下所示：
import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;
class MyTask implements Callable<Integer> {
    private int upperBounds;

    public MyTask(int upperBounds) {
        this.upperBounds = upperBounds;
    }

    @Override
    public Integer call() throws Exception {
        int sum = 0; 
        for(int i = 1; i <= upperBounds; i++) {
            sum += i;
        }
        return sum;
    }
}
class Test {
    public static void main(String[] args) throws Exception {
        List<Future<Integer>> list = new ArrayList<>();
        ExecutorService service = Executors.newFixedThreadPool(10);
        for(int i = 0; i < 10; i++) {
            list.add(service.submit(new MyTask((int) (Math.random() * 100))));
        }
        int sum = 0;
        for(Future<Integer> future : list) {
            // while(!future.isDone()) ;
            sum += future.get();
        }
        System.out.println(sum);
    }
}

62、synchronized关键字的用法？
答：synchronized关键字可以将对象或者方法标记为同步，以实现对对象和方法的互斥访问，可以用synchronized(对象) { … }定义同步代码块，或者在声明方法时将synchronized作为方法的修饰符。在第60题的例子中已经展示了synchronized关键字的用法。

63、举例说明同步和异步。
答：如果系统中存在临界资源（资源数量少于竞争资源的线程数量的资源），例如正在写的数据以后可能被另一个线程读到，或者正在读的数据可能已经被另一个线程写过了，那么这些数据就必须进行同步存取（数据库操作中的排他锁就是最好的例子）。当应用程序在对象上调用了一个需要花费很长时间来执行的方法，并且不希望让程序等待方法的返回时，就应该使用异步编程，在很多情况下采用异步途径往往更有效率。事实上，所谓的同步就是指阻塞式操作，而异步就是非阻塞式操作。

64、启动一个线程是调用run()还是start()方法？
答：启动一个线程是调用start()方法，使线程所代表的虚拟处理机处于可运行状态，这意味着它可以由JVM 调度并执行，这并不意味着线程就会立即运行。run()方法是线程启动后要进行回调（callback）的方法。

65、什么是线程池（thread pool）？
答：在面向对象编程中，创建和销毁对象是很费时间的，因为创建一个对象要获取内存资源或者其它更多资源。在Java中更是如此，虚拟机将试图跟踪每一个对象，以便能够在对象销毁后进行垃圾回收。所以提高服务程序效率的一个手段就是尽可能减少创建和销毁对象的次数，特别是一些很耗资源的对象创建和销毁，这就是”池化资源”技术产生的原因。线程池顾名思义就是事先创建若干个可执行的线程放入一个池（容器）中，需要的时候从池中获取线程不用自行创建，使用完毕不需要销毁线程而是放回池中，从而减少创建和销毁线程对象的开销。
Java 5+中的Executor接口定义一个执行线程的工具。它的子类型即线程池接口是ExecutorService。要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，因此在工具类Executors面提供了一些静态工厂方法，生成一些常用的线程池，如下所示：
- newSingleThreadExecutor：创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。
- newFixedThreadPool：创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。
- newCachedThreadPool：创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。
- newScheduledThreadPool：创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。
- newSingleThreadExecutor：创建一个单线程的线程池。此线程池支持定时以及周期性执行任务的需求。

第60题的例子中演示了通过Executors工具类创建线程池并使用线程池执行线程的代码。如果希望在服务器上使用线程池，强烈建议使用newFixedThreadPool方法来创建线程池，这样能获得更好的性能。

66、线程的基本状态以及状态之间的关系？
答：
说明：其中Running表示运行状态，Runnable表示就绪状态（万事俱备，只欠CPU），Blocked表示阻塞状态，阻塞状态又有多种情况，可能是因为调用wait()方法进入等待池，也可能是执行同步方法或同步代码块进入等锁池，或者是调用了sleep()方法或join()方法等待休眠或其他线程结束，或是因为发生了I/O中断。

67、简述synchronized 和java.util.concurrent.locks.Lock的异同？
答：Lock是Java 5以后引入的新的API，和关键字synchronized相比主要相同点：Lock 能完成synchronized所实现的所有功能；主要不同点：Lock有比synchronized更精确的线程语义和更好的性能，而且不强制性的要求一定要获得锁。synchronized会自动释放锁，而Lock一定要求程序员手工释放，并且最好在finally 块中释放（这是释放外部资源的最好的地方）。

68、Java中如何实现序列化，有什么意义？
答：序列化就是一种用来处理对象流的机制，所谓对象流也就是将对象的内容进行流化。可以对流化后的对象进行读写操作，也可将流化后的对象传输于网络之间。序列化是为了解决对象流读写操作时可能引发的问题（如果不进行序列化可能会存在数据乱序的问题）。
要实现序列化，需要让一个类实现Serializable接口，该接口是一个标识性接口，标注该类对象是可被序列化的，然后使用一个输出流来构造一个对象输出流并通过writeObject(Object)方法就可以将实现对象写出（即保存其状态）；如果需要反序列化则可以用一个输入流建立对象输入流，然后通过readObject方法从流中读取对象。序列化除了能够实现对象的持久化之外，还能够用于对象的深度克隆（可以参考第29题）。

69、Java中有几种类型的流？
答：字节流和字符流。字节流继承于InputStream、OutputStream，字符流继承于Reader、Writer。在java.io 包中还有许多其他的流，主要是为了提高性能和使用方便。关于Java的I/O需要注意的有两点：一是两种对称性（输入和输出的对称性，字节和字符的对称性）；二是两种设计模式（适配器模式和装潢模式）。另外Java中的流不同于C#的是它只有一个维度一个方向。

面试题 - 编程实现文件拷贝。（这个题目在笔试的时候经常出现，下面的代码给出了两种实现方案）

import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.nio.ByteBuffer;
import java.nio.channels.FileChannel;
public final class MyUtil {
    private MyUtil() {
        throw new AssertionError();
    }

    public static void fileCopy(String source, String target) throws IOException {
        try (InputStream in = new FileInputStream(source)) {
            try (OutputStream out = new FileOutputStream(target)) {
                byte[] buffer = new byte[4096];
                int bytesToRead;
                while((bytesToRead = in.read(buffer)) != -1) {
                    out.write(buffer, 0, bytesToRead);
                }
            }
        }
    }

    public static void fileCopyNIO(String source, String target) throws IOException {
        try (FileInputStream in = new FileInputStream(source)) {
            try (FileOutputStream out = new FileOutputStream(target)) {
                FileChannel inChannel = in.getChannel();
                FileChannel outChannel = out.getChannel();
                ByteBuffer buffer = ByteBuffer.allocate(4096);
                while(inChannel.read(buffer) != -1) {
                    buffer.flip();
                    outChannel.write(buffer);
                    buffer.clear();
                }
            }
        }
    }
}

    注意：上面用到Java 7的TWR，使用TWR后可以不用在finally中释放外部资源 ，从而让代码更加优雅。

70、写一个方法，输入一个文件名和一个字符串，统计这个字符串在这个文件中出现的次数。
答：代码如下：

import java.io.BufferedReader;
import java.io.FileReader;

public final class MyUtil {

    // 工具类中的方法都是静态方式访问的因此将构造器私有不允许创建对象(绝对好习惯)
    private MyUtil() {
        throw new AssertionError();
    }

    /**
     * 统计给定文件中给定字符串的出现次数
     * 
     * @param filename  文件名
     * @param word 字符串
     * @return 字符串在文件中出现的次数
     */
    public static int countWordInFile(String filename, String word) {
        int counter = 0;
        try (FileReader fr = new FileReader(filename)) {
            try (BufferedReader br = new BufferedReader(fr)) {
                String line = null;
                while ((line = br.readLine()) != null) {
                    int index = -1;
                    while (line.length() >= word.length() && (index = line.indexOf(word)) >= 0) {
                        counter++;
                        line = line.substring(index + word.length());
                    }
                }
            }
        } catch (Exception ex) {
            ex.printStackTrace();
        }
        return counter;
    }
}

71、如何用Java代码列出一个目录下所有的文件？
答：
如果只要求列出当前文件夹下的文件，代码如下所示：
import java.io.File;
class Test12 {
    public static void main(String[] args) {
        File f = new File("/Users/Hao/Downloads");
        for(File temp : f.listFiles()) {
            if(temp.isFile()) {
                System.out.println(temp.getName());
            }
        }
    }
}

如果需要对文件夹继续展开，代码如下所示：

import java.io.File;
class Test12 {
    public static void main(String[] args) {
        showDirectory(new File("/Users/Hao/Downloads"));
    }

    public static void showDirectory(File f) {
        _walkDirectory(f, 0);
    }

    private static void _walkDirectory(File f, int level) {
        if(f.isDirectory()) {
            for(File temp : f.listFiles()) {
                _walkDirectory(temp, level + 1);
            }
        }
        else {
            for(int i = 0; i < level - 1; i++) {
                System.out.print("\t");
            }
            System.out.println(f.getName());
        }
    }
}

在Java 7中可以使用NIO.2的API来做同样的事情，代码如下所示：

class ShowFileTest {

    public static void main(String[] args) throws IOException {
        Path initPath = Paths.get("/Users/Hao/Downloads");
        Files.walkFileTree(initPath, new SimpleFileVisitor<Path>() {

            @Override
            public FileVisitResult visitFile(Path file, BasicFileAttributes attrs)
                    throws IOException {
                System.out.println(file.getFileName().toString());
                return FileVisitResult.CONTINUE;
            }

        });
    }
}

72、用Java的套接字编程实现一个多线程的回显（echo）服务器。
答：
import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStreamReader;
import java.io.PrintWriter;
import java.net.ServerSocket;
import java.net.Socket;

public class EchoServer {

    private static final int ECHO_SERVER_PORT = 6789;

    public static void main(String[] args) {        
        try(ServerSocket server = new ServerSocket(ECHO_SERVER_PORT)) {
            System.out.println("服务器已经启动...");
            while(true) {
                Socket client = server.accept();
                new Thread(new ClientHandler(client)).start();
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    private static class ClientHandler implements Runnable {
        private Socket client;

        public ClientHandler(Socket client) {
            this.client = client;
        }

        @Override
        public void run() {
            try(BufferedReader br = new BufferedReader(new InputStreamReader(client.getInputStream()));
                    PrintWriter pw = new PrintWriter(client.getOutputStream())) {
                String msg = br.readLine();
                System.out.println("收到" + client.getInetAddress() + "发送的: " + msg);
                pw.println(msg);
                pw.flush();
            } catch(Exception ex) {
                ex.printStackTrace();
            } finally {
                try {
                    client.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }
    }

}

    注意：上面的代码使用了Java 7的TWR语法，由于很多外部资源类都间接的实现了AutoCloseable接口（单方法回调接口），因此可以利用TWR语法在try结束的时候通过回调的方式自动调用外部资源类的close()方法，避免书写冗长的finally代码块。此外，上面的代码用一个静态内部类实现线程的功能，使用多线程可以避免一个用户I/O操作所产生的中断影响其他用户对服务器的访问，简单的说就是一个用户的输入操作不会造成其他用户的阻塞。当然，上面的代码使用线程池可以获得更好的性能，因为频繁的创建和销毁线程所造成的开销也是不可忽视的。

下面是一段回显客户端测试代码：

import java.io.BufferedReader;
import java.io.InputStreamReader;
import java.io.PrintWriter;
import java.net.Socket;
import java.util.Scanner;

public class EchoClient {

    public static void main(String[] args) throws Exception {
        Socket client = new Socket("localhost", 6789);
        Scanner sc = new Scanner(System.in);
        System.out.print("请输入内容: ");
        String msg = sc.nextLine();
        sc.close();
        PrintWriter pw = new PrintWriter(client.getOutputStream());
        pw.println(msg);
        pw.flush();
        BufferedReader br = new BufferedReader(new InputStreamReader(client.getInputStream()));
        System.out.println(br.readLine());
        client.close();
    }
}

如果希望用NIO的多路复用套接字实现服务器，代码如下所示。NIO的操作虽然带来了更好的性能，但是有些操作是比较底层的，对于初学者来说还是有些难于理解。

import java.io.IOException;
import java.net.InetSocketAddress;
import java.nio.ByteBuffer;
import java.nio.CharBuffer;
import java.nio.channels.SelectionKey;
import java.nio.channels.Selector;
import java.nio.channels.ServerSocketChannel;
import java.nio.channels.SocketChannel;
import java.util.Iterator;
public class EchoServerNIO {
    private static final int ECHO_SERVER_PORT = 6789;
    private static final int ECHO_SERVER_TIMEOUT = 5000;
    private static final int BUFFER_SIZE = 1024;

    private static ServerSocketChannel serverChannel = null;
    private static Selector selector = null;    // 多路复用选择器
    private static ByteBuffer buffer = null;    // 缓冲区

    public static void main(String[] args) {
        init();
        listen();
    }

    private static void init() {
        try {
            serverChannel = ServerSocketChannel.open();
            buffer = ByteBuffer.allocate(BUFFER_SIZE);
            serverChannel.socket().bind(new InetSocketAddress(ECHO_SERVER_PORT));
            serverChannel.configureBlocking(false);
            selector = Selector.open();
            serverChannel.register(selector, SelectionKey.OP_ACCEPT);
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }

    private static void listen() {
        while (true) {
            try {
                if (selector.select(ECHO_SERVER_TIMEOUT) != 0) {
                    Iterator<SelectionKey> it = selector.selectedKeys().iterator();
                    while (it.hasNext()) {
                        SelectionKey key = it.next();
                        it.remove();
                        handleKey(key);
                    }
                }
            } catch (Exception e) {
                e.printStackTrace();
            }
        }
    }

    private static void handleKey(SelectionKey key) throws IOException {
        SocketChannel channel = null;

        try {
            if (key.isAcceptable()) {
                ServerSocketChannel serverChannel = (ServerSocketChannel) key.channel();
                channel = serverChannel.accept();
                channel.configureBlocking(false);
                channel.register(selector, SelectionKey.OP_READ);
            } else if (key.isReadable()) {
                channel = (SocketChannel) key.channel();
                buffer.clear();
                if (channel.read(buffer) > 0) {
                    buffer.flip();
                    CharBuffer charBuffer = CharsetHelper.decode(buffer);
                    String msg = charBuffer.toString();
                    System.out.println("收到" + channel.getRemoteAddress() + "的消息：" + msg);
                    channel.write(CharsetHelper.encode(CharBuffer.wrap(msg)));
                } else {
                    channel.close();
                }
            }
        } catch (Exception e) {
            e.printStackTrace();
            if (channel != null) {
                channel.close();
            }
        }
    }

}

import java.nio.ByteBuffer;
import java.nio.CharBuffer;
import java.nio.charset.CharacterCodingException;
import java.nio.charset.Charset;
import java.nio.charset.CharsetDecoder;
import java.nio.charset.CharsetEncoder;

public final class CharsetHelper {
    private static final String UTF_8 = "UTF-8";
    private static CharsetEncoder encoder = Charset.forName(UTF_8).newEncoder();
    private static CharsetDecoder decoder = Charset.forName(UTF_8).newDecoder();

    private CharsetHelper() {
    }

    public static ByteBuffer encode(CharBuffer in) throws CharacterCodingException{
        return encoder.encode(in);
    }

    public static CharBuffer decode(ByteBuffer in) throws CharacterCodingException{
        return decoder.decode(in);
    }
}

73、XML文档定义有几种形式？它们之间有何本质区别？解析XML文档有哪几种方式？
答：XML文档定义分为DTD和Schema两种形式，二者都是对XML语法的约束，其本质区别在于Schema本身也是一个XML文件，可以被XML解析器解析，而且可以为XML承载的数据定义类型，约束能力较之DTD更强大。对XML的解析主要有DOM（文档对象模型，DocumentObjectModel）、SAX（Simple API for XML）和StAX（Java 6中引入的新的解析XML的方式，StreamingAPI forXML），其中DOM处理大型文件时其性能下降的非常厉害，这个问题是由DOM树结构占用的内存较多造成的，而且DOM解析方式必须在解析文件之前把整个文档装入内存，适合对XML的随机访问（典型的用空间换取时间的策略）；SAX是事件驱动型的XML解析方式，它顺序读取XML文件，不需要一次全部装载整个文件。当遇到像文件开头，文档结束，或者标签开头与标签结束时，它会触发一个事件，用户通过事件回调代码来处理XML文件，适合对XML的顺序访问；顾名思义，StAX把重点放在流上，实际上StAX与其他解析方式的本质区别就在于应用程序能够把XML作为一个事件流来处理。将XML作为一组事件来处理的想法并不新颖（SAX就是这样做的），但不同之处在于StAX允许应用程序代码把这些事件逐个拉出来，而不用提供在解析器方便时从解析器中接收事件的处理程序。

74、你在项目中哪些地方用到了XML？
答：XML的主要作用有两个方面：数据交换和信息配置。在做数据交换时，XML将数据用标签组装成起来，然后压缩打包加密后通过网络传送给接收者，接收解密与解压缩后再从XML文件中还原相关信息进行处理，XML曾经是异构系统间交换数据的事实标准，但此项功能几乎已经被JSON（JavaScriptObjectNotation）取而代之。当然，目前很多软件仍然使用XML来存储配置信息，我们在很多项目中通常也会将作为配置信息的硬代码写在XML文件中，Java的很多框架也是这么做的，而且这些框架都选择了dom4j作为处理XML的工具，因为Sun公司的官方API实在不怎么好用。
补充：现在有很多时髦的软件（如Sublime）已经开始将配置文件书写成JSON格式，我们已经强烈的感受到XML的另一项功能也将逐渐被业界抛弃。

75、阐述JDBC操作数据库的步骤。
答：下面的代码以连接本机的Oracle数据库为例，演示JDBC操作数据库的步骤。

    加载驱动。
 Class.forName("oracle.jdbc.driver.OracleDriver");

    创建连接。
    Connection con = DriverManager.getConnection("jdbc:oracle:thin:@localhost:1521:orcl", "scott", "tiger");

    创建语句。
 PreparedStatement ps = con.prepareStatement("select * from emp where sal between ? and ?");
    ps.setInt(1, 1000);
    ps.setInt(2, 3000);

    执行语句。
    ResultSet rs = ps.executeQuery();

    处理结果。
 while(rs.next()) {
        System.out.println(rs.getInt("empno") + " - " + rs.getString("ename"));
    }

    关闭资源。
  finally {
        if(con != null) {
            try {
                con.close();
            } catch (SQLException e) {
                e.printStackTrace();
            }
        }
    }
提示：关闭外部资源的顺序应该和打开的顺序相反，也就是说先关闭ResultSet、再关闭Statement、在关闭Connection。上面的代码只关闭了Connection（连接），虽然通常情况下在关闭连接时，连接上创建的语句和打开的游标也会关闭，但不能保证总是如此，因此应该按照刚才说的顺序分别关闭。此外，第一步加载驱动在JDBC 4.0中是可以省略的（自动从类路径中加载驱动），但是我们建议保留。

76、Statement和PreparedStatement有什么区别？哪个性能更好？
答：与Statement相比，①PreparedStatement接口代表预编译的语句，它主要的优势在于可以减少SQL的编译错误并增加SQL的安全性（减少SQL注射攻击的可能性）；②PreparedStatement中的SQL语句是可以带参数的，避免了用字符串连接拼接SQL语句的麻烦和不安全；③当批量处理SQL或频繁执行相同的查询时，PreparedStatement有明显的性能上的优势，由于数据库可以将编译优化后的SQL语句缓存起来，下次执行相同结构的语句时就会很快（不用再次编译和生成执行计划）。
补充：为了提供对存储过程的调用，JDBC API中还提供了CallableStatement接口。存储过程（Stored Procedure）是数据库中一组为了完成特定功能的SQL语句的集合，经编译后存储在数据库中，用户通过指定存储过程的名字并给出参数（如果该存储过程带有参数）来执行它。虽然调用存储过程会在网络开销、安全性、性能上获得很多好处，但是存在如果底层数据库发生迁移时就会有很多麻烦，因为每种数据库的存储过程在书写上存在不少的差别。

77、使用JDBC操作数据库时，如何提升读取数据的性能？如何提升更新数据的性能？
答：要提升读取数据的性能，可以指定通过结果集（ResultSet）对象的setFetchSize()方法指定每次抓取的记录数（典型的空间换时间策略）；要提升更新数据的性能可以使用PreparedStatement语句构建批处理，将若干SQL语句置于一个批处理中执行。

78、在进行数据库编程时，连接池有什么作用？
答：由于创建连接和释放连接都有很大的开销（尤其是数据库服务器不在本地时，每次建立连接都需要进行TCP的三次握手，释放连接需要进行TCP四次握手，造成的开销是不可忽视的），为了提升系统访问数据库的性能，可以事先创建若干连接置于连接池中，需要时直接从连接池获取，使用结束时归还连接池而不必关闭连接，从而避免频繁创建和释放连接所造成的开销，这是典型的用空间换取时间的策略（浪费了空间存储连接，但节省了创建和释放连接的时间）。池化技术在Java开发中是很常见的，在使用线程时创建线程池的道理与此相同。基于Java的开源数据库连接池主要有：C3P0、Proxool、DBCP、BoneCP、Druid等。
补充：在计算机系统中时间和空间是不可调和的矛盾，理解这一点对设计满足性能要求的算法是至关重要的。大型网站性能优化的一个关键就是使用缓存，而缓存跟上面讲的连接池道理非常类似，也是使用空间换时间的策略。可以将热点数据置于缓存中，当用户查询这些数据时可以直接从缓存中得到，这无论如何也快过去数据库中查询。当然，缓存的置换策略等也会对系统性能产生重要影响，对于这个问题的讨论已经超出了这里要阐述的范围。

79、什么是DAO模式？
答：DAO（Data Access Object）顾名思义是一个为数据库或其他持久化机制提供了抽象接口的对象，在不暴露底层持久化方案实现细节的前提下提供了各种数据访问操作。在实际的开发中，应该将所有对数据源的访问操作进行抽象化后封装在一个公共API中。用程序设计语言来说，就是建立一个接口，接口中定义了此应用程序中将会用到的所有事务方法。在这个应用程序中，当需要和数据源进行交互的时候则使用这个接口，并且编写一个单独的类来实现这个接口，在逻辑上该类对应一个特定的数据存储。DAO模式实际上包含了两个模式，一是Data Accessor（数据访问器），二是Data Object（数据对象），前者要解决如何访问数据的问题，而后者要解决的是如何用对象封装数据。

80、事务的ACID是指什么？ 
答： - 原子性(Atomic)：事务中各项操作，要么全做要么全不做，任何一项操作的失败都会导致整个事务的失败； - 一致性(Consistent)：事务结束后系统状态是一致的； - 隔离性(Isolated)：并发执行的事务彼此无法看到对方的中间状态； - 持久性(Durable)：事务完成后所做的改动都会被持久化，即使发生灾难性的失败。通过日志和同步备份可以在故障发生后重建数据。

    补充：关于事务，在面试中被问到的概率是很高的，可以问的问题也是很多的。首先需要知道的是，只有存在并发数据访问时才需要事务。当多个事务访问同一数据时，可能会存在5类问题，包括3类数据读取问题（脏读、不可重复读和幻读）和2类数据更新问题（第1类丢失更新和第2类丢失更新）。

脏读（Dirty Read）：A事务读取B事务尚未提交的数据并在此基础上操作，而B事务执行回滚，那么A读取到的数据就是脏数据。
时间	转账事务A	取款事务B
T1	
	开始事务
T2	开始事务	
T3	
	查询账户余额为1000元
T4	
	取出500元余额修改为500元
T5	查询账户余额为500元（脏读）	
T6	
	撤销事务余额恢复为1000元
T7	汇入100元把余额修改为600元	
T8	提交事务	

不可重复读（Unrepeatable Read）：事务A重新读取前面读取过的数据，发现该数据已经被另一个已提交的事务B修改过了。
时间	转账事务A	取款事务B
T1	
	开始事务
T2	开始事务	
T3	
	查询账户余额为1000元
T4	查询账户余额为1000元	
T5	
	取出100元修改余额为900元
T6	
	提交事务
T7	查询账户余额为900元（不可重复读）	

幻读（Phantom Read）：事务A重新执行一个查询，返回一系列符合查询条件的行，发现其中插入了被事务B提交的行。
时间	统计金额事务A	转账事务B
T1	
	开始事务
T2	开始事务	
T3	统计总存款为10000元	
T4	
	新增一个存款账户存入100元
T5	
	提交事务
T6	再次统计总存款为10100元（幻读）	

第1类丢失更新：事务A撤销时，把已经提交的事务B的更新数据覆盖了。
时间	取款事务A	转账事务B
T1	开始事务	
T2	
	开始事务
T3	查询账户余额为1000元	
T4	
	查询账户余额为1000元
T5	
	汇入100元修改余额为1100元
T6	
	提交事务
T7	取出100元将余额修改为900元	
T8	撤销事务	
T9	余额恢复为1000元（丢失更新）	

第2类丢失更新：事务A覆盖事务B已经提交的数据，造成事务B所做的操作丢失。
时间	转账事务A	取款事务B
T1	
	开始事务
T2	开始事务	
T3	
	查询账户余额为1000元
T4	查询账户余额为1000元	
T5	
	取出100元将余额修改为900元
T6	
	提交事务
T7	汇入100元将余额修改为1100元	
T8	提交事务	
T9	查询账户余额为1100元（丢失更新）	

数据并发访问所产生的问题，在有些场景下可能是允许的，但是有些场景下可能就是致命的，数据库通常会通过锁机制来解决数据并发访问问题，按锁定对象不同可以分为表级锁和行级锁；按并发事务锁定关系可以分为共享锁和独占锁，具体的内容大家可以自行查阅资料进行了解。直接使用锁是非常麻烦的，为此数据库为用户提供了自动锁机制，只要用户指定会话的事务隔离级别，数据库就会通过分析SQL语句然后为事务访问的资源加上合适的锁，此外，数据库还会维护这些锁通过各种手段提高系统的性能，这些对用户来说都是透明的（就是说你不用理解，事实上我确实也不知道）。ANSI/ISO SQL 92标准定义了4个等级的事务隔离级别，如下表所示：
隔离级别	脏读	不可重复读	幻读	第一类丢失更新	第二类丢失更新
READ UNCOMMITED	允许	允许	允许	不允许	允许
READ COMMITTED	不允许	允许	允许	不允许	允许
REPEATABLE READ	不允许	不允许	允许	不允许	不允许
SERIALIZABLE	不允许	不允许	不允许	不允许	不允许

需要说明的是，事务隔离级别和数据访问的并发性是对立的，事务隔离级别越高并发性就越差。所以要根据具体的应用来确定合适的事务隔离级别，这个地方没有万能的原则。

81、JDBC中如何进行事务处理
答：Connection提供了事务处理的方法，通过调用setAutoCommit(false)可以设置手动提交事务；当事务完成后用commit()显式提交事务；如果在事务处理过程中发生异常则通过rollback()进行事务回滚。除此之外，从JDBC 3.0中还引入了Savepoint（保存点）的概念，允许通过代码设置保存点并让事务回滚到指定的保存点。这里写图片描述

81、JDBC中如何进行事务处理？
答：Connection提供了事务处理的方法，通过调用setAutoCommit(false)可以设置手动提交事务；当事务完成后用commit()显式提交事务；如果在事务处理过程中发生异常则通过rollback()进行事务回滚。除此之外，从JDBC 3.0中还引入了Savepoint（保存点）的概念，允许通过代码设置保存点并让事务回滚到指定的保存点。
这里写图片描述

82、JDBC能否处理Blob和Clob？
答： Blob是指二进制大对象（Binary Large Object），而Clob是指大字符对象（Character Large Objec），因此其中Blob是为存储大的二进制数据而设计的，而Clob是为存储大的文本数据而设计的。JDBC的PreparedStatement和ResultSet都提供了相应的方法来支持Blob和Clob操作。下面的代码展示了如何使用JDBC操作LOB：
下面以MySQL数据库为例，创建一个张有三个字段的用户表，包括编号（id）、姓名（name）和照片（photo），建表语句如下：

create table tb_user
(
id int primary key auto_increment,
name varchar(20) unique not null,
photo longblob
);

下面的Java代码向数据库中插入一条记录：

import java.io.FileInputStream;
import java.io.IOException;
import java.io.InputStream;
import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.PreparedStatement;
import java.sql.SQLException;
class JdbcLobTest {
    public static void main(String[] args) {
        Connection con = null;
        try {
            // 1. 加载驱动（Java6以上版本可以省略）
            Class.forName("com.mysql.jdbc.Driver");
            // 2. 建立连接
            con = DriverManager.getConnection("jdbc:mysql://localhost:3306/test", "root", "123456");
            // 3. 创建语句对象
            PreparedStatement ps = con.prepareStatement("insert into tb_user values (default, ?, ?)");
            ps.setString(1, "骆昊");              // 将SQL语句中第一个占位符换成字符串
            try (InputStream in = new FileInputStream("test.jpg")) {    // Java 7的TWR
                ps.setBinaryStream(2, in);      // 将SQL语句中第二个占位符换成二进制流
                // 4. 发出SQL语句获得受影响行数
                System.out.println(ps.executeUpdate() == 1 ? "插入成功" : "插入失败");
            } catch(IOException e) {
                System.out.println("读取照片失败!");
            }
        } catch (ClassNotFoundException | SQLException e) {     // Java 7的多异常捕获
            e.printStackTrace();
        } finally { // 释放外部资源的代码都应当放在finally中保证其能够得到执行
            try {
                if(con != null && !con.isClosed()) {
                    con.close();    // 5. 释放数据库连接
                    con = null;     // 指示垃圾回收器可以回收该对象
                }
            } catch (SQLException e) {
                e.printStackTrace();
            }
        }
    }
}

83、简述正则表达式及其用途。
答：在编写处理字符串的程序时，经常会有查找符合某些复杂规则的字符串的需要。正则表达式就是用于描述这些规则的工具。换句话说，正则表达式就是记录文本规则的代码。

    说明：计算机诞生初期处理的信息几乎都是数值，但是时过境迁，今天我们使用计算机处理的信息更多的时候不是数值而是字符串，正则表达式就是在进行字符串匹配和处理的时候最为强大的工具，绝大多数语言都提供了对正则表达式的支持。

84、Java中是如何支持正则表达式操作的？
答：Java中的String类提供了支持正则表达式操作的方法，包括：matches()、replaceAll()、replaceFirst()、split()。此外，Java中可以用Pattern类表示正则表达式对象，它提供了丰富的API进行各种正则表达式操作，请参考下面面试题的代码。

    面试题： - 如果要从字符串中截取第一个英文左括号之前的字符串，例如：北京市(朝阳区)(西城区)(海淀区)，截取结果为：北京市，那么正则表达式怎么写？

import java.util.regex.Matcher;
import java.util.regex.Pattern;

class RegExpTest {
    public static void main(String[] args) {
        String str = "北京市(朝阳区)(西城区)(海淀区)";
        Pattern p = Pattern.compile(".*?(?=\\()");
        Matcher m = p.matcher(str);
        if(m.find()) {
            System.out.println(m.group());
        }
    }
}

    说明：上面的正则表达式中使用了懒惰匹配和前瞻，如果不清楚这些内容，推荐读一下网上很有名的《正则表达式30分钟入门教程》。

85、获得一个类的类对象有哪些方式？
答：
- 方法1：类型.class，例如：String.class
- 方法2：对象.getClass()，例如："hello".getClass()
- 方法3：Class.forName()，例如：Class.forName("java.lang.String")

86、如何通过反射创建对象？
答：
- 方法1：通过类对象调用newInstance()方法，例如：String.class.newInstance()
- 方法2：通过类对象的getConstructor()或getDeclaredConstructor()方法获得构造器（Constructor）对象并调用其newInstance()方法创建对象，例如：String.class.getConstructor(String.class).newInstance("Hello");

87、如何通过反射获取和设置对象私有字段的值？
答：可以通过类对象的getDeclaredField()方法字段（Field）对象，然后再通过字段对象的setAccessible(true)将其设置为可以访问，接下来就可以通过get/set方法来获取/设置字段的值了。下面的代码实现了一个反射的工具类，其中的两个静态方法分别用于获取和设置私有字段的值，字段可以是基本类型也可以是对象类型且支持多级对象操作，例如ReflectionUtil.get(dog, "owner.car.engine.id");可以获得dog对象的主人的汽车的引擎的ID号。
import java.lang.reflect.Constructor;
import java.lang.reflect.Field;
import java.lang.reflect.Modifier;
import java.util.ArrayList;
import java.util.List;

/**
 * 反射工具类
 * @author 骆昊
 *
 */
public class ReflectionUtil {

    private ReflectionUtil() {
        throw new AssertionError();
    }

    /**
     * 通过反射取对象指定字段(属性)的值
     * @param target 目标对象
     * @param fieldName 字段的名字
     * @throws 如果取不到对象指定字段的值则抛出异常
     * @return 字段的值
     */
    public static Object getValue(Object target, String fieldName) {
        Class<?> clazz = target.getClass();
        String[] fs = fieldName.split("\\.");

        try {
            for(int i = 0; i < fs.length - 1; i++) {
                Field f = clazz.getDeclaredField(fs[i]);
                f.setAccessible(true);
                target = f.get(target);
                clazz = target.getClass();
            }

            Field f = clazz.getDeclaredField(fs[fs.length - 1]);
            f.setAccessible(true);
            return f.get(target);
        }
        catch (Exception e) {
            throw new RuntimeException(e);
        }
    }

    /**
     * 通过反射给对象的指定字段赋值
     * @param target 目标对象
     * @param fieldName 字段的名称
     * @param value 值
     */
    public static void setValue(Object target, String fieldName, Object value) {
        Class<?> clazz = target.getClass();
        String[] fs = fieldName.split("\\.");
        try {
            for(int i = 0; i < fs.length - 1; i++) {
                Field f = clazz.getDeclaredField(fs[i]);
                f.setAccessible(true);
                Object val = f.get(target);
                if(val == null) {
                    Constructor<?> c = f.getType().getDeclaredConstructor();
                    c.setAccessible(true);
                    val = c.newInstance();
                    f.set(target, val);
                }
                target = val;
                clazz = target.getClass();
            }

            Field f = clazz.getDeclaredField(fs[fs.length - 1]);
            f.setAccessible(true);
            f.set(target, value);
        }
        catch (Exception e) {
            throw new RuntimeException(e);
        }
    }

}

88、如何通过反射调用对象的方法？
答：请看下面的代码：
import java.lang.reflect.Method;
class MethodInvokeTest {
    public static void main(String[] args) throws Exception {
        String str = "hello";
        Method m = str.getClass().getMethod("toUpperCase");
        System.out.println(m.invoke(str));  // HELLO
    }
}

89、简述一下面向对象的"六原则一法则"。
答： - 单一职责原则：一个类只做它该做的事情。（单一职责原则想表达的就是"高内聚"，写代码最终极的原则只有六个字"高内聚、低耦合"，就如同葵花宝典或辟邪剑谱的中心思想就八个字"欲练此功必先自宫"，所谓的高内聚就是一个代码模块只完成一项功能，在面向对象中，如果只让一个类完成它该做的事，而不涉及与它无关的领域就是践行了高内聚的原则，这个类就只有单一职责。我们都知道一句话叫"因为专注，所以专业"，一个对象如果承担太多的职责，那么注定它什么都做不好。这个世界上任何好的东西都有两个特征，一个是功能单一，好的相机绝对不是电视购物里面卖的那种一个机器有一百多种功能的，它基本上只能照相；另一个是模块化，好的自行车是组装车，从减震叉、刹车到变速器，所有的部件都是可以拆卸和重新组装的，好的乒乓球拍也不是成品拍，一定是底板和胶皮可以拆分和自行组装的，一个好的软件系统，它里面的每个功能模块也应该是可以轻易的拿到其他系统中使用的，这样才能实现软件复用的目标。）- 开闭原则：软件实体应当对扩展开放，对修改关闭。（在理想的状态下，当我们需要为一个软件系统增加新功能时，只需要从原来的系统派生出一些新类就可以，不需要修改原来的任何一行代码。要做到开闭有两个要点：①抽象是关键，一个系统中如果没有抽象类或接口系统就没有扩展点；②封装可变性，将系统中的各种可变因素封装到一个继承结构中，如果多个可变因素混杂在一起，系统将变得复杂而换乱，如果不清楚如何封装可变性，可以参考《设计模式精解》一书中对桥梁模式的讲解的章节。）- 依赖倒转原则：面向接口编程。（该原则说得直白和具体一些就是声明方法的参数类型、方法的返回类型、变量的引用类型时，尽可能使用抽象类型而不用具体类型，因为抽象类型可以被它的任何一个子类型所替代，请参考下面的里氏替换原则。）里氏替换原则：任何时候都可以用子类型替换掉父类型。（关于里氏替换原则的描述，Barbara Liskov女士的描述比这个要复杂得多，但简单的说就是能用父类型的地方就一定能使用子类型。里氏替换原则可以检查继承关系是否合理，如果一个继承关系违背了里氏替换原则，那么这个继承关系一定是错误的，需要对代码进行重构。例如让猫继承狗，或者狗继承猫，又或者让正方形继承长方形都是错误的继承关系，因为你很容易找到违反里氏替换原则的场景。需要注意的是：子类一定是增加父类的能力而不是减少父类的能力，因为子类比父类的能力更多，把能力多的对象当成能力少的对象来用当然没有任何问题。）- 接口隔离原则：接口要小而专，绝不能大而全。（臃肿的接口是对接口的污染，既然接口表示能力，那么一个接口只应该描述一种能力，接口也应该是高度内聚的。例如，琴棋书画就应该分别设计为四个接口，而不应设计成一个接口中的四个方法，因为如果设计成一个接口中的四个方法，那么这个接口很难用，毕竟琴棋书画四样都精通的人还是少数，而如果设计成四个接口，会几项就实现几个接口，这样的话每个接口被复用的可能性是很高的。Java中的接口代表能力、代表约定、代表角色，能否正确的使用接口一定是编程水平高低的重要标识。）- 合成聚合复用原则：优先使用聚合或合成关系复用代码。（通过继承来复用代码是面向对象程序设计中被滥用得最多的东西，因为所有的教科书都无一例外的对继承进行了鼓吹从而误导了初学者，类与类之间简单的说有三种关系，Is-A关系、Has-A关系、Use-A关系，分别代表继承、关联和依赖。其中，关联关系根据其关联的强度又可以进一步划分为关联、聚合和合成，但说白了都是Has-A关系，合成聚合复用原则想表达的是优先考虑Has-A关系而不是Is-A关系复用代码，原因嘛可以自己从百度上找到一万个理由，需要说明的是，即使在Java的API中也有不少滥用继承的例子，例如Properties类继承了Hashtable类，Stack类继承了Vector类，这些继承明显就是错误的，更好的做法是在Properties类中放置一个Hashtable类型的成员并且将其键和值都设置为字符串来存储数据，而Stack类的设计也应该是在Stack类中放一个Vector对象来存储数据。记住：任何时候都不要继承工具类，工具是可以拥有并可以使用的，而不是拿来继承的。）- 迪米特法则：迪米特法则又叫最少知识原则，一个对象应当对其他对象有尽可能少的了解。（迪米特法则简单的说就是如何做到"低耦合"，门面模式和调停者模式就是对迪米特法则的践行。对于门面模式可以举一个简单的例子，你去一家公司洽谈业务，你不需要了解这个公司内部是如何运作的，你甚至可以对这个公司一无所知，去的时候只需要找到公司入口处的前台美女，告诉她们你要做什么，她们会找到合适的人跟你接洽，前台的美女就是公司这个系统的门面。再复杂的系统都可以为用户提供一个简单的门面，Java Web开发中作为前端控制器的Servlet或Filter不就是一个门面吗，浏览器对服务器的运作方式一无所知，但是通过前端控制器就能够根据你的请求得到相应的服务。调停者模式也可以举一个简单的例子来说明，例如一台计算机，CPU、内存、硬盘、显卡、声卡各种设备需要相互配合才能很好的工作，但是如果这些东西都直接连接到一起，计算机的布线将异常复杂，在这种情况下，主板作为一个调停者的身份出现，它将各个设备连接在一起而不需要每个设备之间直接交换数据，这样就减小了系统的耦合度和复杂度，如下图所示。迪米特法则用通俗的话来将就是不要和陌生人打交道，如果真的需要，找一个自己的朋友，让他替你和陌生人打交道。）

90、简述一下你了解的设计模式。
答：所谓设计模式，就是一套被反复使用的代码设计经验的总结（情境中一个问题经过证实的一个解决方案）。使用设计模式是为了可重用代码、让代码更容易被他人理解、保证代码可靠性。设计模式使人们可以更加简单方便的复用成功的设计和体系结构。将已证实的技术表述成设计模式也会使新系统开发者更加容易理解其设计思路。
在GoF的《Design Patterns: Elements of Reusable Object-Oriented Software》中给出了三类（创建型[对类的实例化过程的抽象化]、结构型[描述如何将类或对象结合在一起形成更大的结构]、行为型[对在不同的对象之间划分责任和算法的抽象化]）共23种设计模式，包括：Abstract Factory（抽象工厂模式），Builder（建造者模式），Factory Method（工厂方法模式），Prototype（原始模型模式），Singleton（单例模式）；Facade（门面模式），Adapter（适配器模式），Bridge（桥梁模式），Composite（合成模式），Decorator（装饰模式），Flyweight（享元模式），Proxy（代理模式）；Command（命令模式），Interpreter（解释器模式），Visitor（访问者模式），Iterator（迭代子模式），Mediator（调停者模式），Memento（备忘录模式），Observer（观察者模式），State（状态模式），Strategy（策略模式），Template Method（模板方法模式）， Chain Of Responsibility（责任链模式）。
面试被问到关于设计模式的知识时，可以拣最常用的作答，例如：
- 工厂模式：工厂类可以根据条件生成不同的子类实例，这些子类有一个公共的抽象父类并且实现了相同的方法，但是这些方法针对不同的数据进行了不同的操作（多态方法）。当得到子类的实例后，开发人员可以调用基类中的方法而不必考虑到底返回的是哪一个子类的实例。
- 代理模式：给一个对象提供一个代理对象，并由代理对象控制原对象的引用。实际开发中，按照使用目的的不同，代理可以分为：远程代理、虚拟代理、保护代理、Cache代理、防火墙代理、同步化代理、智能引用代理。
- 适配器模式：把一个类的接口变换成客户端所期待的另一种接口，从而使原本因接口不匹配而无法在一起使用的类能够一起工作。
- 模板方法模式：提供一个抽象类，将部分逻辑以具体方法或构造器的形式实现，然后声明一些抽象方法来迫使子类实现剩余的逻辑。不同的子类可以以不同的方式实现这些抽象方法（多态实现），从而实现不同的业务逻辑。
除此之外，还可以讲讲上面提到的门面模式、桥梁模式、单例模式、装潢模式（Collections工具类和I/O系统中都使用装潢模式）等，反正基本原则就是拣自己最熟悉的、用得最多的作答，以免言多必失。

91、用Java写一个单例类。
答：
- 饿汉式单例

public class Singleton {
    private Singleton(){}
    private static Singleton instance = new Singleton();
    public static Singleton getInstance(){
        return instance;
    }
}

    懒汉式单例

public class Singleton {
    private static Singleton instance = null;
    private Singleton() {}
    public static synchronized Singleton getInstance(){
        if (instance == null) instance ＝ new Singleton();
        return instance;
    }
}

注意：实现一个单例有两点注意事项，①将构造器私有，不允许外界通过构造器创建对象；②通过公开的静态方法向外界返回类的唯一实例。这里有一个问题可以思考：Spring的IoC容器可以为普通的类创建单例，它是怎么做到的呢？

92、什么是UML？
答：UML是统一建模语言（Unified Modeling Language）的缩写，它发表于1997年，综合了当时已经存在的面向对象的建模语言、方法和过程，是一个支持模型化和软件系统开发的图形化语言，为软件开发的所有阶段提供模型化和可视化支持。使用UML可以帮助沟通与交流，辅助应用设计和文档的生成，还能够阐释系统的结构和行为。

93、UML中有哪些常用的图？ 
答：UML定义了多种图形化的符号来描述软件系统部分或全部的静态结构和动态结构，包括：用例图（use case diagram）、类图（class diagram）、时序图（sequence diagram）、协作图（collaboration diagram）、状态图（statechart diagram）、活动图（activity diagram）、构件图（component diagram）、部署图（deployment diagram）等。在这些图形化符号中，有三种图最为重要，分别是：用例图（用来捕获需求，描述系统的功能，通过该图可以迅速的了解系统的功能模块及其关系）、类图（描述类以及类与类之间的关系，通过该图可以快速了解系统）、时序图（描述执行特定任务时对象之间的交互关系以及执行顺序，通过该图可以了解对象能接收的消息也就是说对象能够向外界提供的服务）。用例图： 这里写图片描述 类图： 这里写图片描述 时序图： 这里写图片描述


94、用Java写一个冒泡排序。
答：冒泡排序几乎是个程序员都写得出来，但是面试的时候如何写一个逼格高的冒泡排序却不是每个人都能做到，下面提供一个参考代码：

import java.util.Comparator;

/**
 * 排序器接口(策略模式: 将算法封装到具有共同接口的独立的类中使得它们可以相互替换)
 * @author骆昊
 *
 */
public interface Sorter {

   /**
    * 排序
    * @param list 待排序的数组
    */
   public <T extends Comparable<T>> void sort(T[] list);

   /**
    * 排序
    * @param list 待排序的数组
    * @param comp 比较两个对象的比较器
    */
   public <T> void sort(T[] list, Comparator<T> comp);
}

import java.util.Comparator;

/**
 * 冒泡排序
 * 
 * @author骆昊
 *
 */
public class BubbleSorter implements Sorter {

    @Override
    public <T extends Comparable<T>> void sort(T[] list) {
        boolean swapped = true;
        for (int i = 1, len = list.length; i < len && swapped; ++i) {
            swapped = false;
            for (int j = 0; j < len - i; ++j) {
                if (list[j].compareTo(list[j + 1]) > 0) {
                    T temp = list[j];
                    list[j] = list[j + 1];
                    list[j + 1] = temp;
                    swapped = true;
                }
            }
        }
    }

    @Override
    public <T> void sort(T[] list, Comparator<T> comp) {
        boolean swapped = true;
        for (int i = 1, len = list.length; i < len && swapped; ++i) {
            swapped = false;
            for (int j = 0; j < len - i; ++j) {
                if (comp.compare(list[j], list[j + 1]) > 0) {
                    T temp = list[j];
                    list[j] = list[j + 1];
                    list[j + 1] = temp;
                    swapped = true;
                }
            }
        }
    }
}

95、用Java写一个折半查找。
答：折半查找，也称二分查找、二分搜索，是一种在有序数组中查找某一特定元素的搜索算法。搜素过程从数组的中间元素开始，如果中间元素正好是要查找的元素，则搜素过程结束；如果某一特定元素大于或者小于中间元素，则在数组大于或小于中间元素的那一半中查找，而且跟开始一样从中间元素开始比较。如果在某一步骤数组已经为空，则表示找不到指定的元素。这种搜索算法每一次比较都使搜索范围缩小一半，其时间复杂度是O(logN)。
import java.util.Comparator;
public class MyUtil {
   public static <T extends Comparable<T>> int binarySearch(T[] x, T key) {
      return binarySearch(x, 0, x.length- 1, key);
   }

   // 使用循环实现的二分查找
   public static <T> int binarySearch(T[] x, T key, Comparator<T> comp) {
      int low = 0;
      int high = x.length - 1;
      while (low <= high) {
          int mid = (low + high) >>> 1;
          int cmp = comp.compare(x[mid], key);
          if (cmp < 0) {
            low= mid + 1;
          }
          else if (cmp > 0) {
            high= mid - 1;
          }
          else {
            return mid;
          }
      }
      return -1;
   }

   // 使用递归实现的二分查找
   private static<T extends Comparable<T>> int binarySearch(T[] x, int low, int high, T key) {
      if(low <= high) {
        int mid = low + ((high -low) >> 1);
        if(key.compareTo(x[mid])== 0) {
           return mid;
        }
        else if(key.compareTo(x[mid])< 0) {
           return binarySearch(x,low, mid - 1, key);
        }
        else {
           return binarySearch(x,mid + 1, high, key);
        }
      }
      return -1;
   }
}
说明：上面的代码中给出了折半查找的两个版本，一个用递归实现，一个用循环实现。需要注意的是计算中间位置时不应该使用(high+ low) / 2的方式，因为加法运算可能导致整数越界，这里应该使用以下三种方式之一：low + (high - low) / 2或low + (high – low) >> 1或(low + high) >>> 1（>>>是逻辑右移，是不带符号位的右移）
这部分主要是与Java Web和Web Service相关的面试题。

96、阐述Servlet和CGI的区别?
答：Servlet与CGI的区别在于Servlet处于服务器进程中，它通过多线程方式运行其service()方法，一个实例可以服务于多个请求，并且其实例一般不会销毁，而CGI对每个请求都产生新的进程，服务完成后就销毁，所以效率上低于Servlet。
补充：Sun Microsystems公司在1996年发布Servlet技术就是为了和CGI进行竞争，Servlet是一个特殊的Java程序，一个基于Java的Web应用通常包含一个或多个Servlet类。Servlet不能够自行创建并执行，它是在Servlet容器中运行的，容器将用户的请求传递给Servlet程序，并将Servlet的响应回传给用户。通常一个Servlet会关联一个或多个JSP页面。以前CGI经常因为性能开销上的问题被诟病，然而Fast CGI早就已经解决了CGI效率上的问题，所以面试的时候大可不必信口开河的诟病CGI，事实上有很多你熟悉的网站都使用了CGI技术。

97、Servlet接口中有哪些方法？
答：Servlet接口定义了5个方法，其中前三个方法与Servlet生命周期相关：
- void init(ServletConfig config) throws ServletException
- void service(ServletRequest req, ServletResponse resp) throws ServletException, java.io.IOException
- void destory()
- java.lang.String getServletInfo()
- ServletConfig getServletConfig()

Web容器加载Servlet并将其实例化后，Servlet生命周期开始，容器运行其init()方法进行Servlet的初始化；请求到达时调用Servlet的service()方法，service()方法会根据需要调用与请求对应的doGet或doPost等方法；当服务器关闭或项目被卸载时服务器会将Servlet实例销毁，此时会调用Servlet的destroy()方法。

98、转发（forward）和重定向（redirect）的区别？
答：forward是容器中控制权的转向，是服务器请求资源，服务器直接访问目标地址的URL，把那个URL 的响应内容读取过来，然后把这些内容再发给浏览器，浏览器根本不知道服务器发送的内容是从哪儿来的，所以它的地址栏中还是原来的地址。redirect就是服务器端根据逻辑，发送一个状态码，告诉浏览器重新去请求那个地址，因此从浏览器的地址栏中可以看到跳转后的链接地址，很明显redirect无法访问到服务器保护起来资源，但是可以从一个网站redirect到其他网站。forward更加高效，所以在满足需要时尽量使用forward（通过调用RequestDispatcher对象的forward()方法，该对象可以通过ServletRequest对象的getRequestDispatcher()方法获得），并且这样也有助于隐藏实际的链接；在有些情况下，比如需要访问一个其它服务器上的资源，则必须使用重定向（通过HttpServletResponse对象调用其sendRedirect()方法实现）。

99、JSP有哪些内置对象？作用分别是什么？
答：JSP有9个内置对象：
- request：封装客户端的请求，其中包含来自GET或POST请求的参数；
- response：封装服务器对客户端的响应；
- pageContext：通过该对象可以获取其他对象；
- session：封装用户会话的对象；
- application：封装服务器运行环境的对象；
- out：输出服务器响应的输出流对象；
- config：Web应用的配置对象；
- page：JSP页面本身（相当于Java程序中的this）；
- exception：封装页面抛出异常的对象。

    补充：如果用Servlet来生成网页中的动态内容无疑是非常繁琐的工作，另一方面，所有的文本和HTML标签都是硬编码，即使做出微小的修改，都需要进行重新编译。JSP解决了Servlet的这些问题，它是Servlet很好的补充，可以专门用作为用户呈现视图（View），而Servlet作为控制器（Controller）专门负责处理用户请求并转发或重定向到某个页面。基于Java的Web开发很多都同时使用了Servlet和JSP。JSP页面其实是一个Servlet，能够运行Servlet的服务器（Servlet容器）通常也是JSP容器，可以提供JSP页面的运行环境，Tomcat就是一个Servlet/JSP容器。第一次请求一个JSP页面时，Servlet/JSP容器首先将JSP页面转换成一个JSP页面的实现类，这是一个实现了JspPage接口或其子接口HttpJspPage的Java类。JspPage接口是Servlet的子接口，因此每个JSP页面都是一个Servlet。转换成功后，容器会编译Servlet类，之后容器加载和实例化Java字节码，并执行它通常对Servlet所做的生命周期操作。对同一个JSP页面的后续请求，容器会查看这个JSP页面是否被修改过，如果修改过就会重新转换并重新编译并执行。如果没有则执行内存中已经存在的Servlet实例。我们可以看一段JSP代码对应的Java程序就知道一切了，而且9个内置对象的神秘面纱也会被揭开。

JSP页面：

<%@ page pageEncoding="UTF-8"%>
<%
String path = request.getContextPath();
String basePath = request.getScheme() + "://" + request.getServerName() + ":" + request.getServerPort() + path + "/";
%>

<!DOCTYPE html>
<html>
  <head>
    <base href="<%=basePath%>">
    <title>首页</title>
    <style type="text/css">
        * { font-family: "Arial"; }
    </style>
  </head>

  <body>
    <h1>Hello, World!</h1>
    <hr/>
    <h2>Current time is: <%= new java.util.Date().toString() %></h2>
  </body>
</html>

对应的Java代码：

package org.apache.jsp;
import javax.servlet.*;
import javax.servlet.http.*;
import javax.servlet.jsp.*;
public final class index_jsp extends org.apache.jasper.runtime.HttpJspBase
        implements org.apache.jasper.runtime.JspSourceDependent {

    private static final javax.servlet.jsp.JspFactory _jspxFactory = javax.servlet.jsp.JspFactory
            .getDefaultFactory();

    private static java.util.Map<java.lang.String, java.lang.Long> _jspx_dependants;

    private javax.el.ExpressionFactory _el_expressionfactory;
    private org.apache.tomcat.InstanceManager _jsp_instancemanager;

    public java.util.Map<java.lang.String, java.lang.Long> getDependants() {
        return _jspx_dependants;
    }

    public void _jspInit() {
        _el_expressionfactory = _jspxFactory.getJspApplicationContext(
                getServletConfig().getServletContext()).getExpressionFactory();
        _jsp_instancemanager = org.apache.jasper.runtime.InstanceManagerFactory
                .getInstanceManager(getServletConfig());
    }

    public void _jspDestroy() {
    }

    public void _jspService(
            final javax.servlet.http.HttpServletRequest request,
            final javax.servlet.http.HttpServletResponse response)
            throws java.io.IOException, javax.servlet.ServletException {
        // 内置对象就是在这里定义的
        final javax.servlet.jsp.PageContext pageContext;
        javax.servlet.http.HttpSession session = null;
        final javax.servlet.ServletContext application;
        final javax.servlet.ServletConfig config;
        javax.servlet.jsp.JspWriter out = null;
        final java.lang.Object page = this;
        javax.servlet.jsp.JspWriter _jspx_out = null;
        javax.servlet.jsp.PageContext _jspx_page_context = null;

        try {
            response.setContentType("text/html;charset=UTF-8");
            pageContext = _jspxFactory.getPageContext(this, request, response,
                    null, true, 8192, true);
            _jspx_page_context = pageContext;
            application = pageContext.getServletContext();
            config = pageContext.getServletConfig();
            session = pageContext.getSession();
            out = pageContext.getOut();
            _jspx_out = out;

            out.write('\r');
            out.write('\n');

            String path = request.getContextPath();
            String basePath = request.getScheme() + "://"
                    + request.getServerName() + ":" + request.getServerPort()
                    + path + "/";
// 以下代码通过输出流将HTML标签输出到浏览器中
            out.write("\r\n");
            out.write("\r\n");
            out.write("<!DOCTYPE html>\r\n");
            out.write("<html>\r\n");
            out.write("  <head>\r\n");
            out.write("    <base href=\"");
            out.print(basePath);
            out.write("\">\r\n");
            out.write("    <title>首页</title>\r\n");
            out.write("    <style type=\"text/css\">\r\n");
            out.write("    \t* { font-family: \"Arial\"; }\r\n");
            out.write("    </style>\r\n");
            out.write("  </head>\r\n");
            out.write("  \r\n");
            out.write("  <body>\r\n");
            out.write("    <h1>Hello, World!</h1>\r\n");
            out.write("    <hr/>\r\n");
            out.write("    <h2>Current time is: ");
            out.print(new java.util.Date().toString());
            out.write("</h2>\r\n");
            out.write("  </body>\r\n");
            out.write("</html>\r\n");
        } catch (java.lang.Throwable t) {
            if (!(t instanceof javax.servlet.jsp.SkipPageException)) {
                out = _jspx_out;
                if (out != null && out.getBufferSize() != 0)
                    try {
                        out.clearBuffer();
                    } catch (java.io.IOException e) {
                    }
                if (_jspx_page_context != null)
                    _jspx_page_context.handlePageException(t);
                else
                    throw new ServletException(t);
            }
        } finally {
            _jspxFactory.releasePageContext(_jspx_page_context);
        }
    }
}

100、get和post请求的区别？
答：
①get请求用来从服务器上获得资源，而post是用来向服务器提交数据；
②get将表单中数据按照name=value的形式，添加到action 所指向的URL 后面，并且两者使用"?"连接，而各个变量之间使用"&"连接；post是将表单中的数据放在HTTP协议的请求头或消息体中，传递到action所指向URL；
③get传输的数据要受到URL长度限制（1024字节）；而post可以传输大量的数据，上传文件通常要使用post方式；
④使用get时参数会显示在地址栏上，如果这些数据不是敏感数据，那么可以使用get；对于敏感数据还是应用使用post；
⑤get使用MIME类型application/x-www-form-urlencoded的URL编码（也叫百分号编码）文本的格式传递参数，保证被传送的参数由遵循规范的文本组成，例如一个空格的编码是"%20"。

101、常用的Web服务器有哪些？
答：Unix和Linux平台下使用最广泛的免费HTTP服务器是Apache服务器，而Windows平台的服务器通常使用IIS作为Web服务器。选择Web服务器应考虑的因素有：性能、安全性、日志和统计、虚拟主机、代理服务器、缓冲服务和集成应用程序等。下面是对常见服务器的简介：
- IIS：Microsoft的Web服务器产品，全称是Internet Information Services。IIS是允许在公共Intranet或Internet上发布信息的Web服务器。IIS是目前最流行的Web服务器产品之一，很多著名的网站都是建立在IIS的平台上。IIS提供了一个图形界面的管理工具，称为Internet服务管理器，可用于监视配置和控制Internet服务。IIS是一种Web服务组件，其中包括Web服务器、FTP服务器、NNTP服务器和SMTP服务器，分别用于网页浏览、文件传输、新闻服务和邮件发送等方面，它使得在网络（包括互联网和局域网）上发布信息成了一件很容易的事。它提供ISAPI(Intranet Server API）作为扩展Web服务器功能的编程接口；同时，它还提供一个Internet数据库连接器，可以实现对数据库的查询和更新。
- Kangle：Kangle Web服务器是一款跨平台、功能强大、安全稳定、易操作的高性能Web服务器和反向代理服务器软件。此外，Kangle也是一款专为做虚拟主机研发的Web服务器。实现虚拟主机独立进程、独立身份运行。用户之间安全隔离，一个用户出问题不影响其他用户。支持PHP、ASP、ASP.NET、Java、Ruby等多种动态开发语言。
- WebSphere：WebSphere Application Server是功能完善、开放的Web应用程序服务器，是IBM电子商务计划的核心部分，它是基于Java的应用环境，用于建立、部署和管理Internet和Intranet Web应用程序，适应各种Web应用程序服务器的需要。
- WebLogic：WebLogic Server是一款多功能、基于标准的Web应用服务器，为企业构建企业应用提供了坚实的基础。针对各种应用开发、关键性任务的部署，各种系统和数据库的集成、跨Internet协作等Weblogic都提供了相应的支持。由于它具有全面的功能、对开放标准的遵从性、多层架构、支持基于组件的开发等优势，很多公司的企业级应用都选择它来作为开发和部署的环境。WebLogic Server在使应用服务器成为企业应用架构的基础方面一直处于领先地位，为构建集成化的企业级应用提供了稳固的基础。
- Apache：目前Apache仍然是世界上用得最多的Web服务器，其市场占有率很长时间都保持在60%以上（目前的市场份额约40%左右）。世界上很多著名的网站都是Apache的产物，它的成功之处主要在于它的源代码开放、有一支强大的开发团队、支持跨平台的应用（可以运行在几乎所有的Unix、Windows、Linux系统平台上）以及它的可移植性等方面。
- Tomcat：Tomcat是一个开放源代码、运行Servlet和JSP的容器。Tomcat实现了Servlet和JSP规范。此外，Tomcat还实现了Apache-Jakarta规范而且比绝大多数商业应用软件服务器要好，因此目前也有不少的Web服务器都选择了Tomcat。
- Nginx：读作"engine x"，是一个高性能的HTTP和反向代理服务器，也是一个IMAP/POP3/SMTP代理服务器。 Nginx是由Igor Sysoev为俄罗斯访问量第二的Rambler站点开发的，第一个公开版本0.1.0发布于2004年10月4日。其将源代码以类BSD许可证的形式发布，因它的稳定性、丰富的功能集、示例配置文件和低系统资源的消耗而闻名。在2014年下半年，Nginx的市场份额达到了14%。

102、JSP和Servlet是什么关系？
答：其实这个问题在上面已经阐述过了，Servlet是一个特殊的Java程序，它运行于服务器的JVM中，能够依靠服务器的支持向浏览器提供显示内容。JSP本质上是Servlet的一种简易形式，JSP会被服务器处理成一个类似于Servlet的Java程序，可以简化页面内容的生成。Servlet和JSP最主要的不同点在于，Servlet的应用逻辑是在Java文件中，并且完全从表示层中的HTML分离开来。而JSP的情况是Java和HTML可以组合成一个扩展名为.jsp的文件。有人说，Servlet就是在Java中写HTML，而JSP就是在HTML中写Java代码，当然这个说法是很片面且不够准确的。JSP侧重于视图，Servlet更侧重于控制逻辑，在MVC架构模式中，JSP适合充当视图（view）而Servlet适合充当控制器（controller）。

103、讲解JSP中的四种作用域。
答：JSP中的四种作用域包括page、request、session和application，具体来说：
- page代表与一个页面相关的对象和属性。
- request代表与Web客户机发出的一个请求相关的对象和属性。一个请求可能跨越多个页面，涉及多个Web组件；需要在页面显示的临时数据可以置于此作用域。
- session代表与某个用户与服务器建立的一次会话相关的对象和属性。跟某个用户相关的数据应该放在用户自己的session中。
- application代表与整个Web应用程序相关的对象和属性，它实质上是跨越整个Web应用程序，包括多个页面、请求和会话的一个全局作用域。

104、如何实现JSP或Servlet的单线程模式？
答：
对于JSP页面，可以通过page指令进行设置。
<%@page isThreadSafe=”false”%>
对于Servlet，可以让自定义的Servlet实现SingleThreadModel标识接口。
说明：如果将JSP或Servlet设置成单线程工作模式，会导致每个请求创建一个Servlet实例，这种实践将导致严重的性能问题（服务器的内存压力很大，还会导致频繁的垃圾回收），所以通常情况下并不会这么做。

105、实现会话跟踪的技术有哪些？
答：由于HTTP协议本身是无状态的，服务器为了区分不同的用户，就需要对用户会话进行跟踪，简单的说就是为用户进行登记，为用户分配唯一的ID，下一次用户在请求中包含此ID，服务器据此判断到底是哪一个用户。
①URL 重写：在URL中添加用户会话的信息作为请求的参数，或者将唯一的会话ID添加到URL结尾以标识一个会话。
②设置表单隐藏域：将和会话跟踪相关的字段添加到隐式表单域中，这些信息不会在浏览器中显示但是提交表单时会提交给服务器。
这两种方式很难处理跨越多个页面的信息传递，因为如果每次都要修改URL或在页面中添加隐式表单域来存储用户会话相关信息，事情将变得非常麻烦。
③cookie：cookie有两种，一种是基于窗口的，浏览器窗口关闭后，cookie就没有了；另一种是将信息存储在一个临时文件中，并设置存在的时间。当用户通过浏览器和服务器建立一次会话后，会话ID就会随响应信息返回存储在基于窗口的cookie中，那就意味着只要浏览器没有关闭，会话没有超时，下一次请求时这个会话ID又会提交给服务器让服务器识别用户身份。会话中可以为用户保存信息。会话对象是在服务器内存中的，而基于窗口的cookie是在客户端内存中的。如果浏览器禁用了cookie，那么就需要通过下面两种方式进行会话跟踪。当然，在使用cookie时要注意几点：首先不要在cookie中存放敏感信息；其次cookie存储的数据量有限（4k），不能将过多的内容存储cookie中；再者浏览器通常只允许一个站点最多存放20个cookie。当然，和用户会话相关的其他信息（除了会话ID）也可以存在cookie方便进行会话跟踪。
④HttpSession：在所有会话跟踪技术中，HttpSession对象是最强大也是功能最多的。当一个用户第一次访问某个网站时会自动创建HttpSession，每个用户可以访问他自己的HttpSession。可以通过HttpServletRequest对象的getSession方法获得HttpSession，通过HttpSession的setAttribute方法可以将一个值放在HttpSession中，通过调用HttpSession对象的getAttribute方法，同时传入属性名就可以获取保存在HttpSession中的对象。与上面三种方式不同的是，HttpSession放在服务器的内存中，因此不要将过大的对象放在里面，即使目前的Servlet容器可以在内存将满时将HttpSession中的对象移到其他存储设备中，但是这样势必影响性能。添加到HttpSession中的值可以是任意Java对象，这个对象最好实现了Serializable接口，这样Servlet容器在必要的时候可以将其序列化到文件中，否则在序列化时就会出现异常。
**补充：**HTML5中可以使用Web Storage技术通过JavaScript来保存数据，例如可以使用localStorage和sessionStorage来保存用户会话的信息，也能够实现会话跟踪。

106、过滤器有哪些作用和用法？
答： Java Web开发中的过滤器（filter）是从Servlet 2.3规范开始增加的功能，并在Servlet 2.4规范中得到增强。对Web应用来说，过滤器是一个驻留在服务器端的Web组件，它可以截取客户端和服务器之间的请求与响应信息，并对这些信息进行过滤。当Web容器接受到一个对资源的请求时，它将判断是否有过滤器与这个资源相关联。如果有，那么容器将把请求交给过滤器进行处理。在过滤器中，你可以改变请求的内容，或者重新设置请求的报头信息，然后再将请求发送给目标资源。当目标资源对请求作出响应时候，容器同样会将响应先转发给过滤器，在过滤器中你可以对响应的内容进行转换，然后再将响应发送到客户端。
常见的过滤器用途主要包括：对用户请求进行统一认证、对用户的访问请求进行记录和审核、对用户发送的数据进行过滤或替换、转换图象格式、对响应内容进行压缩以减少传输量、对请求或响应进行加解密处理、触发资源访问事件、对XML的输出应用XSLT等。
和过滤器相关的接口主要有：Filter、FilterConfig和FilterChain。
编码过滤器的例子：
import java.io.IOException;
import javax.servlet.Filter;
import javax.servlet.FilterChain;
import javax.servlet.FilterConfig;
import javax.servlet.ServletException;
import javax.servlet.ServletRequest;
import javax.servlet.ServletResponse;
import javax.servlet.annotation.WebFilter;
import javax.servlet.annotation.WebInitParam;

@WebFilter(urlPatterns = { "*" }, 
        initParams = {@WebInitParam(name="encoding", value="utf-8")})
public class CodingFilter implements Filter {
    private String defaultEncoding = "utf-8";

    @Override
    public void destroy() {
    }

    @Override
    public void doFilter(ServletRequest req, ServletResponse resp,
            FilterChain chain) throws IOException, ServletException {
        req.setCharacterEncoding(defaultEncoding);
        resp.setCharacterEncoding(defaultEncoding);
        chain.doFilter(req, resp);
    }

    @Override
    public void init(FilterConfig config) throws ServletException {
        String encoding = config.getInitParameter("encoding");
        if (encoding != null) {
            defaultEncoding = encoding;
        }
    }
}

下载计数过滤器的例子：

import java.io.File;
import java.io.FileReader;
import java.io.FileWriter;
import java.io.IOException;
import java.util.Properties;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

import javax.servlet.Filter;
import javax.servlet.FilterChain;
import javax.servlet.FilterConfig;
import javax.servlet.ServletException;
import javax.servlet.ServletRequest;
import javax.servlet.ServletResponse;
import javax.servlet.annotation.WebFilter;
import javax.servlet.http.HttpServletRequest;

@WebFilter(urlPatterns = {"/*"})
public class DownloadCounterFilter implements Filter {

    private ExecutorService executorService = Executors.newSingleThreadExecutor();
    private Properties downloadLog;
    private File logFile;

    @Override
    public void destroy() {
        executorService.shutdown();
    }

    @Override
    public void doFilter(ServletRequest req, ServletResponse resp,
            FilterChain chain) throws IOException, ServletException {
        HttpServletRequest request = (HttpServletRequest) req;
        final String uri = request.getRequestURI();
        executorService.execute(new Runnable() {

            @Override
            public void run() {
                String value = downloadLog.getProperty(uri);
                if(value == null) {
                    downloadLog.setProperty(uri, "1");
                }
                else {
                    int count = Integer.parseInt(value);
                    downloadLog.setProperty(uri, String.valueOf(++count));
                }
                try {
                    downloadLog.store(new FileWriter(logFile), "");
                } 
                catch (IOException e) {
                    e.printStackTrace();
                }
            }
        });
        chain.doFilter(req, resp);
    }

    @Override
    public void init(FilterConfig config) throws ServletException {
        String appPath = config.getServletContext().getRealPath("/");
        logFile = new File(appPath, "downloadLog.txt");
        if(!logFile.exists()) {
            try {
                logFile.createNewFile();
            } 
            catch(IOException e) {
                e.printStackTrace();
            }
        }
        downloadLog = new Properties();
        try {
            downloadLog.load(new FileReader(logFile));
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

}

    说明：这里使用了Servlet 3规范中的注解来部署过滤器，当然也可以在web.xml中使用<filter>和<filter-mapping>标签部署过滤器，如108题中所示。

107、监听器有哪些作用和用法？
答：Java Web开发中的监听器（listener）就是application、session、request三个对象创建、销毁或者往其中添加修改删除属性时自动执行代码的功能组件，如下所示：
①ServletContextListener：对Servlet上下文的创建和销毁进行监听。
②ServletContextAttributeListener：监听Servlet上下文属性的添加、删除和替换。
③HttpSessionListener：对Session的创建和销毁进行监听。

    补充：session的销毁有两种情况：1). session超时（可以在web.xml中通过<session-config>/<session-timeout>标签配置超时时间）；2). 通过调用session对象的invalidate()方法使session失效。

④HttpSessionAttributeListener：对Session对象中属性的添加、删除和替换进行监听。
⑤ServletRequestListener：对请求对象的初始化和销毁进行监听。
⑥ServletRequestAttributeListener：对请求对象属性的添加、删除和替换进行监听。

下面是一个统计网站最多在线人数监听器的例子。

import javax.servlet.ServletContextEvent;
import javax.servlet.ServletContextListener;
import javax.servlet.annotation.WebListener;

/**
 上下文监听器，在服务器启动时初始化onLineCount和maxOnLineCount两个变量
 并将其置于服务器上下文（ServletContext）中，其初始值都是0
*/
@WebListener
public class InitListener implements ServletContextListener {

    @Override
    public void contextDestroyed(ServletContextEvent evt) {
    }

    @Override
    public void contextInitialized(ServletContextEvent evt) {
        evt.getServletContext().setAttribute("onLineCount", 0);
        evt.getServletContext().setAttribute("maxOnLineCount", 0);
    }

}



import java.text.DateFormat;
import java.text.SimpleDateFormat;
import java.util.Date;

import javax.servlet.ServletContext;
import javax.servlet.annotation.WebListener;
import javax.servlet.http.HttpSessionEvent;
import javax.servlet.http.HttpSessionListener;

/**
 会话监听器，在用户会话创建和销毁的时候根据情况
 修改onLineCount和maxOnLineCount的值
*/
@WebListener
public class MaxCountListener implements HttpSessionListener {

    @Override
    public void sessionCreated(HttpSessionEvent event) {
        ServletContext ctx = event.getSession().getServletContext();
        int count = Integer.parseInt(ctx.getAttribute("onLineCount").toString());
        count++;
        ctx.setAttribute("onLineCount", count);
        int maxOnLineCount = Integer.parseInt(ctx.getAttribute("maxOnLineCount").toString());
        if (count > maxOnLineCount) {
            ctx.setAttribute("maxOnLineCount", count);
            DateFormat df = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");
            ctx.setAttribute("date", df.format(new Date()));
        }
    }

    @Override
    public void sessionDestroyed(HttpSessionEvent event) {
        ServletContext app = event.getSession().getServletContext();
        int count = Integer.parseInt(app.getAttribute("onLineCount").toString());
        count--;
        app.setAttribute("onLineCount", count);
    }
}

    说明：这里使用了Servlet 3规范中的@WebListener注解配置监听器，当然你可以在web.xml文件中用<listener>标签配置监听器，如108题中所示。

108、web.xml文件中可以配置哪些内容？
答：web.xml用于配置Web应用的相关信息，如：监听器（listener）、过滤器（filter）、 Servlet、相关参数、会话超时时间、安全验证方式、错误页面等，下面是一些开发中常见的配置：

①配置Spring上下文加载监听器加载Spring配置文件并创建IoC容器：

 <context-param>
     <param-name>contextConfigLocation</param-name>
    <param-value>classpath:applicationContext.xml</param-value>
  </context-param>

  <listener>
     <listener-class>
       org.springframework.web.context.ContextLoaderListener
     </listener-class>
  </listener>

②配置Spring的OpenSessionInView过滤器来解决延迟加载和Hibernate会话关闭的矛盾：

 <filter>
      <filter-name>openSessionInView</filter-name>
      <filter-class>
         org.springframework.orm.hibernate3.support.OpenSessionInViewFilter
      </filter-class>
  </filter>

  <filter-mapping>
      <filter-name>openSessionInView</filter-name>
      <url-pattern>/*</url-pattern>
  </filter-mapping>

③配置会话超时时间为10分钟：

 <session-config>
      <session-timeout>10</session-timeout>
  </session-config>

④配置404和Exception的错误页面：

 <error-page>
      <error-code>404</error-code>
      <location>/error.jsp</location>
  </error-page>

  <error-page>
      <exception-type>java.lang.Exception</exception-type>
      <location>/error.jsp</location>
  </error-page>

⑤配置安全认证方式：

<security-constraint>
      <web-resource-collection>
          <web-resource-name>ProtectedArea</web-resource-name>
          <url-pattern>/admin/*</url-pattern>
          <http-method>GET</http-method>
          <http-method>POST</http-method>
      </web-resource-collection>
      <auth-constraint>
          <role-name>admin</role-name>
      </auth-constraint>
  </security-constraint>

  <login-config>
      <auth-method>BASIC</auth-method>
  </login-config>

  <security-role>
      <role-name>admin</role-name>
  </security-role>

    说明：对Servlet（小服务）、Listener（监听器）和Filter（过滤器）等Web组件的配置，Servlet 3规范提供了基于注解的配置方式，可以分别使用@WebServlet、@WebListener、@WebFilter注解进行配置。

    补充：如果Web提供了有价值的商业信息或者是敏感数据，那么站点的安全性就是必须考虑的问题。安全认证是实现安全性的重要手段，认证就是要解决“Are you who you say you are?”的问题。认证的方式非常多，简单说来可以分为三类：
    A. What you know? — 口令
    B. What you have? — 数字证书（U盾、密保卡）
    C. Who you are? — 指纹识别、虹膜识别
    在Tomcat中可以通过建立安全套接字层（Secure Socket Layer, SSL）以及通过基本验证或表单验证来实现对安全性的支持。

109、你的项目中使用过哪些JSTL标签？
答：项目中主要使用了JSTL的核心标签库，包括<c:if>、<c:choose>、<c: when>、<c: otherwise>、<c:forEach>等，主要用于构造循环和分支结构以控制显示逻辑。

    说明：虽然JSTL标签库提供了core、sql、fmt、xml等标签库，但是实际开发中建议只使用核心标签库（core），而且最好只使用分支和循环标签并辅以表达式语言（EL），这样才能真正做到数据显示和业务逻辑的分离，这才是最佳实践。

110、使用标签库有什么好处？如何自定义JSP标签？
答：使用标签库的好处包括以下几个方面：
- 分离JSP页面的内容和逻辑，简化了Web开发；
- 开发者可以创建自定义标签来封装业务逻辑和显示逻辑；
- 标签具有很好的可移植性、可维护性和可重用性；
- 避免了对Scriptlet（小脚本）的使用（很多公司的项目开发都不允许在JSP中书写小脚本）

自定义JSP标签包括以下几个步骤：
- 编写一个Java类实现实现Tag/BodyTag/IterationTag接口（开发中通常不直接实现这些接口而是继承TagSupport/BodyTagSupport/SimpleTagSupport类，这是对缺省适配模式的应用），重写doStartTag()、doEndTag()等方法，定义标签要完成的功能
- 编写扩展名为tld的标签描述文件对自定义标签进行部署，tld文件通常放在WEB-INF文件夹下或其子目录中
- 在JSP页面中使用taglib指令引用该标签库

下面是一个自定义标签库的例子。

步骤1 - 标签类源代码TimeTag.java：

package com.jackfrued.tags;

import java.io.IOException;
import java.text.SimpleDateFormat;
import java.util.Date;

import javax.servlet.jsp.JspException;
import javax.servlet.jsp.JspWriter;
import javax.servlet.jsp.tagext.TagSupport;

public class TimeTag extends TagSupport {
    private static final long serialVersionUID = 1L;

    private String format = "yyyy-MM-dd hh:mm:ss";
    private String foreColor = "black";
    private String backColor = "white";

    public int doStartTag() throws JspException {
         SimpleDateFormat sdf = new SimpleDateFormat(format);
         JspWriter writer = pageContext.getOut();
         StringBuilder sb = new StringBuilder();
         sb.append(String.format("<span style='color:%s;background-color:%s'>%s</span>",
             foreColor, backColor, sdf.format(new Date())));
         try {
           writer.print(sb.toString());
         } catch(IOException e) {
           e.printStackTrace();
         }
         return SKIP_BODY;
      }

    public void setFormat(String format) {
        this.format = format;
    }

    public void setForeColor(String foreColor) {
        this.foreColor = foreColor;
    }

    public void setBackColor(String backColor) {
        this.backColor = backColor;
    }
}

步骤2 - 编写标签库描述文件my.tld：

<?xml version="1.0" encoding="UTF-8" ?>
<taglib xmlns="http://java.sun.com/xml/ns/j2ee"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://java.sun.com/xml/ns/j2ee
    http://java.sun.com/xml/ns/j2ee/web-jsptaglibrary_2_0.xsd"
    version="2.0">

    <description>定义标签库</description>
    <tlib-version>1.0</tlib-version>
    <short-name>MyTag</short-name>
    <tag>
        <name>time</name>
        <tag-class>com.jackfrued.tags.TimeTag</tag-class>
        <body-content>empty</body-content>
        <attribute>
            <name>format</name>
            <required>false</required>
        </attribute>
        <attribute>
            <name>foreColor</name>
        </attribute>
        <attribute>
            <name>backColor</name>
        </attribute>
    </tag>
</taglib>

步骤3 - 在JSP页面中使用自定义标签：

<%@ page pageEncoding="UTF-8"%>
<%@ taglib prefix="my" uri="/WEB-INF/tld/my.tld" %>
<%
String path = request.getContextPath();
String basePath = request.getScheme() + "://" + request.getServerName() + ":" + request.getServerPort() + path + "/";
%>

<!DOCTYPE html>
<html>
  <head>
    <base href="<%=basePath%>">
    <title>首页</title>
    <style type="text/css">
        * { font-family: "Arial"; font-size:72px; }
    </style>
  </head>

  <body>
    <my:time format="yyyy-MM-dd" backColor="blue" foreColor="yellow"/>
  </body>
</html>

    提示：如果要将自定义的标签库发布成JAR文件，需要将标签库描述文件（tld文件）放在JAR文件的META-INF目录下，可以JDK中的jar工具完成JAR文件的生成。

111、说一下表达式语言（EL）的隐式对象及其作用。
答：EL的隐式对象包括：pageContext、initParam（访问上下文参数）、param（访问请求参数）、paramValues、header（访问请求头）、headerValues、cookie（访问cookie）、applicationScope（访问application作用域）、sessionScope（访问session作用域）、requestScope（访问request作用域）、pageScope（访问page作用域）。

用法如下所示：

${pageContext.request.method}
${pageContext["request"]["method"]}
${pageContext.request["method"]}
${pageContext["request"].method}
${initParam.defaultEncoding}
${header["accept-language"]}
${headerValues["accept-language"][0]}
${cookie.jsessionid.value}
${sessionScope.loginUser.username}

    补充：表达式语言的.和[]运算作用是一致的，唯一的差别在于如果访问的属性名不符合Java标识符命名规则，例如上面的accept-language就不是一个有效的Java标识符，那么这时候就只能用[]运算符而不能使用.运算符获取它的值

112、表达式语言（EL）支持哪些运算符？
答：除了.和[]运算符，EL还提供了：
- 算术运算符：+、-、*、/或div、%或mod
- 关系运算符：==或eq、!=或ne、>或gt、>=或ge、<或lt、<=或le
- 逻辑运算符：&&或and、||或or、!或not
- 条件运算符：${statement? A : B}（跟Java的条件运算符类似）
- empty运算符：检查一个值是否为null或者空（数组长度为0或集合中没有元素也返回true）

113、Java Web开发的Model 1和Model 2分别指的是什么？
答：Model 1是以页面为中心的Java Web开发，使用JSP+JavaBean技术将页面显示逻辑和业务逻辑处理分开，JSP实现页面显示，JavaBean对象用来保存数据和实现业务逻辑。Model 2是基于MVC（模型-视图-控制器，Model-View-Controller）架构模式的开发模型，实现了模型和视图的彻底分离，利于团队开发和代码复用，如下图所示。

114、Servlet 3中的异步处理指的是什么？
答：在Servlet 3中引入了一项新的技术可以让Servlet异步处理请求。有人可能会质疑，既然都有多线程了，还需要异步处理请求吗？答案是肯定的，因为如果一个任务处理时间相当长，那么Servlet或Filter会一直占用着请求处理线程直到任务结束，随着并发用户的增加，容器将会遭遇线程超出的风险，这这种情况下很多的请求将会被堆积起来而后续的请求可能会遭遇拒绝服务，直到有资源可以处理请求为止。异步特性可以帮助应用节省容器中的线程，特别适合执行时间长而且用户需要得到结果的任务，如果用户不需要得到结果则直接将一个Runnable对象交给Executor并立即返回即可。

    补充：多线程在Java诞生初期无疑是一个亮点，而Servlet单实例多线程的工作方式也曾为其赢得美名，然而技术的发展往往会颠覆我们很多的认知，就如同当年爱因斯坦的相对论颠覆了牛顿的经典力学一般。事实上，异步处理绝不是Serlvet 3首创，如果你了解Node.js的话，对Servlet 3的这个重要改进就不以为奇了。

下面是一个支持异步处理请求的Servlet的例子。

import java.io.IOException;
import javax.servlet.AsyncContext;
import javax.servlet.ServletException;
import javax.servlet.annotation.WebServlet;
import javax.servlet.http.HttpServlet;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;

@WebServlet(urlPatterns = {"/async"}, asyncSupported = true)
public class AsyncServlet extends HttpServlet {
    private static final long serialVersionUID = 1L;

    @Override
    public void doGet(HttpServletRequest req, HttpServletResponse resp)
            throws ServletException, IOException {
        // 开启Tomcat异步Servlet支持
        req.setAttribute("org.apache.catalina.ASYNC_SUPPORTED", true);

        final AsyncContext ctx = req.startAsync();  // 启动异步处理的上下文
        // ctx.setTimeout(30000);
        ctx.start(new Runnable() {

            @Override
            public void run() {
                // 在此处添加异步处理的代码

                ctx.complete();
            }
        });
    }
}

115、如何在基于Java的Web项目中实现文件上传和下载？
答：在Sevlet 3 以前，Servlet API中没有支持上传功能的API，因此要实现上传功能需要引入第三方工具从POST请求中获得上传的附件或者通过自行处理输入流来获得上传的文件，我们推荐使用Apache的commons-fileupload。
从Servlet 3开始，文件上传变得无比简单，相信看看下面的例子一切都清楚了。

上传页面index.jsp：

<%@ page pageEncoding="utf-8"%>
<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Photo Upload</title>
</head>
<body>
<h1>Select your photo and upload</h1>
<hr/>
<div style="color:red;font-size:14px;">${hint}</div>
<form action="UploadServlet" method="post" enctype="multipart/form-data">
    Photo file: <input type="file" name="photo" />
    <input type="submit" value="Upload" />
</form>
</body>
</html>

支持上传的Servlet：

package com.jackfrued.servlet;
import java.io.IOException;
import javax.servlet.ServletException;
import javax.servlet.annotation.MultipartConfig;
import javax.servlet.annotation.WebServlet;
import javax.servlet.http.HttpServlet;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import javax.servlet.http.Part;

@WebServlet("/UploadServlet")
@MultipartConfig
public class UploadServlet extends HttpServlet {
    private static final long serialVersionUID = 1L;

    protected void doPost(HttpServletRequest request,
            HttpServletResponse response) throws ServletException, IOException {
        // 可以用request.getPart()方法获得名为photo的上传附件
        // 也可以用request.getParts()获得所有上传附件（多文件上传）
        // 然后通过循环分别处理每一个上传的文件
        Part part = request.getPart("photo");
        if (part != null && part.getSubmittedFileName().length() > 0) {
            // 用ServletContext对象的getRealPath()方法获得上传文件夹的绝对路径
            String savePath = request.getServletContext().getRealPath("/upload");
            // Servlet 3.1规范中可以用Part对象的getSubmittedFileName()方法获得上传的文件名
            // 更好的做法是为上传的文件进行重命名（避免同名文件的相互覆盖）
            part.write(savePath + "/" + part.getSubmittedFileName());
            request.setAttribute("hint", "Upload Successfully!");
        } else {
            request.setAttribute("hint", "Upload failed!");
        }
        // 跳转回到上传页面
        request.getRequestDispatcher("index.jsp").forward(request, response);
    }
}

116、服务器收到用户提交的表单数据，到底是调用Servlet的doGet()还是doPost()方法？
答：HTML的<form>元素有一个method属性，用来指定提交表单的方式，其值可以是get或post。我们自定义的Servlet一般情况下会重写doGet()或doPost()两个方法之一或全部，如果是GET请求就调用doGet()方法，如果是POST请求就调用doPost()方法，那为什么为什么这样呢？我们自定义的Servlet通常继承自HttpServlet，HttpServlet继承自GenericServlet并重写了其中的service()方法，这个方法是Servlet接口中定义的。HttpServlet重写的service()方法会先获取用户请求的方法，然后根据请求方法调用doGet()、doPost()、doPut()、doDelete()等方法，如果在自定义Servlet中重写了这些方法，那么显然会调用重写过的（自定义的）方法，这显然是对模板方法模式的应用（如果不理解，请参考阎宏博士的《Java与模式》一书的第37章）。当然，自定义Servlet中也可以直接重写service()方法，那么不管是哪种方式的请求，都可以通过自己的代码进行处理，这对于不区分请求方法的场景比较合适。

117、JSP中的静态包含和动态包含有什么区别？
答：静态包含是通过JSP的include指令包含页面，动态包含是通过JSP标准动作<jsp:forward>包含页面。静态包含是编译时包含，如果包含的页面不存在则会产生编译错误，而且两个页面的"contentType"属性应保持一致，因为两个页面会合二为一，只产生一个class文件，因此被包含页面发生的变动再包含它的页面更新前不会得到更新。动态包含是运行时包含，可以向被包含的页面传递参数，包含页面和被包含页面是独立的，会编译出两个class文件，如果被包含的页面不存在，不会产生编译错误，也不影响页面其他部分的执行。代码如下所示：

<%-- 静态包含 --%>
<%@ include file="..." %>

<%-- 动态包含 --%>
<jsp:include page="...">
    <jsp:param name="..." value="..." />
</jsp:include>

118、Servlet中如何获取用户提交的查询参数或表单数据？
答：可以通过请求对象（HttpServletRequest）的getParameter()方法通过参数名获得参数值。如果有包含多个值的参数（例如复选框），可以通过请求对象的getParameterValues()方法获得。当然也可以通过请求对象的getParameterMap()获得一个参数名和参数值的映射（Map）。

119、Servlet中如何获取用户配置的初始化参数以及服务器上下文参数？
答：可以通过重写Servlet接口的init(ServletConfig)方法并通过ServletConfig对象的getInitParameter()方法来获取Servlet的初始化参数。可以通过ServletConfig对象的getServletContext()方法获取ServletContext对象，并通过该对象的getInitParameter()方法来获取服务器上下文参数。当然，ServletContext对象也在处理用户请求的方法（如doGet()方法）中通过请求对象的getServletContext()方法来获得。

120、如何设置请求的编码以及响应内容的类型？
答：通过请求对象（ServletRequest）的setCharacterEncoding(String)方法可以设置请求的编码，其实要彻底解决乱码问题就应该让页面、服务器、请求和响应、Java程序都使用统一的编码，最好的选择当然是UTF-8；通过响应对象（ServletResponse）的setContentType(String)方法可以设置响应内容的类型，当然也可以通过HttpServletResponsed对象的setHeader(String, String)方法来设置。
说明：现在如果还有公司在面试的时候问JSP的声明标记、表达式标记、小脚本标记这些内容的话，这样的公司也不用去了，其实JSP内置对象、JSP指令这些东西基本上都可以忘却了，关于Java Web开发的相关知识，可以看一下我的《Servlet&JSP思维导图》，上面有完整的知识点的罗列。想了解如何实现自定义MVC框架的，可以看一下我的《Java Web自定义MVC框架详解》。

121、解释一下网络应用的模式及其特点。
答：典型的网络应用模式大致有三类：B/S、C/S、P2P。其中B代表浏览器（Browser）、C代表客户端（Client）、S代表服务器（Server），P2P是对等模式，不区分客户端和服务器。B/S应用模式中可以视为特殊的C/S应用模式，只是将C/S应用模式中的特殊的客户端换成了浏览器，因为几乎所有的系统上都有浏览器，那么只要打开浏览器就可以使用应用，没有安装、配置、升级客户端所带来的各种开销。P2P应用模式中，成千上万台彼此连接的计算机都处于对等的地位，整个网络一般来说不依赖专用的集中服务器。网络中的每一台计算机既能充当网络服务的请求者，又对其它计算机的请求作出响应，提供资源和服务。通常这些资源和服务包括：信息的共享和交换、计算资源（如CPU的共享）、存储共享（如缓存和磁盘空间的使用）等，这种应用模式最大的阻力安全性、版本等问题，目前有很多应用都混合使用了多种应用模型，最常见的网络视频应用，它几乎把三种模式都用上了。
补充：此题要跟"电子商务模式"区分开，因为有很多人被问到这个问题的时候马上想到的是B2B（如阿里巴巴）、B2C（如当当、亚马逊、京东）、C2C（如淘宝、拍拍）、C2B（如威客）、O2O（如美团、饿了么）。对于这类问题，可以去百度上面科普一下。

122、什么是Web Service（Web服务）？
答：从表面上看，Web Service就是一个应用程序，它向外界暴露出一个能够通过Web进行调用的API。这就是说，你能够用编程的方法透明的调用这个应用程序，不需要了解它的任何细节，跟你使用的编程语言也没有关系。例如可以创建一个提供天气预报的Web Service，那么无论你用哪种编程语言开发的应用都可以通过调用它的API并传入城市信息来获得该城市的天气预报。之所以称之为Web Service，是因为它基于HTTP协议传输数据，这使得运行在不同机器上的不同应用无须借助附加的、专门的第三方软件或硬件，就可相互交换数据或集成。
补充：这里必须要提及的一个概念是SOA（Service-Oriented Architecture，面向服务的架构），SOA是一种思想，它将应用程序的不同功能单元通过中立的契约联系起来，独立于硬件平台、操作系统和编程语言，使得各种形式的功能单元能够更好的集成。显然，Web Service是SOA的一种较好的解决方案，它更多的是一种标准，而不是一种具体的技术。

123、概念解释：SOAP、WSDL、UDDI。
答：
- SOAP：简单对象访问协议（Simple Object Access Protocol），是Web Service中交换数据的一种协议规范。
- WSDL：Web服务描述语言（Web Service Description Language），它描述了Web服务的公共接口。这是一个基于XML的关于如何与Web服务通讯和使用的服务描述；也就是描述与目录中列出的Web服务进行交互时需要绑定的协议和信息格式。通常采用抽象语言描述该服务支持的操作和信息，使用的时候再将实际的网络协议和信息格式绑定给该服务。
- UDDI：统一描述、发现和集成（Universal Description, Discovery and Integration），它是一个基于XML的跨平台的描述规范，可以使世界范围内的企业在互联网上发布自己所提供的服务。简单的说，UDDI是访问各种WSDL的一个门面（可以参考设计模式中的门面模式）。提示：关于Web Service的相关概念和知识可以在W3CSchool上找到相关的资料。

124、Java规范中和Web Service相关的规范有哪些？
答：Java规范中和Web Service相关的有三个：
- JAX-WS(JSR 224)：这个规范是早期的基于SOAP的Web Service规范JAX-RPC的替代版本，它并不提供向下兼容性，因为RPC样式的WSDL以及相关的API已经在Java EE5中被移除了。WS-MetaData是JAX-WS的依赖规范，提供了基于注解配置Web Service和SOAP消息的相关API。
- JAXM(JSR 67)：定义了发送和接收消息所需的API,相当于Web Service的服务器端。
- JAX-RS(JSR 311 & JSR 339 & JSR 370)：是Java针对REST（Representation State Transfer）架构风格制定的一套Web Service规范。REST是一种软件架构模式，是一种风格，它不像SOAP那样本身承载着一种消息协议， (两种风格的Web Service均采用了HTTP做传输协议，因为HTTP协议能穿越防火墙，Java的远程方法调用（RMI）等是重量级协议，通常不能穿越防火墙），因此可以将REST视为基于HTTP协议的软件架构。REST中最重要的两个概念是资源定位和资源操作，而HTTP协议恰好完整的提供了这两个点。HTTP协议中的URI可以完成资源定位，而GET、POST、OPTION、DELETE方法可以完成资源操作。因此REST完全依赖HTTP协议就可以完成Web Service，而不像SOAP协议那样只利用了HTTP的传输特性，定位和操作都是由SOAP协议自身完成的，也正是由于SOAP消息的存在使得基于SOAP的Web Service显得笨重而逐渐被淘汰。

125、介绍一下你了解的Java领域的Web Service框架。
答：Java领域的Web Service框架很多，包括Axis2（Axis的升级版本）、Jersey（RESTful的Web Service框架）、CXF（XFire的延续版本）、Hessian、Turmeric、JBoss SOA等，其中绝大多数都是开源框架。
提示：面试被问到这类问题的时候一定选择自己用过的最熟悉的作答，如果之前没有了解过就应该在面试前花一些时间了解其中的两个，并比较其优缺点，这样才能在面试时给出一个漂亮的答案。
这部分主要是开源Java EE框架方面的内容，包括Hibernate、MyBatis、Spring、Spring MVC等，由于Struts 2已经是明日黄花，在这里就不讨论Struts 2的面试题，如果需要了解相关内容，可以参考Java程序员面试题集（86-115）。

126、什么是ORM？
答：对象关系映射（Object-Relational Mapping，简称ORM）是一种为了解决程序的面向对象模型与数据库的关系模型互不匹配问题的技术；简单的说，ORM是通过使用描述对象和数据库之间映射的元数据（在Java中可以用XML或者是注解），将程序中的对象自动持久化到关系数据库中或者将关系数据库表中的行转换成Java对象，其本质上就是将数据从一种形式转换到另外一种形式。

127、持久层设计要考虑的问题有哪些？你用过的持久层框架有哪些？
答：所谓"持久"就是将数据保存到可掉电式存储设备中以便今后使用，简单的说，就是将内存中的数据保存到关系型数据库、文件系统、消息队列等提供持久化支持的设备中。持久层就是系统中专注于实现数据持久化的相对独立的层面。
持久层设计的目标包括：
- 数据存储逻辑的分离，提供抽象化的数据访问接口。
- 数据访问底层实现的分离，可以在不修改代码的情况下切换底层实现。
- 资源管理和调度的分离，在数据访问层实现统一的资源调度（如缓存机制）。
- 数据抽象，提供更面向对象的数据操作。
持久层框架有：
- Hibernate
- MyBatis
- TopLink
- Guzz
- jOOQ
- Spring Data
- ActiveJDBC

128、Hibernate中SessionFactory是线程安全的吗？Session是线程安全的吗（两个线程能够共享同一个Session吗）？
答：SessionFactory对应Hibernate的一个数据存储的概念，它是线程安全的，可以被多个线程并发访问。SessionFactory一般只会在启动的时候构建。对于应用程序，最好将SessionFactory通过单例模式进行封装以便于访问。Session是一个轻量级非线程安全的对象（线程间不能共享session），它表示与数据库进行交互的一个工作单元。Session是由SessionFactory创建的，在任务完成之后它会被关闭。Session是持久层服务对外提供的主要接口。Session会延迟获取数据库连接（也就是在需要的时候才会获取）。为了避免创建太多的session，可以使用ThreadLocal将session和当前线程绑定在一起，这样可以让同一个线程获得的总是同一个session。Hibernate 3中SessionFactory的getCurrentSession()方法就可以做到。

129、Hibernate中Session的load和get方法的区别是什么？
答：主要有以下三项区别：
① 如果没有找到符合条件的记录，get方法返回null，load方法抛出异常。
② get方法直接返回实体类对象，load方法返回实体类对象的代理。
③ 在Hibernate 3之前，get方法只在一级缓存中进行数据查找，如果没有找到对应的数据则越过二级缓存，直接发出SQL语句完成数据读取；load方法则可以从二级缓存中获取数据；从Hibernate 3开始，get方法不再是对二级缓存只写不读，它也是可以访问二级缓存的。说明：对于load()方法Hibernate认为该数据在数据库中一定存在可以放心的使用代理来实现延迟加载，如果没有数据就抛出异常，而通过get()方法获取的数据可以不存在。

130、Session的save()、update()、merge()、lock()、saveOrUpdate()和persist()方法分别是做什么的？有什么区别？
答：Hibernate的对象有三种状态：瞬时态（transient）、持久态（persistent）和游离态（detached），如第135题中的图所示。瞬时态的实例可以通过调用save()、persist()或者saveOrUpdate()方法变成持久态；游离态的实例可以通过调用 update()、saveOrUpdate()、lock()或者replicate()变成持久态。save()和persist()将会引发SQL的INSERT语句，而update()或merge()会引发UPDATE语句。save()和update()的区别在于一个是将瞬时态对象变成持久态，一个是将游离态对象变为持久态。merge()方法可以完成save()和update()方法的功能，它的意图是将新的状态合并到已有的持久化对象上或创建新的持久化对象。对于persist()方法，按照官方文档的说明：① persist()方法把一个瞬时态的实例持久化，但是并不保证标识符被立刻填入到持久化实例中，标识符的填入可能被推迟到flush的时间；② persist()方法保证当它在一个事务外部被调用的时候并不触发一个INSERT语句，当需要封装一个长会话流程的时候，persist()方法是很有必要的；③ save()方法不保证第②条，它要返回标识符，所以它会立即执行INSERT语句，不管是在事务内部还是外部。至于lock()方法和update()方法的区别，update()方法是把一个已经更改过的脱管状态的对象变成持久状态；lock()方法是把一个没有更改过的脱管状态的对象变成持久状态。

131、阐述Session加载实体对象的过程。
答：Session加载实体对象的步骤是：
① Session在调用数据库查询功能之前，首先会在一级缓存中通过实体类型和主键进行查找，如果一级缓存查找命中且数据状态合法，则直接返回；
② 如果一级缓存没有命中，接下来Session会在当前NonExists记录（相当于一个查询黑名单，如果出现重复的无效查询可以迅速做出判断，从而提升性能）中进行查找，如果NonExists中存在同样的查询条件，则返回null；
③ 如果一级缓存查询失败则查询二级缓存，如果二级缓存命中则直接返回；
④ 如果之前的查询都未命中，则发出SQL语句，如果查询未发现对应记录则将此次查询添加到Session的NonExists中加以记录，并返回null；
⑤ 根据映射配置和SQL语句得到ResultSet，并创建对应的实体对象；
⑥ 将对象纳入Session（一级缓存）的管理；
⑦ 如果有对应的拦截器，则执行拦截器的onLoad方法；
⑧ 如果开启并设置了要使用二级缓存，则将数据对象纳入二级缓存；
⑨ 返回数据对象。

132、Query接口的list方法和iterate方法有什么区别？
答：
① list()方法无法利用一级缓存和二级缓存（对缓存只写不读），它只能在开启查询缓存的前提下使用查询缓存；iterate()方法可以充分利用缓存，如果目标数据只读或者读取频繁，使用iterate()方法可以减少性能开销。
② list()方法不会引起N+1查询问题，而iterate()方法可能引起N+1查询问题
说明：关于N+1查询问题，可以参考CSDN上的一篇文章《什么是N+1查询》

133、Hibernate如何实现分页查询？
答：通过Hibernate实现分页查询，开发人员只需要提供HQL语句（调用Session的createQuery()方法）或查询条件（调用Session的createCriteria()方法）、设置查询起始行数（调用Query或Criteria接口的setFirstResult()方法）和最大查询行数（调用Query或Criteria接口的setMaxResults()方法），并调用Query或Criteria接口的list()方法，Hibernate会自动生成分页查询的SQL语句。

134、锁机制有什么用？简述Hibernate的悲观锁和乐观锁机制。
答：有些业务逻辑在执行过程中要求对数据进行排他性的访问，于是需要通过一些机制保证在此过程中数据被锁住不会被外界修改，这就是所谓的锁机制。
Hibernate支持悲观锁和乐观锁两种锁机制。悲观锁，顾名思义悲观的认为在数据处理过程中极有可能存在修改数据的并发事务（包括本系统的其他事务或来自外部系统的事务），于是将处理的数据设置为锁定状态。悲观锁必须依赖数据库本身的锁机制才能真正保证数据访问的排他性，关于数据库的锁机制和事务隔离级别在《Java面试题大全（上）》中已经讨论过了。乐观锁，顾名思义，对并发事务持乐观态度（认为对数据的并发操作不会经常性的发生），通过更加宽松的锁机制来解决由于悲观锁排他性的数据访问对系统性能造成的严重影响。最常见的乐观锁是通过数据版本标识来实现的，读取数据时获得数据的版本号，更新数据时将此版本号加1，然后和数据库表对应记录的当前版本号进行比较，如果提交的数据版本号大于数据库中此记录的当前版本号则更新数据，否则认为是过期数据无法更新。Hibernate中通过Session的get()和load()方法从数据库中加载对象时可以通过参数指定使用悲观锁；而乐观锁可以通过给实体类加整型的版本字段再通过XML或@Version注解进行配置。
提示：使用乐观锁会增加了一个版本字段，很明显这需要额外的空间来存储这个版本字段，浪费了空间，但是乐观锁会让系统具有更好的并发性，这是对时间的节省。因此乐观锁也是典型的空间换时间的策略。



135、阐述实体对象的三种状态以及转换关系。 
答：最新的Hibernate文档中为Hibernate对象定义了四种状态（原来是三种状态，面试的时候基本上问的也是三种状态），分别是：瞬时态（new, or transient）、持久态（managed, or persistent）、游状态（detached）和移除态（removed，以前Hibernate文档中定义的三种状态中没有移除态），如下图所示，就以前的Hibernate文档中移除态被视为是瞬时态。
    瞬时态：当new一个实体对象后，这个对象处于瞬时态，即这个对象只是一个保存临时数据的内存区域，如果没有变量引用这个对象，则会被JVM的垃圾回收机制回收。这个对象所保存的数据与数据库没有任何关系，除非通过Session的save()、saveOrUpdate()、persist()、merge()方法把瞬时态对象与数据库关联，并把数据插入或者更新到数据库，这个对象才转换为持久态对象。
    持久态：持久态对象的实例在数据库中有对应的记录，并拥有一个持久化标识（ID）。对持久态对象进行delete操作后，数据库中对应的记录将被删除，那么持久态对象与数据库记录不再存在对应关系，持久态对象变成移除态（可以视为瞬时态）。持久态对象被修改变更后，不会马上同步到数据库，直到数据库事务提交。
    游离态：当Session进行了close()、clear()、evict()或flush()后，实体对象从持久态变成游离态，对象虽然拥有持久和与数据库对应记录一致的标识值，但是因为对象已经从会话中清除掉，对象不在持久化管理之内，所以处于游离态（也叫脱管态）。游离态的对象与临时状态对象是十分相似的，只是它还含有持久化标识。
提示：关于这个问题，在Hibernate的官方文档中有更为详细的解读。

136、如何理解Hibernate的延迟加载机制？在实际应用中，延迟加载与Session关闭的矛盾是如何处理的？
答：延迟加载就是并不是在读取的时候就把数据加载进来，而是等到使用时再加载。Hibernate使用了虚拟代理机制实现延迟加载，我们使用Session的load()方法加载数据或者一对多关联映射在使用延迟加载的情况下从一的一方加载多的一方，得到的都是虚拟代理，简单的说返回给用户的并不是实体本身，而是实体对象的代理。代理对象在用户调用getter方法时才会去数据库加载数据。但加载数据就需要数据库连接。而当我们把会话关闭时，数据库连接就同时关闭了。

延迟加载与session关闭的矛盾一般可以这样处理：
① 关闭延迟加载特性。这种方式操作起来比较简单，因为Hibernate的延迟加载特性是可以通过映射文件或者注解进行配置的，但这种解决方案存在明显的缺陷。首先，出现"no session or session was closed"通常说明系统中已经存在主外键关联，如果去掉延迟加载的话，每次查询的开销都会变得很大。
② 在session关闭之前先获取需要查询的数据，可以使用工具方法Hibernate.isInitialized()判断对象是否被加载，如果没有被加载则可以使用Hibernate.initialize()方法加载对象。
③ 使用拦截器或过滤器延长Session的生命周期直到视图获得数据。Spring整合Hibernate提供的OpenSessionInViewFilter和OpenSessionInViewInterceptor就是这种做法。

137、举一个多对多关联的例子，并说明如何实现多对多关联映射。
答：例如：商品和订单、学生和课程都是典型的多对多关系。可以在实体类上通过@ManyToMany注解配置多对多关联或者通过映射文件中的和标签配置多对多关联，但是实际项目开发中，很多时候都是将多对多关联映射转换成两个多对一关联映射来实现的。

138、谈一下你对继承映射的理解。
答：继承关系的映射策略有三种：
① 每个继承结构一张表（table per class hierarchy），不管多少个子类都用一张表。
② 每个子类一张表（table per subclass），公共信息放一张表，特有信息放单独的表。
③ 每个具体类一张表（table per concrete class），有多少个子类就有多少张表。
第一种方式属于单表策略，其优点在于查询子类对象的时候无需表连接，查询速度快，适合多态查询；缺点是可能导致表很大。后两种方式属于多表策略，其优点在于数据存储紧凑，其缺点是需要进行连接查询，不适合多态查询。

139、简述Hibernate常见优化策略。
答：这个问题应当挑自己使用过的优化策略回答，常用的有：
① 制定合理的缓存策略（二级缓存、查询缓存）。
② 采用合理的Session管理机制。
③ 尽量使用延迟加载特性。
④ 设定合理的批处理参数。
⑤ 如果可以，选用UUID作为主键生成器。
⑥ 如果可以，选用基于版本号的乐观锁替代悲观锁。
⑦ 在开发过程中, 开启hibernate.show_sql选项查看生成的SQL，从而了解底层的状况；开发完成后关闭此选项。
⑧ 考虑数据库本身的优化，合理的索引、恰当的数据分区策略等都会对持久层的性能带来可观的提升，但这些需要专业的DBA（数据库管理员）提供支持。

140、谈一谈Hibernate的一级缓存、二级缓存和查询缓存。
答：Hibernate的Session提供了一级缓存的功能，默认总是有效的，当应用程序保存持久化实体、修改持久化实体时，Session并不会立即把这种改变提交到数据库，而是缓存在当前的Session中，除非显示调用了Session的flush()方法或通过close()方法关闭Session。通过一级缓存，可以减少程序与数据库的交互，从而提高数据库访问性能。
SessionFactory级别的二级缓存是全局性的，所有的Session可以共享这个二级缓存。不过二级缓存默认是关闭的，需要显示开启并指定需要使用哪种二级缓存实现类（可以使用第三方提供的实现）。一旦开启了二级缓存并设置了需要使用二级缓存的实体类，SessionFactory就会缓存访问过的该实体类的每个对象，除非缓存的数据超出了指定的缓存空间。
一级缓存和二级缓存都是对整个实体进行缓存，不会缓存普通属性，如果希望对普通属性进行缓存，可以使用查询缓存。查询缓存是将HQL或SQL语句以及它们的查询结果作为键值对进行缓存，对于同样的查询可以直接从缓存中获取数据。查询缓存默认也是关闭的，需要显示开启。

141、Hibernate中DetachedCriteria类是做什么的？
答：DetachedCriteria和Criteria的用法基本上是一致的，但Criteria是由Session的createCriteria()方法创建的，也就意味着离开创建它的Session，Criteria就无法使用了。DetachedCriteria不需要Session就可以创建（使用DetachedCriteria.forClass()方法创建），所以通常也称其为离线的Criteria，在需要进行查询操作的时候再和Session绑定（调用其getExecutableCriteria(Session)方法），这也就意味着一个DetachedCriteria可以在需要的时候和不同的Session进行绑定。

142、@OneToMany注解的mappedBy属性有什么作用？
答：@OneToMany用来配置一对多关联映射，但通常情况下，一对多关联映射都由多的一方来维护关联关系，例如学生和班级，应该在学生类中添加班级属性来维持学生和班级的关联关系（在数据库中是由学生表中的外键班级编号来维护学生表和班级表的多对一关系），如果要使用双向关联，在班级类中添加一个容器属性来存放学生，并使用@OneToMany注解进行映射，此时mappedBy属性就非常重要。如果使用XML进行配置，可以用<set>标签的inverse="true"设置来达到同样的效果。

143、MyBatis中使用#和$书写占位符有什么区别？
答：#将传入的数据都当成一个字符串，会对传入的数据自动加上引号；$将传入的数据直接显示生成在SQL中。注意：使用$占位符可能会导致SQL注射攻击，能用#的地方就不要使用$，写order by子句的时候应该用$而不是#。

144、解释一下MyBatis中命名空间（namespace）的作用。
答：在大型项目中，可能存在大量的SQL语句，这时候为每个SQL语句起一个唯一的标识（ID）就变得并不容易了。为了解决这个问题，在MyBatis中，可以为每个映射文件起一个唯一的命名空间，这样定义在这个映射文件中的每个SQL语句就成了定义在这个命名空间中的一个ID。只要我们能够保证每个命名空间中这个ID是唯一的，即使在不同映射文件中的语句ID相同，也不会再产生冲突了。

145、MyBatis中的动态SQL是什么意思？
答：对于一些复杂的查询，我们可能会指定多个查询条件，但是这些条件可能存在也可能不存在，例如在58同城上面找房子，我们可能会指定面积、楼层和所在位置来查找房源，也可能会指定面积、价格、户型和所在位置来查找房源，此时就需要根据用户指定的条件动态生成SQL语句。如果不使用持久层框架我们可能需要自己拼装SQL语句，还好MyBatis提供了动态SQL的功能来解决这个问题。MyBatis中用于实现动态SQL的元素主要有：
- if
- choose / when / otherwise
- trim
- where
- set
- foreach

下面是映射文件的片段。

<select id="foo" parameterType="Blog" resultType="Blog">
        select * from t_blog where 1 = 1
        <if test="title != null">
            and title = #{title}
        </if>
        <if test="content != null">
            and content = #{content}
        </if>
        <if test="owner != null">
            and owner = #{owner}
        </if>
   </select>

当然也可以像下面这些书写。

<select id="foo" parameterType="Blog" resultType="Blog">
        select * from t_blog where 1 = 1 
        <choose>
            <when test="title != null">
                and title = #{title}
            </when>
            <when test="content != null">
                and content = #{content}
            </when>
            <otherwise>
                and owner = "owner1"
            </otherwise>
        </choose>
    </select>

再看看下面这个例子。

  <select id="bar" resultType="Blog">
        select * from t_blog where id in
        <foreach collection="array" index="index"
            item="item" open="(" separator="," close=")">
            #{item}
        </foreach>
    </select>

146、什么是IoC和DI？DI是如何实现的？
答：IoC叫控制反转，是Inversion of Control的缩写，DI（Dependency Injection）叫依赖注入，是对IoC更简单的诠释。控制反转是把传统上由程序代码直接操控的对象的调用权交给容器，通过容器来实现对象组件的装配和管理。所谓的"控制反转"就是对组件对象控制权的转移，从程序代码本身转移到了外部容器，由容器来创建对象并管理对象之间的依赖关系。IoC体现了好莱坞原则 - "Don’t call me, we will call you"。依赖注入的基本原则是应用组件不应该负责查找资源或者其他依赖的协作对象。配置对象的工作应该由容器负责，查找资源的逻辑应该从应用组件的代码中抽取出来，交给容器来完成。DI是对IoC更准确的描述，即组件之间的依赖关系由容器在运行期决定，形象的来说，即由容器动态的将某种依赖关系注入到组件之中。

举个例子：一个类A需要用到接口B中的方法，那么就需要为类A和接口B建立关联或依赖关系，最原始的方法是在类A中创建一个接口B的实现类C的实例，但这种方法需要开发人员自行维护二者的依赖关系，也就是说当依赖关系发生变动的时候需要修改代码并重新构建整个系统。如果通过一个容器来管理这些对象以及对象的依赖关系，则只需要在类A中定义好用于关联接口B的方法（构造器或setter方法），将类A和接口B的实现类C放入容器中，通过对容器的配置来实现二者的关联。

依赖注入可以通过setter方法注入（设值注入）、构造器注入和接口注入三种方式来实现，Spring支持setter注入和构造器注入，通常使用构造器注入来注入必须的依赖关系，对于可选的依赖关系，则setter注入是更好的选择，setter注入需要类提供无参构造器或者无参的静态工厂方法来创建对象。

147、Spring中Bean的作用域有哪些？
答：在Spring的早期版本中，仅有两个作用域：singleton和prototype，前者表示Bean以单例的方式存在；后者表示每次从容器中调用Bean时，都会返回一个新的实例，prototype通常翻译为原型。

    补充：设计模式中的创建型模式中也有一个原型模式，原型模式也是一个常用的模式，例如做一个室内设计软件，所有的素材都在工具箱中，而每次从工具箱中取出的都是素材对象的一个原型，可以通过对象克隆来实现原型模式。

Spring 2.x中针对WebApplicationContext新增了3个作用域，分别是：request（每次HTTP请求都会创建一个新的Bean）、session（同一个HttpSession共享同一个Bean，不同的HttpSession使用不同的Bean）和globalSession（同一个全局Session共享一个Bean）。

    说明：单例模式和原型模式都是重要的设计模式。一般情况下，无状态或状态不可变的类适合使用单例模式。在传统开发中，由于DAO持有Connection这个非线程安全对象因而没有使用单例模式；但在Spring环境下，所有DAO类对可以采用单例模式，因为Spring利用AOP和Java API中的ThreadLocal对非线程安全的对象进行了特殊处理。

ThreadLocal为解决多线程程序的并发问题提供了一种新的思路。ThreadLocal，顾名思义是线程的一个本地化对象，当工作于多线程中的对象使用ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程分配一个独立的变量副本，所以每一个线程都可以独立的改变自己的副本，而不影响其他线程所对应的副本。从线程的角度看，这个变量就像是线程的本地变量。

ThreadLocal类非常简单好用，只有四个方法，能用上的也就是下面三个方法：
- void set(T value)：设置当前线程的线程局部变量的值。
- T get()：获得当前线程所对应的线程局部变量的值。
- void remove()：删除当前线程中线程局部变量的值。

ThreadLocal是如何做到为每一个线程维护一份独立的变量副本的呢？在ThreadLocal类中有一个Map，键为线程对象，值是其线程对应的变量的副本，自己要模拟实现一个ThreadLocal类其实并不困难，代码如下所示：

import java.util.Collections;
import java.util.HashMap;
import java.util.Map;

public class MyThreadLocal<T> {
    private Map<Thread, T> map = Collections.synchronizedMap(new HashMap<Thread, T>());

    public void set(T newValue) {
        map.put(Thread.currentThread(), newValue);
    }

    public T get() {
        return map.get(Thread.currentThread());
    }

    public void remove() {
        map.remove(Thread.currentThread());
    }
}

148、解释一下什么叫AOP（面向切面编程）？
答：AOP（Aspect-Oriented Programming）指一种程序设计范型，该范型以一种称为切面（aspect）的语言构造为基础，切面是一种新的模块化机制，用来描述分散在对象、类或方法中的横切关注点（crosscutting concern）。

149、你是如何理解"横切关注"这个概念的？
答："横切关注"是会影响到整个应用程序的关注功能，它跟正常的业务逻辑是正交的，没有必然的联系，但是几乎所有的业务逻辑都会涉及到这些关注功能。通常，事务、日志、安全性等关注就是应用中的横切关注功能。

150、你如何理解AOP中的连接点（Joinpoint）、切点（Pointcut）、增强（Advice）、引介（Introduction）、织入（Weaving）、切面（Aspect）这些概念？
答：
a. 连接点（Joinpoint）：程序执行的某个特定位置（如：某个方法调用前、调用后，方法抛出异常后）。一个类或一段程序代码拥有一些具有边界性质的特定点，这些代码中的特定点就是连接点。Spring仅支持方法的连接点。
b. 切点（Pointcut）：如果连接点相当于数据中的记录，那么切点相当于查询条件，一个切点可以匹配多个连接点。Spring AOP的规则解析引擎负责解析切点所设定的查询条件，找到对应的连接点。
c. 增强（Advice）：增强是织入到目标类连接点上的一段程序代码。Spring提供的增强接口都是带方位名的，如：BeforeAdvice、AfterReturningAdvice、ThrowsAdvice等。很多资料上将增强译为“通知”，这明显是个词不达意的翻译，让很多程序员困惑了许久。

    说明： Advice在国内的很多书面资料中都被翻译成"通知"，但是很显然这个翻译无法表达其本质，有少量的读物上将这个词翻译为"增强"，这个翻译是对Advice较为准确的诠释，我们通过AOP将横切关注功能加到原有的业务逻辑上，这就是对原有业务逻辑的一种增强，这种增强可以是前置增强、后置增强、返回后增强、抛异常时增强和包围型增强。

d. 引介（Introduction）：引介是一种特殊的增强，它为类添加一些属性和方法。这样，即使一个业务类原本没有实现某个接口，通过引介功能，可以动态的未该业务类添加接口的实现逻辑，让业务类成为这个接口的实现类。
e. 织入（Weaving）：织入是将增强添加到目标类具体连接点上的过程，AOP有三种织入方式：①编译期织入：需要特殊的Java编译期（例如AspectJ的ajc）；②装载期织入：要求使用特殊的类加载器，在装载类的时候对类进行增强；③运行时织入：在运行时为目标类生成代理实现增强。Spring采用了动态代理的方式实现了运行时织入，而AspectJ采用了编译期织入和装载期织入的方式。
f. 切面（Aspect）：切面是由切点和增强（引介）组成的，它包括了对横切关注功能的定义，也包括了对连接点的定义。

    补充：代理模式是GoF提出的23种设计模式中最为经典的模式之一，代理模式是对象的结构模式，它给某一个对象提供一个代理对象，并由代理对象控制对原对象的引用。简单的说，代理对象可以完成比原对象更多的职责，当需要为原对象添加横切关注功能时，就可以使用原对象的代理对象。我们在打开Office系列的Word文档时，如果文档中有插图，当文档刚加载时，文档中的插图都只是一个虚框占位符，等用户真正翻到某页要查看该图片时，才会真正加载这张图，这其实就是对代理模式的使用，代替真正图片的虚框就是一个虚拟代理；Hibernate的load方法也是返回一个虚拟代理对象，等用户真正需要访问对象的属性时，才向数据库发出SQL语句获得真实对象。

下面用一个找枪手代考的例子演示代理模式的使用：


/**
 * 参考人员接口
 * @author 骆昊
 *
 */
public interface Candidate {

    /**
     * 答题
     */
    public void answerTheQuestions();
}


/**
 * 懒学生
 * @author 骆昊
 *
 */
public class LazyStudent implements Candidate {
    private String name;        // 姓名

    public LazyStudent(String name) {
        this.name = name;
    }

    @Override
    public void answerTheQuestions() {
        // 懒学生只能写出自己的名字不会答题
        System.out.println("姓名: " + name);
    }

}


/**
 * 枪手
 * @author 骆昊
 *
 */
public class Gunman implements Candidate {
    private Candidate target;   // 被代理对象

    public Gunman(Candidate target) {
        this.target = target;
    }

    @Override
    public void answerTheQuestions() {
        // 枪手要写上代考的学生的姓名
        target.answerTheQuestions();
        // 枪手要帮助懒学生答题并交卷
        System.out.println("奋笔疾书正确答案");
        System.out.println("交卷");
    }

}

public class ProxyTest1 {

    public static void main(String[] args) {
        Candidate c = new Gunman(new LazyStudent("王小二"));
        c.answerTheQuestions();
    }
}

    说明：从JDK 1.3开始，Java提供了动态代理技术，允许开发者在运行时创建接口的代理实例，主要包括Proxy类和InvocationHandler接口。下面的例子使用动态代理为ArrayList编写一个代理，在添加和删除元素时，在控制台打印添加或删除的元素以及ArrayList的大小：

import java.lang.reflect.InvocationHandler;
import java.lang.reflect.Method;
import java.util.List;

public class ListProxy<T> implements InvocationHandler {
    private List<T> target;

    public ListProxy(List<T> target) {
        this.target = target;
    }

    @Override
    public Object invoke(Object proxy, Method method, Object[] args)
            throws Throwable {
        Object retVal = null;
        System.out.println("[" + method.getName() + ": " + args[0] + "]");
        retVal = method.invoke(target, args);
        System.out.println("[size=" + target.size() + "]");
        return retVal;
    }

}

import java.lang.reflect.Proxy;
import java.util.ArrayList;
import java.util.List;

public class ProxyTest2 {

    @SuppressWarnings("unchecked")
    public static void main(String[] args) {
        List<String> list = new ArrayList<String>();
        Class<?> clazz = list.getClass();
        ListProxy<String> myProxy = new ListProxy<String>(list);
        List<String> newList = (List<String>)
                Proxy.newProxyInstance(clazz.getClassLoader(),
                clazz.getInterfaces(), myProxy);
        newList.add("apple");
        newList.add("banana");
        newList.add("orange");
        newList.remove("banana");
    }
}

    说明：使用Java的动态代理有一个局限性就是代理的类必须要实现接口，虽然面向接口编程是每个优秀的Java程序都知道的规则，但现实往往不尽如人意，对于没有实现接口的类如何为其生成代理呢？继承！继承是最经典的扩展已有代码能力的手段，虽然继承常常被初学者滥用，但继承也常常被进阶的程序员忽视。CGLib采用非常底层的字节码生成技术，通过为一个类创建子类来生成代理，它弥补了Java动态代理的不足，因此Spring中动态代理和CGLib都是创建代理的重要手段，对于实现了接口的类就用动态代理为其生成代理类，而没有实现接口的类就用CGLib通过继承的方式为其创建代理。

151、Spring中自动装配的方式有哪些？
答：
- no：不进行自动装配，手动设置Bean的依赖关系。
- byName：根据Bean的名字进行自动装配。
- byType：根据Bean的类型进行自动装配。
- constructor：类似于byType，不过是应用于构造器的参数，如果正好有一个Bean与构造器的参数类型相同则可以自动装配，否则会导致错误。
- autodetect：如果有默认的构造器，则通过constructor的方式进行自动装配，否则使用byType的方式进行自动装配。

    说明：自动装配没有自定义装配方式那么精确，而且不能自动装配简单属性（基本类型、字符串等），在使用时应注意。

152、Spring中如何使用注解来配置Bean？有哪些相关的注解？
答：首先需要在Spring配置文件中增加如下配置：
<context:component-scan base-package="org.example"/>

然后可以用@Component、@Controller、@Service、@Repository注解来标注需要由Spring IoC容器进行对象托管的类。这几个注解没有本质区别，只不过@Controller通常用于控制器，@Service通常用于业务逻辑类，@Repository通常用于仓储类（例如我们的DAO实现类），普通的类用@Component来标注。

153、Spring支持的事务管理类型有哪些？你在项目中使用哪种方式？ 
答：Spring支持编程式事务管理和声明式事务管理。许多Spring框架的用户选择声明式事务管理，因为这种方式和应用程序的关联较少，因此更加符合轻量级容器的概念。声明式事务管理要优于编程式事务管理，尽管在灵活性方面它弱于编程式事务管理，因为编程式事务允许你通过代码控制业务。
事务分为全局事务和局部事务。全局事务由应用服务器管理，需要底层服务器JTA支持（如WebLogic、WildFly等）。局部事务和底层采用的持久化方案有关，例如使用JDBC进行持久化时，需要使用Connetion对象来操作事务；而采用Hibernate进行持久化时，需要使用Session对象来操作事务。
Spring提供了如下所示的事务管理器。
事务管理器实现类	目标对象
DataSourceTransactionManager	注入DataSource
HibernateTransactionManager	注入SessionFactory
JdoTransactionManager	管理JDO事务
JtaTransactionManager	使用JTA管理事务
PersistenceBrokerTransactionManager	管理Apache的OJB事务


这些事务的父接口都是PlatformTransactionManager。Spring的事务管理机制是一种典型的策略模式，PlatformTransactionManager代表事务管理接口，该接口定义了三个方法，该接口并不知道底层如何管理事务，但是它的实现类必须提供getTransaction()方法（开启事务）、commit()方法（提交事务）、rollback()方法（回滚事务）的多态实现，这样就可以用不同的实现类代表不同的事务管理策略。使用JTA全局事务策略时，需要底层应用服务器支持，而不同的应用服务器所提供的JTA全局事务可能存在细节上的差异，因此实际配置全局事务管理器是可能需要使用JtaTransactionManager的子类，如：WebLogicJtaTransactionManager（Oracle的WebLogic服务器提供）、UowJtaTransactionManager（IBM的WebSphere服务器提供）等。

编程式事务管理如下所示。

<?xml version="1.0" encoding="UTF-8"?>
 <beans xmlns="http://www.springframework.org/schema/beans"
     xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"  xmlns:p="http://www.springframework.org/schema/p"
    xmlns:p="http://www.springframework.org/schema/context"
     xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd
     http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd">

     <context:component-scan base-package="com.jackfrued"/>

     <bean id="propertyConfig"
         class="org.springframework.beans.factory.config.
  PropertyPlaceholderConfigurer">
         <property name="location">
             <value>jdbc.properties</value>
         </property>
     </bean>

     <bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource">
         <property name="driverClassName">
             <value>${db.driver}</value>
         </property>
         <property name="url">
             <value>${db.url}</value>
         </property>
         <property name="username">
             <value>${db.username}</value>
         </property>
         <property name="password">
             <value>${db.password}</value>
         </property>
     </bean>

     <bean id="jdbcTemplate" class="org.springframework.jdbc.core.JdbcTemplate">
         <property name="dataSource">
             <ref bean="dataSource" />
         </property>
     </bean>

     <!-- JDBC事务管理器 -->
     <bean id="transactionManager"
         class="org.springframework.jdbc.datasource.
       DataSourceTransactionManager"　scope="singleton">
         <property name="dataSource">
             <ref bean="dataSource" />
         </property>
     </bean>

     <!-- 声明事务模板 -->
     <bean id="transactionTemplate"
         class="org.springframework.transaction.support.
   TransactionTemplate">
         <property name="transactionManager">
             <ref bean="transactionManager" />
         </property>
     </bean>

</beans>

package com.jackfrued.dao.impl;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.jdbc.core.JdbcTemplate;

import com.jackfrued.dao.EmpDao;
import com.jackfrued.entity.Emp;

@Repository
public class EmpDaoImpl implements EmpDao {
    @Autowired
    private JdbcTemplate jdbcTemplate;

    @Override
    public boolean save(Emp emp) {
        String sql = "insert into emp values (?,?,?)";
        return jdbcTemplate.update(sql, emp.getId(), emp.getName(), emp.getBirthday()) == 1;
    }

}

package com.jackfrued.biz.impl;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;
import org.springframework.transaction.TransactionStatus;
import org.springframework.transaction.support.TransactionCallbackWithoutResult;
import org.springframework.transaction.support.TransactionTemplate;

import com.jackfrued.biz.EmpService;
import com.jackfrued.dao.EmpDao;
import com.jackfrued.entity.Emp;

@Service
public class EmpServiceImpl implements EmpService {
    @Autowired
    private TransactionTemplate txTemplate;
    @Autowired
    private EmpDao empDao;

    @Override
    public void addEmp(final Emp emp) {
        txTemplate.execute(new TransactionCallbackWithoutResult() {

            @Override
            protected void doInTransactionWithoutResult(TransactionStatus txStatus) {
                empDao.save(emp);
            }
        });
    }


}

声明式事务如下图所示，以Spring整合Hibernate 3为例，包括完整的DAO和业务逻辑代码。

<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xmlns:p="http://www.springframework.org/schema/p"
    xmlns:context="http://www.springframework.org/schema/context"
    xmlns:aop="http://www.springframework.org/schema/aop"
    xmlns:tx="http://www.springframework.org/schema/tx"
    xsi:schemaLocation="http://www.springframework.org/schema/beans
           http://www.springframework.org/schema/beans/spring-beans-3.2.xsd
           http://www.springframework.org/schema/context
           http://www.springframework.org/schema/context/spring-context-3.2.xsd
           http://www.springframework.org/schema/aop
           http://www.springframework.org/schema/aop/spring-aop-3.2.xsd
           http://www.springframework.org/schema/tx
           http://www.springframework.org/schema/tx/spring-tx-3.2.xsd">

    <!-- 配置由Spring IoC容器托管的对象对应的被注解的类所在的包 -->
    <context:component-scan base-package="com.jackfrued" />

    <!-- 配置通过自动生成代理实现AOP功能 -->
    <aop:aspectj-autoproxy />

    <!-- 配置数据库连接池 (DBCP) -->
    <bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource"
        destroy-method="close">
        <!-- 配置驱动程序类 -->
        <property name="driverClassName" value="com.mysql.jdbc.Driver" />
        <!-- 配置连接数据库的URL -->
        <property name="url" value="jdbc:mysql://localhost:3306/myweb" />
        <!-- 配置访问数据库的用户名 -->
        <property name="username" value="root" />
        <!-- 配置访问数据库的口令 -->
        <property name="password" value="123456" />
        <!-- 配置最大连接数 -->
        <property name="maxActive" value="150" />
        <!-- 配置最小空闲连接数 -->
        <property name="minIdle" value="5" />
        <!-- 配置最大空闲连接数 -->
        <property name="maxIdle" value="20" />
        <!-- 配置初始连接数 -->
        <property name="initialSize" value="10" />
        <!-- 配置连接被泄露时是否生成日志 -->
        <property name="logAbandoned" value="true" />
        <!-- 配置是否删除超时连接 -->
        <property name="removeAbandoned" value="true" />
        <!-- 配置删除超时连接的超时门限值(以秒为单位) -->
        <property name="removeAbandonedTimeout" value="120" />
        <!-- 配置超时等待时间(以毫秒为单位) -->
        <property name="maxWait" value="5000" />
        <!-- 配置空闲连接回收器线程运行的时间间隔(以毫秒为单位) -->
        <property name="timeBetweenEvictionRunsMillis" value="300000" />
        <!-- 配置连接空闲多长时间后(以毫秒为单位)被断开连接 -->
        <property name="minEvictableIdleTimeMillis" value="60000" />
    </bean>

    <!-- 配置Spring提供的支持注解ORM映射的Hibernate会话工厂 -->
    <bean id="sessionFactory"
        class="org.springframework.orm.hibernate3.annotation.AnnotationSessionFactoryBean">
        <!-- 通过setter注入数据源属性 -->
        <property name="dataSource" ref="dataSource" />
        <!-- 配置实体类所在的包 -->
        <property name="packagesToScan" value="com.jackfrued.entity" />
        <!-- 配置Hibernate的相关属性 -->
        <property name="hibernateProperties">
            <!-- 在项目调试完成后要删除show_sql和format_sql属性否则对性能有显著影响 -->
            <value>
                hibernate.dialect=org.hibernate.dialect.MySQL5Dialect
            </value>
        </property>
    </bean>

    <!-- 配置Spring提供的Hibernate事务管理器 -->
    <bean id="transactionManager"
        class="org.springframework.orm.hibernate3.HibernateTransactionManager">
        <!-- 通过setter注入Hibernate会话工厂 -->
        <property name="sessionFactory" ref="sessionFactory" />
    </bean>

    <!-- 配置基于注解配置声明式事务 -->
    <tx:annotation-driven />

</beans>

package com.jackfrued.dao;

import java.io.Serializable;
import java.util.List;

import com.jackfrued.comm.QueryBean;
import com.jackfrued.comm.QueryResult;

/**
 * 数据访问对象接口(以对象为单位封装CRUD操作)
 * @author 骆昊
 *
 * @param <E> 实体类型
 * @param <K> 实体标识字段的类型
 */
public interface BaseDao <E, K extends Serializable> {

    /**
     * 新增
     * @param entity 业务实体对象
     * @return 增加成功返回实体对象的标识
     */
    public K save(E entity);

    /**
     * 删除
     * @param entity 业务实体对象
     */
    public void delete(E entity);

    /**
     * 根据ID删除
     * @param id 业务实体对象的标识
     * @return 删除成功返回true否则返回false
     */
    public boolean deleteById(K id);

    /**
     * 修改
     * @param entity 业务实体对象
     * @return 修改成功返回true否则返回false
     */
    public void update(E entity);

    /**
     * 根据ID查找业务实体对象
     * @param id 业务实体对象的标识
     * @return 业务实体对象对象或null
     */
    public E findById(K id);

    /**
     * 根据ID查找业务实体对象
     * @param id 业务实体对象的标识
     * @param lazy 是否使用延迟加载
     * @return 业务实体对象对象
     */
    public E findById(K id, boolean lazy);

    /**
     * 查找所有业务实体对象
     * @return 装所有业务实体对象的列表容器
     */
    public List<E> findAll();

    /**
     * 分页查找业务实体对象
     * @param page 页码
     * @param size 页面大小
     * @return 查询结果对象
     */
    public QueryResult<E> findByPage(int page, int size);

    /**
     * 分页查找业务实体对象
     * @param queryBean 查询条件对象
     * @param page 页码
     * @param size 页面大小
     * @return 查询结果对象
     */
    public QueryResult<E> findByPage(QueryBean queryBean, int page, int size);

}

package com.jackfrued.dao;

import java.io.Serializable;
import java.util.List;

import com.jackfrued.comm.QueryBean;
import com.jackfrued.comm.QueryResult;

/**
 * BaseDao的缺省适配器
 * @author 骆昊
 *
 * @param <E> 实体类型
 * @param <K> 实体标识字段的类型
 */
public abstract class BaseDaoAdapter<E, K extends Serializable> implements
        BaseDao<E, K> {

    @Override
    public K save(E entity) {
        return null;
    }

    @Override
    public void delete(E entity) {
    }

    @Override
    public boolean deleteById(K id) {
        E entity = findById(id);
        if(entity != null) {
            delete(entity);
            return true;
        }
        return false;
    }

    @Override
    public void update(E entity) {
    }

    @Override
    public E findById(K id) {
        return null;
    }

    @Override
    public E findById(K id, boolean lazy) {
        return null;
    }

    @Override
    public List<E> findAll() {
        return null;
    }

    @Override
    public QueryResult<E> findByPage(int page, int size) {
        return null;
    }

    @Override
    public QueryResult<E> findByPage(QueryBean queryBean, int page, int size) {
        return null;
    }

}

package com.jackfrued.dao;
import java.io.Serializable;
import java.lang.reflect.ParameterizedType;
import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import org.hibernate.Query;
import org.hibernate.Session;
import org.hibernate.SessionFactory;
import org.springframework.beans.factory.annotation.Autowired;
import com.jackfrued.comm.HQLQueryBean;
import com.jackfrued.comm.QueryBean;
import com.jackfrued.comm.QueryResult;

/**
 * 基于Hibernate的BaseDao实现类
 * @author 骆昊
 *
 * @param <E> 实体类型
 * @param <K> 主键类型
 */
@SuppressWarnings(value = {"unchecked"})
public abstract class BaseDaoHibernateImpl<E, K extends Serializable> extends BaseDaoAdapter<E, K> {
    @Autowired
    protected SessionFactory sessionFactory;

    private Class<?> entityClass;       // 业务实体的类对象
    private String entityName;          // 业务实体的名字

    public BaseDaoHibernateImpl() {
        ParameterizedType pt = (ParameterizedType) this.getClass().getGenericSuperclass();
        entityClass = (Class<?>) pt.getActualTypeArguments()[0];
        entityName = entityClass.getSimpleName();
    }

    @Override
    public K save(E entity) {
        return (K) sessionFactory.getCurrentSession().save(entity);
    }

    @Override
    public void delete(E entity) {
        sessionFactory.getCurrentSession().delete(entity);
    }

    @Override
    public void update(E entity) {
        sessionFactory.getCurrentSession().update(entity);
    }

    @Override
    public E findById(K id) {
        return findById(id, false);
    }

    @Override
    public E findById(K id, boolean lazy) {
        Session session = sessionFactory.getCurrentSession();
        return (E) (lazy? session.load(entityClass, id) : session.get(entityClass, id));
    }

    @Override
    public List<E> findAll() {
        return sessionFactory.getCurrentSession().createCriteria(entityClass).list();
    }

    @Override
    public QueryResult<E> findByPage(int page, int size) {
        return new QueryResult<E>(
            findByHQLAndPage("from " + entityName , page, size),
            getCountByHQL("select count(*) from " + entityName)
        );
    }

    @Override
    public QueryResult<E> findByPage(QueryBean queryBean, int page, int size) {
        if(queryBean instanceof HQLQueryBean) {
            HQLQueryBean hqlQueryBean = (HQLQueryBean) queryBean;
            return new QueryResult<E>(
                findByHQLAndPage(hqlQueryBean.getQueryString(), page, size, hqlQueryBean.getParameters()),
                getCountByHQL(hqlQueryBean.getCountString(), hqlQueryBean.getParameters())
            );
        }
        return null;
    }

    /**
     * 根据HQL和可变参数列表进行查询
     * @param hql 基于HQL的查询语句
     * @param params 可变参数列表
     * @return 持有查询结果的列表容器或空列表容器
     */
    protected List<E> findByHQL(String hql, Object... params) {
        return this.findByHQL(hql, getParamList(params));
    }

    /**
     * 根据HQL和参数列表进行查询
     * @param hql 基于HQL的查询语句
     * @param params 查询参数列表
     * @return 持有查询结果的列表容器或空列表容器
     */
    protected List<E> findByHQL(String hql, List<Object> params) {
        List<E> list = createQuery(hql, params).list();
        return list != null && list.size() > 0 ? list : Collections.EMPTY_LIST;
    }

    /**
     * 根据HQL和参数列表进行分页查询
     * @param hql 基于HQL的查询语句
     * @page 页码
     * @size 页面大小
     * @param params 可变参数列表
     * @return 持有查询结果的列表容器或空列表容器
     */
    protected List<E> findByHQLAndPage(String hql, int page, int size, Object... params) {
        return this.findByHQLAndPage(hql, page, size, getParamList(params));
    }

    /**
     * 根据HQL和参数列表进行分页查询
     * @param hql 基于HQL的查询语句
     * @page 页码
     * @size 页面大小
     * @param params 查询参数列表
     * @return 持有查询结果的列表容器或空列表容器
     */
    protected List<E> findByHQLAndPage(String hql, int page, int size, List<Object> params) {
        List<E> list = createQuery(hql, params)
                .setFirstResult((page - 1) * size)
                .setMaxResults(size)
                .list();
        return list != null && list.size() > 0 ? list : Collections.EMPTY_LIST;
    }

    /**
     * 查询满足条件的记录数
     * @param hql 基于HQL的查询语句
     * @param params 可变参数列表
     * @return 满足查询条件的总记录数
     */
    protected long getCountByHQL(String hql, Object... params) {
        return this.getCountByHQL(hql, getParamList(params));
    }

    /**
     * 查询满足条件的记录数
     * @param hql 基于HQL的查询语句
     * @param params 参数列表容器
     * @return 满足查询条件的总记录数
     */
    protected long getCountByHQL(String hql, List<Object> params) {
        return (Long) createQuery(hql, params).uniqueResult();
    }

    // 创建Hibernate查询对象(Query)
    private Query createQuery(String hql, List<Object> params) {
        Query query = sessionFactory.getCurrentSession().createQuery(hql);
        for(int i = 0; i < params.size(); i++) {
            query.setParameter(i, params.get(i));
        }
        return query;
    }

    // 将可变参数列表组装成列表容器
    private List<Object> getParamList(Object... params) {
        List<Object> paramList = new ArrayList<>();
        if(params != null) {
            for(int i = 0; i < params.length; i++) {
                paramList.add(params[i]);
            }
        }
        return paramList.size() == 0? Collections.EMPTY_LIST : paramList;
    }

}

package com.jackfrued.comm;

import java.util.List;

/**
 * 查询条件的接口
 * @author 骆昊
 *
 */
public interface QueryBean {

    /**
     * 添加排序字段
     * @param fieldName 用于排序的字段
     * @param asc 升序还是降序
     * @return 查询条件对象自身(方便级联编程)
     */
    public QueryBean addOrder(String fieldName, boolean asc);

    /**
     * 添加排序字段
     * @param available 是否添加此排序字段
     * @param fieldName 用于排序的字段
     * @param asc 升序还是降序
     * @return 查询条件对象自身(方便级联编程)
     */
    public QueryBean addOrder(boolean available, String fieldName, boolean asc);

    /**
     * 添加查询条件
     * @param condition 条件
     * @param params 替换掉条件中参数占位符的参数
     * @return 查询条件对象自身(方便级联编程)
     */
    public QueryBean addCondition(String condition, Object... params);

    /**
     * 添加查询条件
     * @param available 是否需要添加此条件
     * @param condition 条件
     * @param params 替换掉条件中参数占位符的参数
     * @return 查询条件对象自身(方便级联编程)
     */
    public QueryBean addCondition(boolean available, String condition, Object... params);

    /**
     * 获得查询语句
     * @return 查询语句
     */
    public String getQueryString();

    /**
     * 获取查询记录数的查询语句
     * @return 查询记录数的查询语句
     */
    public String getCountString();

    /**
     * 获得查询参数
     * @return 查询参数的列表容器
     */
    public List<Object> getParameters();
}

package com.jackfrued.comm;

import java.util.List;

/**
 * 查询结果
 * @author 骆昊
 *
 * @param <T> 泛型参数
 */
public class QueryResult<T> {
    private List<T> result;     // 持有查询结果的列表容器
    private long totalRecords;  // 查询到的总记录数

    /**
     * 构造器
     */
    public QueryResult() {
    }

    /**
     * 构造器
     * @param result 持有查询结果的列表容器
     * @param totalRecords 查询到的总记录数
     */
    public QueryResult(List<T> result, long totalRecords) {
        this.result = result;
        this.totalRecords = totalRecords;
    }

    public List<T> getResult() {
        return result;
    }

    public void setResult(List<T> result) {
        this.result = result;
    }

    public long getTotalRecords() {
        return totalRecords;
    }

    public void setTotalRecords(long totalRecords) {
        this.totalRecords = totalRecords;
    }
}

package com.jackfrued.dao;

import com.jackfrued.comm.QueryResult;
import com.jackfrued.entity.Dept;

/**
 * 部门数据访问对象接口
 * @author 骆昊
 *
 */
public interface DeptDao extends BaseDao<Dept, Integer> {

    /**
     * 分页查询顶级部门
     * @param page 页码
     * @param size 页码大小
     * @return 查询结果对象
     */
    public QueryResult<Dept> findTopDeptByPage(int page, int size);

}

package com.jackfrued.dao.impl;

import java.util.List;

import org.springframework.stereotype.Repository;

import com.jackfrued.comm.QueryResult;
import com.jackfrued.dao.BaseDaoHibernateImpl;
import com.jackfrued.dao.DeptDao;
import com.jackfrued.entity.Dept;

@Repository
public class DeptDaoImpl extends BaseDaoHibernateImpl<Dept, Integer> implements DeptDao {
    private static final String HQL_FIND_TOP_DEPT = " from Dept as d where d.superiorDept is null ";

    @Override
    public QueryResult<Dept> findTopDeptByPage(int page, int size) {
        List<Dept> list = findByHQLAndPage(HQL_FIND_TOP_DEPT, page, size);
        long totalRecords = getCountByHQL(" select count(*) " + HQL_FIND_TOP_DEPT);
        return new QueryResult<>(list, totalRecords);
    }

}

package com.jackfrued.comm;

import java.util.List;

/**
 * 分页器
 * @author 骆昊
 *
 * @param <T> 分页数据对象的类型
 */
public class PageBean<T> {
    private static final int DEFAUL_INIT_PAGE = 1;
    private static final int DEFAULT_PAGE_SIZE = 10;
    private static final int DEFAULT_PAGE_COUNT = 5;

    private List<T> data;           // 分页数据
    private PageRange pageRange;    // 页码范围
    private int totalPage;          // 总页数
    private int size;               // 页面大小
    private int currentPage;        // 当前页码
    private int pageCount;          // 页码数量

    /**
     * 构造器
     * @param currentPage 当前页码
     * @param size 页码大小
     * @param pageCount 页码数量
     */
    public PageBean(int currentPage, int size, int pageCount) {
        this.currentPage = currentPage > 0 ? currentPage : 1;
        this.size = size > 0 ? size : DEFAULT_PAGE_SIZE;
        this.pageCount = pageCount > 0 ? size : DEFAULT_PAGE_COUNT;
    }

    /**
     * 构造器
     * @param currentPage 当前页码
     * @param size 页码大小
     */
    public PageBean(int currentPage, int size) {
        this(currentPage, size, DEFAULT_PAGE_COUNT);
    }

    /**
     * 构造器
     * @param currentPage 当前页码
     */
    public PageBean(int currentPage) {
        this(currentPage, DEFAULT_PAGE_SIZE, DEFAULT_PAGE_COUNT);
    }

    /**
     * 构造器
     */
    public PageBean() {
        this(DEFAUL_INIT_PAGE, DEFAULT_PAGE_SIZE, DEFAULT_PAGE_COUNT);
    }

    public List<T> getData() {
        return data;
    }

    public int getStartPage() {
        return pageRange != null ? pageRange.getStartPage() : 1;
    }

    public int getEndPage() {
        return pageRange != null ? pageRange.getEndPage() : 1;
    }

    public long getTotalPage() {
        return totalPage;
    }

    public int getSize() {
        return size;
    }

    public int getCurrentPage() {
        return currentPage;
    }

    /**
     * 将查询结果转换为分页数据
     * @param queryResult 查询结果对象
     */
    public void transferQueryResult(QueryResult<T> queryResult) {
        long totalRecords = queryResult.getTotalRecords();

        data = queryResult.getResult();
        totalPage = (int) ((totalRecords + size - 1) / size);
        totalPage = totalPage >= 0 ? totalPage : Integer.MAX_VALUE;
        this.pageRange = new PageRange(pageCount, currentPage, totalPage);
    }

}

package com.jackfrued.comm;

/**
 * 页码范围
 * @author 骆昊
 *
 */
public class PageRange {
    private int startPage;  // 起始页码
    private int endPage;    // 终止页码

    /**
     * 构造器
     * @param pageCount 总共显示几个页码
     * @param currentPage 当前页码
     * @param totalPage 总页数
     */
    public PageRange(int pageCount, int currentPage, int totalPage) {
        startPage = currentPage - (pageCount - 1) / 2;
        endPage = currentPage + pageCount / 2;
        if(startPage < 1) {
            startPage = 1;
            endPage = totalPage > pageCount ? pageCount : totalPage;
        }
        if (endPage > totalPage) {
            endPage = totalPage;
            startPage = (endPage - pageCount > 0) ? endPage - pageCount + 1 : 1;
        }
    }

    /**
     * 获得起始页页码
     * @return 起始页页码
     */
    public int getStartPage() {
        return startPage;
    }

    /**
     * 获得终止页页码
     * @return 终止页页码
     */
    public int getEndPage() {
        return endPage;
    }

}

package com.jackfrued.biz;

import com.jackfrued.comm.PageBean;
import com.jackfrued.entity.Dept;

/**
 * 部门业务逻辑接口
 * @author 骆昊
 *
 */
public interface DeptService {

    /**
     * 创建新的部门
     * @param department 部门对象
     * @return 创建成功返回true否则返回false
     */
    public boolean createNewDepartment(Dept department);

    /**
     * 删除指定部门
     * @param id 要删除的部门的编号
     * @return 删除成功返回true否则返回false
     */
    public boolean deleteDepartment(Integer id);

    /**
     * 分页获取顶级部门
     * @param page 页码
     * @param size 页码大小
     * @return 部门对象的分页器对象
     */
    public PageBean<Dept> getTopDeptByPage(int page, int size);

}
package com.jackfrued.biz.impl;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;
import com.jackfrued.biz.DeptService;
import com.jackfrued.comm.PageBean;
import com.jackfrued.comm.QueryResult;
import com.jackfrued.dao.DeptDao;
import com.jackfrued.entity.Dept;

@Service
@Transactional  // 声明式事务的注解
public class DeptServiceImpl implements DeptService {
    @Autowired
    private DeptDao deptDao;

    @Override
    public boolean createNewDepartment(Dept department) {
        return deptDao.save(department) != null;
    }

    @Override
    public boolean deleteDepartment(Integer id) {
        return deptDao.deleteById(id);
    }

    @Override
    public PageBean<Dept> getTopDeptByPage(int page, int size) {
        QueryResult<Dept> queryResult = deptDao.findTopDeptByPage(page, size);
        PageBean<Dept> pageBean = new PageBean<>(page, size);
        pageBean.transferQueryResult(queryResult);
        return pageBean;
    }

}

154、如何在Web项目中配置Spring的IoC容器？
答：如果需要在Web项目中使用Spring的IoC容器，可以在Web项目配置文件web.xml中做出如下配置：

<context-param>
    <param-name>contextConfigLocation</param-name>
    <param-value>classpath:applicationContext.xml</param-value>
</context-param>

<listener>
    <listener-class>
        org.springframework.web.context.ContextLoaderListener
    </listener-class>
</listener>


155、如何在Web项目中配置Spring MVC？
答：要使用Spring MVC需要在Web项目配置文件中配置其前端控制器DispatcherServlet，说明：上面的配置中使用了*.html的后缀映射，这样做一方面不能够通过URL推断采用了何种服务器端的技术，另一方面可以欺骗搜索引擎，因为搜索引擎不会搜索动态页面，这种做法称为伪静态化。

    <web-app>
        <servlet>
            <servlet-name>example</servlet-name>
            <servlet-class>
                org.springframework.web.servlet.DispatcherServlet
            </servlet-class>
            <load-on-startup>1</load-on-startup>
        </servlet>

        <servlet-mapping>
            <servlet-name>example</servlet-name>
            <url-pattern>*.html</url-pattern>
        </servlet-mapping>
    </web-app>


156、Spring MVC的工作原理是怎样的？ 
答：Spring MVC的工作原理如下图所示： 
这里写图片描述
① 客户端的所有请求都交给前端控制器DispatcherServlet来处理，它会负责调用系统的其他模块来真正处理用户的请求。
② DispatcherServlet收到请求后，将根据请求的信息（包括URL、HTTP协议方法、请求头、请求参数、Cookie等）以及HandlerMapping的配置找到处理该请求的Handler（任何一个对象都可以作为请求的Handler）。
③在这个地方Spring会通过HandlerAdapter对该处理器进行封装。
④ HandlerAdapter是一个适配器，它用统一的接口对各种Handler中的方法进行调用。
⑤ Handler完成对用户请求的处理后，会返回一个ModelAndView对象给DispatcherServlet，ModelAndView顾名思义，包含了数据模型以及相应的视图的信息。
⑥ ModelAndView的视图是逻辑视图，DispatcherServlet还要借助ViewResolver完成从逻辑视图到真实视图对象的解析工作。
⑦ 当得到真正的视图对象后，DispatcherServlet会利用视图对象对模型数据进行渲染。
⑧ 客户端得到响应，可能是一个普通的HTML页面，也可以是XML或JSON字符串，还可以是一张图片或者一个PDF文件。

157、如何在Spring IoC容器中配置数据源？
答：
DBCP配置：

<bean id="dataSource"
        class="org.apache.commons.dbcp.BasicDataSource" destroy-method="close">
    <property name="driverClassName" value="${jdbc.driverClassName}"/>
    <property name="url" value="${jdbc.url}"/>
    <property name="username" value="${jdbc.username}"/>
    <property name="password" value="${jdbc.password}"/>
</bean>

<context:property-placeholder location="jdbc.properties"/>

C3P0配置：

<bean id="dataSource"
        class="com.mchange.v2.c3p0.ComboPooledDataSource" destroy-method="close">
    <property name="driverClass" value="${jdbc.driverClassName}"/>
    <property name="jdbcUrl" value="${jdbc.url}"/>
    <property name="user" value="${jdbc.username}"/>
    <property name="password" value="${jdbc.password}"/>
</bean>

<context:property-placeholder location="jdbc.properties"/>

    提示： DBCP的详细配置在第153题中已经完整的展示过了。

158、如何配置配置事务增强？
答：
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
     xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
     xmlns:aop="http://www.springframework.org/schema/aop"
     xmlns:tx="http://www.springframework.org/schema/tx"
     xsi:schemaLocation="
     http://www.springframework.org/schema/beans
     http://www.springframework.org/schema/beans/spring-beans.xsd
     http://www.springframework.org/schema/tx
     http://www.springframework.org/schema/tx/spring-tx.xsd
     http://www.springframework.org/schema/aop
     http://www.springframework.org/schema/aop/spring-aop.xsd">

  <!-- this is the service object that we want to make transactional -->
  <bean id="fooService" class="x.y.service.DefaultFooService"/>

  <!-- the transactional advice -->
  <tx:advice id="txAdvice" transaction-manager="txManager">
  <!-- the transactional semantics... -->
  <tx:attributes>
    <!-- all methods starting with 'get' are read-only -->
    <tx:method name="get*" read-only="true"/>
    <!-- other methods use the default transaction settings (see below) -->
    <tx:method name="*"/>
  </tx:attributes>
  </tx:advice>

  <!-- ensure that the above transactional advice runs for any execution
    of an operation defined by the FooService interface -->
  <aop:config>
  <aop:pointcut id="fooServiceOperation" 
    expression="execution(* x.y.service.FooService.*(..))"/>
  <aop:advisor advice-ref="txAdvice" pointcut-ref="fooServiceOperation"/>
  </aop:config>

  <!-- don't forget the DataSource -->
  <bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource"
    destroy-method="close">
  <property name="driverClassName" value="oracle.jdbc.driver.OracleDriver"/>
  <property name="url" value="jdbc:oracle:thin:@localhost:1521:orcl"/>
  <property name="username" value="scott"/>
  <property name="password" value="tiger"/>
  </bean>

  <!-- similarly, don't forget the PlatformTransactionManager -->
  <bean id="txManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager">
  <property name="dataSource" ref="dataSource"/>
  </bean>

  <!-- other <bean/> definitions here -->

</beans>

159、选择使用Spring框架的原因（Spring框架为企业级开发带来的好处有哪些）？
答：可以从以下几个方面作答：
- 非侵入式：支持基于POJO的编程模式，不强制性的要求实现Spring框架中的接口或继承Spring框架中的类。
- IoC容器：IoC容器帮助应用程序管理对象以及对象之间的依赖关系，对象之间的依赖关系如果发生了改变只需要修改配置文件而不是修改代码，因为代码的修改可能意味着项目的重新构建和完整的回归测试。有了IoC容器，程序员再也不需要自己编写工厂、单例，这一点特别符合Spring的精神"不要重复的发明轮子"。
- AOP（面向切面编程）：将所有的横切关注功能封装到切面（aspect）中，通过配置的方式将横切关注功能动态添加到目标代码上，进一步实现了业务逻辑和系统服务之间的分离。另一方面，有了AOP程序员可以省去很多自己写代理类的工作。
- MVC：Spring的MVC框架是非常优秀的，从各个方面都可以甩Struts 2几条街，为Web表示层提供了更好的解决方案。
- 事务管理：Spring以宽广的胸怀接纳多种持久层技术，并且为其提供了声明式的事务管理，在不需要任何一行代码的情况下就能够完成事务管理。
- 其他：选择Spring框架的原因还远不止于此，Spring为Java企业级开发提供了一站式选择，你可以在需要的时候使用它的部分和全部，更重要的是，你甚至可以在感觉不到Spring存在的情况下，在你的项目中使用Spring提供的各种优秀的功能。

160、Spring IoC容器配置Bean的方式？
答：
- 基于XML文件进行配置。
- 基于注解进行配置。
- 基于Java程序进行配置（Spring 3+）
package com.jackfrued.bean;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;
@Component
public class Person {
    private String name;
    private int age;
    @Autowired
    private Car car;

    public Person(String name, int age) {
        this.name = name;
        this.age = age;
    }

    public void setCar(Car car) {
        this.car = car;
    }

    @Override
    public String toString() {
        return "Person [name=" + name + ", age=" + age + ", car=" + car + "]";
    }

}

package com.jackfrued.bean;

import org.springframework.stereotype.Component;

@Component
public class Car {
    private String brand;
    private int maxSpeed;

    public Car(String brand, int maxSpeed) {
        this.brand = brand;
        this.maxSpeed = maxSpeed;
    }

    @Override
    public String toString() {
        return "Car [brand=" + brand + ", maxSpeed=" + maxSpeed + "]";
    }

}

package com.jackfrued.config;

import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

import com.jackfrued.bean.Car;
import com.jackfrued.bean.Person;

@Configuration
public class AppConfig {

    @Bean
    public Car car() {
        return new Car("Benz", 320);
    }

    @Bean
    public Person person() {
        return new Person("骆昊", 34);
    }
}

package com.jackfrued.test;

import org.springframework.context.ConfigurableApplicationContext;
import org.springframework.context.annotation.AnnotationConfigApplicationContext;

import com.jackfrued.bean.Person;
import com.jackfrued.config.AppConfig;

class Test {

    public static void main(String[] args) {
        // TWR (Java 7+)
        try(ConfigurableApplicationContext factory = new AnnotationConfigApplicationContext(AppConfig.class)) {
            Person person = factory.getBean(Person.class);
            System.out.println(person);
        }
    }
}

161、阐述Spring框架中Bean的生命周期？
答：
① Spring IoC容器找到关于Bean的定义并实例化该Bean。
② Spring IoC容器对Bean进行依赖注入。
③ 如果Bean实现了BeanNameAware接口，则将该Bean的id传给setBeanName方法。
④ 如果Bean实现了BeanFactoryAware接口，则将BeanFactory对象传给setBeanFactory方法。
⑤ 如果Bean实现了BeanPostProcessor接口，则调用其postProcessBeforeInitialization方法。
⑥ 如果Bean实现了InitializingBean接口，则调用其afterPropertySet方法。
⑦ 如果有和Bean关联的BeanPostProcessors对象，则这些对象的postProcessAfterInitialization方法被调用。
⑧ 当销毁Bean实例时，如果Bean实现了DisposableBean接口，则调用其destroy方法。

162、依赖注入时如何注入集合属性？
答：可以在定义Bean属性时，通过<list> / <set> / <map> / <props>分别为其注入列表、集合、映射和键值都是字符串的映射属性。

163、Spring中的自动装配有哪些限制？
答：
- 如果使用了构造器注入或者setter注入，那么将覆盖自动装配的依赖关系。
- 基本数据类型的值、字符串字面量、类字面量无法使用自动装配来注入。
- 优先考虑使用显式的装配来进行更精确的依赖注入而不是使用自动装配。

164、在Web项目中如何获得Spring的IoC容器？
答：
WebApplicationContext ctx = 
WebApplicationContextUtils.getWebApplicationContext(servletContext);

165. 大型网站在架构上应当考虑哪些问题？
答：
- 分层：分层是处理任何复杂系统最常见的手段之一，将系统横向切分成若干个层面，每个层面只承担单一的职责，然后通过下层为上层提供的基础设施和服务以及上层对下层的调用来形成一个完整的复杂的系统。计算机网络的开放系统互联参考模型（OSI/RM）和Internet的TCP/IP模型都是分层结构，大型网站的软件系统也可以使用分层的理念将其分为持久层（提供数据存储和访问服务）、业务层（处理业务逻辑，系统中最核心的部分）和表示层（系统交互、视图展示）。需要指出的是：（1）分层是逻辑上的划分，在物理上可以位于同一设备上也可以在不同的设备上部署不同的功能模块，这样可以使用更多的计算资源来应对用户的并发访问；（2）层与层之间应当有清晰的边界，这样分层才有意义，才更利于软件的开发和维护。
- 分割：分割是对软件的纵向切分。我们可以将大型网站的不同功能和服务分割开，形成高内聚低耦合的功能模块（单元）。在设计初期可以做一个粗粒度的分割，将网站分割为若干个功能模块，后期还可以进一步对每个模块进行细粒度的分割，这样一方面有助于软件的开发和维护，另一方面有助于分布式的部署，提供网站的并发处理能力和功能的扩展。
- 分布式：除了上面提到的内容，网站的静态资源（JavaScript、CSS、图片等）也可以采用独立分布式部署并采用独立的域名，这样可以减轻应用服务器的负载压力，也使得浏览器对资源的加载更快。数据的存取也应该是分布式的，传统的商业级关系型数据库产品基本上都支持分布式部署，而新生的NoSQL产品几乎都是分布式的。当然，网站后台的业务处理也要使用分布式技术，例如查询索引的构建、数据分析等，这些业务计算规模庞大，可以使用Hadoop以及MapReduce分布式计算框架来处理。
- 集群：集群使得有更多的服务器提供相同的服务，可以更好的提供对并发的支持。
- 缓存：所谓缓存就是用空间换取时间的技术，将数据尽可能放在距离计算最近的位置。使用缓存是网站优化的第一定律。我们通常说的CDN、反向代理、热点数据都是对缓存技术的使用。
- 异步：异步是实现软件实体之间解耦合的又一重要手段。异步架构是典型的生产者消费者模式，二者之间没有直接的调用关系，只要保持数据结构不变，彼此功能实现可以随意变化而不互相影响，这对网站的扩展非常有利。使用异步处理还可以提高系统可用性，加快网站的响应速度（用Ajax加载数据就是一种异步技术），同时还可以起到削峰作用（应对瞬时高并发）。&quot；能推迟处理的都要推迟处理"是网站优化的第二定律，而异步是践行网站优化第二定律的重要手段。
- 冗余：各种服务器都要提供相应的冗余服务器以便在某台或某些服务器宕机时还能保证网站可以正常工作，同时也提供了灾难恢复的可能性。冗余是网站高可用性的重要保证。

166、你用过的网站前端优化的技术有哪些？
答：
① 浏览器访问优化：
- 减少HTTP请求数量：合并CSS、合并JavaScript、合并图片（CSS Sprite）
- 使用浏览器缓存：通过设置HTTP响应头中的Cache-Control和Expires属性，将CSS、JavaScript、图片等在浏览器中缓存，当这些静态资源需要更新时，可以更新HTML文件中的引用来让浏览器重新请求新的资源
- 启用压缩
- CSS前置，JavaScript后置
- 减少Cookie传输
② CDN加速：CDN（Content Distribute Network）的本质仍然是缓存，将数据缓存在离用户最近的地方，CDN通常部署在网络运营商的机房，不仅可以提升响应速度，还可以减少应用服务器的压力。当然，CDN缓存的通常都是静态资源。
③ 反向代理：反向代理相当于应用服务器的一个门面，可以保护网站的安全性，也可以实现负载均衡的功能，当然最重要的是它缓存了用户访问的热点资源，可以直接从反向代理将某些内容返回给用户浏览器。

167、你使用过的应用服务器优化技术有哪些？
答：
① 分布式缓存：缓存的本质就是内存中的哈希表，如果设计一个优质的哈希函数，那么理论上哈希表读写的渐近时间复杂度为O(1)。缓存主要用来存放那些读写比很高、变化很少的数据，这样应用程序读取数据时先到缓存中读取，如果没有或者数据已经失效再去访问数据库或文件系统，并根据拟定的规则将数据写入缓存。对网站数据的访问也符合二八定律（Pareto分布，幂律分布），即80%的访问都集中在20%的数据上，如果能够将这20%的数据缓存起来，那么系统的性能将得到显著的改善。当然，使用缓存需要解决以下几个问题：
- 频繁修改的数据；
- 数据不一致与脏读；
- 缓存雪崩（可以采用分布式缓存服务器集群加以解决，memcached是广泛采用的解决方案）；
- 缓存预热；
- 缓存穿透（恶意持续请求不存在的数据）。
② 异步操作：可以使用消息队列将调用异步化，通过异步处理将短时间高并发产生的事件消息存储在消息队列中，从而起到削峰作用。电商网站在进行促销活动时，可以将用户的订单请求存入消息队列，这样可以抵御大量的并发订单请求对系统和数据库的冲击。目前，绝大多数的电商网站即便不进行促销活动，订单系统都采用了消息队列来处理。
③ 使用集群。
④ 代码优化：
- 多线程：基于Java的Web开发基本上都通过多线程的方式响应用户的并发请求，使用多线程技术在编程上要解决线程安全问题，主要可以考虑以下几个方面：A. 将对象设计为无状态对象（这和面向对象的编程观点是矛盾的，在面向对象的世界中被视为不良设计），这样就不会存在并发访问时对象状态不一致的问题。B. 在方法内部创建对象，这样对象由进入方法的线程创建，不会出现多个线程访问同一对象的问题。使用ThreadLocal将对象与线程绑定也是很好的做法，这一点在前面已经探讨过了。C. 对资源进行并发访问时应当使用合理的锁机制。
- 非阻塞I/O： 使用单线程和非阻塞I/O是目前公认的比多线程的方式更能充分发挥服务器性能的应用模式，基于Node.js构建的服务器就采用了这样的方式。Java在JDK 1.4中就引入了NIO（Non-blocking I/O）,在Servlet 3规范中又引入了异步Servlet的概念，这些都为在服务器端采用非阻塞I/O提供了必要的基础。
- 资源复用：资源复用主要有两种方式，一是单例，二是对象池，我们使用的数据库连接池、线程池都是对象池化技术，这是典型的用空间换取时间的策略，另一方面也实现对资源的复用，从而避免了不必要的创建和释放资源所带来的开销。

168、什么是XSS攻击？什么是SQL注入攻击？什么是CSRF攻击？ 
答： 
- XSS（Cross Site Script，跨站脚本攻击）是向网页中注入恶意脚本在用户浏览网页时在用户浏览器中执行恶意脚本的攻击方式。跨站脚本攻击分有两种形式：反射型攻击（诱使用户点击一个嵌入恶意脚本的链接以达到攻击的目标，目前有很多攻击者利用论坛、微博发布含有恶意脚本的URL就属于这种方式）和持久型攻击（将恶意脚本提交到被攻击网站的数据库中，用户浏览网页时，恶意脚本从数据库中被加载到页面执行，QQ邮箱的早期版本就曾经被利用作为持久型跨站脚本攻击的平台）。XSS虽然不是什么新鲜玩意，但是攻击的手法却不断翻新，防范XSS主要有两方面：消毒（对危险字符进行转义）和HttpOnly（防范XSS攻击者窃取Cookie数据）。
- SQL注入攻击是注入攻击最常见的形式（此外还有OS注入攻击（Struts 2的高危漏洞就是通过OGNL实施OS注入攻击导致的）），当服务器使用请求参数构造SQL语句时，恶意的SQL被嵌入到SQL中交给数据库执行。SQL注入攻击需要攻击者对数据库结构有所了解才能进行，攻击者想要获得表结构有多种方式：（1）如果使用开源系统搭建网站，数据库结构也是公开的（目前有很多现成的系统可以直接搭建论坛，电商网站，虽然方便快捷但是风险是必须要认真评估的）；（2）错误回显（如果将服务器的错误信息直接显示在页面上，攻击者可以通过非法参数引发页面错误从而通过错误信息了解数据库结构，Web应用应当设置友好的错误页，一方面符合最小惊讶原则，一方面屏蔽掉可能给系统带来危险的错误回显信息）；（3）盲注。防范SQL注入攻击也可以采用消毒的方式，通过正则表达式对请求参数进行验证，此外，参数绑定也是很好的手段，这样恶意的SQL会被当做SQL的参数而不是命令被执行，JDBC中的PreparedStatement就是支持参数绑定的语句对象，从性能和安全性上都明显优于Statement。
- CSRF攻击（Cross Site Request Forgery，跨站请求伪造）是攻击者通过跨站请求，以合法的用户身份进行非法操作（如转账或发帖等）。CSRF的原理是利用浏览器的Cookie或服务器的Session，盗取用户身份，其原理如下图所示。防范CSRF的主要手段是识别请求者的身份，主要有以下几种方式：（1）在表单中添加令牌（token）；（2）验证码；（3）检查请求头中的Referer（前面提到防图片盗链接也是用的这种方式）。令牌和验证都具有一次消费性的特征，因此在原理上一致的，但是验证码是一种糟糕的用户体验，不是必要的情况下不要轻易使用验证码，目前很多网站的做法是如果在短时间内多次提交一个表单未获得成功后才要求提供验证码，这样会获得较好的用户体验。

补充：防火墙的架设是Web安全的重要保障，ModSecurity是开源的Web防火墙中的佼佼者。企业级防火墙的架设应当有两级防火墙，Web服务器和部分应用服务器可以架设在两级防火墙之间的DMZ，而数据和资源服务器应当架设在第二级防火墙之后。

169. 什么是领域模型(domain model)？贫血模型(anaemic domain model)和充血模型(rich domain model)有什么区别？
答：领域模型是领域内的概念类或现实世界中对象的可视化表示，又称为概念模型或分析对象模型，它专注于分析问题领域本身，发掘重要的业务领域概念，并建立业务领域概念之间的关系。贫血模型是指使用的领域对象中只有setter和getter方法（POJO），所有的业务逻辑都不包含在领域对象中而是放在业务逻辑层。有人将我们这里说的贫血模型进一步划分成失血模型（领域对象完全没有业务逻辑）和贫血模型（领域对象有少量的业务逻辑），我们这里就不对此加以区分了。充血模型将大多数业务逻辑和持久化放在领域对象中，业务逻辑（业务门面）只是完成对业务逻辑的封装、事务和权限等的处理。下面两张图分别展示了贫血模型和充血模型的分层架构。

贫血模型下组织领域逻辑通常使用事务脚本模式，让每个过程对应用户可能要做的一个动作，每个动作由一个过程来驱动。也就是说在设计业务逻辑接口的时候，每个方法对应着用户的一个操作，这种模式有以下几个有点：
- 它是一个大多数开发者都能够理解的简单过程模型（适合国内的绝大多数开发者）。 
- 它能够与一个使用行数据入口或表数据入口的简单数据访问层很好的协作。 
- 事务边界的显而易见，一个事务开始于脚本的开始，终止于脚本的结束，很容易通过代理（或切面）实现声明式事务。 
然而，事务脚本模式的缺点也是很多的，随着领域逻辑复杂性的增加，系统的复杂性将迅速增加，程序结构将变得极度混乱。开源中国社区上有一篇很好的译文《贫血领域模型是如何导致糟糕的软件产生》对这个问题做了比较细致的阐述。

170. 谈一谈测试驱动开发（TDD）的好处以及你的理解。 
答：TDD是指在编写真正的功能实现代码之前先写测试代码，然后根据需要重构实现代码。在JUnit的作者Kent Beck的大作《测试驱动开发：实战与模式解析》（Test-Driven Development: by Example）一书中有这么一段内容：“消除恐惧和不确定性是编写测试驱动代码的重要原因”。因为编写代码时的恐惧会让你小心试探，让你回避沟通，让你羞于得到反馈，让你变得焦躁不安，而TDD是消除恐惧、让Java开发者更加自信更加乐于沟通的重要手段。TDD会带来的好处可能不会马上呈现，但是你在某个时候一定会发现，这些好处包括：
- 更清晰的代码 — 只写需要的代码 
- 更好的设计 
- 更出色的灵活性 — 鼓励程序员面向接口编程 
- 更快速的反馈 — 不会到系统上线时才知道bug的存在
补充：敏捷软件开发的概念已经有很多年了，而且也部分的改变了软件开发这个行业，TDD也是敏捷开发所倡导的。
TDD可以在多个层级上应用，包括单元测试（测试一个类中的代码）、集成测试（测试类之间的交互）、系统测试（测试运行的系统）和系统集成测试（测试运行的系统包括使用的第三方组件）。TDD的实施步骤是：红（失败测试）- 绿（通过测试） - 重构。
在使用TDD开发时，经常会遇到需要被测对象需要依赖其他子系统的情况，但是你希望将测试代码跟依赖项隔离，以保证测试代码仅仅针对当前被测对象或方法展开，这时候你需要的是测试替身。测试替身可以分为四类：
- 虚设替身：只传递但是不会使用到的对象，一般用于填充方法的参数列表 
- 存根替身：总是返回相同的预设响应，其中可能包括一些虚设状态 
- 伪装替身：可以取代真实版本的可用版本（比真实版本还是会差很多） 
- 模拟替身：可以表示一系列期望值的对象，并且可以提供预设响应 


171 说下java中内存泄漏的场景 ？
Java的一个重要特性就是通过垃圾收集器(GC)自动管理内存的回收，而不需要程序员自己来释放内存。理论上Java中所有不会再被利用的对象所占用的内存，都可以被GC回收，但是Java也存在内存泄露，但它的表现与C++不同。
释放对象的根本原则就是对象不会再被使用：
给对象赋予了空值null，之后再没有调用过。
另一个是给对象赋予了新值，这样重新分配了内存空间。
不再会被使用的对象的内存不能被回收，就是内存泄露。
对象都是有生命周期的，有的长，有的短，如果长生命周期的对象持有短生命周期的引用，就很可能会出现内存泄露

在堆中的分配的内存，在没有将其释放掉的时候，就将所有能访问这块内存的方式都删掉（如指针重新赋值），这是针对c++等语言的，Java中的GC会帮我们处理这种情况，所以我们无需关心。
在内存对象明明已经不需要的时候，还仍然保留着这块内存和它的访问方式（引用），这是所有语言都有可能会出现的内存泄漏方式。编程时如果不小心，我们很容易发生这种情况，如果不太严重，可能就只是短暂的内存泄露。

解决的原则就是尽量减小对象的作用域（将类的成员变量改写为方法内的局部变量）以及手动设置null值。

例子1：
Java容器ArrayList是数组实现的（可参考：Java之ArrayList源码解读（JDK 1.8）），如果我们要为其写一个pop()（弹出）方法，可能会是这样：:
        public E pop(){
            if(size == 0)
                return null;
            else
                return (E) elementData[--size];
        }

 写法很简洁，但这里却会造成内存溢出：elementData[size-1]依然持有E类型对象的引用，并且暂时不能被GC回收。我们可以如下修改：

        public E pop(){
            if(size == 0)
                return null;
            else{
                E e = (E) elementData[--size];
                elementData[size] = null;
                return e;
            }
        }
		
		http://blog.csdn.net/anxpp/article/details/51325838
		
		
		
例子2：
		void method(){
            Vector vector = new Vector();
            for (int i = 1; i<100; i++)
            {
                Object object = new Object();
                vector.add(object);
                object = null;
            }
            //...对v的操作
            vector = null;
            //...与v无关的其他操作
        }
		
		
		
例子3：
    比如数据库连接（dataSourse.getConnection()），网络连接(socket)和io连接，以及使用其他框架的时候，除非其显式的调用了其close()方法（或类似方法）将其连接关闭，否则是不会自动被GC回收的。
	其实原因依然是长生命周期对象持有短生命周期对象的引用。
    可能很多人使用过Hibernate，我们操作数据库时，通过SessionFactory获取一个session：
    Session session=sessionFactory.openSession();
    完成后我们必须调用close()方法关闭：
    session.close();

    SessionFactory就是一个长生命周期的对象，而session相对是个短生命周期的对象，但是框架这么设计是合理的：它并不清楚我们要使用session到多久，于是只能提供一个方法让我们自己决定何时不再使用。
    因为在close()方法调用之前，可能会抛出异常而导致方法不能被调用，我们通常使用try语言，然后再finally语句中执行close()等清理工作：
	try{
		session=sessionFactory.openSession();
		//...其他操作
	}finally{
		session.close();
	}
		
		
例子4：单例模式，很多时候我们可以把它的生命周期与整个程序的生命周期看做差不多的，所以是一个长生命周期的对象。如果这个对象持有其他对象的引用，也很容易发生内存泄露。

gc()对于程序员来说，GC基本是透明的，不可见的。运行GC的函数是System.gc()，调用后启动垃圾回收器开始清理。但是根据Java语言规范定义， 该函数不保证JVM的垃圾收集器一定会执行。因为，不同的JVM实现者可能使用不同的算法管理GC。通常，GC的线程的优先级别较低。
finalize()，finalize()是Object类中的方法。当在java中调用非java代码（如c和c++）时，在这些非java代码中可能会用到相应的申请内存的操作（如c的malloc()函数），而在这些非java代码中并没有有效的释放这些内存，就可以使用finalize()方法，并在里面调用本地方法的free()等函数。
所以finalize()并不适合用作普通的清理工作。
内存泄露问题，还是编码不认真导致的，我们并不能责怪JVM没有更合理的清理。

172 hashmap和hashtable什么区别？
Hashmap：线程不安全,允许有null的键和值,效率高,方法不是Synchronize的要提供外同步
Hashtable：线程安全,不允许有null的键和值,效率稍低,方法是是Synchronize的 


173 单例模式有什么优缺点？枚举实现单例好处？
【采用原因】
对于系统中的某些类来说，只有一个实例很重要，
例如，一个系统中可以存在多个打印任务，但是只能有一个正在工作的任务；一个系统只能有一个窗口管理器或文件系统；一个系统只能有一个计时工具或ID(序号)生成器。
如在Windows中就只能打开一个任务管理器。如果不使用机制对窗口对象进行唯一化，将弹出多个窗口，如果这些窗口显示的内容完全一致，则是重复对象，浪费内存资源；
比如说一些大对象，如果能够不断初始化实例，那么内存消耗会不断变大。
【单例优点】
1、提供了对唯一实例的受控访问，保证了重要交易的准确性。
2、由于在系统内存中只存在一个对象，因此可以节约系统资源，对于一些需要频繁创建和销毁的对象单例模式无疑可以提高系统的性能。
【单例缺点】
1、在多线程情况下为了线程安全 同步可能会影响性能 
2、单例类的职责过重，在一定程度上违背了单一职责原则。
3、滥用单例将带来一些负面问题，如为了节省资源将数据库连接池对象设计为的单例类，可能会导致共享连接池对象的程序过多而出现连接池溢出；如果实例化的对象长时间不被利用，系统会认为是垃圾而被回收，这将导致对象状态的丢失。
【 枚举单例】
 枚举单例是java中使用枚举提供一个实例对象来实现单例模式的一种新方法，虽然单例模式在java中早已存在，但枚举单例实际上从java5引入枚举作为它的关键特性之后相对来说还是一个新的概念
 1）枚举单例模式代码简洁
 public class Singleton{
    private static final Singleton INSTANCE = new Singleton();
    private Singleton(){}
    public static Singleton getSingleton(){
        return INSTANCE;
    }
}
  2）枚举单例可以自己处理序列化，传统的单例模式的另外一个问题是一旦你实现了serializable接口，他们就不再是单例的了，因为readObject()方法总是返回一个 新的实例对象，就像java中的构造器一样。你可以使用readResolve()方法来避免这种情况
  3）枚举单例是线程安全的，由于枚举实例的创建默认就是线程安全的，你不需要担心双检锁问题。
  
174 静态代理和动态代理区别？
动态代理做到了开闭原则，静态代理没有做到对修改开放

175 策略模式和模板方法模式解决什么问题？
模板方法模式的主要思想：定义一个算法流程，将一些特定步骤的具体实现、延迟到子类。使得可以在不改变算法流程的情况下，通过不同的子类、来实现“定制”流程中的特定的步骤。
策略模式的主要思想：使不同的算法可以被相互替换，而不影响客户端的使用。
在思想和意图上看，模板方法更加强调：
1）定义一条线（算法流程），线上的多个点是可以变化的（具体实现在子类中完成），线上的多个点一定是会被执行的，并且一定是按照特定流程被执行的。
2）算法流程只有唯一的入口，对于点的访问是受限的【通常用受保护的虚函数来定义可变点】。
策略模式更注重于： 一个“策略”是一个 整体的(完整的) 算法，算法是可以被整体替换的。而模板方法只能被替换其中的特定点，算法流程是固定不可变的。
在这样的细节上看来，模板方法 和 一组策略模式 是不可以划等号的。
比如说定义一个业务抽象类，有一个execute方法，包括 initData,doValidate,doBusiness,doAfterBusiness等方法，那么 execute就是一个模板方法，由不同的子类继承，可以走不同的路线，可以去除doValidate但是整体顺序是不变的
子类也可以完全重写doAfterBusiness是策略模式。

176 linux命令
包含XXX名字的进程；ps -ef|grep nginx 
包含XXX名字的文件；find /home -name *.log   
包含XXX名字的日志；find /home -type f -name *erp*.log  
监控日志最后20行；tail -f -n 1000 ops-web-erp.log | perl -pe 's/(22)/\e[1;31m$1\e[0m/g' 
切换用户；su -ddd
退出编辑文本；:q! 
授权777；chmod dd 777 
CPU 内存监控情况 ；top free  


177类的加载器有哪几种？分别加载什么类？
（1） 根类加载器(Bootstrap) 它负责加载虚拟机的核心类库，如java.lang.*等
使用C++编写，它的实现依赖于底层操作系统，它并没有继承java.lang.ClassLoader类
（2） 扩展类加载器(Extension) 它的父加载器为根类加载器，它从jre\lib\ext子目录下加载类库，它使用Java代码实现，是java.lang.ClassLoader类的子类。
（3） 系统(应用)类加载器(System\App)  它的父加载器为扩展类加载器，它从环境变量classpath中加载类，它是用户自定义的类加载器的默认父加载器。它使用java实现，是java.lang.ClassLoader类的子类。
（4）自定义加载器(必须继承ClassLoader)
java的类加载器 ，采用父委托机制,类加载机制是为了保障jvm的安全，先去父类找，父类没有才去子类找，这样就避免了系统自身的方法不被覆盖。如果你试图写一个lang的类去覆盖java.lang，因为类的加载机制，所以不可能成功。
父亲委托机制的优点是能够提高软件系统的安全性。因为在此机制下，用户自定义的类加载器不可能加载应该由父加载器加载的可靠类，从而防止不可靠甚至恶意的代码代替由父加载器加载的可靠代码。
例如，java.lang.Object类总是由根类加载器加载，其他任何用户自定义的类加载器都不可能加载含有恶意代码的java.lang.Object类。


178 讲下字符串的jvm内存分配,堆和栈是什么？
（1）使用关键字new，如：String s1 = new String(“myString”);
第一种方式通过关键字new定义过程：在程序编译期，编译程序先去字符串常量池检查，是否存在“myString”,如果不存在，
则在常量池中开辟一个内存空间存放“myString”；如果存在的话，则不用重新开辟空间，保证常量池中只有一个“myString”常量，节省内存空间。
然后在内存堆中开辟一块空间存放new出来的String实例，在栈中开辟一块空间，命名为“s1”，存放的值为堆中String实例的内存地址，这个过程就是将引用s1指向new出来的String实例。
各位，最模糊的地方到了！堆中new出来的实例和常量池中的“myString”是什么关系呢？等我们分析完了第二种定义方式之后再回头分析这个问题。

（2）直接定义，如：String s1 = “myString”;
第二种方式直接定义过程：在程序编译期，编译程序先去字符串常量池检查，是否存在“myString”，如果不存在，则在常量池中开辟一个内存空间存放“myString”；如果存在的话，则不用重新开辟空间。
然后在栈中开辟一块空间，命名为“s1”，存放的值为常量池中“myString”的内存地址。常量池中的字符串常量与堆中的String对象有什么区别呢？为什么直接定义的字符串同样可以调用String对象的各种方法呢？
常量池中的字符串常量实质上是一个String实例，与堆中的String实例是克隆关系

（3）String str=”kv”+”ill”+” “+”ans”; 
由于String类的immutable性质,这一说又要说很多，大家只 要知道String的实例一旦生成就不会再改变了，比如说：String str=”kv”+”ill”+” “+”ans”; 就是有4个字符串常量，
首先”kv”和”ill”生成了”kvill”存在内存中，然后”kvill”又和” ” 生成 “kvill “存在内存中，最后又和生成了”kvill ans”;并把这个字符串的地址赋给了str,就是因为String的
”不可变”产生了很多临时变量，这也就是为什么建议用StringBuffer的原 因了，因为StringBuffer是可改变的。

179设计工具用过哪些？继承和接口实现用什么箭头表示？
Powerdesigner和visio
实线三角形是继承，虚线三角形是实线接口

180 hashmap内部实现原理？
一、HashMap概述
HashMap是基于哈希表的Map接口的非同步实现。此实现提供所有可选的映射操作，并允许使用null值和null键。此类不保证映射的顺序，特别是它不保证该顺序恒久不变。

二、HashMap的数据结构
在Java编程语言中，最基本的结构就是两种，一个是数组，另外一个是模拟指针（引用），所有的数据结构都可以用这两个基本结构来构造的，HashMap也不例外。HashMap实际上是一个“链表散列”的数据结构，即数组和链表的结合体。
从上图中可以看出，HashMap底层就是一个数组结构，数组中的每一项又是一个链表。当新建一个HashMap的时候，就会初始化一个数组。

/**
* The table, resized as necessary. Length MUST Always be a power of two.
*/
transient Entry[] table;
static class Entry<K,V> implements Map.Entry<K,V> {
final K key;
V value;
Entry<K,V> next;
final int hash;
……
}
可以看出，Entry就是数组中的元素，每个 Map.Entry 其实就是一个key-value对，它持有一个指向下一个元素的引用，这就构成了链表。

三、HashMap的存取实现
1 存储
public V put(K key, V value) {
// HashMap允许存放null键和null值。
// 当key为null时，调用putForNullKey方法，将value放置在数组第一个位置。  
if (key == null)
return putForNullKey(value);
// 根据key的keyCode重新计算hash值。
int hash = hash(key.hashCode());
// 搜索指定hash值在对应table中的索引。
int i = indexFor(hash, table.length);
// 如果 i 索引处的 Entry 不为 null，通过循环不断遍历 e 元素的下一个元素。
for (Entry<K,V> e = table[i]; e != null; e = e.next) {
Object k;
if (e.hash == hash && ((k = e.key) == key || key.equals(k))) {
V oldValue = e.value;
e.value = value;
e.recordAccess(this);
return oldValue;
}
}
// 如果i索引处的Entry为null，表明此处还没有Entry。
modCount++;
// 将key、value添加到i索引处。
addEntry(hash, key, value, i);
return null;
}
从上面的源代码中可以看出：当我们往HashMap中put元素的时候，先根据key的hashCode重新计算hash值，根据hash值得到这个元素在数组中的位置（即下标）， 如果数组该位置上已经存放有其他元素了，那么在这个位置上的元素将以链表的形式存放，新加入的放在链头，最先加入的放在链尾。如果数组该位置上没有元素，就直接将该元素放到此数组中的该位置上。
addEntry(hash, key, value, i)方法根据计算出的hash值，将key-value对放在数组table的i索引处。addEntry 是 HashMap 提供的一个包访问权限的方法，代码如下：
void addEntry(int hash, K key, V value, int bucketIndex) {
// 获取指定 bucketIndex 索引处的 Entry  
Entry<K,V> e = table[bucketIndex];
// 将新创建的 Entry 放入 bucketIndex 索引处，并让新的 Entry 指向原来的 Entry  
table[bucketIndex] = new Entry<K,V>(hash, key, value, e);
// 如果 Map 中的 key-value 对的数量超过了极限
if (size++ >= threshold)
// 把 table 对象的长度扩充到原来的2倍。
resize(2 * table.length);
}
当系统决定存储HashMap中的key-value对时，完全没有考虑Entry中的value，仅仅只是根据key来计算并决定每个Entry的存储位置。我们完全可以把 Map 集合中的 value 当成 key 的附属，当系统决定了 key 的存储位置之后，value 随之保存在那里即可。
hash(int h)方法根据key的hashCode重新计算一次散列。此算法加入了高位计算，防止低位不变，高位变化时，造成的hash冲突。

static int hash(int h) {
h ^= (h >>> 20) ^ (h >>> 12);
return h ^ (h >>> 7) ^ (h >>> 4);  
}
我们可以看到在HashMap中要找到某个元素，需要根据key的hash值来求得对应数组中的位置。如何计算这个位置就是hash算法。前面说过HashMap的数据结构是数组和链表的结合，所以我们当然希望这个HashMap里面的 元素位置尽量的分布均匀些，尽量使得每个位置上的元素数量只有一个，那么当我们用hash算法求得这个位置的时候，马上就可以知道对应位置的元素就是我们要的，而不用再去遍历链表，这样就大大优化了查询的效率。
对于任意给定的对象，只要它的 hashCode() 返回值相同，那么程序调用 hash(int h) 方法所计算得到的 hash 码值总是相同的。我们首先想到的就是把hash值对数组长度取模运算，这样一来，元素的分布相对来说是比较均匀的。但是，“模”运算的消耗还是比较大的，在HashMap中是这样做的：调用 indexFor(int h, int length) 方法来计算该对象应该保存在 table 数组的哪个索引处。indexFor(int h, int length) 方法的代码如下：

static int indexFor(int h, int length) {  
return h & (length-1);
}
这个方法非常巧妙，它通过 h & (table.length -1) 来得到该对象的保存位，而HashMap底层数组的长度总是 2 的 n 次方，这是HashMap在速度上的优化。在 HashMap 构造器中有如下代码：

int capacity = 1;
while (capacity < initialCapacity)  
capacity <<= 1;
这段代码保证初始化时HashMap的容量总是2的n次方，即底层数组的长度总是为2的n次方。
当length总是 2 的n次方时，h& (length-1)运算等价于对length取模，也就是h%length，但是&比%具有更高的效率。
这看上去很简单，其实比较有玄机的，我们举个例子来说明：
假设数组长度分别为15和16，优化后的hash码分别为8和9，那么&运算后的结果如下：
h & (table.length-1) 	hash 		table.length-1 	
8 & (15-1)： 	0100 	& 	1110 	= 0100
9 & (15-1)： 	0101 	& 	1110 	= 0100
8 & (16-1)： 	0100 	& 	1111 	= 0100
9 & (16-1)： 	0101 	& 	1111 	= 0101
从上面的例子中可以看出：当它们和15-1（1110）“与”的时候，产生了相同的结果，也就是说它们会定位到数组中的同一个位置上去，这就产生了碰撞，8和9会被放到数组中的同一个位置上形成链表，那么查询的时候就需要遍历这个链 表，得到8或者9，这样就降低了查询的效率。同时，我们也可以发现，当数组长度为15的时候，hash值会与15-1（1110）进行“与”，那么最后一位永远是0，而0001，0011，0101，1001，1011，0111，1101这几个位置永远都不能存放元素了，空间浪费相当大，更糟的是这种情况中，数组可以使用的位置比数组长度小了很多，这意味着进一步增加了碰撞的几率，减慢了查询的效率！而当数组长度为16时，即为2的n次方时，2n-1得到的二进制数的每个位上的值都为1，这使得在低位上&时，得到的和原hash的低位相同，加之hash(int h)方法对key的hashCode的进一步优化，加入了高位计算，就使得只有相同的hash值的两个值才会被放到数组中的同一个位置上形成链表。
所以说，当数组长度为2的n次幂的时候，不同的key算得得index相同的几率较小，那么数据在数组上分布就比较均匀，也就是说碰撞的几率小，相对的，查询的时候就不用遍历某个位置上的链表，这样查询效率也就较高了。
根据上面 put 方法的源代码可以看出，当程序试图将一个key-value对放入HashMap中时，程序首先根据该 key 的 hashCode() 返回值决定该 Entry 的存储位置：如果两个 Entry 的 key 的 hashCode() 返回值相同，那它们的存储位置相同。如果这两个 Entry 的 key 通过 equals 比较返回 true，新添加 Entry 的 value 将覆盖集合中原有 Entry 的 value，但key不会覆盖。如果这两个 Entry 的 key 通过 equals 比较返回 false，新添加的 Entry 将与集合中原有 Entry 形成 Entry 链，而且新添加的 Entry 位于 Entry 链的头部——具体说明继续看 addEntry() 方法的说明。

2 读取
public V get(Object key) {
if (key == null)
return getForNullKey();
int hash = hash(key.hashCode());
for (Entry<K,V> e = table[indexFor(hash, table.length)];
e != null;
e = e.next) {
Object k;
if (e.hash == hash && ((k = e.key) == key || key.equals(k)))  
return e.value;
}
return null;
}
有了上面存储时的hash算法作为基础，理解起来这段代码就很容易了。从上面的源代码中可以看出：从HashMap中get元素时，首先计算key的hashCode，找到数组中对应位置的某一元素，然后通过key的equals方法在对应位置的链表中找到需要的元素。

3 归纳
简单地说，HashMap 在底层将 key-value 当成一个整体进行处理，这个整体就是一个 Entry 对象。HashMap 底层采用一个 Entry[] 数组来保存所有的 key-value 对，当需要存储一个 Entry 对象时，会根据hash算法来决定其在数组中的存储位置，在根据equals方法决定其在该数组位置上的链表中的存储位置；当需要取出一个Entry时，
也会根据hash算法找到其在数组中的存储位置，再根据equals方法从该位置上的链表中取出该Entry。

四、HashMap的resize（rehash）
当HashMap中的元素越来越多的时候，hash冲突的几率也就越来越高，因为数组的长度是固定的。所以为了提高查询的效率，就要对HashMap的数组进行扩容，数组扩容这个操作也会出现在ArrayList中，这是一个常用的操作，而在HashMap数组扩容之后，最消耗性能的点就出现了：原数组中的数据必须重新计算其在新数组中的位置，并放进去，这就是resize。
那么HashMap什么时候进行扩容呢？当HashMap中的元素个数超过数组大小loadFactor时，就会进行数组扩容，loadFactor的默认值为0.75，这是一个折中的取值。也就是说，默认情况下，数组大小为16，那么当HashMap中元素个数超过160.75=12的时候，就把数组的大小扩展为 2*16=32，即扩大一倍，然后重新计算每个元素在数组中的位置，而这是一个非常消耗性能的操作，所以如果我们已经预知HashMap中元素的个数，那么预设元素的个数能够有效的提高HashMap的性能。

五、HashMap的性能参数
HashMap 包含如下几个构造器：
HashMap()：构建一个初始容量为 16，负载因子为 0.75 的 HashMap。
ashMap(int initialCapacity)：构建一个初始容量为 initialCapacity，负载因子为 0.75 的 HashMap。
HashMap(int initialCapacity, float loadFactor)：以指定初始容量、指定的负载因子创建一个 HashMap。
HashMap的基础构造器HashMap(int initialCapacity, float loadFactor)带有两个参数，它们是初始容量initialCapacity和负载因子loadFactor。
负载因子loadFactor衡量的是一个散列表的空间的使用程度，负载因子越大表示散列表的装填程度越高，反之愈小。对于使用链表法的散列表来说，查找一个元素的平均时间是O(1+a)，因此如果负载因子越大，对空间的利用更充分，然而后果是查找效率的降低；如果负载因子太小，那么散列表的数据将过于稀疏，对空间造成严重浪费。
HashMap的实现中，通过threshold字段来判断HashMap的最大容量：
1 threshold = (int)(capacity * loadFactor);
结合负载因子的定义公式可知，threshold就是在此loadFactor和capacity对应下允许的最大元素数目，超过这个数目就重新resize，以降低实际的负载因子。默认的的负载因子0.75是对空间和时间效率的一个平衡选择。当容量超出此最大容量时， resize后的HashMap容量是容量的两倍：

六、Fail-Fast机制
我们知道java.util.HashMap不是线程安全的，因此如果在使用迭代器的过程中有其他线程修改了map，那么将抛出ConcurrentModificationException，这就是所谓fail-fast策略。
这一策略在源码中的实现是通过modCount域，modCount顾名思义就是修改次数，对HashMap内容的修改都将增加这个值，那么在迭代器初始化过程中会将这个值赋给迭代器的expectedModCount。

HashIterator() {
expectedModCount = modCount;
if (size > 0) { // advance to first entry
Entry[] t = table;
while (index < t.length && (next = t[index++]) == null)  
;
}
}
在迭代过程中，判断modCount跟expectedModCount是否相等，如果不相等就表示已经有其他线程修改了Map：
注意到modCount声明为volatile，保证线程之间修改的可见性。
final Entry<K,V> nextEntry() {
if (modCount != expectedModCount)
throw new ConcurrentModificationException();
在HashMap的API中指出：
由所有HashMap类的“collection 视图方法”所返回的迭代器都是快速失败的：在迭代器创建之后，如果从结构上对映射进行修改，除非通过迭代器本身的 remove 方法，其他任何时间任何方式的修改，迭代器都将抛出 ConcurrentModificationException。因此，面对并发的修改，迭代器很快就会完全失败，而不冒在将来不确定的时间发生任意不确定行为的风险。
注意，迭代器的快速失败行为不能得到保证，一般来说，存在非同步的并发修改时，不可能作出任何坚决的保证。快速失败迭代器尽最大努力抛出ConcurrentModificationException。因此，编写依赖于此异常的程序的做法是错误的，正确做法是：迭代器的快速失败行为应该仅用于检测程序错误。

七、HashMap的两种遍历方式
第一种
Map map = new HashMap();
Iterator iter = map.entrySet().iterator();
while (iter.hasNext()) {
Map.Entry entry = (Map.Entry) iter.next();
Object key = entry.getKey();
Object val = entry.getValue();
}
效率高,以后一定要使用此种方式！

第二种
Map map = new HashMap();
Iterator iter = map.keySet().iterator();
while (iter.hasNext()) {
Object key = iter.next();
Object val = map.get(key);
}
效率低,以后尽量少使用！


181 ArrayList和LinkedList从数据结构有何区别，用于什么场景？
LinkedList和ArrayList的差别主要来自于Array和LinkedList数据结构的不同。如果你很熟悉Array和LinkedList，你很容易得出下面的结论：
1) 因为Array是基于索引(index)的数据结构，它使用索引在数组中搜索和读取数据是很快的。Array获取数据的时间复杂度是O(1),但是要删除数据却是开销很大的，因为这需要重排数组中的所有数据。
2) 相对于ArrayList，LinkedList插入是更快的。因为LinkedList不像ArrayList一样，不需要改变数组的大小，也不需要在数组装满的时候要将所有的数据重新装入一个新的数组，这是ArrayList最坏的一种情况，时间复杂度是O(n)，
而LinkedList中插入或删除的时间复杂度仅为O(1)。ArrayList在插入数据时还需要更新索引（除了插入数组的尾部）。
3) 类似于插入数据，删除数据时，LinkedList也优于ArrayList。
4) LinkedList需要更多的内存，因为ArrayList的每个索引的位置是实际的数据，而LinkedList中的每个节点中存储的是实际的数据和前后节点的位置。
5) 不会随机访问数据。因为如果你需要LinkedList中的第n个元素的时候，你需要从第一个元素顺序数到第n个数据，然后读取数据。
6) 更多的插入和删除元素，更少的读取数据。因为插入和删除元素不涉及重排数据，所以它要比ArrayList要快。
7) 以上就是关于ArrayList和LinkedList的差别。你需要一个不同步的基于索引的数据访问时，请尽量使用ArrayList。ArrayList很快，也很容易使用。但是要记得要给定一个合适的初始大小，尽可能的减少更改数组的大小。


182 怎么预防SQL注入？
1.PreparedStatement
采预编译语句集，它内置了处理SQL注入的能力，只要使用它的setXXX方法传值即可。
使用好处：
(1).代码的可读性和可维护性.
(2).PreparedStatement尽最大可能提高性能.
(3).最重要的一点是极大地提高了安全性.
原理：
sql注入只对sql语句的准备(编译)过程有破坏作用
而PreparedStatement已经准备好了,执行阶段只是把输入串作为数据处理,
而不再对sql语句进行解析,准备,因此也就避免了sql注入问题.
2.使用正则表达式过滤传入的参数
3.字符串过滤
4.jsp中调用该函数检查是否包函非法字符
5.JSP页面判断代码： 


183  unicode和utf-8有什么关系？
1. ASCII码 
我们知道，在计算机内部，所有的信息最终都表示为一个二进制的字符串。每一个二进制位（bit）有0和1两种状态，因此八个二进制位就可以组合出256种状态，这被称为一个字节（byte）。也就是说，一个字节一共可以用来表示256种不同的状态，每一个状态对应一个符号，就是256个符号，从0000000到11111111。 
上个世纪60年代，美国制定了一套字符编码，对英语字符与二进制位之间的关系，做了统一规定。这被称为ASCII码，一直沿用至今。 
ASCII码一共规定了128个字符的编码，比如空格“SPACE”是32（二进制00100000），大写的字母A是65（二进制01000001）。这128个符号（包括32个不能打印出来的控制符号），只占用了一个字节的后面7位，最前面的1位统一规定为0。 

2、非ASCII编码 
英语用128个符号编码就够了，但是用来表示其他语言，128个符号是不够的。比如，在法语中，字母上方有注音符号，它就无法用ASCII码表示。于是，一些欧洲国家就决定，利用字节中闲置的最高位编入新的符号。比如，法语中的é的编码为130（二进制10000010）。这样一来，这些欧洲国家使用的编码体系，可以表示最多256个符号。 
但是，这里又出现了新的问题。不同的国家有不同的字母，因此，哪怕它们都使用256个符号的编码方式，代表的字母却不一样。比如，130在法语编码中代表了é，在希伯来语编码中却代表了字母Gimel (?)，在俄语编码中又会代表另一个符号。但是不管怎样，所有这些编码方式中，0—127表示的符号是一样的，不一样的只是128—255的这一段。 
至于亚洲国家的文字，使用的符号就更多了，汉字就多达10万左右。一个字节只能表示256种符号，肯定是不够的，就必须使用多个字节表达一个符号。比如，简体中文常见的编码方式是GB2312，使用两个字节表示一个汉字，所以理论上最多可以表示256x256=65536个符号。 
中文编码的问题需要专文讨论，这篇笔记不涉及。这里只指出，虽然都是用多个字节表示一个符号，但是GB类的汉字编码与后文的Unicode和UTF-8是毫无关系的。 

3.Unicode 
正如上一节所说，世界上存在着多种编码方式，同一个二进制数字可以被解释成不同的符号。因此，要想打开一个文本文件，就必须知道它的编码方式，否则用错误的编码方式解读，就会出现乱码。为什么电子邮件常常出现乱码？就是因为发信人和收信人使用的编码方式不一样。 
可以想象，如果有一种编码，将世界上所有的符号都纳入其中。每一个符号都给予一个独一无二的编码，那么乱码问题就会消失。这就是Unicode，就像它的名字都表示的，这是一种所有符号的编码。 

Unicode当然是一个很大的集合，现在的规模可以容纳100多万个符号。每个符号的编码都不一样，比如，U+0639表示阿拉伯字母Ain，U+0041表示英语的大写字母A，U+4E25表示汉字“严”。具体的符号对应表，可以查询unicode.org，或者专门的汉字对应表。 

4. Unicode的问题 
需要注意的是，Unicode只是一个符号集，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储。 
比如，汉字“严”的unicode是十六进制数4E25，转换成二进制数足足有15位（100111000100101），也就是说这个符号的表示至少需要2个字节。表示其他更大的符号，可能需要3个字节或者4个字节，甚至更多。 
这里就有两个严重的问题，第一个问题是，如何才能区别unicode和ascii？计算机怎么知道三个字节表示一个符号，而不是分别表示三个符号呢？第二个问题是，我们已经知道，英文字母只用一个字节表示就够了，如果unicode统一规定，每个符号用三个或四个字节表示，那么每个英文字母前都必然有二到三个字节是0，这对于存储来说是极大的浪费，文本文件的大小会因此大出二三倍，这是无法接受的。 
它们造成的结果是：1）出现了unicode的多种存储方式，也就是说有许多种不同的二进制格式，可以用来表示unicode。2）unicode在很长一段时间内无法推广，直到互联网的出现。 

5.UTF-8 
互联网的普及，强烈要求出现一种统一的编码方式。UTF-8就是在互联网上使用最广的一种unicode的实现方式。其他实现方式还包括UTF-16和UTF-32，不过在互联网上基本不用。重复一遍，这里的关系是，UTF-8是Unicode的实现方式之一。 
UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。 
UTF-8的编码规则很简单，只有二条： 
1）对于单字节的符号，字节的第一位设为0，后面7位为这个符号的unicode码。因此对于英语字母，UTF-8编码和ASCII码是相同的。 
2）对于n字节的符号（n>1），第一个字节的前n位都设为1，第n+1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的unicode码。 
下表总结了编码规则，字母x表示可用编码的位。 
Unicode符号范围 | UTF-8编码方式 
(十六进制) | （二进制） 
--------------------+--------------------------------------------- 
0000 0000-0000 007F | 0xxxxxxx 
0000 0080-0000 07FF | 110xxxxx 10xxxxxx 
0000 0800-0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx 
0001 0000-0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 
下面，还是以汉字“严”为例，演示如何实现UTF-8编码。 
已知“严”的unicode是4E25（100111000100101），根据上表，可以发现4E25处在第三行的范围内（0000 0800-0000 FFFF），因此“严”的UTF-8编码需要三个字节，即格式是“1110xxxx 10xxxxxx 10xxxxxx”。然后，从“严”的最后一个二进制位开始，依次从后向前填入格式中的x，多出的位补0。这样就得到了，“严”的UTF-8编码是“11100100 10111000 10100101”，转换成十六进制就是E4B8A5。 

6. Unicode与UTF-8之间的转换 
通过上一节的例子，可以看到“严”的Unicode码是4E25，UTF-8编码是E4B8A5，两者是不一样的。它们之间的转换可以通过程序实现。 
在Windows平台下，有一个最简单的转化方法，就是使用内置的记事本小程序Notepad.exe。打开文件后，点击“文件”菜单中的“另存为”命令，会跳出一个对话框，在最底部有一个“编码”的下拉条。 
里面有四个选项：ANSI，Unicode，Unicode big endian 和 UTF-8。 
1）ANSI是默认的编码方式。对于英文文件是ASCII编码，对于简体中文文件是GB2312编码（只针对Windows简体中文版，如果是繁体中文版会采用Big5码）。 
2）Unicode编码指的是UCS-2编码方式，即直接用两个字节存入字符的Unicode码。这个选项用的little endian格式。 
3）Unicode big endian编码与上一个选项相对应。我在下一节会解释little endian和big endian的涵义。 
4）UTF-8编码，也就是上一节谈到的编码方法。 
选择完”编码方式“后，点击”保存“按钮，文件的编码方式就立刻转换好了。 


184 String,StringBuffer,StringBuilder使用场景？有何不同？
String 字符串常量
StringBuffer 字符串变量,线程安全
StringBuilder 字符串变量,非线程安全
简要的说， String 类型和 StringBuffer 类型的主要性能区别其实在于 String 是不可变的对象, 因此在每次对 String 类型进行改变的时候其实都等同于生成了一个新的 String 对象，
然后将指针指向新的 String 对象，所以经常改变内容的字符串最好不要用 String ，因为每次生成对象都会对系统性能产生影响，特别当内存中无引用对象多了以后， JVM 的 GC 就会开
始工作，那速度是一定会相当慢的。而如果是使用 StringBuffer 类则结果就不一样了，每次结果都会对 StringBuffer 对象本身进行操作，而不是生成新的对象，再改变对象引用。所以
在一般情况下我们推荐使用 StringBuffer ，特别是字符串对象经常改变的情况下。而在某些特别情况下， String 对象的字符串拼接其实是被 JVM 解释成了 StringBuffer 对象的拼接，
所以这些时候 String 对象的速度并不会比 StringBuffer 对象慢，而特别是以下的字符串对象生成中， String 效率是远要比 StringBuffer 快的


185 wait和sleep不同点？怎么唤醒？有没释放锁？
1、这两个方法来自不同的类分别是，sleep来自Thread类，和wait来自Object类。
sleep是Thread的静态类方法，谁调用的谁去睡觉，即使在a线程里调用了b的sleep方法，实际上还是a去睡觉，要让b线程睡觉要在b的代码中调用sleep。

2、最主要是sleep方法没有释放锁，而wait方法释放了锁，使得其他线程可以使用同步控制块或者方法
sleep不出让系统资源；wait是进入线程等待池等待，出让系统资源，其他线程可以占用CPU。一般wait不会加时间限制，因为如果wait线程的运行资源不够，再出来也没用，要等待其他线程调用notify/notifyAll唤醒等待池中的所有线程，才会进入就绪队列等待OS分配系统资源。sleep(milliseconds)可以用时间指定使它自动唤醒过来，如果时间不到只能调用interrupt()强行打断。
Thread.Sleep(0)的作用是“触发操作系统立刻重新进行一次CPU竞争”。

3、使用范围：wait，notify和notifyAll只能在同步控制方法或者同步控制块里面使用，而sleep可以在任何地方使用
   synchronized(x){
      x.notify()
     //或者wait()
   }

4、sleep必须捕获异常，而wait，notify和notifyAll不需要捕获异常


186 concurrentHashMap和普通的map有何区别？采用什么同步技术？
并发编程实践中，ConcurrentHashMap是一个经常被使用的数据结构，相比于Hashtable以及Collections.synchronizedMap()，ConcurrentHashMap在线程安全的基础上提供了更好的写并发能力，但同时降低了对读一致性的要求（这点好像CAP理论啊 O(∩_∩)O）。ConcurrentHashMap的设计与实现非常精巧，大量的利用了volatile，final，CAS等lock-free技术来减少锁竞争对于性能的影响，无论对于Java并发编程的学习还是Java内存模型的理解，ConcurrentHashMap的设计以及源码都值得非常仔细的阅读与揣摩。
这篇日志记录了自己对ConcurrentHashMap的一些总结，由于JDK6，7，8中实现都不同，需要分开阐述在不同版本中的ConcurrentHashMap。
之前已经在ConcurrentHashMap原理分析中解释了ConcurrentHashMap的原理，主要是从代码的角度来阐述是源码是如何写的，本文仍然从源码出发，挑选个人觉得重要的点（会用红色标注）再次进行回顾，以及阐述ConcurrentHashMap的一些注意点。

一、 设计思路
ConcurrentHashMap采用了分段锁的设计，只有在同一个分段内才存在竞态关系，不同的分段锁之间没有锁竞争。相比于对整个Map加锁的设计，分段锁大大的提高了高并发环境下的处理能力。但同时，由于不是对整个Map加锁，导致一些需要扫描整个Map的方法（如size(), containsValue()）需要使用特殊的实现，另外一些方法（如clear()）甚至放弃了对一致性的要求（ConcurrentHashMap是弱一致性的，具体请查看ConcurrentHashMap能完全替代HashTable吗？）。
ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap（JDK7与JDK8中HashMap的实现）的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock）。ConcurrentHashMap中的HashEntry相对于HashMap中的Entry有一定的差异性：HashEntry中的value以及next都被volatile修饰，这样在多线程读写过程中能够保持它们的可见性，代码如下：
static final class HashEntry<K,V> {
final int hash;
final K key;
volatile V value;
volatile HashEntry<K,V> next;

二、 并发度（Concurrency Level）
并发度可以理解为程序运行时能够同时更新ConccurentHashMap且不产生锁竞争的最大线程数，实际上就是ConcurrentHashMap中的分段锁个数，即Segment[]的数组长度。ConcurrentHashMap默认的并发度为16，但用户也可以在构造函数中设置并发度。当用户设置并发度时，ConcurrentHashMap会使用大于等于该值的最小2幂指数作为实际并发度（假如用户设置并发度为17，实际并发度则为32）。运行时通过将key的高n位（n = 32 – segmentShift）和并发度减1（segmentMask）做位与运算定位到所在的Segment。segmentShift与segmentMask都是在构造过程中根据concurrency level被相应的计算出来。
如果并发度设置的过小，会带来严重的锁竞争问题；如果并发度设置的过大，原本位于同一个Segment内的访问会扩散到不同的Segment中，CPU cache命中率会下降，从而引起程序性能下降。（文档的说法是根据你并发的线程数量决定，太多会导性能降低）

三、创建分段锁
和JDK6不同，JDK7中除了第一个Segment之外，剩余的Segments采用的是延迟初始化的机制：每次put之前都需要检查key对应的Segment是否为null，如果是则调用ensureSegment()以确保对应的Segment被创建。
ensureSegment可能在并发环境下被调用，但与想象中不同，ensureSegment并未使用锁来控制竞争，而是使用了Unsafe对象的getObjectVolatile()提供的原子读语义结合CAS来确保Segment创建的原子性。代码段如下：

if ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u))
== null) { // recheck
Segment<K,V> s = new Segment<K,V>(lf, threshold, tab);
while ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u))
== null) {
if (UNSAFE.compareAndSwapObject(ss, u, null, seg = s))
break;
}
}

四、 put/putIfAbsent/putAll
和JDK6一样，ConcurrentHashMap的put方法被代理到了对应的Segment（定位Segment的原理之前已经描述过）中。与JDK6不同的是，JDK7版本的ConcurrentHashMap在获得Segment锁的过程中，做了一定的优化 - 在真正申请锁之前，put方法会通过tryLock()方法尝试获得锁，在尝试获得锁的过程中会对对应hashcode的链表进行遍历，如果遍历完毕仍然找不到与key相同的HashEntry节点，则为后续的put操作提前创建一个HashEntry。当tryLock一定次数后仍无法获得锁，则通过lock申请锁。
需要注意的是，由于在并发环境下，其他线程的put，rehash或者remove操作可能会导致链表头结点的变化，因此在过程中需要进行检查，如果头结点发生变化则重新对表进行遍历。而如果其他线程引起了链表中的某个节点被删除，即使该变化因为是非原子写操作（删除节点后链接后续节点调用的是Unsafe.putOrderedObject()，该方法不提供原子写语义）可能导致当前线程无法观察到，但因为不影响遍历的正确性所以忽略不计。
之所以在获取锁的过程中对整个链表进行遍历，主要目的是希望遍历的链表被CPU cache所缓存，为后续实际put过程中的链表遍历操作提升性能。
在获得锁之后，Segment对链表进行遍历，如果某个HashEntry节点具有相同的key，则更新该HashEntry的value值，否则新建一个HashEntry节点，将它设置为链表的新head节点并将原头节点设为新head的下一个节点。新建过程中如果节点总数（含新建的HashEntry）超过threshold，则调用rehash()方法对Segment进行扩容，最后将新建HashEntry写入到数组中。
put方法中，链接新节点的下一个节点（HashEntry.setNext()）以及将链表写入到数组中（setEntryAt()）都是通过Unsafe的putOrderedObject()方法来实现，这里并未使用具有原子写语义的putObjectVolatile()的原因是：JMM会保证获得锁到释放锁之间所有对象的状态更新都会在锁被释放之后更新到主存，从而保证这些变更对其他线程是可见的。

五、 rehash
相对于HashMap的resize，ConcurrentHashMap的rehash原理类似，但是Doug Lea为rehash做了一定的优化，避免让所有的节点都进行复制操作：由于扩容是基于2的幂指来操作，假设扩容前某HashEntry对应到Segment中数组的index为i，数组的容量为capacity，那么扩容后该HashEntry对应到新数组中的index只可能为i或者i+capacity，因此大多数HashEntry节点在扩容前后index可以保持不变。基于此，rehash方法中会定位第一个后续所有节点在扩容后index都保持不变的节点，然后将这个节点之前的所有节点重排即可。这部分代码如下：

private void rehash(HashEntry<K,V> node) {
HashEntry<K,V>[] oldTable = table;
int oldCapacity = oldTable.length;
int newCapacity = oldCapacity << 1;
threshold = (int)(newCapacity * loadFactor);
HashEntry<K,V>[] newTable =
(HashEntry<K,V>[]) new HashEntry[newCapacity];
int sizeMask = newCapacity - 1;
for (int i = 0; i < oldCapacity ; i++) {
HashEntry<K,V> e = oldTable[i];
if (e != null) {
HashEntry<K,V> next = e.next;
int idx = e.hash & sizeMask;
if (next == null)   //  Single node on list
newTable[idx] = e;
else { // Reuse consecutive sequence at same slot
HashEntry<K,V> lastRun = e;
int lastIdx = idx;
for (HashEntry<K,V> last = next;
last != null;
last = last.next) {
int k = last.hash & sizeMask;
if (k != lastIdx) {
lastIdx = k;
lastRun = last;
}
}
newTable[lastIdx] = lastRun;
// Clone remaining nodes
for (HashEntry<K,V> p = e; p != lastRun; p = p.next) {
V v = p.value;
int h = p.hash;
int k = h & sizeMask;
HashEntry<K,V> n = newTable[k];
newTable[k] = new HashEntry<K,V>(h, p.key, v, n);
}
}
}
}
int nodeIndex = node.hash & sizeMask; // add the new node
node.setNext(newTable[nodeIndex]);
newTable[nodeIndex] = node;
table = newTable;
}

六、 remove
和put类似，remove在真正获得锁之前，也会对链表进行遍历以提高缓存命中率。

七、 get与containsKey
get与containsKey两个方法几乎完全一致：他们都没有使用锁，而是通过Unsafe对象的getObjectVolatile()方法提供的原子读语义，来获得Segment以及对应的链表，然后对链表遍历判断是否存在key相同的节点以及获得该节点的value。但由于遍历过程中其他线程可能对链表结构做了调整，因此get和containsKey返回的可能是过时的数据，这一点是ConcurrentHashMap在弱一致性上的体现。如果要求强一致性，那么必须使用Collections.synchronizedMap()方法。

八、 size、containsValue
这些方法都是基于整个ConcurrentHashMap来进行操作的，他们的原理也基本类似：首先不加锁循环执行以下操作：循环所有的Segment（通过Unsafe的getObjectVolatile()以保证原子读语义），获得对应的值以及所有Segment的modcount之和。如果连续两次所有Segment的modcount和相等，则过程中没有发生其他线程修改ConcurrentHashMap的情况，返回获得的值。
当循环次数超过预定义的值时，这时需要对所有的Segment依次进行加锁，获取返回值后再依次解锁。值得注意的是，加锁过程中要强制创建所有的Segment，否则容易出现其他线程创建Segment并进行put，remove等操作。代码如下：
for(int j =0; j < segments.length; ++j)
ensureSegment(j).lock();// force creation
一般来说，应该避免在多线程环境下使用size和containsValue方法。
注1：modcount在put, replace, remove以及clear等方法中都会被修改。
注2：对于containsValue方法来说，如果在循环过程中发现匹配value的HashEntry，则直接返回true。
最后，与HashMap不同的是，ConcurrentHashMap并不允许key或者value为null，按照Doug Lea的说法，这么设计的原因是在ConcurrentHashMap中，一旦value出现null，则代表HashEntry的key/value没有映射完成就被其他线程所见，需要特殊处理。在JDK6中，get方法的实现中就有一段对HashEntry.value == null的防御性判断。但Doug Lea也承认实际运行过程中，这种情况似乎不可能发生



187 注解有什么好处？
配置文件
1，遵循OCP开发原则，修改配置文件即可进行功能扩展（OCP 开闭原则 Open Closed Principle）
2，集中管理对象和对象之间的组合关系，易于阅读
3，开发速度相对较慢；
4，编译时很难检查出错误，运行中的错误很难定位，调试难度较大。

注解
1，开发速度快
2，编译期间容易发现错误的出处
3，管理分散，基本每个类上都有 
4，扩展功能时，没有遵循OCP开发原则 



188 数组与ArrayList的关系与区别？
存储结构一样 。
数组（[]）：最高效；但是其容量固定且无法动态改变；
ArrayList：容量可动态增长；但牺牲效率；
建议首先使用数组，无法确定数组大小时才使用ArrayList！
数组扩容是对ArrayList效率影响比较大的一个因素。
每当执行Add、AddRange、Insert、InsertRange等添加元素的方法，都会检查内部数组的容量是否不够了，如果是，它就会以当前容量的1.5倍来重新构建一个数组，将旧元素Copy到新数组中，然后丢弃旧数组，在这个临界点的扩容操作，应该来说是比较影响效率的。

189 序列化应用什么场景？
	1 简述
	   在分布式环境下，当进行远程通信时，无论是何种类型的数据，都会以二进制序列的形式在网络上传输。序列化是一种将对象以一连串的字节描述的过程，
	用于解决在对对象流进行读写操作时所引发的问题。序列化可以将对象的状态写在流里进行网络传输，或者保存到文件、数据库等系统中，并在需要时把
	该流读取出来重新构造一个相同的对象。
	   所有实现序列化的类都必须实现Serializable接口，Serializable接口位于java.lang包中，没有任何实现方法，使用一个输出流（例如FileOutputStream）
	来构造一个ObjectOutputStream对象，紧接着使用该对象的writeObject(Object obj)方法就可以将obj对象写出，要恢复时可以使用其对应的输入流ObjectInputStream.
	   Java平台允许我们在内存中创建可复用的Java对象，但一般情况下，只有当JVM处于运行时，这些对象才可能存在，即，这些对象的生命周期不会比JVM的生命周期更长。
	但在现实应用中，就可能要求在JVM停止运行之后能够保存(持久化)指定的对象，并在将来重新读取被保存的对象。Java对象序列化就能够帮助我们实现该功能。使用Java对
	象序列化，在保存对象时，会把其状态保存为一组字节，在未来，再将这些字节组装成对象。必须注意地是，对象序列化保存的是对象的"状态"，即它的成员变量。由此可
	知，对象序列化不会关注类中的静态变量。除了在持久化对象时会用到对象序列化之外，当使用RMI(远程方法调用)，或在网络中传递对象时，都会用到对象序列化。Java序
	列化API为处理对象序列化提供了一个标准机制，该API简单易用，在本文的后续章节中将会陆续讲到。

	2 序列化特点
	（1）如果一个类能被序列化，那么它的子类也能够被序列化。
	（2）由于static(静态)代表类的成员，transient（Java关键字，如果用transient声明一个实例变量，当对象存储时，它的值不需要维持）代表对象的临时数据，因此被声明为这两种类型的数据成员是不能够被序列化的。
	（3）每个枚举类型都会默认继承类java.lang.Enum，而该类实现了Serializable接口，所以枚举类型对象都是默认可以被序列化的。

	3 序列化场景
	1）当你想把的内存中的对象状态保存到一个文件中时候；
	2）当你想把的内存中的对象状态保存到数据库时候；
	3）当你想用套接字在网络上传送对象的时候；
	4）当你想通过RMI传输对象的时候；

	4 序列化
	如下是序列化的代码，首先声明一个Student类继承Serializable接口，由代码中的输出（注释即为输出内容）可得静态变量SCHOOLNAME和SCHOOLID的值发生了变化，难道是静态变量也被序列化
	了吗？其实不是的，因为在当前的运行程序中，Student类的静态变量的值已经发生了变化，如果真的已经序列化了，那么我们将序列化的那个函数去掉，让程序从SourceFile/Student文件中反
	序列化，那么得到的SCHOOLNAME应该为HeBei University，SCHOOLID的值为2，然而当我们去掉序列化代码，直接从文件反序列化，输出SCHOOLNAME是Beijing University of Post and Telecommunications，SCHOOLID为1，说明static变量并没有被序列化。

	5 反序列化
	与序列化相对的是反序列化，它将流转换为对象，在序列化与反序列化的过程中，serialVersionUID起着重要的作用，每一个类都有一个特定的serialVersionUID，在反序列化的过程
	自定义serialVersionUID主要由如下3个优点：
	（1）提高程序运行效率。如果在类中未显示声明serialVersionUID，那么在序列化时会通过计算得到一个serialVersionUID。通过显示声明serialVersionUID的方式省去了计算的过程，提高了程序效率。
	（2）提高程序不同平台上的兼容性。由于各个平台计算serialVersionUID的方式可能不同，通过显示的方式可以完全避免该问题。
	（3）增强程序各个版本的可兼容性。在默认情况下每个类都有唯一的一个serialVersionUID，因此当后期对类进行修改时，类的serialVersionUID值将会发生变化，这将会导致类在修改前对象的文件在修
		 改后无法进行反序列化操作。同样通过显示声明serialVersionUID也会解决该问题。

	6 Serializable接口和serialVersionUID
		序列化运行时使用一个称为 serialVersionUID 的版本号与每个可序列化类相关联，该序列号在反序列化过程中用于验证序列化对象的发送者和接收者是否为该对象加载了与序列化兼容的类。
	如果接收者加载的该对象的类的 serialVersionUID 与对应的发送者的类的版本号不同，则反序列化将会导致 InvalidClassException。可序列化类可以通过声明名为 "serialVersionUID" 
	的字段（该字段必须是静态 (static)、最终 (final) 的 long 型字段）显式声明其自己的 serialVersionUID：
		如果可序列化类未显式声明 serialVersionUID，则序列化运行时将基于该类的各个方面计算该类的默认 serialVersionUID 值，如“Java(TM) 对象序列化规范”中所述。不过，强烈建议所有
	可序列化类都显式声明 serialVersionUID 值，原因计算默认的 serialVersionUID 对类的详细信息具有较高的敏感性，根据编译器实现的不同可能千差万别，这样在反序列化过程中可能会
	导致意外的 InvalidClassException。因此，为保证 serialVersionUID 值跨不同 java 编译器实现的一致性，序列化类必须声明一个明确的 serialVersionUID 值。还强烈建议使用 private 修改
	器显示声明 serialVersionUID，原因是这种声明仅应用于立即声明类 -- serialVersionUID 字段作为继承成员没有用处。
		开始指定了一个serialVersionUID，序列化了一个对象，后来这个类有修改，但是要固定serialVersionUID否则反序列化失败。
	　  实现serializable接口的作用是就是可以把对象存到字节流，然后可以恢复。所以你想如果你的对象没实现序列化怎么才能进行网络传输呢，要网络传输就得转为字节流，所以在分布式应用
	中，你就得实现序列化，如果你不需要分布式应用，那就没那个必要实现序列化。实际上serializable就是一个空接口，一个标识，标识一个类可以序列化。


190 JDK 6/7/8有什么新特性?
java5 泛型,枚举,拆箱与装箱,静态导入
java6 支持JDBC4.0规范,轻量级HttpServer,JSR223脚本引擎
java7 捕获多个异常,try-with-resources，支持JDBC4.1规范
java8 Stream函数式操作流元素集合，类型注解，新增base64加解密API


191 数据库连接池解决什么问题？
一般来说java应用程序访问数据库的过程是：
　①装载数据库驱动程序；
　②通过jdbc建立数据库连接；
　③访问数据库，执行sql语句；
　④断开数据库连接。
程序开发过程中，存在很多问题：首先，每一次web请求都要建立一次数据库连接。建立连接是一个费时的活动，每次都得花费0.05s～1s的时间，而且系统还要分配内存资源。
这个时间对于一次或几次数据库操作，或许感觉不出系统有多大的开销。可是对于现在的web应用，尤其是大型电子商务网站，同时有几百人甚至几千人在线是很正常的事。
在这种情况下，频繁的进行数据库连接操作势必占用很多的系统资源，网站的响应速度必定下降，严重的甚至会造成服务器的崩溃。不是危言耸听，这就是制约某些电子商务网站
发展的技术瓶颈问题。其次，对于每一次数据库连接，使用完后都得断开。否则，如果程序出现异常而未能关闭，将会导致数据库系统中的内存泄漏，最终将不得不重启数据库。
还有，这种开发不能控制被创建的连接对象数，系统资源会被毫无顾及的分配出去，如连接过多，也可能导致内存泄漏，服务器崩溃。

连接池还要考虑更多的问题
1、并发问题
为了使连接管理服务具有最大的通用性，必须考虑多线程环境，即并发问题。这个问题相对比较好解决，因为java语言自身提供了对并发管理的支持，使用synchronized关键字即可确保线程是同步的。使用方法为直接在类方法前面加上synchronized关键
publicsynchronized connection getconnection（）
 
2、多数据库服务器和多用户
对于大型的企业级应用，常常需要同时连接不同的数据库（如连接oracle和sybase）。如何连接不同的数据库呢？我们采用的策略是：设计一个符合单例模式的连接池管理类，在连接池管理类的唯一实例被创建时读取一个资源文件，
其中资源文件中存放着多个数据库的url地址等信息。根据资源文件提供的信息，创建多个连接池类的实例，每一个实例都是一个特定数据库的连接池。连接池管理类实例为每个连接池实例取一个名字，通过不同的名字来管理不同的连接池。
对于同一个数据库有多个用户使用不同的名称和密码访问的情况，也可以通过资源文件处理，即在资源文件中设置多个具有相同url地址，但具有不同用户名和密码的数据库连接信息。

3、事务处理
我们知道，事务具有原子性，此时要求对数据库的操作符合“all-all-nothing”原则即对于一组sql语句要么全做，要么全不做。
在java语言中，connection类本身提供了对事务的支持，可以通过设置connection的autocommit属性为false 然后显式的调用commit或rollback方法来实现。但要高效的进行connection复用，就必须提供相应的事务支持机制。可采用每一个事务独占一个连
接来实现，这种方法可以大大降低事务管理的复杂性。

4、连接池的分配与释放
连接池的分配与释放，对系统的性能有很大的影响。合理的分配与释放，可以提高连接的复用度，从而降低建立新连接的开销，同时还可以加快用户的访问速度。
对于连接的管理可使用空闲池。即把已经创建但尚未分配出去的连接按创建时间存放到一个空闲池中。每当用户请求一个连接时，系统首先检查空闲池内有没有空闲连接。如果有就把建立时间最长（通过容器的顺序存放实现）的那个连接分配给他（实际是
先做连接是否有效的判断，如果可用就分配给用户，如不可用就把这个连接从空闲池删掉，重新检测空闲池是否还有连接）；如果没有则检查当前所开连接池是否达到连接池所允许的最大连接数（maxconn）如果没有达到，就新建一个连接，如果已经达到，
就等待一定的时间（timeout）。如果在等待的时间内有连接被释放出来就可以把这个连接分配给等待的用户，如果等待时间超过预定时间timeout 则返回空值（null）。系统对已经分配出去正在使用的连接只做计数，当使用完后再返还给空闲池。对于空
闲连接的状态，可开辟专门的线程定时检测，这样会花费一定的系统开销，但可以保证较快的响应速度。也可采取不开辟专门线程，只是在分配前检测的方法。

5、连接池的配置与维护
连接池中到底应该放置多少连接，才能使系统的性能最佳？系统可采取设置最小连接数（minconn）和最大连接数（maxconn）来控制连接池中的连接。最小连接数是系统启动时连接池所创建的连接数。如果创建过多，则系统启动就慢，但创建后系统的响应
速度会很快；如果创建过少，则系统启动的很快，响应起来却慢。这样，可以在开发时，设置较小的最小连接数，开发起来会快，而在系统实际使用时设置较大的，因为这样对访问客户来说速度会快些。最大连接数是连接池中允许连接的最大数目，具体设
置多少，要看系统的访问量，可通过反复测试，找到最佳点。如何确保连接池中的最小连接数呢？有动态和静态两种策略。动态即每隔一定时间就对连接池进行检测，如果发现连接数量小于最小连接数，则补充相应数量的新连接以保证连接池的正常运转。静
态是发现空闲连接不够时再去检查。


192 运行时异常是什么？和检查异常有什么区别？
1.可查异常和不可查异常
通常，Java的异常(包括Exception和Error)分为可查的异常（checked exceptions）和不可查的异常（unchecked exceptions）。
可查异常（编译器要求必须处置的异常）：正确的程序在运行中，很容易出现的、情理可容的异常状况。可查异常虽然是异常状况，但在一定程度上它的发生是可以预计的，而且一旦发生这种异常状况，就必须采取某种方式进行处理。
除了RuntimeException及其子类以外，其他的Exception类及其子类都属于可查异常。这种异常的特点是Java编译器会检查它，也就是说，当程序中可能出现这类异常，要么用try-catch语句捕获它，要么用throws子句声明抛出它，否则编译不会通过。
不可查异常(编译器不要求强制处置的异常):包括运行时异常（RuntimeException与其子类）和错误（Error）。
如果使用throw在方法体中抛出可查异常，则需要在方法头部声明方法可能抛出的异常类型。程序会在throw语句后立即终止，它后面的语句执行不到，然后在包含它的所有try块中（可能在上层调用函数中）从里向外寻找含有与其匹配的catch子句的try块。
FileNotFoundException,IOException,SQLException.

2.运行时异常和非运行时异常
(1)运行时异常都是RuntimeException类及其子类异常，如NullPointerException、IndexOutOfBoundsException等，这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生。
当出现RuntimeException的时候，我们可以不处理。当出现这样的异常时，总是由虚拟机接管。比如：我们从来没有人去处理过NullPointerException异常，它就是运行时异常，并且这种异常还是最常见的异常之一。 
出现运行时异常后，如果没有捕获处理这个异常（即没有catch），系统会把异常一直往上层抛，一直到最上层，如果是多线程就由Thread.run()抛出，如果是单线程就被main()抛出。抛出之后，如果是线程，这个线程也就退出了。如果是主程序抛出的异常，那么这整个程序也就退出了。运行时异常是Exception的子类，也有一般异常的特点，是可以被catch块处理的。只不过往往我们不对他处理罢了。也就是说，你如果不对运行时异常进行处理，那么出现运行时异常之后，要么是线程中止，要么是主程序终止。 
如果不想终止，则必须捕获所有的运行时异常，决不让这个处理线程退出。队列里面出现异常数据了，正常的处理应该是把异常数据舍弃，然后记录日志。不应该由于异常数据而影响下面对正常数据的处理。
(2)非运行时异常是RuntimeException以外的异常，类型上都属于Exception类及其子类。如IOException、SQLException等以及用户自定义的Exception异常。对于这种异常，JAVA编译器强制要求我们必需对出现的这些异常进行catch并处理，否则程序就不能编译通过。所以，面对这种异常不管我们是否愿意，只能自己去写一大堆catch块去处理可能的异常。


193 得到线程运行结果有几种方式实现？
（1）最官方办法 Future接口
public class ThreadReturnValue implements Callable {  
    @Override  
    public Object call() throws Exception {  
        int temp = 0;  
        StringBuffer sb = new StringBuffer("");  
        synchronized (App.GLOBALARRAY) {  
            for (int i = 0; i < App.GLOBALARRAY.length; i++) {  
                System.out.println(Thread.currentThread().getName() + "\n" + App.GLOBALARRAY[i]);  
                App.GLOBALARRAY[i] += 1;  
                temp += App.GLOBALARRAY[i];  
                sb.append("+").append(App.GLOBALARRAY[i]);  
            }  
        }  
        return sb.toString() + "=" + temp;  
    }  
} 
 ExecutorService pool = Executors.newFixedThreadPool(3);  
        Future<String> future = pool.submit(new ThreadReturnValue());  
        Future<String> future2 = pool.submit(new ThreadReturnValue());  
        Future<String> future3 = pool.submit(new ThreadReturnValue());  
        pool.shutdown(); // 不允许再想线程池中增加线程  
		String r = future.get();  
		String r2 = future2.get();  
		String r3 = future3.get();  
		
		
		
（2）join方法
（3）循环判断线程的状态如果已结束在获取结果 


194 如何避免超卖和超发的情况发生？
@悲观锁思路，也就是在修改数据的时候，采用锁定状态，排斥外部请求的修改。遇到加锁的状态，就必须等待
@FIFO内存队列思路，我们现在解决了锁的问题，全部请求采用“先进先出”的队列方式来处理。那么新的问题来了，高并发的场景下，因为请求很多，很可能一瞬间将队列内存“撑爆”，然后系统又陷入到了异常状态。
@乐观锁思路，乐观锁，是相对于“悲观锁”采用更为宽松的加锁机制，大都是采用带版本号（Version）更新。实现就是，这个数据所有请求都有资格去修改，但会获得一个该数据的版本号，只有版本号符合的才能更新成功，
其他的返回抢购失败。这样的话，我们就不需要考虑队列的问题，不过，它会增大CPU的计算开销。但是，综合来说，这是一个比较好的解决方案。
@ConrenthashMap思路，支持同步和并发一起。


195 如何实现list中根据对象的某个属性排序？
Bean实现Comparator接口，覆写compare方法
public class ComparatorUser implements Comparator{
 public int compare(Object obj0, Object obj1) {
  User user0=(User)obj0;
  User user1=(User)obj1;
  int flag=user0.getAge().compareTo(user1.getAge());
  if(flag==0){
   return user0.getName().compareTo(user1.getName());
  }else{
   return flag;
  }  
 }
}


196 Memcache和redis存储什么区别？
1)、Redis和Memcache都是将数据存放在内存中，都是内存数据库。不过memcache还可用于缓存其他东西，例如图片、视频等等。
2)、Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，hash等数据结构的存储。
3)、虚拟内存--Redis当物理内存用完时，可以将一些很久没用到的value 交换到磁盘
4)、过期策略--memcache在set时就指定，例如set key1 0 0 8,即永不过期。Redis可以通过例如expire 设定，例如expire name 10
5)、分布式--设定memcache集群，利用magent做一主多从;redis可以做一主多从。都可以一主一从
6)、存储数据安全--memcache挂掉后，数据没了；redis可以定期保存到磁盘（持久化）
7)、灾难恢复--memcache挂掉后，数据不可恢复; redis数据丢失后可以通过aof恢复
8)、Redis支持数据的备份，即master-slave模式的数据备份。


197 Executors有几种模式，分别是什么？
Java通过Executors提供四种线程池，分别为：
newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。
newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。
newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。
newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。


198 线程中Join方法用法是什么？停止线程执行最官方的方法是？
 join方法用得不多,当A线程执行到了B线程的join()方法时,A就会等待,等B线程都运行完,A线程才会执行。
 interrupt使线程停止，stop不建议使用 


199 Lock对比synchronized有什么优势，Condition接口中await和signal方法对比object的wait、nofity有何不同？
synchronized是基于jvm底层实现的数据同步，lock是基于Java编写，主要通过硬件依赖CPU指令实现数据同步。下面一一介绍

一、synchronized的实现方案
1.synchronized能够把任何一个非null对象当成锁，实现由两种方式：
a.当synchronized作用于非静态方法时，锁住的是当前对象的事例，当synchronized作用于静态方法时，锁住的是class实例，又因为Class的相关数据存储在永久带，因此静态方法锁相当于类的一个全局锁。
b.当synchronized作用于一个对象实例时，锁住的是对应的代码块。

2.synchronized锁又称为对象监视器（object）。

3.当多个线程一起访问某个对象监视器的时候，对象监视器会将这些请求存储在不同的容器中。
>Contention List：竞争队列，所有请求锁的线程首先被放在这个竞争队列中
>Entry List：Contention List中那些有资格成为候选资源的线程被移动到Entry List中
>Wait Set：哪些调用wait方法被阻塞的线程被放置在这里
>OnDeck：任意时刻，最多只有一个线程正在竞争锁资源，该线程被成为OnDeck
>Owner：当前已经获取到所资源的线程被称为Owner
> !Owner：当前释放锁的线程
下图展示了他们之前的关系

4.synchronized在jdk1.6之后提供了多种优化方案：
>自旋锁
jdk1.6之后默认开启，可以使用参数-XX:+UseSpinning控制，自旋等待不能代替阻塞，且先不说对处理器数量的要求，自旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间的，因此，如果锁被占用的时间很短，自旋等待的效果就会非常好，反之，如果锁被占用的时候很长，那么自旋的线程只会白白消耗处理器资源，而不会做任何有用的工作，反而会带来性能上的浪费。自旋次数的默认值是 10 次，用户可以使用参数 -XX:PreBlockSpin 来更改。
自旋锁的本质：执行几个空方法，稍微等一等，也许是一段时间的循环，也许是几行空的汇编指令。
>锁消除
即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除，依据来源于逃逸分析的数据支持，那么是什么是逃逸分析？对于虚拟机来说需要使用数据流分析来确定是否消除变量底层框架的同步代码，因为有许多同步的代码不是自己写的。
例1.1
public static String concatString(String s1, String s2, String s3) {  
return s1 + s2 + s3;  
}  
由于 String 是一个不可变的类，对字符串的连接操作总是通过生成新的 String 对象来进行的，因此 Javac 编译器会对 String 连接做自动优化。在 JDK 1.5 之前，会转化为 StringBuffer 对象的连续 append() 操作，在 JDK 1.5 及以后的版本中，会转化为 StringBuilder 对象的连续 append() 操作，这里的stringBuilder.append是线程不同步的（假设是同步）。
Javac 转化后的字符串连接代码为：

public static String concatString(String s1, String s2, String s3) {  
StringBuffer sb = new StringBuffer();  
sb.append(s1);  
sb.append(s2);  
sb.append(s3);  
return sb.toString();  
}  

此时的锁对象就是sb,虚拟机观察变量 sb，很快就会发现它的动态作用域被限制在 concatString() 方法内部。也就是说，sb 的所有引用永远不会 “逃逸” 到concatString() 方法之外，其他线程无法访问到它，虽然这里有锁，但是可以被安全地消除掉，在即时编译之后，这段代码就会忽略掉所有的同步而直接执行了。
>锁粗化
将同步块的作用范围限制得尽量小——只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待锁的线程也能尽快拿到锁。
>轻量级锁
加锁过程：在代码进入同步块的时候，如果此同步对象没有被锁定（锁标志位为 “01” 状态）虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的 Mark Word 的拷贝，这时候线程堆栈与对象头的状态如图 13-3 所示
然后，虚拟机将使用 CAS 操作尝试将对象的 Mark Word 更新为指向 Lock Record 的指针。如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象 Mark Word 的锁标志位 （Mark Word 的最后 2bit）将转变为 “00”，即表示此对象处于轻量级锁定状态，这时线程堆栈与对象头的状态如图13-4　　              
如果上述更新操作失败，则说明这个锁对象被其他锁占用，此时轻量级变为重量级锁，标志位为“10”，后面等待的线程进入阻塞状态。
解锁过程：也是由CAS进行操作的，如果对象的 Mark Word 仍然指向着线程的锁记录，那就用 CAS 操作把对象当前的 Mark Word 和线程中复制的 Displaced Mark Word 替换回来，如果替换成功，整个同步过程就完成了。如果替换失败，说明有其他线程尝试过获取该锁，那就要释放锁的同时，唤醒被挂起的线程。
轻量级锁能提升程序同步性能的依据是 “对于绝大部分的锁，在整个同步周期内都是不存在竞争的”，这是一个经验数据。如果没有竞争，轻量级锁使用 CAS 操作避免了使用互斥量的开销，但如果存在锁竞争，除了互斥量的开销外，还额外发生了 CAS 操作，因此在有竞争的情况下，轻量级锁会比传统的重量级锁更慢。
>偏向锁
偏向锁也是 JDK 1.6 中引入的一项锁优化，它的目的是消除数据在无竞争情况下的同步原语，进一步提高程序的运行性能。如果说轻量级锁是在无竞争的情况下使用 CAS 操作去消除同步使用的互斥量，那偏向锁就是在无竞争的情况下把整个同步都消除掉，连 CAS 操作都不做了。
实质就是设置一个变量，判断这个变量是否是当前线程，是就避免再次加锁解锁操作，从而避免了多次的CAS操作。坏处是如果一个线程持有偏向锁，另外一个线程想争用偏向对象，拥有者想释放这个偏向锁，释放会带来额外的性能开销，但是总体来说偏向锁带来的好处还是大于CAS的代价的。在具体问题具体分析的前提下，有时候使用参数 -XX:-UseBiasedLocking 来禁止偏向锁优化反而可以提升性能。


二、lock的实现方案
与synchronized不同的是lock是纯java手写的，与底层的JVM无关。在java.util.concurrent.locks包中有很多Lock的实现类，常用的有ReenTrantLock、ReadWriteLock(实现类有ReenTrantReadWriteLock)
，其实现都依赖java.util.concurrent.AbstractQueuedSynchronizer类（简称AQS），实现思路都大同小异，因此我们以ReentrantLock作为讲解切入点。
分析之前我们先来花点时间看下AQS。AQS是我们后面将要提到的CountDownLatch/FutureTask/ReentrantLock/RenntrantReadWriteLock/Semaphore的基础，因此AQS也是Lock和Excutor实现的基础。它的基本思想就是一个同步器，支持获取锁和释放锁两个操作。
要支持上面锁获取、释放锁就必须满足下面的条件：
1、  状态位必须是原子操作的
2、  阻塞和唤醒线程
3、  一个有序的队列，用于支持锁的公平性
场景：可定时的、可轮询的与可中断的锁获取操作，公平队列，或者非块结构的锁。
主要从以下几个特点介绍：

1.可重入锁
如果锁具备可重入性，则称作为可重入锁。像synchronized和ReentrantLock都是可重入锁，可重入性在我看来实际上表明了锁的分配机制：基于线程的分配，而不是基于方法调用的分配。

2.可中断锁
可中断锁：顾名思义，就是可以相应中断的锁。
在Java中，synchronized就不是可中断锁，而Lock是可中断锁。
如果某一线程A正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程B不想等待了，想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，这种就是可中断锁。

3.公平锁和非公平锁
公平锁以请求锁的顺序来获取锁，非公平锁则是无法保证按照请求的顺序执行。synchronized就是非公平锁，它无法保证等待的线程获取锁的顺序。而对于ReentrantLock和ReentrantReadWriteLock，它默认情况下是非公平锁，但是可以设置为公平锁。
参数为true时表示公平锁，不传或者false都是为非公平锁。
ReentrantLock lock = new ReentrantLock(true);

4.读写锁
读写锁将对一个资源（比如文件）的访问分成了2个锁，一个读锁和一个写锁。
正因为有了读写锁，才使得多个线程之间的读操作不会发生冲突。
ReadWriteLock就是读写锁，它是一个接口，ReentrantReadWriteLock实现了这个接口。
可以通过readLock()获取读锁，通过writeLock()获取写锁。


三、总结
1.synchronized
优点：实现简单，语义清晰，便于JVM堆栈跟踪，加锁解锁过程由JVM自动控制，提供了多种优化方案，使用更广泛
缺点：悲观的排他锁，不能进行高级功能

2.lock
优点：可定时的、可轮询的与可中断的锁获取操作，提供了读写锁、公平锁和非公平锁　　
缺点：需手动释放锁unlock，不适合JVM进行堆栈跟踪

3.相同点　
都是可重入锁





Condition，Condition 将 Object 监视器方法（wait、notify 和 notifyAll）分解成截然不同的对象，以便通过将这些对象与任意 Lock 实现组合使用，为每个对象提供多个等待 set （wait-set）。其中，Lock 替代了 synchronized 方法和语句的使用，Condition 替代了 Object 监视器方法的使用。下面将之前写过的一个线程通信的例子替换成用Condition实现(Java线程(三))，代码如下：

    public class ThreadTest2 {  
        public static void main(String[] args) {  
            final Business business = new Business();  
            new Thread(new Runnable() {  
                @Override  
                public void run() {  
                    threadExecute(business, "sub");  
                }  
            }).start();  
            threadExecute(business, "main");  
        }     
        public static void threadExecute(Business business, String threadType) {  
            for(int i = 0; i < 100; i++) {  
                try {  
                    if("main".equals(threadType)) {  
                        business.main(i);  
                    } else {  
                        business.sub(i);  
                    }  
                } catch (InterruptedException e) {  
                    e.printStackTrace();  
                }  
            }  
        }  
    }  
    class Business {  
        private boolean bool = true;  
        private Lock lock = new ReentrantLock();  
        private Condition condition = lock.newCondition();   
        public /*synchronized*/ void main(int loop) throws InterruptedException {  
            lock.lock();  
            try {  
                while(bool) {                 
                    condition.await();//this.wait();  
                }  
                for(int i = 0; i < 100; i++) {  
                    System.out.println("main thread seq of " + i + ", loop of " + loop);  
                }  
                bool = true;  
                condition.signal();//this.notify();  
            } finally {  
                lock.unlock();  
            }  
        }     
        public /*synchronized*/ void sub(int loop) throws InterruptedException {  
            lock.lock();  
            try {  
                while(!bool) {  
                    condition.await();//this.wait();  
                }  
                for(int i = 0; i < 10; i++) {  
                    System.out.println("sub thread seq of " + i + ", loop of " + loop);  
                }  
                bool = false;  
                condition.signal();//this.notify();  
            } finally {  
                lock.unlock();  
            }  
        }  
    }  
        在Condition中，用await()替换wait()，用signal()替换notify()，用signalAll()替换notifyAll()，传统线程的通信方式，Condition都可以实现，这里注意，Condition是被绑定到Lock上的，要创建一个Lock的Condition必须用newCondition()方法。

        这样看来，Condition和传统的线程通信没什么区别，Condition的强大之处在于它可以为多个线程间建立不同的Condition，下面引入API中的一段代码，加以说明。
    class BoundedBuffer {  
       final Lock lock = new ReentrantLock();//锁对象  
       final Condition notFull  = lock.newCondition();//写线程条件   
       final Condition notEmpty = lock.newCondition();//读线程条件   
      
       final Object[] items = new Object[100];//缓存队列  
       int putptr/*写索引*/, takeptr/*读索引*/, count/*队列中存在的数据个数*/;  
      
       public void put(Object x) throws InterruptedException {  
         lock.lock();  
         try {  
           while (count == items.length)//如果队列满了   
             notFull.await();//阻塞写线程  
           items[putptr] = x;//赋值   
           if (++putptr == items.length) putptr = 0;//如果写索引写到队列的最后一个位置了，那么置为0  
           ++count;//个数++  
           notEmpty.signal();//唤醒读线程  
         } finally {  
           lock.unlock();  
         }  
       }  
      
       public Object take() throws InterruptedException {  
         lock.lock();  
         try {  
           while (count == 0)//如果队列为空  
             notEmpty.await();//阻塞读线程  
           Object x = items[takeptr];//取值   
           if (++takeptr == items.length) takeptr = 0;//如果读索引读到队列的最后一个位置了，那么置为0  
           --count;//个数--  
           notFull.signal();//唤醒写线程  
           return x;  
         } finally {  
           lock.unlock();  
         }  
       }   
     }  

        这是一个处于多线程工作环境下的缓存区，缓存区提供了两个方法，put和take，put是存数据，take是取数据，内部有个缓存队列，具体变量和方法说明见代码，这个缓存区类实现的功能：有多个线程往里面存数据和从里面取数据，其缓存队列(先进先出后进后出)能缓存的最大数值是100，多个线程间是互斥的，当缓存队列中存储的值达到100时，将写线程阻塞，并唤醒读线程，当缓存队列中存储的值为0时，将读线程阻塞，并唤醒写线程，这也是ArrayBlockingQueue的内部实现。下面分析一下代码的执行过程：
        1. 一个写线程执行，调用put方法；
        2. 判断count是否为100，显然没有100；
        3. 继续执行，存入值；
        4. 判断当前写入的索引位置++后，是否和100相等，相等将写入索引值变为0，并将count+1；
        5. 仅唤醒读线程阻塞队列中的一个；
        6. 一个读线程执行，调用take方法；
        7. ……
        8. 仅唤醒写线程阻塞队列中的一个。
		
        这就是多个Condition的强大之处，假设缓存队列中已经存满，那么阻塞的肯定是写线程，唤醒的肯定是读线程，相反，阻塞的肯定是读线程，唤醒的肯定是写线程，那么假设只有一个Condition会有什么效果呢，缓存队列中已经存满，这个Lock不知道唤醒的是读线程还是写线程了，如果唤醒的是读线程，皆大欢喜，如果唤醒的是写线程，那么线程刚被唤醒，又被阻塞了，这时又去唤醒，这样就浪费了很多时间



200 线程同步方法有哪些？
（1）同步方法
（2）同步代码块
（3）wait与notify
wait():使一个线程处于等待状态，并且释放所持有的对象的lock。
sleep():使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要捕捉InterruptedException异常。
notify():唤醒一个处于等待状态的线程，注意的是在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由JVM确定唤醒哪个线程，而且不是按优先级。
Allnotity():唤醒所有处入等待状态的线程，注意并不是给所有唤醒线程一个对象的锁，而是让它们竞争。
（4）使用特殊域变量(volatile)实现线程同步
//需要同步的变量加上volatile
private volatile int account = 100;
a.volatile关键字为域变量的访问提供了一种免锁机制
b.使用volatile修饰域相当于告诉虚拟机该域可能会被其他线程更新
c.因此每次使用该域就要重新计算，而不是使用寄存器中的值 
d.volatile不会提供任何原子操作，它也不能用来修饰final类型的变量 
（5）ReentrantLock() : 创建一个ReentrantLock实例 
lock() : 获得锁 
unlock() : 释放锁 
（6）ThreadLocal方法
a.ThreadLocal与同步机制都是为了解决多线程中相同变量的访问冲突问题。 
b.前者采用以"空间换时间"的方法，后者采用以"时间换空间"的方式
（7）LinkedBlockingQueue阻塞队列实现线程同步
（8）原子操作就是指将读取变量值、修改变量值、保存变量值看成一个整体来操作即-这几种行为要么同时完成，要么都不完成。在java的util.concurrent.atomic包中提供了创建了原子类
型变量的工具类，使用该类可以简化线程同步。其中AtomicInteger 表可以用原子方式更新int的值，可用在应用程序中(如以原子方式增加的计数器)，但不能用于替换Integer；
可扩展Number，允许那些处理机遇数字类的工具和实用工具进行统一访问。
（9）ConcurrentHashMap并发16个，桶的方式同步 



201 Callable和Runnable不同点？
(1)Callable规定的方法是call()，Runnable规定的方法是run()。其中Runnable可以提交给Thread来包装下，直接启动一个线程来执行，而Callable则一般都是提交给ExecuteService来执行。
(2)Callable的任务执行后可返回值，而Runnable的任务是不能返回值得
(3)call方法可以抛出异常，run方法不可以
(4)运行Callable任务可以拿到一个Future对象，c表示异步计算的结果。


202 Jdk中BlockingQueue有几个实现类？各自有什么特征？
@ArrayBlockingQueue：一个由数组支持的有界阻塞队列，规定大小的BlockingQueue,其构造函数必须带一个int参数来指明其大小.其所含的对象是以FIFO(先入先出)顺序排序的。
@LinkedBlockingQueue：大小不定的BlockingQueue,若其构造函数带一个规定大小的参数,生成的BlockingQueue有大小限制,若不带大小参数,所生成的BlockingQueue的大小由Integer.MAX_VALUE来决定.其所含的对象是以FIFO(先入先出)顺序排序的。
@PriorityBlockingQueue:类似于LinkedBlockQueue,但其所含对象的排序不是FIFO,而是依据对象的自然排序顺序或者是构造函数的Comparator决定的顺序.
@SynchronousQueue:特殊的BlockingQueue,对其的操作必须是放和取交替完成的.
其中LinkedBlockingQueue和ArrayBlockingQueue比较起来,它们背后所用的数据结构不一样,导致LinkedBlockingQueue的数据吞吐量要大于ArrayBlockingQueue,但在线程数量很大时其性能的可预见性低于ArrayBlockingQueue.

  
203现在有1、2、3三个线程，你怎样保证2在1执行完后执行，3在2执行完后执行？
Java多线程中的join方法


204 JDK，JRE，jvm的区别和联系是什么？
我们利用JDK（调用JAVA API）开发了属于我们自己的JAVA程序后，通过JDK中的编译程序（javac）将我们的文本java文件编译成JAVA字节码，在JRE上运行这些JAVA字节码，JVM解析这些字节码，映射到CPU指令集或OS的系统调用。



205 int 和Integer 有什么区别? 
int 是基本类型，直接存数值，进行初始化时int类的变量初始为0。
  integer是对象，用一个引用指向这个对象，Integer的变量则初始化为null。
  原始数据类型，分为boolean,byte,in,char,long,short,double,float 
  为了能够将这些基本数据类型当成对象操作，Java为每 一个基本数据类型都引入了对应的包装类型，int的包装类就是Integer，从Java 5开始引入了自动装箱/拆箱机制，使得二者可以相互转换。
	  Integer num = 9;
  解析原因：归结于java对于Integer与int的自动装箱与拆箱的设计，是一种模式：叫享元模式（flyweight）。加大对简单数字的重利用，Java定义在自动装箱时对于值从–128到127之间的值，它们被装箱为Integer对象后，会存在内存中被重用，始终只存在一个对象。



206 解释内存中的栈（stack）、堆(heap)和静态存储区的用法？
   Runtime Data Areas运行时数据区可以划分为6个区域：
     PC 寄存器(Program Counter Register)，根据不同线程启动而被创建
     JVM 栈(JVM Stacks)，根据不同线程启动而被创建，只保存基础数据类型的对象和自定义对象的引用，每个栈中的数据(原始类型和对象引用)都是私有的，其他栈不能访问。
     本地方法栈(Native Method Stacks)，根据不同线程启动而被创建
	 堆(Heap)，随JVM 启动而被创建，被所有线程公用，存储的是new出来的对象和数组，每个对象都包含一个与之对应的class的信息。(class的目的是得到操作指令)；
	 jvm只有一个堆区(heap)被所有线程共享，堆中不存放基本类型和对象引用，只存放对象本身，可能抛出OutOfMemoryError.堆是GC管理的主要区域。
	 一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收 。
	 分为新生代、老年代、永久代
	 在方法中去new一个对象，那这方法调用完毕后，对象就会被回收，这就是一个典型的新生代对象
	 在新生代中经历了N次垃圾回收后仍然存活的对象就会被放到老年代中。而且大对象直接进入老年代
	 永久代即方法区
     方法区(Method Area)，随JVM 启动而被创建，被所有线程公用，又叫静态区，方法区包含所有的class和static变量。都是在整个程序中永远唯一的元素，如class，static变量。
	 字符串常量池放在方法区。将会抛出OutOfMemoryError
     运行时常量池(Runtime Constant Pool)，随JVM 启动而被创建，被所有线程公用，每个类或接口的常量池在类和接口被JVM 创建时建立



207描述一下JVM 加载class文件的原理机制?
（1）JVM组成：
  JVM 全称是Java Virtual Machine ，Java 虚拟机，也就是在计算机上再虚拟一个计算机，这和我们使用 VMWare不一样，那个虚拟的东西你是可以看到的，这个JVM 你是看不到的，它存在内存中。
  JVM 存储就是内存了，我们写的所有类、常量、变量、方法都在内存中
  整个JVM 分为四部分：
  Class Loader 类加载器 ：Class Loader 只管加载，只要符合文件结构就加载，至于说能不能运行，则不是它负责的，那是由Execution Engine 负责的，
  Execution Engine 执行引擎 ：负责解释命令，提交操作系统执行
  Native Interface 本地接口：融合不同的编程语言为Java 所用
  Runtime data area 运行数据区 ：
  整个JVM 框架由加载器加载文件，然后执行器在内存中处理数据，需要与异构系统交互是可以通过本地接口进行。
  
  （2）加载原理：
  都需要由类加载器装载到JVM中才能运行。类加载器本身也是一个类，而它的工作就是把class文件从硬盘读取到内存中。在写程序的时候，我们几乎不需要关心类的加载，因为这些都是隐式装载的，除非我们有特殊的用法，
  像是反射，就需要显式的加载所需要的类。类装载方式，有两种 
  1.隐式装载， 程序在运行过程中当碰到通过new 等方式生成对象时，隐式调用类装载器加载对应的类到jvm中，
  2.显式装载， 通过class.forname()等方法，显式加载需要的类 
  Java的类加载器有三个，对应Java的三种类:（java中的类大致分为三种：   1.系统类   2.扩展类 3.由程序员自定义的类 ）
  委托模型机制的工作原理很简单：当类加载器需要加载类的时候，先请示其Parent(即上一层加载器)在其搜索路径载入，如果找不到，才在自己的搜索路径搜索该类。这样的顺序其实就是加载器层次上自顶而下的搜索，因为加
  载器必须保证基础类的加载。之所以是这种机制，还有一个安全上的考虑：如果某人将一个恶意的基础类加载到jvm，委托模型机制会搜索其父类加载器，显然是不可能找到的，自然就不会将该类加载进来。
  
  （3）加载步骤：
  @装载:查找和导入class文件;
  @连接:检查:检查载入的class文件数据的正确性;
  准备:为类的静态变量分配存储空间;
  解析:将符号引用转换成直接引用(这一步是可选的)
  @初始化:初始化静态变量，静态代码块。


208 try{}里有一个return语句，那么紧跟在这个try后的finally{}里的code会不会被执行，什么时候被执行，在return前还是后?
在return前执行finally里面的语句。当运行到try或者catch里面的return语句时，JVM会先去执行finally里面的语句，然后再返回执行return语句，当然，如果finally里面有return语句就从这里返回了，而不会去执行之前的return语句。

209 Iterator符合哪个设计模式？
迭代器模式，提供一个方法按顺序遍历一个集合内的元素，而又不需要暴露该对象的内部表示。访问一个聚合的对象，而不需要暴露对象的内部表示；支持对聚合对象的多种遍历；对遍历不同的对象，提供统一的接口。

---------------------------------------------------------------------------------------------------------------
------------------------------------------java se basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------jiagou basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 架构设计的过程和内容的不是固定不变的，现实中，比如售前提供解决方案中，很多时候需要架构师提供细化架构中才会深思的逻辑架构、物理架构等，
这时候，架构师就需要有螺旋思维和跳跃思维的方式，就像武功中，招式是死的，人是活的，要学会灵活运用。

2 5视图架构的设计 
（1） 逻辑架构
逻辑架构的重点是考虑软件功能性需求。
No.	考虑的方面	产出物	工具	说明
1	系统功能划分为几个子系统与功能模块？	系统功能树	树型结构图	 
2	向什么用户提供什么样的功能？	用例模型	UML用例图	体现用户和行为
3	每个功能都是怎样的操作流程与分支？	用例描述	用例描述表
 	含输入输出、事件流分析；
不要有界面描述
			UML活动图	进行业务流程分析，包括泳道图
4	如何通过界面与用户交互？怎样交互？	鲁棒分析	鲁棒图	通过对“用例描述表”进行原文分析法拣出名词和动词
5	应当设计哪些类与界面？怎样设计？	领域模型	UML类图	 
6	与哪些外部系统接口？怎样接口？	接口描述	UML类图	 

（2）开发架构
开发架构重点关注的是开发编码实现方面的问题。
No.	考虑的方面	产出物	工具	说明
1	分层结构设计	分层架构图（开发架构图）	各种绘图工具	好的分层结构支持自动化测试
2	开发技术选项	开发语言
开发框架
开发工具	 	考虑商用产品、开源框架、自研框架
3	模块划分	源码工程；Project目录结构；
分包(分库)	 	 
4	开发规范	开发/编码规范文档；	 	 
5	软件质量属性	分析和决策结果	 	考虑运行期和开发期软件质量属性，并权衡利弊进行决策。

（3）数据架构
数据架构不仅仅要考虑开发中涉及到的数据库，实体模型，也要考虑物理架构中数据存储的设计。
No.	考虑的方面	产出物	工具	说明
1	数据是集中还是分布存储的？如何考虑分布式存储？	数据架构图	 	 
2	领域模型到数据库表的转换？表结构关系的设计？	逻辑模型
物理模型
ER图	Power Designer
Visio	 
3	实体如何设计？充血模型和贫血模型？	UML类图	 	 
4	使用什么数据库？关系型还是非关系型？	选型结果	 	 

（4） 运行架构
运行架构关注的不再是全局而是局部，着重关注那些关键点与难点，常常需要技术攻关与预研。主要考虑控制流、通讯机制、资源争用、锁机制、同步异步、并发、串行，同时也要考虑质量属性。
No.	考虑的方面	产出物	工具	说明
1	运行：同步vs.异步；并发vs.串行	考虑开发架构中代码的实现。	 	 
2	交互：对象间交互；状态转换	考虑开发架构的合理性，到类、到接口、到代码。	 	 
3	质量：安全；可靠；可伸缩	考虑开发架构的合理性	 	 
4	性能：响应时间；吞吐量	估算：
在线人数、并发人数；
每秒事务量；
响应时间。	 	 

（5）物理架构
物理架构主要考虑硬件选择和拓扑结构，软件到硬件的映射，软硬件的相互影响。
 	考虑的方面	产出物	工具	说明
1	网络方面：网络拓扑；网络设备；安全机制	拓扑图
安全规范	 	 
2	性能方面：可靠性、可伸缩性	需要什么样设备性能	 	 
3	部署方面：集中式还是分布式；组件部署	部署图




二、ms相关
1 进程间的通信方式和线程通信方式有什么不同？
几种进程间的通信方式
（1） 管道（pipe）：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有血缘关系的进程间使用。进程的血缘关系通常指父子进程关系。
（2）有名管道（named pipe）：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间通信。
（3）信号量（semophore）：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它通常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
（4）消息队列（message queue）：消息队列是由消息组成的链表，存放在内核中 并由消息队列标识符标识。消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。
（5）信号（signal）：信号是一种比较复杂的通信方式，用于通知接收进程某一事件已经发生。
（6）共享内存（shared memory）：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问，共享内存是最快的IPC方式，它是针对其他进程间的通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量配合使用，来实现进程间的同步和通信。
（7）套接字（socket）：套接口也是一种进程间的通信机制，与其他通信机制不同的是它可以用于不同及其间的进程通信。

几种线程间的通信机制

1、锁机制
     1.1 互斥锁：提供了以排它方式阻止数据结构被并发修改的方法。
     1.2 读写锁：允许多个线程同时读共享数据，而对写操作互斥。
     1.3 条件变量：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。

2、信号量机制：包括无名线程信号量与有名线程信号量
3、信号机制：类似于进程间的信号处理。
线程间通信的主要目的是用于线程同步，所以线程没有象进程通信中用于数据交换的通信机制。
进程和线程的区别？

定义：
进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位.

线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源.

.关系
一个线程可以创建和撤销另一个线程;同一个进程中的多个线程之间可以并发执行.
相对进程而言，线程是一个更加接近于执行体的概念，它可以与同进程中的其他线程共享数据，但拥有自己的栈空间，拥有独立的执行序列。

3.区别
进程和线程的主要差别在于它们是不同的操作系统资源管理方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。
1) 简而言之,一个程序至少有一个进程,一个进程至少有一个线程.
2) 线程的划分尺度小于进程，使得多线程程序的并发性高。
3) 另外，进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。
4) 线程在执行过程中与进程还是有区别的。每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。
5) 从逻辑角度来看，多线程的意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。这就是进程和线程的重要区别。
4.优缺点
线程和进程在使用上各有优缺点：线程执行开销小，但不利于资源的管理和保护；而进程正相反。同时，线程适合于在SMP机器上运行，而进程则可以跨机器迁移。


2  ArrayList如何实现自动扩容？
注意：

    不同的JDK版本的扩容机制可能有差异
    实验环境：JDK1.8

扩容机制：

    当向ArrayList中添加元素的时候，ArrayList如果要满足新元素的存储超过ArrayList存储新元素前的存储能力，ArrayList会增强自身的存储能力，已达到存储新元素的要求

ArrayList:本质通过内部维护的数组对象进行数据存储

①：分析ArrayList的add(E)方法

 public boolean add(E e) {
        ensureCapacityInternal(size + 1);  // Increments modCount!!
        elementData[size++] = e;
        return true;
    }


分析：add方法首先通过ensureCapacityInternal()方法确保当前ArrayList维护的数组具有存储新元素的能力，经过处理之后将元素存储在数组elementData的尾部
elementData：ArrayList真正用于存储元素的数组

②：分析ensureCapacityInternal方法

private void ensureCapacityInternal(int minCapacity) {
        if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
            minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);
        }
        ensureExplicitCapacity(minCapacity);
    }


分析：ensureCapacityInternal判断ArrayList默认的元素存储数据是否为空，为空则设置最小要求的存储能力为必要存储的元素和默认存储元素个数的两个数据之间的最大值，然后调用ensureExplicitCapacity方法实现这种最低要求的存储能力

注意：ArrayList的存储空间并不是需要一个创建一个，而是分阶段性的创建，一般会预留存储空间。
例如，如果ArrayList需要存储10个元素，恰好ArrayList只能存储6个元素，剩余4个元素无法存储，ArrayList可能会一次性扩展10个元素，这种ArrayList就有20个元素的存储能力，在存储能力范围内，下次再存放元素，就不需要再次扩容

③：分析ensureExplicitCapacity方法：

 private void ensureExplicitCapacity(int minCapacity) {
        modCount++;

        // overflow-conscious code
        if (minCapacity - elementData.length > 0)
            grow(minCapacity);
    }


分析：如果最低要求的存储能力>ArrayList已有的存储能力，这就表示ArrayList的存储能力不足，因此需要调用 grow();方法进行扩容
④：分析grow()方法

private void grow(int minCapacity) {
        // overflow-conscious code
        int oldCapacity = elementData.length;
        int newCapacity = oldCapacity + (oldCapacity >> 1);
        if (newCapacity - minCapacity < 0)
            newCapacity = minCapacity;
        if (newCapacity - MAX_ARRAY_SIZE > 0)
            newCapacity = hugeCapacity(minCapacity);
        // minCapacity is usually close to size, so this is a win:
        elementData = Arrays.copyOf(elementData, newCapacity);
    }


分析：当ArrayList扩容的时候，首先会设置新的存储能力为原来的1.5倍

 int newCapacity = oldCapacity + (oldCapacity >> 1);

    1

如果扩容之后还是不能满足要求则MAX_ARRAY_SIZE比较，求取最大值，
如果MAX_ARRAY_SIZE大小的能力还是不能满足则通过hugeCapacity()方法获取ArrayList能允许的最大值：

private static int hugeCapacity(int minCapacity) {
        if (minCapacity < 0) // overflow
            throw new OutOfMemoryError();
        return (minCapacity > MAX_ARRAY_SIZE) ?
            Integer.MAX_VALUE :
            MAX_ARRAY_SIZE;
    }


从hugeCapacity方法看出，ArrayList最大的存储能力：存储元素的个数为整型的范围。
确定ArrayList扩容之后最新的可存储元素个数时，调用
elementData = Arrays.copyOf(elementData, newCapacity);
实现elementData数组的扩容，整个流程就是ArrayList的自动扩容机制工作流程

扩展：
ArrayList的自动扩容机制底层借助于System实现

  public static native void arraycopy
  (Object src,  int  srcPos,
   Object dest, int destPos,
   int length);


arraycopy标识为native意味JDK的本地库，不可避免的会进行IO操作，如果频繁的对ArrayList进行扩容，毫不疑问会降低ArrayList的使用性能，因此当我们确定添加元素的个数的时候，我们可以事先知道并指定ArrayList的可存储元素的个数，这样当我们向ArrayList中加入元素的时候，就可以避免ArrayList的自动扩容，从而提高ArrayList的性能

ArrayList含参构造函数:初始化时指定存储元素的能力：

 public ArrayList(int initialCapacity) {
        if (initialCapacity > 0) {
            this.elementData = new Object[initialCapacity];
        } else if (initialCapacity == 0) {
            this.elementData = EMPTY_ELEMENTDATA;
        } else {
            throw new IllegalArgumentException(
            "Illegal Capacity: "+initialCapacity);                                               
        }
}


3 线程状态中BLOCKED和WAITING有什么区别？
BLOCKED和WAITING有什么区别呢？
答复在JDK源码中可以找到，如下是Java.lang.Thread.State类的一部分注释。

/**
* Thread state for a thread blocked waiting for a monitor lock.
* A thread in the blocked state is waiting for a monitor lock
* to enter a synchronized block/method or
* reenter a synchronized block/method after calling
* {@link Object#wait() Object.wait}.
*/
BLOCKED,

/**
* Thread state for a waiting thread.
* A thread is in the waiting state due to calling one of the
* following methods:
* {@link Object#wait() Object.wait} with no timeout
* {@link #join() Thread.join} with no timeout
* {@link LockSupport#park() LockSupport.park}
*
*
* A thread in the waiting state is waiting for another thread to
* perform a particular action.
*
* For example, a thread that has called Object.wait()
* on an object is waiting for another thread to call
* Object.notify() or Object.notifyAll() on
* that object. A thread that has called Thread.join()
* is waiting for a specified thread to terminate.
*/
WAITING,


从中可以清晰的得到线程处于BLOCKED和WAITING状态的场景。
BLOCKED状态

线程处于BLOCKED状态的场景。

当前线程在等待一个monitor lock，比如等待执行synchronized代码块或者使用synchronized标记的方法。
在synchronized块中循环调用Object类型的wait方法，如下是样例
synchronized(this)
{
while (flag)
{
obj.wait();
}
// some other code
}



WAITING状态

线程处于WAITING状态的场景。

调用Object对象的wait方法，但没有指定超时值。
调用Thread对象的join方法，但没有指定超时值。
调用LockSupport对象的park方法。


提到WAITING状态，顺便提一下TIMED_WAITING状态的场景。
TIMED_WAITING状态

线程处于TIMED_WAITING状态的场景。

调用Thread.sleep方法。
调用Object对象的wait方法，指定超时值。
调用Thread对象的join方法，指定超时值。
调用LockSupport对象的parkNanos方法。
调用LockSupport对象的parkUntil方法。


4 JVM如何加载字节码文件？
见12题，和12题一样 


5 常见GC算法有哪些？
引用计数法 Reference Counting
给对象添加一个引用计数器，每过一个引用计数器值就+1，少一个引用就-1。当它的引用变为0时，该对象就不能再被使用。它的实现简单，但是不能解决互相循环引用的问题。

根搜索算法 GC Roots Tracing
以一系列叫“GC Roots”的对象为起点开始向下搜索，走过的路径称为引用链（Reference Chain），当一个对象没有和任何引用链相连时，证明此对象是不可用的，用图论的说法是不可达的。那么它就会被判定为是可回收的对象。
JAVA里可作为GC Roots的对象 
虚拟机栈（栈帧中的本地变量表）中引用的对象 
方法区中的类静态属性引用的对象 
方法区中的常量引用的对象 
本地方法栈中JNI（即Native方法）的引用的对象

标记-清除算法 Mark-Sweep
这是一个非常基本的GC算法，它是现代GC算法的思想基础，分为标记和清除两个阶段：先把所有活动的对象标记出来，然后把没有被标记的对象统一清除掉。但是它有两个问题，一是效率问题，两个过程的效率都不高。二是空间问题，清除之后会产生大量不连续的内存。

复制算法 Copying
复制算法是将原有的内存空间分成两块，每次只使用其中的一块。在GC时，将正在使用的内存块中的存活对象复制到未使用的那一块中，然后清除正在使用的内存块中的所有对象，并交换两块内存的角色，完成一次垃圾回收。它比标记-清除算法要高效，但不适用于存活对象较多的内存，因为复制的时候会有较多的时间消耗。它的致命缺点是会有一半的内存浪费。

标记整理算法 Mark-Compact
标记整理算法适用于存活对象较多的场合，它的标记阶段和标记-清除算法中的一样。整理阶段是将所有存活的对象压缩到内存的一端，之后清理边界外所有的空间。它的效率也不高。



6 Major GC和Full GC的区别是什么？触发条件呢？ 
GC，即就是Java垃圾回收机制。目前主流的JVM（HotSpot）采用的是分代收集算法。与C++不同的是，Java采用的是类似于树形结构的可达性分析法来判断对象是否还存在引用。即：从gcroot开始，把所有可以搜索得到的对象标记为存活对象。
GC机制
要准确理解Java的垃圾回收机制，就要从：“什么时候”，“对什么东西”，“做了什么”三个方面来具体分析。
第一：“什么时候”即就是GC触发的条件。GC触发的条件有两种。（1）程序调用System.gc时可以触发；（2）系统自身来决定GC触发的时机。
系统判断GC触发的依据：根据Eden区和From Space区的内存大小来决定。当内存大小不足时，则会启动GC线程并停止应用线程。
第二：“对什么东西”笼统的认为是Java对象并没有错。但是准确来讲，GC操作的对象分为：通过可达性分析法无法搜索到的对象和可以搜索到的对象。对于搜索不到的方法进行标记。
第三：“做了什么”最浅显的理解为释放对象。但是从GC的底层机制可以看出，对于可以搜索到的对象进行复制操作，对于搜索不到的对象，调用finalize()方法进行释放。
具体过程：当GC线程启动时，会通过可达性分析法把Eden区和From Space区的存活对象复制到To Space区，然后把Eden Space和From Space区的对象释放掉。当GC轮训扫描To Space区一定次数后，把依然存活的对象复制到老年代，然后释放To Space区的对象。
对于用可达性分析法搜索不到的对象，GC并不一定会回收该对象。要完全回收一个对象，至少需要经过两次标记的过程。
第一次标记：对于一个没有其他引用的对象，筛选该对象是否有必要执行finalize()方法，如果没有执行必要，则意味可直接回收。（筛选依据：是否复写或执行过finalize()方法；因为finalize方法只能被执行一次）。
第二次标记：如果被筛选判定位有必要执行，则会放入FQueue队列，并自动创建一个低优先级的finalize线程来执行释放操作。如果在一个对象释放前被其他对象引用，则该对象会被移除FQueue队列。
GC过程中用到的回收算法：
通过上面的GC过程不难看出，Java堆中的年轻代和老年代采用了不同的回收算法。年轻代采用了复制法；而老年代采用了标记-整理法
具体各种回收算法的详解参考：http://www.cnblogs.com/dolphin0520/p/3783345.html
JVM内存空间图解

程序计数器：线程私有。是一块较小的内存，是当前线程所执行的字节码的行号指示器。是Java虚拟机规范中唯一没有规定OOM（OutOfMemoryError）的区域。
Java栈：线程私有。生命周期和线程相同。是Java方法执行的内存模型。执行每个方法都会创建一个栈帧，用于存储局部变量和操作数（对象引用）。局部变量所需要的内存空间大小在编译期间完成分配。所以栈帧的大小不会改变。存在两种异常情况：若线程请求深度大于栈的深度，抛StackOverflowError。若栈在动态扩展时无法请求足够内存，抛OOM。
Java堆：所有线程共享。虚拟机启动时创建。存放对象实力和数组。所占内存最大。分为新生代（Young区），老年代（Old区）。新生代分Eden区，Servior区。Servior区又分为From space区和To Space区。Eden区和Servior区的内存比为8:1。 当扩展内存大于可用内存，抛OOM。
方法区：所有线程共享。用于存储已被虚拟机加载的类信息、常量、静态变量等数据。又称为非堆（Non – Heap）。方法区又称“永久代”。GC很少在这个区域进行，但不代表不会回收。这个区域回收目标主要是针对常量池的回收和对类型的卸载。当内存申请大于实际可用内存，抛OOM。
本地方法栈：线程私有。与Java栈类似，但是不是为Java方法（字节码）服务，而是为本地非Java方法服务。也会抛StackOverflowError和OOM。

 Minor GC ，Full GC 触发条件 
Minor GC触发条件：当Eden区满时，触发Minor GC。
Full GC触发条件：
（1）调用System.gc时，系统建议执行Full GC，但是不必然执行
（2）老年代空间不足
（3）方法去空间不足
（4）通过Minor GC后进入老年代的平均大小大于老年代的可用内存
（5）由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小




7 JVM内存模型是什么？
下图说明JVM内存模型和JVM参数的关系：

JAVA堆的描述如下：
 
 　　内存由Perm和Heap组成。其中Heap = {Old + NEW = { Eden , from, to } }
　　JVM内存模型中分两大块:
　　NEW Generation：程序新创建的对象都是从新生代分配内存，新生代由Eden Space和两块相同大小的Survivor Space(通常又称S0和S1或From和To)构成，可通过-Xmn参数来指定新生代的大小，也可以通过-XX:SurvivorRation来调整Eden Space及Survivor Space的大小。垃圾回收一般用Copying的算法，速度快。每次GC的时候，存活下来的对象首先由Eden拷贝到某个Survivor Space, 当Survivor Space空间满了后, 剩下的live对象就被直接拷贝到Old Generation中去。因此，每次GC后，Eden内存块会被清空。
　　Old Generation：用于存放经过多次新生代GC任然存活的对象和应用程序中生命周期长的内存对象，例如缓存对象，新建的对象也有可能直接进入老年代，主要有两种情况：①大对象，可通过启动参数设置-XX:PretenureSizeThreshold=1024(单位为字节，默认为0)来代表超过多大时就不在新生代分配，而是直接在老年代分配。②大的数组对象，切数组中无引用外部对象。老年代所占的内存大小为-Xmx对应的值减去-Xmn对应的值。在Old Generation块中，垃圾回收一般用mark-compact的算法，速度慢些，但减少内存要求。
　　PS：还有个Permanent Generation，主要用来放JVM自己的反射对象，比如类对象和方法对象等。
 　　
　　垃圾回收描述：
　　现在收集器都是采用分代收集算法，堆被划分为新生代和老年代。新生代主要存储新创建的对象和尚未进入老年代的对象。老年代存储经过多次新生代GC(Minor GC)任然存活的对象。
　　Minor GC：即新生代GC，指发生在新生代的垃圾收集动作，因为Java对象大多都具备朝生夕灭的特性，所以Minor GC非常频繁，一般回收速度也比较快。垃圾回收分多级是1级或以上为部分垃圾回收，只会回收NEW中的垃圾。
　　Major GC  / Full GC：老年代GC，指发生在老年代的GC，出现了Major GC，经常会伴随至少一次的Minor GC（但非绝对的，在 ParallelScavenge 收集器的收集策略里就有直接进行 Major GC的策略选择过程） 。MajorGC 的速度一般会比Minor GC慢10倍以上。垃圾回收分多级是0级为全部(Full)的垃圾回收，会回收OLD段中的垃圾。
　　PS：内存溢出通常发生于OLD段或Perm段垃圾回收后，Eden区仍然无内存空间容纳新的Java对象的情况。
　　当一个URL被访问时，内存申请过程如下：
　　A. JVM会试图为相关Java对象在Eden中初始化一块内存区域
　　B. 当Eden空间足够时，内存申请结束。否则到下一步
　　C. JVM试图释放在Eden中所有不活跃的对象（这属于1或更高级的垃圾回收）, 释放后若Eden空间仍然不足以放入新对象，则试图将部分Eden中活跃对象放入Survivor区
　　D. Survivor区被用来作为Eden及OLD的中间交换区域，当OLD区空间足够时，Survivor区的对象会被移到Old区，否则会被保留在Survivor区
　　E. 当OLD区空间不够时，JVM会在OLD区进行完全的垃圾收集（0级）
　　F. 完全垃圾收集后，若Survivor及OLD区仍然无法存放从Eden复制过来的部分对象，导致JVM无法在Eden区为新对象创建内存区域，则出现”out of memory错误”
　　为什么一些程序频繁发生GC？有如下原因：
　　（1）程序内调用了System.gc()或Runtime.gc()。
　　 （2）一些中间件软件调用自己的GC方法，此时需要设置参数禁止这些GC。
　　（3）Java的Heap太小，一般默认的Heap值都很小。
　　（4）频繁实例化对象，Release对象。此时尽量保存并重用对象，例如使用StringBuffer()和String()。
　　如果你发现每次GC后，Heap的剩余空间会是总空间的50%，这表示你的Heap处于健康状态。许多Server端的Java程序每次GC后最好能有65%的剩余空间。
 
　　JVM 使用的GC算法是什么？
　　分代收集。即将内存分为几个区域，将不同生命周期的对象放在不同区域里；
　　在GC收集的时候，频繁收集生命周期短的区域(Young area)；
　　比较少的收集生命周期比较长的区域(Old area)；
　　基本不收集的永久区(Perm area)。
 
　　GC何时会被触发？
　　（1）系统空闲：GC线程的优先级低于系统应用线程，当系统中没有应用线程执行时，GC会被触发。
　　（2）堆空间内存不足：当堆空间的内存不足以创建新对象时，GC会被触发。如果第一GC仍不能获得足够的空间，第二次GC将被触发，如果这一次仍无法获取足够的空间，“Out of memory”将被抛出。


8 JAVA运行时数据区域有哪些？


1.程序计数器
    程序计数器（Program Counter Register） 是一块较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条执行字节码指令。
    每条线程都有一个独立的程序计数器。
如果执行的是java方法，这个计数器记录的是正在执行的虚拟机字节码指令地址。如果是native方法，计数器为空。此内存区域是唯一一个在java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。

2.Java虚拟机栈
    同样是线程私有，描述Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。一个方法对应一个栈帧。
    局部变量表存放了各种基本类型、对象引用和returnAddress类型（指向了一条字节码指令地址）。其中64位长度long 和 double占两个局部变量空间，其他只占一个。
规定的异常情况有两种：1.线程请求的栈的深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；2.如果虚拟机可以动态扩展，如果扩展时无法申请到足够的内存，就抛出OutOfMemoryError异常。

3.本地方法栈
和Java虚拟机栈很类似，不同的是本地方法栈为Native方法服务。

4.Java堆
    是Java虚拟机所管理的内存中最大的一块。由所有线程共享，在虚拟机启动时创建。堆区唯一目的就是存放对象实例。
    堆中可细分为新生代和老年代，再细分可分为Eden空间、From Survivor空间、To Survivor空间。
堆无法扩展时，抛出OutOfMemoryError异常

5.方法区
   所有线程共享，存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。
当方法区无法满足内存分配需求时，抛出OutOfMemoryError

6.运行时常量池
   它是方法区的一部分，Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项是常量池（Const Pool Table），用于存放编译期生成的各种字面量和符号引用。并非预置入Class文件中常量池的内容才进入方法运行时常量池，运行期间也可能将新的常量放入池中，这种特性被开发人员利用得比较多的便是String类的intern()方法。
当方法区无法满足内存分配需求时，抛出OutOfMemoryError

7.直接内存
    并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。
    JDK1.4加入了NIO，引入一种基于通道与缓冲区的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。因为避免了在Java堆和Native堆中来回复制数据，提高了性能。
    当各个内存区域总和大于物理内存限制，抛出OutOfMemoryError异常。


9 事务实现过程及原理是什么？
1、Spring中事务处理的作用：
Spring事务处理，是将事务处理的工作统一起来，并为事务处理提供通用的支持。

2、工作原理及实现
a、划分处理单元——IOC
由于spring解决的问题是对单个数据库进行局部事务处理的，具体的实现首相用spring中的IOC划分了事务处理单元。并且将对事务的各种配置放到了ioc容器中（设置事务管理器，设置事务的传播特性及隔离机制）。
b、AOP拦截需要进行事务处理的类
Spring事务处理模块是通过AOP功能来实现声明式事务处理的，具体操作（比如事务实行的配置和读取，事务对象的抽象），用TransactionProxyFactoryBean接口来使用AOP功能，生成proxy代理对象，通过TransactionInterceptor完成对代理方法的拦截，将事务处理的功能编织到拦截的方法中。
读取ioc容器事务配置属性，转化为spring事务处理需要的内部数据结构（TransactionAttributeSourceAdvisor），转化为TransactionAttribute表示的数据对象。
c、对事物处理实现（事务的生成、提交、回滚、挂起）
spring委托给具体的事务处理器实现。实现了一个抽象和适配。适配的具体事务处理器：DataSource数据源支持、hibernate数据源事务处理支持、JDO数据源事务处理支持，JPA、JTA数据源事务处理支持。这些支持都是通过设计PlatformTransactionManager、AbstractPlatforTransaction一系列事务处理的支持。
为常用数据源支持提供了一系列的TransactionManager。
d、结合
PlatformTransactionManager实现了TransactionInterception接口，让其与TransactionProxyFactoryBean结合起来，形成一个Spring声明式事务处理的设计体系。

3、应用场景
支持不同数据源，在底层进行封装，可以做到事务即开即用，这样的好处是：即使有其他的数据源事务处理需要，Spring也提供了一种一致的方式。

10 如何理解http协议和tcp协议？
TCP协议对应于传输层，而HTTP协议对应于应用层，从本质上来说，二者没有可比性。Http协议是建立在TCP协议基础之上的，当浏览器需要从服务器获取网页数据的时候，会发出一次Http请求。Http会通过TCP建立起一个到服务器的连接通道，当本次请求需要的数据完毕后，Http会立即将TCP连接断开，这个过程是很短的。所以Http连接是一种短连接，是一种无状态的连接。所谓的无状态，是指浏览器每次向服务器发起请求的时候，不是通过一个连接，而是每次都建立一个新的连接。如果是一个连接的话，服务器进程中就能保持住这个连接并且在内存中记住一些信息状态。而每次请求结束后，连接就关闭，相关的内容就释放了，所以记不住任何状态，成为无状态连接。

随着时间的推移，html页面变得复杂了，里面可能嵌入了很多图片，这时候每次访问图片都需要建立一次tcp连接就显得低效了。因此Keep-Alive被提出用来解决效率低的问题。从HTTP/1.1起，默认都开启了Keep-Alive，保持连接特性，简单地说，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。虽然这里使用TCP连接保持了一段时间，但是这个时间是有限范围的，到了时间点依然是会关闭的，所以我们还把其看做是每次连接完成后就会关闭。后来，通过Session, Cookie等相关技术，也能保持一些用户的状态。但是还是每次都使用一个连接，依然是无状态连接。

以前有个概念很容忍搞不清楚。就是为什么Http是无状态的短连接，而TCP是有状态的长连接？Http不是建立在TCP的基础上吗，为什么还能是短连接？现在明白了，Http就是在每次请求完成后就把TCP连接关了，所以是短连接。而我们直接通过Socket编程使用TCP协议的时候，因为我们自己可以通过代码区控制什么时候打开连接什么时候关闭连接，只要我们不通过代码把连接关闭，这个连接就会在客户端和服务端的进程中一直存在，相关状态数据会一直保存着。
在C#中会有Socket，实际上socket是对TCP/IP协议的封装，Socket本身并不是协议，而是一个调用接口(API)。Socket的出现只是使得程序员更方便地使用TCP/IP协议栈而已，是对TCP/IP协议的抽象，从而形成了我们知道的一些最基本的函数接口，比如create、listen、connect、accept、send、read和write等等。
比较形象的描述：HTTP是轿车，提供了封装或者显示数据的具体形式;Socket是发动机，提供了网络通信的能力。对于从C#编程的角度来讲，为了方便，你可以直接选择已经制造好的轿车Http来与服务器交互。但是有时候往往因为环境因素或者其他的一些定制的请求，必须要使用TCP协议，这时就需要使用Socket编程，然后自己去处理获取的数据。就像是你用已有的发动机，自己造了一辆卡车，去从服务器交互。

HTTP/1.0和HTTP/1.1都把TCP作为底层的传输协议。HTTP客户首先发起建立与服务器TCP连接。一旦建立连接，浏览器进程和服务器进程就可以通过各自的套接字来访问TCP。如前所述，客户端套接字是客户进程和TCP连接之间的“门”，服务器端套接字是服务器进程和同一TCP连接之间的“门”。客户往自己的套接字发送HTTP请求消息，也从自己的套接字接收HTTP响应消息。类似地，服务器从自己的套接字接收HTTP请求消息，也往自己的套接字发送HTTP响应消息。客户或服务器一旦把某个消息送入各自的套接字，这个消息就完全落入TCP的控制之中。TCP给HTTP提供一个可靠的数据传输服务;这意味着由客户发出的每个HTTP请求消息最终将无损地到达服务器，由服务器发出的每个HTTP响应消息最终也将无损地到达客户。

C#代码连接远程数据库用的是TCP协议。每次new 一个connection的时候，connection.open就打开了这个TCP连接。connection.Close的时候就关闭了这个连接。FTP的底层也是TCP， 不过是长连接的。传输大文件比较快。 需要看具体场景。在服务器端，如果程序是采取的长连接的方式，那么就能控制同时连接到这个服务器的连接个数，防止同时有多个连接。但是采取短连接的方式，那么就不能控制同时连接到这个服务器上的连接的个数，这也是一个优点，可以同时处理大量连接请求。但是如果连接请求量太大的话，可能造成服务器停止工作。
WebService不需要连接，一秒中至少可以支持上万/十万的请求，每次请求然后释放，没有空余的内存消耗。一般不会限制同时连接的个数，这是优势。Message Queue需要建立连接， 支持上千的连接就很吃力了。因为每个连接即使没有在请求数据，也会在内存中占用一定的空间存储。会限制，比如SQL Server数据库服务器，一般最多同时连接16个。
Http协议一定通过指定的端口，80，所以一般计算机上不会限制这个端口，所以Http协议能够顺利通过所有机器上的防火墙。而使用Socket编程的话，就需要自己指定特定的端口，那么很可能这个端口是在某个环境中禁用的，那么就无法穿透防火墙。IIS使用的是80端口，也就是这个程序一直在监听着这个端口。一旦发现有人要建立到这个端口的连接，他就会响应，然后建立连接。这里说的连接都是短连接。所以你对服务器上的网址的请求，都是通过80端口送到网站程序的。然后通过这个端口发送的客户端浏览器。



11 一致性哈希算法原理是什么？
使用场景
现在我们假设有100台redis data服务器，一份数据101进来的时候，以散列公式hash(i)&100，计算所存放的服务器，假设hash(i) = i,那么数据被散列到标号为1的服务器,然后这个时候服务器新增了一台，然后散列公式为hash(i)%101，这个时候请求访问数据101的时候，被分配至0号服务器，但是其实这个时候数据是在1号服务器的。
所以这个时候大量的数据失效了（访问不到了）。
所以这个时候，我们假设是新增了服务器，如果是持久化存储的，我们可以让服务器集群对数据进行重新散列，进行数据迁移，然后进行恢复，但是这个时候就意味着每次增减服务器的时候，集群就需要大量的通信，进行数据迁移，这个开销是非常大的。如果只是缓存，那么缓存就都失效了。所以这个时候怎么办？
我们可以看到，关键问题在于，服务器数量变动的时候，要能够保证旧的数据能够按照老的算法，计算到数据所在的服务器，而新的数据能够按照新的散列算法，计算出数据所在的服务器。

如上图，我们有ABCD四台服务器，这四台服务器被分配至0~232 的一个环上，比如0~230的存储在A服务器，230 +1~231 存储到B服务器上.....CD按照这样的进行均分。将我们的散列空间也划为0~232 ，然后数据进来后对232 取模，得到一个值K1，我们根据K1在环上所处的位置，得到所分配到的服务器，如图，K1被分配到B服务器。 这个时候，我们有一台服务器B失效了。

 
 
我们可以看到，如果是B失效了，那么如果有持久化存储的，需要做数据恢复，将B的数据迁移至C即可，对于原本散列在A和D的数据，不需要做任何改变。 同理，如果我们是新增了服务器，那么只需要对一台服务器的数据迁移一部分至新加的服务器即可。
一致性hash算法，减少了数据映射关系的变动，不会像hash(i)%N那样带来全局的变动
而且这样还有个好处，假设我们使用UID作为散列范围（即上面的232 ）,那么假设有部分UID的访问很频繁，而且这部分UID集中在B服务器上，那么就造成了B的负载远远高于其他服务器。这就是热点数据的问题。这个时候我们可以向B所在的UID空间添加服务器，减少B的压力。
其实还有个更好的解决办法：虚拟节点。
上面说的情况是，使用真实的服务器作为节点散列在232 上。 我们假设，只有4台服务器（如上图），然后A上面有热点数据，结果A挂掉了，然后做数据恢复，A的数据迁移至B，然后B需要承受A+B的数据，也承受不住，也挂了。。。。然后继续CD都挂了。这就造成了
雪崩效应。
上面会造成雪崩效应的原因分析：
如果不存在热点数据的时候，每台机器的承受的压力是M/2(假设每台机器的最高负载能力为M)，原本是不会有问题的，但是，这个时候A服务器由于有热点数据挂了，然后A的数据迁移至B，导致B所需要承受的压力变为M（还不考虑热点数据访问的压力），所以这个失败B是必挂的，然后C至少需要承受1.5M的压力。。。。然后大家一起挂。。。
所以我们通过上面可以看到，之所以会大家一起挂，原因在于如果一台机器挂了，那么它的压力全部被分配到一台机器上，导致雪崩。
如果我们A挂了以后，数据被平均分配到BCD上，每台机器多承受M/6的压力，然后大家就都不会挂啦（不考虑热点数据）。
这里引入虚拟节点，如图：

环上的空间被划分为8份，然后A存储A1和A2。。。
这个时候，如果A服务器挂了，访问压力会分配至C2和D1，也就是C和D服务器，而不是像前面，全部被分配到B上。
引入虚拟节点，主要在于，如果一台服务器挂了，能够将压力引流至不同的服务器。
总结：一致性hash算法（DHT）通过减少影响范围的方式解决了增减服务器导致的数据散列问题，从而解决了分布式环境下负载均衡问题，如果存在热点数据，那么通过增添节点的方式，对热点区间进行划分，将压力分配至其他服务器。重新达到负载均衡的状态。
tair的负载均衡就是采用的一致性hash算法啦~~~
一致性hash算法在分布式环境中应用的很广，只要是涉及到分布式存储的负载均衡问题，一致性hash都是很好的解决的方案。



12 jvm字节码的加载与卸载过程怎样的？
虚拟机把描述类的数据从class文件加载到内存，并对数据进行校验，转换分析和初始化，最终形成可以被虚拟节直接使用的JAVA类型，这就是虚拟机的类加载机制。
类从被加载到虚拟机内存到卸载出内存的生命周期包括：加载->连接(验证->准备->解析)->初始化->使用->卸载
初始化的5种情况：
1.使用new关键字实例化对象时，读取或设置一个类的静态字段，除被final修饰经编译结果放在常量池的静态字段，调用类的静态方法时。 2.使用java.lang.reflect包方法对类进行反射调用时。（Class.forName()）。 3.初始化子类时，如果父类没有初始化。 4.虚拟机启动时main方法所在的类。 5.当使用JDK1.7动态语言支持时，java.lang.invoke.MethodHandle实例解析结果为REF_getStatic,REF_putStatic,REF_invokeStatic的方法句柄，且对应类没有进行初始化。
加载 加载是类加载的第一个阶段，虚拟机要完成以下三个过程：
1.通过类的全限定名获取定义此类的二进制字节流。 2.将字节流的存储结构转化为方法区的运行时结构。 3.在内存中生成一个代表该类的Class对象，作为方法区各种数据的访问入口。
验证 目的是确保class文件字节流信息符合虚拟机的要求。
准备 为static修饰的变量赋初值，例如int型默认为0，boolean默认为false。
解析 虚拟机将常量池内的符号引用替换成直接引用。
初始化 初始化是类加载的最后一个阶段，将执行类构造器< init>()方法，注意这里的方法不是构造方法。该方法将会显式调用父类构造器，接下来按照java语句顺序为类变量和静态语句块赋值。
方法调用
Java是一门面向对象的语言，它具有多态性。那么虚拟机又是如何知道运行时该调用哪一个方法？
静态分派是在编译期就决定了该调用哪一个方法而不是由虚拟机来确定，方法重载就是典型的静态分派。 动态分派是在虚拟机运行阶段才能决定调用哪一个方法，方法重写就是典型的动态分派。
动态分派的实现：当调用一个对象的方法时，会将该对象的引用压栈到操作数栈，然后字节码指令invokevirtual会去寻找该引用实际类型。如果在实际类型中找对应的方法，且访问权限足够，则直接返回该方法引用，否则会依照继承关系对父类进行查找。实际上，如果子类没有重写父类方法，则子类方法的引用会直接指向父类方法。
由Java虚拟机自带的类加载器所加载的类，在虚拟机的生命周期中，始终不会被卸载。
　　前面介绍过，Java虚拟机自带的类加载器包括根类加载器、扩展类加载器和系统类加载器。
　　Java虚拟机本身会始终引用这些类加载器，而这些类加载器则会始终引用它们所加载的类的Class对象，因此这些Class对象始终是可触及的。
　　由用户自定义的类加载器加载的类是可以被卸载的。
具体的例子为：

       loader1变量和obj变量间接应用代表Sample类的Class对象，而objClass变量则直接引用它。
　　如果程序运行过程中，将上图左侧三个引用变量都置为null，此时Sample对象结束生命周期，MyClassLoader对象结束生命周期，代表Sample类的Class对象也结束生命周期，Sample类在方法区内的二进制数据被卸载。
　　当再次有需要时，会检查Sample类的Class对象是否存在，如果存在会直接使用，不再重新加载；如果不存在Sample类会被重新加载，在Java虚拟机的堆区会生成一个新的代表Sample类的Class实例(可以通过哈希码查看是否是同一个实例)。



13 Http连接池作用是什么？实现原理？
随着微服务的流行，服务之间的http调用越来越多，遇到的问题也比较多，写这边文章的目的也是将自己遇到的坑和解决方案跟大家分享

一、为什么要用Http连接池
1、降低延迟：如果不采用连接池，每次连接发起Http请求的时候都会重新建立TCP连接(经历3次握手)，用完就会关闭连接(4次挥手)，如果采用连接池则减少了这部分时间损耗，别小看这几次握手，本人经过测试发现，基本上3倍的时间延迟
2、支持更大的并发：如果不采用连接池，每次连接都会打开一个端口，在大并发的情况下系统的端口资源很快就会被用完，导致无法建立新的连接

二、代码
1、HttpConnectionManager.java连接池管理类，支持https协议
@Component
public class HttpConnectionManager {

    PoolingHttpClientConnectionManager cm = null;
    
    @PostConstruct
    public void init() {
        LayeredConnectionSocketFactory sslsf = null;
        try {
            sslsf = new SSLConnectionSocketFactory(SSLContext.getDefault());
        } catch (NoSuchAlgorithmException e) {
            e.printStackTrace();
        }

        
        Registry<ConnectionSocketFactory> socketFactoryRegistry = RegistryBuilder.<ConnectionSocketFactory> create()
                .register("https", sslsf)
                .register("http", new PlainConnectionSocketFactory())
                .build();
        cm =new PoolingHttpClientConnectionManager(socketFactoryRegistry);
        cm.setMaxTotal(200);
        cm.setDefaultMaxPerRoute(20);
    }

    public CloseableHttpClient getHttpClient() {       
        CloseableHttpClient httpClient = HttpClients.custom()
                .setConnectionManager(cm)
                .build();          
        
        /*CloseableHttpClient httpClient = HttpClients.createDefault();//如果不采用连接池就是这种方式获取连接*/
        return httpClient;
    }
}

2、连接池消费类：HaoMaiClient.java

@Component
public class HaoMaiClient {
    @Autowired
    HttpConnectionManager connManager;
    
    public <T> T get(String path,Class<T> clazz){
        CloseableHttpClient httpClient=connManager.getHttpClient();
        HttpGet httpget = new HttpGet(path);
        String json=null;        
        CloseableHttpResponse response=null;
        try {
            response = httpClient.execute(httpget);
            InputStream in=response.getEntity().getContent();
            json=IOUtils.toString(in);
            in.close();
        } catch (UnsupportedOperationException e) {
            e.printStackTrace();
        } catch (IOException e) {
            e.printStackTrace();
        }finally {            
            if(response!=null){
            try {
                response.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
            }            
        }               
        return JSON.parseObject(json, clazz);
    }

}

三、原理及注意事项
连接池中连接都是在发起请求的时候建立，并且都是长连接
HaoMaiClient.java中的in.close();作用就是将用完的连接释放，下次请求可以复用，这里特别注意的是，如果不使用in.close();而仅仅使用response.close();结果就是连接会被关闭，并且不能被复用，这样就失去了采用连接池的意义。
连接池释放连接的时候，并不会直接对TCP连接的状态有任何改变，只是维护了两个Set，leased和avaliabled，leased代表被占用的连接集合，avaliabled代表可用的连接的集合，释放连接的时候仅仅是将连接从leased中remove掉了，并把连接放到avaliabled集合中



14 Redis如何实现扩容？
team中的一个同学在其项目中使用了Redis作为缓存，将热点数据存放在Redis中。为了提升性能，写Redis时采用了管道的方式，平时使用时，Redis的性能、资源使用都能符合项目需求，但当访问量增加的时候，Redis的QPS还能满足要求，但CPU使用率高的时候已经达到90%+，平时只有30%+，而众所周知，Redis是单进程的，只能占用1个CPU核，跑满了也就100%，无法利用机器的多核，而当CPU跑到100%时，必然会造成性能瓶颈。怎么解决？

方案一：
首先想到的是，增加Redis服务器的数量，在客户端对存储的key进行hash运算，存入不同的Redis服务器中，读取时，也进行相同的hash运算，找到对应的Redis服务器，可以解决问题，但是不好的地方：
第一，客户端要改动代码；
第二、需要客户端记住所有的Redis服务器的地址；
这个方案可以使用，但能不能不用改动代码就能实现扩容呢？

方案二：
搭建一个集群，由于Redis服务器使用的版本低于3.0，不支持集群，只能通过使用代理，就想到了有名的Redis代理twemproxy。
twemproxy的性能也是杠杠滴，虽然是代理，但它对访问性能的影响非常小，连Redis作者都推荐它。
twemproxy使用方便，对于一个新手来说，不到一个小时就能学会使用，而且关键是不用改动客户端代码，几乎支持所有的Redis命令和管道操作，只需要改下客户端的配置文件中配置的Redis的IP和PORT，由原来的Redis的IP和Port改成twemproxy服务的IP和PORT。
客户端不需要考虑hash的问题，这些twemproxy会做，客户端就像操作一台Redis一样。
上面用了“几乎”这个词，因为有些命令，比如"keys *"就不支持
很快部署了好了twemproxy和后面跟着的四个Redis机器，压测发现，后面的四台Redis的CPU使用率降下来了，但新问题来了，twemproxy也是单进程的！性能瓶颈又跑到twemproxy上来了！

方案三：
对Redis的访问分为写和读，类似生产者和消费者， 再仔细分析，发现写的少，读的相对多些，这就可以将读写分离，写的往主的写，读的从备的读，遇到的情况恰好是读和写是两个服务，做到读写分离通过改下配置信息就可以很简单的做到，，这样分散了主Redis的压力。
这里对Redis的访问压力有好转，但不是长久之计，比如遇到举办活动， 数据量增大时，还是会有性能的风险。


最终采用的方法是综合方案二和三，如下图所示：

这种方法对现有的服务改动最小，可以有效缓解redis压力的问题
producer端和consumer端的twemproxy使用的hash算法要求一致，不然找不到key了。
如果把方案一也加进来，会比较复杂，暂时用不到。



15 Netty是如何使用线程池的，为什么这么使用？
线程模型是Netty的核心设计，设计地很巧妙，之前项目中有一块处理并发的设计和Netty的Eventloop单线程设计类似，效果得到了实证。
Netty5的类层次结构和之前的版本变化很大，网上也有很多文章写Netty的线程模型，Reactor模式，比如这篇http://blog.csdn.net/xiaolang85/article/details/37873059， 应该是引自《Netty权威指南》，写得比较全面，但是有几个关键的概念没讲清楚。
这篇文章只讲Netty5线程模型最重要的几个关键点
第一个概念是如何理解NioEventLoop和NioEventLoopGroup：NioEventLoop实际上就是工作线程，可以直接理解为一个线程。NioEventLoopGroup是一个线程池，线程池中的线程就是NioEventLoop。Netty设计这几个类的时候，层次结构挺复杂，反而让人迷惑。
还有一个让人迷惑的地方是，创建ServerBootstrap时，要传递两个NioEventLoopGroup线程池，一个叫bossGroup,一个叫workGroup。《Netty权威指南》里只说了bossGroup是用来处理TCP连接请求的，workGroup是来处理IO事件的。
这么说是没错，但是没说清楚bossGroup具体如何处理TCP请求的。实际上bossGroup中有多个NioEventLoop线程，每个NioEventLoop绑定一个端口，也就是说，如果程序只需要监听1个端口的话，bossGroup里面只需要有一个NioEventLoop线程就行了。
在上一篇文章介绍服务器端绑定的过程中，我们看到最后是NioServerSocketChannel封装的Java的ServerSocketChannel执行了绑定，并且执行accept()方法来创建客户端SocketChannel的连接。一个端口只需要一个NioServerSocketChannel即可。


                    EventLoopGroup bossGroup = new NioEventLoopGroup();  
            EventLoopGroup workerGroup = new NioEventLoopGroup();  
            try {  
                ServerBootstrap b = new ServerBootstrap();  
                b.group(bossGroup, workerGroup)  
                        .channel(NioServerSocketChannel.class)  
                        .option(ChannelOption.SO_BACKLOG, 1024)  
                        .childHandler(new ChildChannelHandler());  
                  
                ChannelFuture f = b.bind(port).sync();  
                f.channel().closeFuture().sync();  
            } finally {  
                bossGroup.shutdownGracefully();  
                workerGroup.shutdownGracefully();  
            }  
      
      
        protected MultithreadEventExecutorGroup(int nThreads, Executor executor, Object... args) {  
            if (nThreads <= 0) {  
                throw new IllegalArgumentException(String.format("nThreads: %d (expected: > 0)", nThreads));  
            }  
      
            if (executor == null) {  
                executor = new ThreadPerTaskExecutor(newDefaultThreadFactory());  
            }  
      
            children = new EventExecutor[nThreads];  
            for (int i = 0; i < nThreads; i ++) {  
                boolean success = false;  
                try {  
                    children[i] = newChild(executor, args);  
                    success = true;  
                } catch (Exception e) {  
                    // TODO: Think about if this is a good exception type  
                    throw new IllegalStateException("failed to create a child event loop", e);  
                } finally {  


第二个概念是每个NioEventLoop都绑定了一个Selector，所以在Netty5的线程模型中，是由多个Selecotr在监听IO就绪事件。而Channel注册到Selector。

举个例子，比如有100万个连接连到服务器端。平时的写法可能是1个Selector线程监听所有的IO就绪事件，1个Selector面对100万个连接(Channel)。

而如果使用了1000个NioEventLoop的线程池来说，1000个Selector面对100万个连接，每个Selector只需要关注1000个连接(Channel)

[java] view plaincopy

    public final class NioEventLoop extends SingleThreadEventLoop {  
      
        
        /** 
         * The NIO {@link Selector}. 
         */  
        Selector selector;  
        private SelectedSelectionKeySet selectedKeys;  
      
        private final SelectorProvider provider;  



第三个概念是一个Channel绑定一个NioEventLoop，相当于一个连接绑定一个线程，这个连接所有的ChannelHandler都是在一个线程中执行的，避免的多线程干扰。更重要的是ChannelPipline链表必须严格按照顺序执行的。单线程的设计能够保证ChannelHandler的顺序执行。

[java] view plaincopy

    public interface Channel extends AttributeMap, Comparable<Channel> {  
      
        /** 
         * Return the {@link EventLoop} this {@link Channel} was registered too. 
         */  
        EventLoop eventLoop();  


第四个概念是一个NioEventLoop的selector可以被多个Channel注册，也就是说多个Channel共享一个EventLoop。EventLoop的Selecctor对这些Channel进行检查。

这段代码展示了线程池如何给Channel分配EventLoop,是根据Channel个数取模

[java] view plaincopy

     public EventExecutor next() {  
            return children[Math.abs(childIndex.getAndIncrement() % children.length)];  
        }  
      
    private void processSelectedKeysOptimized(SelectionKey[] selectedKeys) {  
            for (int i = 0;; i ++) {  
                // 逐个处理注册的Channel  
                final SelectionKey k = selectedKeys[i];  
                if (k == null) {  
                    break;  
                }  
      
                final Object a = k.attachment();  
      
                if (a instanceof AbstractNioChannel) {  
                    processSelectedKey(k, (AbstractNioChannel) a);  
                } else {  
                    @SuppressWarnings("unchecked")  
                    NioTask<SelectableChannel> task = (NioTask<SelectableChannel>) a;  
                    processSelectedKey(k, task);  
                }  
      
                if (needsToSelectAgain) {  
                    selectAgain();  
                    // Need to flip the optimized selectedKeys to get the right reference to the array  
                    // and reset the index to -1 which will then set to 0 on the for loop  
                    // to start over again.  
                    //  
                    // See https://github.com/netty/netty/issues/1523  
                    selectedKeys = this.selectedKeys.flip();  
                    i = -1;  
                }  
            }  
        }  

理解了这4个概念之后就对Netty5的线程模型有了清楚的认识：
在监听一个端口的情况下，一个NioEventLoop通过一个NioServerSocketChannel监听端口，处理TCP连接。后端多个工作线程NioEventLoop处理IO事件。每个Channel绑定一个NioEventLoop线程，1个NioEventLoop线程关联一个selector来为多个注册到它的Channel监听IO就绪事件。NioEventLoop是单线程执行，保证Channel的pipline在单线程中执行，保证了ChannelHandler的执行顺序。






16 介绍Spring的IOC容器初始化过程？
Ioc容器的初始化是由refresh（）方法来启动的，这个方法标志着Ioc容器的正式启动。
具体来说这个启动过程包括三个基本过程：
1.BeanDifinition的Resource定位
2.BeanDifinition的载入与解析
3.BeanDifinition在Ioc容器中的注册
需要注意的是，Spring把这三个过程分开，并使用不同的模块来完成，如使用相应的ResourceLoader、BeanDifinitionReader等模块，通过这样的实际方式，可以让用户更加灵活的对这三个过程进行剪裁和扩展。
定义出最适合自己的Ioc容器的初始化过程。

第一个过程：BeanDifinition的Resource定位
这个Resource定位指的是BeanDifinition的资源定位，它由ResourceLoader通过统一的Resource接口来完成，这个Resource对各种形式的BeanDifinition的使用都提供了统一的接口。
对于这些BeanDifinition的存在形式，相信大家都不会感到陌生。比如，
在文件系统中的Bean定义信息可以使用FileSystemResource来进行抽象。
在类路劲中的Bean定义信息可以使用ClassPathResource。
这个定位过程类似于容器寻找数据的过程，就想水桶装水先要把水找到一样。

第二个过程：BeanDifinition的载入
这个载入过程是把用户定义好的Bean表示成Ioc容器内部的数据结构，而这个容器内部的数据结构就是BeanDifinition。具体来说，BeanDifinition实际上就是POJO对象在IOC容器中的抽象，通过这个BeanDifinition定义的数据结构，使IOC容器能够方便的对POJO对象也就是Bean进行管理。

第三个过程：BeanDifinition的注册
这个操作是通过调用BeanDifinitionRegistry借口来实现的。这个注册过程把载入过程中解析得到的BeanDifinition向Ioc容器进行注册。在阅读源码中可知，在IOC容器内部将BeanDifinition注入到一个HashMap中去，Ioc容器就是通过这个HashMap来持有这些BeanDifinition数据的。
这里说到的Ioc容器的初始化过程，一般不包含Bean依赖注入的实现。在Ioc的设计中，Bean定义的载入和依赖注入是俩个独立的过程。依赖注入一般发生在应用第一次通过getBean向容器索取Bean的时候。（使用预实例化的配置除外）


17 Spring的IOC容器实现原理，为什么可以通过byName和ByType找到Bean？
1. IoC理论的背景
我们都知道，在采用面向对象方法设计的软件系统中，它的底层实现都是由N个对象组成的，所有的对象通过彼此的合作，最终实现系统的业务逻辑。

图1：软件系统中耦合的对象
如果我们打开机械式手表的后盖，就会看到与上面类似的情形，各个齿轮分别带动时针、分针和秒针顺时针旋转，从而在表盘上产生正确的时间。图1中描述的就是这样的一个齿轮组，它拥有多个独立的齿轮，这些齿轮相互啮合在一起，协同工作，共同完成某项任务。我们可以看到，在这样的齿轮组中，如果有一个齿轮出了问题，就可能会影响到整个齿轮组的正常运转。
齿轮组中齿轮之间的啮合关系,与软件系统中对象之间的耦合关系非常相似。对象之间的耦合关系是无法避免的，也是必要的，这是协同工作的基础。现在，伴随着工业级应用的规模越来越庞大，对象之间的依赖关系也越来越复杂，经常会出现对象之间的多重依赖性关系，因此，架构师和设计师对于系统的分析和设计，将面临更大的挑战。对象之间耦合度过高的系统，必然会出现牵一发而动全身的情形。

图2：对象之间复杂的依赖关系
耦合关系不仅会出现在对象与对象之间，也会出现在软件系统的各模块之间，以及软件系统和硬件系统之间。如何降低系统之间、模块之间和对象之间的耦合度，是软件工程永远追求的目标之一。为了解决对象之间的耦合度过高的问题，软件专家Michael Mattson提出了IOC理论，用来实现对象之间的“解耦”，目前这个理论已经被成功地应用到实践当中，很多的J2EE项目均采用了IOC框架产品Spring。
2. 什么是控制反转(IoC)
IOC是Inversion of Control的缩写，多数书籍翻译成“控制反转”，还有些书籍翻译成为“控制反向”或者“控制倒置”。
1996年，Michael Mattson在一篇有关探讨面向对象框架的文章中，首先提出了IOC 这个概念。对于面向对象设计及编程的基本思想，前面我们已经讲了很多了，不再赘述，简单来说就是把复杂系统分解成相互合作的对象，这些对象类通过封装以后，内部实现对外部是透明的，从而降低了解决问题的复杂度，而且可以灵活地被重用和扩展。IOC理论提出的观点大体是这样的：借助于“第三方”实现具有依赖关系的对象之间的解耦，如下图：

图3：IOC解耦过程
大家看到了吧，由于引进了中间位置的“第三方”，也就是IOC容器，使得A、B、C、D这4个对象没有了耦合关系，齿轮之间的传动全部依靠“第三方”了，全部对象的控制权全部上缴给“第三方”IOC容器，所以，IOC容器成了整个系统的关键核心，它起到了一种类似“粘合剂”的作用，把系统中的所有对象粘合在一起发挥作用，如果没有这个“粘合剂”，对象与对象之间会彼此失去联系，这就是有人把IOC容器比喻成“粘合剂”的由来。
我们再来做个试验：把上图中间的IOC容器拿掉，然后再来看看这套系统：

图4：拿掉IoC容器后的系统
我们现在看到的画面，就是我们要实现整个系统所需要完成的全部内容。这时候，A、B、C、D这4个对象之间已经没有了耦合关系，彼此毫无联系，这样的话，当你在实现A的时候，根本无须再去考虑B、C和D了，对象之间的依赖关系已经降低到了最低程度。所以，如果真能实现IOC容器，对于系统开发而言，这将是一件多么美好的事情，参与开发的每一成员只要实现自己的类就可以了，跟别人没有任何关系！
我们再来看看，控制反转(IOC)到底为什么要起这么个名字？我们来对比一下：
软件系统在没有引入IOC容器之前，如图1所示，对象A依赖于对象B，那么对象A在初始化或者运行到某一点的时候，自己必须主动去创建对象B或者使用已经创建的对象B。无论是创建还是使用对象B，控制权都在自己手上。
软件系统在引入IOC容器之后，这种情形就完全改变了，如图3所示，由于IOC容器的加入，对象A与对象B之间失去了直接联系，所以，当对象A运行到需要对象B的时候，IOC容器会主动创建一个对象B注入到对象A需要的地方。
通过前后的对比，我们不难看出来：对象A获得依赖对象B的过程,由主动行为变为了被动行为，控制权颠倒过来了，这就是“控制反转”这个名称的由来。
3.  IOC的别名：依赖注入(DI)
2004年，Martin Fowler探讨了同一个问题，既然IOC是控制反转，那么到底是“哪些方面的控制被反转了呢？”，经过详细地分析和论证后，他得出了答案：“获得依赖对象的过程被反转了”。控制被反转之后，获得依赖对象的过程由自身管理变为了由IOC容器主动注入。于是，他给“控制反转”取了一个更合适的名字叫做“依赖注入（Dependency Injection）”。他的这个答案，实际上给出了实现IOC的方法：注入。所谓依赖注入，就是由IOC容器在运行期间，动态地将某种依赖关系注入到对象之中。
所以，依赖注入(DI)和控制反转(IOC)是从不同的角度的描述的同一件事情，就是指通过引入IOC容器，利用依赖关系注入的方式，实现对象之间的解耦。
我们举一个生活中的例子，来帮助理解依赖注入的过程。大家对USB接口和USB设备应该都很熟悉吧，USB为我们使用电脑提供了很大的方便，现在有很多的外部设备都支持USB接口。

图5：USB接口和USB设备
现在，我们利用电脑主机和USB接口来实现一个任务：从外部USB设备读取一个文件。
电脑主机读取文件的时候，它一点也不会关心USB接口上连接的是什么外部设备，而且它确实也无须知道。它的任务就是读取USB接口，挂接的外部设备只要符合USB接口标准即可。所以，如果我给电脑主机连接上一个U盘，那么主机就从U盘上读取文件；如果我给电脑主机连接上一个外置硬盘，那么电脑主机就从外置硬盘上读取文件。挂接外部设备的权力由我作主，即控制权归我，至于USB接口挂接的是什么设备，电脑主机是决定不了，它只能被动的接受。电脑主机需要外部设备的时候，根本不用它告诉我，我就会主动帮它挂上它想要的外部设备，你看我的服务是多么的到位。这就是我们生活中常见的一个依赖注入的例子。在这个过程中，我就起到了IOC容器的作用。
通过这个例子,依赖注入的思路已经非常清楚：当电脑主机读取文件的时候，我就把它所要依赖的外部设备，帮他挂接上。整个外部设备注入的过程和一个被依赖的对象在系统运行时被注入另外一个对象内部的过程完全一样。
我们把依赖注入应用到软件系统中，再来描述一下这个过程：
对象A依赖于对象B,当对象 A需要用到对象B的时候，IOC容器就会立即创建一个对象B送给对象A。IOC容器就是一个对象制造工厂，你需要什么，它会给你送去，你直接使用就行了，而再也不用去关心你所用的东西是如何制成的，也不用关心最后是怎么被销毁的，这一切全部由IOC容器包办。
在传统的实现中，由程序内部代码来控制组件之间的关系。我们经常使用new关键字来实现两个组件之间关系的组合，这种实现方式会造成组件之间耦合。IOC很好地解决了该问题，它将实现组件间关系从程序内部提到外部容器，也就是说由容器在运行期将组件间的某种依赖关系动态注入组件中。
4.  IOC为我们带来了什么好处
我们还是从USB的例子说起，使用USB外部设备比使用内置硬盘，到底带来什么好处？
第一、USB设备作为电脑主机的外部设备，在插入主机之前，与电脑主机没有任何的关系，只有被我们连接在一起之后，两者才发生联系，具有相关性。所以，无论两者中的任何一方出现什么的问题，都不会影响另一方的运行。这种特性体现在软件工程中，就是可维护性比较好，非常便于进行单元测试，便于调试程序和诊断故障。代码中的每一个Class都可以单独测试，彼此之间互不影响，只要保证自身的功能无误即可，这就是组件之间低耦合或者无耦合带来的好处。
第二、USB设备和电脑主机的之间无关性，还带来了另外一个好处，生产USB设备的厂商和生产电脑主机的厂商完全可以是互不相干的人，各干各事，他们之间唯一需要遵守的就是USB接口标准。这种特性体现在软件开发过程中，好处可是太大了。每个开发团队的成员都只需要关心实现自身的业务逻辑，完全不用去关心其它的人工作进展，因为你的任务跟别人没有任何关系，你的任务可以单独测试，你的任务也不用依赖于别人的组件，再也不用扯不清责任了。所以，在一个大中型项目中，团队成员分工明确、责任明晰，很容易将一个大的任务划分为细小的任务，开发效率和产品质量必将得到大幅度的提高。
第三、同一个USB外部设备可以插接到任何支持USB的设备，可以插接到电脑主机，也可以插接到DV机，USB外部设备可以被反复利用。在软件工程中，这种特性就是可复用性好，我们可以把具有普遍性的常用组件独立出来，反复利用到项目中的其它部分，或者是其它项目，当然这也是面向对象的基本特征。显然，IOC不仅更好地贯彻了这个原则，提高了模块的可复用性。符合接口标准的实现，都可以插接到支持此标准的模块中。
第四、同USB外部设备一样，模块具有热插拔特性。IOC生成对象的方式转为外置方式，也就是把对象生成放在配置文件里进行定义，这样，当我们更换一个实现子类将会变得很简单，只要修改配置文件就可以了，完全具有热插拨的特性。
以上几点好处，难道还不足以打动我们，让我们在项目开发过程中使用IOC框架吗？
5.  IOC容器的技术剖析
IOC中最基本的技术就是“反射(Reflection)”编程，目前.Net C#、Java和PHP5等语言均支持，其中PHP5的技术书籍中，有时候也被翻译成“映射”。有关反射的概念和用法，大家应该都很清楚，通俗来讲就是根据给出的类名（字符串方式）来动态地生成对象。这种编程方式可以让对象在生成时才决定到底是哪一种对象。反射的应用是很广泛的，很多的成熟的框架，比如象Java中的Hibernate、Spring框架，.Net中 NHibernate、Spring.Net框架都是把“反射”做为最基本的技术手段。
反射技术其实很早就出现了，但一直被忽略，没有被进一步的利用。当时的反射编程方式相对于正常的对象生成方式要慢至少得10倍。现在的反射技术经过改良优化，已经非常成熟，反射方式生成对象和通常对象生成方式，速度已经相差不大了，大约为1-2倍的差距。
我们可以把IOC容器的工作模式看做是工厂模式的升华，可以把IOC容器看作是一个工厂，这个工厂里要生产的对象都在配置文件中给出定义，然后利用编程语言的的反射编程，根据配置文件中给出的类名生成相应的对象。从实现来看，IOC是把以前在工厂方法里写死的对象生成代码，改变为由配置文件来定义，也就是把工厂和对象生成这两者独立分隔开来，目的就是提高灵活性和可维护性。
6.  IOC容器的一些产品
Sun ONE技术体系下的IOC容器有：轻量级的有Spring、Guice、Pico Container、Avalon、HiveMind；重量级的有EJB；不轻不重的有JBoss，Jdon等等。Spring框架作为Java开发中SSH(Struts、Spring、Hibernate)三剑客之一，大中小项目中都有使用，非常成熟，应用广泛，EJB在关键性的工业级项目中也被使用，比如某些电信业务。
.Net技术体系下的IOC容器有：Spring.Net、Castle等等。Spring.Net是从Java的Spring移植过来的IOC容器，Castle的IOC容器就是Windsor部分。它们均是轻量级的框架，比较成熟，其中Spring.Net已经被逐渐应用于各种项目中。
7. 使用IOC框架应该注意什么
使用IOC框架产品能够给我们的开发过程带来很大的好处，但是也要充分认识引入IOC框架的缺点，做到心中有数，杜绝滥用框架。
第一、软件系统中由于引入了第三方IOC容器，生成对象的步骤变得有些复杂，本来是两者之间的事情，又凭空多出一道手续，所以，我们在刚开始使用IOC框架的时候，会感觉系统变得不太直观。所以，引入了一个全新的框架，就会增加团队成员学习和认识的培训成本，并且在以后的运行维护中，还得让新加入者具备同样的知识体系。
第二、由于IOC容器生成对象是通过反射方式，在运行效率上有一定的损耗。如果你要追求运行效率的话，就必须对此进行权衡。
第三、具体到IOC框架产品(比如：Spring)来讲，需要进行大量的配制工作，比较繁琐，对于一些小的项目而言，客观上也可能加大一些工作成本。
第四、IOC框架产品本身的成熟度需要进行评估，如果引入一个不成熟的IOC框架产品，那么会影响到整个项目，所以这也是一个隐性的风险。
我们大体可以得出这样的结论：一些工作量不大的项目或者产品，不太适合使用IOC框架产品。另外，如果团队成员的知识能力欠缺，对于IOC框架产品缺乏深入的理解，也不要贸然引入。最后，特别强调运行效率的项目或者产品，也不太适合引入IOC框架产品，象WEB2.0网站就是这种情况


1.首先，区分清楚什么是byType，什么是byName。
<bean id="userServiceImpl" class="cn.com.bochy.service.impl.UserServiceImpl" autowire="byName">
</bean>  
<bean id="userDao" class="cn.com.bochy.dao.impl.UserDaoImpl">
</bean>
比如说如上这段代码，byName就是通过Bean的id或者name，byType就是按Bean的Class的类型。
若autowire="byType"意思是通过 class="cn.com.bochy.dao.impl.UserDaoImpl"来查找UserDaoImpl下所有的对象。
代码autowire="byName"意思是通过id="userDao"来查找Bean中的userDao对象
建议看 《Spring in Action》 第三章第一节，“自动装配 Bean 属性”
在spring中@Autowired注入规则：
1.@Autowired默认是按照byType进行注入的 
二.spring注入的基本语法如下：
xml中语法如下：<bean id="beanId" class="包名.类名">
如果是属性注入，需要为每一个依赖类创建相应的getter和setter方法。
如果是构造方法注入，需要为依赖类创建相应的构造方法。
属性注入的语法如下：
<bean id="被注入的类的beanId" class="包名.类名" />
<bean id="beanId" class="包名.类名">
<property name="被注入的bean的名字" ref="被注入的类的beanId"></property>
</bean>
如例子：
<bean id="userService" class="com.uni2uni.spring.service.impl.UserService"><property name="userDao" ref="userDao"></property></bean>
<bean id="userDao" class="com.uni2uni.spring.dao.impl.UserDao" />
因为UserService依赖于UserDao，因此需要在userService中创建相应的getter和setter方法。





18 消息中间件是如何实现的，技术难点有哪些？
以分布对象技术为基础，不仅能够支持应用集成框架的建立，满足协同工作的需求，而且建立了多层次的软构件框架，更加分布对象中间件便于应用领域框架及领域构件的开发。它也支持以构件形式实现集成平台的系统管理和公共服务，使系统具有良好的开放性和扩展性。基于CORBA标准的对分布对象的透明访问，允许应用对远程对象和本地对象使用相同的访问模式，从而屏蔽了操作系统平台和通信机制，使应用开发者更加关注于应用逻辑的开发。


19 如何搭建一个高可用系统？
今天又温习了一下《分布式java应用》，好多名词看了都知道，但记不住，是不习惯记这些不易理解的专业术语呀。因为和客户说的时候他肯定不懂。但和懂技术的客户或者专家进行沟通的时候都是用这些专业术语，这时候我知道但往往想不起来，看来老了啊。看来以后还得记些，不然显得本架构师不专业呀。
好了，言归正传，如何构建高可用的系统呢？
首先什么是高可用？“高可用性”（High Availability）通常来描述一个系统经过专门的设计，从而减少停工时间，而保持其服务的高度可用性。
 
1.ha
    1.1避免单点
        。负载均衡技术
        。热备
        。使用多机房
    1.2提高应用可用性
        1.2.1尽可能的避免故障
        1.2.2及时发现故障
              。报警系统
              。日志记录和分析系统
         1.2.3访问量和数据量不断上涨的应对策略
              。水平伸缩
              。拆分--1.应用拆分；2.拆分数据库；拆分表。
              。读写分离
              。垂直伸缩
              。其他
 
以上高级知识点看了两遍觉得还是得继续修炼，毕竟实战经验很少。
------------------------------------------------------------------------
计算机系统的可靠性用平均无故障时间(MTTF)来度量，即计算机系统平均能够正常运行多长时间，才会发生一次故障。系统的可靠性能越高，平均无故障时间越长。可维护性用平均维修时间(MTTR)来度量，即系统发生故障后维修和重新恢复正常运行平均花费时间。系统的可维护性越好，平均维修时间越短。计算机系统的可用性定义为：MTTF/(MTTF+MTTR)*100%。
举例来说，淘宝网在2010年成交额为300亿，则每分钟成交额为5—10万，那么对淘宝来说，其后台系统的高可用，对企业运营非常重要。淘宝数据负责人宁海元指出，淘宝系统，可用性至少需要99.999%。那么对于taobao.com系统，在一年365天，系统停止服务时间为5分15秒。
高可用性的衡量指标
可用性的计算公式： 　　%availability=（Total Elapsed Time－Sum of Inoperative Times）/ Total Elapsed Time 　
　elapsed time为operating time+downtime。
TotalElapsed Time 为系统总时间，包括可提供服务时间+停止服务时间。
Sumof Inoperative Times 为停止服务时间，包括宕机时间+维护时间。 　　
可用性和系统组件的失败率相关。衡量系统设备失败率的一个指标是“失败间隔平均时间”MTBF（mean time between failures）。
通常这个指标衡量系统的组件，如磁盘。
　　MTBF=Total Operating Time / Total No. of Failures 　　
Operating time为系统在使用的时间（不包含停机情况）。
高可用性系统的设计
计系统的可用性，最重要的是满足用户的需求。系统的失败只有当其导致服务的失效性足以影响到系统用户的需求时才会影响其可用性的指标。用户的敏感性决定于系统提供的应用。例如，在一个能在1秒钟之内被修复的失败在一些联机事务处理系统中并不会被感知到，但如果是对于一个实时的科学计算应用系统，则是不可被接受的。
　　系统的高可用性设计决定于您的应用。例如，如果几个小时的计划停机时间是可接受的，也许存储系统就不用设计为磁盘可热插拔的。反之，你可能就应该采用可热插拔、热交换和镜像的磁盘系统。
　　所以涉及高可用系统需要考虑：
　　决定业务中断的持续时间。根据公式计算出的衡量HA的指标，可以得到一段时间内可以中断的时间。但可能很大量的短时间中断是可以忍受的，而少量长时间的中断却是不可忍受的。
　　在统计中表明，造成非计划的宕机因素并非都是硬件问题。硬件问题只占40%，软件问题占30%，人为因素占20%，环境因素占10%。您的高可用性系统应该能尽可能地考虑到上述所有因素。
　　当出现业务中断时，尽快恢复的手段。
导致计划内的停机因素有：
　　周期性的备份
　　软件升级
　　硬件扩充或维修
　　系统配置更改
　　数据更改
导致计划外停机的因素有：
　　硬件失败
　　文件系统满错误
　　内存溢出
　　备份失败
　　磁盘满
　　供电失败
　　网络失败
　　应用失败
　　自然灾害
　　操作或管理失误
　　通过有针对性的设计，可以避免上述全部或部分因素带来的损失。当然，100%的高可用系统是不存在的。
创建高可用性的计算机系统
在UNIX系统上创建高可用性计算机系统，业界的通行做法，也是非常有效的做法，就是采用群集系统（Cluster），将各个主机系统通过网络或其他手段有机地组成一个群体，共同对外提供服务。创建群集系统，通过实现高可用性的软件将冗余的高可用性的硬件组件和软件组件组合起来，消除单点故障：
　　消除供电的单点故障
　　消除磁盘的单点故障
　　消除SPU（System Process Unit）单点故障
　　消除网络单点故障
　　消除软件单点故障
　　尽量消除单系统运行时的单点故障
---------------------------------------------------
 1.2.1如何确保高可用（转载）
可用性越高越好，提高可用性主要从一下几个方面入手：
(1)系统架构
(2)容灾性
(3)监控报警
(4)故障转移
1.2.1.1 系统架构
系统架构，指整个网站后台系统的架构。好的系统架构，主要从下面几个方面考虑：
(1)操作系统的选择，从稳定性、安全性和可维护性考虑，unix和linux性能远远好于windows，从成本考虑，Linux远远低于windows 和unix。
(2)负载均衡器的选择，硬件负载均衡器性能和稳定性高于软件负载均衡器。但成本上，软件比如haproxy、LVS优于硬件(比如F5、Netscaler)。
(3)web server的选择，Nginx优于传统的Apache。
(4)各级缓存的选择与应用，varnish、squid、memcached。
(5)网站开发语言的选择，与开发有关，www.linuxidc.com主要分为需要编译性的语言和不需要编译性的语言。
(6)数据库的选择，传统的关系数据库中，Oracle优于MySQL，但Oracle收费远远高于MySQL，实际上，Oracle有两种收费模式，一种是按用户数，一种是按主机处理器个数。而MySQL有免费的版本。
(7)底层存储设备的选择，比如机械磁盘和固态硬盘的选择。
(8)避免单点故障问题，在逻辑架构上，避免单点故障，避免出现割点。
1.2.1.2 容灾性
容灾性能对系统非常重要，比如服务器因为断电，导致数据文件的不一致，因为发生自然或者非自然灾害比如火灾导致的磁盘损坏，发生数据丢失等。所以容灾很重要，主要从以下几个方面提高容灾性能：
(1)服务器热备机的部署，当发生故障后，热备机能马上使用，提供服务。这里的服务器主要指web server 、应用服务器、数据库服务器等。
(2) 数据备份，比如做定期备份、热备份、增量备份，甚至需要做主从备份，来提高抗灾性能。并且从底层存储设备上进行备份，比如做RAID。
(3) 做双线网络交换，尽量优化设计网络，避免因为核心交换机故障，而影响服务。网络上避免单点故障。
1.2.1.3 监控报警
监控是指对在线服务和非服务的在线服务器和相应的进程进行状态检测，当出现宕机或者某项服务进程僵死之后，能够在尽量短的时间获得该信息，然后通过报警系统将信息发送到一线运维人员。所以，监控报警，直接影响宕机时间。监控报警，主要从以下几个方面展开：
(1)  监控主机CPU使用情况，负载情况。
(2)  监控主机内存使用情况。 
(3)  监控主机IO外设，主要以磁盘为主。如磁盘的读写、磁盘使用量等。
(4)  监控主机网卡使用情况。网卡是否损坏，是否招到DDOS攻击。
(5)  监控应用进程，包括web server ，应用服务器等。
(6)  监控数据库使用情况。包括用户的请求数、缓存使用量等。
(7)  监控交换设备的使用情况。网络入、出的流量。
(8)  监控IDC机房温度、湿度等。
(9)  防火墙、入侵检测等安全检测、监控等。
通过上面的各项监控、得到相应数值，应用监控绘图软件，把相应的数值绘画出来，现有监控绘图软件有mrtg、cacti、nagios等。然后设置一个报警阈值，如果超过该阈值，那么通过报警系统，www.linuxidc.com比如短信、msn、邮件、甚至是声音完成报警功能。典型的报警系统如图3-2-1-3所示。

                                            图3-2-1-3
如图3-2-1-3所示，监控服务器从servers上收集系统信息，如果发现系统的某项状态指数超过预设的阈值，则发送邮件到运维人员。同时，把相应的报警信息发送到短信运营商的短信网关服务器，然后短信网关服务器发送短信到运维人员手机中，完成短信报警。上述报警过程，传送邮件报警信息，是基于TCP/IP协议，而传送短信报警信息，是基于gprs网络。
1.2.1.4 故障转移
故障转移是指，当对用户提供服务的服务器或者相应的应用进程发生故障后，比如服务器宕机、进程僵死之后，备用服务器能够在尽量短的时间内启用，提供服务。这样能够最大限度减少损失，保证用户的正常服务。所以，做好故障转移，要解决以下两个问题：
(1)  实时监测故障问题。
(2)  准确快速切换服务器问题。 
针对不同层次的服务，监测机制也不同，详细情况，在3.2.1.3已经阐述。下面主要论述一下故障切换问题。
故障切换包括负载均衡器的故障切换、主机os的故障切换、web server的故障切换、应用进程的故障切换、数据库的故障切换、存储系统的故障切换、DNS的故障切换、交换设备的故障切换等。下面主要分析进程僵死的故障转移和服务器宕机的故障转移。
进程僵死故障转移案例，常见的web server僵死故障转移如图3-2-1-4所示。

如图3-2-1-4-1所示，当主机172.29.141.112的web server 对外提供服务时，通过在主机172.29.141.113上部署监控程序Monitor_nginx.sh来监控主机172.29.141.112上面的web server进程运行情况，一旦发现172.29.141.112上web server停止服务，马上报警，先更改172.29.141.113的ip地址为172.29.141.112，再启用其自身的web server,完成故障转移。此外，也可以在两服务器上同时部署监控程序Monitor_nginx.sh，完成互相监控。
服务器宕机故障转移案例，常见的服务器宕机故障转移，如图3-2-1-4-2所示。

   图3-2-1-4-2
如图3-2-1-4-2所示，服务器A和服务器B同时部署，但服务器A提供服务，而服务器B作为热备机。监控系统单独部署。当服务器A宕机之后，监控系统会检测到这一信息，然后通过浮动更改服务器B的ip地址，完成故障切换。
1.3 本文小结
本文主要阐述了网站后台系统的高可用性，分析了高可用性的定义和应用需求，重点阐述了如何做到高可用。通过从不同应用级别，如主机、存储、网络、外设、数据库、安全等各个级别进行分析，最后详细论述了web server的故障转移和主机系统的故障转移。





20 哪些设计模式可以增加系统的可扩展性？
1、Load Balancer 
该模式中，一个分发器基于某种策略确定由哪个worker实例处理请求。应用最好是无状态的，以使任何一个worker实例都能同等处理请求。大量的网站都会用到负载均衡器这个模式的。

 

2、Scatter and Gather
该模式中，分发器将请求转发给多个worker实例，每个worker实例处理完返回给分发器，分发器将worker们返回的结果再加工后再返回给客户端。以搜索为例，通常得AS、BS架构就是这种典型模式。

 
 

3、Result Cache
承接上个模式，这个模式只是在分发器处理时加了一步查询结果缓存，这都能算是模式！

 

4、Shared Space
这个模式还有个更广泛的名字–“黑板模式”。实现来说，就是在处理流程中，存在一个全局传递的对象，它可能包含了请求参数、中间状态、响应结果等各种信息，供流程中的各个组件对其进行操作。在一些web框架和应用框架中，都可见这个模式的使用。

 

5、Pipe and Filter
这个模式又以“面向数据流编程”知名，是很通用的企业集成模式。

 

6、Map Reduce
因为google和hadoop，这个模式几乎都了解些，尽管多数人都没亲身应用过。

 7、Bulk Synchronous Parellel
该模型基于一个master协调，所有的worker同步（lock-step）执行。
该模式被用于Google Pregel Graph Processing  google-pregel-graph-processing 和Hama。
 

 

8、Execution Orchestrator
又一个不很了解的模式，似乎是一个和map reduce有一拼的分布式计算模型，似乎是微软的创造：Microsoft’s Dryad project。



21 介绍设计模式，如模板，命令，策略，适配器、桥接、装饰，观察者，状态，访问者？
创建型模式共5种：
工厂模式（Factory Pattern）
抽象工厂模式（Abstract Factory Pattern）
单例模式（Singleton Pattern）
建造者模式（Builder Pattern）
原型模式（Prototype Pattern）

结构型模式共8种：
适配器模式（Adapter Pattern）
桥接模式（Bridge Pattern）
过滤器模式（Filter、Criteria Pattern）
组合模式（Composite Pattern）
装饰器模式（Decorator Pattern）
外观模式（Facade Pattern）
享元模式（Flyweight Pattern）
代理模式（Proxy Pattern）。

行为型模式共12种：
责任链模式（Chain of Responsibility Pattern）
命令模式（Command Pattern）
解释器模式（Interpreter Pattern）
迭代器模式（Iterator Pattern）
中介者模式（Mediator Pattern）
备忘录模式（Memento Pattern）
观察者模式（Observer Pattern）
状态模式（State Pattern）
空对象模式（Null Object Pattern）
策略模式（Strategy Pattern）
模板模式（Template Pattern）
访问者模式（Visitor Pattern）

JAVA EE型模式共8种：
MVC 模式（MVC Pattern）
业务代表模式（Business Delegate Pattern）
组合实体模式（Composite Entity Pattern）
数据访问对象模式（Data Access Object Pattern）
前端控制器模式（Front Controller Pattern）
拦截过滤器模式（Intercepting Filter Pattern）
服务定位器模式（Service Locator Pattern）
传输对象模式（Transfer Object Pattern）

22 怎么提高研发效率？


23 什么是高内聚低耦合，请举例子如何实现？
高内聚就是说相关度比较高的部分尽可能的集中，不要分散
低耦合就是说两个相关的模块尽可以能把依赖的部分降低到最小，不要让两个系统产生强依赖。
例子：
比如订单系统，订单是跟库存息息相关的，没有库存就没有订单，订单强依赖库存
如果我们把如何扣减库存的逻辑做在订单系统中，那么订单系统和库存系统就耦合了
同样，订单系统中有扣减库存的逻辑会造成订单系统的功能比较分散，订单系统的功能就不够集中。
所以我们把订单中的库存逻辑给拆分出来一个独立的库存系统，对外暴露扣减库存的接口，订单系统可以通过这个暴露的库存接口来扣减库存
将订单逻辑与库存逻辑的依赖降低到最小，减掉了订单系统与库存的耦合
同事订单系统只包含订单处理的逻辑，库存系统只包含了库存的处理逻辑，两个系统的业务上更加内聚。


24 什么情况用接口，什么情况用消息？
抽象类：只有一个或几个方法需要定义成抽象方法，从而让子类来实现；其他方法有清晰、明确、共同的逻辑需要在本类中实现，由子类“共享”和“复用”。
接口：纯粹定义方法接口，所有方法都由实现该接口的类来实现。没有共享的公共逻辑，此时用接口比较合适。
消息：一个信息包含两个因素：消息描述（用于定义诸如消息传输目标等）和数据信息（如应用程序数据或数据库查询等）。程序之间的通讯通过传递消息而非直接调用程序。如简单对象访问协议（SOAP）、电子数据交换（EDI）、C、COBOL和XML都是常见的消息类型实现。
队列：一个安全的信息存储区。因为消息存放在队列中，所以应用程序可以相互独立的运行，以不同的速度，在不同的时间，在不同的地点。
消息传输系统：用于确保队列之间的信息提供，包括网络中不同系统上的的远程队列之间的信息提供。并保证网络故障或关闭后的恢复。
应用程序接口：应用程序和消息系统之间通过WebSphere MQ API实现交互操作的接口。WebSphere MQ API在所有WebSphere MQ平台上是一致的。API只有十几个调用，2个关键动词：发送（PUT）和接收（GET）。
发布/订阅模式进一步提升了消息队列的扩展性灵活性，双方无需关注具体发送单位、接收单位，只需要关注主题级即可


25 如果AB两个系统互相依赖，如何解除依赖？
spring IOC 模式，降低耦合性，中介者模式  


26 如何写一篇设计文档，目录是什么？
需求、分析设计
1.需求
1.1 项目背景
1.2 需求描述
2.分析设计
2.1 需求分析
三件事：
1. 了解用户的需求，并用软件工程师的语言描述出来。
2. 让用户了解我们能做出来的是什么。
3. 提出合理化的建议。
2.2 模块划分
模块划分的目的：
1 分类后的功能是比较清晰；
2  分类后可以对开发进行计划起指导作用；
3  分类后有利于面向对象的分析与设计；
模块分类的方式：
1  按角色分 ；按角色分类结果决定了界面操作：
2  按功能分；按功能分类结果决定了操作类内容
3  按信息分；按信息分决定了数据库架构
2.3 概要设计
面向对象的概要设计目的有以下几点：
以需求分析为基础，形成程序的功能流程。
以功能流程为基础，设计流程中传递的数据。
设计类与包，用于实现功能。
那么，如何完成概要设计，实现概要设计的目的呢？首先要从需求分析入手。在需求分
析阶段分析出了所有的功能，然后划分模块。其中有一种模块中按信息来划分的，方便我们
找出系统中数据，也就是数据库架构。

27 什么场景应该拆分系统，什么场景应该合并系统？
拆分系统：
当系统通过集群的方式已经无法解决性能问题的时候，或者业务扩展到很大的时候，需要把拆分系统
按照业务的方式垂直拆分：将业务功能结合比较紧密的部分拆分成独立的系统，独立维护
按照性能瓶颈点拆分：将系统性能瓶颈点拆分出一个独立的系统，可以针对这个独立的系统集群部署，增加可伸缩性，提高系统整体的性能

合并系统：
或者系统间通过跨进程访问的性能损耗过高，可以将系统合并成一个系统，减少跨进程访问的消耗

28 系统和模块的区别，分别在什么场景下使用？
系统是一个完整功能的系统，拥有独立的访问方式，和部署方式，拥有完整的生命周期，系统由模块组成
模块是系统的组成部分，不能单独工作，需要依附于系统才能发挥作用，通常是解决一定场景下的问题


29 分布式锁的实现方式有哪几种？
在进行大型网站技术架构设计以及业务实现的过程中，多少都会遇到需要使用分布式锁的情况。那么问题也就接踵而至。分布式锁zk和memcached以及redis三者都能实现，同样是分布式锁，三者的区别何在？各自适用什么场景？
一、Zookeeper
1、实现原理：
基于zookeeper瞬时有序节点实现的分布式锁，其主要逻辑如下（该图来自于IBM网站）。大致思想即为：每个客户端对某个功能加锁时，在zookeeper上的与该功能对应的指定节点的目录下，生成一个唯一的瞬时有序节点。判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。
2、优点
锁安全性高，zk可持久化，且能实时监听获取锁的客户端状态。一旦客户端宕机，则瞬时节点随之消失，zk因而能第一时间释放锁。这也省去了用分布式缓存实现锁的过程中需要加入超时时间判断的这一逻辑。
3、缺点
性能开销比较高。因为其需要动态产生、销毁瞬时节点来实现锁功能。所以不太适合直接提供给高并发的场景使用。
4、实现
可以直接采用zookeeper第三方库curator即可方便地实现分布式锁。
5、适用场景
对可靠性要求非常高，且并发程度不高的场景下使用。如核心数据的定时全量/增量同步等。

二、memcached分布式锁
1、实现原理
memcached带有add函数，利用add函数的特性即可实现分布式锁。add和set的区别在于：如果多线程并发set，则每个set都会成功，但最后存储的值以最后的set的线程为准。而add的话则相反，add会添加第一个到达的值，并返回true，后续的添加则都会返回false。利用该点即可很轻松地实现分布式锁。
2、优点
并发高效
3、缺点
memcached采用列入LRU置换策略，所以如果内存不够，可能导致缓存中的锁信息丢失。
memcached无法持久化，一旦重启，将导致信息丢失。
4、使用场景
高并发场景。需要1)加上超时时间避免死锁;2)提供足够支撑锁服务的内存空间;3)稳定的集群化管理。

三、redis分布式锁
redis分布式锁即可以结合zk分布式锁锁高度安全和memcached并发场景下效率很好的优点，其实现方式和memcached类似，采用setnx即可实现。需要注意的是，这里的redis也需要设置超时时间。以避免死锁。可以利用jedis客户端实现。参考资料Redis实现分布式锁。


30 分布式session的实现方式有哪几种？
一、分布式Session的几种实现方式
1.基于数据库的Session共享
2.基于NFS共享文件系统
3.基于memcached 的session，如何保证 memcached 本身的高可用性？
4.基于resin/tomcat web容器本身的session复制机制
5.基于TT/Redis 或 jbosscache 进行 session 共享。
6.基于cookie 进行session共享

或者是：
一、Session Replication 方式管理 (即session复制)
简介：将一台机器上的Session数据广播复制到集群中其余机器上
使用场景：机器较少，网络流量较小
优点：实现简单、配置较少、当网络中有机器Down掉时不影响用户访问
缺点：广播式复制到其余机器有一定廷时，带来一定网络开销

二、Session Sticky 方式管理
简介：即粘性Session、当用户访问集群中某台机器后，强制指定后续所有请求均落到此机器上
使用场景：机器数适中、对稳定性要求不是非常苛刻
优点：实现简单、配置方便、没有额外网络开销
缺点：网络中有机器Down掉时、用户Session会丢失、容易造成单点故障

三、缓存集中式管理
简介：将Session存入分布式缓存集群中的某台机器上，当用户访问不同节点时先从缓存中拿Session信息
使用场景：集群中机器数多、网络环境复杂
优点：可靠性好
缺点：实现复杂、稳定性依赖于缓存的稳定性、Session信息放入缓存时要有合理的策略写入


31 消息发送一致性解决方案有哪些？
消息发送一致性
是指产生消息的业务动作与消息发送的一致。（如果业务操作成功，那么由这个业务操作所产生的消息一定要成功投递出去，否则就丢消息）
消息发送一致性如何保障：

场景：
1.业务处理成功，执行发送消息的时候 应用故障，导致没有发送消息（后续服务没有收到消息处理业务，结果数据不一致）
2.业务处理成功，执行发送消息的时候，消息系统（MQ）故障，导致消息发送失败（后续服务没有收到消息处理业务，结果数据不一致）

解决方案：
1.主动方应用先把消息发给消息中间件，消息状态标记为“待确认”
2.消息中间件收到消息后，把消息持久化到消息存储中，但并不向被动方应用投递消息
3.消息中间件返回消息持久化结果（成功/失败），主动方应用根据返回结果进行判断如何进行业务操作处理
a：失败，放弃业务操作处理，结束（必要时向上层返回失败结果）
b：成功，执行业务操作处理
4.业务操作完成后，把业务操作结果（成功/失败）发送给消息中间件
5.消息中间件收到业务操作结果后，根据业务结果进行处理
a：失败：删除消息存储的消息，结束
b：成功：更新消息存储的消息状态为“待发送（可发送）”，紧接着执行消息投递
6.确保了主动方应用业务处理成功就一定会发送消息
7.被动方应用监听并接收“待发送状态的消息”执行业务处理
8.业务处理完成后向消息中间件发送ACK确认，确认消息已经收到（消息中间件将从队列中删除该消息）
消息发送一致性流程中的异常点

异常情况：
主动方
1.预发送消息失败：
消息未进行存储，业务操作未执行（可能的原因：主动方应用、网络、消息中间件、消息存储）【一致】
2.预发送消息后，主动方应用没有收到返回消息存储的结果：
a：消息未进存储，业务操作未执行【一致】
b：消息已进存储（待确认），业务操作未执行【不一致：待确认消息已存储，但是业务却没执行】
3.收到消息存储成功的返回结果，但未执行业务操作就失败
消息已进存储（待确认），业务操作未执行【不一致：待确认消息已存储，但是业务却没执行】
消息中间件
1.消息中间件没有收到主动方应用的业务操作处理结果
a：消息已进存储（待确认），业务操作未执行成功（或业务操作出错回滚了）【不一致：待确认消息已存储，但是业务失败】
b：消息已进存储（待确认），业务操作成功（主动方网络中断）【不一致：待确认消息已存储，但是业务操作成功，但是没有修改消息状态为待发送】
2.消息中间件收到业务操作结果（成功/失败），但处理消息存储中的消息状态失败
a：消息已进存储（待确认），业务操作未执行成功（或业务操作出错回滚了）,告知消息中间件失败(MQ操作消息状态失败)【不一致：业务失败，未删除消息】
b：消息已进存储（待确认），业务操作成功,告知消息中间件成功(MQ更新消息状态失败)【不一致：业务成功，消息状态未更新成待发送】

总结：
1.消息未进存储，业务操作未执行【一致】
2.消息已进存储（状态待确认）业务操作未执行或失败【不一致】
异常解决方案：删除消息
3.消息已进存储（状态待确认）业务操作成功【不一致】
异常解决方案：更新消息状态 
异常处理还是会有异常

解决方案：消息持久化，创建定时任务查询消息中间件查询状态为“待确认”的消息调用主动方应用的业务操作结果查询接口，返回业务处理结果（成功/失败）去更新消息状态

被动方
消息重复发送的原因
1.被动方应用接收到消息，业务处理完成后应用出问题，消息中间件不知道消息处理结果，会重新投递消息
2.被动方应用接收到消息，业务处理完成后网络出问题，消息中间件不知道消息处理结果，会重新投递消息
3.被动方应用接收到消息，业务处理时间过长，消息中间件因消息超时未确认，会再次投递消息
4.被动方应用接收到消息，业务处理完成，消息中间件问题导致收不到消息处理结果，消息会重新投递
5.被动方应用接收到消息，业务处理完成，消息中间件收到了消息处理结果，但由于消息存储故障导致消息没能确认，消息会再次投递
总结：消息消费过程中产生消息重复发送主要是因为消息接收者成功处理完消息后，消息中间件没能及时更新消息投递状态（也就是消息没能及时ACK确认）导致的
解决方案：
消息重复发送无法解决，通过被动方应用实现幂等性设计（任意多次执行所产生的影响均与一次执行的影响相同）
1.通过业务操作本身实现幂等性
2.系统缓存所有请求与处理结果 检测到重复请求后，自动返回之前的处理结果
极端情况：
消息重发也得有次数限制，要不然就变成了死循环，对于超过重发限制的消息，进入DLQ（死亡队列），等待人工干预或延后定期处理
实现方式：
1.本地消息服务
1.在主动方应用业务操作中，用一个本地事务将业务处理和消息确认数据存放在本地库中，确保业务完成 本地一定有一条“待确认的消息数据”
2.主动方应用业务处理成功后，发送消息至MQ中
3.被动方应用采用自动ACK确认方式，处理业务（需加幂等性设计）
4.业务处理成功后调用主动方消息确认接口（或再加一个消息确认的MQ，只是业务会相对更复杂），修改消息数据状态，完成整体流程
5.消息恢复系统定时轮询一段时间未确认的消息数据，从新放置再MQ中继续消费
优点：
1.消息数据的可靠性不依赖于MQ，弱化了多MQ的依赖
2.方案轻量级，容易实现
缺点：
1.业务和消息耦合性高，不可共用
2.消息数据与业务数据同库，占用资源
3.业务系统在使用关系型数据库的情况下，消息服务性能会受到关系型数据库并发性能的局限
2.独立消息服务
1.主动方应用系统调用消息服务系统预发送消息
2.获得返回结果后处理业务操作，发送结果告知消息服务系统
3.消息服务系统根据业务处理结果（成功/失败）修改消息状态为“待发送”
异常情况：
业务处理成功，但是与消息系统确认消息状态失败
通过消息状态确认子系统定时轮询未确认的消息去主动请求主动方应用获得业务处理结果更新消息状态
4.被动方系统接收消息，ACK确认删除MQ中的消息，处理业务逻辑完成后
5.调用消息系统确认消息已被成功消费（更新消息状态或删除消息记录）
异常情况：
业务处理成功后没有修改成功消息系统此条消息被成功消费状态
通过消息恢复子系统定时轮询成功消费的消息从新放到MQ队列中去重做直到成功
被动方采用幂等性设计保证多次消费的结果一致性
优点：
1.消息服务独立部署，独立维护、独立伸缩
2.消息存储可以按需选择不同的数据库来集成实现（关系型数据库或者nosql）
3.可复用，可以被相同的使用场景共用
4.消息数据的可靠性不依赖于MQ，弱化了多MQ的依赖
5.降低了业务系统和消息系统间的耦合，有利于系统的扩展维护
缺点：
1.一次消息发送需要两次请求，时效性偏低一点
2.主动方应用系统需要实现业务操作状态校验查询接口
消息状态确认子系统设计
1.系统集成了消息系统查询“未确认”数据接口服务，主动方查询业务状态接口服务
2.消息系统查询“未确认“数据接口，查询条件：
状态“未确认“
查询升序（ASC，先处理最早的数据）
指定固定数量（防止数据量过多一次查询出来）
并且消息存放时间大于一定时间（防止拿到新数据）
3.遍历拿到的“未确认“消息数据，调用主动方查询业务状态接口查询业务状态或者未生成业务数据
a)如果业务状态为成功，则修改消息状态为“待发送”
b)如果业务状态为失败或者就没执行业务，则删除消息
消息恢复子系统设计
1.系统集成了消息系统查询“未消费“数据接口服务
2.消息系统查询“未消费“数据接口，查询条件：
状态“未消费“
查询升序（ASC，先处理最早的数据）
指定固定数量（防止数据量过多一次查询出来）
并且消息存放时间大于一定时间（防止拿到新数据）
未死亡的消息（重试多次后还失败的消息会放入死亡队列）
3.遍历拿到的“未消费“消息数据
a)判断消息重试次数是否达到最多重试次数，如果达到则标记此消息死亡（防止消息一直重试）
b)根据消息重试次数判断是否达到了消息间隔
如第1次失败1分钟后就可以尝试重试，第5次失败则可以30分钟后再尝试，第6次就标记为死亡
c)重发消息
消息服务子系统设计
1.存储预发送消息
2.确定并发送消息
3.查询确认超时的消息（一直处于“未发送”状态的消息）
4.确认已被成功消费消息
5.查询消费确认超时的消息（一直处于“未消费”状态的消息）
6.删除消息
实时消息服务子系统设计（操作MQ）
1.修改mq重试次数为1或者0，将重试的机制交给消息恢复子系统去处理，减少频繁短时间内多次重试带来的效率问题


32 如何理解正向代理（客户端代理）和反向代理（服务器端代理）？
       反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器。
概述：
       通常的代理服务器，只用于代理内部网络对Internet的连接请求，客户机必须指定代理服务器,并将本来要直接发送到Web服务器上的http请求发 送到代理服务器中。由于外部网络上的主机并不会配置并使用这个代理服务器，普通代理服务器也被设计为在Internet上搜寻多个不确定的服务器,而不是 针对Internet上多个客户机的请求访问某一个固定的服务器，因此普通的Web代理服务器不支持外部对内部网络的访问请求。当一个代理服务器能够代理 外部网络上的主机，访问内部网络时，这种代理服务的方式称为反向代理服务。此时代理服务器对外就表现为一个Web服务器，外部网络就可以简单把它当作一个 标准的Web服务器而不需要特定的配置。不同之处在于，这个服务器没有保存任何网页的真实数据，所有的静态网页或者CGI程序，都保存在内部的Web服务 器上。因此对反向代理服务器的攻击并不会使得网页信息遭到破坏，这样就增强了Web服务器的安全性。
　   反向代理方式和包过滤方式或普通代理方式并无冲突，因此可以在防火墙设备中同时使用这两种方式，其中反向代理用于外部网络访问内部网络时使用，正向代理或 包过滤方式用于拒绝其他外部访问方式并提供内部网络对外部网络的访问能力。因此可以结合这些方式提供最佳的安全访问方式。
为何叫反向：
        但是这也没法解释为何他叫反向，从原理上来说.代理服务器都是处理来自客户端的请求，并将其转发到目的服务器上，所以代理服务器的工作并没有任何反向的意味，而下面这张图就能说明为何反向代理叫反向
对了，从结构上来看，正向代理和反向代理的左右两边换了一下，原本代理服务器的客户端来自内网.其和代理服务器组成一个LAN，而反向代理之后.代 理服务器和服务器组成了一组.所以从结构来看,是reverse的，从英文的角度来看，reverse这个词包含翻转的意思,其意思就是指结构图上的这种 反转，但是由于翻译的关系.到了中文变成反向代理.其实proxy并没有做和以前有什么不同的事情.它仍旧是将来自客户端的请求转发给实际端.，而时至今 日,由于CDN的大量使用,反向代理后面的服务器为了适应这种跨网络的架构，而均采用实际IP地址.这样就往往更不容易使得大家对”反向代理这个名词中的反向到底指什么”这个问题有个清晰的答案了。

33 CDN实现原理是什么？
CDN发展背景
像我们所熟知的腾讯、新浪、网易这样的大网站，每天都有成千上百万的流量，他们要保持全国每个地方打开网站的速度都很快，这要怎么做到呢？这其中有CDN不小的功劳！
什么是CDN
我们先来看下CDN的含义，CDN即内容分发网络，加速的意思。那么网站CND服务是网站加速服务。我们可以通俗的了解成CDN可以加速网站的打开速度。
CDN加速原理
CDN是怎么做到加速的呢？其实这是CDN服务商在全国各个省份部署计算节点， CDN加速将网站的内容缓存在网络边缘，然后在用户访问网站内容的时候，通过调度系统将用户的请求路由或者引导到离用户接入网络最近或者访问效果的缓存服务器上，有该缓存服务器为用户提供内容服务；相对于直接访问源站，这种方式缩短了用户和内容之间的网络距离，从而达到加速的效果。
CDN具有哪些特点
1、本地加速，提高了企业站点(尤其含有大量图片和静态页面站点)的访问速度，并大大提高以上性质站点的稳定性。
2、镜像服务 消除了不同运营商之间互联的瓶颈造成的影响，实现了跨运营商的网络加速，保证不同网络中的用户都能得到良好的访问质量。
3、远程加速 远程访问用户根据DNS负载均衡技术 智能自动选择Cache服务器，选择最快的Cache服务器，加快远程访问的速度。
4、带宽优化 自动生成服务器的远程Mirror(镜像)cache服务器，远程用户访问时从cache服务器上读取数据，减少远程访问的带宽、分担网络流量、减轻原站点WEB服务器负载等功能。
5、集群抗攻击 广泛分布的CDN节点加上节点之间的智能冗于机制，可以有效地预防黑客入侵以及降低各种D.D.o.S攻击对网站的影响，同时保证较好的服务质量。



34 怎么提升系统的QPS和吞吐量？
简单而言通过增加集群来提升qps和吞吐量
实际上要比这个要复杂
首先我们需要知道系统的瓶颈
我们所知道的系统拓扑架构
对于rest接口而言
系统设施依次是：
dns
nginx
tomcat
db/soa
首先我们可以通过增加集群来增加qps和吞吐量
其次考虑到负载均衡的问题，我们可以通过其他设施来保证集群节点的负载均衡，进一步提高系统qps
于是就有nginx集群+负载均衡
tomcat集群+负载均衡
到db/soa这一层的时候，同样也可以通过增加集群+负载均衡的方式来解决
我们还可以在每一层增加缓存来应对热点数据
然而另外一个方面，可以系统拆分，服务拆分，分别针对瓶颈的系统单独增加集群和负载均衡来解决
同样db也可以分库分表，
因为单表超过1000万条数据时就很慢了，所以这个时候就需要库拆分，于是就有垂直拆分，水平拆分。　　　
异步化，可以不同调用的异步化，使用mq，比如发送短信，发送邮件等
综上所述：
集群+负载均衡
增加缓存
系统拆分
分库分表
垂直拆分+水平拆分
异步化+MQ


35 线上问题出现内存泄露，CPU利用率标高，应用无响应时如何处理的？
java程序 cup使用率过高，会导致程序运行速度变慢，导致系统崩溃等
原因是多向的。跟内存泄漏,数据库等都有关
检查是否有死循环。
频繁的GC.或者有大量的线程。
算法太复杂或者太多
数据库连接的资源未释放或未关闭，
数据库connection过于频繁。



36 开发中有没有遇到什么技术问题？如何解决的？
axis服务连接被重置；activiti异步任务；springboot 引入es; 报表查询缓慢


37 有几十亿的名单，每天白天需要高并发查询，晚上需要更新一次，如何设计这个功能？
看下高并发网站更新数据的方式是如何做的？如下是收集cnblogs博主的文章。
很多Web系统的瓶颈在网络IO，所以很多系统都采用多Web服务器负载均衡，双DB做双机热备（其实就是只有一个DB，两台只有一台真正工作，死掉一台另一台顶上）的方式部署，在这个时候很多原本不是问题的系统也会产生很多的问题。
这里我们假设有表Product，其定义如下：
列明	类型	说明
Id	Int	自增字段，实例的ID
ProductName	Varchar(100)	商品的名称
StoreCount	int	库存数量
。。。	。。。	。。。
假设很不凑巧的，3个管理员P1,P2,P3同时操作了这个表，且P1 update StoreCount=50,P2 update StoreCount=49,P3 update StoreCount=48。这个时候问题就来了，如果是让他们都同时提交进去，当然没问题，但是如果这个时候N个Web程序在读的时候就会产生每台服务器上读出来的数据都可能不一样，A服务器读出来是48，B服务器读出来是50，C服务器读出来是49。
如果我们采用数据库锁可以避免这个问题，但是随之而来的是系统效率降低和无可避免的异常，而hibernate等实现的乐观锁呢，呵呵，对不起了，在多Web服务器的时候还能起作用吗？
由此产生了以下的解决方案：
和乐观锁的实现相反，我们不反对任何一个客户端的提交，乐观锁对读取的数据增加版本号，那么这个解决方案中对提交的数据增加“版本号”其实也就是时间戳。针对上面的Product表作为例子，为了实现无锁的提交，我们需要增加一个表Product_Dirty，以后我们将称其为脏表，Product表我们称之为主表。脏表的结构和主表几乎完全一致，只是增加了一个时间戳字段用于记录详细的插入时间：
列明	类型	说明
Timespan	Int	时间戳，精确到毫秒（能到纳秒更好）
Id	Int	实例的ID(这里就不是自增字段了)
ProductName	Varchar(100)	商品的名称
StoreCount	int	库存数量
。。。	。。。	。。。

在发生任何update的时候都将数据直接插入这个表，不要犹疑，没锁，所以可以快速的，尽情的插入数据。这里还是保持最初的假设，P1，P2，P3同时修改，所以插入了三条数据。所谓的同时插入其实在毫秒这个级别还是有差距的，所以三条记录的时间戳是不同的。好了这个时候数据进来了，但是主表的列数据还是没有改变，先在假设A服务器和B，C服务器都同时开始读数据了。在主表的时候，如果发现脏表有数据则表明主表数据为脏（已经修改过了）这个时候我们就开始合并数据，当然这个操作是需要在一个事务里实现。合并的操作其实很简单，就是取时间戳最大的（也就是最近一次修改）更新主表的数据，同时删掉脏表里的和主表ID相等的所有数据。如果发现主表关联的脏表没数据，那么就说明主表数据正常，就直接读取主表的内容。
此解决方案来自电信营帐系统的设计，由于省电信众多系统都是由分布很广的地市州电信业务人员操作，所以修改的时候经常存在本文要解决的问题，由于操作的人多，锁表的话会造成严重的拥塞，故产生了这个解决方案，由于电信的业务需要后台跑了一个服务来合并数据，并且每秒定时运行，故每秒为一个业务周期。我将其修改成在读取的时候合并，更加灵活一些。
好处：不用锁表，乐观锁也不用，可以在N多服务器操作的时候使用，且大家都不会报错，简化了异常处理。
坏处：增加了表，结构复杂，如果是用于修改原有业务如果只是几个关键表的话还好，全部都采用这个方式工作量巨大（好在电信不缺钱）。
弱点：和乐观锁类似，在某些场景下仍然可能脏读，所以如果对这方面有很高的要求，还是用悲观锁吧。


38 新浪微博中的推送消息给客户端在技术上如何实现的？

通常情况下，无论是web浏览器还是移动app，我们与服务器之间的交互都是主动的，客户端向服务器端发出请求，然后服务器端返回数据给客户端，客户端浏览器再将信息呈现，客户端与服务端对应的模式是: 客户端请求--服务端响应，这种机制对于信息变化不是特别频繁的应用尚可，但对于实时要求高、海量并发的应用来说显得捉襟见肘，尤其在当前业界移动互联网蓬勃发展的趋势下，高并发与用户实时响应是 Web 应用经常面临的问题，比如金融证券的实时信息，Web 导航应用中的地理位置获取，社交网络的实时消息推送，新闻的订阅,天气的提醒等。这些情况下，需要服务器主动推送消息给客户端。
那么在这样的模式下,会有几个问题需要我们思考下:
1.应用服务器如何确定每一个应用所在的设备
2.服务器端是如何将消息推送到客户端的，客户端又不像服务器有一个固定的地址
带着这些疑问我们来研究一下目前有哪些技术可以解决该问题：

一、Ajax轮询
所谓的Ajax轮询，其实就是定时的通过Ajax查询服务端，客户端按规定时间定时像服务端发送ajax请求，服务器接到请求后马上返回响应信息并关闭连接。
这种技术方式实现起来非常简单，但是这种方式会有非常严重的问题，就是需要不断的向服务器发送消息询问，这种方式会对服务器造成极大的性能浪费。
还有一个类似的轮询是使用JSONP跨域请求的方式轮询，在实现起来有差别，但基本原理都是相同的，都是客户端不断的向服务器发起请求。
优点
实现简单。
缺点
这是通过模拟服务器发起的通信，不是实时通信，不顾及应用的状态改变而盲目检查更新，导致服务器资源的浪费，且会加重网络负载，拖累服务器。

二、Comet
Comet，基于 HTTP 长连接的 "服务器推" 技术，能使服务器端主动以异步的方式向客户端程序推送数据，而不需要客户端显式的发出请求，目前有两种实现方式：
1. 基于 AJAX 的长轮询（long-polling）方式
Ajax 的出现使得 JavaScript 可以调用 XMLHttpRequest 对象发出 HTTP 请求，JavaScript 响应处理函数根据服务器返回的信息对 HTML 页面的显示进行更新。使用 AJAX 实现 "服务器推" 与传统的 AJAX 应用不同之处在于：
服务器端会阻塞请求直到有数据传递或超时才返回。
客户端 JavaScript 响应处理函数会在处理完服务器返回的信息后，再次发出请求，重新建立连接。
当客户端处理接收的数据、重新建立连接时，服务器端可能有新的数据到达；这些信息会被服务器端保存直到客户端重新建立连接，客户端会一次把当前服务器端所有的信息取回。
基于长轮询的服务器推模型
相对于"轮询"（poll），这种长轮询方式也可以称为"拉"（pull）。因为这种方案基于 AJAX，具有以下一些优点：请求异步发出；无须安装插件；IE、Mozilla FireFox 都支持 AJAX。
长轮询 (long polling) 是在打开一条连接以后保持并等待服务器推送来数据再关闭，可以采用HTTP长轮询和XHR长轮询两种方式:
(1). HTTP 和JSONP方式的长轮询
把 script 标签附加到页面上以让脚本执行。服务器会挂起连接直到有事件发生，接着把脚本内容发送回浏览器，然后重新打开另一个 script 标签来获取下一个事件，从而实现长轮询的模型。
(2).XHR长轮询
这种方式是使用比较多的长轮询模式。
客户端打开一个到服务器端的 AJAX 请求然后等待响应；服务器端需要一些特定的功能来允许请求被挂起，只要一有事件发生，服务器端就会在挂起的请求中送回响应并关闭该请求。客户端 JavaScript 响应处理函数会在处理完服务器返回的信息后，再次发出请求，重新建立连接；如此循环。
现在浏览器已经支持CROS的跨域方式请求，因此HTTP和JSONP的长轮询方式是慢慢被淘汰的一种技术，建议采用XHR长轮询。
优点
客户端很容易实现良好的错误处理系统和超时管理，实现成本与Ajax轮询的方式类似。
缺点
需要服务器端有特殊的功能来临时挂起连接。当客户端发起的连接较多时，服务器端会长期保持多个连接，具有一定的风险。
>>在这里简单的说明下长轮询，长连接的概念
轮询：客户端定时向服务器发送Ajax请求，服务器接到请求后马上返回响应信息并关闭连接。优点：后端程序编写比较容易。
缺点：请求中有大半是无用，浪费带宽和服务器资源。
实例：适于小型应用。
长轮询：客户端向服务器发送Ajax请求，服务器接到请求后hold住连接，直到有新消息才返回响应信息并关闭连接，客户端处理完响应信息后再向服务器发送新的请求。
优点：在无消息的情况下不会频繁的请求。
缺点：服务器hold连接会消耗资源。
实例：WebQQ、Hi网页版、Facebook IM。
另外，对于长连接和socket连接也有区分：
长连接：在页面里嵌入一个隐蔵iframe，将这个隐蔵iframe的src属性设为对一个长连接的请求，服务器端就能源源不断地往客户端输入数据。
优点：消息即时到达，不发无用请求。
缺点：服务器维护一个长连接会增加开销。
实例：Gmail聊天
Flash Socket：在页面中内嵌入一个使用了Socket类的 Flash 程序JavaScript通过调用此Flash程序提供的Socket接口与服务器端的Socket接口进行通信，JavaScript在收到服务器端传送的信息后控制页面的显示。
优点：实现真正的即时通信，而不是伪即时。
缺点：客户端必须安装Flash插件；非HTTP协议，无法自动穿越防火墙。
实例：网络互动游戏。
2. 基于 Iframe 及 htmlfile 的流（streaming）方式
iframe 是很早就存在的一种 HTML 标记， 通过在 HTML 页面里嵌入一个隐蔵帧，然后将这个隐蔵帧的 SRC 属性设为对一个长连接的请求，服务器端就能源源不断地往客户端输入数据。
基于流方式的服务器推模型
Comet的优缺点
优点： 实时性好（消息延时小）；性能好（能支持大量用户）
缺点： 长期占用连接，丧失了无状态高并发的特点。
Comet实现框架
1. Dojo CometD —— http://cometdproject.dojotoolkit.org/
2. DWR —— http://directwebremoting.org/dwr/index.html
3. ICEfaces —— http://www.icefaces.org/main/home/
4. GlassFish Grizzly —— https://grizzly.dev.java.net/
CometD 目前实现 Comet 比较成熟， DWR 弱一些。 ICEfaces 更商业化，实现得很成熟。 Grizzly 是基于GlassFish ，也很成熟。CometD, DWR 开源性好。
Comet实现要点
不要在同一客户端同时使用超过两个的 HTTP 长连接
我们使用 IE 下载文件时会有这样的体验，从同一个 Web 服务器下载文件，最多只能有两个文件同时被下载。第三个文件的下载会被阻塞，直到前面下载的文件下载完毕。这是因为 HTTP 1.1 规范中规定，客户端不应该与服务器端建立超过两个的 HTTP 连接， 新的连接会被阻塞。而 IE 在实现中严格遵守了这种规定。
HTTP 1.1 对两个长连接的限制，会对使用了长连接的 Web 应用带来如下现象：在客户端如果打开超过两个的 IE 窗口去访问同一个使用了长连接的 Web 服务器，第三个 IE 窗口的 HTTP 请求被前两个窗口的长连接阻塞。
所以在开发长连接的应用时， 必须注意在使用了多个 frame 的页面中，不要为每个 frame 的页面都建立一个 HTTP 长连接，这样会阻塞其它的 HTTP 请求，在设计上考虑让多个 frame 的更新共用一个长连接。
服务器端的性能和可扩展性
一般 Web 服务器会为每个连接创建一个线程，如果在大型的商业应用中使用 Comet，服务器端需要维护大量并发的长连接。在这种应用背景下，服务器端需要考虑负载均衡和集群技术；或是在服务器端为长连接作一些改进。
应用和技术的发展总是带来新的需求，从而推动新技术的发展。HTTP 1.1 与 1.0 规范有一个很大的不同：1.0 规范下服务器在处理完每个 Get/Post 请求后会关闭套接口连接； 而 1.1 规范下服务器会保持这个连接，在处理两个请求的间隔时间里，这个连接处于空闲状态。 Java 1.4 引入了支持异步 IO 的 java.nio 包。当连接处于空闲时，为这个连接分配的线程资源会返还到线程池，可以供新的连接使用；当原来处于空闲的连接的客户发出新的请求，会从线程池里分配一个线程资源处理这个请求。 这种技术在连接处于空闲的机率较高、并发连接数目很多的场景下对于降低服务器的资源负载非常有效。
但是 AJAX 的应用使请求的出现变得频繁，而 Comet 则会长时间占用一个连接，上述的服务器模型在新的应用背景下会变得非常低效，线程池里有限的线程数甚至可能会阻塞新的连接。Jetty 6 Web 服务器针对 AJAX、Comet 应用的特点进行了很多创新的改进。
控制信息与数据信息使用不同的 HTTP 连接
使用长连接时，存在一个很常见的场景：客户端网页需要关闭，而服务器端还处在读取数据的堵塞状态，客户端需要及时通知服务器端关闭数据连接。服务器在收到关闭请求后首先要从读取数据的阻塞状态唤醒，然后释放为这个客户端分配的资源，再关闭连接。
所以在设计上，我们需要使客户端的控制请求和数据请求使用不同的 HTTP 连接，才能使控制请求不会被阻塞。
在实现上，如果是基于 iframe 流方式的长连接，客户端页面需要使用两个 iframe，一个是控制帧，用于往服务器端发送控制请求，控制请求能很快收到响应，不会被堵塞；一个是显示帧，用于往服务器端发送长连接请求。如果是基于 AJAX 的长轮询方式，客户端可以异步地发出一个 XMLHttpRequest 请求，通知服务器端关闭数据连接。
在客户和服务器之间保持“心跳”信息
在浏览器与服务器之间维持一个长连接会为通信带来一些不确定性：因为数据传输是随机的，客户端不知道何时服务器才有数据传送。服务器端需要确保当客户端不再工作时，释放为这个客户端分配的资源，防止内存泄漏。因此需要一种机制使双方知道大家都在正常运行。在实现上：
服务器端在阻塞读时会设置一个时限，超时后阻塞读调用会返回，同时发给客户端没有新数据到达的心跳信息。此时如果客户端已经关闭，服务器往通道写数据会出现异常，服务器端就会及时释放为这个客户端分配的资源。
如果客户端使用的是基于 AJAX 的长轮询方式；服务器端返回数据、关闭连接后，经过某个时限没有收到客户端的再次请求，会认为客户端不能正常工作，会释放为这个客户端分配、维护的资源。
当服务器处理信息出现异常情况，需要发送错误信息通知客户端，同时释放资源、关闭连接。

三，websocket方式
WebSocket是HTML5开始提供的一种在单个 TCP 连接上进行全双工通讯的协议。WebSocket通讯协议于2011年被IETF定为标准RFC 6455，WebSocketAPI被W3C定为标准。在WebSocket API中，浏览器和服务器只需要做一个握手的动作，然后，浏览器和服务器之间就形成了一条快速通道。两者之间就直接可以数据互相传送。
由于websocket技术要说明白的话所需要的篇幅不小，所以会在之后的单独文章中介绍下websocket的使用方式，这里就不做详细的说明了。

四，总结
根据以上技术的优缺点和具体业务需要，可以选择合适的技术进行应用。



39 Google是如何在一秒内把搜索结果返回给用户的？
在你点击了 Google 搜索按钮之后到看到结果这不足1秒钟的时间内，它做了什么?互联网上的内容如何被谷歌找到?什么样的内容会被收录?想必大家一定都想知道谷歌搜索按钮背后的秘密吧。别急，开始之前我们先来看一下神秘的谷歌数据中心……

谷歌的数据中心高度机密，我们所能得到的信息十分有限。我们先来看几个数据：谷歌在美国本土的数据中心有19个以上，另有17个分布在美国以外的世界各地;每个数据中心有50万平方英尺(46450平方米)，建造一个数据中心要花费约6亿美元;谷歌的数据中心是世界上最高效的设施之一，非常环保;数据中心使用50-100兆瓦的电力，考虑到冷却问题，通常建在便于用水的地方;谷歌的服务器被安置在标准的海运集装箱中，每个集装箱可容纳1160台服务器。关于谷歌的数据中心，我们就只知道这么多了。

谷歌拥有的数十万台服务器都是自己设计的，它们认为这是公司的核心技术之一。每台服务器都配有一颗12伏电池，确保万一主电源断电时还可持续供电。
至于为什么为每台服务器配备电池，谷歌的回答是成本。一般数据中心多依赖 UPS(不间断电源系统)，这基本上算是大电池，会在主电力失效而发电机还来不及启动时暂时协助供电。而谷歌认为直接把电力内建到服务器更便宜，而且成本能直接跟服务器数量相符合，如此便不会浪费多余的容量。另一个原因是效率，大型UPS可达92-95%的效率，这意味着许多电力还是被浪费掉了，但谷歌采用的内建电池作法效率超过99.9%。

Google 搜索谷歌的服务器被安装在集装箱中，每个集装箱容纳1160台
Google 搜索谷歌如何找到并收录你上传的内容?
Google 搜索发生在用户搜索之前

谷歌使用它的”爬虫”工具在一刻不停地周游互联网世界的每一个角落。上图中间的6个步骤依次描绘了从内容出现在互联网上到内容被收录进谷歌的数据库供用户检索这一过程，其中第2、3、5步又有许多分支，所有这些都是为了建立一个信息”集汇池”，这是第一个阶段的工作，第二个阶段才是从这个”池”中为用户筛选他们所需要的内容。接下来我们一步步看谷歌是如何搜集并整合信息的。

1、网友上传内容，比如博客、微博或其它类型的WEB内容被更新到网上。

2、Google的”爬虫”发现了这一更新。在这一步，谷歌加入了许多判断机制，主要包括以下几点：
     2.1、Google的”爬虫”沿着链接路径(URL)周游互联网，但如果没有URL指向某一站点，则这一站点将不会被索引。
     2.2、如果你在 robots.txt 中设置了不许索引(部分或全部)，Google 的”爬虫”将不会抓取你站点上的相应内容。
    2.3、如果指向你站点的连接上有 nofollow 标签，Google 的”爬虫”将不会从这些URL路径来到你的站点。
URL 就像是 Google “爬虫”周游互联网时的路标，谷歌当然希望收录有价值的网页，所以必须采取一种机制分辨哪些 URL 是垃圾信息，nofollow 标签正是谷歌所倡导的方法之一。网站的合法更新人员几乎不会上传垃圾 URL，但它们往往大量出现在评论跟帖和论坛中，就像上图中的例子，这些 URL 对于谷歌来讲是没有意义的，为了防止”爬虫”经由这些 URL 到达某一站点，在源代码中它们都会自动被加上 nofollow 标签。
     2.4、Google 也能通过 blog 软件或 xml 站点地图找到你的网站。
     2.5、从权威性越高的网站链接到你网站的 URL 越多，你的网站的权威性也就越高，但 Google “爬虫”始终会忽略被加上了 nofollow 标签的 URL。
上面这几点大概就是谷歌在收录信息时对内容提出的”准入”要求，看来在一些开放的地方(比如论坛)大量发布 URL 以求让谷歌关注，这一小伎俩是没有什么效果的。以上是信息被谷歌收录之前所发生的事，一旦信息被谷歌收录了会发生什么呢?请往下看：
Google 搜索信息”素材”的存储

3、信息被谷歌收录之后当然也要进行加工处理，主要包括两个步骤，一是信息”素材”的存储，二是对收录的信息按要求进行优化，上图描绘了”素材”的存储方式，主要包括两部分：网页标题和链接数据被保存在一个索引中，用于广度优先搜索(可见文章标题是多么的重要，做编辑的一定要有驾驭标题党的觉悟);网页内容保存在另一个索引中，以用于检索频率不高的长尾、个性化、深度优先搜索。
此时可能你已经明白了，当你用谷歌搜索时，你并没有在检索时时更新的互联网，而是在检索谷歌的缓存，只是谷歌更新的速度非常快，以让其缓存尽量与互联网上的内容同步。
Google 搜索优化已收录的信息

4、谷歌基于 URL 评估域名和网页的总体权威性。

5、检查网页以防止作弊行为，包括以下几点：
      5.1、谷歌的搜索质量和反垃圾信息审查。
      5.2、1万多远程测试用户评价搜索结果的质量。
      5.3、谷歌征请用户对有 PageRank 讹诈嫌疑的垃圾信息进行举报。
      5.4、谷歌根据数字千年版权法( DMCA )去除盗版内容。

6、在对页面进行分析之后，每个页面都被附加上很多用于辅助用户搜索的数据片。
从信息出现在互联网上到被谷歌收录，然后谷歌对这些数据进行分析优化，至此，一个实时更新的互联网信息”集汇池”就建立起来了，可以说谷歌存储着整个互联网的快照。以上就是我们在按谷歌搜索按钮之前它所做的事情，接下来我们看一下谷歌如何响应用户的搜索请求，另外谷歌的广告是如何来到我们面前的，不要忘记，谷歌可是靠广告营生的。
只要有人用谷歌的服务它就能从中赚钱，就怕像安卓 (Android )手机系统那样，有些流氓厂家把安卓装在了自己的智能手机中，但是把其上谷歌的各种服务全部抹掉，改用自己的服务，这样谷歌当然不干了，所以安卓一更新，这些流氓手机厂家就紧张。
谷歌如何帮助用户进行搜索?

从用户开始检索到生成初步结果(这时的结果并不会直接呈现给用户)，经历了4个步骤：
1、用户发出搜索请求。谷歌搜索质量工程师 PatrickRiley 说：在大多数搜索中，你的搜索处于多个并行的控制过程或谷歌实验室的创新项目组过程中，可以说每一个查询请求都会参与一些谷歌的创意实验。我们都是小白鼠?

2、谷歌会对用户输入的关键词提供一些建议。

3、谷歌会用同义词匹配与你的搜索关键词语义相近的查询结果。

4、生成初步的查询结果，虽然谷歌宣称可以找到成千上万的相关结果，但一般只显示不到1000条，同时查询结果将被进行本地化处理，本土站点在查询结果中优先出现。
搜索结果将如何被优化?
      1、对查询结果按权威性和 PageRank 进行排序，重复的查询结果被剔除。此时的查询结果已接近最终形态，在这一基础上，有两个进程将分开进行–查询结果优化和为其匹配相应的广告。我们先来看查询结果优化。
对查询结果进行过滤处理

      2、对查询结果进行过滤处理。包括以下几点：
           2.1、对通常的查询，谷歌会把相关的专题性垂直搜索结果(比如新闻、购物、视频、书籍、地图等)也加到返回的查询结果中。
           2.2、个性化，用户访问过的网站在查询结果列表中会更靠上
           2.3、大量使用锚点的网站有可能被从查询结果中删除
           2.4、如果网页被其他高 PageRank 的网站引用，则网页的重要性会大大提高。
           2.5、趋势分析：对搜索流量爆增或有大量新闻的搜索关键词，谷歌会在新的查询结果中增加额外的 PageRank 权值。
           2.6、同一个域名下的多个网页如果具有相同的 PageRank 会被归为一组。
           2.7、查询结果最终形成(将与广告一同显示)

用户所搜索的内容如何与广告相结合?
1、Google 根据关键词、广告类型、用户所处位置找出相关的被竞价拍卖的关键词广告
      1.1、关键词广告必须遵守当地法律条文。广告业主的非法广告将被取缔，如果关键词的搜索流量过低或关键词广告点击量偏低，则会被自动禁用，出于商业策略，像亚马逊这样的客户会给予优惠折扣。
      1.2、关键词相关广告按收益潜力排序。
      1.3、对广告业主来说广告内容一般是固定的，但有时使用动态关键词使关键词广告与搜索关键词相关度更高。一些广告允许增加附属信息，比如网站链接、电话号码、产品链接、地址等。
      1.4、如果广告拥有相当高的点击率，则会显示在搜索结果列表的上方，以使其更显眼。
      1.5、其余的广告依序显示在页面右侧
经过上述一系列复杂的信息处理过程，最终返回给用户的是一个个性化的、具备地理位置特征的、布局简洁的查询结果页面，当然还精确匹配了广告，所有这些步骤在总共不到1秒的时间内完成，每天3亿次的点击量给 Google 带来了超过200亿美元的年收入

我们搜索技术的后端软件会在服务器侧触发一系列执行时间不到1秒的并行计算，谷歌问世前的传统搜索引擎的搜索结果严重依赖于关键词在页面上出现的频度，我们使用了200多个指标信号(其中包括我们拥有专利的 PageRank 页面等级加权算法)用来检查万维网的链接结构并决定网页的重要程度。

我们假定一个网页的重要程度取决于别的页面对它的引用，就像学术论文中的引用指数一样，重要的论文总是会被很多其他论文引用。然后我们再根据搜索条件进行超文本匹配分析(对”爬虫”抓取的页面内容进行关键词倒排索引检索)确定跟搜索请求最相关的网页。综合最重要的网页和跟搜索请求最相关的网页两个方面，我们就能按重要程度和用户搜索请求相关程度把查询结果排序后呈现给我们的用户。


40 12306网站的订票系统如何实现，如何保证不会票不被超卖？
如果是以前，我肯定会回答：是，因为我们始终认为，一个年投入超3亿元的卖火车票网站，没有什么理由做不好吧？其实不光是马海祥这样认为，包括众多媒体，甚至专业人士都曾喷过12306，但近日一名前淘宝工程师通过科普的方式给了我们一记响亮的耳光：做12306网站的难度要远高于淘宝，而且目前12306网站所面临的问题，也不是那么容易解决的！

1、人们对12306网站的误解
这位名为“代码狗”的前淘宝工程师，后来在一些论坛上发文表达了他自己对12306系统的看法，值得注意的是，“代码狗”在12306系统刚上线时也有过不少微词，为了证明12306系统很容易搭建，“代码狗”甚至曾经发起过一个名为“替12306设计系统”的开源项目，通过工作中的实践，“代码狗”对于12306系统也有了新的认识。
本人淘宝技术专家，曾在淘宝写过一段时间代码，2012年在一家百强民企做电商副总，当时在极为艰苦的条件下带队开发了一个B2C网站，走支付宝和银联支付通道，年营业额千万级。
也就在那个时候，我对12306嗤之以鼻，觉得他们做得太烂了，认为自己能带队花几百万半年时间做个好的出来，于是我狂妄地想做一个开源的订票系统给他们，我花了一个星期时间思考建立数据模型，思考到库存这一步的时候，我才发现，12306的库存复杂性比淘宝、京东高很多倍，运算量也大很多倍，传统的分布式数据库、缓存、负载均衡技术并不能恰好满足12306的需求。
在平时，12306也就是个正常的电商网站，但一到黄金周，12306就是一个全站所有商品都秒杀，所有SKU(库存量单位，物流管理术语，编者注)都是动态库存的变态。
即使不考虑线下既有的电话、代售点等渠道，要实现一个12306，最少最少也是千万级别的硬件投入(这是当时的估算，没有精算，可能与实际相差较大，总之，我说得不一定对，12306的业务也许没我说的那么复杂，但也绝不是某些人喷的那么简单)，软件和人力另算。
那些叫嚣只要40台服务器、只要2个架构师4个程序员、大谈分库分表和前端CDN的人们，只是纸上谈兵罢了，所谓初生牛犊不怕虎，做了三年CMS和BBS，就以这个经验来喷12306，未免太天真了。
媒体人喷12306，是他们不懂技术，没有能力和耐心来分析背后的难度；技术人员喷，则是因为大部分的技术人员在短时间思考时，容易陷入过于乐观的误区，经典的例子就是估算工作量；程序员们往往容易估算出一个超短的工期，把写程序的工作乐观地想象成了打字员照稿敲键盘的工作（具体可查看马海祥博客《史上最牛网站12306订票网的十宗罪及改善开发建议》的相关介绍）。
淘宝技术是比12306强大很多倍，淘宝现在的系统也是花了10倍于12306的钱、时间和人才做起来的，根本原因还是铁路运力不能满足春运需求，淘宝也解决不了这个问题。
12306这一年来进步非常大，从前段动画验证码、分时段抢票，到后端去小型机、虚拟化、内存数据库的运用，可以说，12306是中国政府机关做的最强大的网站(电商系统)，能在短短一两年内做出这样的改变，几乎是个奇迹，就连一些市场化的民企都望尘莫及，甚至一些上市公司都比不上它。
事非经过不知难，在网上批判12306的人，大部分还是形成了“国企=垄断+腐败+低效”的思维定势，小部分是真的轻视了它的难度。
至于12306一期工程3个亿(含硬件)贵不贵我不评价，我只提供一个数字供参考，百度一年的研发费用(不含硬件)是10亿，这个数字来自百度财报，网上能查到，3亿看起来好大一个数字，真用到超大型的电商系统、搜索引擎系统里面，其实也不算什么天文数字了。
再解释一下，为什么秒杀压力大，以及为什么12306的动态库存很复杂。

2、关于“秒杀”
2013年12月25日前后，天猫搞了一个圣诞季积分兑换活动，持续几天，25号上午10点12分，放出了15000个天猫魔盒(淘宝集市有人卖，大概190-230块)，从成交记录上看，是19秒内全部抢完。
实际上，我也参加秒杀了，那天的题目特别简单(请输入xxx汉字的拼音首字母)，我应该是5秒内答题完成并提交订单，结果告诉我排队的人太多，挤不进去，并提示14秒以后重试。
人太多就是因为题目太简单了，门槛越低，5秒内挤进去的人也越多嘛，如果题目换成“2克浓度为3%的U235在大亚湾核电站能发多少KW的电？”，5分钟之内也不会有1万5千人跟我竞争。
我想，14秒以后哪还有我的事情呀，于是重新答题秒杀，结果出现了服务器错误的页面，反复刷新几次，就告诉秒杀结束了。
在群里问了一下同事，有不到10个人回答我，都说没秒到（也可能秒到的人闷声发大财，不回复我）。
淘宝是什么技术水平呢？淘宝有至少4000技术人员，至少4万台服务器(这都是两年前的公开数据了，按规定可以谈论)，2013年11月11日成交额351亿，2012年全年成交额超过1万亿。
淘宝拥有各种自主研发团队：服务器、交换机(网上可以搜索到淘宝公开的绿色服务器开放标准);操作系统(LinuxKerneltaobao版，yunos手机操作系统是阿里云的，暂时不计入)、Web服务器(Tengine)、Java语言虚拟机(JVMtaobao版)、数据库(MySQL内核taobao版，google和facebook也有自己的版本，HBase淘宝版、还有自己全部从头开发的OceanBase)、负载均衡器(LVS，LVS始创人就在淘宝，担任研究员)、Java运行容器(Jboss，其创始人之一，王文彬，也在淘宝，担任副总裁)。
淘宝还有数不清的开源项目和中间件，如高性能Java通信中间件HSF、分布式数据库中间件TDDL、异步消息系统notify等等等等。
以淘宝这样的技术水平，也不能做到秒杀时让每个用户都没有拥挤感，为什么呢？
一是要尊重物理原理，一台服务器一秒钟能承受的计算量是有极限的，任你怎么优化，采用多高效的算法和编程语言，都突破不了某个极限，比方说汽车发动机驱动的F1赛车至今也不能突破400公里的时速(超音速推进号那个1千多公里的时速不能算，那是飞机引擎驱动的)，再往深了说，就不容易懂了，感兴趣的可以从著名的C10K问题开始看起。
二是要考虑经济效益，十一黄金周的时候，北京主城区到八达岭长城的路堵得严严实实，但不能因为黄金周的高峰，就把这段路修成长安街那样10车道的高速公路，否则的话，花费天文数字(真的是天文数字，12306那3个亿大概只够修1-3公里)，修了一段路，黄金周是可以飙到80公里/小时了，可平时呢？难不成拿来给两边的居民晒谷子？
淘宝目前的硬件和带宽数量，已经超出日常运营的需求了，就是留了相当大的余量给大促销(众所周知的是双十一，双十二，其实基本每个季度都有大促销，每个月都有促销，甚至天天都在促销——聚划算)，amazon当年就是为了应对黑色星期五的大促销购置了大量的服务器，平时订单量没那么大了，amazon就把富余的服务器拿来搞云计算了。
顺便说一下，阿里云是当今中国第一世界数一数二的云计算服务商，和amazon走的路也有点像。

3、关于动态库存
淘宝秒杀天猫魔盒的时候，只有一个商品(行话叫做SKU)，它的库存是15000个。有一个人秒杀到了，库存就减1，19秒卖完的，一秒要成功产生789个订单(下订单的请求可能是8万个，只是可能啊，非实际数字，也可能是1万个，用于说明一下壮观程度)，想象一下，你在广场上卖火车票，一秒钟有8万人举着钱对你喊：卖给我！
大家都知道，比秒小的时间单位还有毫秒、皮秒、飞秒，但交易系统登记一个交易可不像原子绕着原子核跑一圈那么简单，它要做这些事：检查是否恶意访问、取到系统时间、取到顾客默认收货地址、核对顾客秒杀资格(当时的规定是天猫T2.T3达人)、生成订单号、把顾客ID系统时间订单号收货地址写入订单系统、扣除顾客天猫积分、商品库存减一、给顾客打标记(每人只能秒一个，下次不能秒了)等等。
这每一件事都要花费毫秒级别的时间，这些操作加起来的时间可能是接近1秒级别的，但由于淘宝的服务器比较强悍，而且采用了分布式和集群技术，结果比1秒理想一点，但即使有1万台服务器，也不能把这个时间稀释成万分之一秒，因为，商品只有一种，它有15000个库存，对应的数据库记录只有一行，所有的交易请求都要到这里来处理。
能不能把这15000个拆分成5000个商品并分配到5000台服务器上呢？那样不就可以5000台服务器同时处理了吗？答案是不能，首先，5000个商品，意味着有5000个商品详情页，5000个购买按钮，这对前期的营销、引流是个灾难，基本上就没法做引流入口了，显然这违背了商业管理原则，人为增加了信息混乱程度。
其次，天猫魔盒秒杀也不是啥大事，即使按官方标价399元来计算，也就6百万的交易，如果6百万的交易要花费那么大的配套成本，那就太不划算了。
再次，淘宝有十几亿商品，这十几亿商品的展示交易和管理，本来就是分布到上万台服务器上去了，没有必要再把每个商品按库存拆成多个商品了。
这789人抢到了，还不一定会付款(99积分换天猫魔盒还好一点，不需要去网银，成本也极低，大部分是会付款的，3999秒杀iPhone5S就不一定，有人可能网银有问题，有人可能改变主意不想要了)，所以就又带来订单取消重新恢复库存的问题，还有想要的消费者们，会认为还有机会，继续在前台刷一会儿，最终这个秒杀会被热情的消费者们猛刷30秒到1分钟。
一分钟过去了，服务器终于可以喘口气了吧？等等，还有超卖，原来，某两台服务器在同一毫秒都拿到了锁，都去减了库存，15000个库存，被下了15500个订单，又得取消一部分订单，如果采用单线程独占锁，是可以做到同时只有一个服务器线程减库存的，但那样就对并发高峰的能力就差了好多了。
8万人举着钱，可能只有8个人能下单成功，这个拥挤狂热的抢购就要持续10分钟以上，平时秒个天猫魔盒，10分钟也就10分钟吧，双十一就惨了，收银台一下子减少了90%，还想做到350亿，要么做梦，要么再加10倍服务器和带宽。
所以，商业是不完美的，要在绝对正确和绝对的快速之间做个取舍，保证相对快速又极为正确，允许一定的库存错误和超卖(具体允许多少我也不知道)。

4、关于12306网站的数据库设计
好了，讲了这半天淘宝，我们再来说说12306了吧！
我以北京西到深圳北的G71次高铁为例(这里只考虑南下的方向，不考虑深圳北到北京西的，那是另外一个车次，叫G72)，它有17个站(北京西是01号站，深圳北是17号站)，3种座位(商务、一等、二等)。
表面看起来，这不就是3个商品吗？G71商务座、G71一等座、G71二等座，大部分轻易喷12306的技术人员(包括某些中等规模公司的专家、CTO)就是在这里栽第一个跟头的。
实际上，G71有136*3=408种商品(408个SKU)，怎么算来的呢？
如果卖北京西始发的，有16种卖法(因为后面有16个站)，北京西到：保定、石家庄、郑州、武汉、长沙、广州、虎门、深圳……，都是一个独立的商品，同理，石家庄上车的，有15种下车的可能，以此类推，单以上下车的站来计算，有136种票：16+15+14…+2+1=136，每种票都有3种座位，一共是408个商品。
好了，再看出票时怎么减库存，由于商务、一等、二等三种座位数是独立的，库存操作也是一样的，下文我就不再提座位的差别的，只讨论出发与到达站。
另外，马海祥跟大家提升一下，下文说的是理论世界的模型，不是说12306的数据库就是这么设计的。
旅客A买了一张北京西(01号站)到保定东(02号站)的，那“北京西到保定东”这个商品的库存就要减一，同时，北京西到石家庄、郑州、武汉、长沙、广州、虎门、深圳等15个站台的商品库存也要减一，也就是说，出一张北京到保定东的票，实际上要减16个商品的库存。
这还不是最复杂的，如果旅客B买了一张北京西(01号站)到深圳北(17号站)的票，除了“北京西到深圳北”这个商品的库存要减一，北京西到保定东、石家庄、郑州、武汉、长沙、广州、虎门等15个站台的商品库存也要减1，保定东到石家庄、郑州、武汉、长沙、广州、虎门、深圳北等15个站台的商品库存要减1，总计要减库存的商品数是16+15+14+……+1=120个。
当然，也不是每一张票都的库存都完全这样实时计算，可以根据往年的运营情况，在黄金周这样的高峰时段，预先对票做一些分配，比如北京到武汉的长途多一点，保定到石家庄的短途少一点，我没有证据证实铁道部这样做了，但马海祥相信，在还没有12306网站的时候，铁道部就有这种人工预分配的策略了。
想象一下，8万人举着钱对你高喊：卖给我！你好不容易在钱堆里找到一只手，拿了他的钱，转身找120个同事，告诉他们减库存，而这120个同事也和你一样被8万人围着，也和你一样，每卖出一个商品要找几十个人减库存……，这就是12306动态库存的变态之处，比你平时买东西的任何网站的库存机制都复杂几十上百倍。

5、关于抢票插件对12306网站的影响
再说一下抢票插件（此前，我也曾在马海祥博客《从12306网站改版来看浏览器产品差异化发展》的一文中跟大家说个抢票插件与浏览器的共生的平衡状态），机器永远比人快，当你好不容易从8万人里突出重围，来到了柜台前，你发现，我操，来了10万根绑着钱的竹竿，而且当有退票出来的时候，你要闯过3层人肉才能接近柜台，竹竿在8个人身后一伸，钱就到了柜台前，你低头看了一眼手机，票就没了，竹竿却永远在那里伸着，永不低头，永不眨眼，如果没有这10万根竹竿，虽然你很可能还是抢不到票，但不至于沮丧成这样：我TM为什么总是手最慢的一个！
防机器人抢票，也不是加个图片验证码那么简单，我写过文章系统性分析过，图片验证码有6种机器暴力破解的办法，抢票插件用的是我说的第三种，OCR识别(光学字符识别)。
Google采用的Wave波形字母已经能比较好地防住机器OCR了，ems上的验证码就是反面教材，机器OCR成功率接近100%，12306的比ems的图片验证码强一点，不过，验证码设置得复杂一点吧！
接下来，人们就要喷了：这只是便宜大学生和办公室白领，农民工连26个字母都认不齐，怎么搞？搞动画验证码吧，也有人喷，视力不好的人怎么办？最后验证码搞得太简单了，皆大欢喜了，其实最高兴的是开发抢票插件的公司。
就算采用了机器完全不可能识别的验证码，也防不住社会工程学的破解办法，招募一堆网吧打游戏的青少年朋友，每成功输入50个验证码给1块钱，或者等值的虚拟货币、游戏装备，我保证想赚这个钱的人数不胜数，这点钱对转卖车票的利润而言，是可以接受的成本。
以上讨论只是把12306当成和淘宝一样没有历史包袱从零起步的交易系统，实际上，它不是，它后面的票池，还有电话售票、火车站售票、代售点售票等多个传统渠道要服务。
除了客运服务，12306还有全国最大(很可能也是全球最大)的大宗物资货运系统。


41 如何实现一个秒杀系统，保证只有几位用户能买到某件商品？
什么是秒杀
秒杀场景一般会在电商网站举行一些活动或者节假日在12306网站上抢票时遇到。对于电商网站中一些稀缺或者特价商品，电商网站一般会在约定时间点对其进行限量销售，因为这些商品的特殊性，会吸引大量用户前来抢购，并且会在约定的时间点同时在秒杀页面进行抢购。
秒杀系统场景特点
秒杀时大量用户会在同一时间同时进行抢购，网站瞬时访问流量激增。 
秒杀一般是访问请求数量远远大于库存数量，只有少部分用户能够秒杀成功。
秒杀业务流程比较简单，一般就是下订单减库存。
秒杀架构设计理念
限流： 鉴于只有少部分用户能够秒杀成功，所以要限制大部分流量，只允许少部分流量进入服务后端。
削峰：对于秒杀系统瞬时会有大量用户涌入，所以在抢购一开始会有很高的瞬间峰值。高峰值流量是压垮系统很重要的原因，所以如何把瞬间的高流量变成一段时间平稳的流量也是设计秒杀系统很重要的思路。实现削峰的常用的方法有利用缓存和消息中间件等技术。
异步处理：秒杀系统是一个高并发系统，采用异步处理模式可以极大地提高系统并发量，其实异步处理就是削峰的一种实现方式。
内存缓存：秒杀系统最大的瓶颈一般都是数据库读写，由于数据库读写属于磁盘IO，性能很低，如果能够把部分数据或业务逻辑转移到内存缓存，效率会有极大地提升。
可拓展：当然如果我们想支持更多用户，更大的并发，最好就将系统设计成弹性可拓展的，如果流量来了，拓展机器就好了。像淘宝、京东等双十一活动时会增加大量机器应对交易高峰。
架构方案
一般秒杀系统架构

设计思路
将请求拦截在系统上游，降低下游压力：秒杀系统特点是并发量极大，但实际秒杀成功的请求数量却很少，所以如果不在前端拦截很可能造成数据库读写锁冲突，甚至导致死锁，最终请求超时。 
充分利用缓存：利用缓存可极大提高系统读写速度。 
消息队列：消息队列可以削峰，将拦截大量并发请求，这也是一个异步处理过程，后台业务根据自己的处理能力，从消息队列中主动的拉取请求消息进行业务处理。
前端方案
浏览器端(js)：
页面静态化：将活动页面上的所有可以静态的元素全部静态化，并尽量减少动态元素。通过CDN来抗峰值。 
禁止重复提交：用户提交之后按钮置灰，禁止重复提交 
用户限流：在某一时间段内只允许用户提交一次请求，比如可以采取IP限流
后端方案
服务端控制器层(网关层)
限制uid（UserID）访问频率：我们上面拦截了浏览器访问的请求，但针对某些恶意攻击或其它插件，在服务端控制层需要针对同一个访问uid，限制访问频率。
服务层
上面只拦截了一部分访问请求，当秒杀的用户量很大时，即使每个用户只有一个请求，到服务层的请求数量还是很大。比如我们有100W用户同时抢100台手机，服务层并发请求压力至少为100W。

采用消息队列缓存请求：既然服务层知道库存只有100台手机，那完全没有必要把100W个请求都传递到数据库啊，那么可以先把这些请求都写到消息队列缓存一下，数据库层订阅消息减库存，减库存成功的请求返回秒杀成功，失败的返回秒杀结束。
利用缓存应对读请求：对类似于12306等购票业务，是典型的读多写少业务，大部分请求是查询请求，所以可以利用缓存分担数据库压力。
利用缓存应对写请求：缓存也是可以应对写请求的，比如我们就可以把数据库中的库存数据转移到Redis缓存中，所有减库存操作都在Redis中进行，然后再通过后台进程把Redis中的用户秒杀请求同步到数据库中。
数据库层
数据库层是最脆弱的一层，一般在应用设计时在上游就需要把请求拦截掉，数据库层只承担“能力范围内”的访问请求。所以，上面通过在服务层引入队列和缓存，让最底层的数据库高枕无忧。
案例：利用消息中间件和缓存实现简单的秒杀系统
Redis是一个分布式缓存系统，支持多种数据结构，我们可以利用Redis轻松实现一个强大的秒杀系统。
我们可以采用Redis 最简单的key-value数据结构，用一个原子类型的变量值(AtomicInteger)作为key，把用户id作为value，库存数量便是原子变量的最大值。对于每个用户的秒杀，我们使用 RPUSH key value插入秒杀请求， 当插入的秒杀请求数达到上限时，停止所有后续插入。
然后我们可以在台启动多个工作线程，使用 LPOP key 读取秒杀成功者的用户id，然后再操作数据库做最终的下订单减库存操作。
当然，上面Redis也可以替换成消息中间件如ActiveMQ、RabbitMQ等，也可以将缓存和消息中间件 组合起来，缓存系统负责接收记录用户请求，消息中间件负责将缓存中的请求同步到数据库。


42 有关注哪些新的技术？
云计算，人工智能，区块链，大数据

43 hash算法的实现原理，hashcode的实现原理？
       Hash，一般翻译做“散列”，也有直接音译为“哈希”的，就是把任意长度的输入，通过散列算法，变换成固定长度的输出，该输出就是散列值。
       散列表,它是基于快速存取的角度设计的，也是一种典型的“空间换时间”的做法。顾名思义，该数据结构可以理解为一个线性表，但是其中的元素不是紧密排列的，而是可能存在空隙。
       散列表（Hash table，也叫哈希表），是根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。

 
hash函数的选择
        哈稀函数按照定义可以实现一个伪随机数生成器(PRNG)，从这个角度可以得到一个公认的结论：哈希函数之间性能的比较可以通过比较其在伪随机生成方面的比较来衡量。

       一般来说，对任意一类的数据存在一个理论上完美的哈希函数。这个完美的哈希函数定义是没有发生任何碰撞，这意味着没有出现重复的散列值。在现实中它很难找到一个完美的哈希散列函数，而且这种完美函数的趋近变种在实际应用中的作用是相当有限的。在实践中人们普遍认识到，一个完美哈希的哈希函数，就是在一个特定的数据集上产生的的碰撞最少哈希的函数。
       我们所能做的就是通过试错方法来找到满足我们要求的哈希函数。可以从下面两个角度来选择哈希函数：
1.数据分布
       一个衡量的措施是考虑一个哈希函数是否能将一组数据的哈希值进行很好的分布。要进行这种分析，需要知道碰撞的哈希值的个数，如果用链表来处理碰撞，则可以分析链表的平均长度，也可以分析散列值的分组数目。
2.哈希函数的效率
       另个一个衡量的标准是哈希函数得到哈希值的效率。通常，包含哈希函数的算法的算法复杂度都假设为O(1)，这就是为什么在哈希表中搜索数据的时间复杂度会被认为是"平均为O(1)的复杂度"，而在另外一些常用的数据结构，比如图(通常被实现为红黑树)，则被认为是O(logn)的复杂度。
       一个好的哈希函数必须在理论上非常的快、稳定并且是可确定的。通常哈希函数不可能达到O(1)的复杂度，但是哈希函数在字符串哈希的线性的搜索中确实是非常快的，并且通常哈希函数的对象是较小的主键标识符，这样整个过程应该是非常快的，并且在某种程度上是稳定的。
       在这篇文章中介绍的哈希函数被称为简单的哈希函数。它们通常用于散列（哈希字符串）数据。它们被用来产生一种在诸如哈希表的关联容器使用的key。这些哈希函数不是密码安全的，很容易通过颠倒和组合不同数据的方式产生完全相同的哈希值。
    
hash方法学
1.基于加法和乘法的散列
       这种方式是通过遍历数据中的元素然后每次对某个初始值进行加操作，其中加的值和这个数据的一个元素相关。通常这对某个元素值的计算要乘以一个素数。

2.基于移位的散列
       和加法散列类似，基于移位的散列也要利用字符串数据中的每个元素，但是和加法不同的是，后者更多的而是进行位的移位操作。通常是结合了左移和右移，移的位数的也是一个素数。每个移位过程的结果只是增加了一些积累计算，最后移位的结果作为最终结果。


hash构造方法
    1. 直接寻址法：取关键字或关键字的某个线性函数值为散列地址。即H(key)=key或H(key) = a?key + b，其中a和b为常数（这种散列函数叫做自身函数）
　　2. 数字分析法：分析一组数据，比如一组员工的出生年月日，这时我们发现出生年月日的前几位数字大体相同，这样的话，出现冲突的几率就会很大，但是我们发现年月日的后几位表示月份和具体日期的数字差别很大，如果用后面的数字来构成散列地址，则冲突的几率会明显降低。因此数字分析法就是找出数字的规律，尽可能利用这些数据来构造冲突几率较低的散列地址。
　　3. 平方取中法：取关键字平方后的中间几位作为散列地址。
　　4. 折叠法：将关键字分割成位数相同的几部分，最后一部分位数可以不同，然后取这几部分的叠加和（去除进位）作为散列地址。
　　5. 随机数法：选择一随机函数，取关键字的随机值作为散列地址，通常用于关键字长度不同的场合。
　　6. 除留余数法：取关键字被某个不大于散列表表长m的数p除后所得的余数为散列地址。即 H(key) = key MOD p, p<=m。不仅可以对关键字直接取模，也可在折叠、平方取中等运算之后取模。对p的选择很重要，一般取素数或m，若p选的不好，容易产生同义词。

hash冲突及解决


hash冲突在所难免，解决冲突是一个复杂问题。冲突主要取决于：
       （1）与散列函数有关，一个好的散列函数的值应尽可能平均分布。
       （2）与解决冲突的哈希冲突函数有关。
       （3）与负载因子的大小。太大不一定就好，而且浪费空间严重，负载因子和散列函数是联动的。
解决冲突的办法：
       （1）开放定址法：线性探查法、平方探查法、伪随机序列法、双哈希函数法。
       （2）拉链法：把所有同义词，即hash值相同的记录，用单链表连接起来。

哈希函数和素数
       没有人可以证明素数和伪随机数生成器之间的关系，但是目前来说最好的结果使用了素数。伪随机数生成器现在是一个统计学上的东西，不是一个确定的实体，所以对其的分析只能对整个的结果有一些认识，而不能知道这些结果是怎么产生的。

       围绕着哈希函数中的素数的使用的基本的概念是，利用一个素数来改变处理的哈希函数的状态值，而不是使用其他类型的数。处理这个词的意思就是对哈希值进行一些简单的操作，比如乘法和加法。这样得到的一个新的哈希值一定要在统计学上具有更高的熵，也就是说不能有为偏向。简单的说，当你用一个素数去乘一堆随机数的时候，得到的数在bit这个层次上是1的概率应该接近0.5。没有具体的证明这种不便向的现象只出现在使用素数的情况下，这看上去只是一个自我宣称的直觉上的理论，并被一些业内人士所遵循。
       决定什么是正确的，甚至更好的方法和对散列素数的使用最好的组合仍然是一个很有黑色艺术。没有单一的方法可以宣称自己是最终的通用散列函数。最好的一所能做的就是通过试错演进和获得适当的散列算法，以满足其需要的统计分析方法。

应用领域

       哈希是一个在现实世界中将数据映射到一个标识符的工具，下面是哈希函数的一些常用领域：

1.字符串哈希
       在数据存储领域，主要是数据的索引和对容器的结构化支持，比如哈希表。
2.加密哈希
       用于数据/用户核查和验证。一个强大的加密哈希函数很难从结果再得到原始数据。加密哈希函数用于哈希用户的密码，用来代替密码本身存在某个服务器撒很难过。加密哈希函数也被视为不可逆的压缩功能，能够代表一个信号标识的大量数据，可以非常有用的判断当前的数据是否已经被篡改(比如MD5)，也可以作为一个数据标志使用，以证明了通过其他手段加密文件的真实性。
3.几何哈希
       这个哈希表用于在计算机视觉领域，为在任意场景分类物体的探测。最初选择的过程涉及一个地区或感兴趣的对象。几何散列包括各种汽车分类的重新检测中任意场景的目的，典型的例子。检测水平可以多种多样，从刚检测是否是车辆，到特定型号的车辆，在特定的某个车辆。
4.布隆过滤器
       布隆过滤器允许一个非常大范围内的值被一个小很多的内存锁代表。在计算机科学，这是众所周知的关联查询，并在关联容器的核心理念。
Bloom Filter的实现通过多种不同的hash函数使用，也可通过允许一个特定值的存在有一定的误差概率会员查询结果的。布隆过滤器的保证提供的是，对于任何会员国的查询就永远不会再有假阴性，但有可能是假阳性。假阳性的概率可以通过改变控制为布隆过滤器，并通过不同的hash函数的数量所使用的表的大小。
       随后的研究工作集中在的散列函数和哈希表以及Mitzenmacher的布隆过滤器等领域。建议对这种结构，在数据被散列熵最实用的用法有助于哈希函数熵，这是理论成果上缔结一项最佳的布隆过滤器（一个提供给定一个最低的进一步导致假阳性的可能性表的大小或反之亦然）提供假阳性的概率定义用户可以建造最多也作为两种截然不同的两两独立的哈希散列函数已知功能，大大提高了查询效率的成员。
布隆过滤器通常存在于诸如拼写检查器，字符串匹配算法，网络数据包分析工具和网络/ Internet缓存的应用程序。
5.Hash算法在信息安全方面的应用主要体现在以下的3个方面：
　　（1) 文件校验
　　我们比较熟悉的校验算法有奇偶校验和CRC校验，这2种校验并没有抗数据篡改的能力，它们一定程度上能检测并纠正数据传输中的信道误码，但却不能防止对数据的恶意破坏。
　　MD5 Hash算法的"数字指纹"特性，使它成为目前应用最广泛的一种文件完整性校验和(Checksum)算法，不少Unix系统有提供计算md5 checksum的命令。
　　（2) 数字签名
　　Hash 算法也是现代密码体系中的一个重要组成部分。由于非对称算法的运算速度较慢，所以在数字签名协议中，单向散列函数扮演了一个重要的角色。 对 Hash 值，又称"数字摘要"进行数字签名，在统计上可以认为与对文件本身进行数字签名是等效的。而且这样的协议还有其他的优点。
　　（3) 鉴权协议
　　如下的鉴权协议又被称作挑战--认证模式：在传输信道是可被侦听，但不可被篡改的情况下，这是一种简单而安全的方法。





HashCode定义
（1）HashCode的存在主要是用于查找的快捷性，如Hashtable，HashMap等，HashCode是用来在散列存储结构中确定对象的存储地址的；
（2）如果两个对象相同， equals方法一定返回true，并且这两个对象的HashCode一定相同；
（3）如果对象的equals方法被重写，那么对象的HashCode也尽量重写，并且产生HashCode使用的对象，一定要和equals方法中使用的一致，否则就会违反上面提到的第2点；
（4）两个对象的HashCode相同，并不一定表示两个对象就相同，也就是equals方法不一定返回true，只能够说明这两个对象在散列存储结构中，如Hashtable，他们存放在同一个篮子里。
HashCode作用
Java中的集合（Collection）有两类，一类是List，再有一类是Set。前者集合内的元素是有序的，元素可以重复；后者元素无序，但元素不可重复。 equals方法可用于保证元素不重复，但是，如果每增加一个元素就检查一次，如果集合中现在已经有1000个元素，那么第1001个元素加入集合时，就要调用1000次equals方法。这显然会大大降低效率。 
于是，Java采用了哈希表的原理。
哈希算法也称为散列算法，是将数据依特定算法直接指定到一个地址上。
这样一来，当集合要添加新的元素时，先调用这个元素的HashCode方法，就一下子能定位到它应该放置的物理位置上。
（1）如果这个位置上没有元素，它就可以直接存储在这个位置上，不用再进行任何比较了；
（2）如果这个位置上已经有元素了，就调用它的equals方法与新元素进行比较，相同的话就不存了；
（3）不相同的话，也就是发生了Hash key相同导致冲突的情况，那么就在这个Hash key的地方产生一个链表，将所有产生相同HashCode的对象放到这个单链表上去，串在一起（很少出现）。这样一来实际调用equals方法的次数就大大降低了，几乎只需要一两次。 
如何理解HashCode的作用：
从Object角度看，JVM每new一个Object，它都会将这个Object丢到一个Hash表中去，这样的话，下次做Object的比较或者取这个对象的时候（读取过程），它会根据对象的HashCode再从Hash表中取这个对象。这样做的目的是提高取对象的效率。若HashCode相同再去调用equal。


44 继承与组合的区别，使用场景？
首先它们都是实现系统功能重用，代码复用的最常用的有效的设计技巧，都是在设计模式中的基础结构。相信大家已了解的，类继承允许我们根据自己的实现来覆盖重写父类的实现细节，父类的实现对于子类是可见的，所以我们一般称之为白盒复用。对象持有（其实就是组合）要求建立一个号的接口，但是整体类和部分类之间不会去关心各自的实现细节，即它们之间的实现细节是不可见的，故成为黑盒复用。
     继承是在编译时刻静态定义的，即是静态复用，在编译后子类和父类的关系就已经确定了。而组合这是运用于复杂的设计，它们之间的关系是在运行时候才确定的，即在对对象没有创建运行前，整体类是不会知道自己将持有特定接口下的那个实现类。在扩展方面组合比集成更具有广泛性。
    继承中父类定义了子类的部分实现，而子类中又会重写这些实现，修改父类的实现，设计模式中认为这是一种破坏了父类的封装性的表现。这个结构导致结果是父类实现的任何变化，必然导致子类的改变。然而组合这不会出现这种现象。
    对象的组合还有一个优点就是有助于保持每个类被封装，并被集中在单个任务上（类设计的单一原则）。这样类的层次结构不会扩大，一般不会出现不可控的庞然大类。而累的继承就可能出来这些问题，所以一般编码规范都要求类的层次结构不要超过3层。组合是大型系统软件实现即插即用时的首选方式。
 最后还说一句，“优先使用对象组合，而不是继承”是面向对象设计的第二原则。但并不是说什么都设计都用组合，只是优先考虑组合，更不是说继承即使不好的设计，应该用组合，应为他们之间也有各自的优势。下面是他们之间的优缺点比比较表：

组 合 关 系	继 承 关 系
优点：不破坏封装，整体类与局部类之间松耦合，彼此相对独立	缺点：破坏封装，子类与父类之间紧密耦合，子类依赖于父类的实现，子类缺乏独立性
优点：具有较好的可扩展性	缺点：支持扩展，但是往往以增加系统结构的复杂度为代价
优点：支持动态组合。在运行时，整体对象可以选择不同类型的局部对象	缺点：不支持动态继承。在运行时，子类无法选择不同的父类
优点：整体类可以对局部类进行包装，封装局部类的接口，提供新的接口	缺点：子类不能改变父类的接口
缺点：整体类不能自动获得和局部类同样的接口	优点：子类能自动继承父类的接口
缺点：创建整体类的对象时，需要创建所有局部类的对象	优点：创建子类的对象时，无须创建父类的对象



45 使用静态工厂方法的好处和坏处？
静态工厂方法的优缺点分析
先看一个Boolean(基本类型boolean的包装类)的简单示例

public static Boolean valueOf(boolean b){
    return b?Boolean.TRUE :Boolean.FALSE;
}

静态工厂方法的优点：
    静态方法有名称具有适当名称的静态工厂方法更易于阅读，而构造器的参数本身没有确切描述被返回的对象。如：BigInteger(int, int, Random)返回的BigInteger可能为素数，如果使用BigInteger.probablePrime的静态方法来表示，就更为清楚。
    不必在每次调用类时都创建一个新对象对于不可变类可以使用预先构建好的实例，或则将构建好的实例缓存起来，进行重新复用。
    可以返回原返回类型的任何子类型的对象
我们在选择返回对象的类时，使用静态工厂方法就更有灵活性。这种灵活性的一种应用是API可以返回对象，同时又不会使对象的类变成公有的。这种方式隐藏实现类会使API变得非常简洁。
在Java的集合框架的接口实现中，几乎所有这些实现都通过静态工厂方法在一个不可实例化的类中导出，所有返回对象的类都是非公有的。
公有的静态工厂方法所返回的对象的类不仅可以是非公有的，还可以随着参数值的不同而每次调用也发生变化。只要是已声明的返回类型的子类型，都是允许的。

    在创建参数化类型实例时，代码更加简洁
调用参数化类的构造器时，即使类型参数很明显，也必须指明，这通常要求你接连两次提供类型参数。例如创建HashMap的实例。
随着类型参数变得越来越长，冗长的说明也很快变得痛苦起来，但是使用静态工厂方法，编译器就可以替你找到类型参数，这被称作类型推导.
Google的Guava集合框架中提供了类似的Lists.newArrayList的方法。可以试着比较下面两个代码：
Map<String, List<String>> map = new HashMap<String, List<String>>();
Map<String, List<String> map =Maps.newHashMap();


下面的写法显然更简便。
静态工厂方法的缺点

一个类如果不含公有的或者受保护的构造器，就不能被子类化。其次静态工厂方法与其他静态方法实际上没有任何区别。Javadoc工具不会区别出静态工厂方法，所有静态工厂方法命名应当遵守标准的命名习惯来弥补这一劣势。惯用名称有：valeuOf，of，getInstance，getType，newType等。


46 排序算法有哪些？他们是时间复杂度是多少？

1、归并排序每次递归都要用到一个辅助表，长度与待排序的表长度相同，虽然递归次数是O(log2n)，但每次递归都会释放掉所占的辅助空间，
2、快速排序空间复杂度只是在通常情况下才为O(log2n)，如果是最坏情况的话，很显然就要O(n)的空间了。当然，可以通过随机化选择pivot来将空间复杂度降低到O(log2n)。
相关概念：
1、时间复杂度
     时间复杂度可以认为是对排序数据的总的操作次数。反映当n变化时，操作次数呈现什么规律。
     常见的时间复杂度有：常数阶O(1),对数阶O(log2n),线性阶O(n), 线性对数阶O(nlog2n),平方阶O(n2)
     时间复杂度O(1)：算法中语句执行次数为一个常数，则时间复杂度为O(1),
2、空间复杂度
    空间复杂度是指算法在计算机内执行时所需存储空间的度量，它也是问题规模n的函数
    空间复杂度O(1)：当一个算法的空间复杂度为一个常量，即不随被处理数据量n的大小而改变时，可表示为O(1)
    空间复杂度O(log2N)：当一个算法的空间复杂度与以2为底的n的对数成正比时，可表示为O(log2n)
                                 ax=N，则x=logaN，
    空间复杂度O(n)：当一个算法的空间复杂度与n成线性比例关系时，可表示为0(n).


47 spring的IOC、AOP的使用场景？ 
（1）AOP用来封装横切关注点，具体可以在下面的场景中使用：
Authentication 权限
Caching 缓存
Context passing 内容传递
Error handling 错误处理
Lazy loading 懒加载
Debugging 调试
logging, tracing, profiling and monitoring 记录跟踪 优化 校准
Performance optimization 性能优化
Persistence 持久化
Resource pooling 资源池
Synchronization 同步
Transactions 事务

（2）IOC使用场景
在 Java EE企业应用开发中，前面介绍的IoC（控制反转）设计模式，是解耦组件之间复杂关系的利器，Spring IoC模块就是这个模式的一种实现。

 在EJB模式中，应用开发人员需要编写EJB组件，而这种组件需要满足EJB容器的规范，才能运行在EJB容器中，从而获取事务管理、生命周期管理这些组件开发的基本服务。
从获取的基本服务上看，Spring提供服务和EJB容器提供的服务并没有太大的差别，只是在具体怎样获取服务的方式上，两者的设计有很大的不同：在Spring中，Spring IoC提供了一个基本的JavaBean容器，通过IoC模式管理依赖关系，并通过依赖注入和AOP切面增强了为JavaBean这样的POJO对象赋予事务管理、生命周期管理等基本功能；而对于EJB，一个简单的EJB组件需要编写远程/本地接口、Home接口以及Bean的实现类，而且EJB运行是不能脱离EJB容器的，查找其他EJB组件也需要通过诸如JNDI这样的方式，从而造成对EJB容器和技术规范的依赖。也就是说Spring把EJB组件还原成了POJO对象或者JavaBean对象，降低了应用开发对传统J2EE技术规范的依赖。

同时，在应用开发中，以应用开发人员的身份设计组件时，往往需要引用和调用其它组件的服务，这种依赖关系如果固化在组件设计中，就会造成依赖关系的僵化和维护难度的增加，这个时候，如果使用IoC容器，把资源获取的方向反转，让IoC容器主动管理这些依赖关系，将这些依赖关系注入到组件中，那么会让这些依赖关系的适配和管理更加灵活。
在具体的注入实现中，接口注入（Type 1 IoC）,setter注入（Type 2 IoC）,构造器注入（Type 3 IoC）是主要的注入方式。在Spring的IoC设计中，setter注入和构造器注入是主要的注入方式；相对而言，使用Spring时setter注入是常见的注入方式，而且为了防止注入异常，Spring IoC容器还提供了对特定依赖的检查。

另一方面，在应用管理依赖关系时，可以通过IoC容器将控制进行反转，在反转的实现中，如果能通过文本来完成配置，并且还能通过工具对这些配置信息进行可视化的管理和浏览，那么肯定是能够提高对组件关系的管理水平，并且如果耦合关系需要变动，并不需要重新修改和编译Java源码，这符合在面向对象设计中的开闭准则，并且能够提高组件系统设计的灵活性，同时，如果结合OSGi的使用特性，还可以提高应用的动态部署能力。

在具体使用Spring IoC容器的时候，我们可以看到，Spring IoC容器已经是一个产品实现。作为产品实现，它对多种应用场景的适配是通过Spring设计的IoC容器系列来实现的，比如在某个容器系列中可以看到各种带有不同容器特性的实现，可以读取不同配置信息的各种容器，从不同I/O源读取读取配置信息的各种容器设计，更加面向框架的容器应用上下文的容器设计等。



48 宕机的原因有哪几种，怎么样分析宕机的原因？
首先我们要对服务器宕机事件按表现方式而非导致的原因进行分类。一般来说，“运行环境”是排名第一的服务器宕机类别，大约35%的时间属于这一类。运行环境可以看作是支持数据库服务器运行的系统和资源集合，包括操作系统、硬件以及网络等。性能问题紧随其后，也是约占35%；然后是复制；最后剩下的10%包含各种类型的数据丢失或损坏，以及其他问题。
我们对服务器宕机事件按类型进行分类后，才能够确定了导致这些事件的原因。以下是一些可能引发服务器宕机的地方。
1、服务器环境的客观原因
比较常见的是机房突然断电，或者是温度过高，服务器就会出现死机、关机的情况，不过这种情况一般是不会发生的，正规的idc商会做好预防措施，备用电路和发电机，以及智能恒温系统都可以预防这种情况的发生。
2、服务器不堪负重
这是一种比较常见的情况，由于网站的流量突然大量增加，或者是受攻击、程序中毒等，都可以发生这种故障。因为流量的突增会让服务器资源耗尽，造成死机的情况。
3、不合理的应用
这种一般是公司为了减少成本的投入，租用一些价格比较低的主机，这些服务器的配置一般是很低的，但是在主机上安装一些与网站建设没有关系的大型软件，这样就会造成服务器超负荷，就会发生宕机的情况。
服务器宕机不仅仅上上面我们所说的几个原因，还有很多的细节也能导致这种情况，比如环境配置、错误程序、数据库丢失等也是其中的因素。 
4、在运行环境的问题中，最普遍的问题时磁盘空间耗尽。
5、在性能问题中，最普通的服务器宕机原因确实是运行很糟糕的SQL，但也不一定都是这个原因，比如也有很多问题时由于服务器Bug或错误的行为导致的。
6、糟糕的Schema和索引设计是第二大影响性能的问题。
7、复制问题通常由于主备数据不一致导致。
8、数据丢失问题通常由于drop  table的错误操作导致，并总是便随着缺少可用备份的问题。 


49 支付宝怎么样保证他的安全？
支付宝采用了HTTPS加密传输,是无法抓包解密的。
攻击者修改了本地系统订单状态是你自己的业务逻辑与支付宝无关,为保证业务安全,你可以在点击发货时向支付宝接口查询交易状态,若未付款则拒绝。
第二种,第二天下载交易数据进行比对。
另外不要用同步通知URL来修改订单状态。

对称加密/非对称加密 

50 谈谈对OOP、IOC、AOP的设计理念的理解？
AOP，他是一种思想，是OOP的延展。
说OOP就来说下之前的OPP，最早开始的程序，一个函数（方法）或者说是功能做一个事情，这种思想划分的是一个功能一个功能的来组合解决问题。
后来人们发现，功能解决问题是解决了，但是功能太多了，人脑实在是有限，太劳财伤命了，而且跟人们看世界的方法有点差异，人们都习惯把某一类的习性划分一起，作为一个整体研究，而不是把某一个习性放一起，很多个种类的东西都拥有这个习性。
所以就搞了一种OOP来解决问题，这个的好处就是在于把某一类或者说某一种特性的功能组合在一起，赋给抽象的对象，这样跟你我他这种人们的世界观很接近，而且不用研究你啊我啊能干什么，只要知道大家都是人类，人类会有一些通用的什么方法类之类的，而你我具体有些什么嗜好差异，就不管了，这样一来，就能把人力集合起来，各司其职了。脉络就清晰了。
再就是AOP，其实这几个都是人类生产力方式的转变有关，有一定的相通处。这个就更加细化了，他把抽象中的某些方面做了合集，就好比大公司，如果一个经理管理具体细致到人，而且管吃喝住行之类的啥都插一脚，他也很累，而且管得也不够多，但是如果他只管某一个方面的东西，比如大家吃，那样就可以多管很多人，他也能轻松很多，这样就可以找不同的经理来管不同方面，效率又会更加高，所以AOP就出来了，之前的OOP，很多种类，很多抽象的东西，你要调用某个类别的方法，至少要知道他是谁，能干嘛直接去调用，而此时你根本不想知道这些，（比如你要找个洗碗的，你肯定不想了解他能不能吃饭，个子高不高之类的，你只要他能给你干好活就可以了）因为你只关心你要的方法，其余的都是多余的。所以AOP的话，有一个专门的管理者帮你管理你要的方法，一种方面的东西，比如add什么，这样是不更省心省力。

所以说， OPP，OOP，AOP，区别就是"字母不同"！是什么意思，就是什么区别。
然后就是DI和IoC。 这个其实就某人觉得IoC不够响亮 ，所以取了个新名字而已。但是其实也是有区别的
IoC他其实也是个抽象的东西，可能不同的语言有不同的方法来实现这种抽象概念（类似设计模式的一种，现在应该算是一种设计模式了） ，而DI就是实现它的一种比较具体的做法，（例如假如某个语言没有inteface的概念，那么肯定就不会有inteface injection这中注入方式了不）。比如除了DI，工厂模式 也是用来实现IoC的一个办法，只是java有反射机制，那么用DI来实现，耦合性更低更优美。（如果某个语言没有反射，那么工厂模式应该就是用来实现的一个办法了）。

就像AOP可以用 代理模式来 实现一样，差不多的意思。
反正我感觉这些东西就像我刚开始理解 策略和工厂，代理和装饰 之类的设计模式差异一样，比较容易没有清晰的概念，一团团的，要经常琢磨，经常把看到的和写的代码实际套上去论证，慢慢就有点概念了。

总之就是一个容器，或者说一个系统里面命名出来的东西，多看看，先硬记住，然后碰到了又想想，慢慢的思想里面有这个概念了，就差不多开始掌握了，和学数学碰到新符号一样的
发现还忘了理解 AOP和IoC的关系了， 这两个其实是两方面的东西。
IoC就是把使用者要使用的东西的控制权拿到具体使用对象的外面来控制，有一个统一的系统或者说容器控制它，那么当你掌控了对象的时候，自然就有能力来控制它的方法和生死，这样你就可以把某一个方面上的方法对象行成一个面从而控制他，也就可以很好的实现AOP这种思想了。



51 谈谈对主流的J2EE框架（Spring、Struts、Ibatis、Hibernate等），这些框架的局限性在哪儿？在何种情况下会不适合用这些框架？
1.Spring架构图
 Spring 是一个开源框架，是为了解决企业应用程序开发复杂性而创建的。框架的主要优势之一就是其分层架构，分层架构允许您选择使用哪一个组件，同时为 J2EE 应用程序开发提供集成的框架。Spring 框架的功能可以用在任何 J2EE 服务器中，大多数功能也适用于不受管理的环境。Spring 的核心要点是：支持不绑定到特定 J2EE 服务的可重用业务和数据访问对象。这样的对象可以在不同 J2EE 环境 （Web 或 EJB）、独立应用程序、测试环境之间重用。
常见Struts、Hibernate、Spring、J2EE、ibatis、Oracle等开发框架架构图及其简介
组成 Spring 框架的每个模块（或组件）都可以单独存在，或者与其他一个或多个模块联合实现。每个模块的功能如下：

    核心容器：核心容器提供 Spring 框架的基本功能。核心容器的主要组件是 BeanFactory，它是工厂模式的实现。BeanFactory 使用控制反转 （IOC） 模式将应用程序的配置和依赖性规范与实际的应用程序代码分开。
    Spring 上下文：Spring 上下文是一个配置文件，向 Spring 框架提供上下文信息。Spring 上下文包括企业服务，例如 JNDI、EJB、电子邮件、国际化、校验和调度功能。
    Spring AOP： 通过配置管理特性，Spring AOP 模块直接将面向方面的编程功能集成到了 Spring 框架中。所以，可以很容易地使 Spring 框架管理的任何对象支持 AOP。Spring AOP 模块为基于Spring 的应用程序中的对象提供了事务管理服务。通过使用 Spring AOP，不用依赖 EJB 组件，就可以将声明性事务管理集成到应用程序中。
    Spring DAO：JDBC DAO 抽象层提供了有意义的异常层次结构，可用该结构来管理异常处理和不同数据库供应商抛出的错误消息。异常层次结构简化了错误处理，并且极大地降低了需要编写 的异常代码数量（例如打开和关闭连接）。Spring DAO 的面向 JDBC 的异常遵从通用的 DAO 异常层次结构。
    Spring ORM：Spring 框架插入了若干个 ORM 框架，从而提供了 ORM 的对象关系工具，其中包括 JDO、Hibernate 和 iBatis SQL Map。所有这些都遵从 Spring 的通用事务和 DAO 异常层次结构。


2.ibatis架构图
ibatis是一个基于Java的持久层框架。iBATIS提供的持久层框架包括SQL Maps和Data Access Objects（DAO），同时还提供一个利用这个框架开发的JPetStore实例。
常见Struts、Hibernate、Spring、J2EE、ibatis、Oracle等开发框架架构图及其简介

IBATIS：最大的优点是可以有效的控制sql发送的数目，提高数据层的执行效率！它需要程序员自己去写sql语句，不象hibernate那样是完全面向对象的，自动化的，ibatis是半自动化的，通过表和对象的映射以及手工书写的sql语句，能够实现比hibernate等更高的查询效率。
Ibatis只是封装了数据访问层，替我们做了部分的对象关系映射。但代价是必须要写xml配置文件，相对于Hibernate还要写很多sql。Hibernate通过工具直接从数据库模式生成实体类和基本的配置文件，而且大部分情况下不需要我们写sql，会较大的提升开发效率。但这些也有很多的局限性，尤其是对环境的要求较高（数据库设计，对象设计，团队的协作等）。 个人感觉Ibatis对项目比较有意义的地方在于它小巧灵活，可扩展，封装了数据访问层（事务，缓存，异常，日志），并提供了DAO框架支持。
利用Ibatis我们可以做到代码和sql的分离，只要sql能够解决的问题，Ibatis就能帮我们较容易的解决，同时也使我们的项目对某一框架的依赖性变小（因为Ibatis是非侵入性的）。这将极大的降低项目风险，减少解决复杂问题的时间，使项目的维护变得简单。
Ibatis对于应用的修改，调试，扩充和维护将会变得容易自然。修改时，我们主要修改的是代表模型的实体对象，xml配置文件中的sql，和/或配置文件的ResultMap（很多时候是不需要的）。同时，sql和代码分离，我们不用在代码的StringBuffer的append方法之间寻找需要修改的sql。配置文件中的sql便利了我们的调试和对sql的评审及以后的sql重用。


3.structs1架构图
Struts是Apache 基金会Jakarta 项目组的一个Open Source 项目，它采用MVC模式，能够很好地帮助java 开发者利用J2EE开发Web应用。和其他的java架构一样，Struts 也是面向对象设计，将MVC模式"分离显示逻辑和业务逻辑"的能力发挥得淋漓尽致。Structs 框架的核心是一个弹性的控制层，基于如 Java Servlets，JavaBeans，ResourceBundles与XML等标准技术，以及 Jakarta Commons 的一些类库。Struts有一组相互协作的类（组件）、Serlvet以及jsp tag lib组成。基于struts构架的web应用程序基本上符合JSP Model2的设计标准，可以说是一个传统 MVC设计模式的一种变化类型。　　
Struts有其自己的控制器（Controller），同时整合了其他的一些技术去实现模型层（Model）和视图层（View）。在模型层，Struts可以很容易的与数据访问技术相结合，如 JDBC / EJB ，以及其它第三方类库，如 Hibernate / iBATIS ，或者 Object Relational Bridge(对象关系桥)。在视图层，Struts能够与JSP，包括 JSTL 与 JSF，以及 Velocity 模板，XSLT 与其它表示层技术。
Struts 为每个专业的 Web 应用程序做背后的支撑，帮助为你的应用创建一个扩展的开发环境。
常见Struts、Hibernate、Spring、J2EE、ibatis、Oracle等开发框架架构图及其简介
  Client browser（客户浏览器）

来自客户浏览器的每个 HTTP 请求创建一个事件。Web 容器将用一个 HTTP 响应作出响应。
  Controller（控制器）

控制器接收来自浏览器的请求，并决定将这个请求发往何处。就 Struts 而言，控制器是以 servlet 实现的一个命令设计模式。 struts-config.xml 文件配置控制器。
  业务逻辑

业务逻辑更新模型的状态，并帮助控制应用程序的流程。就 Struts 而言，这是通过作为实际业务逻辑“瘦”包装的 Action 类完成的。
  Model（模型）的状态

模型表示应用程序的状态。业务对象更新应用程序的状态。ActionForm. bean 在会话级或请求级表示模型的状态，而不是在持久级。JSP 文件使用 JSP 标记读取来自 ActionForm. bean 的信息。
  View（视图）

视图就是一个 JSP 文件。其中没有流程逻辑，没有业务逻辑，也没有模型信息 -- 只有标记。标记是使 Struts 有别于其他框架（如 Velocity）的因素之一

 

4.structs2架构图
Struts 2相对于Struts 1.X，将实现用户业务逻辑（Action）同Servlet API分离开，这种分离机制，是采用了拦截器或者拦截器栈（拦截器链）。拦截器是Struts 2的核心内容之一。
Struts 2内建了多个拦截器和拦截器栈（由多个拦截器形成的拦截器链），将用户的Web请求进行拦截处理，从而提供了更加丰富的功能，例如数据类型转换、国际化、文件上传等。
 常见Struts、Hibernate、Spring、J2EE、ibatis、Oracle等开发框架架构图及其简介

 
5.Hibernate架构图
Hibernate是一个开放源代码的对象关系映射框架，它对JDBC进行了非常轻量级的对象封装，使得Java程序员可以随心所欲的使用对象编程思维来 操纵数据库。 Hibernate可以应用在任何使用JDBC的场合，既可以在Java的客户端程序使用，也可以在Servlet/JSP的Web应用中使用，最具革命 意义的是，Hibernate可以在应用EJB的J2EE架构中取代CMP，完成数据持久化的重任。
 常见Struts、Hibernate、Spring、J2EE、ibatis、Oracle等开发框架架构图及其简介
　　Hibernate的核心接口一共有5个，分别为:Session、SessionFactory、Transaction、Query和Configuration。这5个核心接口在任何开发中都会用到。通过这些接口，不仅可以对持久化对象进行存取，还能够进行事务控制。下面对这五个核心接口分别加以介绍。
·Session接口:Session接口负责执行被持久化对象的CRUD操作 (CRUD的任务是完成与数据库的交流，包含了很多常见的SQL语句。)。但需要注意的是Session对象是非线程安全的。同时，Hibernate的 session不同于JSP应用中的HttpSession。这里当使用session这个术语时，其实指的是Hibernate中的session，而 以后会将HttpSesion对象称为用户session。
·SessionFactory接口:SessionFactory接口负责初 始化Hibernate。它充当数据存储源的代理，并负责创建Session对象。这里用到了工厂模式。需要注意的是SessionFactory并不是 轻量级的，因为一般情况下，一个项目通常只需要一个SessionFactory就够，当需要操作多个数据库时，可以为每个数据库指定一个 SessionFactory。
·Configuration接口:Configuration接口负责配置并启动Hibernate，创建SessionFactory对象。在Hibernate的启动的过程中，Configuration类的实例首先定位映射文档位置、读取配置，然后创建SessionFactory对象。
·Transaction接口:Transaction接口负责事务相关的操作。它是可选的，开发人员也可以设计编写自己的底层事务处理代码。
·Query和Criteria接口:Query和Criteria接口负责执行各种数据库查询。它可以使用HQL语言或SQL语句两种表达方式。


6.J2EE架构图
J2EE是一套全然不同于传统应用开发的技术架构，包含许多组件，主要可简化且规范应用系统的开发与部署，进而提高可移植性、安全与再用价值。
J2EE核心是一组技术规范与指南，其中所包含的各类组件、服务架构及技术层次，均有共通的标准及规格，让各种依循J2EE架构的不同平台之间，存在良好的兼容性，解决过去企业后端使用的信息产品彼此之间无法兼容，导致企业内部或外部难以互通的窘境。




52 列举三种以上垃圾回收算法，并比较其优缺点？
 在引用计数中，每一块动态分配的内存都与一个引用计数有关。这个计数在每次对内存的引用增加的时候增加1，在取消对内存的引用是减1.用C++的术语来说，这意味着每次将一个指针指向一块已分配内存的时候，
 与内存相关的引用计数增加1.当这个指针指向其他位置的时候，引用计数减1.当引用计数下降为0的时候，内存不再被使用，从而可以释放。

（1）引用计数，的最大优点是其简单性----易于理解并实现。另外，它的位置不受堆结构的影响，因为引用计数不依赖于对象的物理位置。引用计数增加了每个指针操作的开销，但是回收阶段的开销相对较低。其主要的缺点是循环的引用阻止了其他不再使用的内存的释放。当两个对象互相指向对方的时候(无论是直接的还是间接的)，就会发生循环引用。在此情况下，对象的引用计数永不为0.为了解决循环引用的问题，设计了一些解决方案，但是这些方案都会增加复杂程度和开销。

（2）标记并清除：标记并清除涉及到两个阶段。在第一个阶段，堆中的所有对象都被设置为未标记状态。然后，可以由程序变量直接或者间接访问的所有对象都被标记为“正在使用”。在第二个阶段，扫描所有已分配的内存(也就是说，进行了内存的清除)，会释放所有未标记的元素。
       标记并清除有两个主要优点：
              首先，他很容易处理循环引用；
              其次，在回收之前，他实际上没有增加运行时开销；
       标记并清除也有两个主要的缺点：
              首先，由于在回收的时候必须扫面整个堆，因此回收垃圾可能会花费较多的时间。因此，对于某次额程序，垃圾回收可能会导致程序运行效率低下；
              其次，尽管标记并清除在概念上很简单，但是要有效地实现它并非易事；
（3）复制：复制算法将自由内存分到两个空间中。一个是活动空间(持有当前的堆)，一个是空闲空间。在垃圾回收期间，活动空间中正在使用的对象被确认，并复制到空闲空间中。然后，两个空间的角色反转，空闲空间变为活动空间，活动空间变为空闲空间。提供了复制过程中压缩堆的优点。它的缺点是在某个时刻只允许使用一个的自由内存。

采用哪种算法：
     三种垃圾回收的经典算法都各自的优缺点，好像很难做出选择。然而，考虑前面列举出的限制，就会得出明显的选择：引用计数。最重要的是，引用计数可以很容易地应用与现有的C++动态分配系统上。其次，他可以以一种直接的方式来实现，而不会影响代码。第三，它不需要堆的任何特定的组织或者结构，从而不会影响C++提供的标准分配系统。
     使用引用计数的一个缺点是很难处理循环引用。这对于许多程序而言，并不是一个问题，因为有意的循环引用并不常用，并且可以避免。(即使我们所说的循环，如循环队列，也不一定要用到循环指针引用)。当然，某些情况下需要使用循环引用。也可能建立了循环引用，而您并不知道，特别是使用第三方库的时候。因此，垃圾回收器必须提供某种方法来适度地处理循环引用。
     为了处理循环引用问题，释放任何已经分配的内存。这将确保涉及到循环引用的对象被释放，并且调用他们的析构函数。通常在程序结束的时候，不应该再有已分配的对象，理解这一点很重要。对于涉及到循环引用而不能被释放的对象，这种机制是显示的。


实现垃圾回收器
    为了实现引用计数的垃圾回收器，必须有某种方法来跟踪指向每块动态分配的内存的指针的数量。问题在于，C++没有内建的机制来确保一个对象知道其他的对象何时指向他。
    幸运的是，在此有一个解决方案：可以建立一个新的支持垃圾回收的指针类型。
    为了支持垃圾回收，新的指针类型必须做三件事情：
    它必须为使用中的动态分配的对象维护一个引用计数的链表；
    它必须跟踪所有的指针运算符，每次某个指向一个对象时，都要使这个对象的引用计数增加1，每次某个指针重新指向其他对象的时候，都要使这个对象的引用计数减1；
    它必须回收那些引用计数为0的对象。除了支持垃圾回收之外，这个新指针类型与普通的指针看起来一样；

垃圾回收指针类型的建立不仅以一种简单的方法实现垃圾回收器，而且还满足不影响原始的C++动态分配系统的限制。当需要垃圾回收的时候，使用支持垃圾回收的指针。当不需要垃圾回收的时候，使用普通的C++指针。因此，这两种类型的指针在同一个程序内都可以使用。
是否使用多线程
       再设计C++的垃圾回收器时，另一个考虑是应该使用单线程还是多线程。也就是，是否应该吧垃圾回收器设计为一个后台进程，在它自己的线程内运行，并且在CPU时间允许是回收垃圾。或者，这个垃圾回收器在使用它的进程的相同线程中运行，当满足某程序条件的时候回收垃圾。这两种方法各有优缺点。
       建立多线程垃圾回收器的主要优点是效率。垃圾可以在CPU空闲时被回收。其缺点是，C++没有提供内建的多线程支持，这意味着威力支持多任务，任何多线程方法都依赖于操作系统是否支持多任务，这使得代码不可移植。
       使用单线程垃圾回收器的主要优点是代码可以移植。在不支持多线程或者支持多线程的代价很高的情况下使用。主要缺点是当垃圾回收发生时，程序的其他部分会停止运行。

何时回收垃圾
       在实现垃圾回收器之前，需要回答一个问题是：什么时候开始垃圾回收？对于多线程的垃圾回收器这不成问题，因为他可以作为后台任务连续运行，并且在CPU空闲的时候回收垃圾。然而对于单线程的垃圾回收器，为了回收垃圾，必须停止运行程序的其他部分。
       实际上，只有在有足够的理由(如内存持续降低)的时候，才会进行垃圾回收。有两个原因使得这样做有意义。首先，通过某种垃圾回收算法，如标记并清除，如果不实际执行回收，就没有办法知道不在使用那块内存。其次，回收垃圾是一个耗时的过程，在不需要的时候不应该执行它。

 

53 说说JVM原理，内存泄露与溢出的区别，何时产生内存泄露？
1、什么是JVM ?
JVM， 中文名是Java虚拟机， 正如它的名字， 是一个虚拟机器，来模拟通用的物理机。 JVM是一个标准，一套规范，  规定了.class文件在其内部运行的相关标准和规范。 及其相关的内部构成。 比如：所有的JVM都是基于栈结构的运行方式。那么不符合这种要求的，不算是JVM， 如Android中所使用的Dalvik 虚拟机就不能称作是JAVA 虚拟机， 因为它是基于寄存器（最新的Android系统据说已经放弃了Dalvik VM, 而是使用ART）。
JVM相关的产品有很多， 通常最有名的莫过于现在Oracle公司所有的HotSpot 虚拟机。因此， 这里讨论的都是HotSpot虚拟机， 如果没有特别说明。 
2、类加载？
类加载， 是通过JVM的类加载器从JVM外部以二进制字节流的方式加载到JVM中。但JVM本身有至少三种类加载器：BootStrap（根类加载器，C++实现， 加载位于jre/lib/rt.jar）、Extension(扩展类加载器， 主要用于加载jre/lib/ext/下的jar)、System（加载classpath环境变量所指定的class）；当然还有，自定义的类加载器（用于实现自己的类加载器， 如Tomcat中就实现多个类加载器，用来管理不同的jar）。
如果， 我有一个HelloWorld的类需要加载， 首先类加载器会去从最底层的类加载器去验证这个类是否被加载， 如果没有， 则委托给上一次的类加载器验证是否被加载， 如果到BootStrap类加载器都没有发现HelloWorld类被加载， 那么类加载器将执行加载任务， 如果根类加载器没有加载， 则委托给下一级的Extension类加载器去尝试加载，直到这个类被加载成功。 参考下图：

需要注意的是：如果一个类被不同的类加载器加载， 那么就是两个不同的类。

3、类加载的具体过程？
被java编译器（不仅限于， 还有其他任何的可以编辑成为.class的编译器）编译过的.class文件（可能是以jar、war、jsp等形式）， 经过类加载器加载 、 验证、准备、解析、初始化之后， 才可以被使用。基本的过程如下：
加载： 首先，通过一个类的全类名来获取此类的二进制字节流。其次，将类中所代表的静态存储结构转换为运行时数据结构， 最后，生成一个代表加载的类的java.lang.Class对象， 作为方法区这个类的所有数据的访问入口。加载完成之后， 虚拟机外部的二进制静态数据结构就转换成了虚拟机所需要的结构存储在方法区中（至于如何转换， 则由具体虚拟机自己定义实现）， 而所生成的Class对象， 则存放在方法区中， 用来作为程序访问方法区中数据的外部接口。
验证：其目的就是保证加载进来的.class文件不会危害到虚拟机本身， 且内容符合当前虚拟机规范要求。主要验证的内容大致有：文件格式、元数据验证、字节码验证、符号引用验证。其中文件格式验证， 主要确保符合class文件格式规范（如文本后缀为.class的文件将验证不通过）， 以及主次版本号， 验证是否当前JVM可以处理等。元数据验证，主要验证编译后的字节码描述信息是否符合java语法规范。字节码验证， 其最为复杂， 主要通过控制流和数据流确定语义是否合法、符合逻辑。符号引用验证，可以看做是除自身以外（常量池中各种引用符号）的信息匹配校验，如通过持有的引用能否找到对应的实例。
准备：正式为类变量分配内存，并设置类变量的初始值。这些变量都会在方法区中进行分配。
解析：将常量池内的符号引用替换为直接引用的过程。主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄等。
初始化：加载的最后阶段， 程序真正运行的开始。

4、java运行时数据区 ？
既然类以及加载到JVM中， 那么数据如何真正的运行？如下图：

类加载进来， JVM是通过上图所示的区域来运行和管理这些加载进来的CLASS。即程序运行的是时候， 由上面逻辑单元来运行程序， 包括：方法区、堆、本地方法栈、栈、程序计数器（PC）五大部分组成（有些VM说常量池也是其中的一个单元， 但是HotSpot VM中的常量池是方法区中的一部分）。（注意线程共享）

程序计数器 （PC）：可以看做是当前线程执行字节码的行号指示器。字节码解释器工作的时候就是通过这个计数器的值来选取下一条需要执行的字节码指令， 分支， 循环、跳转、异常处理、线程恢复等基础功能依赖计数器完成。
虚拟机栈：和计数器一样， 也是线程私有的，生命周期同线程一致。每个方法在执行时，都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接、方法出口等信息。方法调入则入栈， 方法执行完则出站。局部变量表存储各种基本类型数据（java的8种，其中long，double占用2个局部变量控件，其余数据占用1个）、对象引用（reference类型）。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时， 这个方法需要在帧中分配多大的局部变量空间是完全确定的。在方法运行期间是不会改变局部变量表的大小的。
本地方法栈：此栈和JVM栈作用非常类似， 不同在于本地方法栈为虚拟机使用到的Native方法服务， 而JVM栈则是为Java执行的方法服务。Sun HotSpot虚拟机， 直接把本地方法栈和虚拟机栈合二为一。本地方法栈也会抛出StackOverFlowError和OutOfMemoryError异常。
Java堆：是JVM管理内存中最大的一块。被所有线程共享一块区域。堆是GC垃圾收集器管理的主要区域。从内存回收角度看， java堆被分为新生代、老年代， 再细致一点有其他的划分。这些目的主要就是更快的分配和回收内存。

方法区：和java堆相同， 线程共享区域， 用来存储已被虚拟机加载的类信息， 常量、静态变量、即时编译器编译后的代码等数据。有人称作此方法区为“永久带”， 本质上不等价，只是HotSpot VM将GC分代收集扩展到了方法区，这样HotSpot的垃圾收集器管理方法区和管理java堆一样（优点：不用专门为方法区写一套垃圾收集器， 缺点：容易导致内存溢出）。官方现在拥也有放弃永久带并改为采用Native Memory来实现方法区的计划，目前已经发布的JDK7中的HotSpot中， 已经将原本放在方法区中的字符串常量池移出了。
运行时常量池：是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述外，还有一项就是常量池， 用于存放编译期间生成的各种字面量和符号引用 ，这部分内容在类加载后进入方法区的运行时常量池中存放。

5、垃圾收集？
在java运行时区域中， 程序计数器、虚拟机栈、本地方法栈3个区域随线程而生，随程而灭。因为这几个区域
的内存分配和回收都是具有确定性，这几个区域不需要过多考虑回收的问题。因为方法结束之后或线程结束之后， 
内存自然就跟着回收了（这不是绝对的， 因为如果当栈内存中的引用很消耗内存的时候， 需要手动将引用置为null，
以便垃圾收集器回收大对象）。而java堆和方法区不一样，一个接口中的多个实现类需要的内存可能不一样， 一个
方法中的多个分支需要的内存也可能不一样，我们只有在程序处于运行期间时，才知道会创建哪些对象， 垃圾收集
器关注的就是这部分内存。其也是动态的。
垃圾收集器的区域如下图：

垃圾收集本是有一套非常复杂的算法， 如果在方法区中（HotSpot VM中的永久带）进行垃圾收集， 那么其性价比极
底的，因为垃圾回收主要收集永久带中的两部分内容：废弃的常量和无用的类。回收永久带中的常量和方法区非常相
似。但是在堆中， 尤其是在新生代中，常规应用进行一次垃圾收集， 一般可以回收70%——95%的空间。而永久带
的垃圾收集要远地与此。
如上图所示， 每一个黑框中都是一个垃圾收集器， 对应特定的垃圾收集算法， 来挺高整体的垃圾收集效率。



内存溢出和内存泄漏的区别、产生原因以及解决方案
内存溢出 out of memory，是指程序在申请内存时，没有足够的内存空间供其使用，出现out of memory；比如申请了一个integer,但给它存了long才能存下的数，那就是内存溢出。
内存泄露 memory leak，是指程序在申请内存后，无法释放已申请的内存空间，一次内存泄露危害可以忽略，但内存泄露堆积后果很严重，无论多少内存,迟早会被占光。

memory leak会最终会导致out of memory！
内存溢出就是你要求分配的内存超出了系统能给你的，系统不能满足需求，于是产生溢出。 
内存泄漏是指你向系统申请分配内存进行使用(new)，可是使用完了以后却不归还(delete)，结果你申请到的那块内存你自己也不能再访问（也许你把它的地址给弄丢了），而系统也不能再次将它分配给需要的程序。一个盘子用尽各种方法只能装4个果子，你装了5个，结果掉倒地上不能吃了。这就是溢出！比方说栈，栈满时再做进栈必定产生空间溢出，叫上溢，栈空时再做退栈也产生空间溢出，称为下溢。就是分配的内存不足以放下数据项序列,称为内存溢出. 

以发生的方式来分类，内存泄漏可以分为4类： 
1. 常发性内存泄漏。发生内存泄漏的代码会被多次执行到，每次被执行的时候都会导致一块内存泄漏。 
2. 偶发性内存泄漏。发生内存泄漏的代码只有在某些特定环境或操作过程下才会发生。常发性和偶发性是相对的。对于特定的环境，偶发性的也许就变成了常发性的。所以测试环境和测试方法对检测内存泄漏至关重要。 
3. 一次性内存泄漏。发生内存泄漏的代码只会被执行一次，或者由于算法上的缺陷，导致总会有一块仅且一块内存发生泄漏。比如，在类的构造函数中分配内存，在析构函数中却没有释放该内存，所以内存泄漏只会发生一次。 
4. 隐式内存泄漏。程序在运行过程中不停的分配内存，但是直到结束的时候才释放内存。严格的说这里并没有发生内存泄漏，因为最终程序释放了所有申请的内存。但是对于一个服务器程序，需要运行几天，几周甚至几个月，不及时释放内存也可能导致最终耗尽系统的所有内存。所以，我们称这类内存泄漏为隐式内存泄漏。 

从用户使用程序的角度来看，内存泄漏本身不会产生什么危害，作为一般的用户，根本感觉不到内存泄漏的存在。真正有危害的是内存泄漏的堆积，这会最终消耗尽系统所有的内存。从这个角度来说，一次性内存泄漏并没有什么危害，因为它不会堆积，而隐式内存泄漏危害性则非常大，因为较之于常发性和偶发性内存泄漏它更难被检测到 

内存溢出的原因以及解决方法

引起内存溢出的原因有很多种，小编列举一下常见的有以下几种：

1.内存中加载的数据量过于庞大，如一次从数据库取出过多数据；
2.集合类中有对对象的引用，使用完后未清空，使得JVM不能回收；
3.代码中存在死循环或循环产生过多重复的对象实体；
4.使用的第三方软件中的BUG；
5.启动参数内存值设定的过小

内存溢出的解决方案：
第一步，修改JVM启动参数，直接增加内存。(-Xms，-Xmx参数一定不要忘记加。)
第二步，检查错误日志，查看“OutOfMemory”错误前是否有其它异常或错误。
第三步，对代码进行走查和分析，找出可能发生内存溢出的位置。
重点排查以下几点：
1.检查对数据库查询中，是否有一次获得全部数据的查询。一般来说，如果一次取十万条记录到内存，就可能引起内存溢出。这个问题比较隐蔽，在上线前，数据库中数据较少，不容易出问题，上线后，数据库中数据多了，一次查询就有可能引起内存溢出。因此对于数据库查询尽量采用分页的方式查询。
2.检查代码中是否有死循环或递归调用。
3.检查是否有大循环重复产生新对象实体。
4.检查对数据库查询中，是否有一次获得全部数据的查询。一般来说，如果一次取十万条记录到内存，就可能引起内存溢出。这个问题比较隐蔽，在上线前，数据库中数据较少，不容易出问题，上线后，数据库中数据多了，一次查询就有可能引起内存溢出。因此对于数据库查询尽量采用分页的方式查询。
5.检查List、MAP等集合对象是否有使用完后，未清除的问题。List、MAP等集合对象会始终存有对对象的引用，使得这些对象不能被GC回收。
第四步，使用内存查看工具动态查看内存使用情况


54 谈谈架构师的职责有哪些？ 
1. 负责后台系统的架构设计和开发；
2. 构建符合业务需求、高可用、高并发、可伸缩的分布式系统，满足业务需求和用户规模；
3. 管理后台技术团队、开发流程以及后台的运维，和产品以及运营沟通，按时高质量的发布后台系统；

55 如果要设计一个搜索引擎，像Google那样只有两个页面，要求性能最大化，Web方面应该如何设计？
性能: 
1客户端:js的写法,数据排列,不同浏览器区别. 
2服务器:逻辑,计算,缓存,减少I/O,提高命中 
3传输:带宽,缓存,异步,进度条,并发,集群,数据压缩. 
我认为最主要的性能是人的体验,其它都是可以放到第二位去的.


56 描述一个你感觉最成功的一次架构案例?
运营erp：
单机--集群扩容--分布式架构（流程引擎，公共组件及服务，聚引客，客常来）  

工作流前端采用模板语言
后端采用 模板方法模式+策略模式

Maven+spring+mybatis+activci+Jenkins+分布式消息队列+mongodb++分布式缓存+


57 怎么做到系统整合?
（A、通过代码的整合方式，使用相同的数据库。B、通过SSO方式，可以是异构数据库.）

58 浅谈一下负载均衡的原理?
负载均衡(Load Balance，简称LB)是一种服务器或网络设备的集群技术。负载均衡将特定的业务(网络服务、网络流量等)分担给多个服务器或网络设备，从而提高了业务处理能力，保证了业务的高可用性。负载均衡基本概念有：实服务、实服务组、虚服务、调度算法、持续性等，其常用应用场景主要是服务器负载均衡，链路负载均衡。......
负载均衡(Load Balance，简称LB)是一种服务器或网络设备的集群技术。负载均衡将特定的业务(网络服务、网络流量等)分担给多个服务器或网络设备，从而提高了业务处理能力，保证了业务的高可用性。负载均衡基本概念有：实服务、实服务组、虚服务、调度算法、持续性等，其常用应用场景主要是服务器负载均衡，链路负载均衡。
一 服务器负载均衡
服务器负载均衡根据LB设备处理到的报文层次，分为四层服务器负载均衡和七层负载均衡，四层处理到IP包的IP头，不解析报文四层以上载荷(L4 SLB);七层处理到报文载荷部分，比如HTTP，RTSP，SIP报文头，有时也包括报文内容部分(L7 SLB)。
1.四层服务器负载均衡技术
客户端将请求发送给服务器群前端的负载均衡设备，负载均衡设备上的虚服务接收客户端请求，通过调度算法，选择真实服务器，再通过网络地址转换，用真实服务器地址重写请求报文的目标地址后，将请求发送给选定的真实服务器;真实服务器的响应报文通过负载均衡设备时，报文的源地址被还原为虚服务的VSIP，再返回给客户，完成整个负载调度过程。报文交互流程如下：

NAT方式的服务器负载均衡报文交互流程图报文交互流程说明：
(1)Host发送服务请求报文，源IP为Host IP、目的IP为VSIP
(2)LB Device接收到请求报文后，借助调度算法计算出应该将请求分发给哪台Server
(3)LB Device使用DNAT技术分发报文，源IP为Host IP、目的IP为Server IP
(4)Server接收并处理请求报文，返回响应报文，源IP为Server IP、目的IP为Host IP
(5)LB Device接收响应报文，转换源IP后转发，源IP为VSIP、目的IP为Host IP
2.七层服务器负载均衡技术
七层负载均衡和四层负载均衡相比，只是进行负载均衡的依据不同，而选择确定的实服务器后，所做的处理基本相同，下面以HTTP应用的负载均衡为例来说明。
由于在TCP握手阶段，无法获得HTTP真正的请求内容，因此也就无法将客户的TCP握手报文直接转发给服务器， 必须由负载均衡设备先和客户完成TCP握手，等收到足够的七层内容后，再选择服务器，由负载均衡设备和所选服务器建立TCP连接。
七层负载均衡组网和四层负载均衡组网有一个显著的区别：四层负载均衡每个虚服务对应一个实服务组，实服务组内的所有实服务器提供相同的服务;七层负载均衡每个虚服务对应多个实服务组，每组实服务器提供相同的服务。根据报文内容选择对应的实服务组，然后根据实服务组调度算法选择某一个实服务器。

七层负载均衡组网图
上图中描述了基于HTTP的URI目录信息进行的七层负载均衡部署，报文交互流程图如下：

七层负载均衡报文交互流程图报文交互流程说明：
(1)-(3)：Client和LB建立TCP连接;
(4)：Client发送HTTP请求，目的IP为虚IP;
(5)：LB设备分析报文，根据调度算法选择实服务器，注意此时会缓存该报文;
(6)：LB设备向实服务器发Syn报文，序列号为Client的Syn报文序列号
(7)：Server发送Syn/Ack报文，目的IP为Client;
(8)：LB接收Server的Syn/Ack报文后，回应ACK报文
(9)：修改步骤(5)中缓存的报文目的IP和TCP序列号，然后发给Server;
(10)：Server发送响应报文到LB;
(11)：LB修改步骤(9)中的报文的源地址和TCP序列号后转发给Client。
二 链路负载均衡
在企业网、运营商链路出口需要部署LB设备以优化链路选择，提升访问体验，链路负载均衡按照流量发起方向分为Inbound负载均衡和Outbound负载均衡
1.Inbound入方向负载均衡
Inbound负载均衡技术是DNS智能解析的一种，外网用户通过域名访问内部服务器时，Local DNS的地址解析请求到达LB设备，LB根据对Local DNS的就近性探测结果响应一个最优的IP地址，外网用户根据这个最优的IP响应进行对内部服务器的访问。

Inbound链路负载均衡组网图

 入方向负载均衡
流程简述如下：
(1)外部用户进行资源访问前先进行DNS解析，向其本地DNS服务器发送DNS请求。
(2)本地DNS服务器将DNS请求的源IP地址替换为自己的IP地址，并转发给域名对应的权威服务器——LB device。
(3)LB device根据DNS请求的域名和配置的Inbound链路负载均衡规则进行域名解析。
(4)LB device按照域名解析的结果，将DNS应答发送给本地DNS服务器。
(5)本地DNS服务器将解析结果转发给用户。
(6)用户使用解析结果选择的链路，直接对LB device进行资源访问。
2.Outbound出方向负载均衡
内网用户访问Internet上其他服务器。 Outbound链路负载均衡中VSIP为内网用户发送报文的目的网段。用户将访问VSIP的报文发送到负载均衡设备后，负载均衡设备依次根据策略、持续性功能、就近性算法、调度算法选择最佳的链路，并将内网访问外网的业务流量分发到该链路。

Outbound链路负载均衡组网图
Outbound负载均衡报文交互流程如下：

 Outbound 链路负载均衡流程图
Outbound负载均衡报文交互流程说明：
(1)LB Device接收内网用户流量 -
(2)LB Device依次根据策略、持续性功能、就近性算法、调度算法进行链路选择 在Outbound链路负载均衡组网中，通常使用就近性算法或带宽调度算法实现流量分发
(3)LB device按照链路选择的结果将流量转发给选定的链路 -
(4)LB Device接收外网用户流量 -
(5)LB Device将流量转发给内网用户
三 负载均衡优化及应用
1.TCP连接复用
连接复用功能通过使用连接池技术，可以将前端大量的客户的HTTP请求复用到后端与服务器建立的少量的TCP长连接上，大大减小服务器的性能负载，减小与服务器之间新建TCP连接所带来的延时，并最大限度减少后端服务器的并发连接数，降低服务器的资源占用。

TCP连接复用示意图上图给出了TCP连接复用的简单过程描述。由Client端发送的Req1/ Req2/ Req3三个HTTP请求，经过LB设备后，复用了LB设备和Server端已经建立好的连接，将Client端的三个请求通过两个TCP连接发送给了服务器端。
2.SSL卸载
为了避免明文传输出现的安全问题，对于敏感信息，一般采用SSL协议，如HTTPS，对HTTP协议进行加密，以保证整个HTTP传输过程的安全性。SSL是需要耗费大量CPU资源的一种安全技术，如果由后端的服务器来承担，则会消耗很大的处理能力。应用交付设备为了提升用户的体验，分担服务器的处理压力，将SSL加解密集中在自身的处理上，相对于服务器来说LB能提供更高的SSL处理性能，还能够简化对证书的管理，减少日常管理的工作量，LB的该功能又称为SSL卸载。
下图中Client端发送给Server的所有的HTTPS流量都被LB设备终结，LB设备将SSL终结后，与Server之间可采用HTTP或者弱加密的HTTPS进行通讯。LB设备承担了SSL的卸载工作，从而极大的减小了服务器端对SSL处理的压力，将服务器的处理能力释放出来，更加专注于处理服务器本身承担的业务逻辑。

SSL卸载示意图
SSL卸载的处理流程如下：

SSL卸载过程
(1)客户端向服务器端发送SSL握手请求。
(2)LB设备作为中间的卸载设备，代替服务器端和客户端交互，完成SSL握手过程。
(3)客户端发送SSL加密后的请求数据。
(4)LB设备解密数据。
(5)LB设备将解密后的明文发送给Server。
(6)服务器返回给LB设备回应报文。
(7)LB设备将返回的应答报文加密。
(8)LB设备将加密后的应答报文传给客户端。
3.DRX云环境应用交付
业务负载监控平台通过H3C负载均衡设备的参数设定和监控可以动态感知业务负载变化，并通知云管理平台动态调整业务资源。由此实现用户业务资源的实时动态调整、业务资源优化调配。
当业务负载监控平台发现业务资源需要调整时：业务负载超限—增加资源;业务资源过剩——回收资源，云管理平台通过自动创建、启动或者删除停止虚拟机的方式为业务进行资源动态调整。
四 结束语
负载均衡技术不管应用于用户访问服务器资源，还是应用于多链路出口，均大大提高了对资源的高效利用，显著降低了用户的网络布署成本，提升了用户的网络使用体验。随着云计算的发展，负载均衡的技术实现还将与云计算相结合，在虚拟化和NFV软件定义网关等方面持续发展。


59 用JAVA如何实现每天1亿条记录的数据存储，数据库方面怎么设计？
一天秒数：60*60*24=86,400秒
每天写入数据量：100,000,000条
平均每秒写入数据量：100,000,000/86,400=1157.5条
峰值每秒估算写入数：1157.5*10=11575条

因此建议从以下几个层面处理
1、数据库服务器磁盘采用高速SSD磁盘
2、数据库采用2个节点的集群方式部署，每个集群节点3台服务器，1主2备，主数据库为写数据库，备数据库为读数据，采用读写分离，单集群节点内主备库数据实时同步，集群节点主库数据实时同步
3、数据表设计采用分区、分表方式设计表结构
4、数据写入采用单事务批量写入的方法新增数据
5、在关键字段建立索引，提高查询效率
6、第一次查询后将数据缓存到radis中，方便下次查询
7、大的应用集群，插入时使用缓冲，比如每1000条插入一次
8、横向分割，分成不同的数据库（不是表）


60 对应大表数据是如何处理；以及数据库性能调优策略？
（索引，SQL语句效率(切忌全表扫描)，数据迁移，水平切面等）


1、索引优化和SQL语句优化是必须的，避免模糊查询和非索引查询，删改操作根据聚集索引进行，删改操作太频繁的话还是需要考虑分表
2、看需求，如果需求不限制，那就分表
分区会增加管理复杂度和成本这个很难理解，分区增加不了多少工作，如果需求要求必须单表，分区是解决在千万到几亿数据量的比较合适的方法
可能更大数据量还是要回到分的路上，但是可能更多考虑分布式
3、我们一般都是把历史数据定期转存其他表（一样的表名后加年月例如TABLE201205）归档~
这样该表本年度的查询的压力也小点（90%查询量集中在本年度）,即使查询历史数据也不影响性能，强力推荐！
4、
（1）从结构上来说，分区很有必要，我听过一些培训，微软给客户的建议是一个表如果大小超过50M，那就建议分区了。而且分区几乎是“一次性”的事情，不会增加什么管理成本。
（2）可以使用归档方式管理历史数据。其实你的数据量不大啦，我以前做银行系统，单表就2亿多，40G的大小。
（3）优化你的语句和设计。
（4）结合你的业务去晚上结构。有时候可以考虑用空间去换时间。


有数据表明：用户可以承受的最大等待时间为8秒。
之前曾见过某个产品的一个列表页，40秒左右才能加载出来，几乎没有进行任何优化措施。
没有索引，没有缓存机制，没有进行sql优化(sql语句很长，并且各种left join表关联)。
数据库优化策略有很多，设计初期，建立好的数据结构对于后期性能优化至关重要。因为数据库结构是系统的基石，基础打不好，使用各种优化策略，也不能达到很完美的效果。

一：规范化与反规范化
大家都听说过：数据库设计三大范式.
1．第一范式(确保每列保持原子性)
第一范式是最基本的范式。如果数据库表中的所有字段值都是不可分解的原子值，就说明该数据库表满足了第一范式。

2．第二范式(确保表中的每列都和主键相关)
第二范式在第一范式的基础之上更进一层。第二范式需要确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。也就是说在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。

3．第三范式(确保每列都和主键列直接相关,而不是间接相关)
第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。

没有最好的设计，只有最合适的设计，所以不要过分注重理论。三范式可以作为一个基本依据，不要生搬硬套。
数据库操作中最为耗时的操作就是 IO 处理，大部分数据库操作 90% 以上的时间都花在了 IO 读写上面。所以尽可能减少 IO 读写量，可以在很大程度上提高数据库操作的性能。

二:优化策略：
在设计表时应同时考虑对某些表进行反规范化，方法有以下几种:

一是分割表。
分割表可分为水平分割表和垂直分割表两种:
水平分割是按照行将一个表分割为多个表，这可以提高每个表的查询速度，但查询、更新时要选择不同的表，统计时要汇总多个表，因此应用程序会更复杂。
垂直分割是对于一个列很多的表，若某些列的访问频率远远高于其它列，就可以将主键和这些列作为一个表，将主键和其它列作为另外一个表。通过减少列的宽度，增加了每个数据页的行数，一次I/O就可以扫描更多的行，从而提高了访问每一个表的速度。但是由于造成了多表连接，所以应该在同时查询或更新不同分割表中的列的情况比较少的情况下使用。

二是保留冗余列。当两个或多个表在查询中经常需要连接时，可以在其中一个表上增加若干冗余的列，以避免表之间的连接过于频繁，一般在冗余列的数据不经常变动的情况下使用。
三是增加派生列。派生列是由表中的其它多个列的计算所得，增加派生列可以减少统计运算，在数据汇总时可以大大缩短运算时间。

在数据库的设计中，数据应当按两种类别进行组织:频繁访问的数据和频繁修改的数据。
对于频繁访问但是不频繁修改的数据，内部设计应当物理不规范化。
对于频繁修改但并不频繁访问的数据，内部设计应当物理规范化。
有时还需将规范化的表作为逻辑数据库设计的基础，然后再根据整个应用系统的需要，物理地非规范化数据。
规范与反规范都是建立在实际的操作基础之上的约束，脱离了实际两者都没有意义。只有把两者合理地结合在一起，才能相互补充，发挥各自的优点。

适当拆分
有些时候，我们可能会希望将一个完整的对象对应于一张数据库表，这对于应用程序开发来说是很有好的，但是有些时候可能会在性能上带来较大的问题。
当我们的表中存在类似于 TEXT 或者是很大的 VARCHAR类型的大字段的时候，如果我们大部分访问这张表的时候都不需要这个字段，我们就该义无反顾的将其拆分到另外的独立表中，以减少常用数据所占用的存储空间。这样做的一个明显好处就是每个数据块中可以存储的数据条数可以大大增加，既减少物理 IO 次数，也能大大提高内存中的缓存命中率。

适度冗余
为什么我们要冗余?这不是增加了每条数据的大小，减少了每个数据块可存放记录条数吗?
确实，这样做是会增大每条记录的大小，降低每条记录中可存放数据的条数，但是在有些场景下我们仍然还是不得不这样做：
1.被频繁引用且只能通过 Join 2张(或者更多)大表的方式才能得到的独立小字段。
2.这样的场景由于每次Join仅仅只是为了取得某个小字段的值，Join到的记录又大，会造成大量不必要的 IO，完全可以通过空间换取时间的方式来优化。不过，冗余的同时需要确保数据的一致性不会遭到破坏，确保更新的同时冗余字段也被更新。

三：其他技巧：
1:字段类型优化
下面的这些关于字段类型的优化建议主要适用于记录条数较多，数据量较大的场景，因为精细化的数据类型设置可能带来维护成本的提高，过度优化也可能会带来其他的问题：

(1)数字类型
非万不得已不要使用DOUBLE，不仅仅只是存储长度的问题，同时还会存在精确性的问题。同样，固定精度的小数，也不建议使用DECIMAL。
非万不得已不要使用DOUBLE，不仅仅只是存储长度的问题，同时还会存在精确性的问题。同样，固定精度的小数，也不建议使用DECIMAL
(2)字符类型
非万不得已不要使用 TEXT 数据类型，其处理方式决定了他的性能要低于char或者是varchar类型的处理。定长字段，建议使用 CHAR 类型，不定长字段尽量使用 VARCHAR，且仅仅设定适当的最大长度，而不是非常随意的给一个很大的最大长度限定，因为不同的长度范围，MySQL也会有不一样的存储处理。

(3)时间类
尽量使用TIMESTAMP类型，因为其存储空间只需要 DATETIME 类型的一半。对于只需要精确到某一天的数据类型，建议使用DATE类型，因为他的存储空间只需要3个字节，比TIMESTAMP还少。不建议通过INT类型类存储一个unix timestamp 的值，因为这太不直观，会给维护带来不必要的麻烦，同时还不会带来任何好处。
2:合理使用索引
3：缓存机制
4：用EXPLAIN使你的SELECT查询更加清晰
5：利用LIMIT 1取得唯一行
6： 尽量避免SELECT *命令
7：使用ENUM而不是VARCHAR
8:尽可能的使用NOT NULL
　NULL 类型比较特殊，SQL 难优化。虽然 MySQL NULL类型和 Oracle 的NULL 有差异，会进入索引中，但如果是一个组合索引，那么这个NULL 类型的字段会极大影响整个索引的效率。此外，NULL 在索引中的处理也是特殊的，也会占用额外的存放空间。
　很多人觉得 NULL 会节省一些空间，所以尽量让NULL来达到节省IO的目的，但是大部分时候这会适得其反，虽然空间上可能确实有一定节省，倒是带来了很多其他的优化问题，不但没有将IO量省下来，反而加大了SQL的IO量。所以尽量确保 DEFAULT 值不是 NULL，也是一个很好的表结构设计优化习惯。



61 分布式系统，数据库设计方面，应注意哪些方面？
(权限设计、图片存储、服务器集群设计等)

分布式是分布式，集群是集群。分布式比如有ABCD用户，将AB提交的数据写到数据库1去，CD用户群组的数据提交到数据库2去优点：
降低单个数据库的压力（数据量少，单个数据库不会被频繁操作到，如提交事务，少几个人少去抢占资源），不然，像上面单个数据库同时要处理四个人的数据，肯定比处理两个的压力小得多了（PS：1、2两个数据库的内容是不一致的，但是结构是一致的）。
响应速度快，一般用于大客户的解决方案缺点：用的硬件较多，开发成本较高（不像单台机器那样，不管如何都写到一台机器上）。
集群：构建多个相同数据库（内容一样），类似备份(一个数据一生成一条数据，立马将该数据同步到另一台上面去，查询时可以多台任选一台，单台压力低)，一台挂了，别一台上面还是有备份的，也有分布式的优点，不过，需要集群的几台机器网络环境较好，数据推送才能及时。

最近在做系统升级，由于当时设计的局限，导致系统不停服，保证服务的做法非常麻烦。当时再定方案的时候，由于自己在这方面没有经验，导致有些乐观。到了实际做的时候，预期时间至少比预想的多了一周的时间，要知道，在
互联网公司，一周的时间是个非常长的时间。而这一周，还包括了OT。
在这里总结一下分布式系统设计的大忌，本来想试着分一下级，但是还是算了，一来标准太多，无法制定一个合适的规则来界定；二来自己的经验也在增长，低调一下是自己也没详细的研究过超过5个分布式系统；三来做事情还是要严谨，不做没有十足把握的事情。
1. 服务接口的设计至关重要
虽然大家口口声声说对于一个集群来说，每台机器都可能出故障。但是做方案设计的时候，某些资源却向用户直接暴漏了服务的实际地址。对于一个服务几年的服务器来说，故障的可能性非常大，尤其是如果这个服务器的平时负载比较高的话。我不清楚一台服务器的平均保修时间是多少，但是绝对不可能是几个小时能搞定的，这个时间少则一天，多则半个月甚至更长。对于一些高级的用户，它会使用本地的cache，或者其他的策略来屏蔽调用服务不可用带来的影响，但是，几天的停服对于用户方的影响是无论如何不可能忽略的。
这种问题发现后，可能简单的发布一个新版本的api，或者一个简单的配置文件就可以纠正。但是对于线上用户来说，他们运行的是一个一直都在running状态的服务。这个简单的改正可能需要他们服务重启，这对于一个大型的集群来说，带来的成本非常高。如果是因为这个服务的不可用导致了线上事故，那么应用方肯定会非常主动的去修正这个错误。但是如果使用架构方发现了这个问题，而主动推动应用方去修改，可能应用方会因为各种原因而推脱。
因此，设计服务的接口一定要注意，这个接口一定要是稳定的，而且后台服务的故障，升级等操作绝对对于用户要是透明的。不要将服务的实际地址暴漏给用户方:这台服务器终有一天会挂掉。尤其是对于C++等需要编译的api来说，这个接口就更加重要了。毕竟api的修改对于应用方来说意味着要重新编译；重新编译意味着要重新走一下发布流程：至少要提测吧。
2. 后台升级要做到对用户透明
这实际上是又是一句大家都知道的。但是设计时确实有时候会忽略。对于弹性计算系统来说，服务的伸缩是必须的，这个也是设计的目标之一。但是对于一些小规模的计算集群来说，可能大家认为伸缩不是最重要的feature。最重要的feature就是能够快速的完成系统设计和实现，为用户服务。但是实际上，这个通过一些简单的修改，就可以完成：Worker上带一个agent和master或者meta server通信，保持心跳。心跳超时的Worker会被下线，以后的服务都不会发送到这个Worker上来。而新加入的Worker则会加入集群接收计算任务。这个不单是应对服务的伸缩，也是为了应对机器的故障。因此不用太大的改动，就可以将一个系统从山寨提升到真正的可用。
一个系统的服务质量，不是说在一般情况下的服务是可靠的，除了网络丢包、网络传输造成的问题外，服务质量可以做到10000个请求至多有1个失败就是说这个系统是可用的。评价服务质量的另外一个重要指标是全年可服务时间。这个要将机器故障，机房故障考虑在内。如果依赖于运行环境没有问题，才能达到99.99，那么这个服务就有点山寨，对于重要的应用方来说，这种服务不可接受。
3. 应用方设计时候需要衡量后台服务失败的影响
如果服务的可靠性要求非常高，比如是直接面向互联网用户的，要求任何时间都能够对互联网用户提供服务，那么就需要在调用服务时做下服务不可用的预案。甚至做下超时机制：如果服务调用指定时间不返回，那么需要有其余的逻辑来替代。
当然了本次还遇到很多其他的痛点，每个都是设计上得小瑕疵，当时注意的话不会增加工作量，或者增加很少的工作量就可以做到可用。互联网强调快，那么底线应该是可用吧。易用可能是更要的要求。当然了这个可能可以一种互联网风格，就是一个事情可以快速做完，快速上线。当时上线时候也做了二期需要做的改进，但是后台发现上线效果好，符合预期。又去做其它高优先级的事情去了。导致原来设计的局限就永远的停留在那里了，这就是为后来人埋下一个坑。。
本次升级的时候，由于信息的不一致导致一台服务器停服，导致大面积的失败。后来为了避免其它的集群出现类似的问题，因此所有的信息都重新确认了一遍。而这带来了半天的枯燥工作。因此，自己做设计的时候，一定要注意，不求最好，但求可用，在机器故障，服务升级，对于用户来说，服务都可用。



62 当用户反映，平台访问变的很慢的时候，怎样处理这个问题的?
（A、数据库端；B、后端应用平台端；C、前端Web端；D、负载均衡；E、网络设置；F、机器性能的优化；G、考虑是否有病毒、木马等干扰等等）

问题场景：某个用户向你反映说你开发的网站访问速度很慢，但是该用户访问其他问题很正常，分析下原因、有哪些工具分析原因、怎么解决问题？
最近面试两次碰到了这个题目，回来请教了一位做运维的师兄，听他讲解下发现确实这个问题可以牵涉到很多知识面，很具综合型，是个好题目，不过其实这个问题偏运维，但开发人员自然也是越懂越好。结合这位师兄的详细讲解，我梳理了下这个问题牵涉到的一些点。

一、针对这个题目我们可以简单理解成是server端出现的问题，而不是client端出现了问题（用户网络不好包括域名服务器解析等可能），当然面试官要考你用户端的知识，例如域名解析，也是有挺多可以考到的知识点，但单就这个问题，更强调的是server端的知识点。下面逐一来剖析可能的原因：
（1）可能的原因一：服务器出口带宽不够用。这是一个很常见的瓶颈。一方面，可能是本身购买的服务器出口带宽就很小（企业购买带宽相当昂贵），一旦用户访问量上来了，并发量大了，自然均分给用户的出口带宽就更小了，所以某些用户的访问速度就会下降了很多。另一个，就是跨运营商网络导致带宽缩减，例如很多公司的网站（服务器）是放在电信的网络上的，而如果用户这边对接的是长城或者说联通的宽带，运营商之间网络传输在对接时是会有限制的，这就可能导致带宽的缩减。
（2）可能原因二：服务器负载过大忙不过来，比如说CPU和内存消耗完了，这个容易理解，不展开。
（3）可能原因三：网站的开发代码没写好，例如mysql语句没有进行优化，导致数据库的读写相当耗费时间。
（4）可能原因四：数据库的瓶颈，也是很常见的一个瓶颈，这点跟上面第三个原因可以一起来说。当我们的数据库变得愈发庞大，比如好多G好多T这么大，那对于数据库的读写就会变得相当缓慢了，索引优化固然能提升一些效率，但数据库已经如此庞大的话，如果每次查询都对这么大的数据库进行全局查询，自然会很慢。这个学过数据库的话也是挺容易理解的。

二、针对上面可能的原因，有哪些方法和工具去检测呢：
（1）某个用户反馈网站访问变慢，怎么去定位问题。首先你自己也打开下网站，看是否会出现用户反映的问题，如果你这边访问没问题，那就可能是用户那边的问题了，这块就是要先确定是用户那一方的问题还是自身比如说服务器或者网站的问题。
（2）发现确实是自己服务器或者网站的问题，那么可以利用浏览器的调试功能（一般浏览器都会有），调试网络看看各种数据加载的速度，哪一项消耗了多少时间都可以看到，是哪块数据耗时过多，是图片加载太慢，还是某些数据加载老半天都查不出来。
（3）然后针对服务器的负载情况，可以去查看下服务器硬件（网络带宽、CPU、内存）的消耗状况。带宽方面查看流量监控看是不是已经到了峰值，带宽不够用了，如果是公司自己买服务器搭的网站服务器的话，需要自己搭建监控环境；如果用的是阿里云腾讯云这些的，那这些平台那边会提供各方面的监控比如CPU、带宽等等，在后台就可以看到了。
（4）如果发现硬件资源消耗都不高，都比较充裕，那要去看看是不是程序的问题了。这个可以通过查日志来找，比如PHP日志、Apache日志、mysql日志等等的错误日志，特别如mysql有个慢查询的日志功能，可以看到是不是某条mysql语句特别慢，如果某条语句花的时间太长，那这条语句很有可能有问题。
（5）至于说到的数据库太庞大，这个直接看就看得到了，比如一个表的文件大小变得特别大了。

三、针对上面的这些问题，有哪些解决和优化的办法呢：
（1）出口带宽的问题，这个很简单，加带宽，有钱就多买带宽，很简单。
（2）mysql语句优化，开发人员职责。
（3）数据库太庞大，为了读写速度，进行“拆表”、“拆库”，就是把数据表或者数据库进行拆分。
（4）上面的拆库拆表都是针对数据库实在太庞大才会这样做，一般在此之前会有其他优化方法，比如mysql的主从复制，一台主服务器专门用于写，然后其他从服务器用来读，写完之后会同步更新到其他读的服务器中。例如阿里的双十一活动，都不知道用了多少万台服务器一起在扛着。
（6）还有这几年用得比较多的非关系型数据库，它使用了缓存机制，它把数据缓存到了内存，用户访问数据直接从内存读取，读取速度就比在磁盘中读取快了很多，还有它的一个key-value读取机制，这个听师兄说之后没听懂。
（7）CDN（content-delivery-network：内容分发网络），鸡蛋放在多个篮子里，把数据放在离用户更近的位置（例如网站的一些静态文件比如图片或者js脚本），用户访问时判断IP来源是广州，那就通过智能DNS解析到广州的服务器上，直接从广州的篮子里去获取数据，速度就快了。这里有个静态数据和动态数据的概念，例如图片和一些js文件一般是不变的，那就可以把它们的映像分布到全国各地，加快速度，而一些需要在网站后台动态产生的一些数据，则需要去到网站所在的服务器去产生并得到。这个涉及到两种数据的显示的问题，这就交由浏览器处理了。同时异步加载的技术例如前端的Ajax技术，异步请求数据，可以使这些动态数据延迟加载，这块自己不怎么了解，可能表述不好。前端开发的人员应该更懂一些。
（8）上面都没有说到架构的优化，如果网站扛不住，是不是网站架构已经不能适应了，比如做个小博客把数据库服务器和web服务器都用同一台服务器，那所有负载都在同一台服务器上了。但是访问量上来扛不住了，就得加服务器了，就得在架构上优化了，比如在数据库上做集群，在web服务器上也做集群，比如web服务器集群，在服务器前面加一个负载均衡，负载均衡就是专门负责分发，把用户的请求均匀分布到各个服务器上。


63 介绍一下你主导过的项目；
设计开发思想
技术实现
任务安排
进度控制
版本控制
需求控制
资源管理

64 你认为负责一个大型集成系统的系统分析与架构设计，需要具备哪些能力？
运营erp：
单机--集群扩容--分布式架构（流程引擎，公共组件及服务，聚引客，客常来）  

工作流前端采用模板语言
后端采用 模板方法模式+策略模式

Maven+spring+mybatis+activci+Jenkins+分布式消息队列+mongodb++分布式缓存+

系统架构师负责设计系统整体架构，从需求到设计的每个细节都要考虑到，把握整个项目，使设计的项目尽量效率高，开发容易，维护方便，升级简单，等等
系统架构师的职责： 
一、理解系统的业务需求，制定系统的整体框架（包括：技术框架和业务框架） 
二、对系统框架相关技术和业务进行培训，指导开发人员开发。并解决系统开发、运行中出现的各种问题。 系统架构师的目的： 

对系统的重用、扩展、安全、性能、伸缩性、简洁等做系统级的把握。 系统架构师能力要求： 
一、系统架构相关的知识和经验。 
二、很强的自学能力、分析能力、解决问题的能力。 
三、写作、沟通表达、培训。 

角色 
软件架构师Software Architect 定义 
主导系统全局分析设计和实施、负责软件构架和关键技术决策的角色 职责 
l、领导与协调整个项目中的技术活动（分析、设计和实施等） 2、推动主要的技术决策，并最终表达为软件构架 3、确定和文档化系统的相对构架而言意义重大的方面，包括系统的需求、设计、实施和部署等“视图” 4、确定设计元素的分组以及这些主要分组之间的接口 5、为技术决策提供规则，平衡各类涉众的不同关注点，化解技术风险，并保证相关决定被有效的传达和贯彻 6、理解、评价并接收系统需求 7、评价和确认软件架构的实现 专业技能 
l、技术全面、成熟练达、洞察力强、经验丰富，具备在缺乏完整信息、众多问题交织一团、模糊和矛盾的情况下，迅速抓住问题要害，并做出合理的关键决定的能力 l、具备战略性和前瞻性思维能力，善于把握全局，能够在更高抽象级别上进行思考； l、对项目开发涉及的所有问题领域都有经验，包括彻底地理解项目需求，开展分析设计之类软件工程活动等 2、具备领导素质，以在各小组之间推进技术工作，并在项目压力下做出牢靠的关键决策 3、拥有优秀的沟通能力，用以进行说服、鼓励和指导等活动，并赢得项目成员的信任； 4、以目标导向和主动的方式来不带任何感情色彩地关注项目结果，构架师应当是项目背后的技术推动力，而非构想者或梦想家（追求完美） 5、精通构架设计的理论、实践和工具，并掌握多种参考构架、主要的可重用构架机制和模式（例如J2EE架构等）； 6、具备系统设计员的所有技能，但涉及面更广、抽象级别更高； 活动 
确定用例或需求的优先级、进行构架分析、创建构架的概念验证原型、评估构架的概念验证原型的可行性、组织系统实施模型、描述系统分布结构、描述运行时刻构架、确定设计机制、确定设计元素、合并已有设计元素 工件 
软件构架文档、参考构架、分析模型、设计模型、实施模型、部署模型、构架概念验证原型、接口、事件、信号与协议 系统架构师  


65 tomcat的链接模式，是单线程还是多线程？
tomcat是怎样多线程处理http请求并将代码执行到controller里的的
1.线程池，thread = threadPool.getThread(),thread.executeHttp(htttpRequest),thread的start方法执行里面调用：每个thread里再获取所有的controller，根据传进入thread的httprequest找到相应的controllerer对象获取出来，controller对象就开始执行了嘛。
2.轨迹：线程池-》线程-》传request->线程找到对应的controller，执行
3.Main线程负责向子线程传入参数，任何线程的启动都是由主线程来启动加载的

1. tomcat中，并发的请求是采用多线程处理：并发过程中，每个请求带来的处理开始会从线程池取一个线程，如果并发量高于阈值则会等待线程池有空余
2.tomcat 本身对于每个请求接收处理到调用相应servlet中间这段过程，是线程安全的，放心容器肯定考虑到这个问题
3.tomcat中servlet采用的单例模式，所以servlet需要注意尽量写成线程安全类 

66 tomcat启动加载java项目的过程？
基于Java的Web 应用程序是 servlet、JSP 页面、静态页面、类和其他资源的集合，它们可以用标准方式打包，并运行在来自多个供应商的多个容器。Web 应用程序存在于结构化层次结构的目录中，该层次结构是由 Java Servlet 规范定义的。Web 应用程序的根目录包含直接存储或存储在子文件夹中的所有公共资源，比如图像、HTML 页面等。构成：Web应用由Web组件(一组Java类库)、html文件，静态资源文件（如图像）、帮助类和库组成。
1 – Tomcat Server的组成部分

1.1 – Server
A Server element represents the entire Catalina servlet container. (Singleton)

1.2 – Service
A Service element represents the combination of one or more Connector components that share a single Engine
Service是这样一个集合：它由一个或者多个Connector组成，以及一个Engine，负责处理所有Connector所获得的客户请求

1.3 – Connector
一个Connector将在某个指定端口上侦听客户请求，并将获得的请求交给Engine来处理，从Engine处获得回应并返回客户
TOMCAT有两个典型的Connector，一个直接侦听来自browser的http请求，一个侦听来自其它WebServer的请求
Coyote Http/1.1 Connector 在端口8080处侦听来自客户browser的http请求
Coyote JK2 Connector 在端口8009处侦听来自其它WebServer(Apache)的servlet/jsp代理请求

1.4 – Engine
The Engine element represents the entire request processing machinery associated with a particular Service
It receives and processes all requests from one or more Connectors
and returns the completed response to the Connector for ultimate transmission back to the client
Engine下可以配置多个虚拟主机Virtual Host，每个虚拟主机都有一个域名
当Engine获得一个请求时，它把该请求匹配到某个Host上，然后把该请求交给该Host来处理
Engine有一个默认虚拟主机，当请求无法匹配到任何一个Host上的时候，将交给该默认Host来处理

1.5 – Host
代表一个Virtual Host，虚拟主机，每个虚拟主机和某个网络域名Domain Name相匹配
每个虚拟主机下都可以部署(deploy)一个或者多个Web App，每个Web App对应于一个Context，有一个Context path
当Host获得一个请求时，将把该请求匹配到某个Context上，然后把该请求交给该Context来处理
匹配的方法是“最长匹配”，所以一个path==””的Context将成为该Host的默认Context
所有无法和其它Context的路径名匹配的请求都将最终和该默认Context匹配

1.6 – Context
一个Context对应于一个Web Application，一个Web Application由一个或者多个Servlet组成
Context在创建的时候将根据配置文件$CATALINA_HOME/conf/web.xml和$WEBAPP_HOME/WEB-INF/web.xml载入Servlet类
当Context获得请求时，将在自己的映射表(mapping table)中寻找相匹配的Servlet类
如果找到，则执行该类，获得请求的回应，并返回
2 – Tomcat Server的结构图

3 – 配置文件$CATALINA_HOME/conf/server.xml的说明

该文件描述了如何启动Tomcat Server

 
 <!----------------------------------------------------------------------------------------------->

<!-- 启动Server 在端口8005处等待关闭命令 如果接受到"SHUTDOWN"字符串则关闭服务器 -->
<Server port="8005" shutdown="SHUTDOWN" debug="0">
<!-- Listener ??? 目前没有看到这里 -->
<Listener className="org.apache.catalina.mbeans.ServerLifecycleListener" debug="0"/>
<Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" debug="0"/>
<!-- Global JNDI resources ??? 目前没有看到这里，先略去 -->
<GlobalNamingResources>
 ... ... ... ...
</GlobalNamingResources>
<!-- Tomcat的Standalone Service Service是一组Connector的集合 它们共用一个Engine来处理所有Connector收到的请求 -->
<Service name="Tomcat-Standalone">
<!-- Coyote HTTP/1.1 Connector className : 该Connector的实现类是org.apache.coyote.tomcat4.CoyoteConnector port :
在端口号8080处侦听来自客户browser的HTTP1.1请求 minProcessors : 该Connector先创建5个线程等待客户请求，
每个请求由一个线程负责 maxProcessors : 当现有的线程不够服务客户请求时，若线程总数不足75个，则创建新线程来处理请求
acceptCount : 当现有线程已经达到最大数75时，为客户请求排队 当队列中请求数超过100时，后来的请求返回Connection refused
错误 redirectport : 当客户请求是https时，把该请求转发到端口8443去 其它属性略 -->
<Connector className="org.apache.coyote.tomcat4.CoyoteConnector"
 port="8080"
 minProcessors="5" maxProcessors="75" acceptCount="100"
 enableLookups="true"
 redirectPort="8443"
 debug="0"
 connectionTimeout="20000"
 useURIValidationHack="false"
 disableUploadTimeout="true" />
<!-- Engine用来处理Connector收到的Http请求 它将匹配请求和自己的虚拟主机，

并把请求转交给对应的Host来处理默认虚拟主机是localhost -->
<Engine name="Standalone" defaultHost="localhost" debug="0">
<!-- 日志类，目前没有看到，略去先 -->
<Logger className="org.apache.catalina.logger.FileLogger" .../>
<!-- Realm，目前没有看到，略去先 -->
<Realm className="org.apache.catalina.realm.UserDatabaseRealm" .../>
<!-- 虚拟主机localhost appBase : 该虚拟主机的根目录是webapps/ 它将匹配请求和
自己的Context的路径，并把请求转交给对应的Context来处理 -->

<Host name="localhost" debug="0" appBase="webapps" unpackWARs="true" autoDeploy="true">
<!-- 日志类，目前没有看到，略去先 -->
<Logger className="org.apache.catalina.logger.FileLogger" .../>
<!-- Context，对应于一个Web App path : 该Context的路径名是""，故该Context是该Host的
默认Context docBase : 该Context的根目录是webapps/mycontext/ -->

<Context path="" docBase="mycontext" debug="0"/>
<!-- 另外一个Context，路径名是/wsota -->
<Context path="/wsota" docBase="wsotaProject" debug="0"/>
</Host>
</Engine>
</Service>
</Server>

<!----------------------------------------------------------------------------------------------->

 
4 – Context的部署配置文件web.xml的说明
一个Context对应于一个Web App，每个Web App是由一个或者多个servlet组成的
当一个Web App被初始化的时候，它将用自己的ClassLoader对象载入“部署配置文件web.xml”中定义的每个servlet类
它首先载入在$CATALINA_HOME/conf/web.xml中部署的servlet类
然后载入在自己的Web App根目录下的WEB-INF/web.xml中部署的servlet类
web.xml文件有两部分：servlet类定义和servlet映射定义
每个被载入的servlet类都有一个名字，且被填入该Context的映射表(mapping table)中，和某种URL PATTERN对应
当该Context获得请求时，将查询mapping table，找到被请求的servlet，并执行以获得请求回应
分析一下所有的Context共享的web.xml文件，在其中定义的servlet被所有的Web App载入

 

 <!----------------------------------------------------------------------------------------------->
<web-app>
<!-- 概述： 该文件是所有的WEB APP共用的部署配置文件， 每当一个WEB APP
被DEPLOY，该文件都将先被处理，然后才是WEB APP自己的/WEB-INF/web.xml -->
<!-- +-------------------------+ -->
<!-- | servlet类定义部分 | -->
<!-- +-------------------------+ -->
<!-- DefaultServlet
当用户的HTTP请求无法匹配任何一个servlet的时候，该servlet被执行

URL PATTERN MAPPING : / -->

<servlet>
<servlet-name>default</servlet-name>
<servlet-class>
org.apache.catalina.servlets.DefaultServlet
</servlet-class>
<init-param>
   <param-name>debug</param-name>
   <param-value>0</param-value>
</init-param>
<init-param>
   <param-name>listings</param-name>
   <param-value>true</param-value>
</init-param>
<load-on-startup>1</load-on-startup>
</servlet>
<!-- InvokerServlet
处理一个WEB APP中的匿名servlet 当一个servlet被编写并编译放入
/WEB-INF/classes/中，却没有在/WEB-INF/web.xml中定义的时候
该servlet被调用，把匿名servlet映射成/servlet/ClassName的形式
URL PATTERN MAPPING : /servlet/* -->

<servlet>
   <servlet-name>invoker</servlet-name>
   <servlet-class>org.apache.catalina.servlets.InvokerServlet </servlet-class>
   <init-param>
     <param-name>debug</param-name>
     <param-value>0</param-value>
   </init-param>
   <load-on-startup>2</load-on-startup>
</servlet>
<!-- JspServlet
当请求的是一个JSP页面的时候（*.jsp）该servlet被调用
它是一个JSP编译器，将请求的JSP页面编译成为servlet再执行
URL PATTERN MAPPING : *.jsp -->

<servlet>
  <servlet-name>jsp</servlet-name>
  <servlet-class>org.apache.jasper.servlet.JspServlet</servlet-class>
  <init-param>
     <param-name>logVerbosityLevel</param-name>
     <param-value>WARNING</param-value>
  </init-param>
 <load-on-startup>3</load-on-startup>
</servlet>

<!-- +-
<!-- | servlet映射定义部分 | -->
<!-- +---------------------------+ -->
<servlet-mapping>
  <servlet-name>default</servlet-name>
  <url-pattern>/</url-pattern>
</servlet-mapping>
<servlet-mapping>
   <servlet-name>invoker</servlet-name>
   <url-pattern>/servlet/*</url-pattern>
</servlet-mapping>

<servlet-mapping>
  <servlet-name>jsp</servlet-name>
  <url-pattern>*.jsp</url-pattern>
</servlet-mapping>
<!-- +------------------------+ -->
<!-- | 其它部分，略去先 | -->
<!-- +------------------------+ -->
... ... ... ...
</web-app>
<!----------------------------------------------------------------------------------------------->


5 – Tomcat Server处理一个http请求的过程

假设来自客户的请求为：
http://localhost:8080/wsota/wsota_index.jsp

1) 请求被发送到本机端口8080，被在那里侦听的Coyote HTTP/1.1 Connector获得
2) Connector把该请求交给它所在的Service的Engine来处理，并等待来自Engine的回应
3) Engine获得请求localhost/wsota/wsota_index.jsp，匹配它所拥有的所有虚拟主机Host
4) Engine匹配到名为localhost的Host（即使匹配不到也把请求交给该Host处理，因为该Host被定义为该Engine的默认主机）
5) localhost Host获得请求/wsota/wsota_index.jsp，匹配它所拥有的所有Context
6) Host匹配到路径为/wsota的Context（如果匹配不到就把该请求交给路径名为””的Context去处理）
7) path=”/wsota”的Context获得请求/wsota_index.jsp，在它的mapping table中寻找对应的servlet
8) Context匹配到URL PATTERN为*.jsp的servlet，对应于JspServlet类
9) 构造HttpServletRequest对象和HttpServletResponse对象，作为参数调用JspServlet的doGet或doPost方法
10)Context把执行完了之后的HttpServletResponse对象返回给Host
11)Host把HttpServletResponse对象返回给Engine
12)Engine把HttpServletResponse对象返回给Connector
13)Connector把HttpServletResponse对象返回给客户browser
67 垃圾回收的最佳做法？
垃圾收集算法：
1、标记-清除算法：
    首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象。标记过程中 实际上即时上面说的finaLize()的过程。主要缺点一个是效率问题。另外一个是空间问题，标记清除后会产生大量不连续的内存碎片。
2、复制算法：
   这种算法将可用内存按容量划分为大小相等的两块，每次只使用其中的一块，当这一块的内存用完了。就将还存活着的对象复制到另外一块上面，然后再把已经使用过的内存空间一次清理掉。
3、标记-整理算法：
    复制收集算法在对象存活率较高时就要执行较多的复制操作，效率将会遍低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以对应被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。
标记过程仍然与标记-清除算法一样，但是后续步骤不是直接将对可回收对象进行清理，而是让所有存活的对象都向领一端移动，然后直接清理掉端边界以外的内存。
4、分代收集算法：
  当代商业虚拟机的垃圾收集都采用的是“分代收集算法” ，根据对象的存活周期的不同，将内存化为几块，一般是把java堆分为新生代和老年代。这样就可以根据各个年代的特点采用最合适的收集算法。
新生代选用复制算法，老年代使用标记-清理算法 或者 标记-整理算法。


68 简述redis提供的6种数据淘汰策略？
    在 redis 中，允许用户设置最大使用内存大小 server.maxmemory，在内存限定的情况下是很有用的。譬如，在一台 8G 机子上部署了 4 个 redis 服务点，每一个服务点分配 1.5G 的内存大小，减少内存紧张的情况，由此获取更为稳健的服务。
　　redis中当内存超过限制时，按照配置的策略，淘汰掉相应的kv，使得内存可以继续留有足够的空间保存新的数据。redis 确定驱逐某个键值对后，会删除这个数据并，并将这个数据变更消息发布到本地（AOF 持久化）和从机（主从连接）。
　　redis的conf文件中有对该机制的一份很好的解释：　　
    注意：在redis按照master-slave使用时，其maxmeory应设置的比实际物理内存稍小一些，给slave output buffer留有足够的空间。
　　redis 提供 6种数据淘汰策略：　　
    1 volatile-lru:从设置了过期时间的数据集中，选择最近最久未使用的数据释放；
    2 allkeys-lru:从数据集中(包括设置过期时间以及未设置过期时间的数据集中)，选择最近最久未使用的数据释放；
    3 volatile-random:从设置了过期时间的数据集中，随机选择一个数据进行释放；
    4 allkeys-random:从数据集中(包括了设置过期时间以及未设置过期时间)随机选择一个数据进行入释放；
    5 volatile-ttl：从设置了过期时间的数据集中，选择马上就要过期的数据进行释放操作；
    6 noeviction：不删除任意数据(但redis还会根据引用计数器进行释放),这时如果内存不够时，会直接返回错误。
    默认的内存策略是noeviction，在Redis中LRU算法是一个近似算法，默认情况下，Redis随机挑选5个键，并且从中选取一个最近最久未使用的key进行淘汰，在配置文件中可以通过maxmemory-samples的值来设置redis需要检查key的个数,但是栓查的越多，耗费的时间也就越久,但是结构越精确(也就是Redis从内存中淘汰的对象未使用的时间也就越久~),设置多少，综合权衡。


69 Dubbo源码使用了哪些设计模式？
1、工厂模式 
     ServiceConfig中有个字段，代码是这样的： 
   private static final Protocol protocol =ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();  
  Dubbo里有很多这种代码。这也是一种工厂模式，只是实现类的获取采用了jdkspi的机
制。这么实现的优点是可扩展性强，想要扩展实现，只需要在classpath下增加个文件就可
以了，代码零侵入。另外，像上面的Adaptive实现，可以做到调用时动态决定调用哪个实
现，但是由于这种实现采用了动态代理，会造成代码调试比较麻烦，需要分析出实际调用的
实现类。

2、装饰器模式 
Dubbo在启动和调用阶段都大量使用了装饰器模式。以Provider提供的调用链为例，具
体的调用链代码是在ProtocolFilterWrapper的buildInvokerChain完成的，具体是将注解中含
有group=provider的Filter实现，按照order排序，最后的调用顺序是 
查看文本打印 
   EchoFilter-》ClassLoaderFilter-》GenericFilter-》ContextFilter-》ExceptionFilter-》  
   TimeoutFilter-》MonitorFilter-》TraceFilter。  

 更确切地说，这里是装饰器和责任链模式的混合使用。例如，EchoFilter的作用是判断
是否是回声测试请求，是的话直接返回内容，这是一种责任链的体现。而像ClassLoaderFilter
则只是在主功能上添加了功能，更改当前线程的ClassLoader，这是典型的装饰器模式。

3、观察者模式 
 Dubbo的provider启动时，需要与注册中心交互，先注册自己的服务，再订阅自己的服
务，订阅时，采用了观察者模式，开启一个listener。注册中心会每5秒定时检查是否有服
务更新，如果有更新，向该服务的提供者发送一个notify消息，provider接受到notify消息
后，即运行NotifyListener的notify方法，执行监听器方法。 

4、动态代理模式 
      Dubbo扩展jdkspi的类ExtensionLoader的Adaptive实现是典型的动态代理实现。Dubbo
需要灵活地控制实现类，即在调用阶段动态地根据参数决定调用哪个实现类，所以采用先生
成代理类的方法，能够做到灵活的调用。生成代理类的代码是ExtensionLoader的
createAdaptiveExtensionClassCode方法。代理类的主要逻辑是，获取URL参数中指定参数的
值作为获取实现类的key。

70 多线程同步锁有哪些？
A，RentrantLock，可重入的互斥锁，可中断可限时，公平锁，必须在finally释放锁，而synchronize由JVM释放。可重入但是要重复退出，普通的lock()不能响应中断，lock.lockInterruptbly()可响应中断，可以限时tryLock()，超时返回false，不会永久等待构成死锁。
B，Confition条件变量，signal唤醒其中1个在等待的线程，signalall唤醒所有在等待的线程await()等待并释放锁，与lock结合使用。
C，semaphore信号量，多个线程比（额度=10）进入临界区，其他则阻塞在临界区外。
D，ReadWriteLock，读读不互斥，读写互斥，写写互斥。
E，CountDownLantch倒数计时器，countdown()和await()
F，CyCliBarrier
G，LockSupport，方法park和unpark



java允许多线程并发控制，当多个线程同时操作一个可共享的资源变量时（如数据的增删改查），
将会导致数据不准确，相互之间产生冲突，因此加入同步锁以避免在该线程没有完成操作之前，被其他线程的调用，
从而保证了该变量的唯一性和准确性。
同步的方式

1.同步方法
即有synchronized关键字修饰的方法。
由于java的每个对象都有一个内置锁，当用此关键字修饰方法时，
内置锁会保护整个方法。在调用该方法前，需要获得内置锁，否则就处于阻塞状态。

代码如： 
public synchronized void save(){}

注： synchronized关键字也可以修饰静态方法，此时如果调用该静态方法，将会锁住整个类

2.同步代码块
即有synchronized关键字修饰的语句块。
被该关键字修饰的语句块会自动被加上内置锁，从而实现同步

代码如： 
synchronized(object){ 
}


注：同步是一种高开销的操作，因此应该尽量减少同步的内容。 
通常没有必要同步整个方法，使用synchronized代码块同步关键代码即可。 

package com.xhj.thread;

    /**
     * 线程同步的运用
     * 
     * @author XIEHEJUN
     * 
     */
    public class SynchronizedThread {

        class Bank {

            private int account = 100;

            public int getAccount() {
                return account;
            }

            /**
             * 用同步方法实现
             * 
             * @param money
             */
            public synchronized void save(int money) {
                account += money;
            }

            /**
             * 用同步代码块实现
             * 
             * @param money
             */
            public void save1(int money) {
                synchronized (this) {
                    account += money;
                }
            }
        }

        class NewThread implements Runnable {
            private Bank bank;

            public NewThread(Bank bank) {
                this.bank = bank;
            }

            @Override
            public void run() {
                for (int i = 0; i < 10; i++) {
                    // bank.save1(10);
                    bank.save(10);
                    System.out.println(i + "账户余额为：" + bank.getAccount());
                }
            }

        }

        /**
         * 建立线程，调用内部类
         */
        public void useThread() {
            Bank bank = new Bank();
            NewThread new_thread = new NewThread(bank);
            System.out.println("线程1");
            Thread thread1 = new Thread(new_thread);
            thread1.start();
            System.out.println("线程2");
            Thread thread2 = new Thread(new_thread);
            thread2.start();
        }

        public static void main(String[] args) {
            SynchronizedThread st = new SynchronizedThread();
            st.useThread();
        }

    }

3.使用特殊域变量(volatile)实现线程同步
a.volatile关键字为域变量的访问提供了一种免锁机制，
b.使用volatile修饰域相当于告诉虚拟机该域可能会被其他线程更新，
c.因此每次使用该域就要重新计算，而不是使用寄存器中的值
d.volatile不会提供任何原子操作，它也不能用来修饰final类型的变量

例如：
在上面的例子当中，只需在account前面加上volatile修饰，即可实现线程同步。

代码实例： 

    1
    2

  class Bank {
            //需要同步的变量加上volatile
            private volatile int account = 100;

            public int getAccount() {
                return account;
            }
            //这里不再需要synchronized 
            public void save(int money) {
                account += money;
            }
        ｝

多线程中的非同步问题主要出现在对域的读写上，如果让域自身避免这个问题，则就不需要修改操作该域的方法。

4.使用重入锁实现线程同步
在JavaSE5.0中新增了一个java.util.concurrent包来支持同步。
ReentrantLock类是可重入、互斥、实现了Lock接口的锁，
它与使用synchronized方法和快具有相同的基本行为和语义，并且扩展了其能力

ReenreantLock类的常用方法有：

    ReentrantLock() : 创建一个ReentrantLock实例 
    lock() : 获得锁 
    unlock() : 释放锁 

    class Bank {

            private int account = 100;
            //需要声明这个锁
            private Lock lock = new ReentrantLock();
            public int getAccount() {
                return account;
            }
            //这里不再需要synchronized 
            public void save(int money) {
                lock.lock();
                try{
                    account += money;
                }finally{
                    lock.unlock();
                }

            }
        ｝

注：关于Lock对象和synchronized关键字的选择： 
    a.最好两个都不用，使用一种java.util.concurrent包提供的机制， 
        能够帮助用户处理所有与锁相关的代码。 
    b.如果synchronized关键字能满足用户的需求，就用synchronized，因为它能简化代码 
    c.如果需要更高级的功能，就用ReentrantLock类，此时要注意及时释放锁，否则会出现死锁，通常在finally代码释放锁 

5.使用局部变量实现线程同步
如果使用ThreadLocal管理变量，则每一个使用该变量的线程都获得该变量的副本，
副本之间相互独立，这样每一个线程都可以随意修改自己的变量副本，而不会对其他线程产生影响。

ThreadLocal 类的常用方法



ThreadLocal() : 创建一个线程本地变量 
get() : 返回此线程局部变量的当前线程副本中的值 
initialValue() : 返回此线程局部变量的当前线程的"初始值" 
set(T value) : 将此线程局部变量的当前线程副本中的值设置为value



例如： 
    在上面例子基础上，修改后的代码为：
    public class Bank{
            //使用ThreadLocal类管理共享变量account
            private static ThreadLocal<Integer> account = new ThreadLocal<Integer>(){
                @Override
                protected Integer initialValue(){
                    return 100;
                }
            };
            public void save(int money){
                account.set(account.get()+money);
            }
            public int getAccount(){
                return account.get();
            }
        }

注：ThreadLocal与同步机制
a.ThreadLocal与同步机制都是为了解决多线程中相同变量的访问冲突问题。
b.前者采用以”空间换时间”的方法，后者采用以”时间换空间”的方式 



71 栈溢出的原因有哪些？
是否递归的调用；大量循环；全局变量是否过多；数组，List，Map数据是否过大；用DDMS工具检查地方。

一、局部数组过大。当函数内部的数组过大时，有可能导致堆栈溢出。
二、递归调用层次太多。递归函数在运行时会执行压栈操作，当压栈次数太多时，也会导致堆栈溢出。
三、指针或数组越界。这种情况最常见，例如进行字符串拷贝，或处理用户输入等等。



72 内存溢出的原因
过多使用了static；static最好只用int和string等基本类型；大量的递归或者死循环；大数据项的查询，如返回表的所有记录，应该采用分页查询。检查是否有数组、List、map中存放的是对象的引用而不是对象，这些引用会让对应对象不能被释放。
栈过大会导致内存占用过多，频繁页交换阻碍效率。

ava.lang.OutOfMemoryError这个错误我相信大部分开发人员都有遇到过，产生该错误的原因大都出于以下原因：JVM内存过小、程序不严密，产生了过多的垃圾。

导致OutOfMemoryError异常的常见原因有以下几种：
    内存中加载的数据量过于庞大，如一次从数据库取出过多数据；
    集合类中有对对象的引用，使用完后未清空，使得JVM不能回收；
    代码中存在死循环或循环产生过多重复的对象实体；
    使用的第三方软件中的BUG；
    启动参数内存值设定的过小；

此错误常见的错误提示：
    tomcat:java.lang.OutOfMemoryError: PermGen space
    tomcat:java.lang.OutOfMemoryError: Java heap space
    weblogic:Root cause of ServletException java.lang.OutOfMemoryError
    resin:java.lang.OutOfMemoryError
    java:java.lang.OutOfMemoryError

解决java.lang.OutOfMemoryError的方法有如下几种：
一、增加jvm的内存大小。方法有： 1）在执行某个class文件时候，可以使用java -Xmx256M aa.class来设置运行aa.class时jvm所允许占用的最大内存为256M。 2）对tomcat容器，可以在启动时对jvm设置内存限度。对tomcat，可以在catalina.bat中添加：
set CATALINA_OPTS=-Xms128M -Xmx256M
set JAVA_OPTS=-Xms128M -Xmx256M
或者把%CATALINA_OPTS%和%JAVA_OPTS%代替为-Xms128M -Xmx256M
3）对resin容器，同样可以在启动时对jvm设置内存限度。在bin文件夹下创建一个startup.bat文件，内容如下：
@echo off
call "httpd.exe"  "-Xms128M" "-Xmx256M"
:end
其中"-Xms128M"为最小内存，"-Xmx256M"为最大内存。

二、 优化程序，释垃圾。
主要包括避免死循环，应该及时释放种资源：内存, 数据库的各种连接，防止一次载入太多的数据。导致java.lang.OutOfMemoryError的根本原因是程序不健壮。因此，从根本上解决Java内存溢出的唯一方法就是修改程序，及时地释放没用的对象，释放内存空间。 遇到该错误的时候要仔细检查程序，嘿嘿，遇多一次这种问题之后，以后写程序就会小心多了。
Java代码导致OutOfMemoryError错误的解决：

需要重点排查以下几点：
    检查代码中是否有死循环或递归调用。
    检查是否有大循环重复产生新对象实体。
    检查对数据库查询中，是否有一次获得全部数据的查询。一般来说，如果一次取十万条记录到内存，就可能引起内存溢出。这个问题比较隐蔽，在上线前，数据库中数据较少，不容易出问题，上线后，数据库中数据多了，一次查询就有可能引起内存溢出。因此对于数据库查询尽量采用分页的方式查询。
    检查List、MAP等集合对象是否有使用完后，未清除的问题。List、MAP等集合对象会始终存有对对象的引用，使得这些对象不能被GC回收。

tomcat中java.lang.OutOfMemoryError: PermGen space异常处理
PermGen space的全称是Permanent Generation space,是指内存的永久保存区域,这块内存主要是被JVM存放Class和Meta信息的,Class在被Loader时就会被放到PermGen space中, 它和存放类实例(Instance)的Heap区域不同,GC(Garbage Collection)不会在主程序运行期对PermGen space进行清理，所以如果你的应用中有很多CLASS的话,就很可能出现PermGen space错误, 这种错误常见在web服务器对JSP进行pre compile的时候。如果你的WEB APP下都用了大量的第三方jar, 其大小超过了jvm默认的大小(4M)那么就会产生此错误信息了。 解决方法： 手动设置MaxPermSize大小修改TOMCAT_HOME/bin/catalina.sh在
echo "Using CATALINA_BASE:   $CATALINA_BASE"

上面加入以下行：

JAVA_OPTS="-server -XX:PermSize=64M -XX:MaxPermSize=128m

建议：将相同的第三方jar文件移置到tomcat/shared/lib目录下，这样可以达到减少jar 文档重复占用内存的目的。
weblogic中java.lang.OutOfMemoryError异常处理

错误提示： Root cause of ervletException java.lang.OutOfMemoryError 解决办法：调整bea/weblogic/common中CommEnv中参数

    :sun
　　if "%PRODUCTION_MODE%" == "true" goto sun_prod_mode
　　set JAVA_VM=-client
　　set MEM_ARGS=-Xms256m -Xmx512m -XX:MaxPermSize=256m
　　set JAVA_OPTIONS=%JAVA_OPTIONS% -Xverify:none
　　goto continue
　　:sun_prod_mode
　　set JAVA_VM=-server
　　set MEM_ARGS=-Xms256m -Xmx512m -XX:MaxPermSize=256m
　　goto continue

Resin下java.lang.OutOfMemoryError异常处理

产生内存溢出的原因：
出现这个错误，一般是因为JVM物理内存过小。默认的Java虚拟机最大内存仅为64兆，这在开发调试过程中可能没有问题，但在实际的应用环境中是远远不能满足需要的，除非你的应用非常小，也没什么访问量。否则你可能会发现程序运行一段时间后包java.lang.OutOfMemoryError的错误。因此我们需要提升resin可用的虚拟机内存的大小。

解决方法：
修改/usr/local/resin/bin/httpd.sh中的args选项 添加参数-Xms（初始内存）和-Xmx（最大能够使用内存大小）可以用来限制JVM的物理内存使用量。例如：
args="-Xms128m -Xmx256m"
设置后，JVM初始物理内存是128m，最大能使用物理内存为256m。
这两个值应该由系统管理员根据服务器的实际情况进行设置。


73 单例模式的7种写法？
懒汉2种，枚举，饿汉2种，静态内部类，双重校验锁（推荐）。

第一种（懒汉，线程不安全）：
    public class Singleton {  
        private static Singleton instance;  
        private Singleton (){}  
      
        public static Singleton getInstance() {  
        if (instance == null) {  
            instance = new Singleton();  
        }  
        return instance;  
        }  
    }  
 这种写法lazy loading很明显，但是致命的是在多线程不能正常工作。

第二种（懒汉，线程安全）：
    public class Singleton {  
        private static Singleton instance;  
        private Singleton (){}  
        public static synchronized Singleton getInstance() {  
        if (instance == null) {  
            instance = new Singleton();  
        }  
        return instance;  
        }  
    }  
 这种写法能够在多线程中很好的工作，而且看起来它也具备很好的lazy loading，但是，遗憾的是，效率很低，99%情况下不需要同步。

第三种（饿汉）：
    public class Singleton {  
        private static Singleton instance = new Singleton();  
        private Singleton (){}  
        public static Singleton getInstance() {  
        return instance;  
        }  
    } 

 这种方式基于classloder机制避免了多线程的同步问题，不过，instance在类装载时就实例化，虽然导致类装载的原因有很多种，在单例模式中大多数都是调用getInstance方法， 但是也不能确定有其他的方式（或者其他的静态方法）导致类装载，这时候初始化instance显然没有达到lazy loading的效果。

第四种（饿汉，变种）：
    public class Singleton {  
        private Singleton instance = null;  
        static {  
        instance = new Singleton();  
        }  
        private Singleton (){}  
        public static Singleton getInstance() {  
        return this.instance;  
        }  
    }  
 表面上看起来差别挺大，其实更第三种方式差不多，都是在类初始化即实例化instance。

第五种（静态内部类）：
    public class Singleton {  
        private static class SingletonHolder {  
        private static final Singleton INSTANCE = new Singleton();  
        }  
        private Singleton (){}  
        public static final Singleton getInstance() {  
        return SingletonHolder.INSTANCE;  
        }  
    }  

这种方式同样利用了classloder的机制来保证初始化instance时只有一个线程，它跟第三种和第四种方式不同的是（很细微的差别）：第三种和第四种方式是只要Singleton类被装载了，那么instance就会被实例化（没有达到lazy loading效果），而这种方式是Singleton类被装载了，instance不一定被初始化。因为SingletonHolder类没有被主动使用，只有显示通过调用getInstance方法时，才会显示装载SingletonHolder类，从而实例化instance。想象一下，如果实例化instance很消耗资源，我想让他延迟加载，另外一方面，我不希望在Singleton类加载时就实例化，因为我不能确保Singleton类还可能在其他的地方被主动使用从而被加载，那么这个时候实例化instance显然是不合适的。这个时候，这种方式相比第三和第四种方式就显得很合理。

第六种（枚举）：
    public enum Singleton {  
        INSTANCE;  
        public void whateverMethod() {  
        }  
    }  
 这种方式是Effective Java作者Josh Bloch 提倡的方式，它不仅能避免多线程同步问题，而且还能防止反序列化重新创建新的对象，可谓是很坚强的壁垒啊，不过，个人认为由于1.5中才加入enum特性，用这种方式写不免让人感觉生疏，在实际工作中，我也很少看见有人这么写过。

第七种（双重校验锁）：
    public class Singleton {  
        private volatile static Singleton singleton;  
        private Singleton (){}  
        public static Singleton getSingleton() {  
        if (singleton == null) {  
            synchronized (Singleton.class) {  
            if (singleton == null) {  
                singleton = new Singleton();  
            }  
            }  
        }  
        return singleton;  
        }  
    }  
 这个是第二种方式的升级版，俗称双重检查锁定，详细介绍请查看：http://www.ibm.com/developerworks/cn/java/j-dcl.html

在JDK1.5之后，双重检查锁定才能够正常达到单例效果。

总结

有两个问题需要注意：

1.如果单例由不同的类装载器装入，那便有可能存在多个单例类的实例。假定不是远端存取，例如一些servlet容器对每个servlet使用完全不同的类装载器，这样的话如果有两个servlet访问一个单例类，它们就都会有各自的实例。

2.如果Singleton实现了java.io.Serializable接口，那么这个类的实例就可能被序列化和复原。不管怎样，如果你序列化一个单例类的对象，接下来复原多个那个对象，那你就会有多个单例类的实例。

对第一个问题修复的办法是：

 

    private static Class getClass(String classname)      
                                             throws ClassNotFoundException {     
          ClassLoader classLoader = Thread.currentThread().getContextClassLoader();     
          
          if(classLoader == null)     
             classLoader = Singleton.class.getClassLoader();     
          
          return (classLoader.loadClass(classname));     
       }     
    }  

 对第二个问题修复的办法是：

 

    public class Singleton implements java.io.Serializable {     
       public static Singleton INSTANCE = new Singleton();     
          
       protected Singleton() {     
            
       }     
       private Object readResolve() {     
                return INSTANCE;     
          }    
    }   

 

对我来说，我比较喜欢第三种和第五种方式，简单易懂，而且在JVM层实现了线程安全（如果不是多个类加载器环境），一般的情况下，我会使用第三种方式，只有在要明确实现lazy loading效果时才会使用第五种方式，另外，如果涉及到反序列化创建对象时我会试着使用枚举的方式来实现单例，不过，我一直会保证我的程序是线程安全的，而且我永远不会使用第一种和第二种方式，如果有其他特殊的需求，我可能会使用第七种方式，毕竟，JDK1.5已经没有双重检查锁定的问题了。

========================================================================

 superheizai同学总结的很到位：

 

不过一般来说，第一种不算单例，第四种和第三种就是一种，如果算的话，第五种也可以分开写了。所以说，一般单例都是五种写法。懒汉，恶汉，双重校验锁，枚举和静态内部类。

我很高兴有这样的读者，一起共勉。



74 lucence倒排索引？
三个文件：字典文件，频率文件，位置文件。词典文件不仅保存有每个关键词，还保留了指向频率文件和位置文件的指针，通过指针可以找到该关键字的频率信息和位置信息。
field的概念，用于表达信息所在位置（如标题中，文章中，url中），在建索引中，该field信息也记录在词典文件中，每个关键词都有一个field信息(因为每个关键字一定属于一个或多个field)。
关键字是按字符顺序排列的（lucene没有使用B树结构），因此lucene可以用二元搜索算法快速定位关键词。
假设要查询单词 “live”，lucene先对词典二元查找、找到该词，通过指向频率文件的指针读出所有文章号，然后返回结果。词典通常非常小，因而，整个过程的时间是毫秒级的。 　　
对词典文件中的关键词进行了压缩，关键词压缩为<前缀长度，后缀>，例如：当前词为“阿拉伯语”，上一个词为“阿拉伯”，那么“阿拉伯语”压缩为<3，语>。对数字的压缩，数字只保存与上一个值的差值。

关系数据库不适合做全文搜索:
    like '%xxx%'效率很慢，建的索引将无效，查询的时候会像翻书一样一页一页的翻
    返回的结果没有匹配度的概念，比如可能希望搜索的关键词在文章中出现的次数越多越是我想要的文章
    当搜索live的时候，也想把LIVE/lives/living搜出来，但是数据库很难做到

一、简介
    倒排索引源于实际应用中需要根据属性的值来查找记录。
    这种索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址、出现频次等相关信息。
    由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引(inverted index)。
    搜索引擎的关键步骤就是建立倒排索引.
    当用户搜索的时候先找到关键词，也就找到了含有该关键词的相关文章，然后计算出最相关的前几十篇文章返回给用户。

二、Lucene倒排索引原理
(0)设有两篇文章1和2
   文章1的内容为：Tom lives in Guangzhou,I live in Guangzhou too
   文章2的内容为：He once lived in Shanghai.

(1)获取关键字
    全文分析：由于lucene是基于关键词索引和查询的，首先我们要取得这两篇文章的关键词，
    通常我们需要如下处理措施:
    a.我们现在有的是文章内容，即一个字符串，我们先要找出字符串中的所有单词，即分词。
      英文单词由于用空格分隔，比较好处理。中文单词间是连在一起的需要特殊的分词处理。
    b.文章中的”in”, “once” “too”等词没有什么实际意义，中文中的“的”“是”等字通常也无具体含义，
      这些不代表概念的词可以过滤掉
    c.用户通常希望查“He”时能把含“he”，“HE”的文章也找出来，所以所有单词需要统一大小写。
    d.用户通常希望查“live”时能把含“lives”，“lived”的文章也找出来，所以需要把“lives”，“lived”还原成“live”
    e.文章中的标点符号通常不表示某种概念，也可以过滤掉

    经过上面处理后:
　　文章1的所有关键词为：[tom] [live] [guangzhou] [i] [live] [guangzhou]
　　文章2的所有关键词为：[he] [live] [shanghai]

(2) 建立倒排索引
    有了关键词后，我们就可以建立倒排索引了。
    上面的对应关系是：“文章号”对“文章中所有关键词”。
    倒排索引把这个关系倒过来，变成：“关键词”对“拥有该关键词的所有文章号”。
    文章1，2经过倒排后变成:

        关键词       文章号
　　guangzhou     1
　　he                     2
　　i                        1
　　live                   1,2
　　shanghai        2
　　tom                  1

   通常仅知道关键词在哪些文章中出现还不够，我们还需要知道关键词在文章中出现次数和出现的位置，
   通常有两种位置：
       a)字符位置，即记录该词是文章中第几个字符（优点是关键词亮显时定位快）；
       b)关键词位置，即记录该词是文章中第几个关键词（优点是节约索引空间、词组（phase）查询快），lucene中记录的就是这种位置。

 加上“出现频率”和“出现位置”信息后，我们的索引结构变为：

 关键词         文章号     [出现频率]     出现位置
 guangzhou     1                 [2]                3，6
 he                     2                 [1]                1
 i                        1                  [1]               4
 live                   1                  [2]               2，5
                          2                  [1]               2
 shanghai        2                  [1]               3
 tom                  1                  [1]               1

以live这行为例我们说明一下该结构：
live在文章1中出现了2次，文章2中出现了一次，它的出现位置为“2,5,2”这表示什么呢？
我们需要结合文章号和出现频率来分析，
文章1中出现了2次，那么“2,5”就表示live在文章1的关键词中出现的两个位置，
文章2中出现了1次，剩下的“2”就表示live是文章2的关键词中第2个关键字。
　　
以上就是lucene索引结构中最核心的部分。
我们注意到关键字是按字符顺序排列的（lucene没有使用B树结构），
因此lucene可以用二元搜索算法(或叫二分查找/折半查找)快速定位关键词。

(3) 实现
实现时，lucene将上面三列分别作为:
词典文件（Term Dictionary）、频率文件(frequencies)、位置文件 (positions)保存。

其中词典文件不仅保存有每个关键词，还保留了指向频率文件和位置文件的指针，
通过指针可以找到该关键字的频率信息和位置信息。 　　

Lucene中使用了field的概念，用于表达信息所在位置（如标题中，文章中，url中），
在建索引中，该field信息也记录在词典文件中，每个关键词都有一个field信息(因为每个关键字一定属于一个或多个field)。

(4) 压缩算法
为了减小索引文件的大小，Lucene对索引还使用了压缩技术。
首先，对词典文件中的关键词进行了压缩，关键词压缩为<前缀长度，后缀>，
例如：当前词为“阿拉伯语”，上一个词为“阿拉伯”，那么“阿拉伯语”压缩为<3，语>。

其次大量用到的是对数字的压缩，数字只保存与上一个值的差值
（这样可以减小数字的长度，进而减少保存该数字需要的字节数）。
例如当前文章号是16389（不压缩要用3个字节保存），上一文章号是16382，压缩后保存7（只用一个字节）。

<5>应用原因
下面我们可以通过对该索引的查询来解释一下为什么要建立索引。 　　
假设要查询单词 “live”，lucene先对词典二元查找、找到该词，通过指向频率文件的指针读出所有文章号，然后返回结果。
词典通常非常小，因而，整个过程的时间是毫秒级的。 　　

而用普通的顺序匹配算法，不建索引，而是对所有文章的内容进行字符串匹配，
这个过程将会相当缓慢，当文章数目很大时，时间往往是无法忍受的。


75 ZooKeeper分布式高可用？
ZooKeeper 运行期间，集群中至少有过半的机器保存了最新数据。集群超过半数的机器能够正常工作，集群就能够对外提供服务。
zookeeper可以选出N台机器作主机，它可以实现M:N的备份；keepalive只能选出1台机器作主机，所以keepalive只能实现M:1的备份。
通常有以下两种部署方案：双机房部署（一个稳定性更好、设备更可靠的机房，这个机房就是主要机房，而另外一个机房则更加廉价一些，例如，对于一个由 7 台机器组成的 ZooKeeper 集群，通常在主要机房中部署 4 台机器，剩下的 3 台机器部署到另外一个机房中）；三机房部署（无论哪个机房发生了故障，剩下两个机房的机器数量都超过半数。在三个机房中都部署若干个机器来组成一个 ZooKeeper 集群。假设机器总数为 N，各机房机器数：N1 = (N-1)/2 ，N2=1~(N-N1)/2 ，N3 = N - N1 - N2 ）。
水平扩容就是向集群中添加更多机器，Zookeeper2种方式（不完美），一种是集群整体重启，另外一种是逐台进行服务器的重启。



我们通常部署zookeeper集群来实现高可用性，那么zookeeper是如何实现高可用性的呢？
集群组成

要搭建一个高可用的 ZooKeeper 集群，我们首先需要确定好集群的规模。关于 ZooKeeper 集群的服务器组成，相信很多对 ZooKeeper 了解但是理解不够深入的读者，都存在或曾经存在过这样一个错误的认识：为了使得 ZooKeeper 集群能够顺利地选举出 Leader，必须将 ZooKeeper 集群的服务器数部署成奇数。这里我们需要澄清的一点是：任意台 ZooKeeper 服务器都能部署且能正常运行。
其实关于 ZooKeeper 集群服务器数，ZooKeeper 官方确实给出了关于奇数的建议，但绝大部分 ZooKeeper 用户对于这个建议认识有偏差。在本书前面提到的“过半存活即可用”特性中，我们已经了解了，一个 ZooKeeper 集群如果要对外提供可用的服务，那么集群中必须要有过半的机器正常工作并且彼此之间能够正常通信。基于这个特性，如果想搭建一个能够允许 N 台机器 down 掉的集群，那么就要部署一个由 2*N+1 台服务器构成的 ZooKeeper 集群。因此，一个由 3 台机器构成的 ZooKeeper 集群，能够在挂掉 1 台机器后依然正常工作，而对于一个由 5 台服务器构成的 ZooKeeper 集群，能够对 2 台机器挂掉的情况进行容灾。注意，如果是一个由6台服务器构成的 ZooKeeper 集群，同样只能够挂掉 2 台机器，因为如果挂掉 3 台，剩下的机器就无法实现过半了。

因此，从上面的讲解中，我们其实可以看出，对于一个由 6 台机器构成的 ZooKeeper 集群来说，和一个由 5 台机器构成的 ZooKeeper 集群，其在容灾能力上并没有任何显著的优势，反而多占用了一个服务器资源。基于这个原因，ZooKeeper 集群通常设计部署成奇数台服务器即可。
容灾

所谓容灾，在 IT 行业通常是指我们的计算机信息系统具有的一种在遭受诸如火灾、地震、断电和其他基础网络设备故障等毁灭性灾难的时候，依然能够对外提供可用服务的能力。

对于一些普通的应用，为了达到容灾标准，通常我们会选择在多台机器上进行部署来组成一个集群，这样即使在集群的一台或是若干台机器出现故障的情况下，整个集群依然能够对外提供可用的服务。

而对于一些核心应用，不仅要通过使用多台机器构建集群的方式来提供服务，而且还要将集群中的机器部署在两个机房，这样的话，即使其中一个机房遭遇灾难，依然能够对外提供可用的服务。

上面讲到的都是应用层面的容灾模式，那么对于 ZooKeeper 这种底层组件来说，如何进行容灾呢？讲到这里，可能多少读者会有疑问，ZooKeeper 既然已经解决了单点问题，那为什么还要进行容灾呢？
单点问题

单点问题是分布式环境中最常见也是最经典的问题之一，在很多分布式系统中都会存在这样的单点问题。具体地说，单点问题是指在一个分布式系统中，如果某一个组件出现故障就会引起整个系统的可用性大大下降甚至是处于瘫痪状态，那么我们就认为该组件存在单点问题。

ZooKeeper 确实已经很好地解决了单点问题。我们已经了解到，基于“过半”设计原则，ZooKeeper 在运行期间，集群中至少有过半的机器保存了最新的数据。因此，只要集群中超过半数的机器还能够正常工作，整个集群就能够对外提供服务。
容灾

解决了单点问题，是不是该考虑容灾了呢？答案是肯定的，在搭建一个高可用的集群的时候依然需要考虑容灾问题。正如上面讲到的，如果集群中超过半数的机器还在正常工作，集群就能够对外提供正常的服务。那么，如果整个机房出现灾难性的事故，这时显然已经不是单点问题的范畴了。

在进行 ZooKeeper 的容灾方案设计过程中，我们要充分考虑到“过半原则”。也就是说，无论发生什么情况，我们必须保证 ZooKeeper 集群中有超过半数的机器能够正常工作。因此，通常有以下两种部署方案。
双机房部署

在进行容灾方案的设计时，我们通常是以机房为单位来考虑问题。在现实中，很多公司的机房规模并不大，因此双机房部署是个比较常见的方案。但是遗憾的是，在目前版本的 ZooKeeper 中，还没有办法能够在双机房条件下实现比较好的容灾效果——因为无论哪个机房发生异常情况，都有可能使得 ZooKeeper 集群中可用的机器无法超过半数。当然，在拥有两个机房的场景下，通常有一个机房是主要机房（一般而言，公司会花费更多的钱去租用一个稳定性更好、设备更可靠的机房，这个机房就是主要机房，而另外一个机房则更加廉价一些）。我们唯一能做的，就是尽量在主要机房部署更多的机器。例如，对于一个由 7 台机器组成的 ZooKeeper 集群，通常在主要机房中部署 4 台机器，剩下的 3 台机器部署到另外一个机房中。
三机房部署

既然在双机房部署模式下并不能实现好的容灾效果，那么对于有条件的公司，选择三机房部署无疑是个更好的选择，无论哪个机房发生了故障，剩下两个机房的机器数量都超过半数。假如我们有三个机房可以部署服务，并且这三个机房间的网络状况良好，那么就可以在三个机房中都部署若干个机器来组成一个 ZooKeeper 集群。

我们假定构成 ZooKeeper 集群的机器总数为 N，在三个机房中部署的 ZooKeeper 服务器数分别为 N1、N2 和 N3，如果要使该 ZooKeeper 集群具有较好的容灾能力，我们可以根据如下算法来计算 ZooKeeper 集群的机器部署方案。

1.）计算 N1

如果 ZooKeeper 集群的服务器总数是 N，那么：

N1 = (N-1)/2
在 Java 中，“/” 运算符会自动对计算结果向下取整操作。举个例子，如果 N=8，那么 N1=3；如果 N=7，那么 N1 也等于 3。

2.）计算 N2 的可选值

N2 的计算规则和 N1 非常类似，只是 N2的取值是在一个取值范围内：

N2 的取值范围是 1~(N-N1)/2
即如果 N=8，那么 N1=3，则 N2 的取值范围就是 1~2，分别是 1 和 2。注意，1 和 2 仅仅是 N2 的可选值，并非最终值——如果 N2 为某个可选值的时候，无法计算出 N3 的值，那么该可选值也无效。

3.） 计算 N3，同时确定 N2 的值

很显然，现在只剩下 N3 了，可以简单的认为 N3 的取值就是剩下的机器数，即：

N3 = N - N1 - N2
只是 N3 的取值必须满足 N3 < N1+N2。在满足这个条件的基础下，我们遍历步骤 2 中计算得到的 N2 的可选值，即可得到三机房部署时每个机房的服务器数量了。

现在我们以 7 台机器为例，来看看如何分配三机房的机器分布。根据算法的步骤 1，我们首先确定 N1 的取值为 3。根据算法的步骤 2，我们确定了 N2 的可选值为 1 和 2。最后根据步骤 3，我们遍历 N2 的可选值，即可得到两种部署方案，分别是 (3,1,3) 和 (3,2,2)。以下是 Java 程序代码对以上算法的一种简单实现：

public class Allocation {

    static final int n = 7;
    public static void main(String[] args){
        int n1,n2,n3;
        n1 = (n-1) / 2;
        int n2_max = (n-n1) / 2;
        for(int i=1; i<=n2_max; i++){
            n2 = i;
            n3 = n - n1 -n2;
            if(n3 >= (n1+n2)){
                continue;
            }
            System.out.println("("+n1+","+n2+","+n3+")");
        }
    }
}

水平扩容

水平可扩容可以说是对一个分布式系统在高可用性方面提出的基本的，也是非常重要的一个要求，通过水平扩容能够帮助系统在不进行或进行极少改进工作的前提下，快速提高系统对外的服务支撑能力。简单地讲，水平扩容就是向集群中添加更多的机器，以提高系统的服务质量。

很遗憾的是，ZooKeeper 在水平扩容扩容方面做得并不十分完美，需要进行整个集群的重启。通常有两种重启方式，一种是集群整体重启，另外一种是逐台进行服务器的重启。

（1）整体重启

所谓集群整体重启，就是先将整个集群停止，然后更新 ZooKeeper 的配置，然后再次启动。如果在你的系统中，ZooKeeper 并不是个非常核心的组件，并且能够允许短暂的服务停止（通常是几秒钟的时间间隔），那么不妨选择这种方式。在整体重启的过程中，所有该集群的客户端都无法连接上集群。等到集群再次启动，这些客户端就能够自动连接上——注意，整体启动前建立起的客户端会话，并不会因为此次整体重启而失效。也就是说，在整体重启期间花费的时间将不计入会话超时时间的计算中。

（2）逐台重启

这种方式更适合绝大多数的实际场景。在这种方式中，每次仅仅重启集群中的一台机器，然后逐台对整个集群中的机器进行重启操作。这种方式可以在重启期间依然保证集群对外的正常服务。





76 讲讲mybatis的连接池？
对于ORM框架而言，数据源的组织是一个非常重要的一部分，这直接影响到框架的性能问题。本文将通过对MyBatis框架的数据源结构进行详尽的分析，并且深入解析MyBatis的连接池。
    本文首先会讲述MyBatis的数据源的分类，然后会介绍数据源是如何加载和使用的。紧接着将分类介绍UNPOOLED、POOLED和JNDI类型的数据源组织；期间我们会重点讲解POOLED类型的数据源和其实现的连接池原理。
以下是本章的组织结构：
    一、MyBatis数据源DataSource分类
    二、数据源DataSource的创建过程
    三、 DataSource什么时候创建Connection对象
    四、不使用连接池的UnpooledDataSource
    五、为什么要使用连接池？
    六、使用了连接池的PooledDataSource

一、MyBatis数据源DataSource分类
MyBatis数据源实现是在以下四个包中：
MyBatis把数据源DataSource分为三种：
         UNPOOLED    不使用连接池的数据源
         POOLED      使用连接池的数据源
         JNDI            使用JNDI实现的数据源
即：

相应地，MyBatis内部分别定义了实现了java.sql.DataSource接口的UnpooledDataSource，PooledDataSource类来表示UNPOOLED、POOLED类型的数据源。 如下图所示：
对于JNDI类型的数据源DataSource，则是通过JNDI上下文中取值。

二、数据源DataSource的创建过程
  MyBatis 数据源 DataSource 对象的创建发生在 MyBatis 初始化的过程中。 下面让我们一步步地了解MyBatis是如何创建数据源DataSource的。

在mybatis的XML配置文件中，使用<dataSource>元素来配置数据源：

1.  MyBatis在初始化时，解析此文件，根据<dataSource>的type属性来创建相应类型的的数据源DataSource，即：

    type=”POOLED”  ：MyBatis会创建PooledDataSource实例
    type=”UNPOOLED” ：MyBatis会创建UnpooledDataSource实例
    type=”JNDI”     ：MyBatis会从JNDI服务上查找DataSource实例，然后返回使用

2.  顺便说一下，MyBatis是通过工厂模式来创建数据源DataSource对象的，MyBatis定义了抽象的工厂接口 : org.apache.ibatis.datasource.DataSourceFactory ,通过其getDataSource()方法返回数据源DataSource：

定义如下：

public interface DataSourceFactory {

  void setProperties(Properties props);
  //生产DataSource
  DataSource getDataSource();
}

上述三种不同类型的type，则有对应的以下dataSource工厂：

    POOLED        PooledDataSourceFactory
    UNPOOLED     UnpooledDataSourceFactory
    JNDI          JndiDataSourceFactory

   其类图如下所示：

3.  MyBatis创建了DataSource实例后，会将其放到Configuration对象内的Environment对象中， 供以后使用。

三、 DataSource什么时候创建Connection对象

当我们需要创建SqlSession对象并需要执行SQL语句时，这时候MyBatis才会去调用dataSource对象来创建java.sql.Connection对象。也就是说，java.sql.Connection对象的创建一直延迟到执行SQL语句的时候。

比如，我们有如下方法执行一个简单的SQL语句：

String resource = "mybatis-config.xml";
InputStream inputStream = Resources.getResourceAsStream(resource);
SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);
SqlSession sqlSession = sqlSessionFactory.openSession();
sqlSession.selectList("SELECT * FROM STUDENTS");

前4句都不会导致java.sql.Connection对象的创建，只有当第5句sqlSession.selectList("SELECT * FROM STUDENTS ")，才会触发MyBatis在底层执行下面这个方法来创建java.sql.Connection对象：

protected void openConnection() throws SQLException {
    if (log.isDebugEnabled()) {
      log.debug("Opening JDBC Connection");
    }
    connection = dataSource.getConnection();
    if (level != null) {
      connection.setTransactionIsolation(level.getLevel());
    }
    setDesiredAutoCommit(autoCommmit);
  }

而对于DataSource的UNPOOLED的类型的实现-UnpooledDataSource是怎样实现getConnection()方法的呢？请看下一节。
四、不使用连接池的UnpooledDataSource

当 <dataSource>的type属性被配置成了”UNPOOLED”，MyBatis首先会实例化一个UnpooledDataSourceFactory工厂实例，然后通过.getDataSource()方法返回一个UnpooledDataSource实例对象引用，我们假定为dataSource。

使用 UnpooledDataSource 的 getConnection(), 每调用一次就会产生一个新的 Connection 实例对象。

UnPooledDataSource的getConnection()方法实现如下：

/*
UnpooledDataSource的getConnection()实现
*/
public Connection getConnection() throws SQLException
{
  return doGetConnection(username, password);
}

private Connection doGetConnection(String username, String password) throws SQLException
{
  //封装username和password成properties
  Properties props = new Properties();
  if (driverProperties != null)
  {
    props.putAll(driverProperties);
  }
  if (username != null)
  {
    props.setProperty("user", username);
  }
  if (password != null)
  {
    props.setProperty("password", password);
  }
  return doGetConnection(props);
}

/*
 *  获取数据连接
 */
private Connection doGetConnection(Properties properties) throws SQLException
{
  //1.初始化驱动
  initializeDriver();
  //2.从DriverManager中获取连接，获取新的Connection对象
  Connection connection = DriverManager.getConnection(url, properties);
  //3.配置connection属性
  configureConnection(connection);
  return connection;
}

如上代码所示，UnpooledDataSource会做以下事情：

1.  初始化驱动：    判断driver驱动是否已经加载到内存中，如果还没有加载，则会动态地加载driver类，并实例化一个Driver对象，使用DriverManager.registerDriver()方法将其注册到内存中，以供后续使用。

2.  创建Connection对象：     使用DriverManager.getConnection()方法创建连接。

3.  配置Connection对象：    设置是否自动提交autoCommit和隔离级别isolationLevel。

4.  返回Connection对象。

上述的序列图如下所示：

总结：从上述的代码中可以看到， 我们每调用一次 getConnection() 方法，都会通过 DriverManager.getConnection() 返回新的 java.sql.Connection 实例。

五、为什么要使用连接池？

1. 创建一个java.sql.Connection实例对象的代价

首先让我们来看一下创建一个java.sql.Connection对象的资源消耗。我们通过连接Oracle数据库，创建创建Connection对象，来看创建一个Connection对象、执行SQL语句各消耗多长时间。代码如下：

public static void main(String[] args) throws Exception
{

  String sql = "select * from hr.employees where employee_id < ? and employee_id >= ?";
  PreparedStatement st = null;
  ResultSet rs = null;

  long beforeTimeOffset = -1L; //创建Connection对象前时间
  long afterTimeOffset = -1L; //创建Connection对象后时间
  long executeTimeOffset = -1L; //创建Connection对象后时间

  Connection con = null;
  Class.forName("oracle.jdbc.driver.OracleDriver");

  beforeTimeOffset = new Date().getTime();
  System.out.println("before:\t" + beforeTimeOffset);

  con = DriverManager.getConnection("jdbc:oracle:thin:@127.0.0.1:1521:xe", "louluan", "123456");

  afterTimeOffset = new Date().getTime();
  System.out.println("after:\t\t" + afterTimeOffset);
  System.out.println("Create Costs:\t\t" + (afterTimeOffset - beforeTimeOffset) + " ms");

  st = con.prepareStatement(sql);
  //设置参数
  st.setInt(1, 101);
  st.setInt(2, 0);
  //查询，得出结果集
  rs = st.executeQuery();
  executeTimeOffset = new Date().getTime();
  System.out.println("Exec Costs:\t\t" + (executeTimeOffset - afterTimeOffset) + " ms");

}

上述程序在我笔记本上的执行结果为：

从此结果可以清楚地看出，创建一个Connection对象，用了 250 毫秒 ；而执行SQL的时间用了 170毫秒 。

创建一个Connection对象用了250毫秒！这个时间对计算机来说可以说是一个 非常奢侈 的！

这仅仅是一个Connection对象就有这么大的代价，设想一下另外一种情况：如果我们在Web应用程序中，为用户的每一个请求就操作一次数据库，当有10000个在线用户并发操作的话，对计算机而言，仅仅创建Connection对象不包括做业务的时间就要损耗10000×250ms= 250 0000 ms = 2500 s = 41.6667 min,竟然要 41 分钟！！！如果对高用户群体使用这样的系统，简直就是开玩笑！

2. 问题分析：

创建一个java.sql.Connection对象的代价是如此巨大，是因为创建一个Connection对象的过程，在底层就相当于和数据库建立的通信连接，在建立通信连接的过程，消耗了这么多的时间，而往往我们建立连接后（即创建Connection对象后），就执行一个简单的SQL语句，然后就要抛弃掉，这是一个非常大的资源浪费！

3.解决方案:
对于需要频繁地跟数据库交互的应用程序，可以在创建了Connection对象，并操作完数据库后，可以不释放掉资源，而是将它放到内存中，当下次需要操作数据库时，可以直接从内存中取出Connection对象，不需要再创建了，这样就极大地节省了创建Connection对象的资源消耗。由于内存也是有限和宝贵的，这又对我们对内存中的Connection对象怎么有效地维护提出了很高的要求。我们将在内存中存放Connection对象的容器称之为 连接池（Connection Pool）。下面让我们来看一下MyBatis的线程池是怎样实现的。
六、使用了连接池的PooledDataSource

同样地，我们也是使用PooledDataSource的getConnection()方法来返回Connection对象。现在让我们看一下它的基本原理：

 PooledDataSource将java.sql.Connection对象包裹成PooledConnection对象放到了PoolState类型的容器中维护。 MyBatis将连接池中的PooledConnection分为两种状态： 空闲状态（idle）和活动状态(active)，这两种状态的PooledConnection对象分别被存储到PoolState容器内的 idleConnections 和 activeConnections 两个List集合中：

idleConnections :空闲(idle)状态PooledConnection对象被放置到此集合中，表示当前闲置的没有被使用的PooledConnection集合，调用PooledDataSource的getConnection()方法时，会优先从此集合中取PooledConnection对象。当用完一个java.sql.Connection对象时，MyBatis会将其包裹成PooledConnection对象放到此集合中。

activeConnections :活动(active)状态的PooledConnection对象被放置到名为activeConnections的ArrayList中，表示当前正在被使用的PooledConnection集合，调用PooledDataSource的getConnection()方法时，会优先从idleConnections集合中取PooledConnection对象,如果没有，则看此集合是否已满，如果未满，PooledDataSource会创建出一个PooledConnection，添加到此集合中，并返回。

 

PoolState连接池的大致结构如下所示：

6.1 获取java.sql.Connection对象的过程
下面让我们看一下PooledDataSource 的getConnection()方法获取Connection对象的实现：

public Connection getConnection() throws SQLException {
    return popConnection(dataSource.getUsername(), dataSource.getPassword()).getProxyConnection();
  }

  public Connection getConnection(String username, String password) throws SQLException {
    return popConnection(username, password).getProxyConnection();
  }

上述的popConnection()方法，会从连接池中返回一个可用的PooledConnection对象，然后再调用getProxyConnection()方法最终返回Conection对象。（至于为什么会有getProxyConnection(),请关注下一节）

现在让我们看一下popConnection()方法到底做了什么：

1.  先看是否有空闲(idle)状态下的PooledConnection对象，如果有，就直接返回一个可用的PooledConnection对象；否则进行第2步。

2.  查看活动状态的PooledConnection池activeConnections是否已满；如果没有满，则创建一个新的PooledConnection对象，然后放到activeConnections池中，然后返回此PooledConnection对象；否则进行第三步；

3.  看最先进入activeConnections池中的PooledConnection对象是否已经过期：如果已经过期，从activeConnections池中移除此对象，然后创建一个新的PooledConnection对象，添加到activeConnections中，然后将此对象返回；否则进行第4步。

4.  线程等待，循环2步

/*
 * 传递一个用户名和密码，从连接池中返回可用的PooledConnection
 */
private PooledConnection popConnection(String username, String password) throws SQLException
{
  boolean countedWait = false;
  PooledConnection conn = null;
  long t = System.currentTimeMillis();
  int localBadConnectionCount = 0;

  while (conn == null)
  {
    synchronized (state)
    {
      if (state.idleConnections.size() > 0)
      {
        // 连接池中有空闲连接，取出第一个
        conn = state.idleConnections.remove(0);
        if (log.isDebugEnabled())
        {
          log.debug("Checked out connection " + conn.getRealHashCode() + " from pool.");
        }
      }
      else
      {
        // 连接池中没有空闲连接，则取当前正在使用的连接数小于最大限定值，
        if (state.activeConnections.size() < poolMaximumActiveConnections)
        {
          // 创建一个新的connection对象
          conn = new PooledConnection(dataSource.getConnection(), this);
          @SuppressWarnings("unused")
          //used in logging, if enabled
          Connection realConn = conn.getRealConnection();
          if (log.isDebugEnabled())
          {
            log.debug("Created connection " + conn.getRealHashCode() + ".");
          }
        }
        else
        {
          // Cannot create new connection 当活动连接池已满，不能创建时，取出活动连接池的第一个，即最先进入连接池的PooledConnection对象
          // 计算它的校验时间，如果校验时间大于连接池规定的最大校验时间，则认为它已经过期了，利用这个PoolConnection内部的realConnection重新生成一个PooledConnection
          //
          PooledConnection oldestActiveConnection = state.activeConnections.get(0);
          long longestCheckoutTime = oldestActiveConnection.getCheckoutTime();
          if (longestCheckoutTime > poolMaximumCheckoutTime)
          {
            // Can claim overdue connection
            state.claimedOverdueConnectionCount++;
            state.accumulatedCheckoutTimeOfOverdueConnections += longestCheckoutTime;
            state.accumulatedCheckoutTime += longestCheckoutTime;
            state.activeConnections.remove(oldestActiveConnection);
            if (!oldestActiveConnection.getRealConnection().getAutoCommit())
            {
              oldestActiveConnection.getRealConnection().rollback();
            }
            conn = new PooledConnection(oldestActiveConnection.getRealConnection(), this);
            oldestActiveConnection.invalidate();
            if (log.isDebugEnabled())
            {
              log.debug("Claimed overdue connection " + conn.getRealHashCode() + ".");
            }
          }
          else
          {

            //如果不能释放，则必须等待有
            // Must wait
            try
            {
              if (!countedWait)
              {
                state.hadToWaitCount++;
                countedWait = true;
              }
              if (log.isDebugEnabled())
              {
                log.debug("Waiting as long as " + poolTimeToWait + " milliseconds for connection.");
              }
              long wt = System.currentTimeMillis();
              state.wait(poolTimeToWait);
              state.accumulatedWaitTime += System.currentTimeMillis() - wt;
            }
            catch (InterruptedException e)
            {
              break;
            }
          }
        }
      }

      //如果获取PooledConnection成功，则更新其信息

      if (conn != null)
      {
        if (conn.isValid())
        {
          if (!conn.getRealConnection().getAutoCommit())
          {
            conn.getRealConnection().rollback();
          }
          conn.setConnectionTypeCode(assembleConnectionTypeCode(dataSource.getUrl(), username, password));
          conn.setCheckoutTimestamp(System.currentTimeMillis());
          conn.setLastUsedTimestamp(System.currentTimeMillis());
          state.activeConnections.add(conn);
          state.requestCount++;
          state.accumulatedRequestTime += System.currentTimeMillis() - t;
        }
        else
        {
          if (log.isDebugEnabled())
          {
            log.debug("A bad connection (" + conn.getRealHashCode() + ") was returned from the pool, getting another connection.");
          }
          state.badConnectionCount++;
          localBadConnectionCount++;
          conn = null;
          if (localBadConnectionCount > (poolMaximumIdleConnections + 3))
          {
            if (log.isDebugEnabled())
            {
              log.debug("PooledDataSource: Could not get a good connection to the database.");
            }
            throw new SQLException("PooledDataSource: Could not get a good connection to the database.");
          }
        }
      }
    }

  }

  if (conn == null)
  {
    if (log.isDebugEnabled())
    {
      log.debug("PooledDataSource: Unknown severe error condition.  The connection pool returned a null connection.");
    }
    throw new SQLException("PooledDataSource: Unknown severe error condition.  The connection pool returned a null connection.");
  }

  return conn;
}

对应的处理流程图如下所示：

如上所示,对于PooledDataSource的getConnection()方法内，先是调用类PooledDataSource的popConnection()方法返回了一个PooledConnection对象，然后调用了PooledConnection的getProxyConnection()来返回Connection对象。

6.2java.sql.Connection对象的回收
       当我们的程序中使用完Connection对象时，如果不使用数据库连接池，我们一般会调用 connection.close()方法，关闭connection连接，释放资源。如下所示：

private void test() throws ClassNotFoundException, SQLException
{
  String sql = "select * from hr.employees where employee_id < ? and employee_id >= ?";
  PreparedStatement st = null;
  ResultSet rs = null;

  Connection con = null;
  Class.forName("oracle.jdbc.driver.OracleDriver");
  try
  {
    con = DriverManager.getConnection("jdbc:oracle:thin:@127.0.0.1:1521:xe", "louluan", "123456");
    st = con.prepareStatement(sql);
    //设置参数
    st.setInt(1, 101);
    st.setInt(2, 0);
    //查询，得出结果集
    rs = st.executeQuery();
    //取数据，省略
    //关闭，释放资源
    con.close();
  }
  catch (SQLException e)
  {
    con.close();
    e.printStackTrace();
  }
}

调用过close()方法的Connection对象所持有的资源会被全部释放掉，Connection对象也就不能再使用。

那么，如果我们使用了连接池，我们在用完了Connection对象时，需要将它放在连接池中，该怎样做呢？

可能大家第一个在脑海里闪现出来的想法就是：我在应该调用con.close()方法的时候，不调用close()f方法，将其换成将Connection对象放到连接池容器中的代码！
好，我们将上述的想法实现，首先定义一个简易连接池Pool，然后将上面的代码改写：

package com.foo.jdbc;

import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.SQLException;
import java.util.Vector;

/**
 * 
 * 一个线程安全的简易连接池实现，此连接池是单例的
 *  putConnection()将Connection添加到连接池中
 *  getConnection()返回一个Connection对象
 */
public class Pool {

  private static Vector<Connection> pool = new Vector<Connection>();
  
  private static int MAX_CONNECTION =100;
  
  private static String DRIVER="oracle.jdbc.driver.OracleDriver";
  private static String URL = "jdbc:oracle:thin:@127.0.0.1:1521:xe";
  private static String USERNAME = "louluan";
  private static String PASSWROD = "123456";
  
  static {
    try {
      Class.forName(DRIVER);
    } catch (ClassNotFoundException e) {
      e.printStackTrace();
    }
  }
  
  /**
   * 将一个Connection对象放置到连接池中 
   */
  public static  void putConnection(Connection connection){
    
    synchronized(pool)
    {
      if(pool.size()<MAX_CONNECTION)
      {
        pool.add(connection);	   
      }
    }
  }
  
  
  /**
   * 返回一个Connection对象，如果连接池内有元素，则pop出第一个元素；
   * 如果连接池Pool中没有元素，则创建一个connection对象，然后添加到pool中
   * @return Connection
   */
  public static Connection getConnection(){
    Connection connection = null;
    synchronized(pool)
    {
      if(pool.size()>0)
      {
        connection = pool.get(0);
        pool.remove(0);
      }
      else
      {
        connection = createConnection();
        pool.add(connection);
      }
    }
    return connection;
  }
  
  /**
   * 创建一个新的Connection对象
   */
  private static Connection createConnection()
  {
    Connection connection = null;
    try {
      connection = DriverManager.getConnection(URL, USERNAME,PASSWROD);
    } catch (SQLException e) {
      e.printStackTrace();
    }
    return connection;
  }
  
}

package com.foo.jdbc;

import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.PreparedStatement;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.util.Vector;

public class PoolTest
{

  private void test() throws ClassNotFoundException, SQLException
  {
    String sql = "select * from hr.employees where employee_id < ? and employee_id >= ?";
    PreparedStatement st = null;
    ResultSet rs = null;

    Connection con = null;
    Class.forName("oracle.jdbc.driver.OracleDriver");
    try
    {
      con = DriverManager.getConnection("jdbc:oracle:thin:@127.0.0.1:1521:xe", "louluan", "123456");
      st = con.prepareStatement(sql);
      //设置参数
      st.setInt(1, 101);
      st.setInt(2, 0);
      //查询，得出结果集
      rs = st.executeQuery();
      //取数据，省略
      //将不再使用的Connection对象放到连接池中，供以后使用
      Pool.putConnection(con);
    }
    catch (SQLException e)
    {
      e.printStackTrace();
    }
  }
}

 

上述的代码就是将我们使用过的Connection对象放到Pool连接池中，我们需要Connection对象的话，只需要使用Pool.getConnection()方法从里面取即可。

是的,上述的代码完全可以实现此能力，不过有一个很不优雅的实现： 就是我们需要手动地将Connection对象放到Pool连接池中，这是一个很傻的实现方式。这也和一般使用Connection对象的方式不一样：一般使用Connection的方式是使用完后，然后调用.close()方法释放资源。

为了和一般的使用Conneciton对象的方式保持一致，我们希望当Connection使用完后，调用.close()方法，而实际上Connection资源并没有被释放，而实际上被添加到了连接池中。这样可以做到吗？答案是可以。上述的要求从另外一个角度来描述就是：能否提供一种机制，让我们知道Connection对象调用了什么方法，从而根据不同的方法自定义相应的处理机制。恰好代理机制就可以完成上述要求.

怎样实现Connection对象调用了close()方法，而实际是将其添加到连接池中

这是要使用代理模式，为真正的Connection对象创建一个代理对象，代理对象所有的方法都是调用相应的真正Connection对象的方法实现。当代理对象执行close()方法时，要特殊处理，不调用真正Connection对象的close()方法，而是将Connection对象添加到连接池中。

MyBatis的PooledDataSource的PoolState内部维护的对象是PooledConnection类型的对象，而PooledConnection则是对真正的数据库连接java.sql.Connection实例对象的包裹器。

PooledConnection对象内持有一个真正的数据库连接java.sql.Connection实例对象和一个java.sql.Connection的代理：

其部分定义如下：

class PooledConnection implements InvocationHandler {
  
  //......
  //所创建它的datasource引用
  private PooledDataSource dataSource;
  //真正的Connection对象
  private Connection realConnection;
  //代理自己的代理Connection
  private Connection proxyConnection;
  
  //......
}

PooledConenction 实现了 InvocationHandler 接口，并且， proxyConnection 对象也是根据这个它来生成的代理对象：

public PooledConnection(Connection connection, PooledDataSource dataSource) {
  this.hashCode = connection.hashCode();
  this.realConnection = connection;
  this.dataSource = dataSource;
  this.createdTimestamp = System.currentTimeMillis();
  this.lastUsedTimestamp = System.currentTimeMillis();
  this.valid = true;
  this.proxyConnection = (Connection) Proxy.newProxyInstance(Connection.class.getClassLoader(), IFACES, this);
  }

实际上，我们调用PooledDataSource的getConnection()方法返回的就是这个proxyConnection对象。

当我们调用此proxyConnection对象上的任何方法时，都会调用PooledConnection对象内invoke()方法。
让我们看一下PooledConnection类中的invoke()方法定义：

public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
    String methodName = method.getName();
    //当调用关闭的时候，回收此Connection到PooledDataSource中
    if (CLOSE.hashCode() == methodName.hashCode() && CLOSE.equals(methodName)) {
      dataSource.pushConnection(this);
      return null;
    } else {
      try {
        if (!Object.class.equals(method.getDeclaringClass())) {
          checkConnection();
        }
        return method.invoke(realConnection, args);
      } catch (Throwable t) {
        throw ExceptionUtil.unwrapThrowable(t);
      }
    }
  }

从上述代码可以看到，当我们使用了pooledDataSource.getConnection()返回的Connection对象的close()方法时，不会调用真正Connection的close()方法，而是将此Connection对象放到连接池中。
七、JNDI类型的数据源DataSource

对于JNDI类型的数据源DataSource的获取就比较简单，MyBatis定义了一个JndiDataSourceFactory工厂来创建通过JNDI形式生成的DataSource。
下面让我们看一下JndiDataSourceFactory的关键代码：

if (properties.containsKey(INITIAL_CONTEXT)
    && properties.containsKey(DATA_SOURCE))
{
  //从JNDI上下文中找到DataSource并返回
  Context ctx = (Context) initCtx.lookup(properties.getProperty(INITIAL_CONTEXT));
  dataSource = (DataSource) ctx.lookup(properties.getProperty(DATA_SOURCE));
}
else if (properties.containsKey(DATA_SOURCE))
{
  // //从JNDI上下文中找到DataSource并返回
  dataSource = (DataSource) initCtx.lookup(properties.getProperty(DATA_SOURCE));
}



77 spring中beanFactory和ApplicationContext的联系和区别？
ApplicationContext 是 BeanFactory接口的子接口
其实两个在代码看来就是在获取配置文件的时候 的差异，他们还有其他的差异：
1）BeanFactory 采用的是延迟加载，第一次getBean的时候才会初始化Bean
2）ApplicationContext是对BeanFactory的扩展，提供了更多的功能
    国际化处理
    事件传递
    Bean自动装配
    各种不同应用层的Context实现
结论：开发中尽量使用ApplicationContext 就可以了 


---------------------------------------------------------------------------------------------------------------
------------------------------------------jiagou basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------jvm basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 Bootstrap ClassLoader是在JVM开始运行的时候加载java的核心类，是用C++编写的，它用来加载核心类库，在JVM源代码中这样写道
static const char classpathFormat[] = 
"%/lib/rt.jar:" 
"%/lib/i18n.jar:" 
"%/lib/sunrsasign.jar:" 
"%/lib/jsse.jar:" 
"%/lib/jce.jar:" 
"%/lib/charsets.jar:" 
"%/classes"; 
Extension ClassLoader是用来加载扩展类，即/lib/ext中的类。 
AppClassLoader用来加载Classpath的类，是和我们关系最密切的类。 
自定义加载：2种方式，1是URLClassLoader用来加载网络上远程的类，2是自己定义类继承 ClassLoader 。

2 预加载和按需加载
当 java.exe 虚拟机开始运行以后，它会找到安装在机器上的 JRE 环境，然后把控制权交给 JRE ， JRE 的类加载器会将 lib 目录下的 rt.jar 基础类别文件库加载进内存，这些文件是 Java 程序执行所必须的，所以系统在开始就将这些文件加载，避免以后的多次 IO 操作，从而提高程序执行效率。 相对于预先加载，我们在程序中需要使用自己定义的类的时候就要使用依需求加载方法（ load-on-demand ），就是在 Java 程序需要用到的时候再加载，以减少内存的消耗。

3 ClassLoader工作原理： 
1) 线程需要用到某个类，于是contextClassLoader被请求来载入该类 
2) contextClassLoader请求它的父ClassLoader来完成该载入请求 
3) 如果父ClassLoader无法载入类，则contextClassLoader试图自己来载入 


4 父类委托机制 进行加载
保证安全，父类委托机制的优点是能够提高软件系统的安全性，假设我自己定义一个类加载器，然后随便伪造一个类，这个类不符合jvm规范，里面有不安全的代码，如果不适用父类委托机制，那么这个类就会被直接加载到内存里面了。 如果使用父类委托，那么就会被父加载器加载，它会按照jvm规范来加载，不符合规范就不会加载。

5 隐式加载
不通过显示调用class loader来加载需要的类，而是通过JVM因需自动加载到内存当中的方式。比如加载一个类的时候会隐式加载它的父类。

6 显示加载
通过调用classLoader来加载类的方式，比如
    this.getclass().getClassLoader().loadClass();
    Class.forName("className"); 


7 常见的错误
ClassNotFoundException:这个异常发生在显示加载类的时候，没有找到对应类的字节码，显示加载的方式如下：通过类class中的forName()方法；通过ClassLoader中的loadClass()方法
通过ClassLoader中的findSystemClass()方法

NoClassDefFoundError:隐式加载类时出现,涉及隐式加载的情景:
使用new关键字；属性引用加载某个类；继承了某个接口或类；以及方法的某个参数中引用了某个类

UnsatisfiedLinkError是一个在解析native标识的方法时出现的错误，是库文件缺失造成的，无法链接到本地的代码实现库(native实现)

8 JVM初始化sun.misc.Launcher并创建Extension ClassLoader和AppClassLoader实例。并将ExtClassLoader设置为AppClassLoader的父加载器。Bootstrap没有父加载器，但是它却可以作用一个ClassLoader的父加载器。比如ExtClassLoader。这也可以解释之前通过ExtClassLoader的getParent方法获取为Null的现象。

9 ContextClassLoader
通常情况下，JVM中的所有类加载器被组织成一个层次结构，使得每一个类加载器（除了原始类加载器）都有一个父加载器。当被要求加载一个类时，每一个类加载器都将先委托父加载器来加载，只有父加载器都不能成功加载时当前类加载器才会加载，双亲委派。
在这种情况下，如下的委派链中：
ClassLoader A -> System class loader -> Extension class loader -> Bootstrap class loader，
委派链左边的ClassLoader就可以很自然的使用右边的ClassLoader所加载的类。
但如果情况要反过来，是右边的ClassLoader所加载的代码需要反过来去找委派链靠左边的ClassLoader去加载东西怎么办呢？没办法反过来从右边找左边的~

以JNDI举例：它的核心内容（从J2SE1.3开始）在rt.jar中的引导类中实现了，但是这些JNDI核心类可能加载由独立厂商实现和部署在应用程序的classpath中的JNDI提供者。这个例子中的原始类加载器，即加载rt.jar的加载器去加载一个在它的子类加载器中可见的类。此时通常的J2SE委托机制不能工作，解决办法是让JNDI核心类使用线程上下文加载器，从而有效建立一条与类加载器层次结构相反方向的“通道”达到正确的委托。

10 调优基础知识
一台物理机或者虚拟机上面安装一个JVM，也可以安装多个 。
一台物理机或者虚拟机上面安装一个JVM，也就是JDK，上面可疑运行tomcat,eclipse等java进程，分别可以配置JVM的内存参数，但是总的内存不能大于物理机的内存值。
一个eclipse的main是一个进程，在eclipse.ini 中配置 
一个tomcat是一个进程，里面有很多线程，wins在 catalina.bat，linux在catalina.sh中设置 
根据进程号可以找到里面的参数设置  

11  企业级应用开发中经常会遇到以下问题，可以使用工具对JVM进行监管，查找问题所在。
　　内存不足OutOfMemory（大对象没有gc等），内存泄露；
　　线程死锁，线程数过多；
　　锁争用（Lock Contention），资源未及时释放（数据库）；
　　Java进程CPU消耗过高.

12 Jps（JVM Process Status Tools） 虚拟机进程状态工具 
可以列举正在运行的虚拟机进程并显示虚拟机执行的主类以及这些进程的唯一ID（LVMID）
jps [option] [hostid默认为本机]
option选项：
-q只输出LVMID
-m输出JVM启动时传给主类的方法
-l输出主类的全名，如果是Jar则输出jar的路径
-v输出JVM的启动参数

jps -q/
jps -m/
jps -l/
jps -v

13  jstack看某个Java进程内的线程堆栈信息
jstack用于生成java虚拟机当前时刻的线程快照，主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等。
语法：  jstack [ option ] pid
-F 当 jstack [-l] pid 没有响应的时候强制打印栈信息
-l 长列表. 打印关于锁的附加信息,例如属于java.util.concurrent的ownable synchronizers列表.
 第一步先找出Java进程ID，我部署在服务器上的Java应用名称为mrf-center：
得到进程ID为21711，第二步找出该进程内最耗费CPU的线程，可以使用ps -Lfp pid或者ps -mp pid -o THREAD, tid, time或者top -Hp pid。
TIME列就是各个Java线程耗费的CPU时间，CPU时间最长的是线程ID为21742的线程，用得到21742的十六进制值为54ee。
 jstack 21711 | grep 54ee
"PollIntervalRetrySchedulerThread" prio=10 tid=0x00007f950043e000 nid=0x54ee in Object.wait(
可以看到CPU消耗在PollIntervalRetrySchedulerThread这个类的Object.wait()，


4498的十六进制是1192
jstack 7957 > test.txt

14  jstat 查看classloader，compiler，gc相关信息，实时监控资源和性能 。
jstat工具特别强大，可以用来监视VM内存内的各种堆和非堆的大小及其内存使用量。
语法结构：jstat -<option> [-t] [-h<lines>] <pid> [<interval> [<count>]]
Options — 通常使用 -gcutil 查看gc情况
interval – 间隔时间，单位为秒或者毫秒
count — 打印次数，如果缺省则打印无数次

结果说明：
S0     — Heap上的 Survivor space 0 区已使用空间的百分比
S1     — Heap上的 Survivor space 1 区已使用空间的百分比
E       — Heap上的 Eden space 区已使用空间的百分比
O      — Heap上的 Old space 区已使用空间的百分比
P       — Perm space 区已使用空间的百分比
YGC  — 从应用程序启动到采样时发生 Young GC 的次数
YGCT— 从应用程序启动到采样时 Young GC 所用的时间(单位秒)
FGC  — 从应用程序启动到采样时发生 Full GC 的次数
FGCT— 从应用程序启动到采样时 Full GC 所用的时间(单位秒)
GCT  — 从应用程序启动到采样时用于垃圾回收的总时间(单位秒)
    jstat –class <pid> :          显示加载class的数量，及所占空间等信息。
    jstat -compiler  <pid>:    显示VM实时编译的数量等信息。
    jstat -gc  <pid>:              显示gc的信息，查看gc的次数，及时间。
    jstat -gccapacity  <pid>: 显示VM内存中三代（young,old,perm）对象的使用和占用大小
    jstat -gcutil  <pid>:         统计gc信息
    jstat -gcnew / gcnewcapacity<pid>: 年轻代对象的信息(及其占用量)。
    jstat -gcold / gcoldcapacity <pid> ：old代对象的信息(及其占用量)。
    jstat -gcpermcapacity  <pid>:            perm对象的信息及其占用量。
    jstat -printcompilation <pid>:            当前VM执行的信息。

15   jconsole可以监控Java应用程序(如jar应用、tomcat等)
但被监视的应用程序必须和jconsole是用同一个用户运行的。jvisualvm的使用和jconsole类似
    本地监控：  jconsole  pid 
    远程监控：  jconsole  [ hostname:portNum ]      

	使用远程监控需要配置jmx代理信息，修改Tomcat的bin目录下的catalina.bat。
	set JAVA_OPTS= %JAVA_OPTS% -Djava.rmi.server.hostname=HostIP
	set JAVA_OPTS= %JAVA_OPTS% -Dcom.sun.management.jmxremote.port=8888
	set JAVA_OPTS= %JAVA_OPTS% -Dcom.sun.management.jmxremote.ssl=false
	set JAVA_OPTS= %JAVA_OPTS% -Dcom.sun.management.jmxremote.authenticate=false

16 Jmap 打印java进程的堆内存信息
jmap -heap pid：查看heap的概要信息，GC使用的算法、heap的配置使用情况.
jmap -histo[:live] pid：查看堆内存中的每个类的类名、实例数量、内存占用大小
jmap -dump:live, format=b, file=fileName pid：将内存使用情况导出到文件中，再用jhat、MAT、VisualVM分析查看，以便查找内存溢出原因

17 jhat可以对JVM中导出的文件进行分析
使用命令 jhat fileName 即可以在浏览器中输入http://localhost:7000查看内存信息。如果Dump文件太大需要加上-J-Xmx512m指定最大堆内存，如 jhat -J-Xmx512m [-port 9998] tmp.bin分析内存还可以使用Eclipse的Memory Analyzer，插件地址http://download.eclipse.org/releases/juno，找到General Purpose Tools底下的Memory Analyzer并安装


18 执行引擎
JVM 加载 class 文件后，已经将 class 文件中的常量信息、类信息、方法代码等放入方法区中了。JVM 通过执行引擎来完成字节码的执行，在执行过程中 JVM 采用的是自己的一套指令系统，每个线程在创建后，都会产生一个程序计数器（pc）和栈（Stack），其中程序计数器中存放了下一条将要执行的指令，Stack 中存放 Stack Frame，表示的为当前正在执行的方法， 每个方法的执行都会产生 Stack Frame，Stack Frame 中存放了传递给方法的参数、方法内的局部变量以及操作数栈，操作数栈用于存放指令运算的中间结果，指令负责从操作数栈中弹出参与运算的操作数，指令执行完毕后再将计算结果压回到操作数栈，当方法执行完毕后则从 Stack 中弹出，继续其他方法的执行。

 invokestatic：调用类的 static 方法
 public class B{
public static void main(String[] args){ A.execute(“Hello World”);
}
}
编译后 B 中的代码转变为了如下字节码（通过调用 javap –c B 查看）：
public static void main(java.lang.String[]); Code:  
0:	ldc	#16; //String Hello World  
2:	invokestatic	#18; //Method sample/A.execute:(Ljava/lang/String;)V  
5:	return 
当main 线程启动后，JVM 为此线程创建一个PC 和Stack，执行 ldc #16;//String Hello World，并同时将 invokestatic 放入 PC，接着将 Hello World 的引用压入 Stack 的参数变量中，
继续执行 invokestatic 指令，该指令后跟随的//Method 部分的内容称为<method-spec>内容，此内容的规范为：包名/类名.方法名:(参数类型)返回值类型，invokestatic 指令根据此
 method-spec 找到此 Class 的方法，根据 method-spec 中的参数信息找到参数的个数，从 stack frame 中弹出这些参数，然后创建一个新的 stack frame，将参数信息压入，然后重
 复上述过程，完成整个方法的执行。

 invokevirtual：调用对象实例的方法  A a=new A() 
 invokeinterface：调用接口的方法 IA a=new A();
 invokespecial：初始化对象，以及调用对象实例中的私有方法时


19 三种方式执行：
（1）解释~解释执行方式，也就是每次都由 JVM 来解释字节码，进行执行的方式，无疑这种方式会使得性能较低，毕竟每次执行都需要进行解释，然后调用机器指令完成执行。
（2）即时编译~即时编译方式，也就是每次执行字节码时，JVM 都将其首先转为机器码，然后进行执行， 固然这种方式性能较高，但每次转化为机器码，也使得系统执行会受到不小的影响。
（3）自适应编译~自适应编译方式，简称 Hotspot 方式，它是 Sun JDK 保证 Java 程序高性能执行的基础，方式的特点为在运行期根据代码的执行频率来决定是否要编译为机器码，如达到了执行次数的条件，那么就编译成机器码，这也就使得对于那些经常被执行的代码而言，执   行的性能是非常高的，并且做到尽可能少的影响整体应用性能，这个执行次数的条件可通过
-XX:CompileThreshold=10000 来设置，默认情况下为 10000 次，也可通过-XX:+PrintCompilation 参数来查看被编译成机器码的方法。

20 Runtime data area 的整体架构图
1）Runtime  data  area  主要包括五个部分：Heap  (堆),  Method  Area(方法区域),
Java Stack(java 的栈), Program Counter(程序计数器), Native method
stack(本地方法栈)。Heap  和 Method Area 是被所有线程的共享使用的；而 Java stack,  Program  counter  和 Native  method  stack 是以线程为粒度的，每个线程独自拥有。
2） PC 寄存器 PC 寄存器是用于存储每个线程下一步将执行的 JVM 指令，如该方法为 native 的，则 PC寄存器中不存储任何信息。
3）  JVM 栈 线程私有的，每个线程创建的同时都会创建 JVM 栈，JVM 栈中存放的为当前线程中八种基本类型，局域变量，非基本类型的对象在 JVM 栈上仅存放一个指向堆上的地址，因此 Java中基本类型的变量是值传递，而非基本类型的变量是引用传递。并且当线程运行完毕后， 这些内存也就被自动回收。当 JVM 栈的空间不足时，会抛出 StackOverflowError 的错误，当 JVM 参数设置为-Xss1K，运行后会报出类似下面的错误：Exception in thread "Thread-0" java.lang.StackOverflowError。
4）  堆（Heap） 所有线程共享的，用来存储对象实例以及数组值，通过 new 创建的对象的内存都在此分配，其大小通过-Xms 和-Xmx 来控制，-Xms 为 最小 Heap 内存，默认为物理内存的。-Xmx 为 JVM 可申请的最大 Heap 内存，默认当空余堆内存小于 40% 时， JVM 会增大 Heap 的大小到-Xmx 指定的大小，通常都会将-Xms 和-Xmx 的值设成一样。
Heap 分为 New Generation 和 Old Generation两块：
@.New Generation
新生代，新建的对象都将分配到新生代中，新生代又由 Eden Space 和两块 Survivor Space 构成，可通过-Xmn 参数来指定其大小，Eden Space 的大小和两块 Survivor
Space 的大小比例默认为 8，即当 New Generation 的大小为 10M 时，Eden Space 的大小为 8M，两块 Survivor Space 各占 1M，这个比例可通过-XX:SurvivorRatio 来指定。
@.Old Generation
又称为旧生代，用于存放程序中经过几次垃圾回收还存活的对象，例如缓存的对象等旧生代所占用的内存大小即为-Xmx 指定的大小减去-Xmn 指定的大小
5） 方法区域（Method Area）
方法区域存放了所加载的类的信息（名称、修饰符等）、类中的静态变量、类中定义为final 类型的常量、类中的 Field 信息、类中的方法信息，当开发人员在程序中通过 Class 对象中的 getName、isInterface 等方法来获取信息时，这些数据都来源于方法区域，可见方法区域的重要性，同样，方法区域也是全局共享的，在一定的条件下它也会被 GC，当方法区域需要使用的内存超过其允许的大小时，会抛出 OutOfMemory 的错误信息。在 Sun JDK 中这块区域对应的为 Permanet Generation，又称为持久代，默认为 64M，可通过-XX:PermSize 
以及-XX:MaxPermSize 来指定其大小。方法区包含运行时常量池（Runtime Constant Pool），String常量池。

21 String内存分配
（1）使用关键字new，如：String s1 = new String(“myString”);
第一种方式通过关键字new定义过程：在程序编译期，编译程序先去字符串常量池检查，是否存在“myString”,如果不存在，
则在常量池中开辟一个内存空间存放“myString”；如果存在的话，则不用重新开辟空间，保证常量池中只有一个“myString”常量，节省内存空间。
然后在内存堆中开辟一块空间存放new出来的String实例，在栈中开辟一块空间，命名为“s1”，存放的值为堆中String实例的内存地址，这个过程就是将引用s1指向new出来的String实例。
各位，最模糊的地方到了！堆中new出来的实例和常量池中的“myString”是什么关系呢？等我们分析完了第二种定义方式之后再回头分析这个问题。
（2）直接定义，如：String s1 = “myString”;
第二种方式直接定义过程：在程序编译期，编译程序先去字符串常量池检查，是否存在“myString”，如果不存在，则在常量池中开辟一个内存空间存放“myString”；如果存在的话，则不用重新开辟空间。
然后在栈中开辟一块空间，命名为“s1”，存放的值为常量池中“myString”的内存地址。常量池中的字符串常量与堆中的String对象有什么区别呢？为什么直接定义的字符串同样可以调用String对象的各种方法呢？
常量池中的字符串常量实质上是一个String实例，与堆中的String实例是克隆关系
（3）String str=”kv”+”ill”+” “+”ans”; 
由于String类的immutable性质,这一说又要说很多，大家只 要知道String的实例一旦生成就不会再改变了，比如说：String str=”kv”+”ill”+” “+”ans”; 就是有4个字符串常量，
首先”kv”和”ill”生成了”kvill”存在内存中，然后”kvill”又和” ” 生成 “kvill “存在内存中，最后又和生成了”kvill ans”;并把这个字符串的地址赋给了str,就是因为String的
”不可变”产生了很多临时变量，这也就是为什么建议用StringBuffer的原 因了，因为StringBuffer是可改变的。

22 JVM 对象内存回收
对新生代的对象的收集称为 minor GC，对旧生代的对象的收集称为 Full GC，调用 System.gc()为 Full GC，常见算法：
1）、 标记/清除算法
Heap 最明显的一种方法，对每一个对象都提供一个关联的引用计数，以此来标识该对象是否被使用，当这个计数为零时说明这个对象已经不再被使用了。标记和清除两个阶段的效率都不高，因为这两个阶段都需要遍历内存中的对象；标记清除之后会产生大量不连续的内存碎片，内存空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾回收动作。因此 JVM 并没有采用引用计数。

2）、复制算法（新生代 Minor GC)
将可用内存按容量划分为大小相等的两块，每次使用其中的一块。当这一块的内存用完了，就将还存活的对象复制到另一块内存上，然后把这一块内存所有的对象一次性清理掉简单高效，优化了标记/清除算法的效率低、内存碎片多的问题。但是将内存缩小为原来的一半，浪费了一半的内存空间；如果对象的存活率很高，耗费的时间代价也是不可忽视的。由于新生代中的对象几乎都是朝生夕死的（达到98%），虚拟机都采用复制算法来回收新生代。由于新生代的对象存活率低，所以并不需要按照1：1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的From Survivor空间、To Survivor空间，三者的比例为8：1：1。每次使用Eden和From Survivor区域，To Survivor作为保留空间。GC开始时，对象只会存在于Eden区和From Survivor区，To Survivor区是空的。GC进行时，Eden区中所有存活的对象都会被复制到To Survivor区，
接着清空Eden区和From Survivor区，新生代中存活的对象都在To Survivor区。

3）、 标记/整理算法（老年代 Full GC)
老年代中由于对象的存活率非常高，复制算法就不合适了。标记/整理算法。事实上，标记/整理算法的标记过程任然与标记/清除算法一样，但后续步骤不是直接对可回收对象进行回收，
而是让所有存活的对象都向一端移动，然后直接清理掉端边线以外的内存。缺点:效率也不高，不仅要标记存活对象，还要整理所有存活对象的引用地址，在效率上不如复制算法。

4）、分代收集算法
当前商业虚拟机都采用分代收集算法，终极算法，结合了前几种算法的优点，将算法组合使用进行垃圾回收。
分代收集算法的思想是按对象的存活周期不同将内存划分为几块，一般是把Java堆分为新生代和老年代、永久代（很少回收），这样就可以根据各个年代的特点采用最合适的收集算法。
新生代：朝生夕灭，存活时间很短，复制算法。
老年代：经过多次Minor GC而存活下来，存活周期长，标记/整理。

效率：复制算法 > 标记/整理算法 > 标记/清除算法（标记/清除算法有内存碎片问题，给大对象分配内存时可能会触发新一轮垃圾回收）
内存整齐率：复制算法 = 标记/整理算法 > 标记/清除算法
内存利用率：标记/整理算法 = 标记/清除算法 > 复制算法
 
23 参数配置
（1）静态参数：
-Xmn
新生代内存大小的最大值，包括 E 区和两个 S 区的总和，使用方法如：- Xmn65535，-Xmn1024k，-Xmn512m，-Xmn1g (-Xms,-Xmx 也是种写法)
-Xms
初始堆的大小，也是堆大小的最小值，默认值是总共的物理内存/64（且小于1G），默认情况下，当堆中可用内存小于 40%
(这个值可以用-XX:MinHeapFreeRatio 调整，如-X:MinHeapFreeRatio=30)时，堆内存会开始增加，一直增加到-Xmx 的大小；
-Xmx
堆的最大值，默认值是总共的物理内存/64（且小于 1G），如果 Xms 和 Xmx 都不设置，则两者大小会相同；
整个堆的大小=年轻代大小+年老代大小，堆的大小不包含持久代大小，如果增大了年轻代，年老代相应就会减小
线上生产环境，Xms 和 Xmx 设置的值必须一样，原因与年轻代一样——防止抖动；
-Xss
这个参数用于设置每个线程的栈内存，默认 1M，一般来说是不需要改的。除非代码不多，可以设置的小点，另外一个相似的参数是-XX:ThreadStackSize， 这两个参数在 1.6 以前，都是谁设置在后面，谁就生效；1.6 版本以后，-Xss 设置在后面，则以-Xss 为准，-XXThreadStackSize 设置在后面，则主线程以-Xss 为准，其它线程以-XX:ThreadStackSize 为准。

（2）非 Stable静态参数：
-XX:NewSize=2.125m	新生代对象生成时占用内存的默认值
-XX:MaxNewSize=size	新生成对象能占用内存的最大值
-XX:MaxPermSize=64m	方法区所能占用的最大内存
-XX:PermSize=64m	方法区分配的初始内存
-XX:MaxTenuringThreshold=15	对象在新生代存活区切换的次数
-XX:MaxHeapFreeRatio=70	GC 后 java 堆中空闲量占的最大比例，大于该值，则堆内存会减少
-XX:MinHeapFreeRatio=40	GC 后 java 堆中空闲量占的最小比例，小于该值，则堆内存会增加
-XX:NewRatio=2	新生代内存容量与老生代内存容量的比例
-XX:ReservedCodeCacheSize= 32m	保留代码占用的内存容量
-XX:ThreadStackSize=512	设置线程栈大小，若为 0 则使用系统默认值
XX:+ScavengeBeforeFullGC	新生代 GC 优先于 Full GC 执行

（3）调试参数：
-XX:-CITime	打印消耗在JIT 编译的时间
-XX:ErrorFile=./hs_err_pid<pid>.log	保存错误日志或者数据到文件中
-XX:-ExtendedDTraceProbes	开 启	solaris	特 有 的
-XX:HeapDumpPath=./java_pid<pid>.hprof	指定导出堆信息时的路径或文件名
-XX:-HeapDumpOnOutOfMemoryError	当首次遭遇OOM 时导出此时堆中相关信息
-XX:OnError="<cmd args>;<cmd args>"	出现致命 ERROR 之后运行自定义命令
-XX:OnOutOfMemoryError="<cmd	args>;<cmd args>"	当首次遭遇OOM 时执行自定义命令
-XX:-PrintClassHistogram	遇到 Ctrl-Break 后打印类实例的柱状信息，与 jmap -
-XX:-PrintConcurrentLocks	遇到 Ctrl-Break 后打印并发锁的相关信息，与jstack
-XX:-PrintCommandLineFlags	打印在命令行中出现过的标记
-XX:-PrintCompilation	当一个方法被编译时打印相关信息
-XX:-PrintGC	每次 GC 时打印相关信息
-XX:-PrintGC Details	每次 GC 时打印详细信息
-XX:-PrintGCTimeStamps	打印每次 GC 的时间戳
-XX:-TraceClassLoading	跟踪类的加载信息
-XX:-TraceClassLoadingPreorder	跟踪被引用到的所有类的加载信息
-XX:-TraceClassResolution	跟踪常量池
-XX:-TraceClassUnloading	跟踪类的卸载信息
-XX:-TraceLoaderConstraints	跟踪类加载器约束的相关

24 调优方法
一切都是为了这一步，调优，在调优之前，我们需要记住下面的原则：
1）.多数的 Java 应用不需要在服务器上进行 GC 优化；
2）.多数导致 GC 问题的 Java 应用，都不是因为我们参数设置错误，而是代码问题；
3）.在应用上线之前，先考虑将机器的 JVM 参数设置到最优（最适合）；
4）.减少创建对象的数量；
5）.减少使用全局变量和大对象；
6）.GC 优化是到最后不得已才采用的手段；
7）.在实际使用中，分析 GC 情况优化代码比优化 GC 参数要多得多；
8）.将转移到老年代的对象数量降低到最小；
9）.减少 full GC 的执行时间；
10）.减少使用全局变量和大对象；
11）.调整新生代的大小到最合适；
12）.设置老年代的大小为最合适；
13）.选择合适的 GC 收集器；

25 常见配置汇总
（1）堆设置
 -Xms:初始堆大小
 -Xmx:最大堆大小
 -XX:NewSize=n:设置年轻代大小
-XX:NewRatio=n:设置年轻代和年老代的比值。如:为3，表示年轻代与年老代比值为1：3，年轻代占整个年轻代年老代和的1/4
 -XX:SurvivorRatio=n:年轻代中Eden区与两个Survivor区的比值。注意Survivor区有两个。如：3，表示Eden：Survivor=3：2，一个Survivor区占整个年轻代的1/5
-XX:MaxPermSize=n:设置持久代大小
			
（2）收集器设置
 -XX:+UseSerialGC:设置串行收集器
 -XX:+UseParallelGC:设置并行收集器
 -XX:+UseParalledlOldGC:设置并行年老代收集器
-XX:+UseConcMarkSweepGC:设置并发收集器
			
（3）垃圾回收统计信息
-XX:+PrintGC
-XX:+PrintGCDetails
-XX:+PrintGCTimeStamps
-Xloggc:filename
			
（4）并行收集器设置
-XX:ParallelGCThreads=n:设置并行收集器收集时使用的CPU数。并行收集线程数。
-XX:MaxGCPauseMillis=n:设置并行收集最大暂停时间
-XX:GCTimeRatio=n:设置垃圾回收时间占程序运行时间的百分比。公式为1/(1+n)
			
（5）并发收集器设置
 -XX:+CMSIncrementalMode:设置为增量模式。适用于单CPU情况。
 -XX:ParallelGCThreads=n:设置并发收集器年轻代收集方式为并行收集时，使用的CPU数。并行收集线程数。


26 调优总结
（1）年轻代大小选择
1）响应时间优先的应用：尽可能设大，直到接近系统的最低响应时间限制（根据实际情况选择）。在此种情况下，年轻代收集发生的频率也是最小的。同时，减少到达年老代的对象。
2）吞吐量优先的应用：尽可能的设置大，可能到达Gbit的程度。因为对响应时间没有要求，垃圾收集可以并行进行，一般适合8CPU以上的应用。

（2）年老代大小选择
1）响应时间优先的应用：年老代使用并发收集器，所以其大小需要小心设置，一般要考虑并发会话率和会话持续时间等一些参数。如果堆设置小了，可以会造成内存碎片、高回收频率以及应用暂停而使用传统的标记清除方式；如果堆大了，则需要较长的收集时间。最优化的方案，一般需要参考以下数据获得：
@并发垃圾收集信息
@持久代并发收集次数
@传统GC信息
@花在年轻代和年老代回收上的时间比例
@减少年轻代和年老代花费的时间，一般会提高应用的效率
2）吞吐量优先的应用：一般吞吐量优先的应用都有一个很大的年轻代和一个较小的年老代。原因是，这样可以尽可能回收掉大部分短期对象，减少中期的对象，而年老代尽存放长期存活对象。
 
（3）较小堆引起的碎片问题
    因为年老代的并发收集器使用标记、清除算法，所以不会对堆进行压缩。当收集器回收时，他会把相邻的空间进行合并，这样可以分配给较大的对象。但是，当堆空间较小时，运行一段时间以后，就会出现“碎片”，如果并发收集器找不到足够的空间，那么并发收集器将会停止，然后使用传统的标记、清除方式进行回收。如果出现“碎片”，可能需要进行如下配置：
1） -XX:+UseCMSCompactAtFullCollection：使用并发收集器时，开启对年老代的压缩。
2）-XX:CMSFullGCsBeforeCompaction=0：上面配置开启的情况下，这里设置多少次Full GC后，对年老代进行压缩




二、ms相关
1 java中会存在内存泄漏吗，请简单描述。
会。自己实现堆载的数据结构时有可能会出现内存泄露，可参看eﬀective java.

2 64 位 JVM 中，int 的长度是多数？
Java 中，int 类型变量的长度是一个固定值，与平台无关，都是 32 位。意思就是说，在 32 位 和 64 位 的 Java 虚拟机中，int 类型的长度是相同的。

3 Serial 与 Parallel GC 之间的不同之处？
Serial 与 Parallel 在 GC 执行的时候都会引起 stop-the-world。它们之间主要不同 serial 收集器是默认的复制收集器，执行 GC 的时候只有一个线程，而parallel 收集器使用多个 GC 线程来执行。

4 32 位和 64 位的 JVM，int 类型变量的长度是多数？
32 位和 64 位的 JVM 中，int 类型变量的长度是相同的，都是 32 位或者 4个字节。

5 Java 中 WeakReference 与 SoftReference 的区别？
虽然 WeakReference 与 SoftReference 都有利于提高 GC 和 内存的效率，但是 WeakReference ，一旦失去最后一个强引用，就会被 GC回收，而软引用虽然不能阻止被回收，但是可以延迟到 JVM 内存不足的时候。

6 JVM 选项 -XX:+UseCompressedOops 有什么作用？为什么要使用
当你将你的应用从 32 位的 JVM 迁移到 64 位的 JVM 时，由于对象的指针从32 位增加到了 64 位，因此堆内存会突然增加，差不多要翻倍。这也会对 CPU缓存（容量比内存小很多）的数据产生不利的影响。因为，迁移到 64 位的 JVM主要动机在于可以指定最大堆大小，通过压缩
OOP 可以节省一定的内存。通过-XX:+UseCompressedOops 选项，JVM 会使用 32 位的 OOP，而不是 64 位的 OOP。

7 怎样通过 Java 程序来判断 JVM 是 32 位 还是 64位？
你可以检查某些系统属性如 sun.arch.data.model 或 os.arch 来获取该信息。

8 32 位 JVM 和 64 位 JVM 的最大堆内存分别是多数？
理论上说上 32 位的 JVM 堆内存可以到达 2^32， 即 4GB，但实际上会比这个小很多。不同操作系统之间不同，如 Windows 系统大约 1.5GB，Solaris 大约3GB。64 位 JVM 允许指定最大的堆内存，理论上可以达到 2^64，这是一个非常大的数字，实际上你可以指定堆内存大小到 100GB。甚至有的 JVM，如 Azul，堆内存到 1000G 都是可能的。

9 JRE JDK JVM 及 JIT 之间有什么不同？
JRE 代表 Java 运行时（Java run-time），是运行 Java 引用所必须的。JDK 代表 Java 开发工具（Java development kit），是 Java 程序的开发工具，如 Java编译器，它也包含 JRE。JVM 代表 Java 虚拟机（Java virtual machine），它的责任是运行 Java 应用。JIT 代表即时编译（Just In Time compilation），当代码执行的次数超过一定的阈值时，会将 Java 字节码转换为本地代码，如，主要的热点代码会被准换为本地代码，这样有利大幅度提高 Java 应用的性能。

10 解释 Java 堆空间及 GC？
当通过 Java 命令启动 Java 进程的时候，会为它分配内存。内存的一部分用于创建堆空间，当程序中创建对象的时候，就从对空间中分配内存。GC 是 JVM 内部的一个进程，回收无效对象的内存用于将来的分配。

11 JVM 内存区域
JVM 内存区域主要分为线程私有区域【程序计数器 虚拟机栈 本地方法区】 线程共享区域【JAVA 堆 方法区】 直接内存。
线程私有数据区域生命周期与线程相同, 依赖用户线程的启动/结束 而 创建/销毁(在 Hotspot VM 内, 每个线程都与操作系统的本地线程直接映射, 因此这部分内存区域的存/否跟随本地线程的生/死对应)。
线程共享区域随虚拟机的启动/关闭而创建/销毁。
直接内存并不是 JVM 运行时数据区的一部分, 但也会被频繁的使用: 在 JDK 1.4 引入的 NIO 提供了基于 Channel 与 Buﬀer 的 IO 方式, 它可以使用 Native 函数库直接分配堆外内存, 然后使用DirectByteBuﬀer 对象作为这块内存的引用进行操作(详见: Java I/O 扩展), 这样就避免了在 Java堆和 Native 堆中来回复制数据, 因此在一些场景中可以显著提高性能。
 
12 程序计数器(线程私有)
一块较小的内存空间, 是当前线程所执行的字节码的行号指示器，每条线程都要有一个独立的程序计数器，这类内存也称为“线程私有” 的内存。
正在执行 java 方法的话，计数器记录的是虚拟机字节码指令的地址（当前指令的地址） 。如果还是 Native 方法，则为空。这个内存区域是唯一一个在虚拟机中没有规定任何 OutOfMemoryError 情况的区域。

13 虚拟机栈(线程私有)
是描述java方法执行的内存模型，每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表 操作数栈 动态链接 方法出口等信息。 每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。
栈帧（ Frame）是用来存储数据和部分过程结果的数据结构，同时也被用来处理动态链接(Dynamic Linking)  方法返回值和异常分派（ Dispatch Exception）。 栈帧随着方法调用而创建，随着方法结束而销毁——无论方法是正常完成还是异常完成（抛出了在方法内未被捕获的异常）都算作方法结束。

14 本地方法区(线程私有)
本地方法区和 Java Stack 作用类似, 区别是虚拟机栈为执行 Java 方法服务, 而本地方法栈则为Native 方法服务, 如果一个 VM 实现使用 C-linkage 模型来支持 Native 调用, 那么该栈将会是一个C 栈，但 HotSpot VM 直接就把本地方法栈和虚拟机栈合二为一 。

15 你能保证 GC 执行吗？
不能，虽然你可以调用 System.gc() 或者 Runtime.gc()，但是没有办法保证 GC的执行。

16 怎么获取 Java 程序使用的内存？堆使用的百分比？
可以通过 java.lang.Runtime 类中与内存相关方法来获取剩余的内存，总内存及最大堆内存。通过这些方法你也可以获取到堆使用的百分比及堆内存的剩余空间。Runtime.freeMemory() 方法返回剩余空间的字节数，Runtime.totalMemory()方法总内存的字节数，Runtime.maxMemory() 返回最大内存的字节数。

17 Java 中堆和栈有什么区别？
JVM 中堆和栈属于不同的内存区域，使用目的也不同。栈常用于保存方法帧和局部变量，而对象总是在堆上分配。栈通常都比堆小，也不会在多个线程之间共享，而堆被整个 JVM 的所有线程共享。

18 描述一下 JVM 加载 class 文件的原理机制
JVM 中类的装载是由类加载器（ClassLoader）和它的子类来实现的，Java 中的类加载器是一个重要的 Java 运行时系统组件，它负责在运行时查找和装入类文件中的类。
由于 Java 的跨平台性，经过编译的 Java 源程序并不是一个可执行程序，而是一个或多个类文件。当 Java 程序需要使用某个类时，JVM 会确保这个类已经被加载 连接（验证 准备和解析）和初始化。类的加载是指把类的.class 文件中的数据读入到内存中，通常是创建一个字节数组读入.class 文件，然后产生与所加载类对应
的 Class 对象。
加载完成后，Class 对象还不完整，所以此时的类还不可用。当类被加载后就进入连接阶段，这一阶段包括验证 准备（为静态变量分配内存并设置默认的初始值）和解析（将符号引用替换为直接引用）三个步骤。最后 JVM 对
类进行初始化，包括：1)如果类存在直接的父类并且这个类还没有被初始化，那么就先初始化父类；2)如果类中存在初始化语句，就依次执行这些初始化语句。
类的加载是由类加载器完成的，类加载器包括：根加载器（BootStrap） 扩展加载器（Extension） 系统加载器（System）和用户自定义类加载器（java.lang.ClassLoader 的子类）。
从 Java 2（JDK 1.2）开始，类加载过程采取了父亲委托机制（PDM）。PDM 更好的保证了 Java 平台的安全性，在该机制中，JVM 自带的Bootstrap 是根加载器，其他的加载器都有且仅有一个父类加载器。类的加载首先请求父类加载器加载，父类加载器无能为力时才由其子类加载器自行加载。JVM 不会向 Java 程序提供对 Bootstrap 的引用。

下面是关于几个类加载器的说明：
Bootstrap：一般用本地代码实现，负责加载 JVM 基础核心类库（rt.jar）；
Extension：从 java.ext.dirs 系统属性所指定的目录中加载类库，它的父加载器是 Bootstrap；
System：又叫应用类加载器，其父类是 Extension。它是应用最广泛的类加载器。它从环境变量 classpath 或者系统属性
java.class.path 所指定的目录中记载类，是用户自定义加载器的默认父加载器。

19 GC 是什么？为什么要有 GC？
GC 是垃 圾收 集的 意思 ，内存 处理 是编 程人 员容 易出 现问 题的 地方 ，忘记 或者 错误的内 存回 收会 导致 程序 或系 统的 不稳 定甚 至崩 溃， Java 提供 的 GC 功能 可以 自动监测 对象 是否 超过 作用 域从 而达 到自 动回 收内 存的 目的 ，Java 语言 没有 提供 释放已分 配内存的 显示 操作 方法 。Java 程序 员不 用担 心内 存管 理， 因为 垃圾 收集 器会自动 进行 管理 。要 请求 垃圾 收集 ，可 以调 用下 面的 方法 之一 ：System.gc() 或Runtime.getRuntime().gc() ，但 JVM 可以 屏蔽 掉显 示的 垃圾 回收 调用 。
垃圾回收可以有效的防止内存泄露，有效的使用可以使用的内存。垃圾回收器通常是作为一个单独的低优先级的线程运行，不可预知的情况下对内存堆中已经死亡的或者长时间没有使用的对象进行清除和回收，程序员不能实时的调用垃圾回收器对某个对象或所有对象进行垃圾回收。在 Java 诞生初期，垃圾回收是 Java最大的亮点之一，因为服务器端的编程需要有效的防止内存泄露问题，然而时过境迁，如今 Java 的垃圾回收机制已经成为被诟病的东。移动智能终端用户通常觉得 iOS 的系统比 Android 系统有更好的用户体验，其中一个深层次的原因就在于 Android 系统中垃圾回收的不可预知性。

20 堆（Heap-线程共享） -运行时数据区
是被线程共享的一块内存区域， 创建的对象和数组都保存在 Java 堆内存中，也是垃圾收集器进行垃圾收集的最重要的内存区域。 由于现代
VM 采用分代收集算法, 因此 Java 堆从 GC 的角度还可以细分为: 新生代(Eden 区  From Survivor 区和 To Survivor 区)和老年代。

21 方法区/永久代（线程共享）
即我们常说的永久代(Permanent Generation), 用于存储被 JVM 加载的类信息  常量  静态变量  即时编译器编译后的代码等数据. HotSpot VM把GC分代收集扩展至方法区, 即使用Java堆的永久代来实现方法区, 这样 HotSpot 的垃圾收集器就可以像管理 Java 堆一样管理这部分内存,而不必为方法区开发专门的内存管理器(永久带的内存回收的主要目标是针对常量池的回收和类型的卸载, 因此收益一般很小) 。

运行时常量池（Runtime Constant Pool）是方法区的一部分。 Class 文件中除了有类的版本 字段 方法 接口等描述等信息外，还有一项信息是常量池 （Constant Pool Table），用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。 Java 虚拟机对 Class 文件的每一部分（自然也包括常量池）的格式都有严格的规定，每一个字节用于存储哪种数据都必须符合规范上的要求，这样才会被虚拟机认可 装载和执行。

22 JVM 运行时内存
Java 堆从 GC 的角度还可以细分为: 新生代(Eden 区  From Survivor 区和 To Survivor 区)和老年代。

23 新生代
是用来存放新生的对象。一般占据堆的 1/3 空间。由于频繁创建对象，所以新生代会频繁触发MinorGC 进行垃圾回收。新生代又分为 Eden区  ServivorFrom  ServivorTo 三个区。
Eden 区
Java 新对象的出生地（如果新创建的对象占用内存很大，则直接分配到老年代）。当 Eden 区内存不够的时候就会触发 MinorGC，对新生代区进行一次垃圾回收。
ServivorFrom
上一次 GC 的幸存者，作为这一次 GC 的被扫描者。
ServivorTo
保留了一次 MinorGC 过程中的幸存者。
MinorGC 的过程（复制->清空->互换）
MinorGC 采用复制算法。
eden  servicorFrom 复制到 ServicorTo，年龄+1
首先，把 Eden 和 ServivorFrom 区域中存活的对象复制到 ServicorTo 区域（如果有对象的年龄以及达到了老年的标准，则赋值到老年代区），同时把这些对象的年龄+1（如果 ServicorTo 不够位置了就放到老年区）；
清空 eden  servicorFrom
然后，清空 Eden 和 ServicorFrom 中的对象；
ServicorTo 和 ServicorFrom 互换
最后， ServicorTo 和 ServicorFrom 互换，原 ServicorTo 成为下一次 GC 时的 ServicorFrom区。

24 老年代
主要存放应用程序中生命周期长的内存对象。
老年代的对象比较稳定，所以 MajorGC 不会频繁执行。在进行 MajorGC 前一般都先进行了一次 MinorGC，使得有新生代的对象晋身入老年代，导致空间不够用时才触发。当无法找到足够大的连续空间分配给新创建的较大对象时也会提前触发一次 MajorGC 进行垃圾回收腾出空间。
MajorGC 采用标记清除算法：首先扫描一次所有老年代，标记出存活的对象，然后回收没有标记的对象。 ajorGC 的耗时比较长，因为要扫描再回收。 MajorGC 会产生内存碎片，为了减少内存损耗，我们一般需要进行合并或者标记出来方便下次直接分配。当老年代也满了装不下的时候，就会抛出 OOM（Out of Memory）异常。

25 永久代
指内存的永久保存区域，主要存放 Class 和 Meta（元数据）的信息,Class 在被加载的时候被放入永久区域， 它和和存放实例的区域不同,GC 不会在主程序运行期对永久区域进行清理。所以这也导致了永久代的区域会随着加载的 Class 的增多而胀满，最终抛出 OOM 异常。

26 JAVA8 与元数据
在 Java8 中， 永久代已经被移除，被一个称为“元数据区”（元空间）的区域所取代。元空间的本质和永久代类似，元空间与永久代之间最大的区别在于： 元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制。 类的元数据放入
nativememory, 字符串池和类的静态变量放入 java 堆中， 这样可以加载多少类的元数据就不再由MaxPermSize 控制, 而由系统的实际可用空间来控制。

27 引用计数法
在 Java 中，引用和对象是有关联的。如果要操作对象则必须用引用进行。因此，很显然一个简单的办法是通过引用计数来判断一个对象是否可以回收。简单说，即一个对象如果没有任何与之关联的引用， 即他们的引用计数都不为 0， 则说明对象不太可能再被用到，那么这个对象就是可回收对象。

28 可达性分析
为了解决引用计数法的循环引用问题， Java 使用了可达性分析的方法。通过一系列的“GC roots”对象作为起点搜索。如果在“GC roots”和一个对象之间没有可达路径，则称该对象是不可达的。要注意的是，不可达对象不等价于可回收对象， 不可达对象变为可回收对象至少要经过两次标记过程。两次标记后仍然是可回收对象，则将面临回收。

29 标记清除算法（ Mark-Sweep）
最基础的垃圾回收算法，分为两个阶段，标注和清除。标记阶段标记出所有需要回收的对象，清除阶段回收被标记的对象所占用的空间。如
从图中我们就可以发现，该算法最大的问题是内存碎片化严重，后续可能发生大对象不能找到可利用空间的问题。

30 复制算法（copying）
为了解决 Mark-Sweep 算法内存碎片化的缺陷而被提出的算法。按内存容量将内存划分为等大小的两块。每次只使用其中一块，当这一块内存满后将尚存活的对象复制到另一块上去，把已使用的内存清掉，如图：
这种算法虽然实现简单，内存效率高，不易产生碎片，但是最大的问题是可用内存被压缩到了原本的一半。且存活对象增多的话， Copying算法的效率会大大降低。

31 标记整理算法(Mark-Compact)
结合了以上两个算法，为了避免缺陷而提出。标记阶段和 Mark-Sweep 算法相同， 标记后不是清理对象，而是将存活对象移向内存的一端。然后清除端边界外的对象。如图：
 
32 分代收集算法
分代收集法是目前大部分 JVM 所采用的方法，其核心思想是根据对象存活的不同生命周期将内存划分为不同的域，一般情况下将 GC 堆划分为老生代(Tenured/Old Generation)和新生代(YoungGeneration)。老生代的特点是每次垃圾回收时只有少量对象需要被回收，新生代的特点是每次垃圾回收时都有大量垃圾需要被回收，因此可以根据不同区域选择不同的算法。

33 新生代与复制算法
目前大部分 JVM 的 GC 对于新生代都采取 Copying 算法，因为新生代中每次垃圾回收都要回收大部分对象，即要复制的操作比较少，但通常并不是按照 1： 1 来划分新生代。一般将新生代划分为一块较大的 Eden 空间和两个较小的 Survivor 空间(From Space, To Space)，每次使用Eden 空间和其中的一块 Survivor 空间，当进行回收时，将该两块空间中还存活的对象复制到另一块 Survivor 空间中。

34 老年代与标记复制算法
而老年代因为每次只回收少量对象，因而采用 Mark-Compact 算法。
JAVA 虚拟机提到过的处于方法区的永生代(Permanet Generation)， 它用来存储 class 类，常量，方法描述等。对永生代的回收主要包括废弃常量和无用的类。
对象的内存分配主要在新生代的 Eden Space 和 Survivor Space 的 From Space(Survivor 目前存放对象的那一块)，少数情况会直接分配到老生代。
当新生代的 Eden Space 和 From Space 空间不足时就会发生一次 GC，进行 GC 后， EdenSpace 和 From Space 区的存活对象会被挪到 To Space，然后将 Eden Space 和 FromSpace 进行清理。
如果 To Space 无法足够存储某个对象，则将这个对象存储到老生代。
在进行 GC 后，使用的便是 Eden Space 和 To Space 了，如此反复循环。
当对象在 Survivor 区躲过一次 GC 后，其年龄就会+1。 默认情况下年龄到达 15 的对象会被移到老生代中。

35 JAVA 强引用
在 Java 中最常见的就是强引用， 把一个对象赋给一个引用变量，这个引用变量就是一个强引用。当一个对象被强引用变量引用时，它处于可达状态，它是不可能被垃圾回收机制回收的，即使该对象以后永远都不会被用到 JVM 也不会回收。因此强引用是造成 Java 内存泄漏的主要原因之一。

36 JAVA软引用
软引用需要用 SoftReference 类来实现，对于只有软引用的对象来说，当系统内存足够时它不会被回收，当系统内存空间不足时它会被回收。软引用通常用在对内存敏感的程序中。

37 JAVA弱引用
弱引用需要用 WeakReference 类来实现，它比软引用的生存期更短，对于只有弱引用的对象来说，只要垃圾回收机制一运行，不管 JVM 的内存空间是否足够，总会回收该对象占用的内存。

38 JAVA虚引用
虚引用需要 PhantomReference 类来实现，它不能单独使用，必须和引用队列联合使用。 虚引用的主要作用是跟踪对象被垃圾回收的状态。

39 分代收集算法
当前主流 VM 垃圾收集都采用”分代收集” (Generational Collection)算法, 这种算法会根据对象存活周期的不同将内存划分为几块, 如 JVM 中的 新生代 老年代 永久代， 这样就可以根据各年代特点分别采用最适当的 GC 算法

40 在新生代-复制算法
每次垃圾收集都能发现大批对象已死, 只有少量存活. 因此选用复制算法, 只需要付出少量存活对象的复制成本就可以完成收集

41 在老年代-标记整理算法
因为对象存活率高 没有额外空间对它进行分配担保, 就必须采用“标记—清理”或“标记—整理” 算法来进行回收, 不必进行内存复制, 且直接腾出空闲内存。

42 分区收集算法
分区算法则将整个堆空间划分为连续的不同小区间, 每个小区间独立使用, 独立回收. 这样做的好处是可以控制一次回收多少个小区间 , 根据目标停顿时间, 每次合理地回收若干个小区间(而不是整个堆), 从而减少一次 GC 所产生的停顿。

43 GC 垃圾收集器
Java 堆内存被划分为新生代和年老代两部分，新生代主要使用复制和标记-清除垃圾回收算法；年老代主要使用标记-整理垃圾回收算法，因此 java 虚拟中针对新生代和年老代分别提供了多种不同的垃圾收集器， JDK1.6 中 Sun HotSpot 虚拟机的垃圾收集器如下：

44 Serial 垃圾收集器（单线程  复制算法）
Serial（英文连续） 是最基本垃圾收集器，使用复制算法，曾经是JDK1.3.1 之前新生代唯一的垃圾收集器。 Serial 是一个单线程的收集器， 它不但只会使用一个 CPU 或一条线程去完成垃圾收集工作，并且在进行垃圾收集的同时，必须暂停其他所有的工作线程，直到垃圾收集结束。
Serial 垃圾收集器虽然在收集垃圾过程中需要暂停所有其他的工作线程，但是它简单高效，对于限定单个 CPU 环境来说，没有线程交互的开销，可以获得最高的单线程垃圾收集效率，因此 Serial垃圾收集器依然是 java 虚拟机运行在 Client 模式下默认的新生代垃圾收集器。

45 ParNew 垃圾收集器（Serial+多线程）
ParNew 垃圾收集器其实是 Serial 收集器的多线程版本，也使用复制算法，除了使用多线程进行垃圾收集之外，其余的行为和 Serial 收集器完全一样， ParNew 垃圾收集器在垃圾收集过程中同样也要暂停所有其他的工作线程。
ParNew 收集器默认开启和 CPU 数目相同的线程数，可以通过-XX:ParallelGCThreads 参数来限制垃圾收集器的线程数。 【Parallel：平行的】
ParNew 虽然是除了多线程外和Serial 收集器几乎完全一样，但是ParNew垃圾收集器是很多 java虚拟机运行在 Server 模式下新生代的默认垃圾收集器。

46 Parallel Scavenge 收集器（多线程复制算法 高效）
Parallel Scavenge 收集器也是一个新生代垃圾收集器，同样使用复制算法，也是一个多线程的垃圾收集器， 它重点关注的是程序达到一个可控制的吞吐量（Thoughput， CPU 用于运行用户代码的时间/CPU 总消耗时间，即吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间)），高吞吐量可以最高效率地利用 CPU 时间，尽快地完成程序的运算任务，主要适用于在后台运算而不需要太多交互的任务。 自适应调节策略也是 ParallelScavenge 收集器与 ParNew 收集器的一个重要区别。

47 Serial Old 收集器（单线程标记整理算法 ）
Serial Old 是 Serial 垃圾收集器年老代版本，它同样是个单线程的收集器，使用标记-整理算法，这个收集器也主要是运行在 Client 默认的
java 虚拟机默认的年老代垃圾收集器。在 Server 模式下，主要有两个用途：
在 JDK1.5 之前版本中与新生代的 Parallel Scavenge 收集器搭配使用。
作为年老代中使用 CMS 收集器的后备垃圾收集方案。新生代 Serial 与年老代 Serial Old 搭配垃圾收集过程图：
新生代 Parallel Scavenge 收集器与 ParNew 收集器工作原理类似，都是多线程的收集器，都使用的是复制算法，在垃圾收集过程中都需要暂停所有的工作线程。新生代 ParallelScavenge/ParNew 与年老代 Serial Old 搭配垃圾收集过程图：
 
48 Parallel Old 收集器（多线程标记整理算法）
Parallel Old 收集器是Parallel Scavenge的年老代版本，使用多线程的标记-整理算法，在 JDK1.6才开始提供。
在 JDK1.6 之前，新生代使用 ParallelScavenge 收集器只能搭配年老代的 Serial Old 收集器，只能保证新生代的吞吐量优先，无法保证整体的吞吐量， Parallel Old 正是为了在年老代同样提供吞吐量优先的垃圾收集器， 如果系统对吞吐量要求比较高，可以优先考虑新生代Parallel Scavenge和年老代 Parallel Old 收集器的搭配策略。
新生代 Parallel Scavenge 和年老代 Parallel Old 收集器搭配运行过程图
 
49 CMS 收集器（多线程标记清除算法）
Concurrent mark sweep(CMS)收集器是一种年老代垃圾收集器，其最主要目标是获取最短垃圾回收停顿时间， 和其他年老代使用标记-整理算法不同，它使用多线程的标记-清除算法。最短的垃圾收集停顿时间可以为交互比较高的程序提高用户体验。CMS 工作机制相比其他的垃圾收集器来说更复杂。整个过程分为以下 4 个阶段：
初始标记
只是标记一下 GC Roots 能直接关联的对象，速度很快，仍然需要暂停所有的工作线程。
并发标记
进行 GC Roots 跟踪的过程，和用户线程一起工作，不需要暂停工作线程。
重新标记
为了修正在并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，仍然需要暂停所有的工作线程。
并发清除
清除 GC Roots 不可达对象，和用户线程一起工作，不需要暂停工作线程。由于耗时最长的并发标记和并发清除过程中，垃圾收集线程可以和用户现在一起并发工作， 所以总体上来看CMS 收集器的内存回收和用户线程是一起并发地执行。CMS 收集器工作过程

50 G1 收集器
Garbage ﬁrst 垃圾收集器是目前垃圾收集器理论发展的最前沿成果，相比与 CMS 收集器， G1 收集器两个最突出的改进是：
1.基于标记-整理算法，不产生内存碎片。
2.可以非常精确控制停顿时间，在不牺牲吞吐量前提下，实现低停顿垃圾回收。G1 收集器避免全区域垃圾收集，它把堆内存划分为大小固定的几个独立区域，并且跟踪这些区域的垃圾收集进度，同时在后台维护一个优先级列表，每次根据所允许的收集时间， 优先回收垃圾最多的区域。区域划分和优先级区域回收机制，确保 G1 收集器可以在有限时间获得最高的垃圾收集效率

51 JVM 类加载机制
JVM 类加载机制分为五个部分：加载，验证，准备，解析，初始化，下面我们就分别来看一下这五个过程。
加载
加载是类加载过程中的一个阶段， 这个阶段会在内存中生成一个代表这个类的 java.lang.Class 对象， 作为方法区这个类的各种数据的入口。注意这里不一定非得要从一个 Class 文件获取，这里既可以从 ZIP 包中读取（比如从 jar 包和 war 包中读取），也可以在运行时计算生成（动态代理），也可以由其它文件生成（比如将 JSP 文件转换成对应的 Class 类）。
验证
这一阶段的主要目的是为了确保 Class 文件的字节流中包含的信息是否符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。
准备
准备阶段是正式为类变量分配内存并设置类变量的初始值阶段，即在方法区中分配这些变量所使用的内存空间。注意这里所说的初始值概念，比如一个类变量定义为：
实际上变量 v 在准备阶段过后的初始值为 0 而不是 8080， 将 v 赋值为 8080 的 put static 指令是程序被编译后， 存放于类构造器方法之中。
但是注意如果声明为：public static ﬁnal int v = 8080;
在编译阶段会为 v 生成 ConstantValue 属性，在准备阶段虚拟机会根据 ConstantValue 属性将 v赋值为 8080。
解析
解析阶段是指虚拟机将常量池中的符号引用替换为直接引用的过程。符号引用就是 class 文件中的：
public static int v = 8080;
实际上变量 v 在准备阶段过后的初始值为 0 而不是 8080， 将 v 赋值为 8080 的 put static 指令是程序被编译后， 存放于类构造器方法之中。但是注意如果声明为：
在编译阶段会为 v 生成 ConstantValue 属性，在准备阶段虚拟机会根据 ConstantValue 属性将 v
赋值为 8080。解析
解析阶段是指虚拟机将常量池中的符号引用替换为直接引用的过程。符号引用就是 class 文件中的：
public static final int v = 8080;
在编译阶段会为 v 生成 ConstantValue 属性，在准备阶段虚拟机会根据 ConstantValue 属性将 v赋值为 8080。
解析
解析阶段是指虚拟机将常量池中的符号引用替换为直接引用的过程。符号引用就是 class 文件中的：
CONSTANT_Class_info
CONSTANT_Field_info
CONSTANT_Method_info
等类型的常量。
符号引用
符号引用与虚拟机实现的布局无关， 引用的目标并不一定要已经加载到内存中。 各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须是一致的，因为符号引用的字面量形式明确定义在 Java 虚拟机规范的 Class 文件格式中。
直接引用
直接引用可以是指向目标的指针，相对偏移量或是一个能间接定位到目标的句柄。如果有了直接引用，那引用的目标必定已经在内存中存在。
初始化
初始化阶段是类加载最后一个阶段，前面的类加载阶段之后，除了在加载阶段可以自定义类加载器以外，其它操作都由 JVM 主导。到了初始阶段，才开始真正执行类中定义的 Java 程序代码。
类构造器
初始化阶段是执行类构造器方法的过程。 方法是由编译器自动收集类中的类变量的赋值操作和静态语句块中的语句合并而成的。虚拟机会保证子方法执行之前，父类的方法已经执行完毕， 如果一个类中没有对静态变量赋值也没有静态语句块，那么编译器可以不为这个类生成() 方法。注意以下几种情况不会执行类初始化：
通过子类引用父类的静态字段，只会触发父类的初始化，而不会触发子类的初始化。
定义对象数组，不会触发该类的初始化。
常量在编译期间会存入调用类的常量池中，本质上并没有直接引用定义常量的类，不会触发定义常量所在的类。
通过类名获取 Class 对象，不会触发类的初始化。
通过 Class.forName 加载指定类时，如果指定参数 initialize 为 false 时，也不会触发类初始化，其实这个参数是告诉虚拟机，是否要对类进行初始化。
通过 ClassLoader 默认的 loadClass 方法，也不会触发初始化动作。

52 类加载器
虚拟机设计团队把加载动作放到 JVM 外部实现，以便让应用程序决定如何获取所需的类， JVM 提供了 3 种类加载器：
启动类加载器(Bootstrap ClassLoader)
负责加载 JAVA_HOME\lib 目录中的， 或通过-Xbootclasspath 参数指定路径中的， 且被虚拟机认可（按文件名识别， 如 rt.jar） 的类。
扩展类加载器(Extension ClassLoader)
负责加载 JAVA_HOME\lib\ext 目录中的，或通过 java.ext.dirs 系统变量指定路径中的类库。
应用程序类加载器(Application ClassLoader)：
负责加载用户路径（classpath）上的类库。JVM 通过双亲委派模型进行类的加载， 当然我们也可以通过继承 java.lang.ClassLoader实现自定义的类加载器。
 
53 双亲委派
当一个类收到了类加载请求，他首先不会尝试自己去加载这个类，而是把这个请求委派给父类去完成，每一个层次类加载器都是如此，因此所有的加载请求都应该传送到启动类加载其中，只有当父类加载器反馈自己无法完成这个请求的时候（在它的加载路径下没有找到所需加载的Class）， 子类加载器才会尝试自己去加载。
采用双亲委派的一个好处是比如加载位于 rt.jar 包中的类 java.lang.Object，不管是哪个加载器加载这个类，最终都是委托给顶层的启动类加载器进行加载，这样就保证了使用不同的类加载器最终得到的都是同样一个 Object 对象

54 OSGI（ 动态模型系统）
OSGi(Open Service Gateway Initiative)，是面向 Java 的动态模型系统，是 Java 动态化模块化系统的一系列规范。

55 动态改变构造
OSGi 服务平台提供在多种网络设备上无需重启的动态改变构造的功能。为了最小化耦合度和促使这些耦合度可管理， OSGi 技术提供一种面向服务的架构，它能使这些组件动态地发现对方。

56 模块化编程与热插拔
OSGi 旨在为实现 Java 程序的模块化编程提供基础条件，基于 OSGi 的程序很可能可以实现模块级的热插拔功能，当程序升级更新时，可以只停用 重新安装然后启动程序的其中一部分，这对企业级程序开发来说是非常具有诱惑力的特性。
OSGi 描绘了一个很美好的模块化开发目标，而且定义了实现这个目标的所需要服务与架构，同时也有成熟的框架进行实现支持。但并非所有的应用都适合采用 OSGi 作为基础架构，它在提供强大功能同时，也引入了额外的复杂度，因为它不遵守了类加载的双亲委托模型。

57 JVM内存模型
线程独占:栈,本地方法栈,程序计数器线程共享:堆,方法区

58 栈
又称方法栈,线程私有的,线程执行方法是都会创建一个栈阵,用来存储局部变量表,操作栈,动态链接,方法 出口等信息.调用方法时执行入栈,方法返回式执行出栈.

59 本地方法栈
与栈类似,也是用来保存执行方法的信息.执行Java方法是使用栈,执行Native方法时使用本地方法栈.

60 程序计数器
保存着当前线程执行的字节码位置,每个线程工作时都有独立的计数器,只为执行Java方法服务,执行Native方法时,程序计数器为空.

61 堆
JVM内存管理最大的一块,对被线程共享,目的是存放对象的实例,几乎所欲的对象实例都会放在这里,当堆没有可用空间时,会抛出OOM异常.根 据对象的存活周期不同,JVM把对象进行分代管理,由垃圾回收器进行垃圾的回收管理

62 方法区
又称非堆区,用于存储已被虚拟机加载的类信息,常量,静态变量,即时编译器优化后的代码等数据.1.7的永久代和1.8的元空间都是方法区的一种 实现。

63 分代回收
分代回收基于两个事实:大部分对象很快就不使用了,还有一部分不会立即无用,但也不会持续很长时间
年轻代->标记-复制
老年代->标记-清除

64 堆和栈的区别
栈是运行时单位，代表着逻辑，内含基本数据类型和堆中对象引用，所在区域连续，没有碎片；堆是存储单位，代表着数据，可被多个栈共享（包括成员中基本数据类型 引用和引用对象），所在区域不连续，会有碎片。 
1）功能不同
栈内存用来存储局部变量和方法调用，而堆内存用来存储Java中的对象。无论是成员变量，局部变量， 还是类变量，它们指向的对象都存储在堆内存中。
2）共享性不同
栈内存是线程私有的。
堆内存是所有线程共有的。
3）异常错误不同
如果栈内存或者堆内存不足都会抛出异常。
栈空间不足：java.lang.StackOverFlowError。堆空间不足：java.lang.OutOfMemoryError。
4）空间大小
栈的空间大小远远小于堆的

65 什么时候会触发FullGC
除直接调用System.gc外，触发Full GC执行的情况有如下四种。
1）.旧生代空间不足
旧生代空间只有在新生代对象转入及创建为大对象 大数组时才会出现不足的现象，当执行Full GC后空间仍然不足，则抛出如下错误：
java.lang.OutOfMemoryError: Java heap space
为避免以上两种状况引起的FullGC，调优时应尽量做到让对象在Minor GC阶段被回收 让对象在新生代多存活一段时间及不要创建过大的对象及数组。
2）.Permanet Generation空间满
PermanetGeneration中存放的为一些class的信息等，当系统中要加载的类 反射的类和调用的方法较多时，Permanet Generation
可能会被占满，在未配置为采用CMS GC的情况下会执行Full GC。如果经过Full GC仍然回收不了，那么JVM会抛出如下错误信息：
java.lang.OutOfMemoryError: PermGen space
为避免Perm Gen占满造成Full GC现象，可采用的方法为增大Perm Gen空间或转为使用CMS GC。
3）.CMS GC时出现promotion failed和concurrent mode failure
对于采用CMS进行旧生代GC的程序而言，尤其要注意GC日志中是否有promotion failed和concurrent mode failure两种状况，当这两种状况出现时可能会触发Full GC。
promotionfailed是在进行Minor GC时，survivor space放不下 对象只能放入旧生代，而此时旧生代也放不下造成的；concurrent mode failure是在执行CMS GC的过程中同时有对象要放入旧生代，而此时旧生代空间不足造成的。
应对措施为：增大survivorspace 旧生代空间或调低触发并发GC的比率，但在JDK 5.0+ 6.0+的版本中有可能会由于JDK的bug29导致CMS在remark完毕后很久才触发sweeping动作。对于这种状况，可通过设置-XX:CMSMaxAbortablePrecleanTime=5（单位为ms）来避免。
4）.统计得到的Minor GC晋升到旧生代的平均大小大于旧生代的剩余空间
这是一个较为复杂的触发情况，Hotspot为了避免由于新生代对象晋升到旧生代导致旧生代空间不足的现象，在进行Minor GC时，做了一个判断，如果之前统计所得到的Minor GC晋升到旧生代的平均大小大于旧生代的剩余空间，那么就直接触发Full GC。
例如程序第一次触发MinorGC后，有6MB的对象晋升到旧生代，那么当下一次Minor GC发生时，首先检查旧生代的剩余空间是否大于6MB，如果小于6MB，则执行Full GC。
当新生代采用PSGC时，方式稍有不同，PS GC是在Minor GC后也会检查，例如上面的例子中第一次Minor GC后，PS GC会检查此时旧生代的剩余空间是否大于6MB，如小于，则触发对旧生代的回收。除了以上4种状况外，对于使用RMI来进行RPC或管理的Sun JDK应用而言，默认情况下会一小时执行一次Full GC。可通过在启动时通过- java-Dsun.rmi.dgc.client.gcInterval=3600000来设置Full GC执行的间隔时间或通过-XX:+ DisableExplicitGC来禁止RMI调用System.gc

66 什么是Java虚拟机？为什么Java被称作是“平台无关的编程语言”？
Java虚拟机是一个可以执行Java字节码的虚拟机进程。Java源文件被编译成能被Java虚拟机执行的字节码文件。 Java被设计成允许应用程序可以运行在任意的平台，而不需要程序员为每一个平台单独重写或者是重新编译。Java虚拟机让这个变为可能，因为它知道底层硬件平台的 指令长度和其他特性。

67 对象分配规则
对象优先分配在Eden区，如果Eden区没有足够的空间时，虚拟机执行一次Minor GC。
大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）。这样做的目的是避免在Eden区和两个Survivor区之间发生大量的内存拷贝（新生代采用复制算法收集内存）。
长期存活的对象进入老年代。虚拟机为每个对象定义了一个年龄计数器，如果对象经过了1次Minor GC那么对象会进入Survivor区，之后每经过一次Minor GC那么对象的年龄加1，知道达到阀值对象进入老年区。
动态判断对象的年龄。如果Survivor区中相同年龄的所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代。
空间分配担保。每次进行Minor GC时，JVM会计算Survivor区移至老年区的对象的平均大小，如果这个值大于老年区的剩余值大小则进行一次Full GC，如果小于检查HandlePromotionFailure设置，如果true则只进行Monitor GC,如果false则进行Full GC

68 描述一下JVM加载class文件的原理机制？
JVM中类的装载是由类加载器（ClassLoader）和它的子类来实现的，Java中的类加载器是一个重要的Java运行时系统组件，它负责在运行时 查找和装入类文件中的类。
由于Java的跨平台性，经过编译的Java源程序并不是一个可执行程序，而是一个或多个类文件。当Java程序需要使用某个类时，JVM会确保 这个类已经被加载 连接（验证 准备和解析）和初始化。
类的加载是指把类的.class文件中的数据读入到内存中，通常是创建一个字节数组读入.class文件，然后产生与所加载类对应的Class对象。加载完成后，Class对象还不完整，所以此时的类还不可用。
当类被加载后就进入连接阶段，这一阶段包括验证 准备（为静态变量分配内存并设置默认的初始值）和解析（将符号引用替换为直接引用）三个步骤。最后JVM对类进行初始化，
包括：
如果类存在直接的父类并且这个类还没有被初始化，那么就先初始化父类；
如果类中存在初始化语句，就依次执行这些初始化语句。 类的加载是由类加载器完成的，类加载器包括：根加载器（BootStrap） 扩展加载器（Extension） 系统加载器（System）和用户自定义类加载器（java.lang.ClassLoader的子类）。
从Java 2（JDK 1.2）开始，类加载过程采取了父亲委托机制（PDM）。PDM更好的保证了Java平台的安全性，在该机制中，JVM自带的Bootstrap是根加载器，其他的加载器都有且仅有一个父类加载器。
类的加载首先请求父类加载器加载，父类加载器无能为力时才由其子类加载器自行加载。JVM不会向Java程序提供对Bootstrap的引用。下面是关于几个类加载器的说明
Bootstrap：一般用本地代码实现，负责加载JVM基础核心类库（rt.jar）；
Extension：从java.ext.dirs系统属性所指定的目录中加载类库，它的父加载器是Bootstrap；
System：又叫应用类加载器，其父类是Extension。它是应用最广泛的类加载器。它从环境变量classpath或者系统属性java.class.path所指定的目录中记载类，是用户自定义加载器的默认父加载器。

69 Java对象创建过程
JVM遇到一条新建对象的指令时首先去检查这个指令的参数是否能在常量池中定义到一个类的符号引用。然后加载这个类（类加载过程在 后边讲） 2. 为对象分配内存。一种办法“指针碰撞” 一种办法“空闲列表”，最终常用的办法“本地线程缓冲分配(TLAB)”
将除对象头外的对象内存空间初始化为0
对对象头进行必要设置

70 简述Java的对象结构
Java对象由三个部分组成：对象头 实例数据 对齐填充。
对象头由两部分组成，第一部分存储对象自身的运行时数据：哈希码 GC分代年龄 锁标识状态 线程持有的锁 偏向线程ID（一般占32/64 bit）。第二部分是指针类型，指向对象的类元数据类型（即对象代表哪个类）。如果是数组对象，则对象头中还有一部分用来记录数组长度。
实例数据用来存储对象真正的有效信息（包括父类继承下来的和自己定义的） 对齐填充：JVM要求对象起始地址必须是8字节的整数倍（8字节对齐 )

71 如何判断对象可以被回收
判断对象是否存活一般有两种方式：
引用计数：每个对象有一个引用计数属性，新增一个引用时计数加1，引用释放时计数减1，计数为0时可以回收。此方法简单，无法解决对象相互循环引用的问题。
可达性分析（Reachability Analysis）：从GC Roots开始向下搜索，搜索所走过的路径称为引用链。当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的，不可达对象。

72 JVM的永久代中会发生垃圾回收么
垃圾回收不会发生在永久代，如果永久代满了或者是超过了临界值，会触发完全垃圾回收(Full GC)。如果你仔细查看垃圾收集器的输出信息，就会发现永久代也是被回收的。这就是为什么正确的永久代大小对避免Full GC是非常重要的原因。请参考下Java8：从永久代到元数据区 (注：Java8中已经移除了永久代，新加了一个叫做元数据区的native内存区)

73 垃圾收集算法
GC最基础的算法有三种： 标记 -清除算法 复制算法 标记-压缩算法，我们常用的垃圾回收器一般都采用分代收集算法。
标记 -清除算法，“标记-清除”（Mark-Sweep）算法，如它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象。
复制算法，“复制”（Copying）的收集算法，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。
标记-压缩算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存
分代收集算法，“分代收集”（Generational Collection）算法，把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法

74 调优命令有哪些？
Sun JDK监控和故障处理命令有jps jstat jmap jhat jstack jinfo
jps，JVM Process Status Tool,显示指定系统内所有的HotSpot虚拟机进程。
jstat，JVM statistics Monitoring是用于监视虚拟机运行时状态信息的命令，它可以显示出虚拟机进程中的类装载 内存 垃圾收集 JIT编译等运行数据。
jmap，JVM Memory Map命令用于生成heap dump文件
jhat，JVM Heap Analysis Tool命令是与jmap搭配使用，用来分析jmap生成的dump，jhat内置了一个微型的HTTP/HTML服务器，生成dump的分析结果后，可以在浏览器中查看
jstack，用于生成java虚拟机当前时刻的线程快照。
jinfo，JVM Conﬁguration info 这个命令作用是实时查看和调整虚拟机运行参数

75 调优工具
常用调优工具分为两类,jdk自带监控工具：jconsole和jvisualvm，第三方有：MAT(Memory AnalyzerTool) GChisto。
jconsole，Java Monitoring and Management Console是从java5开始，在JDK中自带的java监控和管理控制台，用于对JVM中内存， 线程和类等的监控
jvisualvm，jdk自带全能工具，可以分析内存快照 线程快照；监控内存变化 GC变化等。
MAT，Memory Analyzer Tool，一个基于Eclipse的内存分析工具，是一个快速 功能丰富的Javaheap分析工具，它可以帮助我们查找内存泄漏和减少内存消耗
GChisto，一款专业分析gc日志的工具

76 Minor GC与Full GC分别在什么时候发生？
新生代内存不够用时候发生MGC也叫YGC，JVM内存不够的时候发生FGC

77 你知道哪些JVM性能调优
设定堆内存大小
-Xmx：堆内存最大限制。
设定新生代大小。 新生代不宜太小，否则会有大量对象涌入老年代
-XX:NewSize：新生代大小
-XX:NewRatio 新生代和老生代占比
-XX:SurvivorRatio：伊甸园空间和幸存者空间的占比
设定垃圾回收器 年轻代用 -XX:+UseParNewGC 年老代用-XX:+UseConcMarkSweepGC

---------------------------------------------------------------------------------------------------------------
------------------------------------------jvm basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------k8s basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识

1 Kubernetes是Google开源的容器集群管理系统，其提供应用部署、维护、 扩展机制等功能，利用Kubernetes能方便地管理跨机器运行容器化的应用，是Docker分布式系统的解决方案。k8s里所有的资源都可以用yaml或Json定义。

2  Master
Master节点负责整个集群的控制和管理，所有的控制命令都是发给它，上面运行着一组关键进程：
kube-apiserver：提供了HTTP REST接口，是k8s所有资源增删改查等操作的唯一入口，也是集群控制的入口。
kube-controller-manager：所有资源的自动化控制中心。当集群状态与期望不同时，kcm会努力让集群恢复期望状态，比如：当一个pod死掉，kcm会努力新建一个pod来恢复对应replicas set期望的状态。
kube-scheduler：负责Pod的调度。
实际上，Master只是一个名义上的概念，三个关键的服务不一定需要运行在一个节点上。

3 API Server的原理
集群中的各个功能模块通过 apiserver将信息存储在Etcd，当需要修改这些信息的时候通过其REST接口来实现。

4 Controller Manager的原理
Replication Controller
Node Controller
ResourceQuota Controller
Namespace Controller
ServiceAccount Controller
Token Controller
Service Controller
Endpoint Controller等
这些Controller通过API Server实时监控各个资源的状态，当有资源因为故障导致状态变化，Controller就会尝试将系统由“现有状态”恢复到“期待状态”。

5 Scheduler的原理
作用是将apiserver或controller manager创建的Pod调度和绑定到具体的Node上，一旦绑定，就由Node上的kubelet接手Pod的接下来的生命周期管理。

6 Node
Node是工作负载节点，运行着Master分配的负载（Pod），但一个Node宕机时，其上的负载会被自动转移到其他Node上。其上运行的关键组件是：
kubelet：负责Pod的生命周期管理，同时与Master密切协作，实现集群管理的基本功能。
kube-proxy：实现Service的通信与负载均衡机制的重要组件，老版本主要通过设置iptables规则实现，新版1.9基于kube-proxy-lvs 实现。
Docker Engine：Docker引擎，负责Docker的生命周期管理。

7 kube-proxy的原理
每个Node上都运行着一个kube-proxy进程，它在本地建立一个SocketServer接收和转发请求，可以看作是Service的透明代理和负载均衡器，负载均衡策略模式是Round Robin。也可以设置会话保持，策略使用的是“ClientIP”，将同一个ClientIP的请求转发同一个Endpoint上。
Service的Cluster IP和NodePort等概念都是kube-proxy服务通过Iptables的NAT转换实现，Iptables机制针对的是kube-proxy监听的端口，所以每个Node上都要有kube-proxy。 

8 kubelet原理
每个Node都会启动一个kubelet，主要作用有：
（1）Node管理
注册节点信息；
通过cAdvisor监控容器和节点的资源；
定期向Master（实际上是apiserver）汇报本节点资源消耗情况
（2）Pod管理
所以非通过apiserver方式创建的Pod叫Static Pod，这里我们讨论的都是通过apiserver创建的普通Pod。kubelet通过apiserver监听etcd，所有针对Pod的操作都会被监听到，如果其中有涉及到本节点的Pod，则按照要求进行创建、修改、删除等操作。
（3）容器健康检查
kubelet通过两类探针检查容器的状态：
LivenessProbe：判断一个容器是否健康，如果不健康则会删除这个容器，并按照restartPolicy看是否重启这个容器。实现的方式有ExecAction（在容器内部执行一个命令）、TCPSocketAction（如果端口可以被访问，则健康）、HttpGetAction（如果返回200则健康）。
ReadinessProbe：用于判断容器是否启动完全。如果返回的是失败，则Endpoint Controller会将这个Pod的Endpoint从Service的Endpoint列表中删除。也就是，不会有请求转发给它。

9 Pod
Pod是k8s进行资源调度的最小单位，每个Pod中运行着一个或多个密切相关的业务容器，这些业务容器共享这个Pause容器的IP和Volume，我们以这个不易死亡的Pause容器作为Pod的根容器，以它的状态表示整个容器组的状态。一个Pod一旦被创建就会放到Etcd中存储，然后由Master调度到一个Node绑定，由这个Node上的Kubelet进行实例化。
每个Pod会被分配一个单独的Pod IP，Pod IP + ContainerPort 组成了一个Endpoint。

10 Service
K8s中一个Service相当于一个微服务的概念，一个Service对应后端多个Pod计算实例，使用LabelSelector将一类Pod都绑定到自己上来。一般还会需要一个Deployment或者RC来帮助这个Service来保证这个Service的服务能力和质量。

11 kube-proxy负载均衡
运行在每个Node上的kube-proxy其实就是一个智能的软件负载均衡器，它负载将发给Service的请求转发到后端对应的Pod，也就是说它负责会话保持和负责均衡。

12 Cluster IP
负载均衡的基础是负载均衡器要维护一个后端Endpoint列表，但是Pod的Endpoint会随着Pod的销毁和重建而改变，k8s使这个问题透明化。一旦Service被创建，就会立刻分配给它一个Cluster IP，在Service的整个生命周期内，这个Cluster IP不会改变。于是，服务发现的问题也解决了：只要用Service Name和Service Cluster IP做一个DNS域名映射就可以了。

13 DNS
从Kubernetes 1.3开始，DNS通过使用插件管理系统cluster add-on，成为了一个内建的自启动服务。Kubernetes DNS在Kubernetes集群上调度了一个DNS Pod和Service，并配置kubelet，使其告诉每个容器使用DNS Service的IP来解析DNS名称。
（1）Service
集群中定义的每个Service（包括DNS Service它自己）都被分配了一个DNS名称。默认的，Pod的DNS搜索列表中会包含Pod自己的命名空间和集群的默认域，下面我们用示例来解释以下。 假设有一个名为foo的Service，位于命名空间bar中。运行在bar命名空间中的Pod可以通过DNS查找foo关键字来查找到这个服务，而运行在命名空间quux中的Pod可以通过关键字foo.bar来查找到这个服务。
普通（非headless）的Service都被分配了一个DNS记录，该记录的名称格式为my-svc.my-namespace.svc.cluster.local，通过该记录可以解析出服务的集群IP。 Headless（没有集群IP）的Service也被分配了一个DNS记录，名称格式为my-svc.my-namespace.svc.cluster.local。与普通Service不同的是，它会解析出Service选择的Pod的IP列表。
（2）Pod
Pod也可以使用DNS服务。pod会被分配一个DNS记录，名称格式为pod-ip-address.my-namespace.pod.cluster.local。 比如，一个pod，它的IP地址为1.2.3.4，命名空间为default，DNS名称为cluster.local，那么它的记录就是：1-2-3-4.default.pod.cluster.local。 当pod被创建时，它的hostname设置在Pod的metadata.name中。
在v1.2版本中，用户可以指定一个Pod注解，pod.beta.kubernetes.io/hostname，用于指定Pod的hostname。这个Pod注解，一旦被指定，就将优先于Pod的名称，成为pod的hostname。比如，一个Pod，其注解为pod.beta.kubernetes.io/hostname: my-pod-name，那么该Pod的hostname会被设置为my-pod-name。 v1.2中还引入了一个beta特性，用户指定Pod注解，pod.beta.kubernetes.io/subdomain，来指定Pod的subdomain。比如，一个Pod，其hostname注解设置为“foo”，subdomain注解为“bar”，命名空间为“my-namespace”，那么它最终的FQDN就是“foo.bar.my-namespace.svc.cluster.local”。 在v1.3版本中，PodSpec有了hostname和subdomain字段，用于指定Pod的hostname和subdomain。它的优先级则高于上面提到的pod.beta.kubernetes.io/hostname和pod.beta.kubernetes.io/subdomain。

14 外部访问Service的问题
先明确这样几个IP：
Node IP：Node主机的IP，与它是否属于K8s无关。
Pod IP：是Dokcer Engine通过docker0网桥的IP地址段进行分配的，通常是一个虚拟的二层网络。k8s中一个Pod访问另一个Pod就是通过Pod IP。
Cluster IP：仅用于Service对象，属于k8s的内部IP，外界无法直接访问。
（1）NodePort
在Service的yaml中定义NodePort，k8s为集群中每个Node都增加对这个端口的监听，使用这种方式往往需要一个独立与k8s之外的负载均衡器作为流量的入口。
（2）使用External IP
运行Hello World应用程序的五个实例。
创建一个暴露外部IP地址的Service对象。
使用Service对象访问正在运行的应用程序。
使用deployment创建暴露的Service对象：

~ kubectl expose deployment hello-world --type=LoadBalancer --name=my-service
显示关于Service的信息：

~ kubectl get services my-service
 NAME         CLUSTER-IP     EXTERNAL-IP      PORT(S)    AGE
 my-service   10.3.245.137   104.198.205.71   8080/TCP   54s

~  kubectl describe services my-service
 Name:           my-service
 Namespace:      default
 Labels:         run=load-balancer-example
 Selector:       run=load-balancer-example
 Type:           LoadBalancer
 IP:             10.3.245.137
 LoadBalancer Ingress:   104.198.205.71
 Port:           <unset> 8080/TCP
 NodePort:       <unset> 32377/TCP
 Endpoints:      10.0.0.6:8080,10.0.1.6:8080,10.0.1.7:8080 + 2 more...
 Session Affinity:   None
 Events:

在此例子中，外部IP地址为104.198.205.71。还要注意Port的值。在这个例子中，端口是8080。在上面的输出中，您可以看到该服务有多个端点：10.0.0.6:8080,10.0.1.6:8080,10.0.1.7:8080 + 2 more…。这些是运行Hello World应用程序的pod的内部地址。
使用外部IP地址访问Hello World应用程序：
~  curl http://<external-ip>:<port>
 Hello Kubernetes!

删除服务
~ kubectl delete services my-service
~ kubectl delete deployment hello-world

15 Ingress
通常情况下，service和pod仅可在集群内部网络中通过IP地址访问。所有到达边界路由器的流量或被丢弃或被转发到其他地方。Ingress是授权入站连接到达集群服务的规则集合。你可以给Ingress配置提供外部可访问的URL、负载均衡、SSL、基于名称的虚拟主机等。用户通过POST Ingress资源到API server的方式来请求ingress。 Ingress controller负责实现Ingress，通常使用负载平衡器，它还可以配置边界路由和其他前端，这有助于以HA方式处理流量。
最简化的Ingress配置：
 apiVersion: extensions/v1beta1
 kind: Ingress
 metadata:
   name: test-ingress
 spec:
   rules:
   - http:
       paths:
       - path: /testpath
        backend:
           serviceName: test
           servicePort: 80
      - path: /bar
        backend:
          serviceName: s2
          servicePort: 80

1-4行：跟Kubernetes的其他配置一样，ingress的配置也需要apiVersion，kind和metadata字段。配置文件的详细说明请查看部署应用, 配置容器和 使用resources.
5-7行: Ingress spec 中包含配置一个loadbalancer或proxy server的所有信息。最重要的是，它包含了一个匹配所有入站请求的规则列表。目前ingress只支持http规则。
8-9行：每条http规则包含以下信息：一个host配置项（比如for.bar.com，在这个例子中默认是*），path列表（比如：/testpath），每个path都关联一个backend(比如test:80)。在loadbalancer将流量转发到backend之前，所有的入站请求都要先匹配host和path。
10-12行：backend是一个service:port的组合。Ingress的流量被转发到它所匹配的backend。

16 配置TLS证书
你可以通过指定包含TLS私钥和证书的secret来加密Ingress。 目前，Ingress仅支持单个TLS端口443，并假定TLS termination。 如果Ingress中的TLS配置部分指定了不同的主机，则它们将根据通过SNI TLS扩展指定的主机名（假如Ingress controller支持SNI）在多个相同端口上进行复用。 TLS secret中必须包含名为tls.crt和tls.key的密钥，这里面包含了用于TLS的证书和私钥，例如：
（1）创建Secret
apiVersion: v1
data:
  tls.crt: base64 encoded cert
  tls.key: base64 encoded key
kind: Secret
metadata:
  name: testsecret
  namespace: default
type: Opaque
（2）创建Ingress：
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: no-rules-map
spec:
  tls:
    - secretName: testsecret
  backend:
    serviceName: s1
    servicePort: 80

17 高可用
Kubernetes服务本身的稳定运行对集群管理至关重要，影响服务稳定的因素一般来说分为两种,一种是服务本身异常或者服务所在机器宕机，另一种是因为网络问题导致的服务不可用。本文将从存储层、管理层、接入层三个方面介绍高可用Kubernetes集群的原理。

18 Etcd高可用方案
Kubernetes的存储层使用的是Etcd。Etcd是CoreOS开源的一个高可用强一致性的分布式存储服务，Kubernetes使用Etcd作为数据存储后端，把需要记录的pod、rc、service等资源信息存储在Etcd中。
Etcd使用raft算法将一组主机组成集群，raft 集群中的每个节点都可以根据集群运行的情况在三种状态间切换：follower, candidate 与 leader。leader 和 follower 之间保持心跳。如果follower在一段时间内没有收到来自leader的心跳，就会转为candidate，发出新的选主请求。集群初始化的时候内部的节点都是follower节点，之后会有一个节点因为没有收到leader的心跳转为candidate节点，发起选主请求。当这个节点获得了大于一半节点的投票后会转为leader节点。当leader节点服务异常后，其中的某个follower节点因为没有收到leader的心跳转为candidate节点，发起选主请求。只要集群中剩余的正常节点数目大于集群内主机数目的一半，Etcd集群就可以正常对外提供服务。
当集群内部的网络出现故障集群可能会出现“脑裂”问题，这个时候集群会分为一大一小两个集群（奇数节点的集群），较小的集群会处于异常状态，较大的集群可以正常对外提供服务。

19 Master高可用方案
Master上有三个关键的服务：apiserver、controller-manager和scheduler，这三个不一定要运行在一台主机上。

20 controller-manager和scheduler的选举配置
Kubernetes的管理层服务包括kube-scheduler和kube-controller-manager。kube-scheduer和kube-controller-manager使用一主多从的高可用方案，在同一时刻只允许一个服务处以具体的任务。Kubernetes中实现了一套简单的选主逻辑，依赖Etcd实现scheduler和controller-manager的选主功能。
如果scheduler和controller-manager在启动的时候设置了leader-elect参数，它们在启动后会先尝试获取leader节点身份，只有在获取leader节点身份后才可以执行具体的业务逻辑。它们分别会在Etcd中创建kube-scheduler和kube-controller-manager的endpoint，endpoint的信息中记录了当前的leader节点信息，以及记录的上次更新时间。leader节点会定期更新endpoint的信息，维护自己的leader身份。每个从节点的服务都会定期检查endpoint的信息，如果endpoint的信息在时间范围内没有更新，它们会尝试更新自己为leader节点。

scheduler服务以及controller-manager服务之间不会进行通信，利用Etcd的强一致性，能够保证在分布式高并发情况下leader节点的全局唯一性。整体方案如下图所示：
当集群中的leader节点服务异常后，其它节点的服务会尝试更新自身为leader节点，当有多个节点同时更新endpoint时，由Etcd保证只有一个服务的更新请求能够成功。通过这种机制sheduler和controller-manager可以保证在leader节点宕机后其它的节点可以顺利选主，保证服务故障后快速恢复。当集群中的网络出现故障时对服务的选主影响不是很大，因为scheduler和controller-manager是依赖Etcd进行选主的，在网络故障后，可以和Etcd通信的主机依然可以按照之前的逻辑进行选主，就算集群被切分，Etcd也可以保证同一时刻只有一个节点的服务处于leader状态。

21 apiserver的高可用
Kubernetes的接入层服务主要是kube-apiserver。apiserver本身是无状态的服务，它的主要任务职责是把资源数据存储到Etcd中，后续具体的业务逻辑是由scheduler和controller-manager执行的。所以可以同时起多个apiserver服务，使用nginx把客户端的流量转发到不同的后端apiserver上实现接入层的高可用。具体的实现如下图所示：
接入层的高可用分为两个部分，一个部分是多活的apiserver服务，另一个部分是一主一备的nginx服务。

22 Keepalived简介
Keepalived软件起初是专为LVS负载均衡软件设计的，用来管理并监控LVS集群系统中各个服务节点的状态，后来又加入了可以实现高可用的VRRP功能。因此，Keepalived除了能够管理LVS软件外，还可以作为其他服务（例如：Nginx、Haproxy、MySQL等）的高可用解决方案软件。Keepalived软件主要是通过VRRP协议实现高可用功能的。VRRP是Virtual Router RedundancyProtocol(虚拟路由器冗余协议）的缩写，VRRP出现的目的就是为了解决静态路由单点故障问题的，它能够保证当个别节点宕机时，整个网络可以不间断地运行。所以，Keepalived 一方面具有配置管理LVS的功能，同时还具有对LVS下面节点进行健康检查的功能，另一方面也可实现系统网络服务的高可用功能。

23 故障切换转移原理
Keepalived高可用服务对之间的故障切换转移，是通过 VRRP (Virtual Router Redundancy Protocol ,虚拟路由器冗余协议）来实现的。在 Keepalived服务正常工作时，主 Master节点会不断地向备节点发送（多播的方式）心跳消息，用以告诉备Backup节点自己还活看，当主 Master节点发生故障时，就无法发送心跳消息，备节点也就因此无法继续检测到来自主 Master节点的心跳了，于是调用自身的接管程序，接管主Master节点的 IP资源及服务。而当主 Master节点恢复时，备Backup节点又会释放主节点故障时自身接管的IP资源及服务，恢复到原来的备用角色。

24 docker默认容器网络
在默认情况下会看到三个网络，它们是Docker Deamon进程创建的。它们实际上分别对应了Docker过去的三种『网络模式』，可以使用docker network ls来查看：
master@ubuntu:~$ sudo docker network ls
NETWORK ID          NAME                DRIVER              SCOPE
18d934794c74        bridge              bridge              local
f7a7b763f013        host                host                local
697354257ae3        none                null                local
这 3 个网络包含在 Docker 实现中。运行一个容器时，可以使用 the –net标志指定您希望在哪个网络上运行该容器。您仍然可以使用这 3 个网络。
bridge 网络表示所有 Docker 安装中都存在的 docker0 网络。除非使用 docker run –net=选项另行指定，否则 Docker 守护进程默认情况下会将容器连接到此网络。在主机上使用 ifconfig命令，可以看到此网桥是主机的网络堆栈的一部分。
none 网络在一个特定于容器的网络堆栈上添加了一个容器。该容器缺少网络接口。
host 网络在主机网络堆栈上添加一个容器。您可以发现，容器中的网络配置与主机相同。

25 跨主机通信的方案
和host共享network namespace
这种接入模式下，不会为容器创建网络协议栈，即容器没有独立于host的network namespace，但是容器的其他namespace（如IPC、PID、Mount等）还是和host的namespace独立的。容器中的进程处于host的网络环境中，与host共用L2-L4的网络资源。该方式的优点是，容器能够直接使用host的网络资源与外界进行通信，没有额外的开销（如NAT），缺点是网络的隔离性差，容器和host所使用的端口号经常会发生冲突。
和host共享物理网卡
2与1的区别在于，容器和host共享物理网卡，但容器拥有独立于host的network namespace，容器有自己的MAC地址、IP地址、端口号。这种接入方式主要使用SR-IOV技术，每个容器被分配一个VF，直接通过PCIe网卡与外界通信，优点是旁路了host kernel不占任何计算资源，而且IO速度较快，缺点是VF数量有限且对容器迁移的支持不足。

Behind the POD
这种方式是Google在Kubernetes中的设计中提出来的。Kubernetes中，POD是指一个可以被创建、销毁、调度、管理的最小的部署单元，一个POD有一个基础容器以及一个或一组应用容器，基础容器对应一个独立的network namespace并拥有一个其它POD可见的IP地址（以IP A.B.C.D指代），应用容器间则共享基础容器的network namespace（包括MAC、IP以及端口号等），还可以共享基础容器的其它的namespace（如IPC、PID、Mount等）。POD作为一个整体连接在host的vbridge/vswitch上，使用IP地址A.B.C.D与其它POD进行通信，不同host中的POD处于不同的subnet中，同一host中的不同POD处于同一subnet中。这种方式的优点是一些业务上密切相关的容器可以共享POD的全部资源（它们一般不会产生资源上的冲突），而这些容器间的通信高效便利。




二、ms相关
1 Kubernetes与Docker Swarm有何不同？
（1）swarm优点
1） 架构简单，部署运维成本较低
docker swarm 集群模式由于原生态集成到docker-engine中，所以首先学习成本低，对于使用docker-engine 1.12版本及以上可以平滑过渡，service服务可以满足动态增减容器个数，同时具备自身的负载均衡，swarm管理者多台设定保证了机器在出错后有一个良好的容灾机制
2） 启动速度快
swarm集群只会有两层交互，容器启动是毫秒级
（2）swarm劣势：
1） 无法提供更精细的管理
swarm API兼容docker API，所以使得swarm无法提供集群的更加精细的管理
2） 网络问题
在网络方面，默认docker容器是通过桥接与NAT和主机外网络通信，这样就出现2个问题，一个是因为是NAT，外部主机无法主动访问到容器内（除了端口映射），另外默认桥接IP是一样的，这样会出现不同主机的容器有相同的IP的情况。这样两容器更加不能通信。同时网络性能方面，有人测试经过桥接的网络性能只有主机网络性能的70%。当然以上问题可以通过其他工具解决，比如用 Flannel 或者 OVS网桥
3） 容器可靠性
在容器可靠性方面，相较于Kubernetes的Replication Controllers可以监控并维持容器的生命，swarm在启动时刻可以控制容器启动，在启动后，如果容器或者容器主机崩溃，swarm没有机制来保证容器的运行。
（3）kubernetes优点：
1） 管理更趋于完善稳定
kubernetes 集群管理更趋于完善稳定，同时pod功能上比swarm的service更加强大
2） 健康机制完善
Replication Controllers可以监控并维持容器的生命
3） 轻松应对复杂的网络环境
kubernetes默认使用Flannel作为overlay网络。
Flannel是CoreOS 团队针对 Kubernetes 设计的一个覆盖网络（OverlayNetwork）工具，其目的在于帮助每一个使用 Kuberentes 的CoreOS 主机拥有一个完整的子网。
（4）kubernetes劣势：
1） 配置、搭建稍显复杂，学习成本高
由于配置复杂，学习成本相对较高，对应运维的成本相对高点
2） 启动速度稍逊
kubernetes会有五层交互，启动是秒级，启动速度慢于swarm
通过以上介绍，相信大家应该对docker容器集群管理工具的选择有了一个基本的认识，不管怎么选择，最终我们的目的都是为了减少人为干预，更智能的生产环境运维，所以应该根据实际情况斟酌选择。

2 什么是Kubernetes？
Kubernetes是一个开源容器管理工具，它负责容器部署，容器的缩放和除垢以及负载平衡的职责。作为Google的创意，它提供了出色的社区，并且与所有云提供商都精采合作。
因此，我们可以说Kubernetes不是 一个容器化平台，而是一个多容器管理解决方案。

3 Kubernetes与Docker有何关系？
众所周知，Docker提供了容器的生命周期管理，而Docker映像构建了运行时容器。但是，由于这些容器必须进行通信，因此使用了Kubernetes。因此，Docker构建了容器，这些容器通过Kubernetes相互通信。因此，可以使用Kubernetes手动链接和协调在多个主机上运行的容器。

4 在主机和容器上部署应用程序有什么区别？
在主机上部署应用程序，需要和其他的应用程序分享主机环境，需要有操作系统，操作系统将具有内核，内核会在应用程序所需的操作系统上安装各种库，这些库是所有应用程序共享的。
在容器上部署应用，因为Linux容器技术共享内核，因此只有内核是所有应用程序共同的东西，容器化使得应用程序之间是相互隔离的，容器中应用程序的资源文件不会被其他应用程序侵占。

5 什么是容器编排？
应用一般由单独容器化的组件（通常称为微服务）组成，且必须按顺序在网络级别进行组织，以使其能够按照计划运行。以这种方法对多个容器进行组织的流程即称为容器编排。。

6 容器编排有什么需要？
假设您有5-6个微服务用于执行各种任务的单个应用程序，并且所有这些微服务都放在容器中。现在，要确保这些容器彼此通信，我们需要进行容器编排。
如上图所示，不使用容器编排也存在许多挑战。因此，为了克服这些挑战，进行了容器编排。

7 Kubernetes有什么特点？
1） 应用的定义Kubernetes采用Pod作为应用调度的最小单元。要理解Kubernetes就需要先理解Pod的概念。Pod是一组位于同一节点的容器的结合。
如果把Docker容器比喻成葡萄的化，Docker引擎管理的是一颗颗晶莹剔透的葡萄，而Kubernetes管理的是一串串的葡萄。每个Pod就相当于一串葡萄，
上面的每颗葡萄都连接在同一段的葡萄枝丫（相同的网络IP地址和Volune卷）上，而每段枝丫都生长在同一棵葡萄树（Node服务器）上。
通过Pod的统一管理，Kubernetes抽象了容器的细节，简化了编排的管理。
2） 应用的配置Kubernetes的应用统一通过YAML文件进行各资源状态的描述，可以便利地进行状态的更新、回滚和弹性伸缩。
3） 高可用Kubernetes通过etcd的集群，实现配置高可用管理；多个master节点，实现集群管理的高可用；应用的跨节点多副本负载均衡，实现业务的高可用。
4） 健康检查Kubernetes通过readiness和liveness两层检查，确认是否对外提供网络服务和是否重启应用容器。
5） 存储Kubernetes提供了存储的两级抽象：一级实现后台存储的供应抽象（如NFS，AWS EBS，Ceph等）；一级是前台存储资源需求的抽象。方便将存储的系统配置和应用管理隔离开，方便开发和运维团队的分工合作。某厂这份K8S+Linux内容火了，完整版
6） 网络Kubernetes采用扁平的网络架构实现Pod之间的通信，可以选择Overlay的大二层实现，也可以选择基于三层路由的网络框架，非常灵活。
同时在内部网络互通的基础上，提供了基于Service和Ingress的服务发现功能，可以对外提供网络服务。
7. 监控Kubernetes作为主流的容器编排手段，可以很好地和业界主流的监控手段配合，如何ELK（ElasticSearch、Logstash、Kibana）、
EFK（ElasticSearch、Fluentd、Kibana）、Prometheus、Grafana等。

8 Kubernetes如何简化容器化部署？
由于典型的应用程序具有跨多个主机运行的容器集群，因此所有这些容器都需要相互通信。因此，要做到这一点，您需要一些可以平衡负载，
缩放和监视容器的东西。由于Kubernetes与云无关，并且可以在任何公共/私有提供商上运行，因此必须选择简化容器化部署。

9 您对Kubernetes中的集群了解多少？
Kubernetes的基本原理是，我们可以强制执行所需的状态管理，这意味着我们可以提供特定配置的集群服务，而由集群服务决定是否在基础架构中运行该配置。
因此，如您在上图中所看到的，部署文件将具有需要馈送到集群服务中的所有配置。现在，部署文件将被馈送到API，然后由集群服务来决定如何在环境中调度这些Pod，并确保运行正确数量的Pod。
因此，位于服务，工作节点和节点运行的Kubelet流程前面的API共同构成了Kubernetes集群。

10 什么是Google Container Engine？
Google Container Engine（GKE）是一个用于Docker容器和集群的开源管理平台。这种基于Kubernetes的引擎仅支持在Google的公共云服务中运行的那些集群。

11 什么是堆？
Heapster是在每个节点上运行的Kubelet提供的数据的群集范围内的聚合器。该容器管理工具在Kubernetes集群上本身受支持，并且像集群中的任何其他集群一样作为Pod运行。因此，它基本上会发现群集中的所有节点，并通过计算机上的Kubernetes代理从群集中的Kubernetes节点查询使用情况信息。

12 什么是Minikube？
Minikube是一种可以轻松在本地运行Kubernetes的工具。这将在虚拟机中运行单节点Kubernetes集群。

13 什么是 Kubectl？
Kubectl是一个平台，您可以使用该平台将命令传递给集群。因此，它基本上提供了CLI以各种方式创建和管理Kubernetes组件，从而针对Kubernetes集群运行命令。

14 什么是Kubelet？
这是一个代理服务，它在每个节点上运行，并使从服务器能够与主服务器通信。因此，Kubelet致力于PodSpec中提供给它的容器的描述，并确保PodSpec中描述的容器是正常运行的。

15 您对Kubernetes中的节点了解什么？
Kubernetes 通过将容器放入在节点（Node）上运行的 Pod 中来执行你的工作负载。 节点可以是一个虚拟机或者物理机器，取决于所在的集群配置。
每个节点包含运行 Pods 所需的服务； 这些节点由 控制面 负责管理。通常集群中会有若干个节点；而在一个学习用或者资源受限的环境中，
你的集群中也可能 只有一个节点。节点上的组件包括 kubelet、 容器运行时以及 kube-proxy。

16 Kubernetes体系结构有哪些不同的组成部分？
Kubernetes架构主要包含两个组件-主节点和工作节点。如下图所示，主节点和工作节点中有许多内置组件。
主节点具有kube-controller-manager，kube-apiserver，kube-scheduler等。而工作程序节点在每个节点上都运行kubelet和kube-proxy。

17 您对Kube-proxy了解什么？
Kube-proxy可以在每个节点上运行，并且可以跨后端网络服务执行简单的TCP / UDP数据包转发。
因此，基本上，它是一个网络代理，可反映每个节点上Kubernetes API中配置的服务。因此，可与Docker链接的兼容环境变量提供了由代理打开的群集IP和端口。

18 您能否简要介绍一下Kubernetes中主节点的工作？
Kubernetes主节点控制节点，并且在节点内部存在容器。现在，这些单独的容器包含在Pod内，每个Pod内，您可以根据配置和要求拥有各种数量的容器。因此，如果必须部署Pod，则可以使用用户界面或命令行界面来部署它们。然后，在节点上调度这些Pod，并根据资源需求将Pod分配给这些节点。kube-apiserver确保在Kubernetes节点和主组件之间建立了通信。

19 kube-apiserver和kube-scheduler的作用是什么？
kube – apiserver遵循横向扩展架构，并且是主节点控制面板的前端。这将公开Kubernetes主节点组件的所有API，并负责在Kubernetes节点和Kubernetes主组件之间建立通信。
kube调度程序负责在工作节点上分配和管理工作负载。因此，它根据资源需求选择最合适的节点来运行计划外的Pod，并跟踪资源利用率。它可以确保未在已满的节点上调度工作负载。

20 您能简要介绍一下Kubernetes控制器管理器吗？
多个控制器进程在主节点上运行，但被编译在一起以作为单个进程（即Kubernetes Controller Manager）运行。因此，Controller Manager是一个守护程序，它嵌入控制器并执行名称空间创建和垃圾回收。它负责并与API服务器通信以管理端点。
因此，在主节点上运行的不同类型的控制器管理器为：

21 什么是ETCD？
Etcd用Go编程语言编写，并且是用于在分布式工作之间进行协调的分布式键值存储。因此，Etcd存储Kubernetes集群的配置数据，该数据表示集群在任何给定时间点的状态。

22 Kubernetes中有哪些不同类型的服务？ 
ClusterIP：默认类型，自动分配一个仅Cluster内部可访问的虚拟IP
NodePort：在ClusterIP基础上为Service在每台机器上绑定一个端口，这样就可以通过:来访问该服务
LoadBalance：在NodePort的基础上，借助cloud provider创建一个外部负载均衡器，并将请求转发到:
ExternalName:把集群外部的服务引入到集群内部来，在集群内部直接使用，没有任何类型代理被创建，这只有Kubernetes1.7以上版本的kube-dns才支持

23 您对Kubernetes中的负载均衡器了解什么？
负载平衡器是公开服务的最常见和标准的方式之一。根据工作环境使用两种类型的负载均衡器，即内部负载均衡器或外部负载均衡器。
内部负载平衡器会自动平衡负载并为Pod分配所需的配置，而外部负载平衡器会将流量从外部负载定向到后端Pod。

24 什么是Ingress网络？它如何工作？
入口网络是充当Kubernetes集群入口点的规则的集合。这允许入站连接，可以将其配置为通过可访问的URL，负载平衡流量或通过提供基于名称的虚拟主机在外部提供服务。
因此，Ingress是一个API对象，通常通过HTTP管理对集群中服务的外部访问，这是公开服务的最强大方法。
现在，让我通过一个示例向您解释Ingress网络的工作原理。
有2个节点具有带有Linux网桥的pod和根网络名称空间。除此之外，还向根网络添加了一个名为flannel0（网络插件）的新虚拟以太网设备。
现在，假设我们希望数据包从pod1到pod4 请参考下图。
图11：入口网络的工作-Kubernetes面试问题
因此，数据包在eth0离开pod1的网络，并在veth0进入根网络。
然后将其传递给cbr0，后者发出ARP请求以查找目标，并且发现该节点上没有人具有目标IP地址。
因此，网桥将数据包发送到flannel0，因为节点的路由表已配置了flannel0 
现在，法兰绒守护程序与Kubernetes的API服务器进行对话，以了解所有Pod IP及其各自的节点，以创建Pod IP到节点IP的映射。
网络插件将该数据包包装在带有额外报头的UDP数据包中，该报头将源IP和目标IP更改为它们各自的节点，并通过eth0发送此数据包。
现在，由于路由表已经知道如何在节点之间路由流量，因此它将数据包发送到目标节点2 
数据包到达节点2的eth0，然后返回flannel0进行解封装，然后将其发送回根网络名称空间。
再次，将数据包转发到Linux网桥，以发出ARP请求以找出属于veth1的IP。
数据包最终穿过根网络并到达目标Pod4 

25 您对云控制器经理了解什么？
Cloud Controller Manager负责持久性存储，网络路由，从核心Kubernetes特定代码中提取特定于云的代码以及管理与基础云服务的通信。
根据您所运行的云平台，它可能会分成几个不同的容器，然后它使云供应商和Kubernetes代码得以开发而没有任何相互依赖关系。
因此，云供应商可以在运行Kubernetes时开发他们的代码并与Kubernetes云控制器管理器连接。

26 什么是容器资源监视？
对于用户而言，了解所有不同抽象层的应用程序性能和资源利用率非常重要，Kubernetes通过在不同级别（例如容器，pod，服务和整个集群）创建抽象，
从而对集群的管理进行了分解。现在，可以监视每个级别，这不过是容器资源监视而已。

27 副本集和复制控制器之间有什么区别？
副本集和复制控制器执行几乎相同的操作。它们两者都确保在任何给定时间都运行指定数量的Pod副本。不同之处在于使用选择器来复制容器。副本集使用基于集合的选择器，而复制控制器使用基于权益的选择器。
基于股权的选择器： 这种类型的选择器允许按标签键和值进行过滤。因此，以通俗易懂的术语来说，基于权益的选择器将仅查找具有与标签词组完全相同的词组的豆荚。
示例：假设您的标签键为app = nginx，那么使用此选择器，您只能查找标签为app等于nginx的吊舱。
基于选择器的选择器： 这种类型的选择器允许根据一组值过滤键。因此，换句话说，基于选择器的选择器将查找其标签已在集合中提及的Pod。
示例：说您的标签密钥说（nginx，NPS，Apache）中为app。然后，使用此选择器，如果您的应用等于nginx，NPS或Apache中的任何一个，则选择器会将其视为真实结果。

28 什么是无头服务？
无头服务类似于“普通”服务，但没有群集IP。此服务使您可以直接到达吊舱，而无需通过代理进行访问。

29 使用Kubernetes时可以采取的最佳安全措施是什么？
1） 将环境升级到最新版本
2） 开启基于角色的权限控制（RBAC）
3） 使用命名空间来建立安全的边界.png
4） 隔离敏感的工作负载
5） 安全云元数据访问
6） 创建并定义集群网络策略
7） 运行集群范围内的Pod安全策略
8） 强化节点安全
9） 开启审核日志

30 什么是联合集群？
借助联合集群，可以将多个Kubernetes集群作为一个集群进行管理。因此，您可以在一个数据中心/云中创建多个Kubernetes集群，并使用联合在一个地方控制/管理所有集群。

31、假设一家基于整体架构的公司处理许多产品。现在，随着公司在当今规模化行业中的发展，其整体架构开始引起问题。您如何看待公司从单一服务转向微服务并部署其服务容器？
由于该公司的目标是从单一应用程序转变为微服务，因此它们最终可以一步一步地并行构建，而只需在后台切换配置即可。然后，他们可以将每个内置微服务放在Kubernetes平台上。因此，他们可以从迁移服务一次或两次并监视它们以确保一切运行稳定开始。一旦他们感觉一切顺利，就可以将应用程序的其余部分迁移到其Kubernetes集群中。

32、考虑一家拥有非常分散的系统，拥有大量数据中心，虚拟机以及许多从事各种任务的员工的跨国公司。您认为这样 的公司如何与Kubernetes一致地管理所有任务？
众所周知，IT部门启动了数千个容器，任务在分布式系统中的多个节点上运行。
在这种情况下，公司可以使用能够为基于云的应用程序提供敏捷性，横向扩展功能和DevOps实践的功能。
因此，该公司可以使用Kubernetes定制其调度架构并支持多种容器格式。这使得容器任务之间的亲和力成为可能，它通过对各种容器联网解决方案和容器存储的广泛支持而提高了效率。

33、考虑一种情况，公司希望通过保持最低成本来提高效率和技术运营速度。您如何看待公司将如何实现这一目标？
该公司可以通过构建CI / CD管道来实现DevOps方法，但是此处可能出现的一个问题是，配置可能需要花费一些时间才能启动并运行。因此，在实施CI / CD管道之后，公司的下一步应该是在云环境中工作。一旦他们开始在云环境中工作，他们就可以在集群上调度容器，并可以在Kubernetes的帮助下进行编排。这种方法将帮助公司减少部署时间，并在各种环境中更快地完成部署。

34、假设一家公司想要修改其部署方法，并希望构建一个可扩展性和响应性更高的平台。您如何看待这家公司能够实现这一目标以满足他们的客户？
为了给数百万客户提供他们期望的数字体验，该公司需要一个可扩展且响应迅速的平台，以便他们可以快速将数据获取到客户网站。现在，要做到这一点，公司应该从其私有数据中心（如果他们使用的是任何数据中心）迁移到任何云环境（例如AWS）。不仅如此，他们还应该实现微服务架构，以便他们可以开始使用Docker容器。一旦他们准备好了基础框架，便可以开始使用可用的最佳编排平台，即Kubernetes。这将使团队能够自主构建应用程序并非常快速地交付它们。

35、考虑一家拥有非常分散的系统的跨国公司，希望解决整体代码库问题。您认为公司如何解决他们的问题？
好了，要解决该问题，他们可以将其整体代码库转移到微服务设计中，然后将每个微服务都视为一个容器。因此，所有这些容器都可以在Kubernetes的帮助下进行部署和编排。

36、我们所有人都知道从单服务到微服务的转变从开发方面解决了问题，但在部署方面却增加了问题。公司如何解决部署方面的问题？
该团队可以尝试使用容器编排平台（例如Kubernetes）并在数据中心中运行它。因此，借助此工具，该公司可以生成模板化的应用程序，在五分钟内对其进行部署，并在此时将实际实例包含在登台环境中。这种Kubernetes项目将具有数十个并行运行的微服务，以提高生产率，即使节点发生故障，也可以立即对其进行重新调度，而不会影响性能。

37、假设一家公司希望通过采用新技术来优化其工作负载的分配。公司如何有效地实现这种资源分配？
解决这个问题的方法莫过于Kubernetes。Kubernetes确保有效地优化资源，并且仅使用特定应用程序所需的那些资源。因此，通过使用最佳的容器编排工具，公司可以有效地实现资源分配。

38、考虑一家拼车公司希望通过同时扩展其平台来增加服务器数量。您认为公司将如何处理服务器及其安装？
公司可以采用集装箱化的概念。一旦将所有应用程序部署到容器中，他们就可以使用Kubernetes进行编排，并使用Prometheus等容器监视工具来监视容器中的动作。因此，使用这样的容器，可以为它们提供更好的数据中心容量规划，因为由于服务和运行的硬件之间的这种抽象，它们现在将具有更少的约束。

39、考虑一个公司要向具有各种环境的客户提供所有必需的分发产品的方案。您如何看待他们如何动态地实现这一关键目标？
该公司可以使用Docker环境，组成一个跨部门团队，以使用Kubernetes构建Web应用程序。这种框架将帮助公司实现在最短时间内将所需物品投入生产的目标。因此，通过运行这种机器，公司可以向所有具有各种环境的客户提供帮助。

40、假设一家公司希望在从裸机到公共云的不同云基础架构上运行各种工作负载。在存在不同接口的情况下，公司将如何实现这一目标？
该公司可以将其基础架构分解为微服务，然后采用Kubernetes。这将使公司在不同的云基础架构上运行各种工作负载。

---------------------------------------------------------------------------------------------------------------
------------------------------------------k8s basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------kafka basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识

1为什么需要消息系统
（1）.解耦：
　　允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。
（2）.冗余：
　　消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的"插入-获取-删除"范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。
（3）.扩展性：
　　因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。
（4）.灵活性 & 峰值处理能力：
　　在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。
（5）.可恢复性：
　　系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。
（6）.顺序保证：
　　在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。（Kafka 保证一个 Partition 内的消息的有序性）
（7）.缓冲：
　　有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。
（8）.异步通信：
　　很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。

2 Kafka是一种分布式的，基于发布/订阅的消息系统。
Kafka是最初由Linkedin公司开发，是一个分布式、支持分区的（partition）、多副本的（replica），基于zookeeper协调的分布式消息系统，它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：比如基于hadoop的批处理系统、低延迟的实时系统、storm/Spark流式处理引擎，web/nginx日志、访问日志，消息服务等等，用scala语言编写，Linkedin于2010年贡献给了Apache基金会并成为顶级开源 项目。

特点：
- 高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition, consumer group 对partition进行consume操作。
- 可扩展性：kafka集群支持热扩展
- 持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失
- 容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）
- 高并发：支持数千个客户端同时读写


3 常用Message Queue对比
RabbitMQ
RabbitMQ是使用Erlang编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP, STOMP，也正因如此，它非常重量级，更适合于企业级的开发。同时实现了Broker构架，这意味着消息在发送给客户端时先在中心队列排队。对路由，负载均衡或者数据持久化都有很好的支持。

Redis
Redis是一个基于Key-Value对的NoSQL数据库，开发维护很活跃。虽然它是一个Key-Value数据库存储系统，但它本身支持MQ功能，所以完全可以当做一个轻量级的队列服务来使用。对于RabbitMQ和Redis的入队和出队操作，各执行100万次，每10万次记录一次执行时间。测试数据分为128Bytes、512Bytes、1K和10K四个不同大小的数据。实验表明：入队时，当数据比较小时Redis的性能要高于RabbitMQ，而如果数据大小超过了10K，Redis则慢的无法忍受；出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ的出队性能则远低于Redis。

ZeroMQ
ZeroMQ号称最快的消息队列系统，尤其针对大吞吐量的需求场景。ZMQ能够实现RabbitMQ不擅长的高级/复杂的队列，但是开发人员需要自己组合多种技术框架，技术上的复杂度是对这MQ能够应用成功的挑战。ZeroMQ具有一个独特的非中间件的模式，你不需要安装和运行一个消息服务器或中间件，因为你的应用程序将扮演了这个服务角色。你只需要简单的引用ZeroMQ程序库，可以使用NuGet安装，然后你就可以愉快的在应用程序之间发送消息了。但是ZeroMQ仅提供非持久性的队列，也就是说如果宕机，数据将会丢失。其中，Twitter的Storm 0.9.0以前的版本中默认使用ZeroMQ作为数据流的传输（Storm从0.9版本开始同时支持ZeroMQ和Netty作为传输模块）。

ActiveMQ
ActiveMQ是Apache下的一个子项目。 类似于ZeroMQ，它能够以代理人和点对点的技术实现队列。同时类似于RabbitMQ，它少量代码就可以高效地实现高级应用场景。

Kafka/Jafka
Kafka是Apache下的一个子项目，是一个高性能跨语言分布式发布/订阅消息队列系统，而Jafka是在Kafka之上孵化而来的，即Kafka的一个升级版。具有以下特性：快速持久化，可以在O(1)的系统开销下进行消息持久化；高吞吐，在一台普通的服务器上既可以达到10W/s的吞吐速率；完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡；支持Hadoop数据并行加载，对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka通过Hadoop的并行加载机制来统一了在线和离线的消息处理。Apache Kafka相对于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统。

Kafka的吞吐量高达17.3w/s,不愧是高吞吐量消息中间件的行业老大。这主要取决于它的队列模式保证了写磁盘的过程是线性IO。此时broker磁盘IO已达瓶颈
RocketMQ也表现不俗，吞吐量在11.6w/s磁盘IO %util已接近100%。
RabbitMQ的吞吐量5.95w/s，CPU资源消耗较高。它支持AMQP协议，实现非常重量级，为了保证消息的可靠性在吞吐量上做了取舍。我们还做了RabbitMQ在消息持久化场景下的性能测试，吞吐量在2.6w/s左右。

4 Kafka过程：
1).Producer根据指定的partition方法（round-robin、hash等），将消息发布到指定topic的partition里面
2).kafka集群接收到Producer发过来的消息后，将其持久化到硬盘，并保留消息指定时长（可配置），而不关注消息是否被消费。
3).Consumer从kafka集群pull数据，并控制获取消息的offset
 
5 Kafka原理：
生产者使用自己的序列化方法对消息内容进行编码。然后向broker发起消息。为了提高效率，一个发布请求中可以包含一组消息。
消费者订阅话题，并为话题创建一个或多个消息流。发布到该话题的消息被均衡的分发到这些流中。
每个消息流为不断产生的消息提供了迭代接口。
消费者迭代流中每一条消息，并处理消息的有效负载。
迭代器不会停止。如果当前没有消息，迭代器将阻塞直至有新的消息发布到该话题

6 zookeeper在kafka中的作用
1)Broker注册
Broker在zookeeper中保存为一个临时节点，节点的路径是/brokers/ids/[brokerid],每个节点会保存对应broker的IP以及端口等信息.
2)Topic注册
在kafka中,一个topic会被分成多个区并被分到多个broker上，分区的信息以及broker的分布情况都保存在zookeeper中，根节点路径为/brokers/topics,每个topic都会在topics下建立独立的子节点，每个topic节点下都会包含分区以及broker的对应信息，例如下图中的状态
3)生产者负载均衡
当Broker启动时，会注册该Broker的信息，以及可订阅的topic信息。生产者通过注册在Broker以及Topic上的watcher动态的感知Broker以及Topic的分区情况，从而将Topic的分区动态的分配到broker上.
4)消费者
kafka有消费者分组的概念，每个分组中可以包含多个消费者，每条消息只会发给分组中的一个消费者，且每个分组之间是相互独立互不影响的。
5)消费者与分区的对应关系
对于每个消费者分组，kafka都会为其分配一个全局唯一的Group ID,分组内的所有消费者会共享该ID,kafka还会为每个消费者分配一个consumer ID,通常采用hostname:uuid的形式。在kafka的设计中规定，对于topic的每个分区，最多只能被一个消费者进行消费，也就是消费者与分区的关系是一对多的关系。消费者与分区的关系也被存储在zookeeper中节点的路劲为 /consumers/[group_id]/owners/[topic]/[broker_id-partition_id],该节点的内容就是消费者的Consumer ID
6)消费者负载均衡
消费者服务启动时，会创建一个属于消费者节点的临时节点，节点的路径为 /consumers/[group_id]/ids/[consumer_id],该节点的内容是该消费者订阅的Topic信息。每个消费者会对/consumers/[group_id]/ids节点注册Watcher监听器，一旦消费者的数量增加或减少就会触发消费者的负载均衡。消费者还会对/brokers/ids/[brokerid]节点进行监听，如果发现服务器的Broker服务器列表发生变化，也会进行消费者的负载均衡
7)消费者的offset
在kafka的消费者API分为两种(1)High Level Api：由zookeeper维护消费者的offset (2) Low Level API,自己的代码实现对offset的维护。由于自己维护offset往往比较复杂，所以多数情况下都是使用High Level的APIoffset在zookeeper中的节点路径为/consumers/[group_id]/offsets/[topic]/[broker_id-part_id],该节点的值就是对应的offset
8）需要要消费者知道现在那些生产者（对于消费者而言，kafka就是生产者）是可用的。
如果没了zookeeper消费者如何知道呢？
如果每次消费者在消费之前都去尝试连接生产者测试下是否连接成功，效率呢？
所以kafka需要zk，在kafka的设计中就依赖了zk了。


7  Kakfa Broker Leader的选举 
Kakfa Broker集群受Zookeeper管理。所有的Kafka Broker节点一起去Zookeeper上注册一个临时节点，因为只有一个Kafka Broker会注册成功，其他的都会失败，所以这个成功在Zookeeper上注册临时节点的这个Kafka Broker会成为Kafka Broker Controller，其他的Kafka broker叫Kafka Broker follower。。这个Controller会监听其他的Kafka Broker的所有信息。

如果这个kafka broker controller宕机了，在zookeeper上面的那个临时节点就会消失，此时所有的kafka broker又会一起去Zookeeper上注册一个临时节点，因为只有一个Kafka Broker会注册成功，其他的都会失败，所以这个成功在Zookeeper上注册临时节点的这个Kafka Broker会成为Kafka Broker Controller，其他的Kafka broker叫Kafka Broker follower。

例如：一旦有一个broker宕机了，这个kafka broker controller会读取该宕机broker上所有的partition在zookeeper上的状态，并选取ISR列表中的一个replica作为partition leader（如果ISR列表中的replica全挂，选一个幸存的replica作为leader;如果该partition的所有的replica都宕机了，则将新的leader设置为-1，等待恢复，等待ISR中的任一个Replica“活”过来，并且选它作为Leader；或选择第一个“活”过来的Replica（不一定是ISR中的）作为Leader），这个broker宕机的事情，kafka controller也会通知zookeeper，zookeeper就会通知其他的kafka broker。

8 consumer group消费
当启动一个consumer group去消费一个topic的时候，无论topic里面有多个少个partition，无论我们consumer group里面配置了多少个consumer thread，这个consumer group下面
的所有consumer thread一定会消费全部的partition；即便这个consumer group下只有一个consumer thread，那么这个consumer thread也会去消费所有的partition。因此，最优
的设计就是，consumer group下的consumer thread的数量等于partition数量，这样效率是最高的。
同一partition的一条message只能被同一个Consumer Group内的一个Consumer消费。不能够一个consumer group的多个consumer同时消费一个partition。多个Consumer Group下的consumer可以消费同一条message.
一般来说
   （1）一个Topic的Partition数量大于等于Broker的数量，可以提高吞吐率。
   （2）同一个Partition的Replica尽量分散到不同的机器，高可用。
   
9 Partition Replica
每个partition可以在其他的kafka broker节点上存副本，以便某个kafka broker节点宕机不会影响这个kafka集群。存replica副本的方式是按照kafka broker的顺序存。
例如有5个kafka broker节点，某个topic有3个partition，每个partition存2个副本，那么partition1存broker1,broker2，partition2存broker2,broker3。。。以此类推
（replica副本数目不能大于kafkabroker节点的数目，否则报错。这里的replica数其实就是partition的副本总数，其中包括一个leader，其他的就是copy副本）。
如果某个broker宕机，其实整个kafka内数据依然是完整的。但是，replica副本数越高，系统虽然越稳定，但是回来带资源和性能上的下降；replica副本少的话，也会造成系统丢数据的风险。
  （1）怎样传送消息：producer先把message发送到partition leader，再由leader发送给其他partition follower。
  （2）在向Producer发送ACK响应消息前需要保证有多少个Replica已经收到该消息：根据ack配的个数而定 
  （3）怎样处理某个Replica不工作的情况：如果这个部工作的partition replica不在ack列表中，就是producer在发送消息到partition leader上，partition leader向partition follower发送message没有响应而已，这个不会影响整个系统，也不会有什么问题。
  （4）怎样处理Failed Replica恢复回来的情况：如果这个partition replica之前不在ack列表中，那么启动后重新受Zookeeper管理即可，之后producer发送message的时候，partition leader会继续发送message到这个partition follower上。如果这个partition replica之前在ack列表中，此时重启后，需要把这个partition replica再手动加到ack列表中。（ack列表是手动添加的，出现某个部工作的partition replica的时候自动从ack列表中移除的）
 
  
10 Partition leader与follower
partition也有leader和follower之分。leader是主partition，producer写kafka的时候先写partition leader，再由partition leader push给其他的partition follower。
partition leader与follower的信息受Zookeeper控制，一旦partition leader所在的broker节点宕机，zookeeper会冲其他的broker的partition follower上选择follower变为parition leader。
- Topic分配partition和partition replica的算法：
（1）将Broker（size=n）和待分配的Partition排序。
（2）将第i个Partition分配到第（i%n）个Broker上。
（3）将第i个Partition的第j个Replica分配到第（(i + j) % n）个Broker上

11 消息投递可靠性三种模式
第一种是啥都不管，发送出去就当作成功，这种情况当然不能保证消息成功投递到broker；
第二种是Master-Slave模型，只有当Master和所有Slave都接收到消息时，才算投递成功，这种模型提供了最高的投递可靠性，但是损伤了性能；
第三种模型，即只要Master确认收到消息就算投递成功；实际使用时，根据应用特性选择，绝大多数情况下都会中和可靠性和性能选择第三种模型
  
11 消息在broker上的可靠性
因为消息会持久化到磁盘上，所以如果正常stop一个broker，其上的数据不会丢失；但是如果不正常stop，可能会使存在页面缓存来不及写入磁盘的消息丢失，这可以通过配置flush页面缓存的周期、阈值缓解，但是同样会频繁的写磁盘会影响性能，又是一个选择题，根据实际情况配置。

12 message持久化
Kafka中会把消息持久化到本地文件系统中，并且保持o(1)极高的效率。我们众所周知IO读取是非常耗资源的性能也是最慢的，这就是为了数据库的瓶颈经常在IO上，需要换SSD硬盘的原因。但是Kafka作为吞吐量极高的MQ，却可以非常高效的message持久化到文件。这是因为Kafka是顺序写入o（1）的时间复杂度，速度非常快。也是高吞吐量的原因。
由于message的写入持久化是顺序写入的，因此message在被消费的时候也是按顺序被消费的，保证partition的message是顺序消费的。一般的机器,单机每秒100k条数据。

13 Kafka高吞吐量 
Kafka的高吞吐量体现在读写上，分布式并发的读和写都非常快，写的性能体现在以o(1)的时间复杂度进行顺序写入。读的性能体现在以o(1)的时间复杂度进行顺序读取， 
对topic进行partition分区，consume group中的consume线程可以以很高能性能进行顺序读。

14 Kafka delivery guarantee(message传送保证)
（1）At most once消息可能会丢，绝对不会重复传输；
（2）At least once 消息绝对不会丢，但是可能会重复传输；
（3）Exactly once每条信息肯定会被传输一次且仅传输一次，这是用户想要的。

15 分区机制partition
Kafka的broker端支持消息分区partition，Producer可以决定把消息发到哪个partition，在一个partition 中message的顺序就是Producer发送消息的顺序，一个topic中可以有多个partition，具体partition的数量是可配置的。
partition的概念使得kafka作为MQ可以横向扩展，吞吐量巨大。partition可以设置replica副本，replica副本存在不同的kafka broker节点上，第一个partition是leader,其他的是follower，message先写到partition leader上，再由partition leader push到parition follower上。所以说kafka可以水平扩展，也就是扩展partition。

16 基本名词
Broker：Kafka节点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。
Topic：一类消息，消息存放的目录即主题，例如page view日志、click日志等都可以以topic的形式存在，Kafka集群能够同时负责多个topic的分发。
Partition：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列
Segment：partition物理上由多个segment组成，每个Segment存着message信息
Producer : 生产message发送到topic
Consumer : 订阅topic消费message, consumer作为一个线程来消费
Consumer Group：一个Consumer Group包含多个consumer, 这个是预先在配置文件中配置好的。各个consumer（consumer 线程）可以组成一个组（Consumer group ），
partition中的每个message只能被组（Consumer group ） 中的一个consumer（consumer 线程 ）消费，如果一个message可以被多个consumer（consumer 线程 ） 消费的话，那么这些consumer必须在不同的组。Kafka不支持一个partition中的message由两个或两个以上的consumer thread来处理，即便是来自不同的consumer group的也不行。它不能像AMQ那样可以多个BET作为consumer去处理message，这是因为多个BET去消费一个Queue中的数据的时候，由于要保证不能多个线程拿同一条message，所以就需要行级别悲观所（for update）,这就导致了consume的性能下降，吞吐量不够。而kafka为了保证吞吐量，只允许一个consumer线程去访问一个partition。如果觉得效率不高的时候，可以加partition的数量来横向扩展，那么再加新的consumer thread去消费。这样没有锁竞争，充分发挥了横向的扩展性，吞吐量极高。这也就形成了分布式消费的概念。

17 基本流程
1）. producer 先从 zookeeper 的 "/brokers/.../state" 节点找到该 partition 的 leader
2）. producer 将消息发送给该 leader
3）. leader 将消息写入本地 log
4）. followers 从 leader pull 消息，写入本地 log 后 leader 发送 ACK
5）. leader 收到所有 ISR 中的 replica 的 ACK 后，增加 HW（high watermark，最后 commit 的 offset） 并向 producer 发送 ACK




二、ms相关
1、Kafka的用途有哪些？使用场景如何？
1）日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如Hadoop、Hbase、Solr等
2）消息系统：解耦和生产者和消费者、缓存消息等
3）用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到Hadoop、数据仓库中做离线分析和挖掘
4）运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告
5）流式处理：比如spark streaming和storm
6）事件源

2、 Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么
1）分区中的所有副本统称为AR（Assigned Repllicas）。所有与leader副本保持一定程度同步的副本（包括Leader）组成ISR（In-Sync Replicas），ISR集合是AR集合中的一个子集。与leader副本同步滞后过多的副本（不包括leader）副本，组成OSR(Out-Sync Relipcas),由此可见：AR=ISR+OSR。
2）ISR集合的副本必须满足：
      副本所在节点必须维持着与zookeeper的连接；
      副本最后一条消息的offset与leader副本最后一条消息的offset之间的差值不能超出指定的阈值
3）每个分区的leader副本都会维护此分区的ISR集合，写请求首先由leader副本处理，之后follower副本会从leader副本上拉取写入的消息，这个过程会有一定的延迟，导致follower副本中保存的消息略少于leader副本，只要未超出阈值都是可以容忍的
4）ISR的伸缩指的是Kafka在启动的时候会开启两个与ISR相关的定时任务，名称分别为“isr-expiration"和”isr-change-propagation".。isr-expiration任务会周期性的检测每个分区是否需要缩减其ISR集合。

3、Kafka中的HW、LEO、LSO、LW等分别代表什么？
1）HW是High Watermak的缩写，俗称高水位，它表示了一个特定消息的偏移量（offset），消费之只能拉取到这个offset之前的消息。
2）LEO是Log End Offset的缩写，它表示了当前日志文件中下一条待写入消息的offset。
3）LSO特指LastStableOffset。它具体与kafka的事物有关。消费端参数——isolation.level,这个参数用来配置消费者事务的隔离级别。字符串类型，“read_uncommitted”和“read_committed”。
4）LW是Low Watermark的缩写，俗称“低水位”，代表AR集合中最小的logStartOffset值，副本的拉取请求（FetchRequest）和删除请求（DeleteRecordRequest）都可能促使LW的增长。 

4、Kafka中是怎么体现消息顺序性的？具体的可参考这篇博文，Kafka如何保证消息的顺序性 - windpoplar - 博客园
1）、一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。
2）、写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。

5、Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？
拦截器 -> 序列化器 -> 分区器
补充：Producer拦截器(interceptor)是在Kafka 0.10版本被引入的，主要用于实现clients端的定制化控制逻辑。producer允许用户指定多个interceptor按序作用于同一条消息从而形成一个拦截链(interceptor chain)。Intercetpor的实现接口是org.apache.kafka.clients.producer.ProducerInterceptor。实现下面四个方法
 1）、configure(configs)：获取配置信息和初始化数据时调用
 2）、onSend(ProducerRecord)：用户可以在该方法中对消息做任何操作，但最好保证不要修改消息所属的topic和分区，否则会影响目标分区的计算
 3）、onAcknowledgement(RecordMetadata, Exception)：该方法会在消息被应答或消息发送失败时调用
 4）、close：关闭interceptor，主要用于执行一些资源清理工作

6、Kafka生产者客户端的整体结构是什么样子的？

7、消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？
不正确，通过自定义分区分配策略，可以将一个consumer指定消费所有partition。

8、消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1? 
offset+1 

9、有哪些情形会造成重复消费？
消费者消费后没有commit offset(程序崩溃/强行kill/消费耗时/自动提交偏移情况下unscrible)  

10、那些情景下会造成消息漏消费？
先提交offset，后消费，有可能造成数据的重复 

11、KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？参考：Kafka Consumer多线程实例_我只是一个简单的Coder，为了兴趣和理想奋斗在生活的道路上-CSDN博客
1）、每个线程维护一个KafkaConsumer
2）、维护一个或多个KafkaConsumer，同时维护多个事件处理线程(worker thread) 

12、简述消费者与消费组之间的关系 
消费者从属与消费组，消费偏移以消费组为单位。每个消费组可以独立消费主题的所有数据，同一消费组内消费者共同消费主题数据，每个分区只能被同一消费组内一个消费者消费。 

13、当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？
1）会在zookeeper中的/brokers/topics节点下创建一个新的topic节点，如：/brokers/topics/first
2）触发Controller的监听程序
3）kafka Controller 负责topic的创建工作，并更新metadata cache

14、topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？
可以增加 
bin/kafka-topics.sh --zookeeper localhost:2181/kafka --alter --topic topic-config --partitions 3

15、topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？
不可以减少，被删除的分区数据难以处理。 

16、创建topic时如何选择合适的分区数？如何根据数据量确定Kafka分区个数、Kafka的分区是不是越多越好、Kafak生产者分发策略，消费者负载均衡 09_啊策策大数据社区-CSDN博客
1）创建一个只有1个分区的topic
2）测试这个topic的producer吞吐量和consumer吞吐量。
3）假设他们的值分别是Tp和Tc，单位可以是MB/s。
4）然后假设总的目标吞吐量是Tt，那么分区数=Tt / min（Tp，Tc）
例如：producer吞吐量 = 20m/s；consumer吞吐量 = 50m/s，期望吞吐量100m/s；
分区数 = 100 / 20 = 5分区

17、Kafka目前有那些内部topic，它们都有什么特征？各自的作用又是什么？ 
consumer_offsets 以下划线开头，保存消费组的偏移

18、优先副本是什么？它有什么特殊的作用？
优先副本 会是默认的leader副本 发生leader变化时重选举会优先选择优先副本作为leader 

19、Kafka有哪几处地方有分区分配的概念？简述大致的过程及原理。
参考：如何根据数据量确定Kafka分区个数、Kafka的分区是不是越多越好、Kafak生产者分发策略，消费者负载均衡 
1）Range strategy
Range策略是对每个主题而言的，首先对同一个主题里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序。
2） RoundRobin strategy
使用RoundRobin策略有两个前提条件必须满足：
同一个Consumer Group里面的所有消费者的num.streams必须相等；
每个消费者订阅的主题必须相同。
所以这里假设前面提到的2个消费者的num.streams = 2。
RoundRobin策略的工作原理：将所有主题的分区组成 TopicAndPartition 列表，然后对 TopicAndPartition 列表按照 hashCode 进行排序 

20、简述Kafka的日志目录结构。Kafka中有那些索引文件？ 参考：Kafka面试题 - 知乎
每个分区对应一个文件夹，文件夹的命名为topic-0，topic-1，内部为.log和.index文件 
以及 .timeindex leader-epoch-checkpoint

21、如果我指定了一个offset，Kafka怎么查找到对应的消息？参考:Kafka面试题与答案全套整理_茅坤宝骏氹的博客-CSDN博客
1）.通过文件名前缀数字x找到该绝对offset 对应消息所在文件
2）.offset-x为在文件中的相对偏移
3）.通过index文件中记录的索引找到最近的消息的位置
4）.从最近位置开始逐条寻找

22、 如果我指定了一个timestamp，Kafka怎么查找到对应的消息？
1）.通过文件名前缀数字x找到该绝对offset 对应消息所在文件 
2）.offset-x为在文件中的相对偏移 
3）.通过index文件中记录的索引找到最近的消息的位置 
4）.从最近位置开始逐条寻找

23、kafka过期数据清理
日志清理保存的策略只有delete和compact两种
log.cleanup.policy=delete启用删除策略
log.cleanup.policy=compact启用压缩策略

24、Kafka中的幂等是怎么实现的
Producer的幂等性指的是当发送同一条消息时，数据在Server端只会被持久化一次，数据不丟不重，但是这里的幂等性是有条件的：
1）只能保证Producer在单个会话内不丟不重，如果Producer出现意外挂掉再重启是无法保证的（幂等性情况下，是无法获取之前的状态信息，因此是无法做到跨会话级别的不丢不重）。
2）幂等性不能跨多个Topic-Partition，只能保证单个Partition内的幂等性，当涉及多个 Topic-Partition时，这中间的状态并没有同步。

25、kafka事务。分享一篇大佬讲kafka事务的博客，这一篇讲的更深入：Kafka Exactly-Once 之事务性实现 | Matt's Blog
同时分享一下这两篇博文，感觉这篇博文讲的更容易理解一些，面试我感觉看这两篇就够了：Kafka事务特性详解 - 简书，【干货】Kafka 事务特性分析 - 中间件小哥 - 博客园
Kafka从0.11版本开始引入了事务支持。事务可以保证Kafka在Exactly Once语义的基础上，生产和消费可以跨分区和会话，要么全部成功，要么全部失败。
1）Producer事务
为了实现跨分区跨会话的事务，需要引入一个全局唯一的Transaction ID，并将Producer获得的PID和Transaction ID绑定。这样当Producer重启后就可以通过正在进行的Transaction ID获得原来的PID。
为了管理Transaction，Kafka引入了一个新的组件Transaction Coordinator。Producer就是通过和Transaction Coordinator交互获得Transaction ID对应的任务状态。Transaction Coordinator还负责将事务所有写入Kafka的一个内部Topic，这样即使整个服务重启，由于事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。
2）Consumer事务 
上述事务机制主要是从Producer方面考虑，对于Consumer而言，事务的保证就会相对较弱，尤其时无法保证Commit的信息被精确消费。这是由于Consumer可以通过offset访问任意信息，而且不同的Segment File生命周期不同，同一事务的消息可能会出现重启后被删除的情况。 

26、 Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？
1）控制器的选举
Kafka Controller的选举是依赖Zookeeper来实现的，在Kafka集群中哪个broker能够成功创建/controller这个临时（EPHEMERAL）节点他就可以成为Kafka Controller。
2）分区leader的选举
afka在所有broker中选出一个controller，所有Partition的Leader选举都由controller决定。controller会将Leader的改变直接通过RPC的方式（比Zookeeper Queue的方式更高效）通知需为此作出响应的Broker。同时controller也负责增删Topic以及Replica的重新分配。
3）消费者相关的选举
组协调器GroupCoordinator需要为消费组内的消费者选举出一个消费组的leader，这个选举的算法也很简单，分两种情况分析。如果消费组内还没有leader，那么第一个加入消费组的消费者即为消费组的leader。如果某一时刻leader消费者由于某些原因退出了消费组，那么会重新选举一个新的leader。

27、Kafka中的延迟队列怎么实现？
Kafka中存在大量的延迟操作，比如延迟生产、延迟拉取以及延迟删除等。Kafka并没有使用JDK自带的Timer或者DelayQueue来实现延迟的功能，而是基于时间轮自定义了一个用于实现延迟功能的定时器（SystemTimer）。JDK的Timer和DelayQueue插入和删除操作的平均时间复杂度为O(nlog(n))，并不能满足Kafka的高性能要求，而基于时间轮可以将插入和删除操作的时间复杂度都降为O(1)。
Kafka中的时间轮（TimingWheel）是一个存储定时任务的环形队列，底层采用数组实现，数组中的每个元素可以存放一个定时任务列表（TimerTaskList）。
TimerTaskList是一个环形的双向链表，链表中的每一项表示的都是定时任务项（TimerTaskEntry），其中封装了真正的定时任务TimerTask。
时间轮由多个时间格组成，每个时间格代表当前时间轮的基本时间跨度（tickMs）。时间轮的时间格个数是固定的，可用wheelSize来表示，那么整个时间轮的总体时间跨度（interval）可以通过公式 tickMs × wheelSize计算得出。

---------------------------------------------------------------------------------------------------------------
------------------------------------------kafka basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------linux basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识

1 Linux 简介
Linux内核最初只是由芬兰人李纳斯·托瓦兹（Linus Torvalds）在赫尔辛基大学上学时出于个人爱好而编写的。Linux是一套免费使用和自由传播的类Unix操作系统，是一个基于POSIX和UNIX的多用户、多任务、支持多线程和多CPU的操作系统。Linux能运行主要的UNIX工具软件、应用程序和网络协议。它支持32位和64位硬件。Linux继承了Unix以网络为核心的设计思想，是一个性能稳定的多用户网络操作系统。
Linux以它的高效性和灵活性著称。它能够在 PC计算机上实现全部的 Unix特性， 具有多任务、多用户的能力。 Linux是在 GNU公共许可权限下免费获得的，是一 个符合 POSIX标准的操作系统。 Linux操作系统软件包不仅包括完整的 Linux操 作系统，而且还包括了文本编辑器、高级语言编译器等应用软件。它还包括带有 多个窗口管理器的 X-Windows图形用户界面，如同我们使用 Windows NT一样，允 许我们使用窗口、图标和菜单对系统进行操作。 用C语言，汇编语言开发，支持shell脚本。

2 Linux的发行版
Linux的发行版说简单点就是将Linux内核与应用软件做一个打包。目前市面上较知名的发行版有：Ubuntu、RedHat、CentOS、Debian、Fedora、SuSE、OpenSUSE、Arch Linux、SolusOS 等。

3 Linux应用领域
今天各种场合都有使用各种Linux发行版，从嵌入式设备到超级计算机，并且在服务器领域确定了地位，通常服务器使用LAMP（Linux + Apache + MySQL + PHP）或LNMP（Linux + Nginx+ MySQL + PHP）组合。目前Linux不仅在家庭与企业中使用，并且在政府中也很受欢迎。
（1）巴西联邦政府由于支持Linux而世界闻名。
（2）有新闻报道俄罗斯军队自己制造的Linux发布版的，做为G.H.ost项目已经取得成果.
（3）印度的Kerala联邦计划在向全联邦的高中推广使用Linux。
（4）中华人民共和国为取得技术独立，在龙芯过程中排他性地使用Linux。
（5）在西班牙的一些地区开发了自己的Linux发布版，并且在政府与教育领域广泛使用，如Extremadura地区的gnuLinEx和Andalusia地区的Guadalinex。
（6）葡萄牙同样使用自己的Linux发布版Caixa Mágica，用于Magalh?es笔记本电脑和e-escola政府软件。
（7）法国和德国同样开始逐步采用Linux。

4 Linux vs Windows
比较	Windows	Linux
界面	界面统一，外壳程序固定所有Windows程序菜单几乎一致，快捷键也几乎相同	图形界面风格依发布版不同而不同，可能互不兼容。GNU/Linux的终端机是从UNIX传承下来，基本命令和操作方法也几乎一致。
驱动程序	驱动程序丰富，版本更新频繁。默认安装程序里面一般包含有该版本发布时流行的硬件驱动程序，之后所出的新硬件驱动依赖于硬件厂商提供。对于一些老硬件，如果没有了原配的驱动有时很难支持。另外，有时硬件厂商未提供所需版本的Windows下的驱动，也会比较头痛。	由志愿者开发，由Linux核心开发小组发布，很多硬件厂商基于版权考虑并未提供驱动程序，尽管多数无需手动安装，但是涉及安装则相对复杂，使得新用户面对驱动程序问题（是否存在和安装方法）会一筹莫展。但是在开源开发模式下，许多老硬件尽管在Windows下很难支持的也容易找到驱动。HP、Intel、AMD等硬件厂商逐步不同程度支持开源驱动，问题正在得到缓解。
使用	使用比较简单，容易入门。图形化界面对没有计算机背景知识的用户使用十分有利。	图形界面使用简单，容易入门。文字界面，需要学习才能掌握。
学习	系统构造复杂、变化频繁，且知识、技能淘汰快，深入学习困难。	系统构造简单、稳定，且知识、技能传承性好，深入学习相对容易。
软件	每一种特定功能可能都需要商业软件的支持，需要购买相应的授权。	大部分软件都可以自由获取，同样功能的软件选择较少。

5 著名厂商
(1)红帽系列
Red Hat linux: 大名鼎鼎的红帽，现在已经完结。以此为基础有以下分支:
Red Hat Enterprise: (www.redhat.com) 这个是企业级的linux，主要面向服务器。作为商业版，有比较好的配套软件和技术支持。RH的教材也堪称经典。
Fedora: (http://fedoraproject.org) 由社区维护，去除了一些商业软件。红帽实际上赞助了这个项目，以便以此作为技术测试平台。
CentOS: (www.centos.org) 这个版本不来自红帽的公司，是收集红帽公开的源码组成的免费版本，由社区维护，和红帽完全兼容。版本号升级较慢，但有持续的技术支持，所以适合于不愿意频繁升级的情形，鸟哥中就推荐以CentOS来建站。
(2)SUSE系列
SUSE Linux Enterprise: (www.suse.com) 和红帽商业版类似，是德国公司制作的，据说在欧洲比较流行，但我欧洲的朋友表示没怎么听说过。SUSE系列比较有特色的是YAST2，就是用来设置Linux的界面，对初级管理员比较方便。
openSUSE: (www.opensuse.org) SUSE的免费版本。以前SUSE不是很推这个免费版本，支持不好。现在似乎态度大大转变。就我个人的使用体验来说，还是觉得社区支持不足。
(3)Debian系列
Debian: (www.debian.org) 完全免费，社区维护的Linux版本，有很大的用户群，所以遇到问题，基本都可以找到社区用户的支持。
Ubuntu: (www.ubuntu.com) 由一个基金提供支持的免费Linux版本。 继承自Debian。界面很友好。发邮件过去，还会送你免费安装CD (不知道现在还有没有)。现在的版本加载的东西有些多，速度有些慢。写《大教堂和市集》的Eric Raymond说它是最好的Linux。
Mint (http://www.linuxmint.com), 基于ubuntu。它提供了更加丰富的预装应用，以减少用户搜索并安装应用的麻烦。其使用的应用版本比较新，可能不是很稳定。
		
6 vmware
VMware（中文名威睿”，纽约证券交易所“代码：VMW） 虚拟机软件，是全球桌面到数据中心虚拟化解决方案的领导厂商。全球不同规模的客户依靠VMware来降低成本和运营费用、确保业务持续性、加强安全性并走向绿色。2008年，VMware年收入达到19亿美元，拥有逾150,000的用户和接近22,000多家合作伙伴，是增长最快的上市软件公司之一。VMware总部设在加利福尼亚州的帕罗奥多市（Palo Alto）。
VMware（纽约证交所代码：VMW）在虚拟化和云计算基础架构领域处于全球领先地位，所提供的经客户验证的解决方案可通过降低复杂性以及更灵活、敏捷地交付服务来提高IT效率。VMware使企业可以采用能够解决其独有业务难题的云计算模式。VMware提供的方法可在保留现有投资并提高安全性和控制力的同时，加快向云计算的过度。 VMware拥有 400,000多家客户和55,000多家合作伙伴，它的解决方案可帮助各种规模的组织降低成本、提高业务灵活性并确保选择自由。
	
7 Linux 系统启动过程
@内核的引导。
@运行 init。
@系统初始化。
@建立终端 。
@用户登录系统。
用作桌面就不需要。Linux允许为不同的场合，分配不同的开机启动程序，这就叫做"运行级别"（runlevel）。也就是说，启动时根据"运行级别"，确定要运行哪些程序。

8 Linux系统有7个运行级别(runlevel)
运行级别0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动
运行级别1：单用户工作状态，root权限，用于系统维护，禁止远程登陆
运行级别2：多用户状态(没有NFS)
运行级别3：完全的多用户状态(有NFS)，登陆后进入控制台命令行模式
运行级别4：系统未使用，保留
运行级别5：X11控制台，登陆后进入图形GUI模式
运行级别6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动

9 目录树形结构图
/bin：
bin是Binary的缩写, 这个目录存放着最经常使用的命令。
/boot：
这里存放的是启动Linux时使用的一些核心文件，包括一些连接文件以及镜像文件。
/dev ：
dev是Device(设备)的缩写, 该目录下存放的是Linux的外部设备，在Linux中访问设备的方式和访问文件的方式是相同的。
/etc：
这个目录用来存放所有的系统管理所需要的配置文件和子目录。
/home：
用户的主目录，在Linux中，每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的。
/lib：
这个目录里存放着系统最基本的动态连接共享库，其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库。
/lost+found：
这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些文件。
/media：
linux系统会自动识别一些设备，例如U盘、光驱等等，当识别后，linux会把识别的设备挂载到这个目录下。
/mnt：
系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了。
/opt：
 这是给主机额外安装软件所摆放的目录。比如你安装一个ORACLE数据库则就可以放到这个目录下。默认是空的。
/proc：
这个目录是一个虚拟的目录，它是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息。这个目录的内容不在硬盘上而是在内存里，我们也可以直接修改里面的某些文件，比如可以通过下面的命令来屏蔽主机的ping命令，使别人无法ping你的机器：
echo 1 > /proc/sys/net/ipv4/icmp_echo_ignore_all
/root：
该目录为系统管理员，也称作超级权限者的用户主目录。
/sbin：
s就是Super User的意思，这里存放的是系统管理员使用的系统管理程序。
/selinux：
 这个目录是Redhat/CentOS所特有的目录，Selinux是一个安全机制，类似于windows的防火墙，但是这套机制比较复杂，这个目录就是存放selinux相关的文件的。
/srv：
 该目录存放一些服务启动之后需要提取的数据。
/sys：
这是linux2.6内核的一个很大的变化。该目录下安装了2.6内核中新出现的一个文件系统 sysfs 。sysfs文件系统集成了下面3种文件系统的信息：针对进程信息的proc文件系统、针对设备的devfs文件系统以及针对伪终端的devpts文件系统。该文件系统是内核设备树的一个直观反映。当一个内核对象被创建的时候，对应的文件和目录也在内核对象子系统中被创建。
/tmp：
这个目录是用来存放一些临时文件的。
/usr：
这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似于windows下的program files目录。
/usr/bin：
系统用户使用的应用程序。
/usr/sbin：
超级用户使用的比较高级的管理程序和系统守护程序。
/usr/src：内核源代码默认的放置目录。
/var：
这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件。在linux系统中，有几个目录是比较重要的，平时需要注意不要误删除或者随意更改内部文件。
/etc： 上边也提到了，这个是系统中的配置文件，如果你更改了该目录下的某个文件可能会导致系统不能启动。
/bin, /sbin, /usr/bin, /usr/sbin: 这是系统预设的执行文件的放置目录，比如 ls 就是在/bin/ls 目录下的。值得提出的是，/bin, /usr/bin 是给系统用户使用的指令（除root外的通用户），而/sbin, /usr/sbin 则是给root使用的指令。
/var： 这是一个非常重要的目录，系统上跑了很多程序，那么每个程序都会有相应的日志产生，而这些日志就被记录到这个目录下，具体在/var/log 目录下，另外mail的预设放置也是在这里。


10 文件属性
Linux系统是一种典型的多用户系统，不同的用户处于不同的地位，拥有不同的权限。为了保护系统的安全性，Linux系统对不同的用户访问同一文件（包括目录文件）的权限做了不同的规定。在Linux中我们可以使用ll或者ls –l命令来显示一个文件的属性以及文件所属的用户和组。
[root@www /]# ls -l
total 64
dr-xr-xr-x   2 root root 4096 Dec 14  2012 bin
dr-xr-xr-x   4 root root 4096 Apr 19  2012 boot
……
实例中，bin文件的第一个属性用"d"表示。"d"在Linux中代表该文件是一个目录文件。
在Linux中第一个字符代表这个文件是目录、文件或链接文件等等。
    当为[ d ]则是目录
    当为[ - ]则是文件；
    若是[ l ]则表示为链接文档(link file)；
    若是[ b ]则表示为装置文件里面的可供储存的接口设备(可随机存取装置)；
    若是[ c ]则表示为装置文件里面的串行端口设备，例如键盘、鼠标(一次性读取装置)。

接下来的字符中，以三个为一组，且均为『rwx』 的三个参数的组合。其中，[ r ]代表可读(read)、[ w ]代表可写(write)、[ x ]代表可执行(execute)。 要注意的是，这三个权限的位置不会改变，如果没有权限，就会出现减号[ - ]而已。

每个文件的属性由左边第一部分的10个字符来确定（如下图）。
363003_1227493859FdXT

从左至右用0-9这些数字来表示。第0位确定文件类型，第1-3位确定属主（该文件的所有者）拥有该文件的权限。第4-6位确定属组（所有者的同组用户）拥有该文件的权限，第7-9位确定其他用户拥有该文件的权限。其中，第1、4、7位表示读权限，如果用"r"字符表示，则有读权限，如果用"-"字符表示，则没有读权限；第2、5、8位表示写权限，如果用"w"字符表示，则有写权限，如果用"-"字符表示没有写权限；第3、6、9位表示可执行权限，如果用"x"字符表示，则有执行权限，如果用"-"字符表示，则没有执行权限。

11 Linux文件属主和属组
[root@www /]# ls -l
total 64
drwxr-xr-x 2 root  root  4096 Feb 15 14:46 cron
drwxr-xr-x 3 mysql mysql 4096 Apr 21  2014 mysql
……
对于文件来说，它都有一个特定的所有者，也就是对该文件具有所有权的用户。同时，在Linux系统中，用户是按组分类的，一个用户属于一个或多个组。文件所有者以外的用户又可以分为文件所有者的同组用户和其他用户。因此，Linux系统按文件所有者、文件所有者同组用户和其他用户来规定了不同的文件访问权限。在以上实例中，mysql 文件是一个目录文件，属主和属组都为 mysql，属主有可读、可写、可执行的权限；与属主同组的其他用户有可读和可执行的权限；其他用户也有可读和可执行的权限。对于 root 用户来说，一般情况下，文件的权限对其不起作用。

12 更改文件属性
（1）、chgrp：更改文件属组
语法：
chgrp [-R] 属组名 文件名  
参数选项 
-R：递归更改文件属组，就是在更改某个目录文件的属组时，如果加上-R的参数，那么该目录下的所有文件的属组都会更改。 

（2）、chown：更改文件属主，也可以同时更改文件属组
语法：
chown [–R] 属主名 文件名
chown [-R] 属主名：属组名 文件名
进入 /root 目录（~）将install.log的拥有者改为bin这个账号：
[root@www ~] cd ~
[root@www ~]# chown bin install.log
[root@www ~]# ls -l
-rw-r--r--  1 bin  users 68495 Jun 25 08:53 install.log
将install.log的拥有者与群组改回为root：
[root@www ~]# chown root:root install.log
[root@www ~]# ls -l
-rw-r--r--  1 root root 68495 Jun 25 08:53 install.log

（3）、chmod：更改文件9个属性
Linux文件属性有两种设置方法，一种是数字，一种是符号。
Linux文件的基本权限就有九个，分别是owner/group/others三种身份各有自己的read/write/execute权限。

先复习一下刚刚上面提到的数据：文件的权限字符为：『-rwxrwxrwx』， 这九个权限是三个三个一组的！其中，我们可以使用数字来代表各个权限，各权限的分数对照表如下：
    r:4
    w:2
    x:1
	
每种身份(owner/group/others)各自的三个权限(r/w/x)分数是需要累加的，例如当权限为： [-rwxrwx---] 分数则是：
    owner = rwx = 4+2+1 = 7
    group = rwx = 4+2+1 = 7
    others= --- = 0+0+0 = 0
	
所以等一下我们设定权限的变更时，该文件的权限数字就是770啦！变更权限的指令chmod的语法是这样的：
 chmod [-R] xyz 文件或目录

 选项与参数：
    xyz : 就是刚刚提到的数字类型的权限属性，为 rwx 属性数值的相加。
    -R : 进行递归(recursive)的持续变更，亦即连同次目录下的所有文件都会变更
	
举例来说，如果要将.bashrc这个文件所有的权限都设定启用，那么命令如下：
[root@www ~]# ls -al .bashrc
-rw-r--r--  1 root root 395 Jul  4 11:45 .bashrc
[root@www ~]# chmod 777 .bashrc
[root@www ~]# ls -al .bashrc
-rwxrwxrwx  1 root root 395 Jul  4 11:45 .bashrc
那如果要将权限变成 -rwxr-xr-- 呢？那么权限的分数就成为 [4+2+1][4+0+1][4+0+0]=754。

（4）、符号类型改变文件权限
还有一个改变权限的方法呦！从之前的介绍中我们可以发现，基本上就九个权限分别是(1)user (2)group (3)others三种身份啦！ 那么我们就可以藉由u, g, o来代表三种身份的权限！此外， a 则代表 all 亦即全部的身份！那么读写的权限就可以写成r, w, x！也就是可以使用底下的方式来看：
chmod	u
g
o
a 	+(加入)
-(除去)
=(设定) 	r
w
x	文件或目录

13 处理目录的常用命令
接下来我们就来看几个常见的处理目录的命令吧：
ls: 列出目录 ls-l 
cd：切换目录 cd ./runoob/
pwd：显示目前的目录
mkdir：创建一个新的目录 mkdir -p test1/test2/test3/test4
rmdir：删除一个空的目录 rmdir -p test1/test2/test3/test4
cp: 复制文件或目录 cp ~/.bashrc /tmp/bashrc
rm: 移除文件或目录 rm -r bashrc/
mv ：移动文件与目录，或修改名称) mv bashrc mvtest

14 Linux 文件内容查看
Linux系统中使用以下命令来查看文件的内容：
cat  由第一行开始显示文件内容
tac  从最后一行开始显示，可以看出 tac 是 cat 的倒著写！
nl   显示的时候，顺道输出行号！
more 一页一页的显示文件内容
less 与 more 类似，但是比 more 更好的是，他可以往前翻页！
head 只看头几行
tail 只看尾巴几行
grep -30 "spring" xx.log  

15 head
取出文件前面几行
语法：head [-n number] 文件 
选项与参数：
    -n ：后面接数字，代表显示几行的意思 
[root@www ~]# head /etc/man.config
默认的情况中，显示前面 10 行！若要显示前 20 行，就得要这样：
[root@www ~]# head -n 20 /etc/man.config

16 tail
取出文件后面几行
语法：tail [-n number] 文件 
选项与参数：
    -n ：后面接数字，代表显示几行的意思
    -f ：表示持续侦测后面所接的档名，要等到按下[ctrl]-c才会结束tail的侦测 
[root@www ~]# tail /etc/man.config
# 默认的情况中，显示最后的十行！若要显示最后的 20 行，就得要这样：
[root@www ~]# tail -n 20 /etc/man.config

17 Linux磁盘管理常用三个命令
    df：列出文件系统的整体磁盘使用量
    du：检查磁盘空间使用量
    fdisk：用于磁盘分区
	
18 df
df命令参数功能：检查文件系统的磁盘空间占用情况。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。
[root@www ~]# df
Filesystem      1K-blocks      Used Available Use% Mounted on
/dev/hdc2         9920624   3823112   5585444  41% /
/dev/hdc3         4956316    141376   4559108   4% /home
/dev/hdc1          101086     11126     84741  12% /boot
tmpfs              371332         0    371332   0% /dev/shm

19 du
Linux du命令也是查看使用空间的，但是与df命令不同的是Linux du命令是对文件和目录磁盘使用的空间的查看，还是和df命令有一些区别的，这里介绍Linux du命令。
语法：du [-ahskm] 文件或目录名称
[root@www ~]# du
8       ./test4     <==每个目录都会列出来
8       ./test2
....中间省略....
12      ./.gconfd   <==包括隐藏文件的目录
220     .           <==这个目录(.)所占用的总量

20 fdisk
fdisk 是 Linux 的磁盘分区表操作工具。
语法：fdisk [-l] 装置名称
[root@AY120919111755c246621 tmp]# fdisk -l
Disk /dev/xvda: 21.5 GB, 21474836480 bytes
255 heads, 63 sectors/track, 2610 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x00000000
Device Boot      Start         End      Blocks   Id  System
/dev/xvda1   *           1        2550    20480000   83  Linux
/dev/xvda2            2550        2611      490496   82  Linux swap / Solaris
Disk /dev/xvdb: 21.5 GB, 21474836480 bytes
255 heads, 63 sectors/track, 2610 cylinders
Units = cylinders of 16065 * 512 = 8225280 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x56f40944
Device Boot      Start         End      Blocks   Id  System
/dev/xvdb2               1        2610    20964793+  83  Linux

21 vi/vim 的使用
基本上 vi/vim 共分为三种模式，分别是命令模式（Command mode），输入模式（Insert mode）和底线命令模式（Last line mode）。
（1）命令模式：
用户刚刚启动 vi/vim，便进入了命令模式。此状态下敲击键盘动作会被Vim识别为命令，而非输入字符。比如我们此时按下i，并不会输入一个字符，i被当作了一个命令。以下是常用的几个命令：
    i 切换到输入模式，以输入字符。
    x 删除当前光标所在处的字符。
    : 切换到底线命令模式，以在最底一行输入命令。
若想要编辑文本：启动Vim，进入了命令模式，按下i，切换到输入模式。命令模式只有一些最基本的命令，因此仍要依靠底线命令模式输入更多命令。
（2）输入模式
在命令模式下按下i就进入了输入模式。
在输入模式中，可以使用以下按键：
    字符按键以及Shift组合，输入字符
    ENTER，回车键，换行
    BACK SPACE，退格键，删除光标前一个字符
    DEL，删除键，删除光标后一个字符
    方向键，在文本中移动光标
    HOME/END，移动光标到行首/行尾
    Page Up/Page Down，上/下翻页
    Insert，切换光标为输入/替换模式，光标将变成竖线/下划线
    ESC，退出输入模式，切换到命令模式
（3）底线命令模式
在命令模式下按下:（英文冒号）就进入了底线命令模式。
底线命令模式可以输入单个或多个字符的命令，可用的命令非常多。
在底线命令模式中，基本的命令有（已经省略了冒号）：
    q 退出程序
    w 保存文件
按ESC键可随时退出底线命令模式。
简单的说，我们可以将这三个模式想成底下的图标来表示： 


22  yum（ Yellow dog Updater, Modified）
一个在Fedora和RedHat以及SUSE中的Shell前端软件包管理器。基於RPM包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。yum提供了查找、安装、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。
yum [options] [command] [package ...]
    options：可选，选项包括-h（帮助），-y（当安装过程提示选择全部为"yes"），-q（不显示安装的过程）等等。
    command：要进行的操作。
    package操作的对象。

23  yum常用命令
    1.列出所有可更新的软件清单命令：yum check-update
    2.更新所有软件命令：yum update
    3.仅安装指定的软件命令：yum install <package_name>
    4.仅更新指定的软件命令：yum update <package_name>
    5.列出所有可安裝的软件清单命令：yum list
    6.删除软件包命令：yum remove <package_name>
    7.查找软件包 命令：yum search <keyword>
    8.清除缓存命令:
        yum clean packages: 清除缓存目录下的软件包
        yum clean headers: 清除缓存目录下的 headers
        yum clean oldheaders: 清除缓存目录下旧的 headers
        yum clean, yum clean all (= yum clean packages; yum clean oldheaders) :清除缓存目录下的软件包及旧的headers

24 常用命令简单介绍
（1）常用命令
ls　 显示文件或目录
ls -l  列出文件详细信息l(list)
ls -a  列出当前目录下所有文件及目录，包括隐藏的a(all)
mkdir test1; 简单创建
mkdir -m 777 test2; 授予777权限
mkdir -v test3; 创建并且显示
mkdir -p -v aaa/bbb/ccc; 创建并且显示，父目录自动生成
rm demo.java  直接删除文件
rm -R -v aaa   递归删除，删除完成显示
rmdir -v czj  删除空目录，删除完成显示
rmdir -v -p aaa/bbb/ccc/  递归删除空目录，注意删除的顺序，由子目录到父目录
cd /opt/huawei/hnas_uoms/uoms/bin   进入目录 
cd ..  上级目录
cd ../..   上两级目录
touch -m hs_err_pid2874.log   只更新修改时间
touch demo.c  创建文件
echo 666      输出666换行
echo -n 666   输出666不换行
cat uomsDeploy.sh  查看整个文件内容
cat -n textfile1 > textfile2   把 textfile1 的档案内容加上行号后输入 textfile2 这个档案里
cp file1 file2  将文件file1复制成文件file2
cp -f file1 file2  强制复制的模式
cp -R file1 file2  将目录dir1复制成目录dir2
mv test.log test1.txt 将文件test.log改名为test1.txt
mv test1.txt test3 将文件test1.txt移到test3 
mv -f log3.txt log2.txt 将文件file1改名为file2，即使file2存在，也是直接覆盖掉
mv -i log3.txt log2.txt 将文件file1改名为file2，file2存在，询问
mv dir1 dir2  目录的移动 
find ./ -size -10G 文件size小于10G的文件或目录
find ./ -size +10K 文件size大于10M的文件或目录
find ./ -nogroup 查找文件的组ID不存在的文件
find ./ -group wade 查找组名为wade的文件或目录
find ./ -user czj 所有者为czj的文件或目录
find ./ -perm -o=r 其它用户权限有读权限的目录或文件
find ./ -perm -g=w 用户组权限有写权限的目录或文件
find ./ -perm -u=e 用户权限有执行权限的目录或文件
ind ./ -perm 664 权限为644的文件或目录
find ./ -empty -type f -print -delete 查找空文件并删除
find ./ -mmin -2 查找文件更新日时在距现在时刻二分以内的文件
find ./ -name \*.zip 查找文件名匹配*.zip的文件
find ./ -name test 查找文件名为test的文件
wc testfile testfile_1 testfile_2   #统计三个文件的信息 行数、字数、字符数
grep ‘test’ d* 显示所有以d开头的文件中包含 test的行 
grep ‘[a-z]\{5\}’ aa  显示aa所有包含每个字符串至少有5个连续小写字符的字符串的行
pwd              显示当前目录
clear 清除命令 
more uomsDeploy.sh 分页显示uomsDeploy.sh；enter向下一行；Ctrl+f向下滚动一屏；Ctrl+b返回上一屏 
less uomsDeploy.sh 分页显示uomsDeploy.sh；enter向下一行；空格向下滚动一屏；g第一行；G最后一行。
head -5 uomsDeploy.sh 显示开始5行
tail -10 /etc/passwd  读取最后10行
tail -f /var/log/messages  读取最后几行，不断读取新的内容，实时监控的作用
ctrl+c 退出
全文行号高亮：    grep timerLockMapper -n --color run.log
监控最后行号高亮（只显示）：tail -f -n 1000 run.log |grep timerLockMapper -n --color
监控最后行号高亮（全部显示）：tail -f run.log | perl -pe 's/(request)/\e[1;31m$1\e[0m/g'

（2）系统管理
who  显示在线登陆用户
whoami  显示当前操作用户
hostname  显示主机名
uname    显示系统信息
top    动态显示当前耗费资源最多进程信息
ps   显示瞬间进程状态 ps -aux
ping  www.baidu.com    测试网络连通
netstat  显示网络状态信息
clear   清屏
kill -9 pid  强制终止,杀死进程，可以先用ps 或 top命令查看进程的id，然后再用kill命令杀死进程。
shutdown -r  关机重启
shutdown -h  关机不重启
shutdown now  立刻关机
halt  关机
reboot  重启

（3）打包压缩
tar:                 打包压缩
-c              归档文件
-x              压缩文件
-z              gzip压缩文件
-j              bzip2压缩文件
-v              显示压缩或解压缩过程 v(view)
-f              使用档名
tar -cvf /home/abc.tar /home/abc          只打包，不压缩
tar -zcvf /home/abc.tar.gz /home/abc      打包，并用gzip压缩
tar -jcvf /home/abc.tar.bz2 /home/abc     打包，并用bzip2压缩
tar –cvf mysql-5.0.tar mysql-----把整个目录mysql中文件打包到mysql-5.0.tar
tar – rf mysql-5.0.tar mysql.conf ------将文件mysql.conf增加到包mysql-5.0.tar
tar –uf mysql-5.0.tar mysql.conf --------用文件mysql.conf更新包中的文件mysql.conf
tar –xvf mysql-5.0.tar        -------打开包mysql-5.0.tar中的文件到当前目录

（4）vim三种模式：命令模式(Esc)、插入模式(i)、底行模式 (ctrl+c 或者  :)
命令模式下：
:q  退出
:q! 强制退出
:wq  保存并退出

（5）用户及权限
/etc/passwd    存储用户账号
/etc/group       存储组账号
/etc/shadow    存储用户账号的密码
/etc/gshadow  存储用户组账号的密码
useradd 用户名
userdel 用户名
adduser 用户名
groupadd 组名
groupdel 组名
passwd root     给root设置密码
su root
su - root 
/etc/profile     系统环境变量
bash_profile     用户环境变量
.bashrc              用户环境变量
su user              切换用户，加载配置文件.bashrc
su - user            切换用户，加载配置文件/etc/profile ，加载bash_profile
chgrp  :  改变档案所属群组
chown :  改变档案拥有者; 将install.log的拥有者改为bin这个账号： chown bin install.log
chmod :  改变档案的权限, SUID, SGID, SBIT等等的特性
Linux档案的基本权限就有九个，分别是owner/group/others三种身份各有自己的read/write/execute权限
举例：档案的权限字符为 -rwxrwxrwx  这九个权限是三个三个一组的！其中，我们可以使用数字来代表各个权限，各权限的分数对照表如下：
r:4 　　w:2　　　x:1
每种身份(owner/group/others)各自的三个权限(r/w/x)分数是需要累加的，例如当权限为： [-rwxrwx---] 分数则是：
owner = rwx = 4+2+1 = 7
group = rwx = 4+2+1 = 7
others= --- = 0+0+0 = 0
所以我们设定权限的变更时，该档案的权限数字就是770啦！变更权限的指令chmod的语法是这样的：

u User，即文件或目录的拥有者； 
g Group，即文件或目录的所属群组； 
o Other，除了文件或目录拥有者或所属群组之外，其他用户皆属于这个范围； 
a All，即全部的用户，包含拥有者，所属群组以及其他用户； 
r 读取权限，数字代号为“4”; 
w 写入权限，数字代号为“2”； 
x 执行或切换权限，数字代号为“1”； 
- 不具任何权限，数字代号为“0”；

chmod [who] [+ | - | =] [mode] 文件名
chmod 777 filename
chmod -R  777  /home/mypackage
$ chmod u+x file 给file的属主增加执行权限
$ chmod 751 file 给file的属主分配读、写、执行(7)的权限，给file的所在组分配读、执行(5)的权限，给其他用户分配执行(1)的权限
$ chmod u=rwx,g=rx,o=x file 上例的另一种形式
$ chmod =r file 为所有用户分配读权限
$ chmod 444 file  同上例
$ chmod a-wx,a+r file 同上例
$ chmod -R u+r directory 递归地给directory目录下所有文件和子目录的属主分配读的权限
$ chmod 4755  设置用ID，给属主分配读、写和执行权限，给组和其他用户分配读、执行的权限

25 Shell 脚本
Shell 脚本（shell script），是一种为 shell 编写的脚本程序。业界所说的 shell 通常都是指 shell 脚本，但读者朋友要知道，shell 和 shell script 是两个不同的概念。由于习惯的原因，简洁起见，本文出现的 "shell编程" 都是指 shell 脚本编程，不是指开发 shell 自身。

26 Shell 环境
Shell 编程跟 java、php 编程一样，只要有一个能编写代码的文本编辑器和一个能解释执行的脚本解释器就可以了。Linux 的 Shell 种类众多，常见的有：
    Bourne Shell（/usr/bin/sh或/bin/sh）
    Bourne Again Shell（/bin/bash）
    C Shell（/usr/bin/csh）
    K Shell（/usr/bin/ksh）
    Shell for Root（/sbin/sh）
    …… 
关注的是 Bash，也就是 Bourne Again Shell，由于易用和免费，Bash 在日常工作中被广泛使用。同时，Bash 也是大多数Linux 系统默认的 Shell。在一般情况下，人们并不区分 Bourne Shell 和 Bourne Again Shell，所以，像 #!/bin/sh，它同样也可以改为 #!/bin/bash。#! 告诉系统其后路径所指定的程序即是解释此脚本文件的 Shell 程序。

27 第一个shell脚本
打开文本编辑器(可以使用 vi/vim 命令来创建文件)，新建一个文件 test.sh，扩展名为 sh（sh代表shell），扩展名并不影响脚本执行，见名知意就好，如果你用 php 写 shell 脚本，扩展名就用 php 好了。输入一些代码，第一行一般是这样：
实例
#!/bin/bash 
echo "Hello World !" 
运行实例 » 
#! 是一个约定的标记，它告诉系统这个脚本需要什么解释器来执行，即使用哪一种 Shell。
echo 命令用于向窗口输出文本。

28 运行 Shell 脚本有两种方法
1）作为可执行程序
将上面的代码保存为 test.sh，并 cd 到相应目录：
chmod +x ./test.sh  #使脚本具有执行权限
./test.sh  #执行脚本
注意，一定要写成 ./test.sh，而不是 test.sh，运行其它二进制的程序也一样，直接写 test.sh，linux 系统会去 PATH 里寻找有没有叫 test.sh 的，而只有 /bin, /sbin, /usr/bin，/usr/sbin 等在 PATH 里，你的当前目录通常不在 PATH 里，所以写成 test.sh 是会找不到命令的，要用 ./test.sh 告诉系统说，就在当前目录找。
2）作为解释器参数
这种运行方式是，直接运行解释器，其参数就是 shell 脚本的文件名，如：
/bin/sh test.sh
/bin/php test.php




二、ms相关
1 如何看当前Linux系统有几颗物理CPU和每颗CPU的核数？
[root@centos6 ~ 10:55 #35]# cat /proc/cpuinfo|grep -c 'physical id'
[root@centos6 ~ 10:56 #36]# cat /proc/cpuinfo|grep -c 'processor'


2 查看系统负载有两个常用的命令，是哪两个？这三个数值表示什么含义呢？
[root@centos6 ~ 10:56 #37]# w
10:57:38 up 14 min,  1 user,  load average: 0.00, 0.00, 0.00
USER     TTY      FROM              LOGIN@   IDLE   JCPU   PCPU WHAT
root     pts/0    192.168.147.1    18:44    0.00s  0.10s  0.00s w
[root@centos6 ~ 10:57 #38]# uptime
10:57:47 up 14 min,  1 user,  load average: 0.00, 0.00, 0.00
其中load average即系统负载，三个数值分别表示一分钟、五分钟、十五分钟内系统的平均负载，即平均任务数。

3 vmstat r, b, si, so, bi, bo 这几列表示什么含义呢？
[root@centos6 ~ 10:57 #39]# vmstat
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----
r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
0  0      0 1783964  13172 106056    0    0    29     7   15   11  0  0 99  0  0
r即running，表示正在跑的任务数
b即blocked，表示被阻塞的任务数
si表示有多少数据从交换分区读入内存
so表示有多少数据从内存写入交换分区
bi表示有多少数据从磁盘读入内存
bo表示有多少数据从内存写入磁盘
简记：
i --input，进入内存
o --output，从内存出去
s --swap，交换分区
b --block，块设备，磁盘
单位都是KB

4 linux系统里，您知道buffer和cache如何区分吗？
buffer和cache都是内存中的一块区域，当CPU需要写数据到磁盘时，由于磁盘速度比较慢，所以CPU先把数据存进buffer，然后CPU去执行其他任务，buffer中的数据会定期写入磁盘；当CPU需要从磁盘读入数据时，由于磁盘速度比较慢，可以把即将用到的数据提前存入cache，CPU直接从Cache中拿数据要快的多。

5 使用top查看系统资源占用情况时，哪一列表示内存占用呢？
PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
301 root      20   0     0    0    0 S  0.3  0.0   0:00.08 jbd2/sda3-8
1 root      20   0  2900 1428 1216 S  0.0  0.1   0:01.28 init
2 root      20   0     0    0    0 S  0.0  0.0   0:00.00 kthreadd
3 root      RT   0     0    0    0 S  0.0  0.0   0:00.00 migration/0
VIRT虚拟内存用量
RES物理内存用量
SHR共享内存用量
%MEM内存用量

6 如何实时查看网卡流量为多少？如何查看历史网卡流量？
安装sysstat包，使用sar命令查看。
yum install -y sysstat#安装sysstat包，获得sar命令
sar -n DEV#查看网卡流量，默认10分钟更新一次
sar -n DEV 1 10#一秒显示一次，一共显示10次
sar -n DEV -f /var/log/sa/sa22#查看指定日期的流量日志

7 如何查看当前系统都有哪些进程？
ps -aux 或者ps -elf
[root@centos6 ~ 13:20 #56]# ps -aux
Warning: bad syntax, perhaps a bogus '-'? See /usr/share/doc/procps-3.2.8/FAQ
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  0.0  0.0   2900  1428 ?        Ss   10:43   0:01 /sbin/init
root         2  0.0  0.0      0     0 ?        S    10:43   0:00 [kthreadd]
root         3  0.0  0.0      0     0 ?        S    10:43   0:00 [migration/0]
root         4  0.0  0.0      0     0 ?        S    10:43   0:00 [ksoftirqd/0]
……
[root@centos6 ~ 13:21 #57]# ps -elf
F S UID        PID  PPID  C PRI  NI ADDR SZ WCHAN  STIME TTY          TIME CMD
4 S root         1     0  0  80   0 -   725 -      10:43 ?        00:00:01 /sbin/init
1 S root         2     0  0  80   0 -     0 -      10:43 ?        00:00:00 [kthreadd]
1 S root         3     2  0 -40   - -     0 -      10:43 ?        00:00:00 [migration/0]
1 S root         4     2  0  80   0 -     0 -      10:43 ?        00:00:00 [ksoftirqd/0]
1 S root         5     2  0 -40   - -     0 -      10:43 ?        00:00:00 [migration/0]

8 ps 查看系统进程时，有一列为STAT， 如果当前进程的stat为Ss 表示什么含义？如果为Z表示什么含义？
S表示正在休眠；s表示主进程；Z表示僵尸进程。

9 如何查看系统都开启了哪些端口？
[root@centos6 ~ 13:20 #55]# netstat -lnp
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address               Foreign Address             State       PID/Program name
tcp        0      0 0.0.0.0:22                  0.0.0.0:*                   LISTEN      1035/sshd
tcp        0      0 :::22                       :::*                        LISTEN      1035/sshd
udp        0      0 0.0.0.0:68                  0.0.0.0:*                               931/dhclient
Active UNIX domain sockets (only servers)
Proto RefCnt Flags       Type       State         I-Node PID/Program name    Path
unix  2      [ ACC ]     STREAM     LISTENING     6825   1/init              @/com/ubuntu/upstart
unix  2      [ ACC ]     STREAM     LISTENING     8429   1003/dbus-daemon    /var/run/dbus/system_bus_socket

10 如何查看网络连接状况？
[root@centos6 ~ 13:22 #58]# netstat -an
Active Internet connections (servers and established)
Proto Recv-Q Send-Q Local Address               Foreign Address             State
tcp        0      0 0.0.0.0:22                  0.0.0.0:*                   LISTEN
tcp        0      0 192.168.147.130:22          192.168.147.1:23893         ESTABLISHED
tcp        0      0 :::22                       :::*                        LISTEN
udp        0      0 0.0.0.0:68                  0.0.0.0:*
……

11 想修改ip，需要编辑哪个配置文件，修改完配置文件后，如何重启网卡，使配置生效？
使用vi或者vim编辑器编辑网卡配置文件/etc/sysconfig/network-scripts/ifcft-eth0（如果是eth1文件名为ifcft-eth1），内容如下：
DEVICE=eth0
HWADDR=00:0C:29:06:37:BA
TYPE=Ethernet
UUID=0eea1820-1fe8-4a80-a6f0-39b3d314f8da
ONBOOT=yes
NM_CONTROLLED=yes
BOOTPROTO=static
IPADDR=192.168.147.130
NETMASK=255.255.255.0
GATEWAY=192.168.147.2
DNS1=192.168.147.2
DNS2=8.8.8.8
修改网卡后，可以使用命令重启网卡：
ifdown eth0
ifup eth0
也可以重启网络服务：
service network restart

12 能否给一个网卡配置多个IP? 如果能，怎么配置？
可以给一个网卡配置多个IP，配置步骤如下：
cat /etc/sysconfig/network-scripts/ifcfg-eth0#查看eth0的配置
DEVICE=eth0
HWADDR=00:0C:29:06:37:BA
TYPE=Ethernet
UUID=0eea1820-1fe8-4a80-a6f0-39b3d314f8da
ONBOOT=yes
NM_CONTROLLED=yes
BOOTPROTO=static
IPADDR=192.168.147.130
NETMASK=255.255.255.0
GATEWAY=192.168.147.2
DNS1=192.168.147.2
DNS2=8.8.8.8
（1）新建一个ifcfg-eth0:1文件
cp /etc/sysconfig/network-scripts/ifcfg-eth0 /etc/sysconfig/network-scripts/ifcfg-eth0:1
（2）修改其内容如下：
vim /etc/sysconfig/network-scripts/ifcfg-eth0:1
DEVICE=eth0:1
HWADDR=00:0C:29:06:37:BA
TYPE=Ethernet
UUID=0eea1820-1fe8-4a80-a6f0-39b3d314f8da
ONBOOT=yes
NM_CONTROLLED=yes
BOOTPROTO=static
IPADDR=192.168.147.133
NETMASK=255.255.255.0
GATEWAY=192.168.147.2
DNS1=192.168.147.2
DNS2=8.8.8.8
（3）重启网络服务：
service network restart

13 如何查看某个网卡是否连接着交换机？
mii-tool eth0 或者 mii-tool eth1

14 如何查看当前主机的主机名，如何修改主机名？要想重启后依旧生效，需要修改哪个配 置文件呢？
查看主机名：
hostname
centos6.5
修改主机名：
hostname centos6.5-1
永久生效需要修改配置文件：
vim /etc/sysconig/network
NETWORKING=yes
HOSTNAME=centos6.5-1

15 设置DNS需要修改哪个配置文件？
（1）在文件 /etc/resolv.conf 中设置DNS
（2）在文件 /etc/sysconfig/network-scripts/ifcfg-eth0 中设置DNS

16 使用iptables 写一条规则：把来源IP为192.168.1.101访问本机80端口的包直接拒绝
iptables -I INPUT -s 192.168.1.101 -p tcp --dport 80 -j REJECT

17 要想把iptable的规则保存到一个文件中如何做？如何恢复？
使用iptables-save重定向到文件中：
iptables-save > 1.ipt
使用iptables-restore反重定向回来：
iptables-restore < 1.ipt

18 如何备份某个用户的任务计划？
将/var/spool/cron/目录下指定用户的任务计划拷贝到备份目录cron_bak/下即可
cp /var/spool/cron/rachy /tmp/bak/cron_bak/

19 任务计划格式中，前面5个数字分表表示什么含义？
依次表示：分、时、日、月、周

20 如何可以把系统中不用的服务关掉？
（1）使用可视化工具：ntsysv
（2）使用命令：
chkconfig servicename off

21 如何让某个服务（假如服务名为 nginx）只在3,5两个运行级别开启，其他级别关闭？
先关闭所有运行级别：
chkconfig nginx off
然后打开35运行级别：
chkconfig --level 35 nginx on

22 rsync 同步命令中，下面两种方式有什么不同呢？
(1) rsync -av  /dira/  ip:/dirb/
(2) rsync -av  /dira/  ip::dirb
(1)前者是通过ssh方式同步的
(2)后者是通过rsync服务的方式同步的

23 rsync 同步时，如果要同步的源中有软连接，如何把软连接的目标文件或者目录同步？
同步源文件需要加-L选项

24 某个账号登陆linux后，系统会在哪些日志文件中记录相关信息？
用户身份验证过程记录在/var/log/secure中，登录成功的信息记录在/var/log/wtmp。

25 网卡或者硬盘有问题时，我们可以通过使用哪个命令查看相关信息？
使用命令dmesg

26 分别使用xargs和exec实现这样的需求，把当前目录下所有后缀名为.txt的文件的权限修改为777
（1）find ./ -type f -name "*.txt" |xargs chmod 777
（2）find ./ -type f -name "*.txt" -exec chmod 777 {} ;

27 有一个脚本运行时间可能超过2天，如何做才能使其不间断的运行，而且还可以随时观察脚本运行时的输出信息？
使用screen工具

28 在Linux系统下如何按照下面要求抓包：只过滤出访问http服务的，目标ip为192.168.0.111，一共抓1000个包，并且保存到1.cap文件中？
tcpdump -nn -s0 host 192.168.0.111 and port 80 -c 1000 -w 1.cap

29 rsync 同步数据时，如何过滤出所有.txt的文件不同步？
加上--exclude选项：
--exclude=“*.txt”

30 rsync同步数据时，如果目标文件比源文件还新，则忽略该文件，如何做？
保留更新使用-u或者--update选项

31 想在Linux命令行下访问某个网站，并且该网站域名还没有解析，如何做？
在/etc/hosts文件中增加一条从该网站域名到其IP的解析记录即可，或者使用curl -x

32 自定义解析域名的时候，我们可以编辑哪个文件？是否可以一个ip对应多个域名？是否一个域名对应多个ip？
编辑 /etc/hosts ,可以一个ip对应多个域名，不可以一个域名对多个ip

33 我们可以使用哪个命令查看系统的历史负载（比如说两天前的）？
sar -q -f /var/log/sa/sa22  #查看22号的系统负载

34 在Linux下如何指定dns服务器，来解析某个域名？
使用dig命令：dig @DNSip http://domain.com
如：
dig @8.8.8.8 www.baidu.com#使用谷歌DNS解析百度

35 使用rsync同步数据时，假如我们采用的是ssh方式，并且目标机器的sshd端口并不是默认的22端口，那我们如何做？
rsync "--rsh=ssh -p 10022"或者rsync -e "ssh -p 10022"

36 rsync同步时，如何删除目标数据多出来的数据，即源上不存在，但目标却存在的文件或者目录？
加上--delete选项

37 使用free查看内存使用情况时，哪个数值表示真正可用的内存量？
free列第二行的值

38 有一天你突然发现公司网站访问速度变的很慢很慢，你该怎么办呢？
（服务器可以登陆，提示：你可以从系统负载和网卡流量入手）
可以从两个方面入手分析：分析系统负载，使用w命令或者uptime命令查看系统负载，如果负载很高，则使用top命令查看CPU，MEM等占用情况，要么是CPU繁忙，要么是内存不够，如果这二者都正常，再去使用sar命令分析网卡流量，分析是不是遭到了攻击。一旦分析出问题的原因，采取对应的措施解决，如决定要不要杀死一些进程，或者禁止一些访问等。

39 rsync使用服务模式时，如果我们指定了一个密码文件，那么这个密码文件的权限应该设置成多少才可以？
600或400

40 说出10个linux常用的指令
ls 查看目录中的文件
cd /home 进入 ‘/ home’ 目录；cd .. 返回上一级目录；cd ../.. 返回上两级目录
mkdir dir1 创建一个叫做 ‘dir1’ 的目录
rmdir dir1 删除一个叫做 ‘dir1’ 的目录 （只能删除空目录）
rm -f file1 删除一个叫做 ‘file1’ 的文件’，-f 参数，忽略不存在的文件，从不给出提示。
rm -rf /mulu  目录下面文件以及子目录下文件
cp /test1/file1 /test3/file2   如将/test1目录下的file1复制到/test3目录，并将文件名改为file2
mv /test1/file1 /test3/file2  如将/test1目录下的file1移动到/test3 目录，并将文件名改为file2
mv * ../ Linux当前目录所有文件移动到上一级目录
ps -ef|grep xxx 显示进程pid
kill  使用kill命令来终结进程。先使用ps命令找到进程id，使用kill -9命令，终止进程。
tar –xvf file.tar  解压 tar包
unzip file.zip 解压zip
unrar e file.rar 解压rar
free -m  查看服务器内存使用情况
ps查看进程

42 如何查看所有java进程
grep是搜索关键字
ps -ef | grep java
-aux 显示所有状态
ps -aux | grep java
kill 杀掉进程

43 如何杀掉某个服务的进程
kill 命令用于终止进程
-9 强迫进程立即停止
kill -9 [PID]
这里pid需要用 ps -ef | grep 查询pid
启动服务

44 如何启动服务
以启动Tomcat为例,先cd到启动的.sh文件目录
> cd /java/tomcat/bin
> ./startup.sh
停止Tomcat服务命令
./shutdown.sh
查看日志

45 如何查看测试项目的日志
一般测试的项目里面，有个logs的目录文件，会存放日志文件，有个xxx.out的文件，可以用tail -f 动态实时查看后端日志
先cd 到logs目录(里面有xx.out文件)
tail -f xx.out
这时屏幕上会动态实时显示当前的日志，ctr+c停止

46.如何查看最近1000行日志
tail -1000 xx.out

47.LINUX中如何查看某个端口是否被占用
netstat  -anp  | grep   端口号
图中主要看监控状态为LISTEN表示已经被占用，最后一列显示被服务mysqld占用，查看具体端口号，只要有如图这一行就表示被占用了
查看82端口的使用情况，如图
netstat  -anp  |grep  82
可以看出并没有LISTEN那一行，所以就表示没有被占用。此处注意，图中显示的LISTENING并不表示端口被占用，不要和LISTEN混淆哦，查看具体端口时候，必须要看到tcp，端口号，LISTEN那一行，才表示端口被占用了
查看当前所有已经使用的端口情况，如图：
netstat   -nultp（此处不用加端口号）

48.如何查找一个文件大小超过5M的文件
find . -type f -size +100M

49.如果知道一个文件名称，怎么查这个文件在linux下的哪个目录，如：要查找tnsnames.ora文件
find / -name tnsnames.ora
查到：
/opt/app/oracle/product/10.2/network/admin/tnsnames.ora
/opt/app/oracle/product/10.2/network/admin/samples/tnsnames.ora
还可以用locate 来查找
locate tnsnames.ora
结果是：
/opt/app/oracle/product/10.2/hs/admin/tnsnames.ora.sample
/opt/app/oracle/product/10.2/network/admin/tnsnames.ora
/opt/app/oracle/product/10.2/network/admin/samples/tnsnames.ora

50.find查找文件
find / -name httpd.conf　　#在根目录下查找文件httpd.conf，表示在整个硬盘查找
find /etc -name httpd.conf　　#在/etc目录下文件httpd.conf
find /etc -name ‘srm‘　　#使用通配符(0或者任意多个)。表示在/etc目录下查找文件名中含有字符串‘srm’的文件
find . -name ‘srm‘ 　　#表示当前目录下查找文件名开头是字符串‘srm’的文件
按照文件特征查找 　　　　
find / -amin -10 　　# 查找在系统中最后10分钟访问的文件(access time)
find / -atime -2　　 # 查找在系统中最后48小时访问的文件
find / -empty 　　# 查找在系统中为空的文件或者文件夹
find / -group cat 　　# 查找在系统中属于 group为cat的文件
find / -mmin -5 　　# 查找在系统中最后5分钟里修改过的文件(modify time)
find / -mtime -1 　　#查找在系统中最后24小时里修改过的文件
find / -user fred 　　#查找在系统中属于fred这个用户的文件
find / -size +10000c　　#查找出大于10000000字节的文件(c:字节，w:双字，k:KB，M:MB，G:GB)
find / -size -1000k 　　#查找出小于1000KB的文件
查看文件内容的命令：
cat     由第一行开始显示内容，并将所有内容输出   （之前公司用的比较多）
tac     从最后一行倒序显示内容，并将所有内容输出
more    根据窗口大小，一页一页的现实文件内容
less    和more类似，但其优点可以往前翻页，而且进行可以搜索字符
head    只显示头几行
tail    只显示最后几行                             （之前公司用的比较多）
nl      类似于cat -n，显示时输出行号
tailf   类似于tail -f     
查看命令下一步其实就是编辑，但是编辑命令涉及比较多，参考文章：Linux文件编辑命令vi详细说明

51.cat 与 tac
cat的功能是将文件从第一行开始连续的将内容输出在屏幕上。但是cat并不常用，原因是当文件大，行数比较多时，屏幕无法全部容下时，只能看到一部分内容。
cat语法：cat [-n]  文件名 （-n ： 显示时，连行号一起输出）
tac的功能是将文件从最后一行开始倒过来将内容数据输出到屏幕上。我们可以发现，tac实际上是cat反过来写。这个命令也不常用。
tac语法：tac 文件名。

52.more和less（常用）
more的功能是将文件从第一行开始，根据输出窗口的大小，适当的输出文件内容。当一页无法全部输出时，可以用“回车键”向下翻行，用“空格键”向下翻页。退出查看页面，请按“q”键。另外，more还可以配合管道符“|”（pipe）使用，例如:ls -al | more
more的语法：more 文件名
Enter 向下n行，需要定义，默认为1行； 
Ctrl f 向下滚动一屏； 
空格键 向下滚动一屏； 
Ctrl b 返回上一屏； 
= 输出当前行的行号； 
:f 输出文件名和当前行的行号； 
v 调用vi编辑器； 
! 命令 调用Shell，并执行命令； 
q 退出more
less的功能和more相似，但是使用more无法向前翻页，只能向后翻。
less可以使用【pageup】和【pagedown】键进行前翻页和后翻页，这样看起来更方便。
less的语法：less 文件名
less还有一个功能，可以在文件中进行搜索你想找的内容，假设你想在passwd文件中查找有没有weblogic字符串，那么你可以这样来做：
[root@redhat etc]# less passwd
然后输入：
/weblogic
回车
此时如果有weblogic字符串，linux会把该字符已高亮方式显示。
退出查看页面，请按“q”键。

53.head和tail
head和tail通常使用在只需要读取文件的前几行或者后几行的情况下使用。head的功能是显示文件的前几行内容
head的语法：head [n number] 文件名 (number 显示行数)
tail的功能恰好和head相反，只显示最后几行内容
tail的语法:tail [-n number] 文件名

54.nl
nl的功能和cat -n一样，同样是从第一行输出全部内容，并且把行号显示出来
nl的语法：nl 文件名

55.tailf
tailf命令几乎等同于tail -f，严格说来应该与tail --follow=name更相似些。
当文件改名之后它也能继续跟踪，特别适合于日志文件的跟踪。
与tail -f不同的是，如果文件不增长，它不会去访问磁盘文件。
tailf特别适合那些便携机上跟踪日志文件，因为它能省电，因为减少了磁盘访问嘛。
tailf命令不是个脚本，而是一个用C代码编译后的二进制执行文件，某些Linux安装之后没有这个命令，本文提供了怎么编译安装tailf命令的方法。
---------------------------------------------------------------------------------------------------------------
------------------------------------------linux basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------lua basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 Lua 
一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。
Lua 是巴西里约热内卢天主教大学（Pontifical Catholic University of Rio de Janeiro）里的一个研究小组于 1993 年开发的，该小组成员有：Roberto Ierusalimschy、Waldemar Celes 和 Luiz Henrique de Figueiredo。

2 Lua 特性
轻量级: 它用标准C语言编写并以源代码形式开放，编译后仅仅一百余K，可以很方便的嵌入别的程序里。
可扩展: Lua提供了非常易于使用的扩展接口和机制：由宿主语言(通常是C或C++)提供这些功能，Lua可以使用它们，就像是本来就内置的功能一样。
支持面向过程(procedure-oriented)编程和函数式编程(functional programming)；
自动内存管理；只提供了一种通用类型的表（table），用它可以实现数组，哈希表，集合，对象；
语言内置模式匹配；闭包(closure)；函数也可以看做一个值；提供多线程（协同进程，并非操作系统所支持的线程）支持；
通过闭包和table可以很方便地支持面向对象编程所需要的一些关键机制，比如数据抽象，虚函数，继承和重载等。

3 Lua 应用场景
游戏开发
独立应用脚本
Web 应用脚本
扩展和数据库插件如：MySQL Proxy 和 MySQL WorkBench
安全系统，如入侵检测系统

4 Linux 系统上安装
curl -R -O http://www.lua.org/ftp/lua-5.3.0.tar.gz
tar zxf lua-5.3.0.tar.gz
cd lua-5.3.0
make linux test
make install

5 交互式编程
Lua 提供了交互式编程模式。我们可以在命令行中输入程序并立即查看效果。
Lua 交互式编程模式可以通过命令 lua -i 或 lua 来启用：
$ lua -i 
$ Lua 5.3.0  Copyright (C) 1994-2015 Lua.org, PUC-Rio
> 
在命令行中，输入以下命令:
> print("Hello World！")
接着我们按下回车键，输出结果如下：
> print("Hello World！")
Hello World！

6 脚本式编程
我们可以将 Lua 程序代码保存到一个以 lua 结尾的文件，并执行，该模式称为脚本式编程，如我们将如下代码存储在名为 hello.lua 的脚本文件中：
print("Hello World！")
print("www.runoob.com")
使用 lua 名执行以上脚本，输出结果为：
$ lua hello.lua
Hello World！
www.runoob.com
我们也可以将代码修改为如下形式来执行脚本（在开头添加：#!/usr/local/bin/lua）：
实例
#!/usr/local/bin/lua
print("Hello World！")
print("www.runoob.com")
以上代码中，我们指定了 Lua 的解释器 /usr/local/bin directory。加上 # 号标记解释器会忽略它。接下来我们为脚本添加可执行权限，并执行：
./hello.lua 
Hello World！
www.runoob.com

5 OpenResty 
OpenResty 是一个nginx和它的各种三方模块的一个打包而成的软件平台。最重要的一点是它将lua/luajit打包了进来，使得我们可以使用lua脚本来进行web的开发。
有了lua，我们可以借助于nginx的异步非阻塞的功能，达到使用 lua 异步并发访问后端的 MySQL, PostgreSQL, Memcached, Redis等等服务。

6 nginx嵌入lua 脚本
方法就是在nginx的配置文件nginx.conf 中使用 content_by_lua 或者 cotent_by_lua_file 指令
location /lua2 {
	#lua_code_cache off;
	content_by_lua_file lua/hello.lua;
}

7 lua 访问 redis
lua-resty-redis 模块：https://github.com/openresty/lua-resty-redis （有文档可以参考）
在nginx.conf中加入：

        location /redis_test{
            content_by_lua_file lua/redis_test.lua;
        }
redis_test.lua 内容:
[root@localhost lua]# cat redis_test.lua
local redis = require "resty.redis"
local red = redis:new()
red:set_timeout(1000)
local ok, err = red:connect("127.0.0.1", 6379)
if not ok then
        ngx.say("failed to connect: ", err)
        return
end

ngx.say("set result: ", ok)

local res, err = red:get("dog")
if not res then
        ngx.say("failed to get doy: ", err)
        return
end

if res == ngx.null then
        ngx.say("dog not found.")
        return
end

ngx.say("dog: ", res)

[root@localhost lua]#
		
8 lua 访问mysql
		

二、ms相关
1、Lua的基础工作原理，.lua文件实时编译之后，给到虚拟机的是什么指令.
具体指令形式有看吗？这个指令占了多少位数据，第n位主句代表啥，稍微看一下，有一个认识。 然后这些指令，具体怎么跟lua源码的模块代码相结合呢？比如我们是怎么调用到Talbe里面的add的？ 其实每个指令具体执行，都有一个switch（指令类型）这样执行的，找到这个文件，然后有时间可以大概了解一下lua的文件结构，大概每个文件都放了一些啥,可以更深入了解一下。 lua源码（window项目）可以打开tolua_rumtime-master_5_3_2\lua-5.3.3\lua.sln来看
Lua使用虚拟堆栈向C传递值。此堆栈中的每个元素表示Lua值（nil，number，string等）。API中的函数可以通过它们接收的Lua状态参数访问此堆栈。
Lua运行代码时，首先把代码编译成虚拟机的指令("opcode")，然后执行它们。 Lua编译器为每个函数创建一个原型(prototype)，这个原型包含函数执行的一组指令和函数所用到的数据表。
虚拟机指令类型
/*
**虚拟机指令类型;;
**必须是无符号的(至少)4字节(请参阅lopcode .h中的详细信息)
*/
#if LUAI_BITSINT >= 32
typedef unsigned int Instruction;
#else
typedef unsigned long Instruction;
#endif

2、Lua的数据类型
（如果要看源码了，可以看一下会被gc的那个类型数据，是如何被定义的，为啥lua不需要定义数据类型就可以赋值？什么要的数据类型会被放到_G那里去。然后可能还有一些数据类型不不会暴露给我们使用的，比如Proto，这个跟function的实现相关，有兴趣可以了解一下。还有lua_State）
Lua 中有 8 个基本类型分别为：nil、boolean、number、string、userdata、function、thread 和 table。
为啥lua不需要定义数据类型就可以赋值？
在赋值的时候，会调用函数expr解析表达式，=号右边的值，它最终会走入函数simpleexp中，在simpleexp中会根据expr解析出来的expdesc结构体里的t.token,用一个switch判断该表达式的类型，初始化expdesc结构体，将具体的数据赋值给expdesc结构体中的nval，所以，lua不需要定义数据类型就可以赋值，因为在解析器中会根据值的类型来进行初始化。
在函数localstat中，会读取“=”号左边的所有变量，首先看到在函数localstat中，首先会有一个循环调用函数new_localvar，将“=”左边的所有以","分隔的变量都生成一个相应的局部变量。 每一个局部变量，存储它的信息时使用的是LocVar结构体：
static void localstat (LexState *ls) {
  /* stat -> LOCAL NAME {',' NAME} ['=' explist] */
  int nvars = 0;
  int nexps;
  expdesc e;
  do {
    new_localvar(ls, str_checkname(ls));
    nvars++;
  } while (testnext(ls, ','));
  if (testnext(ls, '='))
    nexps = explist(ls, &e);
  else {
    e.k = VVOID;
    nexps = 0;
  }
  adjust_assign(ls, nvars, nexps, &e);
  adjustlocalvars(ls, nvars);
}

typedef struct LocVar {
  TString *varname;
  int startpc;  /* first point where variable is active */
  int endpc;    /* first point where variable is dead */
} LocVar;
这里主要存储了变量名，放在该结构体的变量varname中。一个函数的所有局部变量的LocVar信息，是存放在Proto结构体的locvars中。 在函数localstat中，会读取“=”号左边的所有变量，创建相应的局部变量信息在Proto结构体中。

我们从通过lua_pushbollean等指令函数看，c通过这些函数将各种类型的值压入lua栈，从而传递给lua。

(lapi.c) 556行
LUA_API void lua_pushboolean (lua_State *L, int b) {
  lua_lock(L);
  setbvalue(L->top, (b != 0));  /* ensure that true is 1 */
  api_incr_top(L);
  lua_unlock(L);
}

(lobject.h) 225行
#define setsvalue(L,obj,x) \
  { TValue *io = (obj); TString *x_ = (x); \
    val_(io).gc = obj2gco(x_); settt_(io, ctb(x_->tt)); \
    checkliveness(L,io); }
可以看到从虚拟栈里取出top之后，把值传给了setbvalue(L,obj,x)。

而在 setbvalue 里，obj 被转换成了 TValue 类型，接着又调用了两个宏 val_()，settt_()来设置 TValue 类型的两个成员。

由此可见，lua 栈中所有类型的值都是用 TValue 结构体来表示的。

那么TValue结构体是什么样的呢？
(lobject.h) 110行
#define TValuefields    Value value_; int tt_

typedef struct lua_TValue {
  TValuefields;
} TValue;
它由一个实际的 value 和一个int类型的 tag 组成。

基本类型
(lua.h)  
/*
** basic types
*/
#define LUA_TNONE (-1)          // 无类型
#define LUA_TNIL 0              // 空类型
#define LUA_TBOOLEAN 1          // 布尔
#define LUA_TLIGHTUSERDATA 2    // 指针 (void *)
#define LUA_TNUMBER 3           // 数字 (lua_Number)
#define LUA_TSTRING 4           // 字符串 (TString)
#define LUA_TTABLE 5            // 表 (Table)
#define LUA_TFUNCTION 6         // 函数 (CClosure)
#define LUA_TUSERDATA 7         // 指针 (void *)
#define LUA_TTHREAD 8           // LUA虚拟机 (lua_State)
value_ 是一个 union 类型 Value，所以它可以存储多种类型的值，根据注释可知全称叫Tagged Values。

(lobject.h 100行)
/*
** Tagged Values. This is the basic representation of values in Lua,
** an actual value plus a tag with its type.
*/

/*
** Union of all Lua values
*/
typedef union Value {
  GCObject *gc;    /* collectable objects */
  void *p;         /* light userdata */
  int b;           /* booleans */
  lua_CFunction f; /* light C functions */
  lua_Integer i;   /* integer numbers */
  lua_Number n;    /* float numbers */
} Value;
Lua内部用一个宏,表示哪些数据类型需要进行gc操作的: (lobject.h)

#define iscollectable(o)    (rttype(o) & BIT_ISCOLLECTABLE)

/* TValue的原始类型标签*/
#define rttype(o)   ((o)->tt_)

/*可收集类型的位标记*/
#define BIT_ISCOLLECTABLE   (1 << 6)


#define rttype(o) ((o)->tt_)
可以看到,tt_的第六位用于标记类型是否需要进行垃圾回收，

可进行垃圾回收的类型：GCObject
/*
** Common type has only the common header
*/
struct GCObject {
  CommonHeader;
};

#define CommonHeader    GCObject *next; lu_byte tt; lu_byte marked
可以看到GCObject结构中只有一个CommonHeader,CommonHeader主要由一个指向下一个回收类型的指针，一个对象类型tt和一个对象标记marked组成。
所以，lua中所有类型都的结构示意图如下:
TValue 里不是已经有一个 tt_ 字段用于表示类型了吗？为什么在 GCObject 里还需要这个字段呢？
答:要从 GCObject 反向得到 TValue 是不行的，假如 GCObject 没有 tt 字段，单单持有 GCObject 的时候，没法判断这个 GCObject 的类型是什么。 GC 在回收对象的时候需要根据类型来释放资源。基于第一点，必须在 GCObject 里加一个表示类型的字段 tt。

3、为什么说Lua一切皆Table,Table有哪两种存储形式，Table是如何Resize的
Lua的table是由数组部分（array part）和哈希部分（hash part）组成。数组部分索引的key是1~n的整数，哈希部分是一个哈希表（open address table），哈希表本质是一个数组，它利用哈希算法将键转化为数组下标，若下标有冲突(即同一个下标对应了两个不同的键)，则它会将冲突的下标上创建一个链表，将不同的键串在这个链表上，这种解决冲突的方法叫做：链地址法。
table 最基础的作用就是当成字典来用。 它的 key 值可以是除了 nil 之外的任何类型的值，当把 table 当成字典来用时，可以使用 ==pairs== 函数来进行遍历，使用==pairs==进行遍历时的顺序是随机的，事实上相同的语句执行多次得到的结果是不一样的。
当 key 为整数时，table 就可以当成数组来用。而且这个数组是一个 ==索引从1开始== ，没有固定长度，可以根据需要自动增长的数组，我们可以使用使用 ipairs 对数组进行遍历。
其他语言提供的所有结构---数组，记录，列表，队列，集合这些在lua中都用==table==来表示。
向table中插入数据时，如果已经满了，Lua会重新设置数据部分或哈希表的大小，容量是成倍增加的，哈希部分还要对哈希表中的数据进行整理。需要特别注意的没有赋初始值的table，数组和部分哈希部分默认容量为0。
resize代价高昂，当我们把一个新键值赋给表时，若数组和哈希表已经满了，则会触发一个再哈希(rehash)。再哈希的代价是高昂的。首先会在内存中分配一个新的长度的数组，然后将所有记录再全部哈希一遍，将原来的记录转移到新数组中。新哈希表的长度是最接近于所有元素数目的2的乘方。
local a = {}     --容量为0
a[1] = true      --重设数组部分的size为1
a[2] = true      --重设数组部分的size为2
a[3] = true      --重设数组部分的size为4
local b = {}     --容量为0
b.x = true       --重设哈希部分的size为1
b.y = true       --重设哈希部分的size为2
b.z = true       --重设哈希部分的size为4

4、Lua的面向对象实现
所以，实际上，class.new是什么呢？然后new完之后，返回的是什么东西？
使用元方法模拟面向对象的实现
--[[
云风的lua面向对象编程架构，用来模拟一个基类
--]]
local _class={}
function class(super)
    local class_type={}
    class_type.ctor=false
    class_type.super=super

    --[[
    模拟构造函数的function
    --]]
    class_type.new=function(...) 
            local obj={}
            do
                local create
                create = function(c,...)
                    --如果本类存在着基类，就递归调用基类的创建函数初始化基类的成员
                    if c.super then
                        create(c.super,...)
                    end
                    -- 如果本类有构造函数，就执行本类的构造函数操作
                    if c.ctor then
                        c.ctor(obj,...)
                    end
                end
                --前面的这段代码是声明create function，下面的就是执行
                create(class_type,...)
            end
            --将此对象的元表的__index元方法设为下面的虚函数表
            setmetatable(obj,{ __index=_class[class_type] })
            return obj
        end
    -- 用一个table来构造类的函数表
    local vtbl={}
    _class[class_type]=vtbl
   --[[
    设置表class_type的元表并定义__newindex字段，字段对应的函数，
    参数1就是表class_type本身，当添加一个新方法的时候就会执行此__newindex的实现
    --]]
    setmetatable(class_type,{__newindex=
        function(t,k,v)
            vtbl[k]=v
        end
    })
    --[[
    如果本类有父类的话，将本类虚函数表的原表__index设从父类的函数表，直接从父类的函数表中查找。
    --]]
    if super then
        setmetatable(vtbl,{__index=
            function(t,k)
                local ret=_class[super][k]  --这里，就是查找父类的函数表的操作
                vtbl[k]=ret
                return ret
            end
        })
    end
    return class_type
end

5、Lua元表是什么？
元表主要用于对两个table进行操作，例如两个table相加，当Lua试图对两个表进行相加时，先检查两者之一是否有元表，之后检查是否有一个叫"add"的字段，若找到，则调用对应的值。"add"等即时字段，其对应的值（往往是一个函数或是table）就是"元方法"。

6、Lua的gc机制简述
在Lua5.0及其更早的版本中，Lua的GC是一次性不可被打断的过程，使用的++Mark算法是双色标记算法(Two color mark)++，这样系统中对象的非黑即白，要么被引用，要么不被引用，这会带来一个问题：在GC的过程中如果新加入对象，这时候新加入的对象无论怎么设置都会带来问题，如果设置为白色，则如果处于回收阶段，则该对象会在没有遍历其关联对象的情况下被回收；如果标记为黑色，那么没有被扫描就被标记为不可回收，是不正确的。
为了降低一次性回收带来的性能问题以及双色算法的问题，在Lua5.1后，Lua都采用分布回收以及++三色增量标记清除算法（Tri-color incremental mark and sweep）++
将所有对象分成三个状态：
White状态，也就是待访问状态。表示对象还没有被垃圾回收的标记过程访问到。==（白色又分为White0和White1，主要为了解决上面所说到的在GC过程中新加入的对象的处理问题）==
Gray状态，也就是待扫描状态。表示对象已经被垃圾回收访问到了，但是对象本身对于其他对象的引用还没有进行遍历访问。
Black状态，也就是已扫描状态。表示对象已经被访问到了，并且也已经遍历了对象本身对其他对象的引用。
GC流程：
每个新创建的对象颜色设置为White
//初始化阶段
遍历root节点中引用的对象，从白色置为灰色，并且放入到Gray节点列表中
//标记阶段
while(Gray集合不为空,并且没有超过本次计算量的上限)：
从中取出一个对象，将其置为Black
遍历这个对象关联的其他所有对象：
if 为White
标记为Gray，加入到Gray链表中
//回收阶段
遍历所有对象：
if 为White，
没有被引用的对象，执行回收
else
重新塞入到对象链表中，等待下一轮GC
在每个步骤之间，由于程序可以正常执行，所以会破坏当前对象之间的引用关系。black对象表示已经被扫描的对象，所以他应该不可能引用到一个white对象。当程序的改变使得一个black对象引用到一个white对象时，就会造成错误。解决这个问题的办法就是设置barrier。barrier在程序正常运行过程中，监控所有的引用改变。如果一个black对象需要引用一个white对象，存在两种处理办法：
将white对象设置成gray，并添加到gray列表中等待扫描。这样等于帮助整个GC的标识过程向前推进了一步。
将black对象改回成gray，并添加到gray列表中等待扫描。这样等于使整个GC的标识过程后退了一步。
这种垃圾回收方式被称为"++Incremental Garbage Collection++"(简称为"IGC"，Lua所采用的就是这种方法。使用"IGC"并不是没有代价的。IGC所检测出来的垃圾对象集合比实际的集合要小，也就是说，有些在GC过程中变成垃圾的对象，有可能在本轮GC中检测不到。不过，这些残余的垃圾对象一定会在下一轮GC被检测出来，不会造成泄露。

7、Lua的全局变量跟local变量的区别，Lua是如何查询一个全局变量的，local的作用域
Lua将所有的全局变量保存在一个常规的table中,这个table称之为环境(_G),使 用下面的代码可以打印当前环境中所有全局变量的名称
for n in pairs(_G) do
print(n) 
end
在Lua中,要声明全局变量很简单,那就是定义变量的时候,前面不要加上 local。这个神秘的全局环境,其实本质上也是一个table,它把我们创建的全局变量都保存到一个table里了。而这个table的名字是:_G
本地变量定义在一个函数体中, 那么作用域就在函数中.
如果定义在一个控制结构中, 那么就在这个控制结构中.
如果定义在一个文件中, 那么作用域就在这个文件中.
一些lua使用中要注意的点
使用local，在代码运行前，Lua会把源码预编译成一种中间码，类似于Java的虚拟机。这种格式然后会通过C的解释器进行解释，整个过程其实就是通过一个while循环，里面有很多的switch...case语句，一个case对应一条指令来解析。 自Lua 5.0之后，Lua采用了一种类似于寄存器的虚拟机模式。Lua用栈来储存其寄存器。每一个活动的函数，Lua都会其分配一个栈，这个栈用来储存函数里的活动记录。每一个函数的栈都可以储存至多250个寄存器，因为栈的长度是用8个比特表示的。 有了这么多的寄存器，Lua的预编译器能把所有的local变量储存在其中。这就使得Lua在获取local变量时其效率十分的高。
如果你有很多非常多的很小的表需要创建时，你可以将其预先填充以避免rehash。
比如：
{true,true,true}
Lua知道这个表有三个元素，所以Lua直接创建了三个元素长度的数组。
所以，当需要创建非常多的小size的表时，应预先填充好表的大小。
---------------------------------------------------------------------------------------------------------------
------------------------------------------lua basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------manager basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识

（一）、分段概述
1 团队建设手段
（1）团队建设的三个层面
1、团队的凝聚力。
团队的凝聚力是针对团队和成员之间的关系而言的。团队精神表现为团队成员强烈的归属感和一体性，每个团队成员都能感受到自己是团队当中的一分子，把个人工作和团队目标联系在一起，对团队忠诚，对团队的成功感到自豪，对团队的困境感到忧虑。
2、团队的合作意识。
团队的合作意识是指团队和团队成员表现为协作和共为一体的特点。团队成员间相互依存、同舟共济、互相敬重、彼此宽容和尊重个性的差异；彼此间形成一种信任的关系，待人真诚、遵守承诺；相互帮助和共同提高；共享利益和成就、共担责任。 
3、团队士气。
团队士气是团队精神的一个重要方面。拿破仑曾说过：“一支军队的实力四分之三靠的是士气”。将这句话的含义延伸到现代企业管理，为团队目标而奋斗的精神状态对团队的业绩非常重要。

（2）团队建设的方法和手段
团队建设不是简单的人员挑选和人员组合的问题，而是如何培养一支高效，作战能力强的项目团的的问题。要想要一支好的项目团队，项目成员本身的能力和潜力起到一定作用，这个在组建项目团队时就决定的了，有时候项目管理者没办法干涉到这一部分。有些项目管理者是替换某个项目经理来管理这支团队管理的，这时候也是需要做团队建设的。

1） 挑选骨干
如果没有几个核心骨干，一个项目经理难以管理众多人员。骨干成员与基本成员的重要区别是：基本成员要求合理物质回报和良好文化氛围，而骨干成员往往认识到机会的重要性，认为成功比金钱重要。

2） 沟通渠道
一个团队不仅需要工作上的沟通，还需要一些“生活”上的沟通，这可以帮助大家建立信任和友情，在工作中能起促进作用。可以采用的方法包括每天与不同的人吃工作午餐;还可以在周末组织大家一起吃晚餐，逐步建立开诚布公的良好文化氛围，假期举办公共活动，用活动经费吃饭唱K等 

3） 地理集中
在相对集中的环境下一起工作对团队建设的作用决不可忽视。大家可以经常交流工作和个人情况，避免“我们”对“他们”以及团队的分裂成小团体的情况发生。

4） 注意心理疲劳
项目团队的工作强度一般都比较大，为了进度往往连续加班，在这种情况下，更要注意工作的阶段性和节奏性。可以在取得阶段性目标的情况下举行庆祝活动，并让每个人参加，让大家适度放松并建立信心。

5） 团队会议
团队会议不同于工作会议
一种是讨论团队工作中存在哪些问题以及如何改进，项目经理不是下结论的人，而是寻求答案的人。
另一种是帮助某个成员进行改进。第二种会议可以先让被讨论的对象回避，自己写评语，同时大家写对他的评语。然后对比双方的差异，找出问题所在以求不断改进。

6 ）评价成员
一个团队成员在完成委派的任务后都非常期待着评价。评价可以是正向的也可以是负面的。一般都可以表扬、提醒、批评和处罚。表扬和批评最好公开公正，否则达不到鼓励先进、鞭策后进的作用。
对工作中出现的过失、或因事先没有约定造成的问题，应该考虑先提醒。提醒要隐蔽，让成员知道错误和后果，并承诺不再犯错。处罚是万不得以的措施，处罚不是惩罚：惩罚是报复性措施，
有感情色彩和“摆平”的意思，而处罚是中性处理措施，不涉及人身攻击，且被处罚的人事先知道这是自己行为的结果。

7） 解决冲突
好的团队是“打出来的，不是练出来的!”，在巨大的工作压力下冲突在所难免。冲突的益处是暴露问题，激起讨论，澄清思想或寻求新的方案;害处是控制不好就会破坏沟通、破坏团结、降低信任。
第一，要营造氛围，控制情绪，建立友善信任的环境;
第二，要正视问题，换位思考，愿意倾听别人的意见;
第三，要积极沟通，交换意见，寻找分歧;
第四，要肯放弃原来观点并重新考虑问题;
第五，力争达成一致，尽力得到最好和最全面的方案。




2 项目经理具备能力和素质
（1）四种素质 
1）.品德素质。项目经理对外与供应商、客户打交道，对内需要跨部门整合资源，诚信的品德素质是基础。 

2）.能力素质。项目经理需要具备较强的综合管理能力。 

3）.知识结构。如今的项目经理不再仅仅是个技术专家、在办公室画画图就可以了，需具备一般的管理知识，如市场营销、人力资源管理等；项目管理专业知识；应用领域知识，如IT、金融、房地产等行业知识。 

4）.身体素质。没有一天只干8个小时的项目经理。项目管理工作经常赶周期，赶进度，工作起来没日没夜，业内戏称“体力活”，需要具备良好的身体素质。 

（2）八大技能 
1）.项目管理与专业知识技能。项目经理需要制订项目计划、控制项目成本、确保项目质量，需要具备项目管理专业知识。 

2）.人际关系技能。这是项目经理面临的最大挑战，项目经理对上需要向老板汇报进展，对下需要向项目成员分配任务，对外要与供应商、承包商打交道，耳听八方，眼观六路，需要具备良好的人际关系技能。 

3）.情境领导技能。项目经理需要不断激励项目员工，努力冲锋陷阵。管理因人而异，需要针对项目组不同成员不同需求，在不同情境下因需而变。 

4）.谈判与沟通的技能。无论是与客户还是员工相处，项目经理85%的时间都在谈判、沟通。 

5）.客户关系与咨询技能。现在的项目经理不仅是技术专家，需要走到客户端，根据客户需求，为客户量身定做项目方案。有一位项目经理给一家工业锅炉公司设计网页，他把网页设计得十分漂亮，又是玫瑰花又是鸟鸣什么的。结果，客户大为不满：“我们的产品就是灰不溜秋的铁疙瘩，又不是搞电子商务的，搞这么花哨有什么用？” 

6）.商业头脑和财务技能。企业目标是通过项目管理实现的，项目经理需要把项目放在整个企业战略中考虑。比如由于IT行业竞争激烈，IBM转型为IT服务商，IBM的项目经理就必须跟上企业转型。另外，项目经理需要了解项目的投资汇报率，净现值等财务指标。 

7）.解决问题和处理冲突的技能，每天项目经理都会碰到无穷无尽的问题，如安全事故，成本超支了或项目人员携款潜逃了，作为项目经理，需要具备较强的应变能力及化解冲突的能力。 

8）.创新技能，很多项目都是前无古人，后无来者的事业，如神舟六号，这往往需要项目经理具备创新能力。



（3）要求
1） 要公正无私：
99年我主管过一个项目，该项目的项目经理在分配奖金时论资派辈，不按业绩，使得项目组中资历浅但是干活多的员工怨言很大，导致整个项目的积极性很差，最后不得不由我出面制定新的业绩评估办法。如果一个项目经理不能做到公正无私，他就难以服众，无法带好项目团队。

2） 要有良好的职业道德
2002年在我经手主管的一个项目中，由于项目经理蓄意隐瞒了项目的真实进展情况，对用户的承诺没有兑现，而导致用户不信任他，向公司提出了撤换项目经理的要求。用户对于项目有知情权，给用户暴露出问题不一定是坏事，因为只要大家能够互相理解，才能保证项目的顺利进展。如果明知完不成进度，而故意隐瞒了真相，当然是要受到惩罚的。

3） 要具有管理的基本技能与知识
要做一个好的项目经理，他肯定要好好的学习一些关于项目管理的基础知识，进行项目管理的技能训练，既要有管理意识，还要有管理的基本技能，要"心有余且力也有余"。

4） 要具有很好的沟通与表达能力
项目经理要和方方面面的人员沟通，包括项目组内的人员、市场人员、用户、上级主管，也要和各个层次的人员打交道，为了项目的成功要通过沟通交流消除来自各方面的阻力。譬如，一个系统集成的项目，在用户现场布线时，你可能要和用户的工程主管、电工、施工队等各种角色沟通，否则，可能因为很小的问题，你的系统就要失败。

5） 要有很强的分析问题解决问题的能力
项目经理要能够通过现象看到本质,通过细节发现大问题,发现问题后要果断采取措施,而不是延误时机。如果一个项目经理对问题比较麻木，不能防微杜渐，那么就谁都可以做项目经理了！

6） 要懂技术，不要求精通，但是要全面
这可能是争议比较大的一个原则，因为如果按此原则执行，那些拿到PMP证书的专职项目经理如何找工作？使用不懂技术的项目经理我也曾经尝试过，用过一个不懂开发的人来做项目经理，他主要对项目的进度负责，进行项目组内外的协调，但是为了弥补其不足，必须还要给他配一个助手专门负责技术。对于大的项目这种方式是可以的，对于小的项目而言肯定不能这样做，否则就会出现资源浪费，项目经理的工作量不饱满。所以我的意见还是要使用懂技术的项目经理，这样他能清楚地知道组员在做什么、做的怎么样，能够发出正确的方向性指令，而不是瞎指挥，外行领导内行。

7） 要谦虚，不能不懂装懂
有的项目经理搞一言堂，听不进去大家的意见，而且不懂装懂。有一位软件公司的人力资源部经理向我诉说了他们公司由于软件项目经理选择不当而带来的烦恼。2001年他们公司聘用了一位项目经理，该项目经理被程序员们冠以"外行领导内行"的帽子，团队中绝大多数成员对他非议很多，他也听不进去别人的意见，从而使项目团队的效率很低，项目的质量很差，系统开始实施后，就陷入到大量的纠错改错的泥潭中。

8） 要平易近人，不要摆架子
如果你的项目经理不能做到这一点，你肯定会对这样的项目经理很反感的！你也不会去和他很好地沟通的，当然项目组的效率也不会很高的。


3制定项目计划
在适当的活动和阶段或其他的概括的标准说明下，输入确定的任务。将适当的可交付产品及里程碑和特定的任务联系起来。连接全部需要依赖关联的任务。把资源角色或资源名字加到每个任务上。应用度量结果确定事先的任务工作量，把更多的时间用于需求收集，设计和测试。考虑所有已知的节假日，培训，休假或其他的资源停工时间。计划草案将同支持团体，管理层和商务用户一起复查，做为补充性的输入和最终的批准。 


4如果给你一个4-6个人的Team，那么你怎么分配管理他们？
挑选一个技术过硬的人作为我的替补和项目的轻骑兵，是的团队中必须有机动人员，否则你的项目十有八九会夭折。其他的人会被平均的分配任务。
我们会在每周进行全面的任务分配，每个人获取一周的大概工作，然后每天的工作由他自己完成并汇报。掌握每个人都长处和短板，充分发挥他们的价值。


5 项目出现延迟如何处理？
很多企业的项目管理人员遇到项目拖期的情形，首先采取的策略是加班，管理水平稍好一点的企业则会修正计划。加班，可能使拖期现象暂时得到缓解，但是产生拖期的根本原因依然存在，一段时间之后，这些问题会继续暴露出来。
所以大多数情况下，如果不采取针对性的措施，而是单纯用加班赶进度的策略解决不了问题。管理人员应该慎用加班这个策略。
改计划，起码实事求是地承认了问题，但是对解决问题于事无补。项目经理应该是走向成功之路的引领者，而不是分析员、记录员这样被动的角色。
其实无论加班还是改计划，都没有解决问题。项目管理者发现项目拖期，应当分析问题的真正原因，然后对症下药。该返工的返工，该培训的培训，该招人的时候招人，甚至必要的情况下终止这个项目，以免更大的损失。
项目管理者的真正挑战，不是发现问题和记录问题，而是预见问题、控制问题和解决问题。


6 项目管理过程中经常出现过哪些conflicts?
1）. 进度（Schedule）在项目任务的时间安排、先后顺序及安排方面存在不一致的意见
2）. 项目优先级（Priorities）项目参与者在活动和任务的优先级上观点不同
3）. 资源冲突（Resource）项目团队成员安排与其他领域人员安排方面的冲突
4）. 技术意见与执行情况的冲突。在技术问题，执行规范和技术权衡上的不一致
5）. 管理程序（Administration Procedures）在项目如何管理问题上发生的管理导向和行政导向的冲突
6）. 成本（Cost）在设计工作分解结构上，来自支持部门的成本估算上的冲突
7）. 个性(Personality)人际关系方面的冲突


7 如果你明天开始正式接任这个职位，你希望能够获取哪方面的信息呢?
1）.岗位相关的部门内部组织架构关系以及与其他部门接口人信息。
2）.所负责产品的以前，现在和将来。
3）.岗位的绩效考核状况和公司级别的制度



8 成功的团队有哪些特点?
    （1）明确的目标。团队的每个成员可以有不同的目的、不同的个性，但作为一个整体，必须有共同的奋斗目标。
　　（2）清晰的角色。有效团队的成员必须在清楚的组织架构中有清晰的角色定位和分工，团队成员应清楚了解自己的定位与责任。
　　（3）相互的技能。团队成员要具备为实现共同目标的基本技能，并能够有良好的合作。
　　（4）相互间信任。相互信任是一个成功团队最显著的特征。
　　（5）良好的沟通。团队成员间拥有畅通的信息交流，才会使成员的情感得到交流，才能协调成员的行为，使团队形成凝聚力和战斗力。
（6）合适的领导。团队的领导往往起到教练或后盾作用，他们对团队提供指导和支持，而不是企图控制下属。


9 在你以前的项目管理工作中，你碰到最大的困难是什么？
(1) 自身知识包括专业和管理的不足，这个需要利用各种时间进行充电。
(2) 各方不配合，相互推诿，特别是甲方内部，各种关系错综复杂包括甲乙不分。
(3) 工程进度不好控制，无论天气原因还是人为因素，很少有工期提前结束的，虽然工期早就做出预留。大会小会都要做好挨批的准备。
(4) 后期验收调试责任不明确，都想推脱责任。


10 软件开发面临的问题都有哪些?
1)  软件开发是高风险、高投入的项目
2)  开发时间长、成本高
3)  无法证明正确性
4)  维护代价高
5)  开发、维护难于度量 等等
6)  偏激看法：凡是软件开发项目就不可能按时完成。


11 软件项目失败的主要原因有哪些?
1) 项目经理实战经验不足
项目经理都是从企业高级软件工程师和高级构架师提升来的项目经理职位，因此不可避免的造就了这样的项目经理过分集中于技术上，从而忽视用户的角度去分析。以技术为主的应该将重心放在IT项目交付上，以商业为主的要满足用户的商业目标的需求。
2) 项目计划不够合理
项目计划过程中存在不合理假设和风险预测不足导致项目失败的主要因素，在计划过程中必须留时间处理不可预知的问题，因此在任何项目过程中各种无法预知的都应该预留10%的时间来应对。
3) 需求不确定性
需求分析和开发过中不断的进行修改与变更，需求在初期的过程中对需求定义阶段出现很多不确定的因素，本可以避免的错误在后期过程中影响进度和预算等情况，从而导致项目失败，还有就是开发过程中需求变更处理机制的不合理，麻木进行用户满意度追求，导致附加功能不断增加，原有设计不停变更等，以致于超出预算成本导致项目失败。
4) 项目测试不足
项目开发过程中项目经理经常牺牲项目测试时间压缩几天内完成项目测试，从而导致项目测试结果不到位，用户也放弃测试与检测的责任，开发人员关注系统的性能从而对结果的商业需求满意度缺失导致致命的错误。
5) 无项目时间节点
项目没有具体的开始时间和结束时间，会导致项目在永远不确定的时间无休止的进行，项目成员疲惫最终项目失败。因此必须明确项目何时开始何时结束。
6) 领导者经验不足
项目成功的关键在于领导而不是过多的管理制度，领导需要卓越技能和丰富的经验以及职能以外的奉献精神，也需要激发和带领团队的领导气质。


12 什么是猴子管理法则？
为什么有些领导总是看起来那么忙？这是因为他们不懂得猴子管理法则。猴子管理法则通俗地说，就是每个人背上都有一只猴子，这只猴子代表着对自己承担问题的解决责任，如果下属学会解决自己的工作问题，领导就会有更多属于自己的时间去思考自己的问题。
（1）打断下属负面的“依赖”神经链。
（2）训练了下属分析问题、全面思考问题的能力。
（3）让下属产生信心与成就感。他会觉得自己居然也有解决复杂问题的能力。越来越有能力的下属能越来越胜任更重要的任务。
（4）激发下属的行动力。
（5）你将因此不必照看下属的“猴子”而腾出更多的精力去照看自己的“猴子”。
（6）该下属做决定的事，一定要让他们自己学着做决定；
（7）做决定意味着为自己的决定负责任。不想做决定，常常是潜意识里他不想承担责任；
（8）下属不思考问题、不习惯做决定的根源一般有两个：其一是有“托付思想”，依赖上司或别人，这样的下属不堪大用；其二是上司习惯代替下属做决定或喜欢享受别人听命于自己的成就感，这样的上司以及他所带领的团队难以胜任复杂的任务；
（9）让下属自己想办法，做决定，就是训练下属独立思考问题的能力和勇于承担责任的行事风格。



13 管理团队的思路
（1）团队的组成
    在现代企业管理中, 团队管理同样具有十分重要的地位和作用。团队精神是企业真正的核心竞争力所在, 是企业的灵魂,缺乏“团队精神”的群体不过是乌合之众,如同一盘散沙一般没有任何凝聚力。
    所谓团队，是由一群不同背景，不同技能及不同知识的人员组成的，通常人数不多，他们分别来自组织中的不同部门，为了某一特殊的任务而工作。团队中通常有一人为领导人，在团队存在期间，
	长期作为团队的领导人，但所谓领导是按工作的逻辑而领导，并无主管与部属之分。任何机构 有不常见的临时任务时，均曾采用过组成团队的方式。这种团队虽然是一种临时组织，但团队组织本身，却可能是长期的。团队的成员也许因任务的不同而有所不同，但团队组织的基础却可以保持不变。随着任务变了，团队的成员可能变动，甚至同一成员可以归属于两个以上的团体。
	随着知识经济时代的到来，各种知识、技术不断推陈出新，竞争日趋紧张激烈，市场需求越来越多样化。在很多情况下，单靠个人能力已很难处理各种错综复杂的关系，所有这些都要求企业人员组成团队加强沟通共同合作完成。但是，团队的规模和结构的设计往往是困扰企业的大问题：团队成员过多，容易产生交流障碍，削弱团队凝聚力，降低团队决策效率，团队成员过少，则容易形成“一言堂”，决策失去客观公正性;团队成员背景经历趋同，容易出现以偏概全的现象，但是如果团队成员的背景差异过大，容易造成不易沟通的现象。
	
	研究结果表明：团队的人数不宜过多，7-9人为最佳，并且组成人员应具多样性，即团队成员最好具备不同的资历背景。这样可以使团队成员在知识结构上具有互补性。

（2）团队的特点
    团队管理具有强大的威力,能使各个本来分散的个体和具有不同能力,不同个性的人组织成一个有共同目标的相互协调的整体。 这一团队管理的能力并不是他的所属成员能力的简单算术和,而是不论从数量上还是从质量上都远远超过原有成员能力的新的力量。 就如同一根由无数细线组成的绳索,单根细线的承载量是有限的,但是一旦它们被拧成绳索,其承载力却不可小视。但如果这一团队管理发挥得不好,反而会使成员力量发生内耗。 团队管理就是要具有不断改善,不断革新的精神,使每个人的才能不能停留在原有水平上,而是不断的发展和增强,从而起到1+1>2的效果。 同时, 在团队里每个人都能知道整个团队的工作，因此也都能对整体负责。 而且团队易于接受新观点和新的工作方式，因此团队具有极大的适应性。
　　团队管理也有许多缺点，倘使团队领导人/小组组长不能确立明确的任务，就会降低团队的工作效率。团队工作有赖持续性地注意其管理，注意其成员之间的关系，注意其个人职务的分配，注意于解释，筹划，沟通等，因此所有成员均须耗费大部分精力，以维持业务的正常进行. 此外团队中的成员虽然人人都能了解整个团队的共同任务，却不一定了解其基本的特定任务，而且团队经常由于疏于自律和疏于负责而失败，而且由于小组成员和小组领导之间不存在隶属的组织关系，此种失败率很高。 因此团队的成功要求极高度的自律和团队协作精神。这种自律和协作精神要求所有团队成员能顾大局,摒弃部门差异, 形成一个整体。

（3）管理思路
　　(一) 专业分工与协作相结合的原则
　　现代企业管理管理工作量大，专业性强, 应按照专业不同进行不同分工，但是一项工作的完成往往涉及不同的专业科室。这就要求不同专业和科室之间充分合作发挥团队精神,协调配合。分工与协作是社会化大生产的客观要求，不仅生产操作要有个分工协作，企业管理也要实行专业分工，各司其职有利于提高工作效率和工作质量。 

　　(二)分工要适当，不是越细越好
　　在设置不同组织结构时，分工要适当，不是越细越好，分工过细扯皮的事情就多，工作环节增加而引起工作流程延长，领导者因忙于协调组织中不同部门和成员的相互关系而难以集中精力抓大事，这势必会削弱分工带来的好处，眼科医生不看耳疾这是合理分工，但左眼科医生不看右眼疾就是分工过细，解决扯皮的事情关键是整个团队或成员要有团队精神，朝着共同的目标努力。

    (三)加强工作的计划性
　　计划就是对整个项目的进展进行总体规划，计划包括制定计划，执行计划和检查计划的执行情况三个阶段。搞好计划的前提条件是对计划在实施过程中可能遇到的情况进行合理预测并制定相对预案, 常用的编写项目计划的形式有甘特图表法(GANTT CHART)和 微软公司项目计划软件MicroSoft project。

　　(四)加强队团队的有效控制
　　团队活动是为了实现团队目标，目标确定后就层层分解，落实到组织的各个单位甚至个人，主管人员怎样才能知道这些单位和成员的工作是否有助于实现目标呢?这就需要控制工作。控制(CONTROL)是对计划的监督，管理进度的跟进及改善，并适时地校正偏差，这种偏差包括计划制定偏差和计划执行偏差，控制工作是指主管人员或小组组长对小组成员的工作进行测量，衡量和评价，并采取相应纠正措施的过程，   因此控制包括三个基本步骤，拟定标准，衡量成效，纠正偏差。

　　(五)加强团队的组织学习能力
　　作为一个管理人员,无论是企业的管理者,还是部门主管或跨部门功能小组组长,必须充分认到学习在组织决定自己目标是的作用.必须弄清楚自己需要智慧和这些智慧的源泉，必须调整学习以达到创新和变革的目的，必须了解打算进行哪些活动和采取哪些措施才能完成项目达到目的。

　　(六)加强团队成员间的沟通
　　沟通是指信息交流的过程，是指将某一信息传递给客体或对象，以期得客体或对象作出相应反映的过程，如果将信息传递给了对方，但对方并没有相应的反应，则是沟而不通，沟通是一个双向性的过程,在企业管理和团队管理中具有十分重要的作用。加强沟通，开诚布公。显然，较大差异的学术背景、性格特征和工作经历等因素先天决定了团队成员在决策时不可避免会产生一定的矛盾和冲突，因此调和这些矛盾和冲突的最有效方法，就是鼓励组织内部自由地沟通和讨论，集思广益。

　　(七)采取必要的激励措施
　　激励是指管理人员促进诱导小组成员形成动机，并引导行为指向目标的活动过程。由于人们一般是跟随那些他们认为有助于达到个人目标的人，因此管理人员应了解什么最能激励下级，以及这些因素如何发挥作用。
　　1、 建立团队协作机制。赋予团队一定的自主决策权，促进员工互相学习、协作的精神。
　　2、 建设流畅的工作成绩反馈机制。良好地工作成绩反馈机制，不仅满足员工的心理诉求，而且还是对他们今后工作改善和提高的最好帮助。
　　3、 鼓励员工参与决策的积极性。员工如果也能有机会参与到决策过程，那么他们将会具有更强烈的责任心、更积极的工作态度及更高涨的工作热情。
　　4、 鼓励员工的创造力。为员工搭建一个能展示他们能力的舞台，创建一个员工勇敢分享新想法的工作氛围，并对员工的创新给予一定的支持力度。
　　5、 采取有效的绩效评估体系。

   （八）关注下属的职业生涯
　　1、点燃下属的激-情，多一份自信。
　　2、为下属创造学习机会，创新性开展工作。
　　3、鼓励下属的自主思考力和团队协作精神。
　　4、根据个性调整工作岗位，做自己适合的工作。
　　5、上司的小题大做与大题小做，让下属走正确的路。

   （九）关注下属的精神需求和心路历程
　　1、塑造和-谐温馨的家庭氛围。
　　2、理解信任、支持鼓励，做下属坚强的后盾。
　　3、科***用表扬和批评，
　　4、爱要讲原则、有责任，制度就是一把尺子。
　　5、利用下属纪念日的机会增进感情。
　　6、形成营销团队与下属家庭之间的互动，密切联系。



14 绩效考核
（1）自评
首先自己给自己打分，描述自评

（2）相互评
各自评分

（3）兄弟部门评
其它合作部门人员评分

（4）绩效指标 

评估指标	衡量标准	计分方式
(事实数据+360匿名调查+总监评分)	权重	分值区间
			T2
有经验者	
工作业绩	工作质量
交付的工作产出的质量，包括文档、代码等，以测试发现的Bug数、线上Bug数、上线成功率等综合评定	T2: 工作产出质量符合上线标准	事实数据	25%	0~100
	工作中的创新度
技术创新意识，创新性方案，能有效提升产品的KPI	T2: 能提出创新性方案	总监评分	5%	0~100
	工作计划与完成率	T2: 对指定的工作任务能科学合理的安排	事实数据	25%	0~100
	问题解决率
技术性问题、线上故障的解决率	T2: 日常问题在他人协助下能够解决	事实数据+总监评分	5%	0~100
个人能力	沟通协调能力	T2: 能和他人互动交流，倾听他人的观点并给予有效反馈	360调查+总监评分	5%	0~100
	专业知识与技能
个人开展工作所需的知识技能	T2: 能独立开展工作并解决一般性问题	360调查+总监评分	15%	0~100
工作态度	规范性、主动性、积极性与责任感
对规范的遵守，主动承担工作任务，积极学习新知识技能	T2: 能承担一些领域外的工作任务	总监评分	10%	0~100
	团队合作
团队荣誉感，团队精神，分享知识	T2: 乐于助人，积极配合团队工作	360调查+总监评分	10%	0~100
合计				100%	



（5）面谈（找出客观事实说出突出点和不足的地方 ）  
收集资料，面谈指出优点和不足的地方 



15 晨会&汇报
每天或者每两天召开部门晨会，紧急时候可临时召开会议，每天及时向上级汇报情况 

01贝蜂&贝蚁 项目晨会记录
名称	工作日期	昨天工作回顾	今日工作计划	完成情况
曹智军	2018-1-1			
	2018-1-2			
	2018-1-3			
	2018-1-4			
	2018-1-5			
肖云飞	2018-1-1			
	2018-1-2			
	2018-1-3			
	2018-1-4			
	2018-1-5			

02 贝虎晨会记录
名称	工作日期	昨天工作回顾	今日工作计划	完成情况
向磊磊    	2018-1-1			
	2018-1-2			
	2018-1-3			
	2018-1-4			
	2018-1-5			
刘宏羽	2018-1-1			
	2018-1-2			
	2018-1-3			
	2018-1-4			
	2018-1-5			




16 总结性资料
平时总结每个成员的优缺点，记录下来，后面好写评语 
  liao：同步代码问题，自测试观念缺乏，反复测试，不能一次性好。
  sun: 主动性好
  huang :效率偏低，态度很好，积极主动。
  peng: 编码规范，首字母大写，空指针等，上班爱迟到，偶尔睡觉 。



17 整体把控
制定里程碑
及时发现风险

一、需求地址
运营系统V3.2
原型V3.2

二、版本开发安排 
 3.2版本总共包含：需求分析/需求串讲（24）+概要设计/设计评审（33）+研发/联调/自测试（154）=211人天，
 其中前端投入人力2.5人，总工作量51人天；后端投入8人，总工作量 160人天。
 项目周期：211/10.5 = 20.09天，由于4.26-4.28投入一半人力，另外一半修复3.1版本bug和保障3.1上生产。
 实际项目周期：2018-04-28 --- 2018-05-30，计划05-31日转测试。   
编号	需求名称	功能点拆分	需求提出人	开发范围	需求+设计+研发	总工作量	分组	负责人	开始时间	结束时间（自测）	  测试时间
（测试和验收）	生产时间	备注	当前进度
1	运营系统 — 优化聚引客流程V3.2	1 新增推广提案审核流程   5
2 新增微博充值流程 4
3 新增推广上线与监控优化流程  4 
4 新增审核设计稿流程和简化推广素材输出任务节点  5

	魏穗明	前端+后端	8+10+55	73	1组	曹智军流程图
肖云飞 
 	2018-04-26	2018-05-30	2018-05-31			需求分析
2	运营系统 — 聚引客管理 — 优化推广资料管理V3.2	1  推广资料管理页入口更改到聚引客管理下，聚引客管理—推广资料管理  0
2  个人浏览权限和全部浏览权限 2
3 操作日志记录和查看 2
4 文本类信息资料修改 1
5 文件类信息资料修改 1
6 卡券信息资料修改 1	魏穗明	前端+后端	1+1+7	9	2组	后端：邓鹏
前端：徐生延	2018-04-26	2018-05-30	2018-05-31			需求分析
三、里程碑节点
2018-4-27~2018-4-28：需求串讲复述
2018-5-2~2018-5-3：概要设计
2018-5-4：概要设计评审
2018-5-24：代码评审 

里程碑	功能	分组	责任人	计划完成进度
5.15	新增推广提案审核流程	1组	肖云飞	开发50%,联调0%
	优化任务节点	1组	肖云飞	开发50%,联调0%
	新增微博提审流程	1组	肖云飞	开发0%,联调0%
	新增推广上线与监控优化流程	1组	肖云飞	开发50%,联调0%
	新增审核设计稿流程和简化推广素材	1组	肖云飞	开发50%,联调0%
5.22	新增推广提案审核流程	1组	肖云飞	开发100%,联调80%
	优化任务节点	1组	肖云飞	开发80%,联调80%
	新增微博提审流程	1组	肖云飞	开发70%,联调50%
	新增推广上线与监控优化流程	1组	肖云飞	开发100%,联调80%
5.29	3.2所有功能	全体	/	开发100%，开发100%
5.30	3.2所有功能	全体	/	部署测试环境，自测试修改问题

四、需求变更记录

2018年4月26日：
1 3.1版本小程序触发条件变更，5月4日发版，开发+联调新增1.5人天 .
2 3.2版本新增删除门店逻辑，新增3人天。
3 3.2版本流程激活小程序模块和服务进度变更 ，开发+联调新增6人天 。
评估结果：3.2版本新转测时间延迟一天，新的转测时间是：5月29日。


2018年5月7日：
1 小程序前端，记住上一次登录的Tab体验优化,开发+联调新增2人天 .
2 掌贝智慧服务中心（小程序）前端支持通过用户名登录，开发+联调新增2人天 .
3 oem里有赠送短信的开启功能，而这个功能依赖订单里的已购的商品信息；掌贝进件后，需要再推送商户ID与订单信息到oem激活该短信功能，开发+联调新增4人天 。
 4 “同步功能”完善 ,11 人天 
评估结果：一共19人天，3.2版本新转测时间延迟2天，新的转测时间是：5月31日。

2018年5月9日：
1 优化制作卡券的任务节点环节，开发+联调新增1人天 .
2 优化“经营诊断与营销策划”任务内容，开发+联调新增2人天 .
3 推广图片素材新增“下载图片”入口，开发+联调新增3人天 。
评估结果：一共6人天，延时半天。

18 招聘交接
1 口头交接和文档交接，文档上传到wiki
2 交接人可以是新入职人员也可以是其他老员工
3 交接人确认交接完毕后考虑最后一天 


19 项目经理所必需掌握的知识
类别	职责/要求	点评
专业技术	精通多种编程语言和技术框架；精通中间件技术；熟悉Android及Hadoop。	项目经理必须是技术专家，也许你自己不用写代码，但你必须能指导下属，解决技术问题。必要时，还得参与做系统架构和系统分析。
管理技能	项目整体管理；成本管理；进度管理；资源管理；团队管理；沟通协调能力。	难道风险管理、质量管理、采购管理就不需要了吗？九大领域一个都不能少。
个人内在	适应能力；应变能力；抗压能力；责任心；分析问题解决问题的能力。	①     适应能力：像变色龙。能适用不同公司文化和氛围，不同性格的同事，特别是上司。②     应变能力：像变形虫。项目过程中会出现各状况，必须能调整自己、调整计划，以适应变化。③     抗压能力：像驴子。项目管理压力很大哦，天塌下来要也扛着。④     责任心：项目出问题，基本上责任都是你的，决不可推卸责任，勇敢的去解决问题吧，不要辜负领导的重托。⑤     逻辑思维：项目经常会出问题的，所以你必须思维清晰，能够客观的分析问题和解决问题。
相关经验	4年开发经验+2年管理经验	老板可不想冒险，把项目给你去做试验田。



20 项目经理所必需能力
1）风险掌控能力：一个优秀的项目经理能够熟练的运用项目风险管理过程，进行风险计划，识别，分析和开发应对策略，准确地预测到项目的风险，采取正确的风险规避措施。一个有经验的项目经理，无时无刻不关注项目的风险；项目中有各种各样的决策，每做出决策，就要清醒认识带来的新风险。

2） 团队建设和人员激励能力：团队建设方面，根据项目团队的不同阶段，项目经理建设团队的工作重点也不同， 项目团队组建初期，要介绍项目团队每个成员，他们每个人的角色和职责，以及对成员的期望；因为是初期，需要提供给团队所需的信息和支持，对成员的不确定性的问题要做出积极会与回应。理清成员的资质，帮助团队成员互相了解；给予成员指导和培训。随着团队开始运转，成员也开始了自己的工作，由于成员之间尚未建立起信任关系，冲突在所难免，项目团队进入动荡阶段，这一阶段的特点是竞争和冲突，项目经理关注的重点是解决冲突：及时识别冲突并处理冲突，继续表明团队和个人的期望，鼓励成员对争议发表自己的看法；鼓励成员互相倾听和参与决策。经过动荡期后进入团队的规范阶段，大家彼此信任，并互相帮助，项目经理需要完善团队的规范，形成团队文化。再之后项目进入高产阶段，项目经理重点是关注提高生产率，对成员进行必要的授权，给予成员挑战性目标。团队解散阶段：项目接近收尾时，团队行将解散，项目经理要进行对团队和成员的表彰，召开总结大会，做好知识管理工作。优秀的项目经理会采取不同的员工，不同的激励方式，对于指挥型的成员，要给予授权，关系型的员工，给予一些需要协作方面的工作，技术大牛，要给予技术含量高的工作；勤恳型的呢，要给予一些重复性的工作。

3） 沟通能力：沟通既是素质也是能力，在上面内容谈的比较多了，不再赘述，一个优秀的项目经理知道什么类型的信息给什么样的项目干系人，有些不能让客户知道的东西不需要让客户知道；还要具有会议管理能力和演示PPT的能力。

4） 谈判能力：几乎每个项目经理都会遇到需要谈判的情况，这里不仅仅在项目合同方面，比如客户需要提前工期啦，需要变更需求啦等等，作为优秀的项目经理就需要沉着冷静，深度分析和评估双方谈判的目的和目标，根据实际情况，有理有据的进行谈判，大家都各让一步，达到谈判目的。

5 问题解决能力：优秀的项目经理善于能够认识问题的本质，能够找出什么是解决问题的关键。


22 代码质量控制：
  （1）制定编码规范，分层，健壮，稳定，扩展，伸缩，性能，安全，维护
  （2）概要设计评审 
  （3）代码review 
  （4）sonar扫描 



23 技术思维和管理思维对比 
比较方面	技术思维	管理思维
关注中心	以过程为中心的思维	关心每项任务本身，而不是整体目标。不重视计划，对任务缺乏控制。	以目标为中心的思维	以终为始。关注整体目标、实现的路线、影响目标实现的因素、各种事件对目标的影响，区分重点。
事物结构	局部思维	过于关注细节，对整个项目工作的内容、完成路线没有概念。上来就干，工作缺乏计划性、条理性。	整体思维	采用结构化分析方法，自顶向下，先整体后局部。有时亦采用头脑风暴，先将细节展开再归纳。
逻辑思维	以机器为中心的思维	思想单纯，性格直率。在人际问题上过于讲究逻辑。	以人为中心的思维	人是执行项目的主体，关注事情本身，更关注人的价值。学会包容，能与各种不同情格的人打交道。
决策依据	完美思维	不关心进度和成本，只关心完美的功能和代码，并视之为艺术。经常对上一任的工作推倒重来。	平衡思维	拒绝渡金，项目不需要艺术。在进度和质量之间取得平衡，在员工个性与团队凝聚力之间取得平衡，在员工、项目、公司和客户之间取得平衡。
人际关系	个人思维	以个人为中心，单兵作战，依赖个人能力。个性固执，工作方法简单。	团队思维	你不是一个人在战斗，发挥每个成员的作用比个人埋头苦干重要得多。关注团队分工、配合以及士气和凝聚力。




24 项目管理九大领域 

这就是项目管理的九大领域：整合管理、范围管理、时间管理、费用管理、质量管理、人力资源管理、沟通管理、风险管理、采购管理。

1）整体管理
　　项目的整体管理，或者说是综合管理也不为错，它是综合运用其他八个领域的知识，合理集成与平衡各要素之间的关系，确保项目成功完成的关键。
　　项目的整体管理包括三个主要过程：
　　项目计划制定：即收集各种计划编制的结果，并形成统一协调项目计划文档。
　　项目计划执行：通过执行项目计划的活动，来实施计划。
　　整体变更控制：控制项目的变更。
　　项目经理负责协调完成一个项目所需的人员、计划以及工作，统领全局，带领团队实现项目的目标；当项目目标之间或参与项目的人员之间出现冲突时，负责拍 板定夺；并负责及时向高层管理人员汇报项目进展信息。总而言之，项目经理主要负责项目的整体管理，这也是项目成功的关键。

2）项目范围管理知识
　　项目范围的不确定，会导致项目范围的不断扩大，作为项目经理，在项目开始时，就要对项目范围拿出项目干系人都认可的、理解无歧意的范围说明文档——项目章程。然后为了保证项目的实施，明确项目组成员的工作责任，还必须分解项目范围，使之成为更小的项目任务包——工作分解结构（WBS）。

3）项目的时间管理知识
　　项目的时间管理，就是确保项目按期完成的过程。首先要制定项目的进度计划，然后是跟踪检查进度计划与实际完成情况之间的差异，及时调整资源、工作任务 等，以保证项目的进度实现。在跟踪过程中，要及时与项目干系人进行交流，以及时发现范围的偏差，而产生时间与进度上的差异，或项目组成员有意或无意识的虚 报了项目完成情况，导致进度的失控。
　　具体包括以下内容：
　　活动定义：从WBS分解而来；
　　活动排序：明确活动之间的依赖关系；
　　活动历时估算：估算每项活动的时间，可以PERT方法进行；
　　利用PROJECT2002等工具软件，协助项目的时间管理；
　　利用甘特图帮助跟踪项目进度；
　　利用网络图及关键路径分析，协助确定完成日期上的重要性或调整工期对项目工期的影响，以及处理关注的焦点活动。需要注意一点，以前学习项目的时间管理工具及方法以后，就以为可以实现对项目的跟踪控制了，其实不然，这些工工具都是通过人来发生作用，活动也是由人来完成的，因此项目经理不能把太多心思花在工具上，而是学会利用工具来协调人与资源的矛盾冲突。

4）项目的成本管理知识
　　对于项目经理在成本管理方面，就是要努力减少和控制成本，满足项目干系人的期望。其过程包括：
　　资源计划：即制定资源需求清单；
　　成本估算：对所需资源进行成本估算；
　　成本预算：将整体成本估算配置到各个单项工作，建立成本基准计划；
　　成本控制：控制项目预算的变化，修正成本的估算，更新预算，纠正项目组成员的行动，进行完工估算与成本控制的分析。
在成本管理中涉及很多财务管理的概念、术语、基础理论及方法与工具的使用，作为项目经理，对这些内容要熟悉，特别是挣值分析的相关术语及简称，如：BCWS、BCWP、ACWP、CV、SV、CPI、SPI等等，不光要了解这些术语的涵意，还要掌握他们的计算公式。

5）项目人力资源管理知识
　　项目的人力资源管理就是有效发挥每个参与项目的人员的作用的过程。项目的人力资源管理过程包括：
　　组织计划编制：形成项目的组织结构图；
　　获取相关人员：其中重点是业务相关人员；
　　团队建设：明确每个项目干系人的责任，训练与提高其技能，实现团队的合作与沟通。
　　因为与人发生关系，其中首先是要明确各自的责任，这一点计划编制时就要明确，可以通过项目管理软件帮助项目经理提高效率，并能及时发现任务分解的合理性，最后形成合理的任务分解表。
同时，要通过有效的激励方法来帮助项目成员实施项目计划，提高效率。项目是通过团队共同努力实现的，注意充分发挥团队的作用，使团队成员各尽所能是项目经理的挑战。在处理过程中，争取做到对事不对人，通过有效的会议来帮助项目实现沟通、检查以及目标实现。

6）项目的质量管理知识
　　项目的质量，理解为项目满足客户明确或隐含的要求的一致性程度。注意这里包括明确的要求，也包括隐含的要求。这对IT项目来说，如何满足用户隐含的质量要求，可能是IT项目质量失败的重要原因。可能所开发的系统符合需求说明中的要求，却与用户实际的要求（包含隐含的需求中），相差很大，导致不一致，结果导致IT项目的失败。
　　现代质量管理经过了一个发展过程，目前已建立起相对完善的质量体系，国际组织也有相关的质量文件，以评审普通的生产质量，如ISO2000系列质量标准；对软件的生产质量，也有一些评价模型，如SQFD模型、CMM软件成熟度模型等等。其中CMM成熟度模型分成五个层次：自发的、简单的、有组织的、被管理的及适应的，分别标识为不同的级别。
　　对于项目管理需要制订质量计划，并应用质量保证的工具确保质量计划的实施。在质量控制的过程中，有许多现成的工具与方法，如帕累托分析、统计抽样和标 准差等。要提高项目的质量，必须在领导中形成质量意识，通过建立一个好的工作环境来提高质量，通过形成质量文化来改进质量，是全面提升项目质量管理的关键 因素之一。
在以往所经历的项目中，项目的质量管理基本上没有得到重视，公司每年都在开展QC活动，该活动的目的就是改进质量，但活动成了科技创新活动，而更多的项目实施过程中，如何开展质量管理，却未能有所体现，这也是值得探讨的问题。

   代码质量控制：
  （1）制定编码规范，分层，健壮，稳定，扩展，伸缩，性能，安全，维护
  （2）概要设计评审 
  （3）代码review 
  （4）sonar扫描 


7）项目的沟通管理知识
　　项目的沟通管理非常重要，对项目经理而言，就如同前线指挥需要情报管理一样，这是使整个项目组掌握项目信息，实施其他管理手段的基础，所有的控制都有基于沟通基础之上的。
　　在项目的开始，需要编制沟通计划，包括什么时间、将什么内容、以什么样的格式、通过什么样的方式、向谁传递。在项目的沟通中，可以采用书面报告、口头报告或非正式的交流，各种方式有利也有弊，关键看是否有利于沟通的效果。沟通的复杂程度随着对象的增加而快速增加，因此要通过适当的工具和手段，使面对面的沟通控制在一定范围之内，尽量减少因无效沟通而给项目管理带来的负责影响。在沟通中，会议是有效形式之一。很多业务员人员喜欢通过会议，以简单的形式化的语言描述项目的进展与项目中碰到的问题，而不喜欢技术化的图表与文档。电话会议，视频会议，面对面沟通 。

8）项目的风险管理知识
　　当因为未能做好风险管理，导致项目的风险发生时，项目干系人将难以一下子接受风险发生的事实以及风险所带来的损失，需要用更多的时间来调整整心理状态，才能恢复对项目的实施。项目的风险管理不仅是在项目进行过程中，有效避免风险的发生；而且能在风险发生时，帮助我们用正确的心态去面对，而不会手足无措。很多项目的失败，是 因为风险发生时，对项目干系心理上造成的伤害，导致失去主观判断能力，而作出错误的决策。从这种意义上讲，项目的风险计划的制定主要是为提高项目干系人的 风险意识，只要有了足够的风险意识，风险识别全面与否，在有些项目中可能重要性反而不是太明显。
　　风险识别可以采用头脑风暴法、经验法则等方法，在识别这些风险因子之后，可以对这些因子加上权重，最后可以计算出项目成功的概率，并能据此决策项目是 否应该开展、继续或停止。识别风险因子之后，紧接着就是制定风险应对措施。根据风险发生的概率，产生的风险成本与收益，决定相应的应对策略，如风险处理、 风险接受、风险改善等等。
实际工作中，可能识别到存在的风险，但却不能加以正确处理。风险就这样被层层传递。如因用户参与不够，导致需求不正确，进一步产生工期估计的失误，结果是计划的偏差，最后整个项目的结果产生偏差。因此，要注意从风险的源头抓起，防止风险的层层放大。

9）项目的采购管理知识
　　采购就是从外界获得产品或服务。对于IT项目而言，采购变得越来越重要。目前绝大多数的IT项目都离不开采购管理，而且很多项目的主要内容就是设备采购或咨询采购，对于企业而言，能否做好采购管理是保证项目成功的重点内容。
　　有效采购管理包括以下过程：
　　编制合理有效的采购计划：这是项目管理的一个重要过程，即确定项目的哪些需求可以通过采购得到更好的满足。在采购计划中，首先是决定是否需要采购、如何采购、采购什么、采购多少、何时采购等内容；
　　编制询价计划：即编制报价邀请书RFQ或招标书；
　　询价：进行实际询价；
　　开标：评估并选择供应商；
　　管理：对采购合同进行管理；
　　收尾：对采购合同进行收尾。

在整个过程中，容易忽视的两个过程，一是采购计划，二是合同收尾。采购计划的编制，是采购管理整体按需求进行的前提，如果这一步做不好，其他都是白费劲；而在采购的合同收尾过程中，最容易忘记或做不到的就是采购审计。至于供应商的选择等过程，在IT 项目中，往往会过分重视技术，而忽略管理与成本。其实，管理与成本决定合同能否按期保持履行的前提。在我公司的实际情况中，一般项目以设备为主要成本时， 往往就不再考虑其他内容，而仅是作为一般的设备采购，交会器材部门实施。因为不光没能做到项目管理，亦未做到采购管理，所以这类项目虽然也实施完成了，但 项目的实施质量总令人不太满意



25 五大过程组
五大过程组与九大领域一样，同样体现了做事的逻辑，只不过角度有所不同：
●启动：确定是否要做，以及做什么 
●规划：打算怎么做 
● 执行：按照计划去做 
●控制：做对了没有 
●收尾：做完了收工 

　1）项目的启动过程
　　项目的启动过程就是一个新的项目识别与开始的过程。一定要认识这样一个概念，即在重要项目上的微小成功，比在不重要的项目上获得巨大成功更具意义与价 值。从这种意义上讲，项目的启动阶段显得尤其重要，这是决定是否投资，以及投资什么项目的关键阶段，此时的决策失误可能造成巨大的损失。重视项目启动过 程，是保证项目成功的首要步骤。
　　启动涉及项目范围的知识领域，其输出结果有项目章程、任命项目经理、确定约束条件与假设条件等。启动过程的最主要内容是进行项目的可行性研究与分析， 这项活动要以商业目标为核心，而不是以技术为核心。无论是领导关注，还是项目宗旨，都应围绕明确的商业目标，以实现商业预期利润分析为重点，并要提供科学 合理的评价方法，以便未来能对其进行评估。
　　
2）项目的计划过程
　　项目的计划过程是项目实施过程中非常重要的一个过程。通过对项目的范围、任务分解、资源分析等制定一个科学的计划，能使项目团队的工作有序的开展。也 因为有了计划，我们在实施过程中，才能有一个参照，并通过对计划的不断修订与完善，使后面的计划更符合实际，更能准确的指导项目工作。
　　以前有一个错误的概念，认为计划应该准确，所谓准确，就是实际进展必须按计划来进行。实际并不是如此，计划是管理的一种手段，仅是通过这种方式，使项目的资源配置、时间分配更为科学合理而已，而计划在实际执行中是可以不断修改的。
　　在项目的不同知识领域有不同的计划，应根据实际项目情况，编制不同的计划，其中项目计划、范围说明书、工作分解结构、活动清单、网络图、进度计划、资源计划、成本估计、质量计划、风险计划、沟通计划、采购计划等等，是项目计划过程常见的输出，应重点把握与运用。
　　
3）项目的实施过程 
　　项目的实施，一般指项目的主体内容执行过程，但实施包括项目的前期工作，因此不光要在具体实施过程中注意范围变更、记录项目信息，鼓励项目组成员努力完成项目，还要在开头与收尾过程中，强调实施的重点内容，如正式验收项目范围等。
　　在项目实施中，重要的内容就是项目信息的沟通，即及时提交项目进展信息，以项目报告的方式定期通过项目进度，有利开展项目控制，对质量保证提供了手段。
　　
4）项目的控制过程 
　　项目管理的过程控制，是保证项目朝目标方向前进的重要过程，就是要及时发现偏差并采取纠正措施，使项目进展朝向目标方向。
　　控制可以使实际进展符合计划，也可以修改计划使之更切合目前的现状。修改计划的前提是项目符合期望的目标。控制的重点有这么几个方面：范围变更、质量标准、状态报告及风险应对。基本上处理好以上四个方面的控制，项目的控制任务大体上就能完成了。
　　
5）项目的收尾过程 
　　一个项目通过一个正式而有效的收尾过程，不仅是对当前项目产生完整文档，对项目干系人的交待，更是以后项目工作的重要财富。在经历的很多项目中，更多重视项目的开始与过程，忽视了项目收尾工作，所以项目管理水平一直未能得到提高。
　　另外要重视那一类未能实施成功的项目收尾工作，不成功项目的收尾工作比成功项目的收尾更难，也来得更重要，因为这样的项目的主要价值就是项目失败的教训，因此要通过收尾将这些教训提炼出来。
　　项目收尾包括对最终产品进行验收，形成项目档案，吸取的教训等。另外，对项目干系人要做一个合理的安排，这也是容易忽视的地方，简单的打发回去不是最好的处理办法，更是对项目组成员的不负责任。
项目收尾的形式，可以根据项目的大小自由决定，可以通过召开发布会、表彰会、公布绩效评估等手段来进行，形式是根据情况采用，但一定要明确，并能达到效果。如果能对项目进行收尾审计，则是再好不过的了，当然也有很多项目是无需审计的。


26 管理放权
  解决Who的问题。虽然我们提倡项目经理要以身作则、亲力亲为，但并不是说每件事项目经理要亲自去做。对于下属可以胜任的事情，就把它分配出去。如果出现项目经理很忙、下属很闲的情况，那就说明项目经理你做得太多了，不要和你的下属抢事情做。
  
是不是任何事情都可以授权呢？理论上是可以，但由于资源的稀缺性，这种条件往往并不具备。至于什么可以授权，什么不可以，这要因项目而异，根据项目工作与资源的实际情况，两厢权衡之后才能决定。不管怎么说，授权不可过度，否则项目经理就成了甩手掌柜，实际也等于放弃对项目的控制权。


27 项目经理应该做的工作：
l 系统性工作由项目经理做，比如制定计划、安排任务、鼓舞士气、项目检查等，具体事务由下属去做。
l 重要的事情项目经理来做，紧急的事情让下属去做。
l 决策由项目经理来做，执行由下属去做。
l 下属能做的事由下属去做，否则由项目经理自己做或带着做。
  
  

28 如何对付琐碎的事情？
l 制定规则，约好时间讨论 
例如约定在指定的时间签单、讨论技术问题、反馈进展等，而不是随时进行。

l琐碎事情一起做
对于工作中的琐碎问题，不用急着处理，可以启动“碎片整理程序”，将其记录下来，在你不需要“炒菜”的时候一起处理。

l利用碎片时间
碎片时间并非不可利用，而是要安排合理的工作。几块大石头中间的缝隙，肯定塞不下另一块大石头，但放一些小石子或沙子还是没问题。例如与员工沟通、向领导汇报工作、检查员工工作、辅导员工、项目风险分析、项目目标回顾、发传真、收邮件等，这些工作就是小石子一样，利用小块小块的时间就可以完成。
  

29 用人原则 
1 喜欢提意见的人，可以让也负责质量管理。
2  能说会道的人，可以让他负责与客户沟通；
3 沉默寡言者，一般心思缜密，可以负责技术性较强的工作；
4 对于脾气倔强的人，应该安排确定性的、没有争议的工作交给他；
5 慢手慢脚的人，应该安排缓冲时间比较多的工作，不能安排关键路径上的工作；
6 思维敏捷的人，可以安排紧急的任务给他。


30 项目管理人员职责
1、不断地识别项目干系人，并管理好项目干系人的期望。
   比如一个软件产品开发项目，可能的干系人包括但不限于：
   投资方希望通过产品赚钱
   产品用户希望产品好用、能给自己带来使用价值和良好的使用体验
   项目团队希望通过该产品体现自己的创造力、成就感，并收获劳动回报和能力提升
   政府机构希望该产品有着良好的社会效应
项目干系人不是一开始就能完全识别出来的，所以需要不断识别
要管理好项目干系人的期望，需要良好的沟通技能，要能换位思考，充分从对方的角度去理解与认识
注：项目干系人，其实就是项目相关的人员。这是项目管理理论中的术语。

2、组建和建设一支强有力的项目团队。
项目团队是项目成功的关键要素，组建团队、激励并持续建设团队、协调好团队内部的关系和任务分配、充分沟通，是项目经理必须一直要做的事情。
建设项目团队，包括了招募、培训、调配、指导等各方面的工作。

3、做好项目管理计划，充分管控项目的范围、进度、成本、质量、风险等要素。
项目的范围、进度、成本、质量、风险管控是项目管理的基本要素，也是项目经理要做的事情之一。当然，具体的需求调研及确认、系统架构设计、详细设计、开发、测试、变更、风险、文档、验收、交付、培训等等，甚至包括项目进度计划，都可以分解给项目团队成员来做，但项目经理要负责总体的管理和掌控，协调各方面的资源。

4、总结项目。
项目结束、产品验收交付后，项目经理的一个重要工作就是总结和分析项目的成败得失，尤其是充分总结经验和教训，作为自己、团队、所在的企业组织以后项目的借鉴和参考。

注：软件项目经理，如果过多地深入到产品设计、开发过程，而或多或少地忽略其真正应该专注和关注的职责，对项目有害无益。我们目前项目多，人少，每个项目经理都要参与到自己项目或者别人的项目中担负相应的工作，需要高效调整自己的工作计划，并每天执行和修正工作计划。




（二）、管理架构总图
1 专业知识
    (1)系统架构(Distributed/Microservice/JVM/Concurrent/Spring/DesignPattern)
    (2)基础技能(JS/DB/SE/EE)
    (3)支撑技能(大数据/云计算/人工智能/区块链 )

	
2 管理思路
	 (1)团队建设
	     <1>挑选骨干(3-5人挑选副手和骨干/6-15人分组责任制) 
		 <2>沟通渠道(团队活动/会议/聚餐/座谈会吐槽)  
		 <3>解决冲突(控制情绪/换位思考/交换意见) 
		 <4>人员管理(猴子法则/适当放权) 
		 <5>绩效考核 
		    考核方法：自评/相互评/兄弟部门评/复评/面谈/总结客观资料
			考核指标：本职工作/责任心/协作能力/积极主动/态度/技术突破/加班
	 
	 (2)项目管理
		 @@九大领域@@
			<1>整体管理(合理集成与平衡各要素之间的关系)
			<2>范围管理(干系人/业务/时间/外围系统)
			<3>成本管理(控制资源和成本)
			<4>质量管理(编码规范/设计评审/代码评审[健壮/稳定/性能/安全/扩展/复用/维护/配置/内聚/耦合]/SONAR扫描)
			<5>进度管理(晨会汇报/里程碑/识别风险)
			<6>资源管理(提意见-质量/能说会道-客户沟通/寡言-技术性强/脾气倔强-无争议/慢手慢脚-缓冲时间/思维敏捷-紧急任务)
			<7>沟通管理(需求分析/需求讲解/设计评审/代码评审/总结会/团队培训/原因分析会/启动会)
			<8>风险管理(需求分析和设计/技术调研/汇报)
			<9>采购管理(从外界获得产品或服务/报价邀请书/招标书)
			
		@@五大过程组@@
			<1>启动过程(要不要做/做什么)
			<2>规划过程(打算怎么做)
			<3>实施过程(按照计划去做)
			<4>监控过程(做对了没有/制定计划/安排任务/鼓舞士气/项目检查)
			<5>收尾过程(做完了没有)
			
		@@敏捷开发@@
(需求分析--需求评审--需求讲解--概要设计--设计评审--代码开发--代码评审--联调自测--测试验收--上线及支持--版本总结)

        
3 素质能力
     (1)身体素质(没有一天只干8个小时的项目经理。项目管理工作经常赶周期，赶进度，工作起来没日没夜，体力活)
	 (2)品德素质(对外与供应商客户打交道/对内需要跨部门整合资源/诚信的品德素质是基础)
	 (3)沟通能力
	 (4)应变能力(调整心态/调整计划)
	 (5)解决能力(冲突/问题/拍板/决策)
	 (6)组织能力(会议/活动/评审)
	 (7)处理能力(约好时间/重要紧急四个维度/时间碎片)
     (8)风险掌控能力

	 
4 岗位职责
     (1)识别项目干系人(干系人期望)
     (2)组建强有力团队(招募/培训/调配/指导)
	 (3)做好95工作(架构设计/详细设计/开发/测试/变更/风险/文档/验收/交付/培训)
	 (4)总结项目(问题原因/改进措施/吐槽点)




（三）、文化组织管理培训
一、文化之根
1 、文化本质：掌贝文化是掌贝人的基本必备属性，也是与其他群体的根本区别，更是掌贝人共有的标签和符号！	不同的企业，因为不同的业务环境、不同的组织形态、不同的创始人和管理者特质，会形成不同的企业文化。企业间文化各有差异，最重要的在于是否适用、是否落地、是否坚守、是否迭代升级。
2 、文化要求：人人必备、人人践行、人人传承，行为背后是文化的根源	文化是企业的根，一家没有文化承载的企业，很难走得很远，很难经历艰难。文化最终要依赖每个员工去践行，外化为符合文化的行为。
3 、文化三基石
	
【使命】：让天下没有难做的掌柜	流量升级项目，天下为范围，掌柜为对象，没有难做的掌柜为目标
【愿景】：成为商户与消费者连接的桥梁	让商户更好找到消费者
【核心价值观】：执行、极致、思考	决策分析基础，事前事中事后思考。
执行：使命必达，承诺必达；鼓励碰撞、不同观点，但一旦明确指令，则坚决执行；
极致：工作做到极致，给客户提供的服务做到极致；
思考：做正确的事，把事做正确；
4 、文化六准则
	
1）以奋斗者为本，奋斗是唯一正确的事，奋斗者是唯一正确的人！	承担工作内容多，勤猫奖；心中总有奋斗的原动力，对于业务的发展、个人的成长，总在追求不断进步；
愿意为了业务、个人的进步不断付出心力，敢吃苦，敢于不断跳出自己的舒适区。
2）以客户为中心，客户是我们存在的理由，是我们唯一的衣食父母！	服务好客户，例如聚引客运营中，通常时效承诺是15个工作日，但有时商户的确因为开业等原因上线周期很紧张，团队成员加班特殊帮客户赶上线时间。
3）以职业化为荣，一切以公司利益为准绳，开放透明分享为规矩！	以工作为核心，针对事情的探讨、争论，就事论事，不要带情绪、不要人身攻击。
4）以团队为核心，团队利益和荣誉至上，舍我求大我，服从团队！	当个人利益和团队利益有冲突的处理方法，友文在贝蜂项目2.0期间，为了保障项目进度，陪产假只休了两天。
5）以责任为使命，不推脱、不逃避、不罢休，勇于承担负责到底！	24小时随时解决问题，主动承担边界模糊的工作；对于有挑战、脱离自己舒适区的工作，舍我其谁，不怕承担
6）以执行为铁律，事必行、行必果，杜绝根除不动、慢动、乱动者！	行动力，积极主动的心态；聚引客2.0时50个案例输出，几个人连续近一周加班到夜里十二点以后，保障按时按质输出
5 、文化落地法
	
1）传道解惑谋共识	晨会，培训；对于新员工通过培训、导师指导，实现文化讲解和充分理解；日常工作中要持续坚守、引导正确的文化理解，匡正不符合文化的行为。
2）察言观色剖根源	分析行为的原因，平时观察员工行为，注意情绪态度变化
3）抓典型、树榜样	表扬和批评的权利和义务，肖云飞在执行、责任方面文化的践行突出，在团队中树立榜样
4）扣细节事件营销	裁判，明是非的能力，抓迟到事情
5）仪式性奖罚分明	年会颁奖，惩罚，产研季度奖，奋斗奖，挖虫，金点子，微创新
二、组织之魂	
1 、组织本质：结构清晰、责任明确、协作流畅的系统性群体	织结构清楚，不能是一盘散沙，明确责任主体，主动承担风险，协作就像篮球一样，单打独斗不能成大事，也不能持久。
2 、组织特性	
1）群体一致，组织全员整体必须有相对统一的味道和作风	同一个组织共性多，形成统一风格，每一个组织的作风不一样。
2）结构清晰，上下层次、左右分工各组织单元架构划分清晰	组织架构清楚明白，上下左右不能重复。
3）责任明确，组织单元必有管理责任人且管理责任明确	组织负责人需要明确，否则容易引起混乱，内部产生不团结的现象。
4）协作流畅，上下及左右需要主动积极协作保障业务流动	不仅仅是下级配合上级的协作，发现问题并且需要上级及时决策；横向业务线之间要有协作意识，比如积极回邮件，及时回复。
3 、组织五要求
	
1）尊重、认同组织特性	组织和个人相互认同才能走到一起，这是一个必然性，去除埋怨的行为，不认可组织的人早晚遭到淘汰。
2）融入、践行组织要求	组织不需要个性化，需要每个人融入组织的行为方式，及时吸收和跟进。
3）积极、争当组织表率	组织是一个公平的平台，作为一个群个体表率，对今后的职业发展也是不错的，出现一些边界模糊事项时，肖云飞主动承担，牵头推动负责。
4）发扬、传承组织文化	运营顾问每周服务理念口号视频
5）捍卫、维护组织形象	聚引客业务，客户说销售过度承诺时，策划专家首先表明销售不会存在这样的乱承诺现象，然后进一步沟通解决问题。
4 、组织三准则
	
1）个人服从组织，组织服务个人	因业务调整，李普政一年内数次涉及岗位调整，但均服从组织安排；组织也同时会兼顾李普政的个人成长和发展
2）个人贡献组织，组织成就个人	个人为组织贡献业绩，组织给个人带来成长
3）个人破坏组织，组织抛弃个人	组织管理者不能有侠客心里，对破坏者不能同情，从组织的角度考虑问题，对于破坏者必要清理或者帮助其走出困境。
5 、组织六大问题	
1）病从口入	招人不严，招聘进来的人员不适合岗位要求，长期下去可能导致创业失败。
2）消化不良	组织缺乏吸收转化能力，某些人员岗位要求可能不太匹配，缺乏合理的培训和引导。对于新进员工，通过培训、日常工作指导管理，实现新人对掌贝文化的真正理解和融入、岗位的能力匹配、心态认可，快速达到高绩效高战斗力状态。
3）肥胖臃肿	人多难于管理，效率低下，容易导致分工不明确，需要及时清理效率低下的人员，留下来的都是精干人员。
4）恶性癌变	某人的态度或者文化价值观出现问题，会像瘟疫一样传染给其他同事，对于能力强但是价值观不好的坚决清除，对于能力和价值观都不好的需要清理，积极培养能力和价值观双赢的人员。
5）便秘难排	组织是一个生命体，需要新陈代谢，人员的综合素质需要培养到位，遇到对某些人依赖较高导致便秘难排。
6）复发感染	一个人的行为，所有人学习，荷花效应。有些问题前期优化了 后期又会出现。需要遏制这种行为。避免问题反复出现；一个人的行为，特别是不良行为，极易形成连锁学习反应。
6 、组织落地法	
1）组织特性、要求、准则讲解宣导	对于组织架构调整，人员变动，需要召集组织人员进行宣讲；新人入职需要介绍引导；离职人员需要谈心，了解根本原因以及传递给其他同事，避免引起怀疑。
2）组织洞察、分析、运营升级优化	管理者洞察和协调分工，发现出现的问题，分析根本原因，及时优化和解决。
3）组织行为结果惩恶扬善积极引导	人员状态起伏，需要有管理行为，干预以正视听。比如说优秀人员进行识别，开会表扬；
三、管理之本

1 、管理两条腿：团队管理，即管人；业务管理，即管事！	
2 、管理六能力	
1）沟通能力	对人员采取什么方式进行沟通，不同的人对事情认识的深度不一样，说服力要强。
2）协调能力	理顺各部门合作的事项
3）规划能力	对资源的规划，基于目标和环境排兵布阵。
4）决策能力	识别风险，有一种决策意识，预防在开始阶段，如果事故发生了，比较被动；做好多个决策，做选择题。
5）培训能力	必备能力，把知识和技能传播好，传输到位
6）领导能力	管理者价值观的表率，个人魅力足，在团队中起到榜样作用
3 、管人落地法	
1）激精神	激发动力，职业规划，点亮梦想；压力驱动，分析社会现实，压力转化成动力
2）正思想	统一思想，对公司，业务，文化的理解统一；开会过程中及时发现异常的偏差，并且给与纠正 。
3）建能力	通用能力，专业知识，专业技能，人才培养机制，导师，培训，高层辅导，战略推演，内部分享，
4）铁执行	定流程，统一的执行标准的动作。严格纪律，同一团队思想；明晰奖惩机制，奖罚分明。PMO管理
5）送关怀	心理疏导；表扬先进人员。团建活动，松弛有度；组织形式关怀、个人形式关怀；触动情感的形式，用心关怀
4 、管事落地法	
1）定目标	Smart目标，具体明确的，可衡量，方案可实现，相关性的人，有截止时间。
2）分任务	拆分任务项，粒度要很细，不能疏漏；控制力度和边界；根据任务的难易按照人员的能力进行匹配。
3）出策略	沙盘模拟，模拟现实场景，概要设计，提问作答方式，对设计进行评审，纠正。
4）抓过程	主要是三大块：里程碑，薄弱点，风险识别
5）盯结果	管理者亲自查看验收结果，指出不足和改进的地方，加以改进。站在的角度不一样，看到的结果不一样。分成2种形式：会议和汇报。





二、ms相关
1 讲一下你们整个实施过程包括哪些？哪些环节风险比较大的？
需求分析，概要设计，编码，调试，测试，预发布，上线 
风险比较大：需求分析，概要设计

2 在团队建设上面有什么手段？
团队建设的三个层面
1、团队的凝聚力。
团队的凝聚力是针对团队和成员之间的关系而言的。团队精神表现为团队成员强烈的归属感和一体性，每个团队成员都能感受到自己是团队当中的一分子，把个人工作和团队目标联系在一起，对团队忠诚，对团队的成功感到自豪，对团队的困境感到忧虑。
2、团队的合作意识。
团队的合作意识是指团队和团队成员表现为协作和共为一体的特点。团队成员间相互依存、同舟共济、互相敬重、彼此宽容和尊重个性的差异；彼此间形成一种信任的关系，待人真诚、遵守承诺；相互帮助和共同提高；共享利益和成就、共担责任。 
3、团队士气。
团队士气是团队精神的一个重要方面。拿破仑曾说过：“一支军队的实力四分之三靠的是士气”。将这句话的含义延伸到现代企业管理，为团队目标而奋斗的精神状态对团队的业绩非常重要。

3 作为项目经理应该具备哪些能力和素质？
1）1 能适应变化  
1）2 有实践能力
1）3 能进行创造性的思考
1）4 乐于学习
1）5 有带团队的能力
1）6 具有大局观与组织能力
1）7 适应各类企业的文化与价值观
1）8 善于与人沟通
1）9 善于描绘愿景

4 在绩效考核上如何做使下属都信服？主要指标有哪些？
（1）主要方法：
自评，相互评，兄弟部门评，面谈，找出客观事实说出突出点和不足的地方 
（2）主要指标：
 完成本职工作，责任心，协作能力，积极主动，态度，有新的技术突破，加班情况
（3）公平才能信服：
a，绩效考核制度是不区分职位高低和亲疏远近的，对于所有需要参与考核的部门和考核人都应该有效。
b，绩效考核制度的制定是取决于部门、岗位职责的。并不是所有的工作都会有明确的衡量指标，所以就要求绩效考核的方法存在一定程度上的差异，以适用于不同的方位和指标。
c，绩效考核的指标必须是明确且可以衡量的，需要符合被考核人的岗位且在正常的工作时间能够完成的。
d，绩效考核必须要有明确的截止时间，并且需要验证的遵守，给出合理的评价。

5怎么着手制定项目计划？
在适当的活动和阶段或其他的概括的标准说明下，输入确定的任务。将适当的可交付产品及里程碑和特定的任务联系起来。连接全部需要依赖关联的任务。把资源角色或资源名字加到每个任务上。应用度量结果确定事先的任务工作量，把更多的时间用于需求收集，设计和测试。考虑所有已知的节假日，培训，休假或其他的资源停工时间。计划草案将同支持团体，管理层和商务用户一起复查，做为补充性的输入和最终的批准。 

6你认为项目中最重要的是哪些过程？
分析、设计阶段、测试阶段

7如果给你一个4-6个人的Team，那么你怎么分配管理他们？
挑选一个技术过硬的人作为我的替补和项目的轻骑兵，是的团队中必须有机动人员，否则你的项目十有八九会夭折。其他的人会被平均的分配任务。
我们会在每周进行全面的任务分配，每个人获取一周的大概工作，然后每天的工作由他自己完成并汇报。掌握每个人都长处和短板，充分发挥他们的价值。

8你认为你应聘我们公司的项目经理，你自身的优势在哪？
带领团队经验丰富，技术能力扎实，工作积极主动，责任心强 

9你的管理的思路有哪些？
（1）注重成果，管理重在追求或取得成果。检验管理的一个原则是：是否达到了目标，是否完成了任务。当然，这个原则并不是在所有情况下都适用，管理者应该把精力和注意力放在“行得通”的事情上。　　
（2）把握整体，管理者之所以成为管理者，是因为他们眼观全局，着眼于整体，把整体发展视为己任。管理者应该理解自己的任务，不应从自己的职位出发，而应着眼于如何运用源于职位的知识、能力和经验来为整体效力。　　
（3）专注要点，专注要点的关键在于专注少数真正重要的东西。许多管理者热衷于寻找所谓的“秘方”，其实这是一种冒险行为。倘若真的有什么“秘方”，那就是专注要点应该是最重要的。要具备专注要点的能力、技巧和纪律性，是效率高的典型表现。　　
（4）利用优点，利用优点是指利用现有的优点，而不是那些需要重新建立和开发的优点。但现实中，很多管理者总是致力于与之相反的方面，即开发新的优点，而不是发挥现有的优点。如果这样，即使管理方法很有技巧，看上去也很科学，但造成的管理失误却是无法弥补的。　　
（5）相互信任，怎样在自己的部门或组织内部创造和谐、完美的工作氛围呢？有些管理者一板一眼地按照教科书上说的来做，但效果却不是很好。其实，只要管理者能够赢得周围其他人的信任，那么他所管理的部门或组织的工作气氛就会是和谐的。　　
（6）正面思维，正面思维的关键在于运用正确的或创造性的方式思考。正面思维的原则能让管理者把注意力放在机会上。事实上，发现和抓住机会要比解决问题更重要，但这并不是说管理者可以忽视存在的问题。有效率的管理者能够清楚地看到问题和困难，并不加以回避，而是先去寻找可能的办法和机会。

10 项目中代码质量如何控制的？
1） 进行相关的培训，邀请有经验的人对新员工或者junior的开发人员进行培训，以提高代码质量。
2） 制定相关的coding standard和coding pattern, 要求开发人员严格follow。
3） 使用相关的工具对代码进行静态分析和动态分析，及早发现代码中的问题。
4） 严格执行代码审查，每次代码提交前都要求进行review, 具体可以有CCR(持续代码审查) 和 FCR(正式代码审查)两种code review

11 项目管理的五大过程组与九大领域是什么？
5个过程组指的是：启动、规划、执行、监控、收尾
9大知识领域指的是：整体、范围、进度、成本、质量、人力资源、沟通、风险、采购   

12 工作任务非常多非常杂时如何处理？
首先把所有的工作都列出来，免得被遗漏。
其次，把所有工作按时间的紧迫和任务的轻重进行分类，先做比较急而且比较重要的，
再做不那么急又不那么重要的。把相同类别的任务放在一起做。一件一件地做，做一件就画一个对勾，你会很有成就感，工作效率也会很快的。

13 项目出现延迟如何处理？
很多企业的项目管理人员遇到项目拖期的情形，首先采取的策略是加班，管理水平稍好一点的企业则会修正计划。加班，可能使拖期现象暂时得到缓解，但是产生拖期的根本原因依然存在，一段时间之后，这些问题会继续暴露出来。
所以大多数情况下，如果不采取针对性的措施，而是单纯用加班赶进度的策略解决不了问题。管理人员应该慎用加班这个策略。
改计划，起码实事求是地承认了问题，但是对解决问题于事无补。项目经理应该是走向成功之路的引领者，而不是分析员、记录员这样被动的角色。
其实无论加班还是改计划，都没有解决问题。项目管理者发现项目拖期，应当分析问题的真正原因，然后对症下药。该返工的返工，该培训的培训，该招人的时候招人，甚至必要的情况下终止这个项目，以免更大的损失。
项目管理者的真正挑战，不是发现问题和记录问题，而是预见问题、控制问题和解决问题。

14 和同事的设计思路不一样怎么处理？
先认真倾听对方的想法，衡量下两边的优缺点，结合当时的业务场景选择最适合的方案

15 如何保证开发质量？
1） Java代码规范学习
2） CodeReview，CodeReview是在开发阶段发现代码缺陷的一种方式，可以有效提高代码质量，降低维护成本；是团队成员互相学习、分享编程经验的提高过程。
3） 重构，在不改变代码外在行为的前提下，对代码做出修改，以改进程序的内部结构。
4） 工具查bug：findbugs（idea插件）

16 团队的规划是什么？
1树立核心形象与威信，把你的工作经验传授给你的手下，尤其是那些业务新手。在工作中承担更多的责任，有利于你树立威信。
2、创造一个良好的沟通环境，对于沟通的力量，是不容置疑的。有意见、有矛盾，不说出来会积怨；出现问题相互推诿，可能出现更大的问题，这些都是沟通不够的表现。
3合理分工各尽其才，在营销行业里流行着这么一句话：只有优秀的团队，没有优秀的个人。而我的理解是：优秀的团队里，每个一人都优秀。

17 能介绍下从工作到现在自己的成长在那里？
 团队管理能力，技术能力，沟通能力，协调能力

18 敏捷开发的价值是什么?
个人和团队之间的协作比流程和工具更重要。可以交付使用的系统产品比繁琐的文档更重要跟客户的协作比合同上的斤斤计较更重要快速响应需求变更而不是一味的严格执行计划敏捷开发不代表没有流程，没有文档或者没有计划，这些东西都很重要，但是不如团队之间和团队和客户之间的协作更重要

19 你们公司都采取了什么措施来提高代码质量?
1） 进行相关的培训，邀请有经验的人对新员工或者junior的开发人员进行培训，以提高代码质量。
2） 制定相关的coding standard和coding pattern, 要求开发人员严格follow。
3） 使用相关的工具对代码进行静态分析和动态分析，及早发现代码中的问题。
4） 严格执行代码审查，每次代码提交前都要求进行review, 具体可以有CCR(持续代码审查) 和 FCR(正式代码审查)两种code review

20 软件项目团队的特征有哪些?
–是一个临时性的团队
–是跨职能的
–在软件项目不同阶段中团队成员具有不稳定性
–成员具有极大的流动性
–年轻化程度高
–软件项目团队属于高度集中的知识型团队
–员工业绩难以量化考核
–软件项目团队非常注重自我
高效的软件开发团队是建立在合理的开发流程及团队成员密切合作的基础之上，团队成员需共同迎接挑战、有效的计划、协调和管理各自的工作直至成功完成项目目标。

21 常见的软件风险管理模式都有哪些?
（1）危机管理-这种模式类似于救火模式，其特点是听任软件风险的发生，及至软件风险给软件项目开发造成麻烦后才着手进行处理。
（2）失败处理-在这种模式中，项目组人员和负责人察觉到了潜在的风险，但听任软件风险的发生和演化，只是在风险发生之后才采取应对措施。
（3）风险缓解-在风险缓解模式中，项目组人员和负责人在软件开发过程中有意识地识别各种软件风险，并且针对这些软件风险事先制定好风险发生后的补救措施，但是不做任何防范措施。
（4）风险预防-风险预防模式将风险识别和风险防范作为软件项目的一部分加以规划和执行。
（5）消灭根源-在该模式中，项目组人员和负责人不仅要识别软件开发过程中各种潜在的软件风险，而且还要分析导致这些软件风险发生的主要因素，并采取积极的措施消除软件风险产生的根源。

22 项目管理过程中经常出现过哪些conflicts?
1） 进度（Schedule）在项目任务的时间安排、先后顺序及安排方面存在不一致的意见
2） 项目优先级（Priorities）项目参与者在活动和任务的优先级上观点不同
3） 资源冲突（Resource）项目团队成员安排与其他领域人员安排方面的冲突
4） 技术意见与执行情况的冲突。在技术问题，执行规范和技术权衡上的不一致
5） 管理程序（Administration Procedures）在项目如何管理问题上发生的管理导向和行政导向的冲突
6） 成本（Cost）在设计工作分解结构上，来自支持部门的成本估算上的冲突
7） 个性(Personality)人际关系方面的冲突

23 你认为什么样的团队是高效团队，什么样的团队是糟糕团队?
高效团队具有如下特征：
1） 团队成员对团队遵守承诺和高度忠诚
2） 团队成员对其他成员及项目经理遵守承诺
3） 团队成员具备各种不同的专业技能及专业素养。
4） 团队成员具有较高的工作满意度
5） 团队成员之间不断加强和改善沟通
6） 团队成员对隶属管理和目标的感知
7） 具有较高的团队精神及团队士气
8） 具有合理的冲突化解机制
糟糕团队的特征：
1） 团队缺乏动力或者项目组成员抱着“事不关己、高高挂起”的态度
2） 挫折感，团队成员普遍对项目工作不满意，对所从事的工作充满挫折感
3） 冲突和不良竞争，项目组成员之间经常发生冲突和不良竞争
4） 没有效率的会议，如状态会议变成牢骚会议
5） 沟通太差。团队成员之间不交流项目信息，不能很好的配合工作
6） 对项目经理缺乏尊重和信任。


24 如果你明天开始正式接任这个职位，你希望能够获取哪方面的信息呢?
1）岗位相关的部门内部组织架构关系以及与其他部门接口人信息。
2）所负责产品的以前，现在和将来。
3）岗位的绩效考核状况和公司级别的制度

25 项目管理部门在项目开发中的质量管理主要包括哪些内容？
(1)决策阶段的质量管理
主要内容是在广泛搜集资料、调查研究的基础上研究、分析、比较，决定项目的可行性和最佳方案。
(2)项目实施前的质量管理
①对项目组的能力重新审查，包括各个成员资质的审查。如果发现实际情况有所变化，必须采取有效措施予以纠正。
②对所有的合同和技术文件、报告进行详细的审阅。如图纸是否完备，有无错漏空缺，各个设计文件之间有无矛盾之处，技术标准是否齐全，等等。
③审阅进度计划和实施方案。
(3)项目实施中的质量管理
①参与项目的阶段性评审。该评审从保证评审过程有效性方面入手，如参与评审的人是否具备一定资格，是否规定的人员都参与了评审，是否对评审对象每个部分都进行了评审，是否给出了明确的结论等。
⑤跟踪问题的解决情况。在项目组内一可以解决的问题就在项目组内部解决，对于在项目组内部无法解决的一问题，或是在项目组中催多次也没有得到解决的问题，可以利用其独立汇报的渠道报告给高层经理。
⑥收集新方法，提供过程改进的依据，便于下一步对规程进行修改和完善。
(4)项目完成后的质量管理
①监督检查项目测试情况。
④进行项目实施后审计。
⑤总结项目实施的经验和教训。

26 成功的团队有哪些特点?
（1）明确的目标。团队的每个成员可以有不同的目的、不同的个性，但作为一个整体，必须有共同的奋斗目标。
（2）清晰的角色。有效团队的成员必须在清楚的组织架构中有清晰的角色定位和分工，团队成员应清楚了解自己的定位与责任。
（3）相互的技能。团队成员要具备为实现共同目标的基本技能，并能够有良好的合作。
（4）相互间信任。相互信任是一个成功团队最显著的特征。
（5）良好的沟通。团队成员间拥有畅通的信息交流，才会使成员的情感得到交流，才能协调成员的行为，使团队形成凝聚力和战斗力。
（6）合适的领导。团队的领导往往起到教练或后盾作用，他们对团队提供指导和支持，而不是企图控制下属。

27 在你以前的项目管理工作中，你碰到最大的困难是什么？
(1) 自身知识包括专业和管理的不足，这个需要利用各种时间进行充电。
(2) 各方不配合，相互推诿，特别是甲方内部，各种关系错综复杂包括甲乙不分。
(3) 工程进度不好控制，无论天气原因还是人为因素，很少有工期提前结束的，虽然工期早就做出预留。大会小会都要做好挨批的准备。
(4) 后期验收调试责任不明确，都想推脱责任。

28 软件开发面临的问题都有哪些?
1)  软件开发是高风险、高投入的项目
2)  开发时间长、成本高
3)  无法证明正确性
4)  维护代价高
5)  开发、维护难于度量 等等
6)  偏激看法：凡是软件开发项目就不可能按时完成。

29 软件项目失败的主要原因有哪些?
1) 项目经理实战经验不足
项目经理都是从企业高级软件工程师和高级构架师提升来的项目经理职位，因此不可避免的造就了这样的项目经理过分集中于技术上，从而忽视用户的角度去分析。以技术为主的应该将重心放在IT项目交付上，以商业为主的要满足用户的商业目标的需求。
2) 项目计划不够合理
项目计划过程中存在不合理假设和风险预测不足导致项目失败的主要因素，在计划过程中必须留时间处理不可预知的问题，因此在任何项目过程中各种无法预知的都应该预留10%的时间来应对。
3) 需求不确定性
需求分析和开发过中不断的进行修改与变更，需求在初期的过程中对需求定义阶段出现很多不确定的因素，本可以避免的错误在后期过程中影响进度和预算等情况，从而导致项目失败，还有就是开发过程中需求变更处理机制的不合理，麻木进行用户满意度追求，导致附加功能不断增加，原有设计不停变更等，以致于超出预算成本导致项目失败。
4) 项目测试不足
项目开发过程中项目经理经常牺牲项目测试时间压缩几天内完成项目测试，从而导致项目测试结果不到位，用户也放弃测试与检测的责任，开发人员关注系统的性能从而对结果的商业需求满意度缺失导致致命的错误。
5) 无项目时间节点
项目没有具体的开始时间和结束时间，会导致项目在永远不确定的时间无休止的进行，项目成员疲惫最终项目失败。因此必须明确项目何时开始何时结束。
6) 领导者经验不足
项目成功的关键在于领导而不是过多的管理制度，领导需要卓越技能和丰富的经验以及职能以外的奉献精神，也需要激发和带领团队的领导气质。

30 什么是猴子管理法则？
为什么有些领导总是看起来那么忙？这是因为他们不懂得猴子管理法则。猴子管理法则通俗地说，就是每个人背上都有一只猴子，这只猴子代表着对自己承担问题的解决责任，如果下属学会解决自己的工作问题，领导就会有更多属于自己的时间去思考自己的问题。
（1）打断下属负面的“依赖”神经链。
（2）训练了下属分析问题、全面思考问题的能力。
（3）让下属产生信心与成就感。他会觉得自己居然也有解决复杂问题的能力。越来越有能力的下属能越来越胜任更重要的任务。
（4）激发下属的行动力。
（5）你将因此不必照看下属的“猴子”而腾出更多的精力去照看自己的“猴子”。
（6）该下属做决定的事，一定要让他们自己学着做决定；
（7）做决定意味着为自己的决定负责任。不想做决定，常常是潜意识里他不想承担责任；
（8）下属不思考问题、不习惯做决定的根源一般有两个：其一是有“托付思想”，依赖上司或别人，这样的下属不堪大用；其二是上司习惯代替下属做决定或喜欢享受别人听命于自己的成就感，这样的上司以及他所带领的团队难以胜任复杂的任务；
（9）让下属自己想办法，做决定，就是训练下属独立思考问题的能力和勇于承担责任的行事风格。

31 如何对软件项目的规模、工作量和成本进行估算?
基于代码行和功能点的估算软件项目的规模是影响软件项目成本和工作量的主要因素。
在基于代码行（LOC，Line Of Code）和功能点（Function Point）的估算方法中，利用代码行和功能点来表示软件系统的规模，并通过对软件项目规模的估算进而来估算软件项目的成本和工作量。
显然,一个软件项目的代码行数目越多，它的规模也就越大。软件代码行的数目易于度量，许多软件开发组织和项目组都保留有以往软件项目代码行数目的记录，这有助于在以往类似软件项目代码行记录的基础上对当前软件项目的规模进行估算。

32 在需求分析阶段都通过哪些方式进行需求沟通?
1） 问卷调查法， 开发方就用户需求中的一些个性化的、需要进一步明确的需求，通过采用向用户发问卷调查表的方式，达到彻底弄清项目需求的一种需求获取方法。单的问卷调查方法就能使问题得到较好的解决
2） 会议讨论法 ，开发方和用户方召开若干次需求讨论会议，达到彻底弄清项目需求的一种需求获取方法
3） 界面原型法 ，开发方根据自己所了解的用户需求，描画出应用系统的功能界面后与用户进行交流和沟通，通过“界面原型”这一载体，达到双方逐步明确项目需求的一种需求获取的方法。

33 软件项目主合同至少应包括哪些内容?
项目名称
项目的技术内容、范围、形式和要求
项目实施计划、进度、期限
地点和方式
项目合同价款、报酬及其支付方式
项目验收标准和方法
各方当事人义务或协作责任
技术成果归属和分享及后续改进的提供与分享规定
技术保密事项
风险责任的承担
违约金或者损失赔偿额的计算方法、仲裁及其它

34 IT项目管理中的团队沟通？
（1）尽早沟通
尽早沟通要求项目经理要有前瞻性，定期与项目成员及项目干系人建立沟通，这不仅容易发现当前存在的问题，而且很多潜在问题也能暴露出来。在项目中出现问题并不可怕，可怕的是问题没被发现。沟通得越晚，暴露得越迟，带来的损失越大。
（2）主动沟通
主动沟通说到底是对沟通的一种态度。在项目中，应该极力提倡主动沟通，尤其是当已经明确了必须要去沟通的时候。当沟通是项目经理面对项目干系人或上级、团队成员面对项目经理时，主动沟通不仅能建立紧密的联系，更能表明你对项目的重视和参与，会使沟通的另一方满意度大大提高，对整个项目非常有利。
（3）内外有别
不管项目组内部有多大的分歧，当面对项目组外部人员，需要处理与项目有关的问题时，要强调对外的一致性，一个项目团队要一种声音说话，这不是一种形式，而是一种文化。面对不同的对象甚至可以选用特定的发言人，这样能取得意想不到的效果。
（4）采用对方能接受的沟通风格
注意肢体语言、语态给对方的感觉。无论在语言和肢体表达上，都需要传递一种合作和双赢的态度，使双方无论在问题的解决上还是在气氛上都达到“双赢”。
（5）沟通的升级原则
横向沟通有平等的感觉，但合理使用纵向沟通，有助于问题的快速解决。沟通的升级可以通过四个步骤来完成。第一步，和对方沟通；第二步与对方的上级沟通；第三步，和自己的上级沟通；第四步，自己的上级与对方的上级沟通。

35 影响团队有效沟通的因素有哪些?
沟通障碍：指延误或曲解消息的因素。沟通障碍的出现必然导致冲突。信息过载、缺少知识、文化差异、组织气候、情绪、沟通线路、选择性认知、噪声、项目行话和术语、距离等造成沟通障碍。

---------------------------------------------------------------------------------------------------------------
------------------------------------------manager basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------maven basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------

一、基础知识
1 Maven的标准工程结构
Maven的标准工程结构如下
|-- pom.xml(maven的核心配置文件)
|-- src
|-- main
|   `-- java(java源代码目录)
|   `-- resources(资源文件目录)
|-- test
        `-- java(单元测试代码目录)
|-- target(输出目录，所有的输出物都存放在这个目录下)
    |--classes(编译后的class文件存放处)
 
maven profile：根据需要，可以在以下文件声明profile。
      1、pom.xml 针对当前项目
      2、用户 settings.xml 用户目录下的.m2/settings.xml， 对当前用户的所有项目有效。
      3、全局 settings.xml 即maven安装目录下的conf/settings.xml。对本机上的所有项目有效。

2 Maven的版本规范
maven使用如下几个要素来唯一定位某一个输出物
@groudId
团体、组织的标识符。团体标识的约定是，它以创建这个项目的组织名称的逆向域名(reverse domain name)开头。一般对应着JAVA的包的结构。例如org.apache
@artifactId 
单独项目的唯一标识符。比如我们的tomcat, commons等。不要在artifactId中包含点号(.)。
@version 
一个项目的特定版本。
@packaging 
项目的类型，默认是jar，描述了项目打包后的输出。类型为jar的项目产生一个JAR文件，类型为war的项目产生一个web应用。
 
3 常用Maven插件
maven-antrun-plugin
http://maven.apache.org/plugins/maven-antrun-plugin/
maven-antrun-plugin能让用户在Maven项目中运行Ant任务。用户可以直接在该插件的配置以Ant的方式编写Target，然后交给该插件的run目标去执行。在一些由Ant往Maven迁移的项目中，该插件尤其有用。此外当你发现需要编写一些自定义程度很高的任务，同时又觉得Maven不够灵活时，也可以以Ant的方式实现之。maven-antrun-plugin的run目标通常与生命周期绑定运行。
 
maven-archetype-plugin
http://maven.apache.org/archetype/maven-archetype-plugin/
Archtype指项目的骨架，Maven初学者最开始执行的Maven命令可能就是mvn archetype:generate，这实际上就是让maven-archetype-plugin生成一个很简单的项目骨架，帮助开发者快速上手。可能也有人看到一些文档写了mvn archetype:create，但实际上create目标已经被弃用了，取而代之的是generate目标，该目标使用交互式的方式提示用户输入必要的信息以创建项目，体验更好。 maven-archetype-plugin还有一些其他目标帮助用户自己定义项目原型，例如你由一个产品需要交付给很多客户进行二次开发，你就可以为他们提供一个Archtype，帮助他们快速上手。
 
maven-assembly-plugin
http://maven.apache.org/plugins/maven-assembly-plugin/
maven-assembly-plugin的用途是制作项目分发包，该分发包可能包含了项目的可执行文件、源代码、readme、平台脚本等等。 maven-assembly-plugin支持各种主流的格式如zip、tar.gz、jar和war等，具体打包哪些文件是高度可控的，例如用户可以按文件级别的粒度、文件集级别的粒度、模块级别的粒度、以及依赖级别的粒度控制打包，此外，包含和排除配置也是支持的。maven-assembly- plugin要求用户使用一个名为assembly.xml的元数据文件来表述打包，它的single目标可以直接在命令行调用，也可以被绑定至生命周期。
 
maven-dependency-plugin
http://maven.apache.org/plugins/maven-dependency-plugin/
maven-dependency-plugin最大的用途是帮助分析项目依赖，dependency:list能够列出项目最终解析到的依赖列表，dependency:tree能进一步的描绘项目依赖树，dependency:analyze可以告诉你项目依赖潜在的问题，如果你有直接使用到的却未声明的依赖，该目标就会发出警告。maven-dependency-plugin还有很多目标帮助你操作依赖文件，例如dependency:copy-dependencies能将项目依赖从本地Maven仓库复制到某个特定的文件夹下面。
 
maven-enforcer-plugin
http://maven.apache.org/plugins/maven-enforcer-plugin/
在一个稍大一点的组织或团队中，你无法保证所有成员都熟悉Maven，那他们做一些比较愚蠢的事情就会变得很正常，例如给项目引入了外部的 SNAPSHOT依赖而导致构建不稳定，使用了一个与大家不一致的Maven版本而经常抱怨构建出现诡异问题。maven-enforcer- plugin能够帮助你避免之类问题，它允许你创建一系列规则强制大家遵守，包括设定Java版本、设定Maven版本、禁止某些依赖、禁止 SNAPSHOT依赖。只要在一个父POM配置规则，然后让大家继承，当规则遭到破坏的时候，Maven就会报错。除了标准的规则之外，你还可以扩展该插件，编写自己的规则。maven-enforcer-plugin的enforce目标负责检查规则，它默认绑定到生命周期的validate阶段。
 
maven-help-plugin
http://maven.apache.org/plugins/maven-help-plugin/
maven-help-plugin是一个小巧的辅助工具，最简单的help:system可以打印所有可用的环境变量和Java系统属性。help:effective-pom和help:effective-settings最为有用，它们分别打印项目的有效POM和有效settings，有效POM是指合并了所有父POM（包括Super POM）后的XML，当你不确定POM的某些信息从何而来时，就可以查看有效POM。有效settings同理，特别是当你发现自己配置的 settings.xml没有生效时，就可以用help:effective-settings来验证。此外，maven-help-plugin的describe目标可以帮助你描述任何一个Maven插件的信息，还有all-profiles目标和active-profiles目标帮助查看项目的Profile。
 
maven-release-plugin
http://maven.apache.org/plugins/maven-release-plugin/
maven-release-plugin的用途是帮助自动化项目版本发布，它依赖于POM中的SCM信息。release:prepare用来准备版本发布，具体的工作包括检查是否有未提交代码、检查是否有SNAPSHOT依赖、升级项目的SNAPSHOT版本至RELEASE版本、为项目打标签等等。release:perform则是签出标签中的RELEASE源码，构建并发布。版本发布是非常琐碎的工作，它涉及了各种检查，而且由于该工作仅仅是偶尔需要，因此手动操作很容易遗漏一些细节，maven-release-plugin让该工作变得非常快速简便，不易出错。maven-release-plugin的各种目标通常直接在命令行调用，因为版本发布显然不是日常构建生命周期的一部分。
 
maven-resources-plugin
http://maven.apache.org/plugins/maven-resources-plugin/
为了使项目结构更为清晰，Maven区别对待Java代码文件和资源文件，maven-compiler-plugin用来编译Java代码，maven-resources-plugin则用来处理资源文件。默认的主资源文件目录是src/main/resources，很多用户会需要添加额外的资源文件目录，这个时候就可以通过配置maven-resources-plugin来实现。此外，资源文件过滤也是Maven的一大特性，你可以在资源文件中使用${propertyName}形式的Maven属性，然后配置maven-resources-plugin开启对资源文件的过滤，之后就可以针对不同环境通过命令行或者Profile传入属性的值，以实现更为灵活的构建。
 
maven-surefire-plugin
http://maven.apache.org/plugins/maven-surefire-plugin/
可能是由于历史的原因，Maven 2/3中用于执行测试的插件不是maven-test-plugin，而是maven-surefire-plugin。其实大部分时间内，只要你的测试类遵循通用的命令约定（以Test结尾、以TestCase结尾、或者以Test开头），就几乎不用知晓该插件的存在。然而在当你想要跳过测试、排除某些测试类、或者使用一些TestNG特性的时候，了解maven-surefire-plugin的一些配置选项就很有用了。例如 mvn test -Dtest=FooTest 这样一条命令的效果是仅运行FooTest测试类，这是通过控制maven-surefire-plugin的test参数实现的。
 
build-helper-maven-plugin
http://mojo.codehaus.org/build-helper-maven-plugin/
Maven默认只允许指定一个主Java代码目录和一个测试Java代码目录，虽然这其实是个应当尽量遵守的约定，但偶尔你还是会希望能够指定多个源码目录（例如为了应对遗留项目），build-helper-maven-plugin的add-source目标就是服务于这个目的，通常它被绑定到默认生命周期的generate-sources阶段以添加额外的源码目录。需要强调的是，这种做法还是不推荐的，因为它破坏了 Maven的约定，而且可能会遇到其他严格遵守约定的插件工具无法正确识别额外的源码目录。
build-helper-maven-plugin的另一个非常有用的目标是attach-artifact，使用该目标你可以以classifier的形式选取部分项目文件生成附属构件，并同时install到本地仓库，也可以deploy到远程仓库。
 
exec-maven-plugin
http://mojo.codehaus.org/exec-maven-plugin/
exec-maven-plugin很好理解，顾名思义，它能让你运行任何本地的系统程序，在某些特定情况下，运行一个Maven外部的程序可能就是最简单的问题解决方案，这就是exec:exec的用途，当然，该插件还允许你配置相关的程序运行参数。除了exec目标之外，exec-maven-plugin还提供了一个java目标，该目标要求你提供一个mainClass参数，然后它能够利用当前项目的依赖作为classpath，在同一个JVM中运行该mainClass。有时候，为了简单的演示一个命令行Java程序，你可以在POM中配置好exec-maven-plugin的相关运行参数，然后直接在命令运行mvn exec:java 以查看运行效果。
 
jetty-maven-plugin
http://wiki.eclipse.org/Jetty/Feature/Jetty_Maven_Plugin
在进行Web开发的时候，打开浏览器对应用进行手动的测试几乎是无法避免的，这种测试方法通常就是将项目打包成war文件，然后部署到Web容器中，再启动容器进行验证，这显然十分耗时。为了帮助开发者节省时间，jetty-maven-plugin应运而生，它完全兼容 Maven项目的目录结构，能够周期性地检查源文件，一旦发现变更后自动更新到内置的Jetty Web容器中。做一些基本配置后（例如Web应用的contextPath和自动扫描变更的时间间隔），你只要执行 mvn jetty:run ，然后在IDE中修改代码，代码经IDE自动编译后产生变更，再由jetty-maven-plugin侦测到后更新至Jetty容器，这时你就可以直接测试Web页面了。需要注意的是，jetty-maven-plugin并不是宿主于Apache或Codehaus的官方插件，因此使用的时候需要额外的配置settings.xml的pluginGroups元素，将org.mortbay.jetty这个pluginGroup加入。
 
versions-maven-plugin
http://mojo.codehaus.org/versions-maven-plugin/
很多Maven用户遇到过这样一个问题，当项目包含大量模块的时候，为他们集体更新版本就变成一件烦人的事情，到底有没有自动化工具能帮助完成这件事情呢？（当然你可以使用sed之类的文本操作工具，不过不在本文讨论范围）答案是肯定的，versions-maven- plugin提供了很多目标帮助你管理Maven项目的各种版本信息。例如最常用的，命令 mvn versions:set -DnewVersion=1.1-SNAPSHOT 就能帮助你把所有模块的版本更新到1.1-SNAPSHOT。该插件还提供了其他一些很有用的目标，display-dependency- updates能告诉你项目依赖有哪些可用的更新；类似的display-plugin-updates能告诉你可用的插件更新；然后use- latest-versions能自动帮你将所有依赖升级到最新版本。最后，如果你对所做的更改满意，则可以使用 mvn versions:commit 提交，不满意的话也可以使用 mvn versions:revert 进行撤销。
 
4 常用Maven命令
生命周期	阶段描述
mvn validate	验证项目是否正确，以及所有为了完整构建必要的信息是否可用
mvn generate-sources	生成所有需要包含在编译过程中的源代码
mvn process-sources	处理源代码，比如过滤一些值
mvn generate-resources	生成所有需要包含在打包过程中的资源文件
mvn process-resources	复制并处理资源文件至目标目录，准备打包
mvn compile	编译项目的源代码
mvn process-classes	后处理编译生成的文件，例如对Java类进行字节码增强（bytecode enhancement）
mvn generate-test-sources	生成所有包含在测试编译过程中的测试源码
mvn process-test-sources	处理测试源码，比如过滤一些值
mvn generate-test-resources	生成测试需要的资源文件
mvn process-test-resources	复制并处理测试资源文件至测试目标目录
mvn test-compile	编译测试源码至测试目标目录
mvn test	使用合适的单元测试框架运行测试。这些测试应该不需要代码被打包或发布
mvn prepare-package	在真正的打包之前，执行一些准备打包必要的操作。这通常会产生一个包的展开的处理过的版本（将会在Maven 2.1+中实现）
mvn package	将编译好的代码打包成可分发的格式，如JAR，WAR，或者EAR
mvn pre-integration-test	执行一些在集成测试运行之前需要的动作。如建立集成测试需要的环境
mvn integration-test	如果有必要的话，处理包并发布至集成测试可以运行的环境
mvn post-integration-test	执行一些在集成测试运行之后需要的动作。如清理集成测试环境。
mvn verify	执行所有检查，验证包是有效的，符合质量规范
mvn install	安装包至本地仓库，以备本地的其它项目作为依赖使用
mvn deploy	复制最终的包至远程仓库，共享给其它开发人员和项目（通常和一次正式的发布相关）

5 mvn deploy命令
mvn deploy:deploy-file -DgroupId=com -DartifactId=client -Dversion=0.1.0 -Dpackaging=jar -Dfile=d:client-0.1.0.jar -DrepositoryId=maven-repository-inner -Durl=ftp://xxxxxxx/opt/maven/repository/

6 mvn install命令：发布第三方Jar到本地库中：
mvn install:install-file -DgroupId=com -DartifactId=client -Dversion=0.1.0 -Dpackaging=jar -Dfile=d:client-0.1.0.jar

7 常见问题
（1）dependencies和dependencyManagement，plugins和pluginManagement有什么区别？
@ dependencyManagement是表示依赖jar包的声明，即你在项目中的dependencyManagement下声明了依赖，maven不会加载该依赖，dependencyManagement声明可以被继承。
@ dependencyManagement的一个使用案例是当有父子项目的时候，父项目中可以利用dependencyManagement声明子项目中需要用到的依赖jar包，
之后，当某个或者某几个子项目需要加载该插件的时候，就可以在子项目中dependencies节点只配置 groupId 和 artifactId就可以完成插件的引用。
@ dependencyManagement主要是为了统一管理插件，确保所有子项目使用的插件版本保持一致，类似的还是plugins和pluginManagement。
setting.xml 配合 compiler 3.5 ，ALT+F5 ，java compiler自动跟着setting.xml 走。
<profile>    
    <id>jdk-1.8</id>    
    <activation>    
        <activeByDefault>true</activeByDefault>    
        <jdk>1.8</jdk>    
    </activation>    
    <properties>    
        <maven.compiler.source>1.8</maven.compiler.source>    
        <maven.compiler.target>1.8</maven.compiler.target>    
        <maven.compiler.compilerVersion>1.8</maven.compiler.compilerVersion>    
    </properties>    
</profile> 
 
 也可以配置 pom.xml  ，当配置了pom这个优先级高 。
 <plugin>
	<groupId>org.apache.maven.plugins</groupId>
	<artifactId>maven-compiler-plugin</artifactId>
	<version>3.5.1</version>
	<configuration>
		<source>${jdk.version}</source>
		<target>${jdk.version}</target>
		<showWarnings>true</showWarnings>
	</configuration>
</plugin>

配置打包跳过测试
<!-- 打包跳过测试 -->
<plugin>  
		<groupId>org.apache.maven.plugins</groupId>  
		<artifactId>maven-surefire-plugin</artifactId>  
		<version>2.4.2</version>  
		<configuration>  
		  <skipTests>true</skipTests>  
		</configuration>  
</plugin> 
			

（2）mirror和repository 区别
例如， 有一个项目，需要在公司和住所都编码，并在项目pom.xml配置了A Maven库。在公司，是电信网络，访问A库很快，所以maven管理依赖和插件都从A库下载；在住所，是网通网络，访问A库很慢，但是访问B库很快。这时，在住所的setting.xml里，只要配置一下<mirrors><mirror>....</mirror></mirrors>，让B库成为A库的mirror，即可不用更改项目pom.xml里对于A库的相关配置。由于镜像仓库完全屏蔽了被镜像仓库，当镜像仓库不稳定或者停止服务的时候，Maven仍将无法访问被镜像仓库，因而将无法下载构件。如果该镜像仓库需要认证，则配置setting.xml中的<server></server>即可。

repository就是个仓库。maven里有两种仓库，本地仓库和远程仓库。远程仓库相当于公共的仓库，大家都能看到。本地仓库是你本地的一个山寨版，只有你看的到，主要起缓存作用。当你向仓库请求插件或依赖的时候，会先检查本地仓库里是否有。如果有则直接返回，否则会向远程仓库请求，并做缓存。

<mirrors>  
  <mirror>  
    <id>UK</id>  
    <name>UK Central</name>  
    <url>http://uk.maven.org/maven2</url>  
    <mirrorOf>central</mirrorOf>  
  </mirror>  
</mirrors>  
这样的话，就会给上面id为central的远程仓库做了个镜像。以后向central这个仓库发的请求都会发到http://uk.maven.org/maven2而不是http://repo1.maven.org/maven2了。 
<mirrorOf>central</mirrorOf>里是要替代的仓库的id。如果填*，就会替代所有仓库。 


8 pom.xml文件详解
pom中节点如下分布
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0
            http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <!-- 基本配置 -->
    <groupId>...</groupId>
    <artifactId>...</artifactId>
    <version>...</version>
    <packaging>...</packaging>

    <!-- 依赖配置 -->
    <dependencies>...</dependencies>
    <parent>...</parent>
    <dependencyManagement>...</dependencyManagement>
    <modules>...</modules>
    <properties>...</properties>

    <!-- 构建配置 -->
    <build>...</build>
    <reporting>...</reporting>

    <!-- 项目信息 -->
    <name>...</name>
    <description>...</description>
    <url>...</url>
    <inceptionYear>...</inceptionYear>
    <licenses>...</licenses>
    <organization>...</organization>
    <developers>...</developers>
    <contributors>...</contributors>

    <!-- 环境设置 -->
    <issueManagement>...</issueManagement>
    <ciManagement>...</ciManagement>
    <mailingLists>...</mailingLists>
    <scm>...</scm>
    <prerequisites>...</prerequisites>
    <repositories>...</repositories>
    <pluginRepositories>...</pluginRepositories>
    <distributionManagement>...</distributionManagement>
    <profiles>...</profiles>
</project>

9 repositories,pluginRepositories：依赖和扩展的远程仓库列表，同上篇文章，setting.xml配置中介绍的。
  <repositories>
    <repository>
      <releases>
        <enabled>false</enabled>
        <updatePolicy>always</updatePolicy>
        <checksumPolicy>warn</checksumPolicy>
      </releases>
      <snapshots>
        <enabled>true</enabled>
        <updatePolicy>never</updatePolicy>
        <checksumPolicy>fail</checksumPolicy>
      </snapshots>
      <id>codehausSnapshots</id>
      <name>Codehaus Snapshots</name>
      <url>http://snapshots.maven.codehaus.org/maven2</url>
      <layout>default</layout>
    </repository>
  </repositories>
  <pluginRepositories>
    ...
  </pluginRepositories>

    releases, snapshots:这是各种构件的策略，release或者snapshot。这两个集合，POM就可以根据独立仓库任意类型的依赖改变策略。如：一个人可能只激活下载snapshot用来开发。
    enable：true或者false，决定仓库是否对于各自的类型激活(release 或者 snapshot)。
    updatePolicy: 这个元素决定更新频率。maven将比较本地pom的时间戳（存储在仓库的maven数据文件中）和远程的. 有以下选择: always, daily (默认), interval:X (x是代表分钟的整型) ， never.
    checksumPolicy：当Maven向仓库部署文件的时候，它也部署了相应的校验和文件。可选的为：ignore，fail，warn，或者不正确的校验和。
    layout：在上面描述仓库的时候，提到他们有统一的布局。Maven 2有它仓库默认布局。然而，Maven 1.x有不同布局。使用这个元素来表明它是default还是legacy。

10 distributionManagement：它管理的分布在整个构建过程生成的工件和支持文件
  <distributionManagement>
    ...
    <downloadUrl>http://mojo.codehaus.org/my-project</downloadUrl>
    <status>deployed</status>
  </distributionManagement>
    downloadUrl: 其他pom可以通过此url的仓库抓取组件
    status：给出该构件在远程仓库的状态
        none: 默认
        converted: 将被早期Maven 2 POM转换过来
        partner: 这个项目会从合作者仓库同步过来
        deployed: 从Maven 2或3实例部署
        verified: 被核实时正确的和最终的

11 Repository：指定Maven pom从远程下载控件到当前项目的位置和方式，如果snapshotRepository没有被定义则使用repository相关的配置
  <distributionManagement>
    <repository>
      <uniqueVersion>false</uniqueVersion>
      <id>corp1</id>
      <name>Corporate Repository</name>
      <url>scp://repo/maven2</url>
      <layout>default</layout>
    </repository>
    <snapshotRepository>
      <uniqueVersion>true</uniqueVersion>
      <id>propSnap</id>
      <name>Propellors Snapshots</name>
      <url>sftp://propellers.net/maven</url>
      <layout>legacy</layout>
    </snapshotRepository>
    ...
  </distributionManagement>

    id, name：仓库的唯一标识
    uniqueVersion：true或false，指明控件部署的时候是否获取独立的版本号。
    url：repository元素的核心。指定位置和部署协议发布控件到仓库。
    layout：布局，default或legacy

12 Maven私服的特性
1.节省自己的外网带宽：减少重复请求造成的外网带宽消耗
2.加速Maven构件：如果项目配置了很多外部远程仓库的时候，构建速度就会大大降低
3.部署第三方构件：有些构件无法从外部仓库获得的时候，我们可以把这些构件部署到内部仓库(私服)中，供内部maven项目使用
4.提高稳定性，增强控制：Internet不稳定的时候，maven构建也会变的不稳定，一些私服软件还提供了其他的功能
5.降低中央仓库的负荷：maven中央仓库被请求的数量是巨大的，配置私服也可以大大降低中央仓库的压力


13 Nexus 的仓库分类
1 hosted 宿主仓库：主要用于部署无法从公共仓库获取的构件（如 oracle 的 JDBC 驱动）以及自己或第三方的项目构件；
2 proxy 代理仓库：代理公共的远程仓库； virtual 虚拟仓库：用于适配 Maven 1； 
3 group 仓库组：Nexus 通过仓库组的概念统一管理多个仓库，这样我们在项目中直接请求仓库组即可请求到仓库组管理的多个仓库。
我们看到仓库的类型主要有proxy、hosted、group类型，
proxy是代理的远程仓库，
hosted是指本地或者内部项目仓库，
group只是一个仓库组，它包含其他的几个仓库，
Releases是指发行版本（本地或者内部项目），
Snapshots是指正在构建的版本（本地或者内部项目），
Central是指中央仓库（远程中央仓库下载的构件放入此处）

14 问题详解
1）[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project pep-common: Compilation failure
[ERROR] No compiler is provided in this environment. Perhaps you are running on a JRE rather than a JDK?
分析： 对这个问题其实报错中已经说的很清楚了，看第一条最后的 Perhaps you are running on a JRE rather than a JDK?
 就是说你可能编译在一个JRE而不是JDK上，maven 编译是要JDK的，可能你的编译器配置了一个jre路径。
解决：在eclipse中，选择window→preference→java→Installed JREs 点add添加你的jdk路径，选jdk而不是jre,之前的报错原因就出在这里。

2） [ERROR] Failed to execute goal on project pep-generator: Could not resolve dependencies for project yunnex.pep:pep-generator:jar:0.0.1-SNAPSHOT: Failed to collect dependencies at yunnex.pep:pep-common:jar:0.0.1-SNAPSHOT: Failed to read artifact descriptor for yunnex.pep:pep-common:jar:0.0.1-SNAPSHOT: Failure to find yunnex.pep:pep:pom:${pep.version} in http://nexus.dev.yunnex.com/nexus/content/repositories/releases was cached in the local repository, resolution will not be reattempted until the update interval of releases has elapsed or updates are forced -> [Help 1]
解决方法：
将本地Maven仓库中已下载的相关依赖Jar删掉，从新build update工程即可.!

3）[ERROR] Failed to execute goal org.apache.maven.plugins:maven-resources-plugin:2.6:resources (default-resources) on project pep-web-admin: Cannot create resource output directory: D:\git\pep\pep-web-admin\target\classes -> [Help 1]




二、ms相关
1.什么是Maven？
   Maven主要服务于基于java平台的项目构建，依赖管理和项目信息管理。Maven项目对象模型(POM)，可以通过一小段描述信息来管理项目的构建，报告和文档的项目管理工具软件。
   它包含了一个项目对象模型，一组标准集合，一个项目生命周期，一个依赖管理系统和用来运行定义在生命周期阶段中插件目标的逻辑。当使用Maven的时候，你用一个明确定
   义的项目对象模型来描述你的项目，然后Maven可以应用横切的逻辑，这些逻辑来自于一组共享的（或自定义的）插件。

2.为什么选用Maven进行构建？（能为我们解决什么问题？）
	①添加第三方jar包
	按照最原始的做法，我们是手动复制jar包到项目WEB-INF/lib下，每个项目都会有一份，造成大量重复文件。而Maven将jar包放在本地仓库中统一管理，需要jar包只需要用坐标的方式引用即可。
	②jar包之间的依赖关系
	jar包之间往往不是独立的，很多jar需要在其他jar包的支持下才能够正常工作，称为jar包之间的依赖关系。如果我们手动去导入，要知道jar包之间的依赖关系并一一导入是及其麻烦而且容易出错的。如果使用Maven，它能够将当前jar包所依赖的其他所有jar包全部导入。
	③获取第三方jar包
	开发过程中我们需要用到很多jar包，每个jar包在官网获取的方式不尽相同，给工作带来了额外困难。但是使用Maven可以以坐标的方式依赖一个jar包，Maven从中央仓库进行下载，并同时下载这个jar包依赖的其他jar包。
	④将项目拆分为多个工程模块
	项目的规模越来越大，已经不可能通过package结构来划分模块，必须将项目拆分为多个工程协同开发。

3.Maven的优点
　①简化了项目依赖管理
　②易于上手，对于新手来说了解几个常用命令即可满足日常工作
　③便于与持续集成工具（jenkins）整合
　④便于项目升级，无论是项目本身还是项目使用的依赖
　⑤maven有很多插件，便于功能扩展，比如生产站点，自动发布版本等
　⑥为什么使用Maven中的各点

4.Maven的缺点
　①Maven是一个庞大的构建系统，学习难度大。（很多都可以这样说，入门容易[优点]但是精通难[缺点]）
　②Maven采用约定约定优于配置的策略，虽然上手容易但是一旦出现问题，难于调试
　③中国网络环境较差，很多repository无法访问

5.什么是Maven的坐标
　Maven的坐标通过groupId，artifactId，version唯一标志一个构件。groupId通常为公司或组织名字，artifactId通常为项目名称，versionId为版本号。

6.通过坐标如何定位地址
　加上groupId为org.codehaus.mojo,artifactId为myproject，versionId为v1.0.0，则对应地址为：仓库目录（.m2）/org/codehaus/mojo/myproject/v1.0.0

7.Maven的依赖范围有哪些（在scope中指定）
　compile：默认范围，如果未指定任何范围，则使用该范围。编译依赖项在所有（编译，测试，运行）类路径中都可用。此外，这些依赖关系会传播到依赖的项目
　provided：这很像compile，但表示您希望JDK或容器在运行时提供它。它只在编译和测试类路径上可用，不可传递。
　runtime：此范围表示编译不需要依赖项，但需要执行依赖项。它在运行时和测试类路径中，但不在编译类路径中。（servlet-api）
　test：表示应用程序的正常使用不需要依赖项，并且仅在测试编译和执行阶段可用。它不是传递的。（jdbc）
　system：系统依赖范围。该依赖与三种classpath的关系和provided依赖范围完全一致。但是，使用system范围的依赖时必须通过systemPath元素显式地指定依赖文件的路径。由于此类依赖不是通过Maven仓库解析的，而且往往与本机系统绑定，可能造成构建的不可移植。

8.Maven生命周期
　有三套什么周期，分别为clean，default，site
　   clean：
	此生命周期旨在给工程做清理工作，它主要包含以下阶段：
	pre-clean - 执行项目清理前所需要的工作。
	clean - 清理上一次build项目生成的文件。
	post-clean - 执行完成项目清理所需的工作。
	　default：
	validate - 验证项目是否正确且所有必要的信息都可用。
	initialize - 初始化构建工作，如：设置参数，创建目录等。
	generate-sources - 为包含在编译范围内的代码生成源代码.
	process-sources - 处理源代码, 如过滤值.
	generate-resources -
	process-resources - 复制并处理资源文件，至目标目录，准备打包。
	compile - 编译项目中的源代码.
	process-classes - 为编译生成的文件做后期工作, 例如做Java类的字节码增强.
	generate-test-sources - 为编译内容生成测试源代码.
	process-test-sources - 处理测试源代码。
	generate-test-resources -
	process-test-resources - 复制并处理资源文件，至目标测试目录。
	test-compile - 将需测试源代码编译到路径。一般来说，是编译/src/test/java目录下的java文件至目标输出的测试classpath目录中。
	process-test-classes -
	test - 使用合适的单元测试框架运行测试。这些测试代码不会被打包或部署。
	prepare-package -
	package - 接受编译好的代码，打包成可发布的格式，如 JAR 。
	pre-integration-test -
	integration-test - 按需求将发布包部署到运行环境。
	post-integration-test -
	verify -
	install -将包安装到本地仓库，给其他本地引用提供依赖。
	deploy -完成集成和发布工作，将最终包复制到远程仓库以便分享给其他开发人员。
	　site：
	pre-site - 执行一些生成项目站点前的准备工作。
	site - 生成项目站点的文档。
	post-site - 执行需完成站点生成的工作，如站点部署的准备工作。
	site-deploy - 向制定的web服务器部署站点生成文件。

9.Maven命令
　mvn archetype:generate 创建Maven项目
　mvn compile 编译源代码
　mvn deploy 发布项目
　mvn test-compile 编译测试源代码
　mvn test 运行应用程序中的单元测试
　mvn site 生成项目相关信息的网站
　mvn clean 清除项目目录中的生成结果
　mvn package 根据项目生成的jar
　mvn install 在本地Repository中安装jar
　mvn eclipse:eclipse 生成eclipse项目文件
　mvnjetty:run 启动jetty服务
　mvntomcat:run 启动tomcat服务
　mvn clean package -Dmaven.test.skip=true:清除以前的包后重新打包，跳过测试类

10.依赖的解析机制
　当依赖的范围是 system 的时候，Maven 直接从本地文件系统中解析构件。
　根据依赖坐标计算仓库路径，尝试直接从本地仓库寻找构件，如果发现对应的构件，就解析成功。
　如果在本地仓库不存在相应的构件，就遍历所有的远程仓库，发现后，下载并解析使用。
　如果依赖的版本是 RELEASE 或 LATEST，就基于更新策略读取所有远程仓库的元数据文件（groupId/artifactId/maven-metadata.xml），将其与本地仓库的对应元合并后，计算出 RELEASE 或者 LATEST 真实的值，然后基于该值检查本地仓库，或者从远程仓库下载。
　如果依赖的版本是 SNAPSHOT，就基于更新策略读取所有远程仓库的元数据文件，将它与本地仓库对应的元数据合并，得到最新快照版本的值，然后根据该值检查本地仓库，或从远程仓库下载。
　如果最后解析得到的构件版本包含有时间戳，先将该文件下载下来，再将文件名中时间戳信息删除，剩下 SNAPSHOT 并使用（以非时间戳的形式使用）。

11.插件的解析机制
　与依赖的构件一样，插件也是基于坐标保存在Maven仓库中。在用到插件的时候会先从本地仓库查找插件，如果本地仓库没有则从远程仓库查找插件并下载到本地仓库。与普通的依赖构件不同的是，Maven会区别对待普通依赖的远程仓库与插件的远程仓库。前面提到的配置远程仓库只会对普通的依赖有效果。当Maven需要的插件在本地仓库不存在时是不会去我们以前配置的远程仓库查找插件的，而是需要有专门的插件远程仓库。

12.如何聚合多模块
　配置一个打包类型为pom的聚合模块，然后在该pom中使用<module>元素声明要聚合的模块。

13.如何管理多模块项目依赖的版本
　通过在父模块中声明dependencyManagement和pluginManagement， 然后让子模块通过<parent>元素指定父模块，这样子模块在定义依赖是就可以只定义groupId和artifactId，自动使用父模块的version,这样统一整个项目的依赖的版本。

14.如何解决依赖传递引起的版本冲突
　可通过dependency的exclusion元素排除掉依赖

15.Maven依赖原则
　①最短路径原则（依赖传递的路径越短越优先）
　②pom文件申明顺序优先（路径长度一样，则先申明的优先）
　③覆写原则（当前pom文件里申明的直接覆盖父工程传过来的）

16.Maven版本规则
　主版本.次版本.增量版本
　主版本：一般来说代表了项目的重大的架构变更
　次版本：一般代表了一些功能的增加或变化，但没有架构的变化
　增量版本：一般是一些小的 bug fix ，不会有重大的功能变化
---------------------------------------------------------------------------------------------------------------
------------------------------------------maven basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------mongodb basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 MongoDB介绍
MongoDB是面向文档的非关系型数据库，不是现在使用最普遍的关系型数据库，其放弃关系模型的原因就是为了获得更加方便的扩展、稳定容错等特性。面向文档的基本思路就是：将关系模型中的“行”的概念换成“文档（document）”模型。面向文档的模型可以将文档和数组内嵌到文档中。因此，实际中可以用一条数据表示非常复杂的结构。
MongoDB没有预定义模式：文档的键(key)和值(value)不再是固定的类型和大小，而且根据需求要添加或者删除字段变得更容易了。由于没有模式需要更改，通常不需要迁移大量数据。不必将所有数据都放到一个模子里面，应用层可以处理新增或丢失的键。这样开发者可以非常容易地变更数据模型。实际应用中，随着数据量的增大，数据库都要进行扩展。扩展有纵向扩展和横向扩展。纵向扩展是使用计算能力更强的机器，也是最省力的方法，但是很容易达到物理极限，无论花多少钱也买不到最新的机器了。横向扩展就是通过分区将数据分散到更多的机器上。MongoDB的设计采用横向扩展。面向文档的数据模型使它很容易地在多台服务器之间进行数据分割。还可以自动处理跨集群的数据和负载，自动重新分配文档，以及将用户请求路由到正确的机器上。开发者根本不用考虑数据库层次的扩展问题，需要扩展数据库时，在集群中添加机器即可，MongoDB会自动处理后续的事情。MongoDB有如上各种特性，但为了达到这些，他也放弃了关系型数据库的某些功能如表连接join和复杂的多行事务。

2 MongoDB使用场景
mongodb的主要目标是在键/值存储方式（提供了高性能和高度伸缩性）以及传统的RDBMS系统（丰富的功能）架起一座桥梁，集两者的优势于一身。
（1）MongoDB适用于以下场景
  a.网站数据：mongo非常适合实时的插入，更新与查询，并具备网站实时数据存储所需的复制及高度伸缩性。
  b.缓存：由于性能很高，mongo也适合作为信息基础设施的缓存层。在系统重启之后，由mongo搭建的持久化缓存可以避免下层的数据源过载。
  c.大尺寸、低价值的数据：使用传统的关系数据库存储一些数据时可能会比较贵，在此之前，很多程序员往往会选择传统的文件进行存储。
  d.高伸缩性的场景：mongo非常适合由数十或者数百台服务器组成的数据库。
  e.用于对象及JSON数据的存储：mongo的BSON数据格式非常适合文档格式化的存储及查询。
（2）MongoDB不适合的场景：
  a.高度事物性的系统：例如银行或会计系统。传统的关系型数据库目前还是更适用于需要大量原子性复杂事务的应用程序。
  b.传统的商业智能应用：针对特定问题的BI数据库会对产生高度优化的查询方式。对于此类应用，数据仓库可能是更合适的选择。
  c.需要SQL的问题。

3 物理内存和虚拟内存
物理内存所指的就是你主板上所插的可以看到的内存条，它的容量有64M、128M、256M、512M等不同规格。
内存在计算机中的作用很大，电脑中所有运行的程序都需要经过内存来执行，如果执行的程序很大或很多，就会导致内存消耗殆尽。
为了解决这个问题，Windows中运用了虚拟内存技术，即拿出一部分硬盘空间来充当内存使用，当内存占用完时，电脑就会自动调用硬盘来充当内存，以缓解内存的紧张。举一个例子来说，如果电脑只有128MB物理内存的话，当读取一个容量为200MB的文件时，就必须要用到比较大的虚拟内存，文件被内存读取之后就会先储存到虚拟内存，等待内存把文件全部储存到虚拟内存之后，跟着就会把虚拟内存储存的文件释放到原来的安装目录里了。
虚拟内存是作业系统在硬盘上建立一个档案，把物理内存中不常用的部分拷贝起来，再把那个部分的物理内存清空，方便别的程序写入。虚拟内存的大小是可以自定，但是大小通常在物理内存的1到2倍之间，太大的话，虚拟内存的效能会下降。因为虚拟内存在硬盘上，所以它的速度是取决于硬盘的存取速度、碎片的多少等。另外，因为它不像物理内存一样，资料与停机后消失，所以虚拟内存是可以透过解密方法读取其中的资料。

4 Memeory-Mapped Files
@内存映射文件是OS通过mmap在内存中创建一个数据文件，这样就把文件映射到一个虚拟内存的区域。
@虚拟内存对于进程来说，是一个物理内存的抽象，寻址空间大小为2^64
@操作系统通过mmap来把进程所需的所有数据映射到这个地址空间(红线)，然后再把当前需要处理的数据映射到物理内存(灰线)
@当进程访问某个数据时，如果数据不在虚拟内存里，触发page fault，然后OS从硬盘里把数据加载进虚拟内存和物理内存
@如果物理内存满了，触发swap-out操作，这时有些数据就需要写回磁盘，如果是纯粹的内存数据，写回swap分区，如果不是就写回磁盘。

5 MongoDB的优势与劣势
（1）优势
快速！基于内存，将热数据存放在物理内存中（不仅仅只是索引和少部分数据），从而提高了整体速度和效率。
高扩展性！MongoDB的高可用和集群架构拥有十分高的扩展性。
自身的FailOver机制！在副本集中，当主库遇到问题，无法继续提供服务的时候，副本集将选举一个新的主库继续提供服务。
JSon格式的数据！MongoDB的Bson和JSon格式的数据十分适合文档格式的存储与查询。
 
（2）劣势
应用经验少！由于NoSQL兴起时间短，应用经验相比关系型数据库较少。
由于以往用到的都是关系型数据库，可能会造成使用者一开始的不适应。
无事务机制！MongoDB本身没有自带事务机制，若需要在MongoDB中实现事务机制，需通过一个额外的表，从逻辑上自行实现事务。

6  MongoDB与MYSQL对比  
（1）基础比较 
数据库	MongoDB	MySQL
数据库模型	非关系型	关系型
存储方式	以类JSON的文档的格式存储	不同引擎有不同的存储方式
查询语句	MongoDB查询方式（类似JavaScript的函数）	SQL语句
数据处理方式	基于内存，将热数据存放在物理内存中，从而达到高速读写	不同引擎有自己的特点
成熟度	新兴数据库，成熟度较低	成熟度高
广泛度	NoSQL数据库中，比较完善且开源，使用人数在不断增长	开源数据库，市场份额不断增长
事务性	仅支持单文档事务操作，弱一致性	支持事务操作
占用空间	占用空间大	占用空间小
join操作	MongoDB没有join	MySQL支持join

7 分片     
（1）到目前为止，你都是把MongoDB当做一台服务器在用，每个mongod实例都包含应用程序数据的完整副本。就算使用了复制，每个副本也都是完整克隆了其他副本的数据。对于大多数应用程序而言，在一台服务器上保存完整数据集是完全可以接受的。但随着数据量的增长，以及应用程序对读写吞吐量的要求越来越高，普通服务器渐渐显得捉襟见肘了。尤其是这些服务器可能无法分配足够的内存，或者没有足够的CPU核数来有效处理工作负荷。除此之外，随着数据量的增长，要在一块磁盘或者一组RAID阵列上保存和管理备份如此大规模的数据集也变得不太现实。如果还想继续使用普通硬件或者虚拟硬件来托管数据库，那么这对这类问题的解决方案就是将数据库分布到多台服务器上，这种方法称之为分片。
（2）为数众多的Web应用程序，知名的如Flicker和LiveJournal，都实现了手动分片，将负载分布到多台MySQL数据库上。在这些实现中，分片逻辑都寄生于应用程序上。要明白这是如何实现的，想象一下，假如你有很多用户，需要将Users表分布到多台数据库服务器上。你可以指定一台数据库作为元数据库。这台数据库包含每个用户ID（或者用户ID范围）到指定分片映射关系的元数据。因此，要查询一个用户实际涉及两次查询：第一次查询访问元数据库以获得用户的分片位置，第二次查询直接访问包含用户数据的分片。对于这些Web应用程序而言，手动分片解决了负载问题，但气质并非无懈可击。最明显的问题就是迁移数据非常困难。如果单个分片负载过重，将其中的数据迁移到其他分片的过程完全是手动的。手动分片的第二个问题在于编写可靠的应用程序代码对于读写请求进行路由，并且将数据库作为一个整体进行管理，这也是非常困难的。最近也出现了管理手动分片的的框架，
最著名的就是Twitter的Gizzard。
（3）但正如那些手动分片数据库的人所说，要把事情做好并非易事。MongoDB中有一大块工作就是为了解决这个问题。因为分片是MongoDB的核心内容，所以用户无需担心在需求水平扩展时要自己设计外置分片框架。在处理困难的跨分片数据均衡问题时，这点尤为重要。这些代码并非那些大多数人在一个周末能够写出来的东西。也许最值得一提的是MongoDB在设计时为应用程序提供了统一接口，无论是在分片前，还是在分片后。也就是说，在数据库需要转换为分片架构时，应用程序几乎无需改变。

8 何时分片
（1）这个问题的答案比你想的简单得多。我们之前已经说过把索引和工作数据集放在内存里时很重要的，这也是分片的主要原因。如果应用程序的数据集持续无限增长，那么迟早一天，内存会容纳不下这些数据。如果你正在使用亚马逊的EC2，那么这个阈值是68GB。或者你可以运行自己的硬件，并使用远高于68GB的内存，这样便能延后一段时间再做分片。但没有哪台机器内存时无限的，因此你早晚都会用到分片。
（2）不可否认，还有一些其他的应对措施。举例来说，如果你有自己的硬件，而且可以将所有的数据都保存在固态硬盘上，那么可以增加数据内存比，而不会为性能带来负面影响。还有一种情况，工作集是总数据量中的一部分，这是可以使用相对较小的内存。另一方面，如果有特殊的写负载要求，那么可以在数据达到内存大小之前先进行适当的分片，原因是需要将负载分到多台机器上，以便能够获得想要的吞吐量。五论哪种情况，对现有系统进行分片的决定都要基于以下几点--磁盘活动、系统负载以及最重要的工作集大小与可用内存的比例。
	
9 分片的工作原理
@分片
MongoDB分片集群将数据分布在一个或多个分片上。每个分片部署成一个MongoDB副本集，该副本集保存了集群整体数据的一部分。因为每个分片都是一个副本集，所以他们拥有自己的复制机制，能够自动进行故障转移。你可以直接连接单个分片，就像连接单独的副本集一样。但是，如果连接的副本集是分片集群的一部分，那么只能看到部分数据。
@mongos路由器
如果每个分片都包含部分集群数据，那么还需要一个接口连接整个集群。这就是mongos。mongos进程是一个路由器，将所有的读写请求指引到合适的分片上。如此一来，mongos为客户端提供了一个合理的系统视图。mongos进程是轻量级且非持久化的。它们通常运行与与应用服务器相同的机器上，确保对任意分片的请求只经过一次网络跳转。换言之，应用程序连接本地的mongos，而mongos管理了指向单独分片的连接。
@配置服务器
如果mongs进程是非持久化的，那么必须有地方能持久保存集群的公认状态；这就是配置服务器的工作，其中持久化了分片集群的元数据，改数据包括：每个数据库，集合和特定范围数据的位置；一份变更记录，保存了数据在分片之间进行迁移的历史信息。配置服务器中保存的元数据是某些特定功能和集群维护是的重中之重。举例来说，每次有mongos进程启动，它都会从配置服务器中获取一份元数据的副本。没有这些数据，就无法获得一致的分片集群视图。该数据的重要性对配置服务器的设计和部署也有影响。如上面结构图中所示，有三个配置服务器，但它们并不是以副本集的形式部署的。它们比异步复制要求更严格；mongos进程向配置服务器写入时，会使用两阶段提交。这能保证配置服务器之间的一致性。在各种生产环境的分片部署中，必须运行三个配置服务器，这些服务器都必须部署在独立的机器上以实现冗余。
   
10 分片核心 
（1）分布式存储系统
所谓分布式系统，就是利用多个独立的计算机来解决单个节点（计算机）无法处理的存储、计算问题，这是非常典型的分而治之的思想。每个节点只负责原问题（即整个系统需要完成的任务）的一个子集，那么原问题如何拆分到多个节点？在分布式存储系统中，任务的拆分即数据分片。需要解决的两个最主要的问题，即数据分片和数据冗余。
（2）三个问题
@如何做数据分片，即如何将数据映射到节点
@数据分片的特征值，即按照数据中的哪一个属性（字段）来分片
@数据分片的元数据的管理，如何保证元数据服务器的高性能、高可用，如果是一组服务器，如何保证强一致性
（3）如何做数据分片，即如何将数据映射到节点
三种分片方式：hash方式，一致性hash（consistent hash），按照数据范围（range based）。
为了后面分析不同的数据分片方式，假设有三个物理节点，编号为N0， N1， N2；有以下几条记录：
（4）hash方式
在哈希表中，最为简单的散列函数是 mod N（N为表的大小）。即首先将关键值计算出hash值（这里是一个整型），通过对N取余，余数即在表中的位置。
数据分片的hash方式也是这个思想，即按照数据的某一特征（key）来计算哈希值，并将哈希值与系统中的节点建立映射关系,从而将哈希值不同的数据分布到不同的节点上。
@优点：按照hash方式做数据分片，映射关系非常简单；需要管理的元数据也非常之少，只需要记录节点的数目以及hash方式就行了。
@缺点：但hash方式的缺点也非常明显：当加入或者删除一个节点的时候，大量的数据需要移动。比如在这里增加一个节点N3，因此hash方式变为了mod 4
在这种方式下，是不满足单调性（Monotonicity）的：如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。 
在工程中，为了减少迁移的数据量，节点的数目可以成倍增长，这样概率上来讲至多有50%的数据迁移。
（5）一致性hash
一致性hash是将数据按照特征值映射到一个首尾相接的hash环上，同时也将节点（按照IP地址或者机器名hash）映射到这个环上。对于数据，从数据在环上的位置开始，顺时针找到的第一个节点即为数据的存储节点。这里仍然以上述的数据为例，假设id的范围为［0， 1000］，N0， N1， N2在环上的位置分别是100， 400， 800
一致性hash在增加或者删除节点的时候，受到影响的数据是比较有限的，比如这里增加一个节点N3，其在环上的位置为600，因此，原来N2负责的范围段（400， 800］现在由N3（400， 600] N2(600, 800]负责，因此只需要将记录R7(id:533) 从N2,迁移到N3:
不难发现一致性hash方式在增删的时候只会影响到hash环上响应的节点，不会发生大规模的数据迁移。
（6）range based
简单来说，就是按照关键值划分成不同的区间，每个物理节点负责一个或者多个区间。其实这种方式跟一致性hash有点像，可以理解为物理节点在hash环上的位置是动态变化的。
还是以上面的数据举例，三个节点的数据区间分别是N0(0, 200]， N1(200, 500]， N2(500, 1000]。
注意，区间的大小不是固定的，每个数据区间的数据量与区间的大小也是没有关系的。比如说，一部分数据非常集中，那么区间大小应该是比较小的，即以数据量的大小为片段标准。在实际工程中，一个节点往往负责多个区间，每个区间成为一个块（chunk、block），每个块有一个阈值，当达到这个阈值之后就会分裂成两个块。这样做的目的在于当有节点加入的时候，可以快速达到均衡的目的。
（7）分片特征值的选择
上面的三种方式都提到了对数据的分片是基于关键值、特征值的。这个特征值在不同的系统中有不同的叫法，比如MongoDB中的sharding key， Oracle中的Partition Key，不管怎么样，这个特征值的选择都是非常非常重要的。
（8）元数据服务器
在上面讨论的三种数据分片分式中，或多或少都会记录一些元数据：数据与节点的映射关系、节点状态等等。
我们称记录元数据的服务器为元数据服务器（metaserver），不同的系统叫法不一样，比如master、configserver、namenode等。
（9）HDFS元数据
上图中NN即NameNode， DN即DataNode（即实际存储数据的节点）。从图中可以看到， 两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务。
Active NN与standby NN之间的数据同步通过共享存储实现，共享存储系统保证了Namenode的高可用。为了保证元数据的强一致性，在进行准备切换的时候，新的Active NN必须要在确认元数据完全同步之后才能继续对外提供服务。

11 文档document
文档：多个 键key 及其关联的 值value 有序地 放置在一起。
（1）文档(document)是MongoDB中数据的基本单元，非常类似于关系型数据库系统中的行(但是比行要复杂的多)。
（2）集合(collection)就是一组文档，如果说MongoDB中的文档类似于关系型数据库中的行，那么集合就如同表。
（3）MongoDB的单个计算机可以容纳多个独立的数据库，每一个数据库都有自己的集合和权限。
（4）MongoDB自带简洁但功能强大的JavaScript shell，这个工具对于管理MongoDB实例和操作数据作用非常大。
（5）每一个文档都有一个特殊的键”_id”,它在文档所处的集合中是唯一的，相当于关系数据库中的表的主键。

12 MongoDB体系结构
1） MongoDB是一个可移植的数据库，它在流行的每一个平台上都可以使用，即所谓的跨平台性，在不同的操作系统上虽然略有差别，但是从整体架构上来看，
MongoDB在不同的平台上是一样的，如数据逻辑结构和数据存储等等。
2） 一个运行着的MongoDB数据库就可以看成是一个MongoDB Server，该Server由实例和数据库组成，在一般情况下，一个MongoDB Server机器上包含一个实例或者多个与之对应的数据库，但是在特殊情况下，如硬件投入成本或者特殊的应用需求，也允许一个Server机器上可以有多个实例或者多个数据库。
MongoDB中一系列物理文件(数据文件、日志文件等)的集合与之对应的逻辑结构(集合、文档等)被称之为数据库，简单的说，就是数据库是由一系列与磁盘有关系的物理文件的组成。
3） 数据逻辑结构
很多人在学习MongoDB体系结构的时候会遇到各种各样的问题，我在这里给大家简单的介绍下MongoDB体系结构之一的逻辑结构，MongoDB的逻辑结构是一种层次结构，
主要由：文档(Document)、集合(Collection)、数据库(database)这三部分组成，逻辑结构是面向用户的，用户使用MongoDB开发应用程序使用的就是逻辑结构。
    
13 数据存储结构
MongoDB对国内用户来说比较新，它就像是一个黑盒子，但是如果对于它内部的数据存储了解多一些的话，那么就会很快的理解和驾驭MongoDB，让它发挥更大的作用。
MongoDB的默认数据目录是/daba/db,它负责存储所有的MongoDB的数据文件，在MongoDB内部，每个数据库都包含一个.ns文件和一些数据文件，而且这些文件会随着数据量的增加变的越来越多，所以如果系统中有一个叫做foo的数据库，那么构成foo这个数据库的文件就会由foo.ns、foo.0、foo.1、foo.2等组成，具体如下：
MongoDB内部有预分配空间的机制，每个预分配的文件都用0进行填充，由于有了这个机制，MongoDB始终保持额外的空间和空余的数据文件，从而有效避免了由于数据暴增而带来的磁盘压力过大的问题。
由于表中数据量的增加，数据文件每新分配一次，它的大小都会是上一个数据文件大小的2倍，每个数据文件最大2G，这样的机制有利于防止较小的数据库浪费过多的磁盘空间，同时又能保证较大的数据库有相应的预留空间使用。
数据库的每张表都对应一个命名空间，每个索引也有对应的命名空间，这些命名空间的元数据集中在*.ns文件中。
在下图中。foo这个数据库包含3个文件用于存储表和索引数据，foo.2文件属于预分配的空文件，foo.0和foo.1这两个数据文件被分为了相应的盘区对应不同的名字空间。

14 MongoDB、Cassandra 和 HBase比较
1） MongoDB：源于开发人员，为开发人员服务
在众多NoSQL的方案中，MongoDB的Stirman指出，MongoDB的瞄准了适合各种应用的平衡的方法。它的功能接近于传统的关系型数据库，MongoDB的用户不仅可以利用其横向扩展机器的云基础架构的优势，并且，因为它能够轻松定义各种灵活的数据模型，所以可以支持不同类型的数据集存储。MongoDB通常是开发人员第一个尝试的NoSQL数据库，因为它是很容易学习。Will Shulman，MongoLab（一个MongoDB服务提供商）的CEO，是这样说的：MongoDB中的成功在很大程度上是因为它数据结构存储的创新，让我们更容易和更具表现力地定义我们应用程序中的数据模型。在通常开发和应用场景中，和原有数据库具有相同的基本数据模型是有极大好处的，因为它简化了应用程序开发的任务，另一方面，消除了复杂的数据格式代码转换层。当然，像任何其他技术一样，MongoDB中都有其长处和短处。 MongoDB是专门为OLTP（On-Line Transaction Processing，联机事务处理系统）模式。如果您需要复杂的事务处理，它不是一个好的选择。然而，MongoDB的简单性使其成为一个优秀的存储。（注：MongoDB以文档的形式存储数据，不支持事务和表连接。因此查询的编写、理解和优化都容易得多。）
2） Cassandra：规模化安全运行
三种数据库中，至少两种数据库具有简单特性：开发简单，操作简便。而MongoDB赢得人心的原因是简单的开发应用，Cassandra赢得人心是因为易于管理的规模。DataStax的McFadin告诉我，用户往往倾向于使用Cassandra ，是因为特别在大规模集群下，增强一个关系型数据的性能、可靠性是非常困难的。一位前甲骨文DBA，McFadin是兴高采烈地发现，“复制和可扩放性是基础”，Cassandra 特点是从一开始设计就解决这个问题。在RDBMS中的世界，数据库功能，拓展和复制对很多开发者用户来说，是一个难题。这个问题在过往的企业规模小的时候，不是一个大问题。而在今天，它很迅速地成为大问题。
我从McFadin和其他人那里获知，Cassandra在机器拓展部署上，表现特别出色。Cassandra自带的备份机制，保证各个数据中心的数据安全。至于增加容量到集群，“你只需启动一台新机器，并告诉Cassandra那里的新节点，”McFadin说，“然后，它完成其他剩下的事情。”
优秀的可拓展性，加上出色的写入和可观的查询性能，加起来成为Cassandra高性能的核心。NoSQL的一篇文章认为Cassandra在集群规模管理方面非常出色，但它需要一个博士学位才能上手。
事实并非如此，McFadin坚持认为：
在复制、读取和写入是故意简单。你可以在几个小时内学会Cassandra的核心功能。在部署这项新技术的时候，为给开发者带来很多的信心，因为比较少引入“黑盒子”内的技术细节和复杂的故障模式原理。这意味着主要的开发成本，是对Cassandra数据模型的理解，以及如何结合您的应用程序。鉴于Cassandra的CQL查询语言（类似于SQL，实际上不是SQL），McFadin说，学习这个也不困难。更重要的是，他告诉我，“Cassandra回报给你的是，在一个数据库中：没有戏剧性的场（故障）出现。这就是用户喜欢使用Cassandra的原因。”
3） HBase：Hadoop的知心伙伴
HBase，像Cassandra一样是个通过key-value面向列存储的服务。因为它和Hadoop有着“共同血统”，被广泛使用。事实上，正如Cloudera的Kestelyn所说的那样，“HBase提供了一个基于记录的存储层，能够快速随机读取和写入数据，正好弥补了Hadoop的缺陷，Hadoop侧重系统吞吐量，而牺牲I / O读取效率为代价。”Kestelyn接着说：更改有效录入到内存中，以达到最大的访问量，同时将数据保存到HDFS。这种设计使基于Hadoop的EDH（enterprise data hub，企业数据中心）服务，能够实时完成随机读写存储数据，但仍拥有HDFS的高容错性和耐用性。Hadoop的亲和力，不是HBase数据库中的人气排名不断上升的唯一原因。类似Cassandra，HBase是Google的Bigtable的开源实现转化成的数据库，天然被设计为高可扩展性。Hbase可以利用任何数量服务器的磁盘、内存和CPU资源，同时拥有极佳的扩展功能，如自动分片。当系统负载和性能要求不断增加，HBase的可通过简单增加服务器节点的方式无限拓展。 HBase从底层设计上保证，在确保数据一致性的同时，提供最佳性能。但规模不是它的唯一用途。Kestelyn指出，“由于它与Hadoop的生态系统紧密集成，对于用户和应用程序来说，数据是容易获取的，可以通过SQL的方式查询（使用Cloudera的Impala，Phoenix，或Hive），甚至自由文本搜索（使用Cloudera Search）。“




二、ms相关
1. 你说的NoSQL数据库是什么意思?NoSQL与RDBMS直接有什么区别?为什么要使用和不使用NoSQL数据库?说一说NoSQL数据库的几个优点?
NoSQL是非关系型数据库，NoSQL = Not Only SQL。
关系型数据库采用的结构化的数据，NoSQL采用的是键值对的方式存储数据。
在处理非结构化/半结构化的大数据时；在水平方向上进行扩展时；随时应对动态增加的数据项时可以优先考虑使用NoSQL数据库。
在考虑数据库的成熟度；支持；分析和商业智能；管理及专业性等问题时，应优先考虑关系型数据库。

2. NoSQL数据库有哪些类型?
NoSQL数据库的类型
例如：MongoDB, Cassandra, CouchDB, Hypertable, Redis, Riak, Neo4j, HBASE, Couchbase, MemcacheDB, RevenDB and Voldemort are the examples of NoSQL databases.。

3. MySQL与MongoDB之间最基本的差别是什么?
MySQL和MongoDB两者都是免费开源的数据库。MySQL和MongoDB有许多基本差别包括数据的表示(data representation)，查询，关系，事务，schema的设计和定义，标准化(normalization)，速度和性能。
通过比较MySQL和MongoDB，实际上我们是在比较关系型和非关系型数据库，即数据存储结构不同。

4. 你怎么比较MongoDB、CouchDB及CouchBase?
MongoDB和CouchDB都是面向文档的数据库。MongoDB和CouchDB都是开源NoSQL数据库的最典型代表。 除了都以文档形式存储外它们没有其他的共同点。MongoDB和CouchDB在数据模型实现、接口、对象存储以及复制方法等方面有很多不同。
细节可以参见下面的链接：
MongDB vs CouchDB
CouchDB vs CouchBase

5. MongoDB成为最好NoSQL数据库的原因是什么?
以下特点使得MongoDB成为最好的NoSQL数据库：
面向文件的
高性能
高可用性
易扩展性
丰富的查询语言

6.32位系统上有什么细微差别?
journaling会激活额外的内存映射文件。这将进一步抑制32位版本上的数据库大小。因此，现在journaling在32位系统上默认是禁用的。

7. journal回放在条目(entry)不完整时(比如恰巧有一个中途故障了)会遇到问题吗?
每个journal (group)的写操作都是一致的，除非它是完整的否则在恢复过程中它不会回放。

8. 分析器在MongoDB中的作用是什么?
MongoDB中包括了一个可以显示数据库中每个操作性能特点的数据库分析器。通过这个分析器你可以找到比预期慢的查询(或写操作);利用这一信息，比如，可以确定是否需要添加索引。

9. 名字空间(namespace)是什么?
MongoDB存储BSON对象在丛集(collection)中。数据库名字和丛集名字以句点连结起来叫做名字空间(namespace)。

10. 如果用户移除对象的属性，该属性是否从存储层中删除?
是的，用户移除属性然后对象会重新保存(re-save())。

11. 能否使用日志特征进行安全备份?
是的。

12. 允许空值null吗?
对于对象成员而言，是的。然而用户不能够添加空值(null)到数据库丛集(collection)因为空值不是对象。然而用户能够添加空对象{}。

13. 更新操作立刻fsync到磁盘?
不会，磁盘写操作默认是延迟执行的。写操作可能在两三秒(默认在60秒内)后到达磁盘。例如，如果一秒内数据库收到一千个对一个对象递增的操作，仅刷新磁盘一次。(注意，尽管fsync选项在命令行和经过getLastError_old是有效的)(译者：也许是坑人的面试题??)。

14. 如何执行事务/加锁?
MongoDB没有使用传统的锁或者复杂的带回滚的事务，因为它设计的宗旨是轻量，快速以及可预计的高性能。可以把它类比成MySQL MylSAM的自动提交模式。通过精简对事务的支持，性能得到了提升，特别是在一个可能会穿过多个服务器的系统里。

15. 为什么我的数据文件如此庞大?
MongoDB会积极的预分配预留空间来防止文件系统碎片。

16. 启用备份故障恢复需要多久?
从备份数据库声明主数据库宕机到选出一个备份数据库作为新的主数据库将花费10到30秒时间。这期间在主数据库上的操作将会失败--包括写入和强一致性读取(strong consistent read)操作。然而，你还能在第二数据库上执行最终一致性查询(eventually consistent query)(在slaveOk模式下)，即使在这段时间里。

17. 什么是master或primary?
它是当前备份集群(replica set)中负责处理所有写入操作的主要节点/成员。在一个备份集群中，当失效备援(failover)事件发生时，一个另外的成员会变成primary。

18. 什么是secondary或slave?
Seconday从当前的primary上复制相应的操作。它是通过跟踪复制oplog(local.oplog.rs)做到的。

19. 我必须调用getLastError来确保写操作生效了么?
不用。不管你有没有调用getLastError(又叫"Safe Mode")服务器做的操作都一样。调用getLastError只是为了确认写操作成功提交了。
当然，你经常想得到确认，但是写操作的安全性和是否生效不是由这个决定的。

20. 我应该启动一个集群分片(sharded)还是一个非集群分片的 MongoDB 环境?
为开发便捷起见，我们建议以非集群分片(unsharded)方式开始一个 MongoDB 环境，除非一台服务器不足以存放你的初始数据集。从非集群分片升级到集群分片(sharding)是无缝的，所以在你的数据集还不是很大的时候没必要考虑集群分片(sharding)。

21. 分片(sharding)和复制(replication)是怎样工作的?
每一个分片(shard)是一个分区数据的逻辑集合。分片可能由单一服务器或者集群组成，我们推荐为每一个分片(shard)使用集群。

22. 数据在什么时候才会扩展到多个分片(shard)里?
MongoDB 分片是基于区域(range)的。所以一个集合(collection)中的所有的对象都被存放到一个块(chunk)中。只有当存在多余一个块的时候，才会有多个分片获取数据的选项。现在，每个默认块的大小是 64Mb，所以你需要至少 64 Mb 空间才可以实施一个迁移。

23. 当我试图更新一个正在被迁移的块(chunk)上的文档时会发生什么?
更新操作会立即发生在旧的分片(shard)上，然后更改才会在所有权转移(ownership transfers)前复制到新的分片上。

24. 如果在一个分片(shard)停止或者很慢的时候，我发起一个查询会怎样?
如果一个分片(shard)停止了，除非查询设置了“Partial”选项，否则查询会返回一个错误。如果一个分片(shard)响应很慢，MongoDB则会等待它的响应。

25. 我可以把moveChunk目录里的旧文件删除吗?
没问题，这些文件是在分片(shard)进行均衡操作(balancing)的时候产生的临时文件。一旦这些操作已经完成，相关的临时文件也应该被删除掉。
但目前清理工作是需要手动的，所以请小心地考虑再释放这些文件的空间。

26. 我怎么查看 Mongo 正在使用的链接?
db._adminCommand("connPoolStats");

27. 如果块移动操作(moveChunk)失败了，我需要手动清除部分转移的文档吗?
不需要，移动操作是一致(consistent)并且是确定性的(deterministic);
一次失败后，移动操作会不断重试;当完成后，数据只会出现在新的分片里(shard)。

28. 如果我在使用复制技术(replication)，可以一部分使用日志(journaling)而其他部分则不使用吗?
可以。

29.当更新一个正在被迁移的块（Chunk）上的文档时会发生什么？
更新操作会立即发生在旧的块（Chunk）上，然后更改才会在所有权转移前复制到新的分片上。

30.MongoDB在A:{B,C}上建立索引，查询A:{B,C}和A:{C,B}都会使用索引吗？
不会，只会在A:{B,C}上使用索引。

31.如果一个分片（Shard）停止或很慢的时候，发起一个查询会怎样？
如果一个分片停止了，除非查询设置了“Partial”选项，否则查询会返回一个错误。如果一个分片响应很慢，MongoDB会等待它的响应。

32. MongoDB支持存储过程吗？如果支持的话，怎么用？
MongoDB支持存储过程，它是javascript写的，保存在db.system.js表中。

33.如何理解MongoDB中的GridFS机制，MongoDB为何使用GridFS来存储文件？
GridFS是一种将大型文件存储在MongoDB中的文件规范。使用GridFS可以将大文件分隔成多个小文档存放，这样我们能够有效的保存大文档，而且解决了BSON对象有限制的问题。
---------------------------------------------------------------------------------------------------------------
------------------------------------------mongodb basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------mybatis basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 对原生态JDBC问题的总结
1）数据库连接，使用时就创建，不使用立即释放，对数据库进行频繁连接开启和关闭，造成数据库资源浪费，影响数据库性能。解决方案：使用数据库连接池管理数据库连接。
2）将sql语句硬编码到java代码中，如果sql 语句修改，需要重新编译java代码，不利于系统维护。解决方案：将sql语句配置在xml配置文件中，即使sql变化，不需要对java代码进行重新编译。
3）向preparedStatement中设置参数，对占位符号位置和设置参数值，硬编码在java代码中，不利于系统维护。解决方案：将sql语句及占位符号和参数全部配置在xml中。
4）从resutSet中遍历结果集数据时，存在硬编码，将获取表的字段进行硬编码，，不利于系统维护。解决方案：将查询的结果集，自动映射成java对象。

2 MyBatis框架
MyBatis 本是apache的一个开源项目iBatis, 2010年这个项目由apache software foundation 迁移到了google code，并且改名为MyBatis，实质上Mybatis对ibatis进行一些改进。 MyBatis是一个优秀的持久层框架，它对jdbc的操作数据库的过程进行封装，使开发者只需要关注 SQL 本身，而不需要花费精力去处理例如注册驱动、创建connection、创建statement、手动设置参数、结果集检索等jdbc繁杂的过程代码。Mybatis通过xml或注解的方式将要执行的各种statement（statement、preparedStatemnt、CallableStatement）配置起来，并通过java对象和statement中的sql进行映射生成最终执行的sql语句，最后由mybatis框架执行sql并将结果映射成java对象并返回。

3 MyBatis的#和$有什么区别？
1.#将传入的数据都当成一个字符串，会对自动传入的数据加一个双引号。如：order by #user_id#，如果传入的值是111,那么解析成sql时的值为order by "111", 如果传入的值是id，则解析成的sql为order by "id".
2.$将传入的数据直接显示生成在sql中。如：order by $user_id$，如果传入的值是111,那么解析成sql时的值为order by user_id, 如果传入的值是id，则解析成的sql为order by id.
3.#方式能够很大程度防止sql注入。　
4.$方式无法防止Sql注入。 
5.$方式一般用于传入数据库对象，例如传入表名. 
6.一般能用#的就别用$. 

4 MyBatis架构图
@mybatis配置
（1）SqlMapConfig.xml，作为mybatis的全局配置文件，配置了的运行环境等信息。
（2）mapper.xml文件即sql映射文件，文件中配置了操作数据库的sql语句。此文件需要在SqlMapConfig.xml中加载。
@通过mybatis环境等配置信息构造SqlSessionFactory即会话工厂
@由会话工厂创建sqlSession即会话，操作数据库需要通过sqlSession进行。
@mybatis底层自定义了Executor执行器接口操作数据库，Executor接口有两个实现，一个是基本执行器、一个是缓存执行器。
@Mapped Statement也是mybatis一个底层封装对象，它包装了mybatis配置信息及sql映射信息等。mapper.xml文件中一个sql对应一个Mapped Statement对象，sql的id即是Mapped statement的id。
@Mapped Statement对sql执行输入参数进行定义，包括HashMap、基本类型、pojo，Executor通过Mapped Statement在执行sql前将输入的java对象映射至sql中，输入参数映射就是jdbc编程中对preparedStatement设置参数。
@Mapped Statement对sql执行输出结果进行定义，包括HashMap、基本类型、pojo，Executor通过Mapped Statement在执行sql后将输出结果映射至java对象中，输出结果映射过程相当于jdbc编程中对结果的解析处理过程。


5 Mybatis缓存机制
@一级缓存: 基于PerpetualCache 的 HashMap本地缓存，其存储作用域为 Session，当 Session flush 或 close 之后，该Session中的所有 Cache 就将清空。
@二级缓存与一级缓存其机制相同，默认也是采用 PerpetualCache，HashMap存储，不同在于其存储作用域为 Mapper(Namespace)，并且可自定义存储源，如 Ehcache。
@ 对于缓存数据更新机制，当某一个作用域(一级缓存Session/二级缓存Namespaces)的进行了 C/U/D 操作后，默认该作用域下所有 select 中的缓存将被clear。
（1）、一级缓存
MyBatis 默认开启了一级缓存，一级缓存是在SqlSession 层面进行缓存的。即，同一个SqlSession ，多次调用同一个Mapper和同一个方法的同一个参数，只会进行一次数据库查询，然后把数据缓存到缓冲中，以后直接先从缓存中取出数据，不会直接去查数据库。但是不同的SqlSession对象，因为不用的SqlSession都是相互隔离的，所以相同的Mapper、参数和方法，他还是会再次发送到SQL到数据库去执行，返回结果。

        // 获得SqlSession对象
        SqlSession sqlSession = factory.openSession();
        // 获得dao实体
        UserMapper userMapper = sqlSession.getMapper(UserMapper.class);
        // 进行两次相同的查询操作
        userMapper.selectByPrimaryKey(1);
        userMapper.selectByPrimaryKey(1);

        // 获得一个新的SqlSession 对象
        SqlSession sqlSession1 = factory.openSession();
        // 进行相同的查询操作
        sqlSession1.getMapper(UserMapper.class).selectByPrimaryKey(1);可以发现，第一次的两个相同操作，只执行了一次数据库。后来的那个操作又进行了数据库查询。

（2）二级缓存
在userMapper.xml文件中添加如下配置
<mapper namespace="me.gacl.mapping.userMapper">
<!-- 开启二级缓存 -->
<cache/>
　　1. 映射语句文件中的所有select语句将会被缓存。
　　2. 映射语句文件中的所有insert，update和delete语句会刷新缓存。
　　3. 缓存会使用Least Recently Used（LRU，最近最少使用的）算法来收回。
　　4. 缓存会根据指定的时间间隔来刷新。
5. 缓存会存储1024个对象
cache标签常用属性：
<cache 
eviction="FIFO"  <!--回收策略为先进先出-->
flushInterval="60000" <!--自动刷新时间60s-->
size="512" <!--最多缓存512个引用对象-->
readOnly="true"/> <!--只读-->

收回策略
LRU——默认，最近最少使用的：移除最长时间不被使用的对象 
FIFO——先进先出的：按对象进入缓存的顺序来移除他们 
SOFT——软引用：移除基于垃圾回收器状态和软引用规则的对象 
WEAK——弱引用：更积极地移除基于垃圾收集器状态和弱引用规则的对象。

（3）二级缓存使用redis
spring-context-jedis.xml
  <bean id="jedisPoolConfig" class="redis.clients.jedis.JedisPoolConfig">
        <property name="maxIdle" value="300"/> 
        <property name="maxTotal" value="60000"/> 
        <property name="testOnBorrow" value="true"/> 
    </bean>
    <bean id="jedisPool" class="redis.clients.jedis.JedisPool">
        <constructor-arg index="0" ref="jedisPoolConfig"/>
        <constructor-arg index="1" value="${redis.host}"/>
        <constructor-arg index="2" value="${redis.port}" type="int"/>
    </bean>

MyBatis配置文件（SqlMapConfig.xml）打开二级缓存
<settings>
<setting name="cacheEnabled" value="true"/>
</settings>

Mapper配置文件添加cache标签
import org.apache.ibatis.cache.Cache;
public class RedisCache implements Cache 
<cache type="com.hiya.ee.RedisCache "/>	

缓存结果继承序列化接口
public class User implements Serializable

测试二级缓存
SqlSessionFactory factory=new SqlSessionFactoryBuilder().build(Test.class.getClassLoader().getResourceAsStream("SqlMapConfig.xml"));
SqlSession session = factory.openSession();
UserMapper mapper = session.getMapper(UserMapper.class);
User user = mapper.findById(1);
System.out.println(user.toString());
session.commit();
session.close();
SqlSession session2 = factory.openSession();
UserMapper mapper2 = session2.getMapper(UserMapper.class);
User user2 = mapper2.findById(1);
System.out.println(user2.toString());
session2.commit();
session2.close();

6 MyBatis框架的优点
1. 与JDBC相比，减少了50%以上的代码量。
2. MyBatis是最简单的持久化框架，小巧并且简单易学。
3. MyBatis相当灵活，不会对应用程序或者数据库的现有设计强加任何影响，SQL写在XML里，从程序代码中彻底分离，降低耦合度，便于统一管理和优化，并可重用。
4. 提供XML标签，支持编写动态SQL语句。
5. 提供映射标签，支持对象与数据库的ORM字段关系映射。

7 MyBatis框架的缺点
1. SQL语句的编写工作量较大，尤其是字段多、关联表多时，更是如此，对开发人员编写SQL语句的功底有一定要求。
2. SQL语句依赖于数据库，导致数据库移植性差，不能随意更换数据库。

8 Hibernate与MyBatis对比
@ 相同点：
（1）Hibernate与MyBatis都是通过SessionFactoryBuider由XML配置文件生成SessionFactory，由SessionFactory 生成Session，由Session来开启执行事务和SQL(Structured Query Language，结构化查询语言)语句。
（2）Hibernate和MyBatis都支持JDBC（Java DataBase Connectivity，java数据库连接）和JTA（Java Transaction API，Java事务API（Application Programming Interface，应用程序编程接口））事务处理。注：jdbc和jta的主要作用是增强数据访问能力。
（3）基于ORM（Object Relational Mapping， 对象关系映射）思想解决了entity和数据库的映射问题

@ 不同点：
（1）sql方面：mybaits通过mapper.xml维护映射结果，程序员手动编写sql相比hibernate自动生成hql（hibernate sql）更加灵活，sql调优更加容易（hibernate因为更好的封装性，开发效率提高的同时，sql语句调优要更费力，当然可以手动修改sql来优化，但是同时也会影响开发效率）；hibernate的hql数据库移植性更好，体现在强壮性。hibernate在级联删除的时候效率低；数据量大， 表多的时候，基于关系操作会变得复杂。
（2）缓存方面：mybatis和hibernate都可以使用第三方缓存，而hibernate相比maybatis有更好的二级缓存机制。

9 配置解析
在应用启动的时候，MyBatis解析两种配置文件
SqlMapConfig.xml
SqlMap.xml
SqlMapConfig.xml是在XMLConfigBuilder类中完成解析的，其类图关系大致如下

我们知道XML有两种解析方式：一是DOM，另一个是SAX，MyBatis使用的是org.wrc.dom——JDK提供的文档对象模型(DOM)接口(SqlMapConfig.xml并不大，所以DOM方式并没有什么效率损耗，JDK也提供了SAX模型接口org.xml.sax，这两个都是JAXP的组件API)，以及JDK官方提供的javax.xml.xpath.XPath来作为XML路径寻找组件。
SqlMap.xml是在XMLMapperBuilder中解析完成的，其中把对Statement的解析(即SqlMap.xml中SELECT|INSERT|UPDATE|DELETE定义部分)委托给XMLStatementBuilder来完成。SqlMap.xml的解析比较复杂的，涉及到PreparedMapping、ResultMapping、LanguageDriver、Discriminator、缓存、自动映射等一系列对象的构造，这里暂时略过，后面专题分析。

10  SQL执行
MyBatis中Executor是的核心，围绕着它完成了数据库操作的完整过程。下面是Executor的类图
在上图中我列出了Executor中方法的参数，而在其子类中就没有明确写出。从上图中可以看到，Executor主要提供了QUERY|UPDATE(INSERT和DELETE也是使用UPDATE)，从方法定义中可看到，它需要MappedStatement、parameter、resultHandler这几个实例对象，这几个也是SQL执行的主要部分，详细实现在后面专题中再介绍。事务提交/回滚，这委托给Transaction对象来完成。缓存，createCacheKey()/isCached()。延迟加载，deferload()。关闭，close()，主要是事务回滚/关闭。BaseExecutor的属性表明：它内部维护了localCache来localOutputParameterCache来处理缓存，至于这缓存保存的是什么，这后面专题再说。以及线程安全的延迟加载列表deferredLoads、事务对象Transaction。
BatchExecutor的属性已经表明：它内部维护了StatementList批量提交并通过batchResultList保存执行结果。ResueExecutor的属性及方法表明：它内部维护了java.sql.Statement对象缓存，以重用Statement对象(对于支持预编译的数据库而言，在创建PreparedStatement时需要发送一次数据库请求预编译，而重用Statement对象主要是减少了这次预编译的网路开销)。下面以SqlSession.selectList为例，画出SQL执行的时序图(点击下方的图片查看大图，部分分支有所简化)


11 Mapper的动态代理
采用Mapper动态代理方法只需要编写相应的Mapper接口（相当于Dao接口），那么Mybatis框架根据接口定义创建接口的动态代理对象，代理对象的方法体同Dao接口实现类方法。
Mapper接口开发需要遵循以下规范：
1、Mapper.xml文件中的namespace与mapper接口的全类名相同。
2、Mapper接口方法名和Mapper.xml中定义的每个statement的id相同。
3、Mapper接口方法的输入参数类型和mapper.xml中定义的每个sql 的parameterType的类型相同。
4、Mapper接口方法的输出参数类型和mapper.xml中定义的每个sql的resultType的类型相同。

12 Mapper代码对象的生成过程
DefaultSqlSession.getMapp()方法最终会调用MapperRegistry.getMapper()方法
    public <T> T getMapper(Class<T> type, SqlSession sqlSession) {  
       //这个MapperProxyFactory是调用addMapper方法时加到knownMappers中的，  
       final MapperProxyFactory<T> mapperProxyFactory = (MapperProxyFactory<T>) knownMappers.get(type);  
       if (mapperProxyFactory == null)  
         //说明这个Mapper接口没有注册  
         throw new BindingException("Type " + type + " is not known to the MapperRegistry.");  
       try {  
          //生成一个MapperProxy对象  
         return mapperProxyFactory.newInstance(sqlSession);  
       } catch (Exception e) {  
         throw new BindingException("Error getting mapper instance. Cause: " + e, e);  
       }  
     }  
（1）在Mybatis提供的编程接口中，开发人员只需要定义好Mapper接口(如：UserDao)，开发人员无需去实现。Mybatis会利用JDK的动态代理实现 Mapper接口。
（2）在Mybatis中，每个Mapper接口都会对应一个MapperProxyFactory对象实例，这个对应关系在Configuration.mapperRegistry.knownMappers中。
（3）当getMapper()方法被调用时，Mybatis会找到相对应的MapperProxyFactory对象实例，利用这个工厂来创建一个jdk动态代理对象，是这个Mapper接口的实现类,当Mapper定义的方法被调用时，会调用MapperProxy来处理。
（4）MapperProxy会根据方法找到对应的MapperMethod对象来实现这次调用。
（5）MapperMethod对应会读取方法中的注解，从Configuration中找到相对应的MappedStatement对象，再执行。

13 Mybatis中的数据源与连接池
1）Mybatis中支持三种形式数据源的配置，分别为：UNPOOLED、POOLED和JNDI
2）在Mybatis内部定义了一个接口DataSourceFactory，而支持的三种形式都需要实现这个接口
3）MyBatis创建了DataSource实例后，会将其放到Configuration对象内的Environment对象中， 供以后使用.
DataSourceFactory dsFactory = dataSourceElement(child.evalNode("dataSource"));
DataSource dataSource = dsFactory.getDataSource();
Environment.Builder environmentBuilder = new Environment.Builder(id)
  .transactionFactory(txFactory)
  .dataSource(dataSource);
configuration.setEnvironment(environmentBuilder.build());



二、ms相关
1、什么是Mybatis？
（1）Mybatis是一个半ORM（对象关系映射）框架，它内部封装了JDBC，加载驱动、创建连接、创建statement等繁杂的过程，开发者开发时只需要关注如何编写SQL语句，可以严格控制sql执行性能，灵活度高。
（2）作为一个半ORM框架，MyBatis 可以使用 XML 或注解来配置和映射原生信息，将 POJO映射成数据库中的记录，避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。
称Mybatis是半自动ORM映射工具，是因为在查询关联对象或关联集合对象时，需要手动编写sql来完成。不像Hibernate这种全自动ORM映射工具，Hibernate查询关联对象或者关联集合对象时，可以根据对象关系模型直接获取。
（3）通过xml 文件或注解的方式将要执行的各种 statement 配置起来，并通过java对象和 statement中sql的动态参数进行映射生成最终执行的sql语句，最后由mybatis框架执行sql并将结果映射为java对象并返回。（从执行sql到返回result的过程）。
（4）由于MyBatis专注于SQL本身，灵活度高，所以比较适合对性能的要求很高，或者需求变化较多的项目，如互联网项目。

2、Mybaits的优缺点
（1）优点
① 基于SQL语句编程，相当灵活，不会对应用程序或者数据库的现有设计造成任何影响，SQL写在XML里，解除sql与程序代码的耦合，便于统一管理；提供XML标签，支持编写动态SQL语句，并可重用。
② 与JDBC相比，减少了50%以上的代码量，消除了JDBC大量冗余的代码，不需要手动开关连接；
③ 很好的与各种数据库兼容（因为MyBatis使用JDBC来连接数据库，所以只要JDBC支持的数据库MyBatis都支持）。
④ 能够与Spring很好的集成；
⑤ 提供映射标签，支持对象与数据库的ORM字段关系映射；提供对象关系映射标签，支持对象关系组件维护。
（2）缺点
① SQL语句的编写工作量较大，尤其当字段多、关联表多时，对开发人员编写SQL语句的功底有一定要求。
② SQL语句依赖于数据库，导致数据库移植性差，不能随意更换数据库。

3、#{}和${}的区别是什么？
${}是字符串替换，#{}是预处理；
Mybatis在处理${}时，就是把${}直接替换成变量的值。而Mybatis在处理#{}时，会对sql语句进行预处理，将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值；
使用#{}可以有效的防止SQL注入，提高系统安全性。

4、通常一个mapper.xml文件，都会对应一个Dao接口，这个Dao接口的工作原理是什么？Dao接口里的方法，参数不同时，方法能重载吗？
Mapper接口的工作原理是JDK动态代理，Mybatis运行时会使用JDK动态代理为Mapper接口生成代理对象proxy，代理对象会拦截接口方法，根据类的全限定名+方法名，唯一定位到一个MapperStatement并调用执行器执行所代表的sql，然后将sql执行结果返回。
Mapper接口里的方法，是不能重载的，因为是使用 全限名+方法名 的保存和寻找策略。
Dao接口即Mapper接口。接口的全限名，就是映射文件中的namespace的值；接口的方法名，就是映射文件中Mapper的Statement的id值；接口方法内的参数，就是传递给sql的参数。
当调用接口方法时，接口全限名+方法名拼接字符串作为key值，可唯一定位一个MapperStatement。在Mybatis中，每一个SQL标签，比如、、、标签，都会被解析为一个MapperStatement对象。
举例com.mybatis3.mappers.StudentDao.findStudentById，可以唯一找到namespace为com.mybatis3.mappers.StudentDao下面 id 为 findStudentById 的 MapperStatement。

5、Mybatis的Xml映射文件中，不同的Xml映射文件，id是否可以重复？
不同的Xml映射文件，如果配置了namespace，那么id可以重复；如果没有配置namespace，那么id不能重复；
原因就是namespace+id是作为Map的key使用的，如果没有namespace，就剩下id，那么，id重复会导致数据互相覆盖。有了namespace，自然id就可以重复，namespace不同，namespace+id自然也就不同。
备注在旧版本的Mybatis中，namespace是可选的，不过新版本的namespace已经是必须的了。

6、Mybatis是如何进行分页的？分页插件的原理是什么？
Mybatis使用RowBounds对象进行分页，它是针对ResultSet结果集执行的内存分页，而非物理分页。可以在sql内直接书写带有物理分页的参数来完成物理分页功能，也可以使用分页插件来完成物理分页。
分页插件的基本原理是使用Mybatis提供的插件接口，实现自定义插件，在插件的拦截方法内拦截待执行的sql，然后重写sql，根据dialect方言，添加对应的物理分页语句和物理分页参数。

7、简述Mybatis的插件运行原理，以及如何编写一个插件。
答Mybatis仅可以编写针对ParameterHandler、ResultSetHandler、StatementHandler、Executor这4种接口的插件，Mybatis使用JDK的动态代理，为需要拦截的接口生成代理对象以实现接口方法拦截功能，每当执行这4种接口对象的方法时，就会进入拦截方法，具体就是InvocationHandler的invoke()方法，当然，只会拦截那些你指定需要拦截的方法。
编写插件实现Mybatis的Interceptor接口并复写intercept()方法，然后再给插件编写注解，指定要拦截哪一个接口的哪些方法即可，最后在配置文件中配置你编写的插件。

8、Mybatis是否支持延迟加载？如果支持，它的实现原理是什么？
Mybatis仅支持association关联对象和collection关联集合对象的延迟加载，association指的就是一对一，collection指的就是一对多查询。在Mybatis配置文件中，可以配置是否启用延迟加载lazyLoadingEnabled=true|false。
延迟加载的基本原理是，使用CGLIB创建目标对象的代理对象，当调用目标方法时，进入拦截器方法，比如调用a.getB().getName()，拦截器invoke()方法发现a.getB()是null值，那么就会单独发送事先保存好的查询关联B对象的sql，把B查询上来，然后调用a.setB(b)，于是a的对象b属性就有值了，接着完成a.getB().getName()方法的调用。
当然了，不光是Mybatis，几乎所有的包括Hibernate，支持延迟加载的原理都是一样的。

9、Mybatis的一级、二级缓存:
（1）一级缓存: 基于 PerpetualCache 的 HashMap 本地缓存，其存储作用域为 Session，当 Session flush 或 close 之后，该 Session 中的所有 Cache 就将清空，默认打开一级缓存。
（2）二级缓存与一级缓存其机制相同，默认也是采用 PerpetualCache，HashMap 存储，不同在于其存储作用域为 Mapper(Namespace)，并且可自定义存储源，如 Ehcache。默认不打开二级缓存，要开启二级缓存，使用二级缓存属性类需要实现Serializable序列化接口(可用来保存对象的状态),可在它的映射文件中配置 ；
（3）对于缓存数据更新机制，当某一个作用域(一级缓存 Session/二级缓存Namespaces)的进行了C/U/D 操作后，默认该作用域下所有 select 中的缓存将被 clear 掉并重新更新，如果开启了二级缓存，则只根据配置判断是否刷新。

10、Mybatis是如何将sql执行结果封装为目标对象并返回的？都有哪些映射形式？
第一种是使用标签，逐一定义数据库列名和对象属性名之间的映射关系。
第二种是使用sql列的别名功能，将列的别名书写为对象属性名。
有了列名与属性名的映射关系后，Mybatis通过反射创建对象，同时使用反射给对象的属性逐一赋值并返回，那些找不到映射关系的属性，是无法完成赋值的。

11、Mybatis动态sql有什么用？执行原理？有哪些动态sql？
Mybatis动态sql可以在Xml映射文件内，以标签的形式编写动态sql，执行原理是根据表达式的值 完成逻辑判断 并动态拼接sql的功能。
Mybatis提供了9种动态sql标签trim | where | set | foreach | if | choose | when | otherwise | bind。

12、Xml映射文件中，除了常见的select|insert|updae|delete标签外，还有哪些标签？
<resultMap>、<parameterMap>、<sql>、<include>、<selectKey>，加上动态sql的9个标签 trim | where | set | foreach | if | choose | when | otherwise | bind 等，其中 <sql> 为sql片段标签，通过<include>标签引入sql片段，<selectKey>为不支持自增的主键生成策略标签。

13、使用MyBatis的mapper接口调用时有哪些要求？
Mapper接口方法名和mapper.xml中定义的每个sql的id相同；
Mapper接口方法的输入参数类型和mapper.xml中定义的每个sql 的parameterType的类型相同；
Mapper接口方法的输出参数类型和mapper.xml中定义的每个sql的resultType的类型相同；
Mapper.xml文件中的namespace即是mapper接口的类路径。

14、 模糊查询like语句该怎么写?
第1种在Java代码中添加sql通配符。
string wildcardname = “%smi%”;
list<name> names = mapper.selectlike(wildcardname);
<select id=”selectlike”>
select * from foo where bar like #{value}
</select>
第2种在sql语句中拼接通配符，会引起sql注入
string wildcardname = “smi”;
list<name> names = mapper.selectlike(wildcardname);
<select id=”selectlike”>
select * from foo where bar like "%"${value}"%"
</select>

15、当实体类中的属性名和表中的字段名不一样 ，怎么办 ？
第1种 通过在查询的sql语句中定义字段名的别名，让字段名的别名和实体类的属性名一致。
<select id=”selectorder” parametertype=”int” resultetype=”me.gacl.domain.order”>
select order_id id, order_no orderno ,order_price price form orders where order_id=#{id};
</select>
第2种 通过来映射字段名和实体类属性名的一一对应的关系。
<select id="getOrder" parameterType="int" resultMap="orderresultmap">
select * from orders where order_id=#{id}
</select>
<resultMap type=”me.gacl.domain.order” id=”orderresultmap”>
<!–用id属性来映射主键字段–>
<id property=”id” column=”order_id”>
<!–用result属性来映射非主键字段，property为实体类属性名，column为数据表中的属性–>
<result property = “orderno” column =”order_no”/>
<result property=”price” column=”order_price” />
</reslutMap>

16、如何获取自动生成的(主)键值?
insert 方法总是返回一个int值 ，这个值代表的是插入的行数。
如果采用自增长策略，自动生成的键值在 insert 方法执行完后可以被设置到传入的参数对象中。
<insert id=”insertname” usegeneratedkeys=”true” keyproperty=”id”>
insert into names (name) values (#{name})
</insert>
name name = new name();
name.setname(“fred”);
int rows = mapper.insertname(name);
// 完成后,id已经被设置到对象中
system.out.println(“rows inserted = ” + rows);
system.out.println(“generated key value = ” + name.getid());

17、在mapper中如何传递多个参数?
（1）第一种
//DAO层的函数
Public UserselectUser(String name,String area);  
//对应的xml,#{0}代表接收的是dao层中的第一个参数，#{1}代表dao层中第二参数，更多参数一致往后加即可。
<select id="selectUser"resultMap="BaseResultMap">  
select *  fromuser_user_t   whereuser_name = #{0} anduser_area=#{1}  
</select>  
（2）第二种 使用 @param 注解:
public interface usermapper {
user selectuser(@param(“username”) string username,@param(“hashedpassword”) string hashedpassword);
}
然后,就可以在xml像下面这样使用(推荐封装为一个map,作为单个参数传递给mapper):
<select id=”selectuser” resulttype=”user”>
select id, username, hashedpassword
from some_table
where username = #{username}
and hashedpassword = #{hashedpassword}
</select>
（3）第三种多个参数封装成map
try{
//映射文件的命名空间.SQL片段的ID，就可以调用对应的映射文件中的SQL
//由于我们的参数超过了两个，而方法中只有一个Object参数收集，因此我们使用Map集合来装载我们的参数
Map<String, Object> map = new HashMap();
map.put("start", start);
map.put("end", end);
return sqlSession.selectList("StudentID.pagination", map);
}catch(Exception e){
e.printStackTrace();
sqlSession.rollback();
throw e; }
finally{
MybatisUtil.closeSqlSession();
}

18、 一对一、一对多的关联查询 ？ 
<mapper namespace="com.lcb.mapping.userMapper">  
<!--association  一对一关联查询 -->  
<select id="getClass" parameterType="int" resultMap="ClassesResultMap">  
select * from class c,teacher t where c.teacher_id=t.t_id and c.c_id=#{id}  
</select>  
<resultMap type="com.lcb.user.Classes" id="ClassesResultMap">  
<!-- 实体类的字段名和数据表的字段名映射 -->  
<id property="id" column="c_id"/>  
<result property="name" column="c_name"/>  
<association property="teacher" javaType="com.lcb.user.Teacher">  
<id property="id" column="t_id"/>  
<result property="name" column="t_name"/>  
</association>  
</resultMap>  
<!--collection  一对多关联查询 -->  
<select id="getClass2" parameterType="int" resultMap="ClassesResultMap2">  
select * from class c,teacher t,student s where c.teacher_id=t.t_id and c.c_id=s.class_id and c.c_id=#{id}  
</select>  
<resultMap type="com.lcb.user.Classes" id="ClassesResultMap2">  
<id property="id" column="c_id"/>  
<result property="name" column="c_name"/>  
<association property="teacher" javaType="com.lcb.user.Teacher">  
<id property="id" column="t_id"/>  
<result property="name" column="t_name"/>  
</association>  
<collection property="student" ofType="com.lcb.user.Student">  
<id property="id" column="s_id"/>  
<result property="name" column="s_name"/>  
</collection>  
</resultMap>  
</mapper> 

19、MyBatis实现一对一有几种方式?具体怎么操作的？
有联合查询和嵌套查询,联合查询是几个表联合查询,只查询一次, 通过在resultMap里面配置association节点配置一对一的类就可以完成；
嵌套查询是先查一个表，根据这个表里面的结果的 外键id，去再另外一个表里面查询数据,也是通过association配置，但另外一个表的查询通过select属性配置。

20、MyBatis实现一对多有几种方式,怎么操作的？
有联合查询和嵌套查询。联合查询是几个表联合查询,只查询一次,通过在resultMap里面的collection节点配置一对多的类就可以完成；嵌套查询是先查一个表,根据这个表里面的 结果的外键id,去再另外一个表里面查询数据,也是通过配置collection,但另外一个表的查询通过select节点配置。


21、Mapper编写有哪几种方式？
@@第一种接口实现类继承SqlSessionDaoSupport使用此种方法需要编写mapper接口，mapper接口实现类、mapper.xml文件。
（1）在sqlMapConfig.xml中配置mapper.xml的位置
<mappers>
<mapper resource="mapper.xml 文件的地址" />
<mapper resource="mapper.xml 文件的地址" />
</mappers>
（2）定义mapper接口
（3）实现类集成SqlSessionDaoSupportmapper方法中可以this.getSqlSession()进行数据增删改查。
（4）spring 配置
<bean id="对象ID" class="mapper 接口的实现">
<property name="sqlSessionFactory" ref="sqlSessionFactory"></property>
</bean>

@@第二种使用org.mybatis.spring.mapper.MapperFactoryBean
（1）在sqlMapConfig.xml中配置mapper.xml的位置，如果mapper.xml和mappre接口的名称相同且在同一个目录，这里可以不用配置
<mappers>
<mapper resource="mapper.xml 文件的地址" />
<mapper resource="mapper.xml 文件的地址" />
</mappers>
（2）定义mapper接口
① mapper.xml中的namespace为mapper接口的地址
② mapper接口中的方法名和mapper.xml中的定义的statement的id保持一致
③ Spring中定义
<bean id="" class="org.mybatis.spring.mapper.MapperFactoryBean">
<property name="mapperInterface" value="mapper 接口地址" />
<property name="sqlSessionFactory" ref="sqlSessionFactory" />
</bean>

@@第三种使用mapper扫描器
（1）mapper.xml文件编写
mapper.xml中的namespace为mapper接口的地址；
mapper接口中的方法名和mapper.xml中的定义的statement的id保持一致；
如果将mapper.xml和mapper接口的名称保持一致则不用在sqlMapConfig.xml中进行配置。 
（2）定义mapper接口
注意mapper.xml的文件名和mapper的接口名称保持一致，且放在同一个目录
（3）配置mapper扫描器
<bean class="org.mybatis.spring.mapper.MapperScannerConfigurer">
<property name="basePackage" value="mapper接口包地址" />
<property name="sqlSessionFactoryBeanName" value="sqlSessionFactory"/>
</bean>
（4）使用扫描器后从spring容器中获取mapper的实现对象。


22、什么是MyBatis的接口绑定？有哪些实现方式？
接口绑定，就是在MyBatis中任意定义接口,然后把接口里面的方法和SQL语句绑定, 我们直接调用接口方法就可以,这样比起原来了SqlSession提供的方法我们可以有更加灵活的选择和设置。
接口绑定有两种实现方式,一种是通过注解绑定，就是在接口的方法上面加上 @Select、@Update等注解，里面包含Sql语句来绑定；另外一种就是通过xml里面写SQL来绑定, 在这种情况下,要指定xml映射文件里面的namespace必须为接口的全路径名。当Sql语句比较简单时候,用注解绑定, 当SQL语句比较复杂时候,用xml绑定,一般用xml绑定的比较多。

23、MyBatis与Hibernate有哪些不同？
（1）Mybatis和hibernate不同，它不完全是一个ORM框架，因为MyBatis需要程序员自己编写Sql语句。
（2）Mybatis直接编写原生态sql，可以严格控制sql执行性能，灵活度高，非常适合对关系数据模型要求不高的软件开发，因为这类软件需求变化频繁，一但需求变化要求迅速输出成果。但是灵活的前提是mybatis无法做到数据库无关性，如果需要实现支持多种数据库的软件，则需要自定义多套sql映射文件，工作量大。 
（3）Hibernate对象/关系映射能力强，数据库无关性好，对于关系模型要求高的软件，如果用hibernate开发可以节省很多代码，提高效率。
---------------------------------------------------------------------------------------------------------------
------------------------------------------mybatis basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------mysql basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 MySQL的数据类型
主要包括以下五大类：
整数类型：BIT、BOOL、TINY INT、SMALL INT、MEDIUM INT、 INT、 BIG INT
浮点数类型：FLOAT、DOUBLE、DECIMAL
字符串类型：CHAR、VARCHAR、TINY TEXT、TEXT、MEDIUM TEXT、LONGTEXT、TINY BLOB、BLOB、MEDIUM BLOB、LONG BLOB
日期类型：Date、DateTime、TimeStamp、Time、Year
其他数据类型：BINARY、VARBINARY、ENUM、SET、Geometry、Point、MultiPoint、LineString、MultiLineString、Polygon、GeometryCollection等
 
date “1000-01-01”到“9999-12-31” 3字节
time “-838:59:59”到“838:59:59” 3字节
datetime “1000-01-01 00:00:00” 到“9999-12-31 23:59:59” 8字节
timestamp 19700101000000 到2037 年的某个时刻 4字节
year 1901 到2155 1字节

2 整型
MySQL数据类型	含义（有符号）
tinyint(m)	1个字节  范围(-128~127)
smallint(m)	2个字节  范围(-32768~32767)
mediumint(m)	3个字节  范围(-8388608~8388607)
int(m)	4个字节  范围(-2147483648~2147483647)
bigint(m)	8个字节  范围(+-9.22*10的18次方)
取值范围如果加了unsigned，则最大值翻倍，如tinyint unsigned的取值范围为(0~256)。
int(m)里的m是表示SELECT查询结果集中的显示宽度，并不影响实际的取值范围，没有影响到显示的宽度，不知道这个m有什么用。
 
3 浮点型(float和double)
MySQL数据类型	含义
float(m,d)	单精度浮点型    8位精度(4字节)     m总个数，d小数位
double(m,d)	双精度浮点型    16位精度(8字节)    m总个数，d小数位
设一个字段定义为float(6,3)，如果插入一个数123.45678,实际数据库里存的是123.457，但总个数还以实际为准，即6位。整数部分最大是3位，如果插入数12.123456，存储的是12.1234，如果插入12.12，存储的是12.1200.
 
4 定点数
浮点型在数据库中存放的是近似值，而定点类型在数据库中存放的是精确值。 
decimal(m,d) 参数m<65 是总个数，d<30且 d<m 是小数位。
 
5 字符串(char,varchar,_text)
MySQL数据类型	含义
char(n)	固定长度，最多255个字符
varchar(n)	变长长度，最多65535个字符
tinytext	可变长度，最多255个字符
text	可变长度，最多65535个字符
mediumtext	可变长度，最多2的24次方-1个字符
longtext	可变长度，最多2的32次方-1个字符
char定义的是固定长度，长度范围为0-255，存储时，如果字符数没有达到定义的位数，会在后面用空格补全存入数据库中，在上例中，name实际存储在数据中的数据为'zejin '
varchar是变长长度，长度范围为0-65535，存储时，如果字符没有达到定义的位数，也不会在后面补空格，在上例subject字段中，实际存储在数据中的数据为'zejin '，当然还有一或两个字节来描述该字节长度
1）text和varchar基本相同
2）text会忽略指定的大小这和varchar有所不同，text不能有默认值
3）text尾部有空格不会被截断
4）text使用额 外的2个字节来存储数据的大小，varchar根据存储数据的大小选择用几个字节来存储
5）text的65535字节全部用来存储数据，varchar则会 占用1－3个字节去存储数据大小

6 char和varchar：
（1）char(n) 若存入字符数小于n，则以空格补于其后，查询之时再将空格去掉。所以char类型存储的字符串末尾不能有空格，varchar不限于此。 
（2）char(n) 固定长度，char(4)不管是存入几个字符，都将占用4个字节，varchar是存入的实际字符数+1个字节（n<=255）或2个字节(n>255)，所以varchar(4),存入3个字符将占用4个字节。 
（3）char类型的字符串检索速度要比varchar类型的快。

7 varchar和text
（1）varchar可指定n，text不能指定，内部存储varchar是存入的实际字符数+1个字节（n<=255）或2个字节(n>255)，text是实际字符数+2个字
节。 
（2）text类型不能有默认值。 
（3）varchar可直接创建索引，text创建索引要指定前多少个字符。varchar查询速度快于text,在都创建索引的情况下，text的索引似乎不起作用。
 
8 二进制数据(_Blob)
1._BLOB和_text存储方式不同，_TEXT以文本方式存储，英文存储区分大小写，而_Blob是以二进制方式存储，不分大小写。
2._BLOB存储的数据只能整体读出。 
3._TEXT可以指定字符集，_BLO不用指定字符集。
 
9 日期时间类型
MySQL数据类型	含义
date	日期 '2008-12-2'
time	时间 '12:25:36'
datetime	日期时间 '2008-12-2 22:06:44'
timestamp	自动存储记录修改时间
若定义一个字段为timestamp，这个字段里的时间数据会随其他字段修改的时候自动刷新，所以这个数据类型的字段可以存放这条记录最后被修改的时间。
 
10 数据类型的属性
MySQL关键字	含义
NULL	数据列可包含NULL值
NOT NULL	数据列不允许包含NULL值
DEFAULT	默认值
PRIMARY KEY	主键
AUTO_INCREMENT	自动递增，适用于整数类型
UNSIGNED	无符号
CHARACTER SET name	指定一个字符集
 
11 MYSQL数据类型的长度和范围
各数据类型及字节长度一览表：
数据类型	字节长度	范围或用法
Bit	1	无符号[0,255]，有符号[-128,127]，天缘博客备注：BIT和BOOL布尔型都占用1字节
TinyInt	1	整数[0,255]
SmallInt	2	无符号[0,65535]，有符号[-32768,32767]
MediumInt	3	无符号[0,2^24-1]，有符号[-2^23,2^23-1]]
Int	4	无符号[0,2^32-1]，有符号[-2^31,2^31-1]
BigInt	8	无符号[0,2^64-1]，有符号[-2^63 ,2^63 -1]
Float(M,D)	4	单精度浮点数。天缘博客提醒这里的D是精度，如果D<=24则为默认的FLOAT，如果D>24则会自动被转换为DOUBLE型。
Double(M,D)	8	 双精度浮点。
Decimal(M,D)	M+1或M+2	未打包的浮点数，用法类似于FLOAT和DOUBLE，天缘博客提醒您如果在ASP中使用到Decimal数据类型，直接从数据库读出来的Decimal可能需要先转换成Float或Double类型后再进行运算。
Date	3	以YYYY-MM-DD的格式显示，比如：2009-07-19
Date Time	8	以YYYY-MM-DD HH:MM:SS的格式显示，比如：2009-07-19 11：22：30
TimeStamp	4	以YYYY-MM-DD的格式显示，比如：2009-07-19
Time	3	以HH:MM:SS的格式显示。比如：11：22：30
Year	1	以YYYY的格式显示。比如：2009
Char(M)	M	定长字符串。
VarChar(M)	M	变长字符串，要求M<=255
Binary(M)	M	类似Char的二进制存储，特点是插入定长不足补0
VarBinary(M)	M	类似VarChar的变长二进制存储，特点是定长不补0
Tiny Text	Max:255	大小写不敏感
Text	Max:64K	大小写不敏感
Medium Text	Max:16M	大小写不敏感
Long Text	Max:4G	大小写不敏感
TinyBlob	Max:255	大小写敏感
Blob	Max:64K	大小写敏感
MediumBlob	Max:16M	大小写敏感
LongBlob	Max:4G	大小写敏感
Enum	1或2	最大可达65535个不同的枚举值
Set	可达8	最大可达64个不同的值

12 SQL函数
1） 数学函数-数学函数主要用于处理数字，包括整型、浮点数等。
ABS(x) 	
返回x的绝对值　　
SELECT ABS(-1) -- 返回1

CEIL(x),CEILING(x) 	
返回大于或等于x的最小整数　　
SELECT CEIL(1.5) -- 返回2

FLOOR(x) 	
返回小于或等于x的最大整数　　
SELECT FLOOR(1.5) -- 返回1

RAND() 	
返回0->1的随机数　　
SELECT RAND() --0.93099315644334

RAND(x) 	
返回0->1的随机数，x值相同时返回的随机数相同　　
SELECT RAND(2) --1.5865798029924

SIGN(x) 	
返回x的符号，x是负数、0、正数分别返回-1、0和1　　
SELECT SIGN(-10) -- (-1)

PI() 	
返回圆周率(3.141593）　　
SELECT PI() --3.141593

TRUNCATE(x,y) 	
返回数值x保留到小数点后y位的值（与ROUND最大的区别是不会进行四舍五入）　　
SELECT TRUNCATE(1.23456,3) -- 1.234

ROUND(x) 	返回离x最近的整数　　SELECT ROUND(1.23456) --1
ROUND(x,y) 	
保留x小数点后y位的值，但截断时要进行四舍五入　　
SELECT ROUND(1.23456,3) -- 1.235

POW(x,y).POWER(x,y) 	
返回x的y次方　　
SELECT POW(2,3) -- 8

SQRT(x) 	
返回x的平方根　　
SELECT SQRT(25) -- 5

EXP(x) 	
返回e的x次方　　
SELECT EXP(3) -- 20.085536923188

MOD(x,y) 	
返回x除以y以后的余数　　
SELECT MOD(5,2) -- 1

LOG(x) 	
返回自然对数(以e为底的对数)　　
SELECT LOG(20.085536923188) -- 3

LOG10(x) 	
返回以10为底的对数　　
SELECT LOG10(100) -- 2

RADIANS(x) 	
将角度转换为弧度　　
SELECT RADIANS(180) -- 3.1415926535898

SIN(x) 	
求正弦值(参数是弧度)　　
SELECT SIN(RADIANS(30)) -- 0.5
ASIN(x) 	求反正弦值(参数是弧度)
COS(x) 	求余弦值(参数是弧度)
ACOS(x) 	求反余弦值(参数是弧度)
TAN(x) 	求正切值(参数是弧度)
ATAN(x) ATAN2(x) 	求反正切值(参数是弧度)
COT(x) 	求余切值(参数是弧度)

2） 字符串函数-字符串函数是MySQL中最常用的一类函数，字符串函数主要用于处理表中的字符串。
CHAR_LENGTH(s) 	
返回字符串s的字符数
SELECT CHAR_LENGTH('你好123') -- 5

LENGTH(s) 	
返回字符串s的长度
SELECT LENGTH('你好123') -- 9

CONCAT(s1,s2,...) 	
将字符串s1,s2等多个字符串合并为一个字符串
SELECT CONCAT('12','34') -- 1234

CONCAT_WS(x,s1,s2,...) 	
同CONCAT(s1,s2,...)函数，但是每个字符串直接要加上x
SELECT CONCAT_WS('@','12','34') -- 12@34

INSERT(s1,x,len,s2) 	
将字符串s2替换s1的x位开始长度为len的字符串
SELECT INSERT('12345',1,3,'abc') -- abc45

UPPER(s),UCAASE(S) 
将字符串s的所有字母变成写字母
SELECT UPPER('abc') -- ABC

LOWER(s),LCASE(s) 	
将字符串s的所有字母变成小写字母
SELECT LOWER('ABC') -- abc

LEFT(s,n) 	
返回字符串s的前n个字符
SELECT LEFT('abcde',2) -- ab

RIGHT(s,n) 	
返回字符串s的后n个字符
SELECT RIGHT('abcde',2) -- de

LPAD(s1,len,s2) 	
字符串s2来填充s1的开始处，使字符串长度达到len
SELECT LPAD('abc',5,'xx') -- xxabc

RPAD(s1,len,s2) 	
字符串s2来填充s1的结尾处，使字符串的长度达到len
SELECT RPAD('abc',5,'xx') -- abcxx

LTRIM(s) 	去掉字符串s开始处的空格
RTRIM(s) 	去掉字符串s结尾处的空格
TRIM(s) 	去掉字符串s开始和结尾处的空格

TRIM(s1 FROM s) 	
去掉字符串s中开始处和结尾处的字符串s1
SELECT TRIM('@' FROM '@@abc@@') -- abc

REPEAT(s,n) 	
将字符串s重复n次
SELECT REPEAT('ab',3) -- ababab

SPACE(n) 	返回n个空格
REPLACE(s,s1,s2) 	将字符串s2替代字符串s中的字符串s1
SELECT REPLACE('abc','a','x') --xbc

STRCMP(s1,s2) 	比较字符串s1和s2
SUBSTRING(s,n,len) 	获取从字符串s中的第n个位置开始长度为len的字符串
MID(s,n,len) 	同SUBSTRING(s,n,len)

LOCATE(s1,s),POSITION(s1 IN s) 	
从字符串s中获取s1的开始位置
SELECT LOCATE('b', 'abc') -- 2

INSTR(s,s1) 	
从字符串s中获取s1的开始位置
SELECT INSTR('abc','b') -- 2

REVERSE(s) 
将字符串s的顺序反过来
SELECT REVERSE('abc') -- cba

ELT(n,s1,s2,...) 	
返回第n个字符串
SELECT ELT(2,'a','b','c') -- b

EXPORT_SET(x,s1,s2) 	
返回一个字符串，在这里对于在“bits”中设定每一位，你得到一个“on”字符串，并且对于每个复位(reset)的位，你得到一个 “off”字符串。每个字符串用“separator”分隔(缺省“,”)，并且只有“bits”的“number_of_bits” (缺省64)位被使用。
SELECT EXPORT_SET(5,'Y','N',',',4) -- Y,N,Y,N

FIELD(s,s1,s2...) 	
返回第一个与字符串s匹配的字符串位置
SELECT FIELD('c','a','b','c') -- 3

FIND_IN_SET(s1,s2) 	返回在字符串s2中与s1匹配的字符串的位置

MAKE_SET(x,s1,s2) 	返回一个集合 (包含由“,”
字符分隔的子串组成的一个 字符串)，由相应的位在bits集合中的的字符串组成。str1对应于位0，str2对 应位1，等等。
SELECT MAKE_SET(1|4,'a','b','c'); -- a,c

SUBSTRING_INDEX 	
返回从字符串str的第count个出现的分隔符delim之后的子串。
如果count是正数，返回第count个字符左边的字符串。
如果count是负数，返回第(count的绝对值(从右边数))个字符右边的字符串。
SELECT SUBSTRING_INDEX('a*b','*',1) -- a
SELECT SUBSTRING_INDEX('a*b','*',-1) -- b
SELECT SUBSTRING_INDEX(SUBSTRING_INDEX('a*b*c*d*e','*',3),'*',-1) -- c
LOAD_FILE(file_name) 	
读入文件并且作为一个字符串返回文件内容。文件必须在服务器上，你必须指定到文件的完整路径名，而且你必须有file权 限。文件必须所有内容都是可读的并且小于max_allowed_packet。 如果文件不存在或由于上面原因之一不能被读出，函数返回NULL。

3） 日期时间函数-MySQL的日期和时间函数主要用于处理日期时间。
CURDATE(),CURRENT_DATE 	
返回当前日期
SELECT CURDATE()
->2014-12-17

CURTIME(),CURRENT_TIME 	
返回当前时间
SELECT CURTIME()
->15:59:02

NOW(),CURRENT_TIMESTAMP(),LOCALTIME(),
SYSDATE(),LOCALTIMESTAMP()
返回当前日期和时间
SELECT NOW()
->2014-12-17 15:59:02

UNIX_TIMESTAMP() 	
以UNIX时间戳的形式返回当前时间
SELECT UNIX_TIMESTAMP()
->1418803177

UNIX_TIMESTAMP(d) 	
将时间d以UNIX时间戳的形式返回
SELECT UNIX_TIMESTAMP('2011-11-11 11:11:11')
->1320981071

FROM_UNIXTIME(d) 	
将UNIX时间戳的时间转换为普通格式的时间
SELECT FROM_UNIXTIME(1320981071)
->2011-11-11 11:11:11

UTC_DATE() 	
返回UTC日期
SELECT UTC_DATE()
->2014-12-17

UTC_TIME() 	
返回UTC时间
SELECT UTC_TIME()
->08:01:45 (慢了8小时)

MONTH(d) 	
返回日期d中的月份值，1->12
SELECT MONTH('2011-11-11 11:11:11')
->11

MONTHNAME(d) 	
返回日期当中的月份名称，如Janyary
SELECT MONTHNAME('2011-11-11 11:11:11')
->November

DAYNAME(d) 	
返回日期d是星期几，如Monday,Tuesday
SELECT DAYNAME('2011-11-11 11:11:11')
->Friday

DAYOFWEEK(d) 	
日期d今天是星期几，1星期日，2星期一
SELECT DAYOFWEEK('2011-11-11 11:11:11')
->6

WEEKDAY(d) 	
日期d今天是星期几，0表示星期一，1表示星期二
WEEK(d)，WEEKOFYEAR(d) 	
计算日期d是本年的第几个星期，范围是0->53
SELECT WEEK('2011-11-11 11:11:11')
->45

DAYOFYEAR(d) 	
计算日期d是本年的第几天
SELECT DAYOFYEAR('2011-11-11 11:11:11')
->315

DAYOFMONTH(d) 	
计算日期d是本月的第几天
SELECT DAYOFMONTH('2011-11-11 11:11:11')
->11

QUARTER(d) 	
返回日期d是第几季节，返回1->4
SELECT QUARTER('2011-11-11 11:11:11')
->4

HOUR(t) 	
返回t中的小时值
SELECT HOUR('1:2:3')
->1

MINUTE(t) 	
返回t中的分钟值
SELECT MINUTE('1:2:3')
->2

SECOND(t) 	
返回t中的秒钟值
SELECT SECOND('1:2:3')
->3

EXTRACT(type FROM d) 	
从日期d中获取指定的值，type指定返回的值
SELECT EXTRACT(MINUTE FROM '2011-11-11 11:11:11')
->11

4） type可取值为
MICROSECOND
SECOND
MINUTE
HOUR
DAY
WEEK
MONTH
QUARTER
YEAR
SECOND_MICROSECOND
MINUTE_MICROSECOND
MINUTE_SECOND
HOUR_MICROSECOND
HOUR_SECOND
HOUR_MINUTE
DAY_MICROSECOND
DAY_SECOND
DAY_MINUTE
DAY_HOUR
YEAR_MONTH
TIME_TO_SEC(t) 	

5） 将时间t转换为秒
SELECT TIME_TO_SEC('1:12:00')
->4320

SEC_TO_TIME(s) 	
将以秒为单位的时间s转换为时分秒的格式
SELECT SEC_TO_TIME(4320)
->01:12:00

TO_DAYS(d) 	
计算日期d距离0000年1月1日的天数
SELECT TO_DAYS('0001-01-01 01:01:01')
->366

FROM_DAYS(n) 	
计算从0000年1月1日开始n天后的日期
SELECT FROM_DAYS(1111)
->0003-01-16

DATEDIFF(d1,d2) 	
计算日期d1->d2之间相隔的天数
SELECT DATEDIFF('2001-01-01','2001-02-02')
->-32

ADDDATE(d,n) 	
计算其实日期d加上n天的日期
ADDDATE(d，INTERVAL expr type) 	
计算起始日期d加上一个时间段后的日期
SELECT ADDDATE('2011-11-11 11:11:11',1)
->2011-11-12 11:11:11 (默认是天)
SELECT ADDDATE('2011-11-11 11:11:11', INTERVAL 5 MINUTE)
->2011-11-11 11:16:11 (TYPE的取值与上面那个列出来的函数类似)

DATE_ADD(d,INTERVAL expr type) 	同上
SUBDATE(d,n) 	
日期d减去n天后的日期
SELECT SUBDATE('2011-11-11 11:11:11', 1)
->2011-11-10 11:11:11 (默认是天)

SUBDATE(d,INTERVAL expr type) 	
日期d减去一个时间段后的日期
SELECT SUBDATE('2011-11-11 11:11:11', INTERVAL 5 MINUTE)
->2011-11-11 11:06:11 (TYPE的取值与上面那个列出来的函数类似)

ADDTIME(t,n) 	
时间t加上n秒的时间
SELECT ADDTIME('2011-11-11 11:11:11', 5)
->2011-11-11 11:11:16 (秒)

SUBTIME(t,n) 	
时间t减去n秒的时间
SELECT SUBTIME('2011-11-11 11:11:11', 5)
->2011-11-11 11:11:06 (秒)

DATE_FORMAT(d,f) 	
按表达式f的要求显示日期d
SELECT DATE_FORMAT('2011-11-11 11:11:11','%Y-%m-%d %r')
->2011-11-11 11:11:11 AM

TIME_FORMAT(t,f) 	
按表达式f的要求显示时间t
SELECT TIME_FORMAT('11:11:11','%r')
11:11:11 AM

GET_FORMAT(type,s) 	
获得国家地区时间格式函数
select get_format(date,'usa')
->%m.%d.%Y (注意返回的就是这个奇怪的字符串(format字符串))

6） 条件判断函数
IF(expr,v1,v2)函数
如果表达式expr成立，返回结果v1；否则，返回结果v2。
SELECT IF(1 > 0,'正确','错误')    
->正确

IFNULL(v1,v2)函数
如果v1的值不为NULL，则返回v1，否则返回v2。
SELECT IFNULL(null,'Hello Word')
->Hello Word

CASE
　　语法1：
CASE 
　　WHEN e1
　　THEN v1
　　WHEN e2
　　THEN e2
　　...
　　ELSE vn
END
　　CASE表示函数开始，END表示函数结束。如果e1成立，则返回v1,如果e2成立，则返回v2，当全部不成立则返回vn，而当有一个成立之后，后面的就不执行了。
SELECT CASE 
　　WHEN 1 > 0
　　THEN '1 > 0'
　　WHEN 2 > 0
　　THEN '2 > 0'
　　ELSE '3 > 0'
　　END
->1 > 0

　　语法2：
CASE expr 
　　WHEN e1 THEN v1
　　WHEN e1 THEN v1
　　...
　　ELSE vn
END
　　如果表达式expr的值等于e1，返回v1；如果等于e2,则返回e2。否则返回vn。
SELECT CASE 1 
　　WHEN 1 THEN '我是1'
　　WHEN 2 THEN '我是2'
ELSE '你是谁'

7） 系统信息函数-系统信息函数用来查询MySQL数据库的系统信息。
VERSION() 	
返回数据库的版本号
SELECT VERSION()
->5.0.67-community-nt

CONNECTION_ID()  	返回服务器的连接数
DATABASE()、SCHEMA 	返回当前数据库名
USER()、SYSTEM_USER()、SESSION_USER()、
CURRENT_USER()、CURRENT_USER返回当前用户
CHARSET(str) 	返回字符串str的字符集
COLLATION(str) 	返回字符串str的字符排列方式
LAST_INSERT_ID() 	返回最近生成的AUTO_INCREMENT值

8） 加密函数-加密函数是MySQL用来对数据进行加密的函数。
PASSWORD(str)
该函数可以对字符串str进行加密，一般情况下，PASSWORD(str)用于给用户的密码加密。
SELECT PASSWORD('123')
->*23AE809DDACAF96AF0FD78ED04B6A265E05AA257

MD5
MD5(str)函数可以对字符串str进行散列，可以用于一些普通的不需要解密的数据加密。
SELECT md5('123')
->202cb962ac59075b964b07152d234b70

ENCODE(str,pswd_str)与DECODE(crypt_str,pswd_str)
ENCODE函数可以使用加密密码pswd_str来加密字符串str，加密结果是二进制数，需要使用BLOB类型的字段保存。该函数与DECODE是一对，需要同样的密码才能够解密。
SELECT ENCODE('123','xxoo')
    ->;vx
SELECT DECODE(';vx','xxoo')
    ->123

9）转换数据类型
CAST(x AS type)
CONVERT(x,type)
这两个函数只对BINARY、CHAR、DATE、DATETIME、TIME、SIGNED INTEGER、UNSIGNED INTEGER。
SELECT CAST('123' AS UNSIGNED INTEGER) + 1
    ->124
SELECT '123' + 1
    ->124 其实MySQL能默认转换
SELECT CAST(NOW() AS DATE)
　　->2014-12-18

13 MySQL查询截取分析步骤
（1）开启慢查询日志，捕获慢SQL   
（2）explain+慢SQL分析  
（3）show profile查询SQL语句在服务器中的执行细节和生命周期  
（4）SQL数据库服务器参数调优  

14 开启慢查询日志，捕获慢SQL
（1）查看慢查询日志是否开启
SHOW VARIABLES LIKE '%slow_query_log%';
（2）开启慢查询日志
SET GLOBAL slow_query_log=1;
（3）查看慢查询日志阙值
SHOW [GLOBAL] VARIABLES LIKE '%long_query_time%';
这个值表示超过多长时间的SQL语句会被记录到慢查询日志中
（4）设置慢查询日志阙值
SET GLOBAL long_query_time=3;
（5）查看多少SQL语句超过了阙值
SHOW GLOBAL STATUS LIKE '%Slow_queries%';
（6）MySQL提供的日志分析工具mysqldumpslow

15 explain+慢SQL分析
使用EXPLAIN关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是 如何处理你的SQL语句的。分析你的查询语句或是表结构的性能瓶颈。
使用方式：Explain+SQL语句
执行计划包含的信息：
+----+-------------+-------+------+---------------+------+---------+------+------+-------+
 |  id  |  select_type |  table  | type  | possible_keys | key   | key_len  | ref     | rows  | Extra   |
+----+-------------+-------+------+---------------+------+---------+------+------+-------+
（1）id
SELECT查询的序列号，包含一组数字，表示查询中执行SELECT语句或操作表的顺序
（2）select_type
SIMPLE:简单SELECT查询，查询中不包含子查询或者UNION
PRIMARY:查询中包含任何复杂的子部分，最外层的查询
SUBQUERY：SELECT或WHERE中包含的子查询部分
DERIVED：在FROM中包含的子查询被标记为DERIVER(衍生)， MySQL会递归执行这些子查询，把结果放到临时表中
UNION：若第二个SELECT出现UNION，则被标记为UNION, 若UNION包含在FROM子句的子查询中，外层子查询将被标记为DERIVED
UNION RESULT：从UNION表获取结果的SELECT
（3）table
显示这一行数据是关于哪张表的
（4）type  
type显示的是访问类型，是较为重要的一个指标，结果值从最好到最坏依次是：
system>const>eq_ref>ref>fulltext>ref_or_null>index_merge>unique_subquery>index_subquery>range>index>ALL
（5）possible_keys
显示可能应用在这张表中的索引，一个或多个。 查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询实际使用
（6）key
实际使用的索引。如果为NULL，则没有使用索引。 
查询中若出现了覆盖索引，则该索引仅出现在key列表中。
（7）key_len
表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。在不损失精度的情况下，长度越短越好。
key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的。
（8）ref
显示索引的哪一列被使用了，哪些列或常量被用于查找索引列上的值。
（9）rows
根据表统计信息及索引选用情况，大致估算出找到所需记录多需要读取的行数。
（10）Extra
包含不适合在其他列中显示但十分重要的额外信息

16 提升性能的建议
1）.如果opened_tables太大,应该把my.cnf中的table_cache变大 
2）.如果Key_reads太大,则应该把my.cnf中key_buffer_size变大.可以用Key_reads/Key_read_requests计算出cache失败率 
3）.如果Handler_read_rnd太大,则你写的SQL语句里很多查询都是要扫描整个表,而没有发挥索引的键的作用 
4）.如果Threads_created太大,就要增加my.cnf中thread_cache_size的值.可以用Threads_created/Connections计算cache命中率 
5）.如果Created_tmp_disk_tables太大,就要增加my.cnf中tmp_table_size的值,用基于内存的临时表代替基于磁盘的

17 读写分离
1 ）大型网站为了软解大量的并发访问，除了在网站实现分布式负载均衡，远远不够。到了数据业务层、数据访问层，如果还是传统的数据结构，或者只是单单靠一台服务器扛，
如此多的数据库连接操作，数据库必然会崩溃，数据丢失的话，后果更是不堪设想。这时候，我们会考虑如何减少数据库的联接，一方面采用优秀的代码框架，进行代码的优化，
采用优秀的数据缓存技术如：memcached,如果资金丰厚的话，必然会想到假设服务器群，来分担主数据库的压力。Ok切入今天微博主题，利用MySQL主从配置，实现读写分离，减轻数据库压力。
2）概述：搭设一台Master服务器（win8.1系统，Ip：192.168.0.104），搭设两台Slave服务器（虚拟机——一台Ubuntu，一台 Windows Server 2003）
3）原理：主服务器（Master）负责网站NonQuery操作，从服务器负责Query操作，用户可以根据网站功能模特性块固定访问Slave服务器，或者自己写个池或队列，
自由为请求分配从服务器连接。主从服务器利用MySQL的二进制日志文件，实现数据同步。二进制日志由主服务器产生，从服务器响应获取同步数据库。
4） 在主从服务器上都装上MySQL数据库，windows系统鄙人安装的是mysql_5.5.25.msi版本，Ubuntu安装的是mysql-5.6.22-linux-glibc2.5-i686.tar 

18 Mysql复制原理及其流程
1） 在Slave 服务器上执行sart slave命令开启主从复制开关，开始进行主从复制。
2） 此时，Slave服务器的IO线程会通过在master上已经授权的复制用户权限请求连接master服务器，并请求从执行binlog日志文件的指定位置（日志文件名和位置就是在配置主从复制服务时执行change master命令指定的）之后开始发送binlog日志内容
3） Master服务器接收到来自Slave服务器的IO线程的请求后，二进制转储IO线程会根据Slave服务器的IO线程请求的信息分批读取指定binlog日志文件指定位置之
后的binlog日志信息，然后返回给Slave端的IO线程。返回的信息中除了binlog日志内容外，还有在master服务器端记录的新的binlog文件名称，以及在新的binlog
中的下一个指定更新位置。
4） 当Slave服务器的IO线程获取到Master服务器上IO线程发送的日志内容、日志文件及位置点后，会将binlog日志内容依次写到Slave端自身的Relay Log（即中继日志）文件（MySQL-relay-bin.xxx）的最末端，并将新的binlog文件名和位置记录到master-info文件中，以便下一次读取master端新binlog日志时能告诉Master服务器从新binlog日志的指定文件及位置开始读取新的binlog日志内容
5） Slave服务器端的SQL线程会实时检测本地Relay Log 中IO线程新增的日志内容，然后及时把Relay LOG 文件中的内容解析成sql语句，并在自身Slave服务器上按解析SQL语句的位置顺序执行应用这样sql语句，并在relay-log.info中记录当前应用中继日志的文件名和位置点

19 Mysql的存储引擎
1）. MyISAM  : 是旧版本mysql的默认引擎，现在默认引擎是InnoDB。MyISAM引擎的主要特点就是快，没有事务处理操作，也不支持外键操作。适合于多读取插入，少更新删除的操作表。存储数据分成三个文件：.frm(存储表定义) .MYD(存储数据)  .MYI(存储索引)
用法： engine=myisam default charset=utf-8 ;
2）.InnoDB  ：是新版本mysql的默认引擎，支持事务处理和外键，但是其缺点几就是慢了些。存储方式分为两种：1.共享表空间存储。[.frm(表结构) 和 innodb_data_home(数据)和innodb_data_file_path(索引)]   2.多表空间存储。 [.frm(表结构) 和 .idb（数据）  ]。
适用于对于事务由较高要求的表的创建。
用法：engine=innodb default charset=utf-8 ;
3）.MEMORY： 数据访问非常快的引擎，存储格式同一放在内存中的一个磁盘文件中格式是.frm 。默认使用hash索引。一旦服务器关闭表中的数据就会丢失。数据大小有限制。
用法：engine=memory ;
4）.MERGE：本身是融合的意思，实质是MyISUM表的融合，这些融合的表必须结构完全相同。MERGE本身是没有数据的。插入操作可以是first或者是last。删除只是删除MERGE表定义，并不删除真正表的数据。存储方式：.frm(文件存储表定义信息)  .MRG(描述组合表的信息，比如由哪些表组成，插入时的依据)。
适用于：将一系列等同的MyISAM表逻辑方式组合在一起，作为一个对象引用它们。
用法：engine=merge union=(__,__) insert_method=last/first ;


20 Mysql垂直分库/水平分表/水平分区/水平分片/读写分离/主从复制
1水平分区，就是将一个数据量比较大的表，用某种方法把数据从物理上分成若干个小表来存储，从逻辑来看还是一个大表。通俗地讲表分区是将一大表，根据条件分割成若干个小表。mysql5.1开始支持数据表分区了。 如：某用户表的记录超过了600万条，那么就可以根据入库日期将表分区，也可以根据所在地将表分区。当然也可根据其他的条件分区
（1）RANGE分区 
CREATE TABLE employees (
    id INT NOT NULL,
    fname VARCHAR(30),
    lname VARCHAR(30),
    hired DATE NOT NULL DEFAULT '1970-01-01',
    separated DATE NOT NULL DEFAULT '9999-12-31',
    job_code INT NOT NULL,
    store_id INT NOT NULL
)
partition BY RANGE (store_id) (
    partition p0 VALUES LESS THAN (6),
    partition p1 VALUES LESS THAN (11),
    partition p2 VALUES LESS THAN (16),
    partition p3 VALUES LESS THAN (21)
);
（2）LIST分区
类似于按RANGE分区，区别在于LIST分区是基于列值匹配一个离散值集合中的某个值来进行选择。
LIST分区通过使用“PARTITION BY LIST(expr)”来实现，其中“expr”是某列值或一个基于某个列值、并返回一个整数值的表达式，然后通过“VALUES IN (value_list)”的方式来定义每个分区，其中“value_list”是一个通过逗号分隔的整数列表。 注释：在MySQL 5.1中，当使用LIST分区时，有可能只能匹配整数列表。
CREATE TABLE employees (
    id INT NOT NULL,
    fname VARCHAR(30),
    lname VARCHAR(30),
    hired DATE NOT NULL DEFAULT '1970-01-01',
    separated DATE NOT NULL DEFAULT '9999-12-31',
    job_code INT,
    store_id INT
)
PARTITION BY LIST(store_id)
    PARTITION pNorth VALUES IN (3,5,6,9,17),
    PARTITION pEast VALUES IN (1,2,10,11,19,20),
    PARTITION pWest VALUES IN (4,12,13,14,18),
    PARTITION pCentral VALUES IN (7,8,15,16)
);
（3）HASH分区
基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。这个函数可以包含MySQL 中有效的、产生非负整数值的任何表达式。
要使用HASH分区来分割一个表，要在CREATE TABLE 语句上添加一个“PARTITION BY HASH (expr)”子句，其中“expr”是一个返回一个整数的表达式。它可以仅仅是字段类型为MySQL整型的一列的名字。此外，你很可能需要在后面再添加一个“PARTITIONS num”子句，其中num是一个非负的整数，它表示表将要被分割成分区的数量。
CREATE TABLE employees (
    id INT NOT NULL,
    fname VARCHAR(30),
    lname VARCHAR(30),
    hired DATE NOT NULL DEFAULT '1970-01-01',
    separated DATE NOT NULL DEFAULT '9999-12-31',
    job_code INT,
    store_id INT
)
PARTITION BY HASH(store_id)
PARTITIONS 4;
（4）读写分离&主从复制
Mysql作为目前世界上使用最广泛的免费数据库，相信所有从事系统运维的工程师都一定接触过。但在实际的生产环境中，由单台Mysql作为独立的数据库是完全不能满足实际需求的，无论是在安全性，高可用性以及高并发等各个方面。因此，一般来说都是通过 主从复制（Master-Slave）的方式来同步数据，再通过读写分离（MySQL-Proxy）来提升数据库的并发负载能力 这样的方案来进行部署与实施的。
（5）垂直分库
按照功能划分，把数据分别放到不同的数据库和服务器。
当一个网站开始刚刚创建时，可能只是考虑一天只有几十或者几百个人访问，数据库可能就个db，所有表都放一起，一台普通的服务器可能就够了，而且开发人员也非常高兴，而且信心十足，因为所有的表都在一个库中，这样查询语句就可以随便关联了，多美的一件事情。但是随着访问压力的增加，读写操作不断增加，数据库的压力绝对越来越大，可能接近极限，这时可能人们想到增加从服务器，做什么集群之类的，可是问题又来了，数据量也快速增长。这时可以考虑对读写操作进行分离，按照业务把不同的数据放到不同的库中。其实在一个大型而且臃肿的数据库中表和表之间的数据很多是没有关系的，或者更加不需要（join）操作，理论上就应该把他们分别放到不同的服务器。例如用户的收藏夹的数据和博客的数据库就可以放到两个独立的服务器。这个就叫垂直划分（其实叫什么不重要）。


21 mysql分片与分区的区别
MySQL5.1提供的分区(Partition)功能确实可以实现表的分区，但是这种分区是局限在单个数据库范围里的，它不能跨越服务器的限制。
（一）单库单表：一个库，一个表T_USER

（二）水平分区：就是将一个数据量比较大的表，用某种方法把数据从物理上分成若干个小表来存储，从逻辑来看还是一个大表。

（三）水平分表：可以通过某种方式将user进行水平的切分，产生两个表结构完全一样的user_0000,user_0001等表，user_0000 + user_0001 + …的数据刚好是一份完整的数据。

（四）水平分库：则把一个表的数据划分到不同的数据库，两个数据库的表结构一样。根据一定的规则，可以根据数据的产生者来做引导，上面的数据是由人产生的，可以根据人的id来划分数据库。然后再根据一定的规则，先获知数据在哪个数据库。

（五）垂直分库：按照业务不同，拆分成多个库 。	

（六）读写分离/主从复制：一般来说都是通过 主从复制（Master-Slave）的方式来同步数据，再通过读写分离（MySQL-Proxy）来提升数据库的并发负载能力 这样的方案来进行部署与实施的。

（七）水平分片：在分布式存储系统中，数据需要分散存储在多台设备上，数据分片（Sharding）就是用来确定数据在多台存储设备上分布的技术。数据分片要达到三个目的：
分布均匀，即每台设备上的数据量要尽可能相近；负载均衡，即每台设备上的请求量要尽可能相近；扩缩容时产生的数据迁移尽可能少。
水平分区功能确实可以实现表的分区，但是这种分区是局限在单个数据库范围里的，它不能跨越服务器的限制。


22 Mysql并发/锁/事务
（1）、什么是事务
事务是一条或多条数据库操作语句的组合，具备ACID，4个特点。
原子性：要不全部成功，要不全部撤销
隔离性：事务之间相互独立，互不干扰
一致性：数据库正确地改变状态后，数据库的一致性约束没有被破坏
持久性：事务的提交结果，将持久保存在数据库中
（2）、事务并发会产生什么问题
1）第一类丢失更新：在没有事务隔离的情况下，两个事务都同时更新一行数据，但是第二个事务却中途失败退出， 导致对数据的两个修改都失效了。
例如：
张三的工资为5000，事务A中获取工资为5000，事务B获取工资为5000，汇入100，并提交数据库，工资变为5100，
随后
事务A发生异常，回滚了，恢复张三的工资为5000，这样就导致事务B的更新丢失了。
2）脏读：脏读就是指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。
例如：
　　张三的工资为5000,事务A中把他的工资改为8000,但事务A尚未提交。
　　与此同时，
　　事务B正在读取张三的工资，读取到张三的工资为8000。
　　随后，
　　事务A发生异常，而回滚了事务。张三的工资又回滚为5000。
　　最后，
　　事务B读取到的张三工资为8000的数据即为脏数据，事务B做了一次脏读。
3）不可重复读：是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。
例如：
　　在事务A中，读取到张三的工资为5000，操作没有完成，事务还没提交。
　　与此同时，
　　事务B把张三的工资改为8000，并提交了事务。
　　随后，
　　在事务A中，再次读取张三的工资，此时工资变为8000。在一个事务中前后两次读取的结果并不致，导致了不可重复读。
4）第二类丢失更新：不可重复读的特例。有两个并发事务同时读取同一行数据，然后其中一个对它进行修改提交，而另一个也进行了修改提交。这就会造成第一次写操作失效。 
例如：
在事务A中，读取到张三的存款为5000，操作没有完成，事务还没提交。
　　与此同时，
　　事务B，存储1000，把张三的存款改为6000，并提交了事务。
　　随后，
　　在事务A中，存储500，把张三的存款改为5500，并提交了事务，这样事务A的更新覆盖了事务B的更新。
5）幻读：是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。
例如：
　　目前工资为5000的员工有10人，事务A读取所有工资为5000的人数为10人。
　　此时，
　　事务B插入一条工资也为5000的记录。
　　这是，事务A再次读取工资为5000的员工，记录为11人。此时产生了幻读。
提醒：
不可重复读的重点是修改，同样的条件，你读取过的数据，再次读取出来发现值不一样了
幻读的重点在于新增或者删除，同样的条件，第 1 次和第 2 次读出来的记录数不一样

（3）事务隔离级别，解决什么并发问题，以及存在什么并发问题
（1）READ_UNCOMMITTED
　　这是事务最低的隔离级别，它充许另外一个事务可以看到这个事务未提交的数据。
　　解决第一类丢失更新的问题，但是会出现脏读、不可重复读、第二类丢失更新的问题，幻读 。
（2）READ_COMMITTED
　　保证一个事务修改的数据提交后才能被另外一个事务读取，即另外一个事务不能读取该事务未提交的数据。
　　解决第一类丢失更新和脏读的问题，但会出现不可重复读、第二类丢失更新的问题，幻读问题
（3）REPEATABLE_READ
　　保证一个事务相同条件下前后两次获取的数据是一致的
解决第一类丢失更新，脏读、不可重复读、第二类丢失更新的问题，但会出幻读。
（4）SERIALIZABLE
　　事务被处理为顺序执行。
　　解决所有问题
提醒：
Mysql默认的事务隔离级别为repeatable_read

（4）锁
1）共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。
2）排他锁（X)：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。
3）意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。
4）意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。

共享锁【S锁】
又称读锁，若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。
排他锁【X锁】
又称写锁。若事务T对数据对象A加上X锁，事务T可以读A也可以修改A，其他事务不能再对A加任何锁，直到T释放A上的锁。这保证了其他事务在T释放A上的锁之前不能再读取和修改A。

waitig for table metadata lock 问题深入分析
一个没提交的事务使用了A表， 另外一个session 对A表进行alter，出现waiting for table metadata lock 
在insert into t select * from share 运行时， 同时执行alter table t add index(play_count)， 
alter table语句会Waiting for table metadata lock， 直到insert into … select 语句结束。 
1>>show processlist ;   找到线程ID和库 
2>>kill 279685174  
3>>解决 

23 说明
1）共享锁和排他锁都是行锁，意向锁都是表锁，应用中我们只会使用到共享锁和排他锁，意向锁是mysql内部使用的，不需要用户干预。
2）对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加排他锁（X)；对于普通SELECT语句，InnoDB不会加任何锁，事务可以通过以下语句显示给记录集加共享锁或排他锁。
共享锁（S）：SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE。
排他锁（X)：SELECT * FROM table_name WHERE ... FOR UPDATE。
3）InnoDB行锁是通过给索引上的索引项加锁来实现的，因此InnoDB这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！。


24 Mysql系统表
（1）获取所有表结构(TABLES)
SELECT  *  FROM information_schema.TABLES WHERE  TABLE_SCHEMA='数据库名';
TABLES表：提供了关于数据库中的表的信息（包括视图）。详细表述了某个表属于哪个schema，表类型，表引擎，创建时间等信息。各字段说明如下：
（2） 获取表字段(COLUMNS)
SELECT * FROM information_schema.COLUMNS WHERE TABLE_SCHEMA='数据库名' AND TABLE_NAME='表名'
COLUMNS表：提供了表中的列信息。详细表述了某张表的所有列以及每个列的信息。各字段的说明信息如下：
（3）获取表键值
SELECT  *  FROM information_schema.KEY_COLUMN_USAGE  WHERE  TABLE_SCHEMA='数据库名'  AND TABLE_NAME='表名'
KEY_COLUMN_USAGE表：存取表的健值。各字段的说明信息如下
（4）获取表Check约束
SELECT * FROM information_schema.TABLE_CONSTRAINTS  WHERE  TABLE_SCHEMA='数据库名' AND TABLE_NAME='表名'
TABLE_CONSTRAINTS表：存储主键约束、外键约束、唯一约束、check约束。各字段的
（5）获取表索引
SELECT * FROM information_schema.STATISTICS WHERE TABLE_SCHEMA='数据库名' AND TABLE_NAME='表名'
STATISTICS表：提供了关于表索引的信息。各字段的说明信息如下

25 mysql有关show的用法
SHOW DATABASES列出 MySQL Server上的数据库。
SHOW TABLES [FROM db_name]列出数据库中的表。
SHOW TABLE STATUS [FROM db_name]列出数据库的表信息，比较详细。
SHOW COLUMNS FROM tbl_name [FROM db_name]列出表的列信息，同 SHOW FIELDS FROM tbl_name [FROM db_name]，DESCRIBE tbl_name [col_name]。
SHOW FULL COLUMNS FROM tbl_name [FROM db_name]列出表的列信息，比较详细，同 SHOW FULL FIELDS FROM tbl_name [FROM db_name]。
SHOW INDEX FROM tbl_name [FROM db_name]列出表的索引信息。
SHOW STATUS列出 Server 的状态信息。
SHOW VARIABLES列出 MySQL 系参数值
SHOW PROCESSLIST查看当前mysql查询进程
SHOW GRANTS FOR user列出用户的授权命令

26 MySQL由以下几部分组成：
- 连接池组件
- 管理服务和工具组件
- 查询分析器组件
- 优化器组件
- 缓冲组件
- 插件式存储引擎
- 物理文件
Connection:不同语言与SQL的交互
Management Serveices &Utilities:系统管理和控制工具—备份和恢复的安全性，复制，集群，管理，配置，迁移和元数据。
Connection Pool:连接池—进行身份验证，线程重用，连接限制，检查内存，数据缓冲；管理用户的链接，线程处理等需要缓冲的需求。
SQL Interface:SQL接口—进行DML,DDL，存储过程，视图，触发器等操作和管理；用户通过SQL命令来查询所需要结果。
Parser:解析器—查询翻译对象的特权；SQL命令传递到解析器的时候会被解析器验证和解析。
Optimize:查询优化器—访问路径的统计数据；
Cache和Buffer:查询缓冲器—全局和引擎特定的缓冲和缓冲区；
Pluggable Storage Engine:插件式存储引擎；

27 MySQL主要执行过程
从架构上来看，Mysql服务器对于一条SQL语句的执行过程可以分成如下几部分：
接受命令 包括用户验证，资源申请等
|
V
命令解析 解析SQL语句，生成语法树
|
V
寻找执行计划 根据解析出来的语法树，找到可能的执行计划。对于一条SQL语句，很可能会有多种执行方案，特别是在SQL语句比较复杂的时候。这里需要对于各种可能的方案进行代价评估，最快的找到最有的执行方案。
|
V
优化执行计划 优化执行计划。这是SQL执行中最复杂的部分之一，据说全都是由数学博士们写出来的，而且比较难懂。我目前还处于不懂的状态。
|
V
执行 没啥可说的，只剩执行及返回结果了 


28 mysql服务器调整优化
关闭不必要的二进制日志和慢查询日志，仅在内存足够或开发调试时打开。使用下来语句查
看是否打开：
show variables like '%slow%';

使用下列语句查看慢查询条数：
show global status like '%slow%';
慢查询会消耗过度消耗CPU，可以间歇性打开慢查询日志来定位新能瓶颈。
增加mysql允许的最大连接数。查看mysql最大连接数：
show variables like 'max_connections';

对于InnoDB存储引擎，需要安装服务器内存来设置innodb_buffer_pool_size一般是操作系统内存的70%-80%最佳。
定期的执行optimize table tableName 进行碎片整理 ，或者在大量删除后进行。
对数据库进行分区，分表操作。
使用Nosql辅助,如：Memcached，redis。

29 mysql最大连接数修改方法
方法一：进入MYSQL安装目录 打开MYSQL配置文件 my.ini 或 my.cnf查找 max_connections=100   修改为 max_connections=（数字） 服务里重起MYSQL即可
方法二：set GLOBAL max_connections=200
mysql修改innodb_buffer_pool_size
进入MYSQL安装目录 打开MYSQL配置文件 my.ini 或 my.cnf 查找  innodb_buffer_pool_size  这一项设置 修改为 例如：   innodb_buffer_pool_size = 6G
增加mysql配置中的buffer和cache的数值

30 体系架构
 1).最上层：
最上层是一些客户端和连接服务，包含本地的sock通信和大多数基于客户端/服务端工具实现的类似于tcp/ip的通信，主要完成一些类似于连接处理、授权认证及相关的安全方案，在该层上引用了线程池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于ssl的安全链接。服务器也会为安全接入的每个客户端验证它所具有的操作权限。
 2).第二层：
第二层架构主要完成大多数的核心服务功能。如sql接口，并完成缓存的查询。sql的分析和优化 以及部分内置函数的执行。所有跨存储引擎的功能也在这一层实现，如过程，函数等。在该层，服务器会解析查询并创建相应的内部解析树，并对其完成相应的优化如确定查询表的顺序，是否利用索引等。最后生成相应的执行操作。如select语句，服务器还会查询内部的缓存。如果缓存空间足够大，这样就解决大量读操作的环境中能够很好的提升系统的性能。
3).存储引擎层：
存储引擎真正的负责MySQL中数据的存储和提取，服务器通过API与存储引擎进行通信，不同的存储引擎具有的功能不同，这样我们可以根据自己的实际需进行选取。
4).数据存储层：
主要是将数据存储在运行于裸设备的文件系统之上，并完成于存储引擎的交互。

31 并发控制和锁的概念
当数据库中有多个操作需要修改同一数据时，不可避免的会产生数据的脏读。这时就需要数据库具有良好的并发控制能力，这一切在MySQL中都是由服务器和存储引擎来实现的。解决并发问题最有效的方案是引入了锁的机制，锁在功能上分为共享锁(shared lock)和排它锁(exclusive lock)即通常说的读锁和写锁。当一个select语句在执行时可以施加读锁，这样就可以允许其它的select操作进行，因为在这个过程中数据信息是不会被改变的这样就能够提高数据库的运行效率。当需要对数据更新时，就需要施加写锁了，不在允许其它的操作进行，以免产生数据的脏读和幻读。锁同样有粒度大小，有表级锁(table lock)和行级锁(row lock)，分别在数据操作的过程中完成行的锁定和表的锁定。这些根据不同的存储引擎所具有的特性也是不一样的。MySQL大多数事务型的存储引擎都不只是简单的行级锁，基于性能的考虑，他们一般在行级锁基础上实现了多版本并发控制(MVCC)。这一方案也被Oracle等主流的关系数据库采用。它是通过保存数据中某个时间点的快照来实现的，这样就保证了每个事务看到的数据都是一致的。详细的实现原理可以参考《高性能MySQL》第三版。

32 Mycat概述
1 ）mycat是一个数据库中间件，也可以理解为是数据库代理。在架构体系中是位于数据库和应用层之间的一个组件，并且对于应用层是透明的，
即数据库感受不到mycat的存在，认为是直接连接的mysql数据库（实际上是连接的mycat,mycat实现了mysql的原生协议）
2） mycat的三大功能：分表、读写分离、主从切换




二、ms相关
1、Mysql中的MyISAM与InnoDB的区别？
（1）InnoDB存储引擎支持事务，而MyISAM不支持事务；
（2）InnoDB支持行级锁，而MyISAM只支持表级锁；
InnoDB行锁是通过给索引加锁实现的，即只有通过索引条件检索数据，InnoDB才使用行级锁，否则将使用表级锁！行级锁在每次获取锁和释放锁的操作需要比表级锁消耗更多的资源。
MySQL表级锁有两种模式：表共享读锁和表独占写锁。就是说对MyIASM表进行读操作时，它不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写操作；而对MyISAM表的写操作，会阻塞其他用户对同一表的读和写操作。
（3）InnoDB支持外键，而MyISAM不支持外键；
（4）InnoDB不保存数据库表中表的具体行数，而MyISAM会保存；
（ 也就是说，执行 select count(*) from table 时，InnoDB要扫描一遍整个表来计算有多少行，而MyISAM只需要读出保存好的行数即可（内部维护了一个计算器，可以直接调取）。
【注】：当count(*)语句包含where条件时，两种表的操作是一样的。也就是上述介绍到的InnoDB使用表锁的一种情况。）
对于select ,update ,insert ,delete 操作：
如果执行大量的SELECT，MyISAM是更好的选择（因为MyISAM不支持事务，使得MySQL可以提供高速存储和检索，以及全文搜索能力）；
如果执行大量的INSERT或UPDATE，出于性能方面的考虑，应该使用InnoDB表（因为InnoDB支持事务，在一些列增删改中只要哪个出错还可以回滚还原，而MyISAM就不可以了）。

2、InnoDB存储引擎的四大特性？
插入缓冲、二次写、自适应哈希索引、预读
（1）插入缓冲：
一般情况下，主键是行唯一的标识符。通常应用程序中行记录的插入顺序是按照主键递增的顺序进行插入的。因此，插入聚集索引一般是顺序的，不需要磁盘的随机读取。因为，对于此类情况下的插入，速度还是非常快的。
如果索引是非聚集的且不唯一，在进行插入操作时，数据的存放对于非聚集索引叶子节点的插入不是顺序的，这时需要离散地访问非聚集索引页，由于随机读取的存在而导致了插入操作性能下降。（这是因为B+树的特性决定了非聚集索引插入的离散性。）
插入缓冲对于非聚集索引的插入和更新操作，不是每一次直接插入索引页中，而是先判断插入的非聚集索引页是否在缓存池中。如果在，则直接插入；如果不在，则先放入一个插入缓冲区中，好似欺骗数据库这个非聚集的索引已经插入到叶子结点了，然后再以一定的频率执行插入缓冲和非聚集索引页子节点的合并操作，这时通常能将多个插入合并到一个操作中（因为在一个索引页中），这就大大提高了对非聚集索引执行插入和修改操作的性能。
插入缓冲的使用要满足两个条件：
索引是辅助索引
索引不是唯一的
（辅助索引不能是唯一的，因为在把它插入到插入缓冲时，我们并不去查找索引页的情况。如果去查找肯定又会出现离散读的情况，插入缓冲就失去了意义。）
存在的问题：
在写密集的情况下，插入缓冲会过多的占用缓冲池内存，默认情况下最大可以占用1/2的缓冲池内存。
（2）二次写
当数据库宕机时，可能发生数据库正在写一个页面，而这个页只写了一部分的情况，我们称之为部分写失效。当写入失效发生时，先通过页的副本来还原该页，再重做日志，这就是两次写。
doublewrite步骤：
当一系列机制（main函数触发、checkpoint等）触发数据缓冲池中的脏页进行刷新时，并不直接写磁盘，而是会通过memcpy函数将脏页拷贝到内存中的doublewrite buffer，之后通过doublewrite buffer再分两次、每次1MB顺序写入共享表空间的物理磁盘上。
然后马上调用fsync函数，同步脏页进磁盘。在这个过程中，doublewrite页的存储是连续的，因此写入磁盘为顺序写，性能很高在完成doublewrite页的写入后，再将doublewrite buffer中的页写入到各个表空间文件中，此时的写入则是离散的。
如果操作系统在将页写入磁盘的过程中崩溃了，在恢复过程中，InnoDB存储引擎可以从共享表空间中的doublewrite中找到该页的一个副本，将其拷贝到表空间文件，再应用重做日志，就完成了恢复过程。因为有副本所以也不担心表空间中数据页是否损坏。
（3）自适应哈希索引
InnoDB存储引擎会监控对表上索引的查找，如果观察到建立哈希索引可以带来速度的提升，则建立哈希索引，所以称为自适应的。自适应哈希索引通过缓冲池的B+树构造而来，因此建立的速度很快，而且不需要将整个表都建哈希索引，InnoDB存储引擎会自动根据访问的频率和模式来为某些页建立哈希索引。
（4）预读
InnoDB 提供了两种预读的方式，一种是 Linear read ahead，由参数innodb_read_ahead_threshold控制，当你连续读取一个 extent 的 threshold 个 page 的时候，会触发下一个 extent 64个page的预读。另外一种是Random read-ahead，由参数innodb_random_read_ahead控制，当你连续读取设定的数量的page后，会触发读取这个extent的剩余page。
InnoDB 的预读功能是使用后台线程异步完成的。

3. InnoDB如何保证事务的四大特性？
MySQL的存储引擎InnoDB使用重做日志(redo log)保证一致性与持久性，回滚日志(undo log)保证原子性，使用各种锁来保证隔离性。
 

4. MySQL中的重做日志（redo log），回滚日志（undo log），以及二进制日志（binlog）？
MySQL中有六种日志文件，分别是：
重做日志（redo log）
回滚日志（undo log）
二进制日志（binlog）
错误日志（errorlog）
慢查询日志（slow query log）
一般查询日志（general log）
中继日志（relay log）
其中重做日志和回滚日志与事务操作息息相关，二进制日志也与事务操作有一定的关系。
事务是如何通过日志来实现的？
Undo 记录某 数据 被修改 前 的值，可以用来在事务失败时进行 rollback；
Redo 记录某 数据块 被修改 后 的值，可以用来恢复未写入 data file 的已成功事务更新的数据。
即，
Redo Log 保证事务的持久性
Undo Log 保证事务的原子性（在 InnoDB 引擎中，还用 Undo Log 来实现 MVCC）
比如某一时刻数据库 DOWN 机了，有两个事务，一个事务已经提交，另一个事务正在处理。数据库重启的时候就要根据日志进行前滚及回滚，把已提交事务的更改写到数据文件，未提交事务的更改恢复到事务开始前的状态。即通过 redo log 将所有已经在存储引擎内部提交的事务应用 redo log 恢复，所有已经 prepared 但是没有 commit 的事务将会应用 undo log 做回滚。

（1）重做日志（redo log）：
redo log在事务没有提交前，会记录每一个修改操作变更后的数据。主要是防止在发生故障的时间点，尚有脏页未写入磁盘。在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。（作用）
在事务提交前，只要将 Redo Log 持久化即可，不需要将数据持久化。当系统崩溃时，系统可以根据redo Log的内容，将所有数据恢复到最新的状态。（持久化：先将重做日志写入缓存，再刷新(fsync)到磁盘）
重做日志是物理日志，记录的是对于每个页的修改。事务开始后Innodb存储引擎先将重做日志写入缓存（innodb_log_buffer）中。然后会通过以下三种方式将innodb日志缓冲区的日志刷新到磁盘。
Master Thread每秒一次执行刷新Innodb_log_buffer到重做日志文件。
每个事务提交时会将重做日志刷新到重做日志文件。
当重做日志缓存可用空间少于一半时，重做日志缓存被刷新到重做日志文件
当事务提交时，必须先将该事务的所有日志写入到重做日志文件进行持久化。
1）内容：
物理格式的日志，记录的是物理数据页面的修改的信息，其redo log是顺序写入redo log file的物理文件中去的。
2）redo log是什么时候写盘的？
是在事物开始之后逐步写盘的。
事务开始之后就产生redo log，redo log的写盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入redo log文件中。（先将重做日志写入缓存，将日志缓冲区的日志刷新到磁盘，写入磁盘的方式有上面3种）
【注】即使某个事务还没有提交，Innodb存储引擎仍然每秒会将重做日志缓存刷新到重做日志文件。这一点是必须要知道的，因为这可以很好地解释再大的事务的提交（commit）的时间也是很短暂的。
3）什么时候释放：
当对应事务的脏页写入到磁盘之后，redo log的使命也就完成了，重做日志占用的空间就可以重用（被覆盖）。

（2）回滚日志（undo log）：
保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读。（作用）
事务发生异常需要回滚，这时就需要回滚日志。回滚日志不同于重做日志，它是逻辑日志，对数据库的修改都逻辑的取消了。当事务回滚时，它实际上做的是与先前相反的工作。对于每个INSERT，InnoDB存储引擎都会完成一个DELETE；对于每个UPDATE，InnoDB存储引擎都会执行一个相反的UPDATE。
未提交的事务和回滚了的事务也会产生重做日志。InnoDB存储引擎会重做所有事务包括未提交的事务和回滚了的事务，然后通过回滚日志回滚那些未提交的事务。使用这种策略需要回滚日志在重做日志之前写入磁盘，使得持久化变得复杂起来。为了降低复杂度，InnoDB存储引擎将回滚日志作数据，记录回滚日志的操作也会记录到重做日志中。这样回滚日志就可以像数据一样缓存起来，而不用在重写日志之前写入磁盘了。
1）内容：
逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，这一点是不同于redo log的。
2）什么时候产生？
事务开始之前，将当前是的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性
3）什么时候释放？
当事务提交之后，undo log并不能立马被删除，而是放入待清理的链表，由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间。

（3）二进制日志（bin log）：
1）作用：
用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。 用于数据库的基于时间点的还原。
2）内容：
逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。
但又不完全是sql语句这么简单，而是包括了执行的sql语句（增删改）反向的信息，也就意味着delete对应着delete本身和其反向的insert；update对应着update执行前后的版本的信息；insert对应着delete和insert本身的信息。
在使用mysqlbinlog解析binlog之后一些都会真相大白。
因此可以基于binlog做到类似于oracle的闪回功能，其实都是依赖于binlog中的日志记录。
3）什么时候产生：
事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到binlog中。这里与redo log很明显的差异就是redo log并不一定是在事务提交的时候刷新到磁盘，redo log是在事务开始之后就开始逐步写入磁盘。
因此对于事务的提交，即便是较大的事务，提交（commit）都是很快的，但是在开启了bin_log的情况下，对于较大事务的提交，可能会变得比较慢一些。这是因为binlog是在事务提交的时候一次性写入的造成的，这些可以通过测试验证。
4）什么时候释放：
binlog的默认是保持时间由参数expire_logs_days配置，也就是说对于非活动的日志文件，在生成时间超过expire_logs_days配置的天数之后，会被自动删除。
binlog与redolog的区别？
在MySQL数据库中还有一种二进制日志，其用来基于时间点的还原及主从复制。从表面上来看其和重做日志非常相似，都是记录了对于数据库操作的日志。但是，从本质上来看有着非常大的不同。 首先重做日志是在InnoDB存储引擎层产生的，而二进制日志是在MySQL数据库的上层产生的。其次，两种日志记录的内容形式不同。二进制日志是一种逻辑日志，其记录的是对应的SQL语句。而重做日志是物理日志，记录的是每个页的修改。此外，两种日志记录写入磁盘的时间点不同，二进制日志只在事务提交完成后进行一次写入，重做日志在事务进行时不断地写入。


5、 什么是事务？
事务就是一个操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位。事务是数据库维护数据一致性的单位，在每个事务结束时，都能保持数据一致性。

6、 数据库事务的四大特性？
原子性、一致性、隔离性、持久性  （ACID）
原子性：是指整个数据库事务是不可分割的单位。只有使事务中的所有数据库操作都成功，才算整个事务成功。如果事务中任何一个sql语句执行失败，那么已经执行的sql语句也必须撤销，事务状态退回到执行事务之前的状态。
一致性：一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态。在事务开始之前和事务结束之后，事务的完整性约束没有被破坏。
隔离性：一个事务的影响在该事务提交前对其他事物都不可见。——这通过锁来实现
持久性：事务一旦提交，其结果就是永久性的。
（隔离性由锁来实现；原子性、一致性和持久性通过数据库的redo和undo来完成。）

7、不考虑事务的隔离性，会发生几种问题？
通过锁可以实现事务隔离性的要求，使得事务可以并发地工作。因为事务隔离性的要求，锁会带来3种问题：丢失更新、脏读、不可重复读。
1）丢失更新：
指一个事务正在访问修改数据，与此同时另一个事务也在访问修改此数据，两个事务互相不知道对方的存在。假如在是事务A修改数据前事务B已经修改过1次数据，那么事务A最终只能查询到假数据，丢失了更新操作。
解决方案：
悲观锁的方式： 加锁，建议最后一步更新数据的时候加上排它锁，不要在一开始就加锁。执行到了最后一步更新，首先做一下加锁的查询确认数据有没有没改变，如果没有被改变，则进行数据的更新，否则失败。 一定要是做加锁的查询确认，因为如果你不加锁的话，有可能你在做确认的时候数据又发生了改变。
乐观锁的方式：使用版本控制实现。
2）脏读：
一个事务读取了另一个事务未提交的数据，那这个读取就是脏读。
解决方法 ： 把数据库的事务隔离级别调整到read commited。
3）不可重复读：
不可重复读是指在一个事务内多次读同一数据，在这个事务还没有结束时，另外一个事务也访问并修改该同一数据，那么在第一个事务的两次读数据之间，由于第二个事务的修改，第一个事务两次读到的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为不可重复读。
如何避免：InnoDB存储引擎中，通过使用Next-Key Lock算法来避免不可重复读的问题。在Next-Key Lock算法下，对于索引的扫描，不仅仅是锁住扫描到的索引，而且还能锁住这些索引覆盖的范围。因此对于这个范围内的插入都是不允许的。InnoDB存储引擎的默认事务隔离级别是READ REPEATABLE，采用Next-Key Lock算法，就避免了不可重复读的现象。
解决办法：把数据库的事务隔离级别调整到 REPEATABLE READ ， 读取时候不允许其他事务修改该数据，不管数据在事务过程中读取多少次，数据都是一致的。
4）幻读：
是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。
如何避免：Repeatable read及以上级别通过间隙锁来防止幻读的出现，即锁定特定数据的前后间隙让数据无法被插入。

8、MySQL数据库提供的四种隔离级别？
read uncommitted（读未提交）
read committed（读已提交）
repeatable read（可重复读）：InnoDB的默认隔离级别
serializable（串行）

9、有多少种日志？
错误日志    ：记录出错信息，也记录一些警告信息或者正确的信息。
查询日志    ：记录所有对数据库请求的信息，不论这些请求是否得到了正确的执行。
慢查询日志：设置一个阈值，将运行时间超过该值的所有SQL语句都记录到慢查询的日志文件中。
二进制日志：记录对数据库执行更改的所有操作。
中继日志
事务日志

10、事务是如何通过日志来实现的？
InnoDB中，事务日志通过重做（redo）日志文件和InnoDB存储引擎的日志缓冲来实现。当开始一个事务时,会记录该事务的一个LSN（日志序列号），当事务执行时，会往InnoDB的日志缓冲里插入事务日志，当事务提交时，必须将innoDB存储引擎的日志缓冲写入磁盘。也就是在写数据前，需要先写日志。这种方式称为预写日志方式。
InnoDB通过预写日志的方式来保证事务的完整性。这意味着磁盘上存储的数据页和内存缓冲池中的数据页是不同步的，对于内存缓冲池中页的修改，先是写入重做日志文件，然后再写入磁盘，因此是一种异步的方式。
事务有时还需要撤销，这就需要undo。对数据库进行修改时，数据库不但会产生redo，而且会产生一定量的undo，如果你执行的事务或语句由于某种原因失败了，或者如果你用一条rollback语句请求回滚，就可以利用这些undo信息将数据回滚到修改之前的样子。


11、数据库的乐观锁和悲观锁是什么？
乐观并发控制(乐观锁)和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。
1）悲观锁：假定会发生并发冲突，屏蔽掉一切可能违反数据完整性的操作，在读取的时候就对数据进行加锁， 在该用户读取数据的期间，其他任何用户都不能来修改该数据，但是其他用户是可以读取该数据的， 只有当自己读取完毕才释放锁。
乐观锁：假定不会发生并发冲突，只在提交的时候检查是否发生并发冲突。
事务和锁的存在都是为了更好地解决并发访问造成的数据不一致性问题。乐观锁和悲观锁都是为了解决并发控制问题，乐观锁可以看做一种在最后提交时检测冲突的手段，而悲观锁是一种避免冲突的手段。

2）乐观锁：假设不会发生并发冲突，只在提交的时候检查是否发生并发冲突。可以使用版本号机制和CAS算法实现。
版本号机制：一般在数据表中加一个数据版本号version字段，表示数据被修改的次数，当数据被修改时version值加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若当前读取到的version值与第一次读取到的数据库version值相等时才更新，否则重试更新操作，直到更新成功。
例子：
假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 100 。
操作员A此时将其读出（ version=1 ），并从其帐户余额中扣除 50（100-50 =50）；
在操作员A操作的过程中，操作员B也读入此用户信息（ version=1 ），并从其帐户余额中扣除20 （100-20=80 ）。
操作员A完成了修改工作，将数据版本号加一（ version=2 ），连同帐户扣除后余额（ balance=50 ），提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 ；
操作员B完成了操作，也将版本号加一（ version=2 ）试图向数据库提交数据（ balance=80 ），但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 2 ，数据库记录当前版本也为 2 ，不满足 “ 当前最后更新的version与操作员第一次的版本号相等 “ 的乐观锁策略，因此，操作员B的提交被驳回。

3）CAS机制：即compare and swap（比较与交换），无锁编程，在不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，因此也叫非阻塞同步。
CAS过程是这样：它包含3个参数：内存值V（要更新变量的值），旧的预期值A，要修改的值B。当且仅当预期值A的值等于内存值V时，才会将内存值V修改为B，否则不会执行任何操作（V值和A值不同，则说明已经有其他线程做了更新）。一般情况下是一个自旋操作，即不断的重试。
例子：
假设 t1，t2 线程同时更新同一变量56的值。
因为t1和t2线程都同时去访问同一变量56，所以他们会把主内存的值完全拷贝一份到自己的工作内存空间，所以t1和t2线程的预期值都为56。
假设t1在与t2线程竞争中线程t1能去更新变量的值，而其他线程都失败。（失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次发起尝试）。t1线程去更新变量值改为57，然后写到内存中。此时对于t2来说，内存值变为了57，与预期值56不一致，就操作失败了（想改的值不再是原来的值）。

4）乐观锁的优势和劣势 ：
优势：如果数据库记录始终处于悲观锁加锁状态，可以想见，如果面对几百上千个并发，那么要不断的加锁减锁，而且用户等待的时间会非常的长， 乐观锁机制避免了长事务中的数据库加锁解锁开销，大大提升了大并发量下的系统整体性能表现。所以如果系统的并发非常大的话，悲观锁定会带来非常大的性能问题，所以建议就要选择乐观锁定的方法， 而如果并发量不大，完全可以使用悲观锁定的方法。乐观锁也适合于读比较多的场景。 
劣势： 乐观锁只能在提交数据时才发现业务事务将要失败，如果系统的冲突非常的多，而且一旦冲突就要因为重新计算提交而造成较大的代价的话，乐观锁也会带来很大的问题。而且乐观锁也无法解决脏读的问题 。
悲观锁假定会发生并发冲突，在读取的时候就对数据进行加锁， 在该用户读取数据的期间，其他任何用户都不能来修改该数据，但是其他用户是可以读取该数据的， 只有当自己读取完毕才释放锁。
在数据库中可以使用Repeatable Read的隔离级别（可重复读）来实现悲观锁，它完全满足悲观锁的要求（加锁）。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。

5）悲观锁的优势和劣势 ：
优势：  能避免冲突的发生 。
劣势 ：开销较大，而且加锁时间较长，对于并发的访问性支持不好。
两种锁的使用场景：
如果冲突很少，或者冲突的后果不会很严重，那么通常情况下应该选择乐观锁，因为它能得到更好的并发性；
如果冲突太多或者冲突的结果对于用户来说痛苦的，那么就需要使用悲观策略，它能避免冲突的发生。
一般乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候；悲观锁适用于多写的情况，多写的情况一般会经常产生冲突。
数据库中的乐观锁，悲观锁
面试必备之乐观锁与悲观锁

12、共享锁与排它锁？
共享锁和排它锁是具体的锁，是数据库机制上的锁。
共享锁（读锁）： 在同一个时间段内，多个用户可以读取同一个资源，读取的过程中数据不会发生任何变化。读锁之间相互不阻塞， 多个用户可以同时读，但是不能允许有人修改。 
排它锁（写锁）： 在任何时候只能有一个用户写入资源，当进行写锁时会阻塞其他的读锁或者写锁操作，只能由这一个用户来写，其他用户既不能读也不能写。
加锁会有粒度问题，从粒度上从大到小可以划分为 ：
表锁：开销较小，一旦有用户访问这个表就会加锁，其他用户就不能对这个表操作了，应用程序的访问请求遇到锁等待的可能性比较高。
页锁：是MySQL中比较独特的一种锁定级别，锁定颗粒度介于行级锁定与表级锁之间，所以获取锁定所需要的资源开销，以及所能提供的并发处理能力也同样是介于上面二者之间。另外，页级锁定和行级锁定一样，会发生死锁。
行锁：开销较大，能具体的锁定到表中的某一行数据，但是能更好的支持并发处理， 会发生死锁。

13、什么是存储过程？什么是触发器？
存储过程：
（1）定义：
存储过程是一组SQL命令集合，经过预编译存放在系统中。也就是将常用的或很复杂的工作，预先用SQL语句写好并用一个指定的名称存储起来，以后只要调用它就可以完成相应的功能。 
（2）存储过程的种类：
存储过程一般分为“系统存储过程”与“用户存储过程”。系统存储过程一般以sp_开头，用户不可以编辑修改，只能调用；用户存储过程是用户编写的处理数据的存储过程。
（3）存储过程的创建和使用： 
create procedure proc2
@mobile varchar(50),@sendMsg varchar(50)
as
begin
print @mobile  ---输出mobile这个参数
end

14、存储过程与一般的SQL语句有什么区别呢? （存储过程的优点 ）
存储过程只在创造时进行编译，以后每次执行存储过程都不需再重新编译，而一般SQL语句每执行一次就编译一次,所以使用存储过程可提高数据库执行速度。 
当对数据库进行复杂操作时(如对多个表进行Update,Insert,Query,Delete时），可将此复杂操作用存储过程封装起来与数据库提供的事务处理结合一起使用。 
存储过程可以重复使用,可减少数据库开发人员的工作量 。
安全性高,可设定只有某此用户才具有对指定存储过程的使用权。
缺点：对于简单的sql语句没必要使用存储过程，存储过程适合用于对数据库进行复杂的操作。

15、触发器
（1）定义：
触发器（Trigger）是个特殊的存储过程，它不是由用户主动发起调用的，而是当发生某一事件而触发，由系统自动调用。比如当用户在数据库中新增一条商品记录，我们希望同时在库存中做登记，而库存登记不是人工去录入，是在发生新增商品记录这一事件时发生，由系统自动完成录入，这个工作就可以交给一个特殊的存储过程来完成，这个存储过程就是触发器。
（2）触发器的工作机制：
触发器是建在表上的，当这个表发生新增、修改、删除操作时，如果这个表上有触发器，就会被自动调用。在这个事件的过程中，系统会产生一个临时表，这个临时表只有一行记录：
当执行新增操作时，临时表的名字叫inserted
当执行删除操作时，临时表的名字叫deleted
当执行修改操作时，会同时产生2个临时表，一个是inserted，存放的是新的数据，一个是deleted，存的是旧的数据
当需要触发器连带操作登记库存时就可以从inserted表或者deleted表中获得变量，更新到库存表中数据。
（3）作用：维护表的完整性，记录表的修改来审计表的相关信息。分为：
DML触发器：当数据库服务器中发生数据操作语言事件时执行的存储过程，分为：After触发器和instead of触发器。
DDL触发器：特殊的触发器，在响应数据定义语言（DDL）语句时触发，一般用于数据库中执行管理任务。DDL触发器是响应create、after、或drop开头的语句而激活。
触发器用处还是很多的，比如校内网、开心网、Facebook，你发一个日志，自动通知好友，其实就是在增加日志时做一个后触发，再向通知表中写入条目。因为触发器效率高。
（4）创建触发器的SQL语法：
复制代码
create trigger 触发器名称   --触发器名称
on 表名                 --建在那个表上
for insert|update|delete    --是插入事件处理还是修改事件处理还是删除事件处理
as                       --以下是触发器基本格式
begin
end
调用存储过程：call procedure_name(参数,参数...)

16、触发器优点
自动执行：触发器不用像存储过程一样需要手动调用，是自动触发的，只有当对表进行更新，删除等操作的时候会立即触发。
级联更新：触发器可以通过数据库中的相关表进行层叠更改，这比直接将代码写在前端的做法更安全合理。
强化约束：触发器可以引用其他表的列，能够实现比check约束更为复杂的约束。
跟踪变化：触发器可以阻止数据库中未经允许的指定更新和变化。
强制业务逻辑：触发器可用于执行管理任务，并强制影响数据库的复杂业务规则。
缺点：不同数据库，语法差别很大，移植困难，换了数据库，需要重新编写；不好管理，把过多业务逻辑写在存储过程不好维护，不利于分层管理，容易混乱，一般存储过程适用于个别对性能要求较高的业务。

17、存储过程与触发器的区别？与函数的区别？
存储过程与触发器：
它们都是sql语句集，不同的是：
存储过程是需要用户调用的（通过存储过程名字直接调用），而触发器不是由用户主动发起调用的，而是当发生某一事件而触发，由系统自动调用。在insert、delete和update命令之前或之后自动调用sql命令或者存储过程。
函数：
函数：MySQL中提供了许多内置函数，还可以自定义函数（实现程序员需要sql逻辑处理）
自定义函数创建语法：
创建：CREATE FUNCTION 函数名称(参数列表) 
RETURNS 返回值类型 函数体
修改： ALTER FUNCTION 函数名称 [characteristic ...]
删除：DROP FUNCTION [IF EXISTS] 函数名称
调用：SELECT 函数名称(参数列表)
存储过程和函数的区别：
一般来说，存储过程实现的功能要复杂一点，而函数的实现的功能针对性比较强。
对于存储过程来说可以返回参数，而函数只能返回值或者表对象。
存储过程一般是作为一个独立的部分来执行，而函数可以作为查询语句的一个部分来调用，由于函数可以返回一个表对象，因此它可以在查询语句中位于FROM关键字的后面。

18、索引是什么？有什么作用以及优缺点？
索引是对数据库表中一或多个列的值进行排序的结构，利用索引可快速访问数据库表的特定信息。
举个例子：假设有一张数据表Emplyee，该表有三列：Employee_name，Employee_age，Employee_address，表中有几万条记录。现在要执行下面这条查询语句：Select * from Employee where Employee_name='Jesus'。
如果没有数据库索引功能，数据库系统会全表扫描，逐行的遍历整张表，对于每一行都要检查其Employee_Name字段是否等于“Jesus”。而数据库索引功能索引的最大作用就是加快查询速度，它能从根本上减少需要扫表的记录/行的数量。
1）优点：
索引加快数据库的检索速度
通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性；
加速表和表之间的连接；
使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间。
2）缺点：
创建索引和维护索引需要耗费时间，这个时间随着数据量的增加而增加；
索引需要占用物理空间，不光是表需要占用数据空间，每个索引也需要占用物理空间；
当对表进行增、删、改、的时候索引也要动态维护，这样就降低了数据的维护速度。

19、说一说MySQL数据库几个基本的索引类型？
普通索引、唯一索引、主键索引、联合索引、全文索引。
唯一索引：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。
主键索引：是一种特殊的唯一索引，一个表只能有一个主键，不允许有空值。 为表定义主键将自动创建主键索引。（数据库表某列或列组合，其值唯一标识表中的每一行。该列称为表的主键。）
联合索引：指对表上的多个列做索引。只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用组合索引时遵循最左前缀原则。
全文索引：主要用来查找文本中的关键字，而不是直接与索引中的值相比较。目前只有char、varchar，text 列上可以创建全文索引。

20、使用索引查询一定能提高查询的性能吗？为什么？
通常，通过索引查询数据比全表扫描要快。但是我们也必须注意到它的代价：
索引需要空间来存储，也需要定期维护，每当有记录在表中增减或索引列被修改时，索引本身也会被修改。这意味着每条记录的INSERT、DELETE、UPDATE将为此多付出4,5 次的磁盘I/O。因为索引需要额外的存储空间和处理，那些不必要的索引反而会使查询反应时间变慢。使用索引查询不一定能提高查询性能，索引范围查询(INDEX RANGE SCAN)适用于两种情况：
如果某个字段的取值范围很广，几乎没有重复，即高选择性，则此时使用B+树索引是最适合的，例如姓名。
基于一个范围的检索，一般查询返回结果集小于表中记录数的20%。（MySQL数据库的优化器会预估查询可能得到的行，如果大于某一个值，则B+树会选择全表的扫描。这个值一般在20%（即当取出的数据量超过表中数据的20%，优化器就不会使用索引））

21、为数据表建立索引的原则有哪些？
在最频繁使用的、用以缩小查询范围的字段上建立索引。
在频繁使用的、需要排序的字段上建立索引。

22、什么情况下应不建或少建索引？
对于那些在查询中很少使用或者参考的列不应该创建索引。（既然这些列很少使用到，因此有索引或者无索引并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。）
对于那些只有很少数据值的列也不应该增加索引。（由于这些列的取值很少，例如人事表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比例，即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度。）
对于那些定义为text, image和bit数据类型的列不应该增加索引。（这是因为，这些列的数据量要么相当大，要么取值很少。）
当修改性能远远大于检索性能时，不应该创建索引。（这是因为，修改性能和检索性能是互相矛盾的。当增加索引时，会提高检索性能，但是会降低修改性能。当减少索引时，会提高修改性能，降低检索性能。）


23、什么是mysql联合索引？
联合索引是指对表上的多个列做索引。在mysql建立联合索引时会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。
最左前缀匹配原则：
最左优先，在检索数据时从联合索引的最左边开始匹配。
对列col1、列col2和列col3建一个联合索引：KEY test_col1_col2_col3 on test(col1,col2,col3);
联合索引 test_col1_col2_col3 相当于建立了(col1)、(col1,col2)、(col,col2,col3)三个索引。

（1）SELECT * FROM test WHERE col1="1" AND clo2="2" AND clo4=|"4"
上面这个查询语句执行时会依照最左前缀匹配原则，检索时会使用索引(col1,col2)进行数据匹配。

（2）索引的字段可以是任意顺序的，如：
SELECT * FROM test WHERE col1=“1” AND clo2=“2”
SELECT * FROM test WHERE col2=“2” AND clo1=“1”
这两个查询语句都会用到索引(col1,col2)，mysql创建联合索引的规则是首先会对联合合索引的最左边的，也就是第一个字段col1的数据进行排序，在第一个字段的排序基础上，然后再对后面第二个字段col2进行排序。其实就相当于实现了类似 order by col1 col2这样一种排序规则。
有人会疑惑第二个查询语句不符合最左前缀匹配：首先可以肯定是两个查询语句都保函索引(col1,col2)中的col1、col2两个字段，只是顺序不一样，查询条件一样，最后所查询的结果肯定是一样的。既然结果是一样的，到底以何种顺序的查询方式最好呢？此时我们可以借助mysql查询优化器explain，explain会纠正sql语句该以什么样的顺序执行效率最高，最后才生成真正的执行计划。

（3）如果只查询col2：SELECT * FROM test WHERE col2=2;
第一个col字段是绝对有序的，而第二字段就是无序的了。所以通常情况下，直接使用第二个字段col2进行条件判断是用不到索引的。当然是col2字段的索引数据也是有序的情况下才能使用咯，什么时候才是有序的呢？在col1字段是等值匹配的情况下，cid才是有序的。这也就是mysql索引规则中要求复合索引要想使用第二个索引，必须先使用第一个索引的原因。（而且第一个索引必须是等值匹配）。
为什么要使用联合索引？
减少开销。建一个联合索引(col1,col2,col3)，实际相当于建了(col1),(col1,col2),(col1,col2,col3)三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引会大大的减少开销！

（4）覆盖索引。对联合索引(col1,col2,col3)，如果有如下的sql: select col1,col2,col3 from test where col1=1 and col2=2。那么MySQL可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机io操作。减少io操作，特别的随机io其实是dba主要的优化策略。所以，在真正的实际应用中，覆盖索引是主要的提升性能的优化手段之一。
效率高。索引列越多，通过索引筛选出的数据越少。有1000W条数据的表，有如下sql:select from table where col1=1 and col2=2 and col3=3,假设假设每个条件可以筛选出10%的数据，如果只有单值索引，那么通过该索引能筛选出1000W10%=100w条数据，然后再回表从100w条数据中找到符合col2=2 and col3= 3的数据，然后再排序，再分页；如果是联合索引，通过索引筛选出1000w10% 10% *10%=1w，效率提升可想而知！
从本质上来说，联合索引还是一颗B+树，不同的是联合索引的键值的数量不是1，而是大于等于2。
对于查询 SELECT * FROM TABLE WHERE a=xxx and b=xxx，显然可以使用(a,b)这个联合索引。对于单个的a列查询 SELECT * FROM TABLE WHERE a=xxx 也是可以使用(a,b)索引。但对于b列的查询 SELECT * FROM TABLE WHERE b=xxx 不可以使用这颗B+树索引。因为叶节点上的b值为1,2,1,4,1,2，显然不是排序的，因此对于b列的查询使用不到(a,b)的索引。
联合索引的第二个好处是，可以对第二个键值进行排序。例如，在很多情况下我们都需要查询某个用户的购物情况，并按照时间排序，去除最近3次的购买记录，这是使用联合索引可以避免多一次的排序操作，因为索引本身在叶节点已经排序了。
【注】：对于相同的第一个键值的数据，第二个键值是排好序的。
对于单个列a的查询往往使用单个键的索引，因为其叶节点包含单个键值，能存放的记录更多。

24、说一说 B+树索引、哈希索引？
Hash索引和B+树索引的特点：
Hash索引结构的特殊性，其检索效率非常高，索引的检索可以一次定位;
B+树索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问。

25、Hash索引与B+树索引区别？
如果是等值查询，那么哈希索引明显有绝对优势，因为只需要经过一次算法即可找到相应的键值；当然了，这个前提是，键值都是唯一的。如果键值不是唯一的，就需要先找到该键所在位置，然后再根据链表往后扫描，直到找到相应的数据；
从示意图中也能看到，如果是范围查询检索，这时候哈希索引就毫无用武之地了，因为原先是有序的键值，经过哈希算法后，有可能变成不连续的了，就没办法再利用索引完成范围查询检索；
同理，哈希索引也没办法利用索引完成排序，以及like ‘xxx%’ 这样的部分模糊查询（这种部分模糊查询，其实本质上也是范围查询）；
哈希索引也不支持多列联合索引的最左匹配规则；
B+树索引的关键字检索效率比较平均，不像B树那样波动幅度大，在有大量重复键值情况下，哈希索引的效率也是极低的，因为存在所谓的哈希碰撞问题。

26、B树和B+树的区别？
B+树是一种平衡查找树。在B+树中，所有记录节点都是按键值的大小顺序存放在同一层的叶节点中，各叶结点指针进行连接。
（平衡二叉树AVL：首先符合二叉查找树的定义（最结点的值比根节点小，右结点的值比根结点大），其次必须满足任何节点的左右两个子树的高度最大差为1。）
B树  ：每个节点都存储key和data，所有节点组成这棵树，并且叶子节点指针为nul，叶子结点不包含任何关键字信息。
B+树：所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大的顺序链接，所有的非终端结点可以看成是索引部分。

27、为什么说B+比B树更适合实际应用中操作系统的文件索引和数据库索引？
（1）B+的磁盘读写代价更低
B+的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对B树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。
（2）B+tree的查询效率更加稳定
由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。

28、聚集索引和非聚集索引区别?
数据库中的B+索引可以分为聚集索引和辅助聚集索引。不管是聚集索引还是非聚集的索引，其内部都是B+树的，即高度平衡的，叶节点存放着所有的数据，聚集索引与非聚集索引不同的是，叶节点存放的是否是一整行的信息。
1）聚集索引(clustered index)：
聚集索引就是按照每张表的主键构造一颗B+树，并且叶节点中存放着整张表的行记录数据，因此也让聚集索引的叶节点成为数据页。聚集索引的这个特性决定了索引组织表中数据也是索引的一部分。由于实际的数据页只能按照一颗B+树进行排序，因此每张表只能拥有一个聚集索引。
聚集索引表记录的排列顺序和索引的排列顺序一致，所以查询效率快，只要找到第一个索引值记录，其余就连续性的记录在物理也一样连续存放。聚集索引对应的缺点就是修改慢，因为为了保证表中记录的物理和索引顺序一致，在记录插入的时候，会对数据页重新排序。
2）非聚集索引(nonclustered index)（也叫辅助索引）：
对于辅助索引(非聚集索引)，叶级别不包含行的全部数据。聚集索引键来告诉InnoDB存储引擎，哪里可以找到与索引相对应的行数据。辅助索引的存在并不影响数据在聚集索引中的组织，因此每张表上可以有多个辅助索引。通过辅助索引来寻找数据时，InnoDB存储引擎会遍历辅助索引并通过叶级别的指针获得指向主键索引的主键，然后再通过主键索引来找到一个完整的行记录。
非聚集索引指定了表中记录的逻辑顺序，但是记录的物理和索引不一定一致，两种索引都采用B+树结构，非聚集索引的叶子层并不和实际数据页相重叠，而采用叶子层包含一个指向表中的记录在数据页中的指针方式。非聚集索引层次多，不会造成数据重排。
3）根本区别：
聚集索引和非聚集索引的根本区别是表记录的排列顺序和与索引的排列顺序是否一致。

29、说一说drop、delete与truncate的区别？
drop直接删掉表。
truncate删除表中数据，再插入时自增长id又从1开始。
delete删除表中数据，可以加where字句。
（1）truncate和delete只删除数据，而drop则删除整个表（结构和数据）。
（2）delete语句执行删除的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中保存以便进行进行回滚操作。truncate table则一次性地从表中删除所有的数据并不把单独的删除操作记录记入日志保存，删除行是不能恢复的。并且在删除的过程中不会激活与表有关的删除触发器。执行速度快。
（3）执行速度：drop> truncate >delete
（4）delete语句是dml，这个操作会放到rollback segement中，事务提交之后才生效。如果有相应的trigger（触发器），执行的时候将被触发；
truncate、drop是ddl，操作立即生效，原数据不放到rollback segment中，不能回滚，操作不触发trigger。
（5）当表被truncate后，这个表和索引所占用的空间会恢复到初始大小， delete操作不会减少表或索引所占用的空间。
（6）应用范围：truncate只能对table；delete可以是table和view
如果直接删除一个表drop，对数据量很大的表，这个过程会占用比较长的时间，如果先truncat后drop table：1、可以降低操作失败的风险；2、可以降低数据字典锁占用的时间，降低系统开销。

30、drop、delete与truncate分别在什么场景之下使用？
不再需要一张表的时候，用drop
想删除部分数据行时候，用delete，并且带上where子句
保留表而删除所有数据的时候用truncate

31、超键、候选键、主键、外键分别是什么？
超键   ：在关系中能唯一标识元组的属性集称为关系模式的超键。一个属性可以为作为一个超键，多个属性组合在一起也可以作为一个超键。超键包含候选键和主键。
候选键：是最小超键，即没有冗余元素的超键。
主键    ：数据库表中对存储数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值（Null）。
外键    ：在一个表中存在的另一个表的主键称此表的外键。

32、mysql为什么建议用自增列作为主键？
如果我们定义了主键(PRIMARY KEY)，那么InnoDB会选择主键作为聚集索引、如果没有显式定义主键，则InnoDB会选择第一个不包含有NULL值的唯一索引作为主键索引、如果也没有这样的唯一索引，则InnoDB会选择内置6字节长的ROWID作为隐含的聚集索引(ROWID随着行记录的写入而主键递增，这个ROWID不像ORACLE的ROWID那样可引用，是隐含的)。
使用自增列(INT/BIGINT类型)做主键，这时候写入顺序是自增的，和B+数叶子节点分裂顺序一致；
该表不指定自增列做主键，同时也没有可以被选为主键的唯一索引(上面的条件)，这时候InnoDB会选择内置的ROWID作为主键，写入顺序和ROWID增长顺序一致；
除此以外，如果一个InnoDB表又没有显示主键，又有可以被选择为主键的唯一索引，但该唯一索引可能不是递增关系时(例如字符串、UUID、多字段联合唯一索引的情况)，该表的存取效率就会比较差。

33、MySQL中的varchar和char的区别以及varchar(50）中的50代表的涵义？
char是一种固定长度的类型，varchar是一种可变长度的类型。
varchar(50)中50的含义：
最多存放50个字符，varchar(50)和(200)存储hello所占空间一样，但后者在排序时会消耗更多内存，因为order by col采用fixed_length计算col长度。ppp-
int(20)中20的含义：
是指显示字符的长度
但要加参数的，最大为255，比如它是记录行数的id,插入10笔资料，它就显示00000000001 ~~~00000000010，当字符的位数超过11,它也只显示11位，如果你没有加那个让它未满11位就前面加0的参数，它不会在前面加0.
20表示最大显示宽度为20，但仍占4字节存储，存储范围不变；
mysql为什么这么设计：
对大多数应用没有意义，只是规定一些工具用来显示字符的个数；int(1)和int(20)存储和计算均一样。

34、什么是视图？视图的使用场景有哪些？
视图（View）是一个命名的虚表，它由一个查询来定义，可以当作表使用。
视图有什么用（应用场景）：
1、当一个查询你需要频频的作为子查询使用时，视图可以简化代码，直接调用而不是每次都去重复写这个东西。
2、系统的数据库管理员，需要给他人提供一张表的某两列数据，而不希望他可以看到其他任何数据，这时可以建一个只有这两列数据的视图，然后把视图公布给他。
创建视图sql语句：
CREATE VIEW view_name AS
SELECT column_name(s)
FROM table_name
WHERE condition

35、视图与表的区别？
1、视图是已经编译好的sql语句，而表不是。
2、视图没有实际的物理记录，而表有。
3、表是内容，视图是窗口。
4、表只用物理空间而视图不占用物理空间，视图只是逻辑概念的存在，表可以及时对它进行修改，但视图只能由创建的语句来修改。
5、视图是查看数据表的一种方法，可以查询数据表中某些字段构成的数据，只是一些SQL语句的集合。从安全的角度说，视图可以不给用户接触数据表，从而不知道表结构。
6、表属于全局模式中的表，是实表；视图属于局部模式的表，是虚表。 
7、视图的建立和删除只影响视图本身，不影响对应的基本表。
8、不能对视图进行update或者insert into操作。

36、数据库三大范式？
第一范式（1NF）
（在任何一个关系数据库中，第一范式（1NF）是对关系模式的基本要求，不满足第一范式（1NF）的数据库就不是关系数据库。）
所谓第一范式（1NF）是指数据库表的每一列都是不可分割的基本数据项，第一范式就是无重复的列。强调的是列的原子性，即列不能够再分成其他几列。
第二范式（2NF）
满足第二范式（2NF）必须先满足第一范式（1NF）。另外包含两部分内容，一是表必须有主键；二是没有包含在主键中的列必须完全依赖于主键，而不能只依赖于主键的一部分。
第三范式（3NF）
满足第三范式（3NF）必须先满足第二范式（2NF）第三范式就是属性不依赖于其它非主属性。非主键列必须直接依赖于主键，不能存在传递依赖。

37、sql优化
1. explain sql 分析sql语句，这个语句可以打印出的各种item的意义：
select_type ：表示查询中每个select子句的类型
type ：表示MySQL在表中找到所需行的方式，又称“访问类型”
possible_keys ：指出MySQL能使用哪个索引在表中找到行，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用。
key ：显示MySQL在查询中实际使用的索引，若没有使用索引，显示为NULL。
key_len ：表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度
ref ：表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值 
Extra ：包含不适合在其他列中显示但十分重要的额外信息
2. 查询语句不同元素（where、jion、limit、group by、having等等）执行先后顺序?
查询中用到的关键词主要包含6个，并且他们的顺序依次为 select--from--where--group by--having--order by--limit。
其中select和from是必须的，其他关键词是可选的。
（使用having字句对分组后的结果进行筛选，所以having只能用在group by之后；
limit 起始记录位置：取记录的条数对记录进行选取，主要用来实现分页功能）

38、非关系型数据库和关系型数据库区别，优势比较?
非关系型数据库的优势：
性能：NOSQL是基于键值对的，可以想象成表中的主键和值的对应关系，而且不需要经过SQL层的解析，所以性能非常高。
可扩展性：同样也是因为基于键值对，数据之间没有耦合性，所以非常容易水平扩展。
关系型数据库的优势：
复杂查询：可以用SQL语句方便的在一个表以及多个表之间做非常复杂的数据查询。
事务支持：使得对于安全性能很高的数据访问要求得以实现。
其他：
1）.对于这两类数据库，对方的优势就是自己的弱势，反之亦然。
2）.NOSQL数据库慢慢开始具备SQL数据库的一些复杂查询功能，比如MongoDB。
3）.对于事务的支持也可以用一些系统级的原子操作来实现例如乐观锁之类的方法来曲线救国，比如Redis set nx。

39、什么是 内连接、外连接、交叉连接、笛卡尔积等?
内连接: 只连接匹配的行
左外连接: 包含左边表的全部行（不管右边的表中是否存在与它们匹配的行），以及右边表中全部匹配的行
右外连接: 包含右边表的全部行（不管左边的表中是否存在与它们匹配的行），以及左边表中全部匹配的行
例如1：
SELECT a.,b. FROM luntan LEFT JOIN usertable as b ON a.username=b.username
例如2：
SELECT a.,b. FROM city as a FULL OUTER JOIN user as b ON a.username=b.username
全外连接: 包含左、右两个表的全部行，不管另外一边的表中是否存在与它们匹配的行。
交叉连接: 生成笛卡尔积－它不使用任何匹配或者选取条件，而是直接将一个数据源中的每个行与另一个数据源的每个行都一一匹配
例如：
SELECT type,pub_name FROM titles CROSS JOIN publishers ORDER BY type
1）.以A，B两张表为例
A left join B
选出A的所有记录，B表中没有的以null 代替
right join 同理
2）.inner join
A,B的所有记录都选出，没有的记录以null代替
3）.cross join (笛卡尔积)
A中的每一条记录和B中的每一条记录生成一条记录
例如A中有4条，B中有4条，cross join 就有16条记录

40、SQL语言分类
数据查询语言DQL ：基本结构是由SELECT子句、FROM子句、WHERE子句组成的查询块。
数据操纵语言DML ：1）插入INSERT 2) 更新：UPDATE 3) 删除：DELETE
数据定义语言DDL ：用来创建数据库中的各种对象-----表、视图、索引、同义词、聚簇等如：CREATE TABLE/VIEW/INDEX/SYN/CLUSTER
DDL操作是隐性提交的！不能rollback
数据控制语言DCL ：用来授予或回收访问数据库的某种特权，并控制数据库操纵事务发生的时间及效果，对数据库实行监视等。ROLLBACK/COMMIT
(1) 显式提交
用COMMIT命令直接完成的提交为显式提交。其格式为：SQL>COMMIT；
(2) 隐式提交
用SQL命令间接完成的提交为隐式提交。这些命令是：ALTER，AUDIT，COMMENT，CONNECT，CREATE，DISCONNECT，DROP，EXIT，GRANT，NOAUDIT，QUIT，REVOKE，RENAME。
(3) 自动提交
若把AUTOCOMMIT设置为ON，则在插入、修改、删除语句执行后，系统将自动进行提交。其格式为：SQL>SET AUTOCOMMIT ON；

41、like %和-的区别
% 通配符：表示任何字符出现任意次数 (可以是0次)。
_ 通配符：表示只能匹配单个字符，不能多也不能少，就是一个字符。
使用通配符进行模糊查询需要用 like操作符，例：
SELECT * FROM products WHERE products.prod_name like '%es%';
SELECT * FROM products WHERE products.prod_name like '_es';
【注】如果在使用like操作符时，后面的没有使用通用匹配符效果是和 = 是一致的。
SELECT * FROM products WHERE products.prod_name like '1000'：只能匹配的结果为1000，而不能匹配像JetPack 1000这样的结果。

42、count(*)、count(1)、count(column)的区别
count(*)  ：对行的数目进行计数，包含NULL
count(column) ：对特定的列的值具有的行进行计数，不包含NULL值。
count(1)这个用法和count(*)的结果是一样的，包含null。
性能问题:
任何情况下SELECT COUNT(*) FROM tablename是最优选择;
尽量减少SELECT COUNT(*) FROM tablename WHERE COL = ‘value’ 这种查询;
杜绝SELECT COUNT(COL) FROM tablename WHERE COL2 = ‘value’ 的出现。
如果表没有主键，那么count(1)比count(*)快。
如果有主键，那么count(主键,联合主键)比count(*)快。
如果表只有一个字段，count(*)最快。
count(1)跟count(主键)一样，只扫描主键；count(*)跟count(非主键)一样，扫描整个表。明显前者更快一些。

43、你们数据库是否支持emoji表情，如果不支持，如何操作？
如果是utf8字符集的话，需要升级至utf8_mb4方可支持。

44、你是如何监控你们的数据库的？你们的慢日志都是怎么查询的？
监控的工具有很多，例如zabbix，lepus，我这里用的是lepus。
slow_query_log        ：慢查询开启状态。
slow_query_log_file ：慢查询日志存放的位置（这个目录需要MySQL的运行帐号的可写权限，一般设置为MySQL的数据存放目录）。
long_query_time      ：查询超过多少秒才记录。
开启慢日志查询：set global slow_query_log='ON';
那么开启了慢查询日志后，什么样的SQL才会记录到慢查询日志里面呢？ 
这个是由参数long_query_time控制，默认情况下long_query_time的值为10秒，可以使用命令修改，也可以在my.cnf参数里面修改。运行时间大于long_query_time（非大于等于），才会记录到慢查询日志里。

45、谈谈mongodb,mysql的区别和具体应用场景
（1）MongoDB是神马？
MongoDB是非关系型数据库，是一个基于分布式文件存储的数据库。（文档型数据库：可以存放xml、json、bson类型的数据。）同时MongoDB是由C++语言编写。旨在为WEB应用提供可扩展的高性能数据存储解决方案。 是非关系数据库当中功能最丰富，最像关系数据库的。
MongoDB 将数据存储为一个文档，数据结构由键值(key=>value)对组成。MongoDB 文档类似于 JSON 对象。字段值可以包含其他文档，数组及文档数组。
它可以存储比较复杂的数据类型。Mongo最大的特点是它支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。
mongodb与mysql不同，mysql的每一次更新操作都会直接写入硬盘，但是mongo不会，作为内存型数据库，数据操作会先写入内存，然后再会持久化到硬盘中去 ，但MongoDB采用的预分配空间的方式来防止文件碎片，所以MongoDB的数据文件很大。
（2）MongoDB的特点是：
1）面向文档；2）高性能；3）高可用；4）易扩展；5）丰富的查询语言
（3）MongoDB 缺点：
① MongoDB 不支持事务操作(最主要的缺点)
② MongoDB 占用空间过大
③ MongoDB 没有如 MySQL 那样成熟的维护工具，这对于开发和IT运营都是个值得注意的地方
存储方式：虚拟内存+持久化。
持久化方式：MongoDB 的所有数据实际上是存放在硬盘的，所有要操作的数据通过 mmap 的方式映射到内存某个区域内。然后，MongoDB 就在这块区域里面进行数据修改，避免了零碎的硬盘操作。
（4）mongodb,mysql的区别？
1）MongoDB 非关系型数据库，MySql是关系型数据库
2）MongoDB存储方式：虚拟内存+持久化； MySql在不同的引擎上有不同 的存储方式。
3）MongoDB查询语句：是独特的Mongodb的查询方式； MySqlMySql查询语句是使用传统的sql语句，拥有较为成熟的体系，成熟度很高。
4）mysql的每一次更新操作都会直接写入硬盘，但是mongo的数据操作会先写入内存，然后再会持久化到硬盘中去 。（MongoDB数据是存储在硬盘上的，只不过需要经常读取的数据会被加载到内存中，将数据存储在物理内存中，从而达到高速读写。）
5）mysql缺点就是在海量数据处理的时候效率会显著变慢。在适量级的内存的Mongodb的性能是非常迅速的。
6）MongoDB 不支持事务操作，mysql的innodb和bdb存储引擎支持事务。（注：myisam不支持事务）

46.一条sql语句的执行过程？
（1）先简单介绍一下一些组件的基本作用：
连接器： 身份认证和权限相关(登录 MySQL 的时候)。
查询缓存: 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。
分析器: 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。
优化器： 按照 MySQL 认为最优的方案去执行。
执行器: 执行语句，然后从存储引擎返回数据。
（2）一条查询语句的执行顺序：
１）.客户端通过TCP连接发送连接请求到mysql连接器，连接器会对该请求进行权限验证及连接资源分配。
２）.建立连接后客户端发送一条语句，mysql收到该语句后，通过命令分发器判断其是否是一条select语句，如果是，在开启查询缓存的情况下，先在查询缓存中查找该SQL是否完全匹配，如果完全匹配，验证当前用户是否具备查询权限，如果权限验证通过，直接返回结果集给客户端，该查询也就完成了。如果不匹配继续向下执行。
3）.如果在查询缓存中未匹配成功，则将语句交给分析器作语法分析，MySQL需要知道到底要查哪些东西，如果语法不对，就会返回语法错误中断查询。
4）.分析器的工作完成后，将语句传递给预处理器，检查数据表和数据列是否存在，解析别名看是否存在歧义等
5）.语句解析完成后，MySQL就知道要查什么了，之后会将语句传递给优化器进行优化（通过索引选择最快的查找方式），并生成执行计划。
6）.之后交给执行器去具体执行该语句，在执行之前，会先检查该用户是否具有查询权限，如果有，继续执行该语句。执行器开始执行后，会逐渐将数据保存到结果集中，同时会逐步将数据缓存到查询缓存中，最终将结果集返回给客户端。（如果该SQL执行过程中超过了慢查询阀值，该SQL会被记录到慢查询日志中） 
---------------------------------------------------------------------------------------------------------------
------------------------------------------mysql basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------netty&nio basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 同步&异步&阻塞&非阻塞
同步 ： 自己亲自出马持银行卡到银行取钱（使用同步IO时，Java自己处理IO读写）；
异步 ： 委托一小弟拿银行卡到银行取钱，然后给你（使用异步IO时，Java将IO读写委托给OS处理，需要将数据缓冲区地址和大小传给OS(银行卡和密码)，OS需要支持异步IO操作API）；
阻塞 ： ATM排队取款，你只能等待（使用阻塞IO时，Java调用会一直阻塞到读写完成才返回）；
非阻塞 ： 柜台取款，取个号，然后坐在椅子上做其它事，等号广播会通知你办理，没到号你就不能去，你可以不断问大堂经理排到了没有，大堂经理如果说还没到你就不能去
（使用非阻塞IO时，如果不能读写Java调用会马上返回，当IO事件分发器会通知可读写时再继续进行读写，不断循环直到读写完成）

2 IO的方式通常分为几种，同步阻塞的BIO、同步非阻塞的NIO、异步非阻塞的AIO。

3 BIO
在JDK1.4出来之前，我们建立网络连接的时候采用BIO模式，需要先在服务端启动一个ServerSocket，然后在客户端启动Socket来对服务端进行通信，默认情况下服务端需要对每个请求建立一堆线程等待请求，而客户端发送请求后，先咨询服务端是否有线程相应，如果没有则会一直等待或者遭到拒绝请求，如果有的话，客户端会线程会等待请求结束后才继续执行。

4 NIO
NIO本身是基于事件驱动思想来完成的，其主要想解决的是BIO的大并发问题：在使用同步I/O的网络应用中，如果要同时处理多个客户端请求，或是在客户端要同时和多个服务器进行通讯，就必须使用多线程来处理。也就是说，将每一个客户端请求分配给一个线程来单独处理。这样做虽然可以达到我们的要求，但同时又会带来另外一个问题。由于每创建一个线程，就要为这个线程分配一定的内存空间（也叫工作存储器），而且操作系统本身也对线程的总数有一定的限制。如果客户端的请求过多，服务端程序可能会因为不堪重负而拒绝客户端的请求，甚至服务器可能会因此而瘫痪。
NIO的最重要的地方是当一个连接创建后，不需要对应一个线程，这个连接会被注册到多路复用器上面，所以所有的连接只需要一个线程就可以搞定，当这个线程中的多路复用器进行轮询的时候，发现连接上有请求的话，才开启一个线程进行处理，也就是一个请求一个线程模式。
在NIO的处理方式中，当一个请求来的话，开启线程进行处理，可能会等待后端应用的资源(JDBC连接等)，其实这个线程就被阻塞了，当并发上来的话，还是会有BIO一样的问题。

5 AIO
与NIO不同，当进行读写操作时，只须直接调用API的read或write方法即可。这两种方法均为异步的，对于读操作而言，当有流可读取时，操作系统会将可读的流传入read方法的缓冲区，并通知应用程序；对于写操作而言，当操作系统将write方法传递的流写入完毕时，操作系统主动通知应用程序。 即可以理解为，read/write方法都是异步的，完成后会主动调用回调函数。  在JDK1.7中，这部分内容被称作NIO.2，主要在java.nio.channels包下增加了下面四个异步通道：
    AsynchronousSocketChannel
    AsynchronousServerSocketChannel
    AsynchronousFileChannel
    AsynchronousDatagramChannel
其中的read/write方法，会返回一个带回调函数的对象，当执行完读取/写入操作后，直接调用回调函数。

6 Java对BIO、NIO、AIO的支持
Java BIO ： 同步并阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。
Java NIO ： 同步非阻塞，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。
Java AIO(NIO.2) ： 异步非阻塞，服务器实现模式为一个有效请求一个线程，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理，

7 BIO、NIO、AIO适用场景分析
BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择，但程序直观简单易理解。
NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4开始支持。服务器需要支持超大量的长时间连接。比如10000个连接以上，并且每个客户端并不会频繁地发送太多数据。例如总公司的一个中心服务器需要收集全国便利店各个收银机的交易信息，只需要少量线程按需处理维护的大量长期连接。Jetty、Mina、Netty、ZooKeeper等都是基于NIO方式实现。
AIO方式使用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持。

8 NIO三种模型
（1）Reactor单线程模型：
单个线程完成所有事情包括接收客户端的TCP连接请求，读取和写入套接字数据等。对于一些小容量应用场景，可以使用单线程模型。但是对于高负载、大并发的应用却不合适，主要原因如下：
1) 一个NIO线程同时处理成百上千的链路，性能上无法支撑，即便NIO线程的CPU负荷达到100%，也无法满足海量消息的编码、解码、读取和发送；
2) 当NIO线程负载过重之后，处理速度将变慢，这会导致大量客户端连接超时，超时之后往往会进行重发，这更加重了NIO线程的负载，最终会导致大量消息积压和处理超时，NIO线程会成为系统的性能瓶颈；
3) 可靠性问题：一旦NIO线程意外跑飞，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。
为了解决这些问题，演进出了Reactor多线程模型。
（2）Reactor多线程模型：
Rector多线程模型与单线程模型最大的区别就是有一组NIO线程处理真实的IO操作。
1) 有专门一个NIO线程-Acceptor线程用于监听服务端，接收客户端的TCP连接请求；
2) 网络IO操作-读、写等由一个NIO线程池负责，线程池可以采用标准的JDK线程池实现，它包含一个任务队列和N个可用的线程，由这些NIO线程负责消息的读取、解码、编码和发送；
3) 1个NIO线程可以同时处理N条链路，但是1个链路只对应1个NIO线程，防止发生并发操作问题。
在绝大多数场景下，Reactor多线程模型都可以满足性能需求；但是，在极特殊应用场景中，一个NIO线程负责监听和处理所有的客户端连接可能会存在性能问题。例如百万客户端并发连接，或者服务端需要对客户端的握手消息进行安全认证，认证本身非常损耗性能。在这类场景下，单独一个Acceptor线程可能会存在性能不足问题，为了解决性能问题，产生了第三种Reactor线程模型-主从Reactor多线程模型。即从单线程中由一个线程即监听连接事件、读写事件、由完成数据读写，拆分为由一个线程专门监听各种事件，再由专门的线程池负责处理真正的IO数据读写。
（3）主从Reactor多线程模型
主从Reactor线程模型与Reactor多线程模型的最大区别就是有一组NIO线程处理连接、读写事件。主从Reactor线程模型的特点是：服务端用于接收客户端连接的不再是个1个单独的NIO线程，而是一个独立的NIO线程池。Acceptor接收到客户端TCP连接请求处理完成后（可能包含接入认证等），将新创建的SocketChannel注册到IO线程池（sub reactor线程池）的某个IO线程上，由它负责SocketChannel的读写和编解码工作。Acceptor线程池仅仅只用于客户端的登陆、握手和安全认证，一旦链路建立成功，就将链路注册到后端subReactor线程池的IO线程上，由IO线程负责后续的IO操作。
即从多线程模型中由一个线程来监听连接事件和数据读写事件，拆分为一个线程监听连接事件，线程池的多个线程监听已经建立连接的套接字的数据读写事件，另外和多线程模型一样有专门的线程池处理真正的IO操作。

9 原生NIO开发大致流程
本文大致讲述了使用NIO进行服务器端开发的大致流程，但代码显然仍然存在问题，其一是我们只使用了一个线程执行所有操作，包括接收客户端连接，读取数据，返回数据，对于这个简单的Demo来说已经足够了，但在实际的服务器开发中，例如你想使用NIO开发自己的HTTP服务器，服务器本地需要做大量操作，包括解析用户请求，根据请求路由到某一个Action执行业务逻辑，这其中又很可能某些数据从数据库读取，渲染模板等操作，十分耗时，这无疑又称为系统的瓶颈，再者，使用单一线程不能充分利用多核CPU提供的计算能力。下一篇中会看到，在基于Reactor模型的Netty中，会使用一个Boss线程接收客户端请求，使用多个Worker线程执行具体的业务逻辑。

10 Channel
国内大多翻译成“通道”。Channel和IO中的Stream(流)是差不多一个等级的。只不过Stream是单向的，譬如：InputStream, OutputStream.而Channel是双向的，既可以用来进行读操作，又可以用来进行写操作。
NIO中的Channel的主要实现有：
    FileChannel
    DatagramChannel
    SocketChannel
    ServerSocketChannel
这里看名字就可以猜出个所以然来：分别可以对应文件IO、UDP和TCP（Server和Client）。下面演示的案例基本上就是围绕这4个类型的Channel进行陈述的。

11 Buffer
NIO中的关键Buffer实现有：ByteBuffer, CharBuffer, DoubleBuffer, FloatBuffer, IntBuffer, LongBuffer, ShortBuffer，
分别对应基本数据类型: byte, char, double, float, int, long, short。
当然NIO中还有MappedByteBuffer, HeapByteBuffer, DirectByteBuffer等这里先不进行陈述。
Buffer的使用一般遵循下面几个步骤：
@分配空间（ByteBuffer buf = ByteBuffer.allocate(1024); 还有一种allocateDirector后面再陈述）
@写入数据到Buffer(int bytesRead = fileChannel.read(buf);)
@调用filp()方法（ buf.flip();）
@从Buffer中读取数据（System.out.print((char)buf.get());）
@调用clear()方法或者compact()方法

12 Selector 
Selector运行单线程处理多个Channel，如果你的应用打开了多个通道，但每个连接的流量都很低，使用Selector就会很方便。例如在一个聊天服务器中。要使用Selector, 得向Selector注册Channel，然后调用它的select()方法。这个方法会一直阻塞到某个注册的通道有事件就绪。一旦这个方法返回，线程就可以处理这些事件，事件的例子有如新的连接进来、数据接收等。

13 Netty 
一个基于 JAVA NIO 类库的异步通信框架，它的架构特点是：异步非阻塞、基于事件驱动、高性能、高可靠性和高可定制性。换句话说，Netty是一个NIO框架，使用它可以简单快速地开发网络应用程序，比如客户端和服务端的协议。Netty大大简化了网络程序的开发过程比如TCP和UDP的 Socket的开发。Netty 已逐渐成为 Java NIO 编程的首选框架
Netty是最流行的NIO框架，它的健壮性、功能、性能、可定制性和可扩展性在同类框架都是首屈一指的。它已经得到成百上千的商业/商用项目验证，如Hadoop的RPC框架Avro、RocketMQ以及主流的分布式通信框架Dubbox等等。

14 Netty 的优点
API 使用简单，开发门槛低；
功能强大，预置了多种编解码功能，支持多种主流协议；
定制能力强，可以通过 ChannelHandler 对通信框架进行灵活的扩展；
性能高，通过与其它业界主流的 NIO 框架对比，Netty 的综合性能最优；
社区活跃，版本迭代周期短，发现的 BUG 可以被及时修复，同时更多的新功能会被加入；
经历了大规模的商业应用考验，质量得到验证。在互联网、大数据、网络游戏、企业应用、电信软件等众多行业得到成功商用，证明了它完全满足不同行业的商用标准。

15 NIO的通信步骤
①创建ServerSocketChannel，为其配置非阻塞模式。
②绑定监听，配置TCP参数，录入backlog大小等。
③创建一个独立的IO线程，用于轮询多路复用器Selector。
④创建Selector，将之前创建的ServerSocketChannel注册到Selector上，并设置监听标识位SelectionKey.OP_ACCEPT。
⑤启动IO线程，在循环体中执行Selector.select()方法，轮询就绪的通道。
⑥当轮询到处于就绪状态的通道时，需要进行操作位判断，如果是ACCEPT状态，说明是新的客户端接入，则调用accept方法接收新的客户端。
⑦设置新接入客户端的一些参数，如非阻塞，并将其继续注册到Selector上，设置监听标识位等。
⑧如果轮询的通道标识位是READ，则进行读取，构造Buffer对象等。
⑨更细节的问题还有数据没发送完成继续发送的问题......

16 Netty通信的步骤
①创建两个NIO线程组，一个专门用于网络事件处理（接受客户端的连接），另一个则进行网络通信的读写。
②创建一个ServerBootstrap对象，配置Netty的一系列参数，例如接受传出数据的缓存大小等。
③创建一个用于实际处理数据的类ChannelInitializer，进行初始化的准备工作，比如设置接受传出数据的字符集、格式以及实际处理数据的接口。
④绑定端口，执行同步阻塞方法等待服务器端启动即可。


17 TCP粘包、拆包问题
熟悉TCP编程的可能都知道，无论是服务器端还是客户端，当我们读取或者发送数据的时候，都需要考虑TCP底层的粘包/拆包机制。TCP是一个“流”协议，所谓流就是没有界限的遗传数据。大家可以想象一下，如果河水就好比数据，他们是连成一片的，没有分界线，TCP底层并不了解上层业务数据的具体含义，它会根据TCP缓冲区的具体情况进行包的划分，也就是说，在业务上一个完整的包可能会被TCP分成多个包进行发送，也可能把多个小包封装成一个大的数据包发送出去，这就是所谓的粘包/拆包问题。
解决方案：
①消息定长，例如每个报文的大小固定为200个字节，如果不够，空位补空格。
②在包尾部增加特殊字符进行分割，例如加回车等。
③将消息分为消息头和消息体，在消息头中包含表示消息总长度的字段，然后进行业务逻辑的处理。
Netty中解决TCP粘包/拆包的方法：
①分隔符类：DelimiterBasedFrameDecoder（自定义分隔符）
②定长：FixedLengthFrameDecoder


18 心跳检测
我们使用Socket通信一般经常会处理多个服务器之间的心跳检测，一般来讲我们去维护服务器集群，肯定要有一台或多台服务器主机（Master），然后还应该有N台（Slave），那么我们的主机肯定要时时刻刻知道自己下面的从服务器的各方面情况，然后进行实时监控的功能。这个在分布式架构里交做心跳检测或者心跳监控。最佳处理方案是使用一些通信框架进行实现，Netty就可以做这样的事。

19 Netty高阶
作为一个学Java的，如果没有研究过Netty，那么你对Java语言的使用和理解仅仅停留在表面水平，会点SSH，写几个MVC，访问数据库和缓存，这些只是初等Java程序员干的事。如果你要进阶，想了解Java服务器的深层高阶知识，Netty绝对是一个必须要过的门槛。有了Netty，你可以实现自己的HTTP服务器，FTP服务器，UDP服务器，RPC服务器，WebSocket服务器，Redis的Proxy服务器，MySQL的Proxy服务器等等。如果你想
知道Nginx是怎么写出来的，如果你想知道Tomcat和Jetty是如何实现的，如果你也想实现一个简单的Redis服务器，那都应该好好理解一下Netty，它们高性能的原理都是类似的。

我们回顾一下传统的HTTP服务器的原理创建一个ServerSocket，监听并绑定一个端口一系列客户端来请求这个端口服务器使用Accept，获得一个来自客户端的Socket连接对象启动一个新线程处理连接读Socket，得到字节流解码协议，得到Http请求对象处理Http请求，得到一个结果，封装成一个HttpResponse对象编码协议，将结果序列化字节流写Socket，将字节流发给客户端继续循环步骤3HTTP服务器之所以称为HTTP服务器，是因为编码解码协议是HTTP协议，如果协议是Redis协议，那它就成了Redis服务器，如果协议是WebSocket，那它就成了WebSocket服务器，等等。使用Netty你就可以定制编解码协议，实现自己的特定协议的服务器。上面我们说的是一个传统的多线程服务器，这个也是Apache处理请求的模式。在高并发环境下，线程数量可能会创建太多，操作系统的任务调度压力大，系统负载也会比较高。那怎么办呢？

于是NIO诞生了，NIO并不是Java独有的概念，NIO代表的一个词汇叫着IO多路复用。它是由操作系统提供的系统调用，早期这个操作系统调用的名字是select，但是性能低下，后来渐渐演化成了Linux下的epoll和Mac里的kqueue。我们一般就说是epoll，因为没有人拿苹果电脑作为服务器使用对外提供服务。而Netty就是基于Java NIO技术封装的一套框架。为什么要封装，因为原生的JavaNIO使用起来没那么方便，而且还有臭名昭著的bug，Netty把它封装之后，提供了一个易于操作的使用模式和接口，用户使用起来也就便捷多了。那NIO究竟是什么东西呢？

NIO的全称是NoneBlocking IO，非阻塞IO，区别与BIO，BIO的全称是BlockingIO，阻塞IO。那这个阻塞是什么意思呢？Accept是阻塞的，只有新连接来了，Accept才会返回，主线程才能继Read是阻塞的，只有请求消息来了，Read才能返回，子线程才能继续处理Write是阻塞的，只有客户端把消息收了，Write才能返回，子线程才能继续读取下一个请求所以传统的多线程服务器是BlockingIO模式的，从头到尾所有的线程都是阻塞的。这些线程就干等在哪里，占用了操作系统的调度资源，什么事也不干，是浪费。那么NIO是怎么做到非阻塞的呢。它用的是事件机制。它可以用一个线程把Accept，读写操作，请求处理的逻辑全干了。如果什么事都没得做，它也不会死循环，它会将线程休眠起来，直到下一个事件来了再继续干活，这样的一个线程称之为NIO线程。
while true {
    events = takeEvents(fds)  // 获取事件，如果没有事件，线程就休眠
    for event in events {
        if event.isAcceptable {
            doAccept() // 新链接来了
        } elif event.isReadable {
            request = doRead() // 读消息
            if request.isComplete() {
                doProcess()
            }
        } elif event.isWriteable {
            doWrite()  // 写消息
        }
    }
}

NIO的流程大致就是上面的伪代码描述的过程，跟实际真实的代码有较多差异，不过对于初学者，这样理解也是足够了。Netty是建立在NIO基础之上，Netty在NIO之上又提供了更高层次的抽象。在Netty里面，Accept连接可以使用单独的线程池去处理，读写操作又是另外的线程池来处理。Accept连接和读写操作也可以使用同一个线程池来进行处理。而请求处理逻辑既可以使用单独的线程池进行处理，也可以跟放在读写线程一块处理。线程池中的每一个线程都是NIO线程。用户可以根据实际情况进行组装，构造出满足系统需求的并发模型。Netty提供了内置的常用编解码器，包括行编解码器［一行一个请求］，前缀长度编解码器［前N个字节定义请求的字节长度］，可重放解码器［记录半包消息的状态］，HTTP编解码器，WebSocket消息编解码器等等Netty提供了一些列生命周期回调接口，当一个完整的请求到达时，当一个连接关闭时，当一个连接建立时，用户都会收到回调事件，然后进行逻辑处理。Netty可以同时管理多个端口，可以使用NIO客户端模型，这些对于RPC服务是很有必要的。Netty除了可以处理TCP Socket之外，还可以处理UDP Socket。在消息读写过程中，需要大量使用ByteBuffer，Netty对ByteBuffer在性能和使用的便捷性上都进行了优化和抽象。总之，Netty是Java程序员进阶的必备神奇。如果你知其然，还想知其所以然，一定要好好研究下Netty。如果你觉得Java枯燥无谓，Netty则是重新开启你对Java兴趣大门的钥匙。




二、ms相关
1、Java中IO 流？
Java 中 IO 流分为几种?
按照流的流向分，可以分为输入流和输出流；
按照操作单元划分，可以划分为字节流和字符流；
按照流的角色划分为节点流和处理流。
Java Io 流共涉及 40 多个类，这些类看上去很杂乱，但实际上很有规则，而且彼此之间存在非常紧密的
联系， Java I0 流的 40 多个类都是从如下 4 个抽象类基类中派生出来的。
InputStream/Reader: 所有的输入流的基类，前者是字节输入流，后者是字符输入流。
OutputStream/Writer: 所有输出流的基类，前者是字节输出流，后者是字符输出流。

2、 Java IO与 NIO的区别
NIO即New IO，这个库是在JDK1.4中才引入的。NIO和IO有相同的作用和目的，但实现方式不同，NIO 主要用到的是块，所以NIO的效率要比IO高很多。在Java API中提供了两套NIO，一套是针对标准输入输出NIO，另一套就是网络编程NIO。

3、常用io类有那些
File
FileInputSteam，FileOutputStream
BufferInputStream，BufferedOutputSream
PrintWrite
FileReader，FileWriter
BufferReader，BufferedWriter
ObjectInputStream，ObjectOutputSream

4、字节流与字符流的区别
以字节为单位输入输出数据，字节流按照8位传输 以字符为单位输入输出数据，字符流按照16位传输

5、阻塞 IO 模型
最传统的一种 IO 模型，即在读写数据过程中会发生阻塞现象。当用户线程发出 IO 请求之后，内核会去查看数据是否就绪，如果没有就绪就会等待数据就绪，而用户线程就会处于阻塞状态，用户线程交出 CPU。当数据就绪之后，内核会将数据拷贝到用户线程，并返回结果给用户线程，用 户线程才解除 block 状态。典型的阻塞 IO 模型的例子为： data = socket.read();如果数据没有就绪，就会一直阻塞在 read 方法

6、非阻塞 IO 模型
当用户线程发起一个 read 操作后，并不需要等待，而是马上就得到了一个结果。 如果结果是一个error 时，它就知道数据还没有准备好，于是它可以再次发送 read 操作。一旦内核中的数据准备好了，并且又再次收到了用户线程的请求，那么它马上就将数据拷贝到了用户线程，然后返回。所以事实上，在非阻塞 IO 模型中，用户线程需要不断地询问内核数据是否就绪，也就说非阻塞 IO不会交出 CPU，而会一直占用 CPU。 典型的非阻塞 IO 模型一般如下：
while(true){
    data = socket.read();
    if(data!= error){
        //处理数据
        break;
    }
但是对于非阻塞 IO 就有一个非常严重的问题， 在 while 循环中需要不断地去询问内核数据是否就绪，这样会导致 CPU 占用率非常高，因此一般情况下很少使用 while 循环这种方式来读取数据。

7、多路复用 IO 模型
多路复用 IO 模型是目前使用得比较多的模型。 Java NIO 实际上就是多路复用 IO。在多路复用 IO模型中，会有一个线程不断去轮询多个 socket 的状态，只有当 socket 真正有读写事件时，才真正调用实际的 IO 读写操作。因为在多路复用 IO 模型中，只需要使用一个线程就可以管理多个socket，系统不需要建立新的进程或者线程，也不必维护这些线程和进程，并且只有在真正有socket 读写事件进行时，才会使用 IO 资源，所以它大大减少了资源占用。在 Java NIO 中，是通过 selector.select()去查询每个通道是否有到达事件，如果没有事件，则一直阻塞在那里，因此这种方式会导致用户线程的阻塞。多路复用 IO 模式，通过一个线程就可以管理多个 socket，只有当 socket 真正有读写事件发生才会占用资源来进行实际的读写操作。因此，多路复用 IO 比较适合连接数比较多的情况。
另外多路复用 IO 为何比非阻塞 IO 模型的效率高是因为在非阻塞 IO 中，不断地询问 socket 状态时通过用户线程去进行的，而在多路复用 IO 中，轮询每个 socket 状态是内核在进行的，这个效率要比用户线程要高的多。
不过要注意的是，多路复用 IO 模型是通过轮询的方式来检测是否有事件到达，并且对到达的事件 逐一进行响应。因此对于多路复用 IO 模型来说， 一旦事件响应体很大，那么就会导致后续的事件 迟迟得不到处理，并且会影响新的事件轮询。

8、信号驱动 IO 模型
在信号驱动 IO 模型中，当用户线程发起一个 IO 请求操作，会给对应的 socket 注册一个信号函数，然后用户线程会继续执行，当内核数据就绪时会发送一个信号给用户线程，用户线程接收到信号之后，便在信号函数中调用 IO 读写操作来进行实际的 IO 请求操作。

9、异步 IO 模型
异步 IO 模型才是最理想的 IO 模型，在异步 IO 模型中，当用户线程发起 read 操作之后，立刻就可以开始去做其它的事。而另一方面，从内核的角度，当它受到一个 asynchronous read 之后，它会立刻返回，说明 read 请求已经成功发起了，因此不会对用户线程产生任何 block。然后，内核会等待数据准备完成，然后将数据拷贝到用户线程，当这一切都完成之后，内核会给用户线程发送一个信号，告诉它 read 操作完成了。也就说用户线程完全不需要实际的整个 IO 操作是如何进行的， 只需要先发起一个请求，当接收内核返回的成功信号时表示 IO 操作已经完成，可以直接去使用数据了。
也就说在异步 IO 模型中， IO 操作的两个阶段都不会阻塞用户线程，这两个阶段都是由内核自动完成，然后发送一个信号告知用户线程操作已完成。用户线程中不需要再次调用 IO 函数进行具体的读写。这点是和信号驱动模型有所不同的，在信号驱动模型中，当用户线程接收到信号表示数据已经就绪，然后需要用户线程调用 IO 函数进行实际的读写操作；而在异步 IO 模型中，收到信号表示 IO 操作已经完成，不需要再在用户线程中调用 IO 函数进行实际的读写操作。
注意，异步 IO 是需要操作系统的底层支持，在 Java 7 中，提供了 Asynchronous IO。 更多参考： http://www.importnew.com/19816.html

10、JAVA NIO
NIO 主要有三大核心部分： Channel(通道)， Buffer(缓冲区), Selector。传统 IO 基于字节流和字符流进行操作， 而 NIO 基于 Channel 和 Buffer(缓冲区)进行操作，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。 Selector(选择区)用于监听多个通道的事件（比如：连接打开，数据到达）。因此，单个线程可以监听多个数据通道。 NIO 和传统 IO 之间第一个最大的区别是， IO 是面向流的， NIO 是面向缓冲区的。

11、NIO 的缓冲区
Java IO 面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据， 需要先将它缓存到一个缓冲区。 NIO 的缓冲导向方法不同。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动。这就增加了处理过程中的灵活性。但是，还需要检查是否该缓冲区中包含所有您需要处理的数据。而且，需确保当更多的数据读入缓冲区时，不要覆盖缓冲区里尚未处理的数据。

12、NIO 的非阻塞
IO 的各种流是阻塞的。这意味着，当一个线程调用 read() 或 write()时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了。 NIO 的非阻塞模式，使一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取。而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。 线程通常将非阻塞 IO 的空闲时间用于在其它通道上执行 IO 操作，所以一个单独的线程现在可以管理多个输入和输出通道（channel）。

13、Channel
首先说一下 Channel，国内大多翻译成“通道”。 Channel 和 IO 中的 Stream(流)是差不多一个等级的。 只不过 Stream 是单向的，譬如： InputStream, OutputStream， 而 Channel 是双向的，既可以用来进行读操作，又可以用来进行写操作。NIO 中的 Channel 的主要实现有：
FileChannel
DatagramChannel
SocketChannel
ServerSocketChannel 这里看名字就可以猜出个所以然来：分别可以对应文件 IO、 UDP 和 TCP（Server 和 Client）。 下面演示的案例基本上就是围绕这 4 个类型的 Channel 进行陈述的。

14、Buffer
Buffer，故名思意， 缓冲区，实际上是一个容器，是一个连续数组。 Channel 提供从文件、网络读取数据的渠道，但是读取或写入的数据都必须经由 Buffer。
上面的图描述了从一个客户端向服务端发送数据，然后服务端接收数据的过程。客户端发送数据时，必须先将数据存入 Buffer 中，然后将 Buffer 中的内容写入通道。服务端这边接收数据必须通过 Channel 将数据读入到 Buffer 中，然后再从 Buffer 中取出数据来处理。
在 NIO 中， Buffer 是一个顶层父类，它是一个抽象类，常用的 Buffer 的子类有：ByteBuffer、 IntBuffer、 CharBuffer、 LongBuffer、 DoubleBuffer、 FloatBuffer、ShortBuffer

15、Selector
Selector 类是 NIO 的核心类， Selector 能够检测多个注册的通道上是否有事件发生，如果有事件发生，便获取事件然后针对每个事件进行相应的响应处理。这样一来，只是用一个单线程就可以管理多个通道，也就是管理多个连接。这样使得只有在连接真正有读写事件发生时，才会调用函数来进行读写，就大大地减少了系统开销，并且不必为每个连接都创建一个线程，不用去维护多个线程，并且避免了多线程之间的上下文切换导致的开销。
对每个事件进行相应的响应处理。这样一来，只是用一个单线程就可以管理多个通道，也就是管理多个连接。这样使得只有在连接真正有读写事件发生时，才会调用函数来进行读写，就大大地减少了系统开销，并且不必为每个连接都创建一个线程，不用去维护多个线程，并且避免了多线程之间的上下文切换导致的开销。


16、 Netty 是什么？
面试官：介绍一下自己对 Netty 的认识吧！小伙子。
我：好的！那我就简单用 3 点来概括一下 Netty 吧！
Netty 是一个 基于 NIO 的 client-server(客户端服务器)框架，使用它可以快速简单地开发网络应用程序。
它极大地简化并优化了 TCP 和 UDP 套接字服务器等网络编程,并且性能以及安全性等很多方面甚至都要更好。
支持多种协议 如 FTP，SMTP，HTTP 以及各种二进制和基于文本的传统协议。
用官方的总结就是：Netty 成功地找到了一种在不妥协可维护性和性能的情况下实现易于开发，性能，稳定性和灵活性的方法。
除了上面介绍的之外，很多开源项目比如我们常用的 Dubbo、RocketMQ、Elasticsearch、gRPC 等等都用到了 Netty。
网络编程我愿意称 Netty 为王 。

17、 为什么要用 Netty？
面试官：为什么要用 Netty 呢？能不能说一下自己的看法。
我：因为 Netty 具有下面这些优点，并且相比于直接使用 JDK 自带的 NIO 相关的 API 来说更加易用。
统一的 API，支持多种传输类型，阻塞和非阻塞的。
简单而强大的线程模型。
自带编解码器解决 TCP 粘包/拆包问题。
自带各种协议栈。
真正的无连接数据包套接字支持。
比直接使用 Java 核心 API 有更高的吞吐量、更低的延迟、更低的资源消耗和更少的内存复制。
安全性不错，有完整的 SSL/TLS 以及 StartTLS 支持。
社区活跃
成熟稳定，经历了大型项目的使用和考验，而且很多开源项目都使用到了 Netty， 比如我们经常接触的 Dubbo、RocketMQ 等等。
......

18、 Netty 应用场景了解么？
面试官：能不能通俗地说一下使用 Netty 可以做什么事情？
我：凭借自己的了解，简单说一下吧！理论上来说，NIO 可以做的事情 ，使用 Netty 都可以做并且更好。Netty 主要用来做网络通信 :
作为 RPC 框架的网络通信工具 ：我们在分布式系统中，不同服务节点之间经常需要相互调用，这个时候就需要 RPC 框架了。不同服务节点之间的通信是如何做的呢？可以使用 Netty 来做。比如我调用另外一个节点的方法的话，至少是要让对方知道我调用的是哪个类中的哪个方法以及相关参数吧！
实现一个自己的 HTTP 服务器 ：通过 Netty 我们可以自己实现一个简单的 HTTP 服务器，这个大家应该不陌生。说到 HTTP 服务器的话，作为 Java 后端开发，我们一般使用 Tomcat 比较多。一个最基本的 HTTP 服务器可要以处理常见的 HTTP Method 的请求，比如 POST 请求、GET 请求等等。
实现一个即时通讯系统 ：使用 Netty 我们可以实现一个可以聊天类似微信的即时通讯系统，这方面的开源项目还蛮多的，可以自行去 Github 找一找。
实现消息推送系统 ：市面上有很多消息推送系统都是基于 Netty 来做的。
......

19、 Netty 核心组件有哪些？分别有什么作用？
面试官：Netty 核心组件有哪些？分别有什么作用？
我：表面上，嘴上开始说起 Netty 的核心组件有哪些，实则，内心已经开始 mmp 了，深度怀疑这面试官是存心搞我啊！
1）.Channel
Channel 接口是 Netty 对网络操作抽象类，它除了包括基本的 I/O 操作，如 bind()、connect()、read()、write() 等。
比较常用的Channel接口实现类是NioServerSocketChannel（服务端）和NioSocketChannel（客户端），这两个 Channel 可以和 BIO 编程模型中的ServerSocket以及Socket两个概念对应上。Netty 的 Channel 接口所提供的 API，大大地降低了直接使用 Socket 类的复杂性。
2）.EventLoop
这么说吧！EventLoop（事件循环）接口可以说是 Netty 中最核心的概念了！
《Netty 实战》这本书是这样介绍它的：
“EventLoop 定义了 Netty 的核心抽象，用于处理连接的生命周期中所发生的事件。
是不是很难理解？说实话，我学习 Netty 的时候看到这句话是没太能理解的。
说白了，EventLoop 的主要作用实际就是负责监听网络事件并调用事件处理器进行相关 I/O 操作的处理。
那 Channel 和 EventLoop 直接有啥联系呢？
Channel 为 Netty 网络操作(读写等操作)抽象类，EventLoop 负责处理注册到其上的Channel 处理 I/O 操作，两者配合参与 I/O 操作。
3）.ChannelFuture
Netty 是异步非阻塞的，所有的 I/O 操作都为异步的。
因此，我们不能立刻得到操作是否执行成功，但是，你可以通过 ChannelFuture 接口的 addListener() 方法注册一个 ChannelFutureListener，当操作执行成功或者失败时，监听就会自动触发返回结果。
并且，你还可以通过ChannelFuture 的 channel() 方法获取关联的Channel
public interface ChannelFuture extends Future<Void> { Channel channel(); ChannelFuture addListener(GenericFutureListener<? extends Future<? super Void>> var1); ...... ChannelFuture sync() throws InterruptedException;}
另外，我们还可以通过 ChannelFuture 接口的 sync()方法让异步的操作变成同步的。
4）.ChannelHandler 和 ChannelPipeline
下面这段代码使用过 Netty 的小伙伴应该不会陌生，我们指定了序列化编解码器以及自定义的 ChannelHandler 处理消息。
b.group(eventLoopGroup) .handler(new ChannelInitializer<SocketChannel>() { @Override protected void initChannel(SocketChannel ch) { ch.pipeline().addLast(new NettyKryoDecoder(kryoSerializer, RpcResponse.class)); ch.pipeline().addLast(new NettyKryoEncoder(kryoSerializer, RpcRequest.class)); ch.pipeline().addLast(new KryoClientHandler()); } });
ChannelHandler 是消息的具体处理器。他负责处理读写操作、客户端连接等事情。
ChannelPipeline 为 ChannelHandler 的链，提供了一个容器并定义了用于沿着链传播入站和出站事件流的 API 。当 Channel 被创建时，它会被自动地分配到它专属的 ChannelPipeline。
我们可以在 ChannelPipeline 上通过 addLast() 方法添加一个或者多个ChannelHandler ，因为一个数据或者事件可能会被多个 Handler 处理。当一个 ChannelHandler 处理完之后就将数据交给下一个 ChannelHandler 。

20、 EventloopGroup 了解么?和 EventLoop 啥关系?
面试官：刚刚你也介绍了 EventLoop。那你再说说 EventloopGroup 吧！和 EventLoop 啥关系?
我：
EventLoopGroup 包含多个 EventLoop（每一个 EventLoop 通常内部包含一个线程），上面我们已经说了 EventLoop 的主要作用实际就是负责监听网络事件并调用事件处理器进行相关 I/O 操作的处理。
并且 EventLoop 处理的 I/O 事件都将在它专有的 Thread 上被处理，即 Thread 和 EventLoop 属于 1 : 1 的关系，从而保证线程安全。
上图是一个服务端对 EventLoopGroup 使用的大致模块图，其中 Boss EventloopGroup 用于接收连接，Worker EventloopGroup 用于具体的处理（消息的读写以及其他逻辑处理）。
从上图可以看出：当客户端通过 connect 方法连接服务端时，bossGroup 处理客户端连接请求。当客户端处理完成后，会将这个连接提交给 workerGroup 来处理，然后 workerGroup 负责处理其 IO 相关操作。

21、 Bootstrap 和 ServerBootstrap 了解么？
面试官：你再说说自己对 Bootstrap 和 ServerBootstrap 的了解吧！
我：
Bootstrap 是客户端的启动引导类/辅助类，具体使用方法如下：
EventLoopGroup group = new NioEventLoopGroup(); try { //创建客户端启动引导/辅助类：Bootstrap Bootstrap b = new Bootstrap(); //指定线程模型 b.group(group). ...... // 尝试建立连接 ChannelFuture f = b.connect(host, port).sync(); f.channel().closeFuture().sync(); } finally { // 优雅关闭相关线程组资源 group.shutdownGracefully(); }
ServerBootstrap 客户端的启动引导类/辅助类，具体使用方法如下：
// 1.bossGroup 用于接收连接，workerGroup 用于具体的处理 EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { //2.创建服务端启动引导/辅助类：ServerBootstrap ServerBootstrap b = new ServerBootstrap(); //3.给引导类配置两大线程组,确定了线程模型 b.group(bossGroup, workerGroup). ...... // 6.绑定端口 ChannelFuture f = b.bind(port).sync(); // 等待连接关闭 f.channel().closeFuture().sync(); } finally { //7.优雅关闭相关线程组资源 bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } }
从上面的示例中，我们可以看出：
Bootstrap 通常使用 connet() 方法连接到远程的主机和端口，作为一个 Netty TCP 协议通信中的客户端。另外，Bootstrap 也可以通过 bind() 方法绑定本地的一个端口，作为 UDP 协议通信中的一端。
ServerBootstrap通常使用 bind() 方法绑定本地的端口上，然后等待客户端的连接。
Bootstrap 只需要配置一个线程组— EventLoopGroup ,而 ServerBootstrap需要配置两个线程组— EventLoopGroup ，一个用于接收连接，一个用于具体的处理。

23、 NioEventLoopGroup 默认的构造函数会起多少线程？
面试官：看过 Netty 的源码了么？NioEventLoopGroup 默认的构造函数会起多少线程呢？
我：嗯嗯！看过部分。
回顾我们在上面写的服务器端的代码：
1.bossGroup 用接收连接，workerGroup 用于具体的处理EventLoopGroup bossGroup = new NioEventLoopGroup(1);EventLoopGroup workerGroup = new NioEventLoopGroup();
为了搞清楚NioEventLoopGroup 默认的构造函数 到底创建了多少个线程，我们来看一下它的源码。
一直向下走下去的话，你会发现在 MultithreadEventLoopGroup 类中有相关的指定线程数的代码，如下：
综上，我们发现 NioEventLoopGroup 默认的构造函数实际会起的线程数为 CPU核心数*2。
另外，如果你继续深入下去看构造函数的话，你会发现每个NioEventLoopGroup对象内部都会分配一组NioEventLoop，其大小是 nThreads, 这样就构成了一个线程池， 一个NIOEventLoop 和一个线程相对应，这和我们上面说的 EventloopGroup 和 EventLoop关系这部分内容相对应。

24、 Netty 线程模型了解么？
面试官：说一下 Netty 线程模型吧！
我：大部分网络框架都是基于 Reactor 模式设计开发的。
“Reactor 模式基于事件驱动，采用多路复用将事件分发给相应的 Handler 处理，非常适合处理海量 IO 的场景。
在 Netty 主要靠 NioEventLoopGroup 线程池来实现具体的线程模型的 。
我们实现服务端的时候，一般会初始化两个线程组：
bossGroup :接收连接。
workerGroup ：负责具体的处理，交由对应的 Handler 处理。
下面我们来详细看一下 Netty 中的线程模型吧！
1）.单线程模型：
一个线程需要执行处理所有的 accept、read、decode、process、encode、send 事件。对于高负载、高并发，并且对性能要求比较高的场景不适用。
对应到 Netty 代码是下面这样的
“使用 NioEventLoopGroup 类的无参构造函数设置线程数量的默认值就是 CPU 核心数 *2。
//1.eventGroup既用于处理客户端连接，又负责具体的处理。 EventLoopGroup eventGroup = new NioEventLoopGroup(1); //2.创建服务端启动引导/辅助类：ServerBootstrap ServerBootstrap b = new ServerBootstrap(); boobtstrap.group(eventGroup, eventGroup) //......
2）.多线程模型
一个 Acceptor 线程只负责监听客户端的连接，一个 NIO 线程池负责具体处理：accept、read、decode、process、encode、send 事件。满足绝大部分应用场景，并发连接量不大的时候没啥问题，但是遇到并发连接大的时候就可能会出现问题，成为性能瓶颈。
对应到 Netty 代码是下面这样的：
3）.主从多线程模型
从一个 主线程 NIO 线程池中选择一个线程作为 Acceptor 线程，绑定监听端口，接收客户端连接的连接，其他线程负责后续的接入认证等工作。连接建立完成后，Sub NIO 线程池负责具体处理 I/O 读写。如果多线程模型无法满足你的需求的时候，可以考虑使用主从多线程模型 。

25、 简单解析一下服务端的创建过程具体是怎样的：
1）.首先你创建了两个 NioEventLoopGroup 对象实例：bossGroup 和 workerGroup。
bossGroup : 用于处理客户端的 TCP 连接请求。
workerGroup ：负责每一条连接的具体读写数据的处理逻辑，真正负责 I/O 读写操作，交由对应的 Handler 处理。
举个例子：我们把公司的老板当做 bossGroup，员工当做 workerGroup，bossGroup 在外面接完活之后，扔给 workerGroup 去处理。一般情况下我们会指定 bossGroup 的 线程数为 1（并发连接量不大的时候） ，workGroup 的线程数量为 CPU 核心数 *2 。另外，根据源码来看，使用 NioEventLoopGroup 类的无参构造函数设置线程数量的默认值就是 CPU 核心数 *2 。
2）.接下来 我们创建了一个服务端启动引导/辅助类：ServerBootstrap，这个类将引导我们进行服务端的启动工作。
3）.通过 .group() 方法给引导类 ServerBootstrap 配置两大线程组，确定了线程模型。
通过下面的代码，我们实际配置的是多线程模型，这个在上面提到过。
EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup();
4）.通过channel()方法给引导类 ServerBootstrap指定了 IO 模型为NIO
NioServerSocketChannel ：指定服务端的 IO 模型为 NIO，与 BIO 编程模型中的ServerSocket对应
NioSocketChannel : 指定客户端的 IO 模型为 NIO， 与 BIO 编程模型中的Socket对应5.通过 .childHandler()给引导类创建一个ChannelInitializer ，然后制定了服务端消息的业务处理逻辑 HelloServerHandler 对象6.调用 ServerBootstrap 类的 bind()方法绑定端口

26、 继续分析一下客户端的创建流程：
1）.创建一个 NioEventLoopGroup 对象实例
2）.创建客户端启动的引导类是 Bootstrap
3）.通过 .group() 方法给引导类 Bootstrap 配置一个线程组
4）.通过channel()方法给引导类 Bootstrap指定了 IO 模型为NIO
5）.通过 .childHandler()给引导类创建一个ChannelInitializer ，然后制定了客户端消息的业务处理逻辑 HelloClientHandler 对象
6）.调用 Bootstrap 类的 connect()方法进行连接，这个方法需要指定两个参数：

27、 什么是 TCP 粘包/拆包?有什么解决办法呢？
面试官：什么是 TCP 粘包/拆包?
我：TCP 粘包/拆包 就是你基于 TCP 发送数据的时候，出现了多个字符串“粘”在了一起或者一个字符串被“拆”开的问题。比如你多次发送：“你好,你真帅啊！哥哥！”，但是客户端接收到的可能是下面这样的：

28、 面试官：那有什么解决办法呢?
我：
1）.使用 Netty 自带的解码器
LineBasedFrameDecoder : 发送端发送数据包的时候，每个数据包之间以换行符作为分隔，LineBasedFrameDecoder 的工作原理是它依次遍历 ByteBuf 中的可读字节，判断是否有换行符，然后进行相应的截取。
DelimiterBasedFrameDecoder : 可以自定义分隔符解码器，LineBasedFrameDecoder 实际上是一种特殊的 DelimiterBasedFrameDecoder 解码器。
FixedLengthFrameDecoder: 固定长度解码器，它能够按照指定的长度对消息进行相应的拆包。
LengthFieldBasedFrameDecoder：
2）.自定义序列化编解码器
在 Java 中自带的有实现 Serializable 接口来实现序列化，但由于它性能、安全性等原因一般情况下是不会被使用到的。
通常情况下，我们使用 Protostuff、Hessian2、json 序列方式比较多，另外还有一些序列化性能非常好的序列化方式也是很好的选择：
专门针对 Java 语言的：Kryo，FST 等等
跨语言的：Protostuff（基于 protobuf 发展而来），ProtoBuf，Thrift，Avro，MsgPack 等等

29、 Netty 长连接、心跳机制了解么？
面试官：TCP 长连接和短连接了解么？
我：我们知道 TCP 在进行读写之前，server 与 client 之间必须提前建立一个连接。建立连接的过程，需要我们常说的三次握手，释放/关闭连接的话需要四次挥手。这个过程是比较消耗网络资源并且有时间延迟的。
所谓，短连接说的就是 server 端 与 client 端建立连接之后，读写完成之后就关闭掉连接，如果下一次再要互相发送消息，就要重新连接。短连接的有点很明显，就是管理和实现都比较简单，缺点也很明显，每一次的读写都要建立连接必然会带来大量网络资源的消耗，并且连接的建立也需要耗费时间。
长连接说的就是 client 向 server 双方建立连接之后，即使 client 与 server 完成一次读写，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。长连接的可以省去较多的 TCP 建立和关闭的操作，降低对网络资源的依赖，节约时间。对于频繁请求资源的客户来说，非常适用长连接。

30、 面试官：为什么需要心跳机制？Netty 中心跳机制了解么？
我：
在 TCP 保持长连接的过程中，可能会出现断网等网络异常出现，异常发生的时候， client 与 server 之间如果没有交互的话，它们是无法发现对方已经掉线的。为了解决这个问题, 我们就需要引入 心跳机制。
心跳机制的工作原理是: 在 client 与 server 之间在一定时间内没有数据交互时, 即处于 idle 状态时, 客户端或服务器就会发送一个特殊的数据包给对方, 当接收方收到这个数据报文后, 也立即发送一个特殊的数据报文, 回应发送方, 此即一个 PING-PONG 交互。所以, 当某一端收到心跳消息后, 就知道了对方仍然在线, 这就确保 TCP 连接的有效性.
TCP 实际上自带的就有长连接选项，本身是也有心跳包机制，也就是 TCP 的选项：SO_KEEPALIVE。但是，TCP 协议层面的长连接灵活性不够。所以，一般情况下我们都是在应用层协议上实现自定义心跳机制的，也就是在 Netty 层面通过编码实现。通过 Netty 实现心跳机制的话，核心类是 IdleStateHandler 。

31、 Netty 的零拷贝了解么？
面试官：讲讲 Netty 的零拷贝？
我：
维基百科是这样介绍零拷贝的：
“零复制（英语：Zero-copy；也译零拷贝）技术是指计算机执行操作时，CPU 不需要先将数据从某处内存复制到另一个特定区域。这种技术通常用于通过网络传输文件时节省 CPU 周期和内存带宽。
在 OS 层面上的 Zero-copy 通常指避免在 用户态(User-space) 与 内核态(Kernel-space) 之间来回拷贝数据。而在 Netty 层面 ，零拷贝主要体现在对于数据操作的优化。
Netty 中的零拷贝体现在以下几个方面：
使用 Netty 提供的 CompositeByteBuf 类, 可以将多个ByteBuf 合并为一个逻辑上的 ByteBuf, 避免了各个 ByteBuf 之间的拷贝。
ByteBuf 支持 slice 操作, 因此可以将 ByteBuf 分解为多个共享同一个存储区域的 ByteBuf, 避免了内存的拷贝。
通过 FileRegion 包装的FileChannel.tranferTo 实现文件传输, 可以直接将文件缓冲区的数据发送到目标 Channel, 避免了传统通过循环 write 方式导致的内存拷贝问题.
---------------------------------------------------------------------------------------------------------------
------------------------------------------netty&nio basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------nginx basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 Nginx
一款高性能的http 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器。官方测试nginx能够支支撑5万并发链接，并且cpu、内存等资源消耗却非常低，运行非常稳定。C语言开发。
一款自由的、开源的、高性能的HTTP服务器和反向代理服务器；同时也是一个IMAP、POP3、SMTP代理服务器；nginx可以作为一个HTTP服务器进行网站的发布处理，另外nginx可以作为反向代理、负载均衡、动静分离的实现。

2 Nginx配置
1）全局块：配置影响nginx全局的指令。一般有运行nginx服务器的用户组，nginx进程pid存放路径，日志存放路径，配置文件引入，允许生成worker process数等。
2）events块：配置影响nginx服务器或与用户的网络连接。有每个进程的最大连接数，选取哪种事件驱动模型处理连接请求，是否允许同时接受多个网路连接，开启多个网络连接序列化等。
3）http块：可以嵌套多个server，配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置。如文件引入，mime-type定义，日志自定义，是否使用sendfile传输文件，连接超时时间，单连接请求数等。
4）server块：配置虚拟主机的相关参数，一个http中可以有多个server。
5）location块：配置请求的路由，以及各种页面的处理情况。

#全局设置
main 
# 运行用户
user www-data;    
# 启动进程,通常设置成和cpu的数量相等
worker_processes  1;

# 全局错误日志及PID文件
error_log  /var/log/nginx/error.log;
pid        /var/run/nginx.pid;

# 工作模式及连接数上限
events {
    use epoll; #epoll是多路复用IO(I/O Multiplexing)中的一种方式,但是仅用于linux2.6以上内核,可以大大提高nginx的性能
    worker_connections 1024; #单个后台worker process进程的最大并发链接数
    # multi_accept on; 
}

#设定http服务器，利用它的反向代理功能提供负载均衡支持
http {
    #设定mime类型,类型由mime.type文件定义
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;
    #设定日志格式
    access_log    /var/log/nginx/access.log;
    #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，对于普通应用，
    #必须设为 on,如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，以平衡磁盘与网络I/O处理速度，降低系统的uptime.
    sendfile        on;
    #将tcp_nopush和tcp_nodelay两个指令设置为on用于防止网络阻塞
    tcp_nopush      on;
    tcp_nodelay     on;
    #连接超时时间
    keepalive_timeout  65;
    #开启gzip压缩
    gzip  on;
    gzip_disable "MSIE [1-6]\.(?!.*SV1)";

    #设定请求缓冲
    client_header_buffer_size    1k;
    large_client_header_buffers  4 4k;
    include /etc/nginx/conf.d/*.conf;
    include /etc/nginx/sites-enabled/*;

    #设定负载均衡的服务器列表
    upstream mysvr {
        #weigth参数表示权值，权值越高被分配到的几率越大
        #本机上的Squid开启3128端口
        server 192.168.8.1:3128 weight=5;
        server 192.168.8.2:80  weight=1;
        server 192.168.8.3:80  weight=6;
    }

    server {
        #侦听80端口
        listen       80;
        #定义使用www.xx.com访问
        server_name  www.xx.com;

        #设定本虚拟主机的访问日志
        access_log  logs/www.xx.com.access.log  main;

        #默认请求
        location / {
            root   /root;      #定义服务器的默认网站根目录位置
            index index.php index.html index.htm;   #定义首页索引文件的名称
            fastcgi_pass  www.xx.com;
            fastcgi_param  SCRIPT_FILENAME  $document_root/$fastcgi_script_name; 
            include /etc/nginx/fastcgi_params;
        }

        # 定义错误提示页面
        error_page   500 502 503 504 /50x.html;  
            location = /50x.html {
            root   /root;
        }

        #静态文件，nginx自己处理
        location ~ ^/(images|javascript|js|css|flash|media|static)/ {
            root /var/www/virtual/htdocs;
            #过期30天，静态文件不怎么更新，过期可以设大一点，如果频繁更新，则可以设置得小一点。
            expires 30d;
        }
        #PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置.
        location ~ \.php$ {
            root /root;
            fastcgi_pass 127.0.0.1:9000;
            fastcgi_index index.php;
            fastcgi_param SCRIPT_FILENAME /home/www/www$fastcgi_script_name;
            include fastcgi_params;
        }
        #设定查看Nginx状态的地址
        location /NginxStatus {
            stub_status            on;
            access_log              on;
            auth_basic              "NginxStatus";
            auth_basic_user_file  conf/htpasswd;
        }
        #禁止访问 .htxxx 文件
        location ~ /\.ht {
            deny all;
        }

    }

    #第一个虚拟服务器
    server {
        #侦听192.168.8.x的80端口
        listen       80;
        server_name  192.168.8.x;

        #对aspx后缀的进行负载均衡请求
        location ~ .*\.aspx$ {
            root   /root;#定义服务器的默认网站根目录位置
            index index.php index.html index.htm;#定义首页索引文件的名称
            proxy_pass  http://mysvr;#请求转向mysvr 定义的服务器列表
            #以下是一些反向代理的配置可删除.
            proxy_redirect off;
            #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            client_max_body_size 10m;    #允许客户端请求的最大单文件字节数
            client_body_buffer_size 128k;  #缓冲区代理缓冲用户端请求的最大字节数，
            proxy_connect_timeout 90;  #nginx跟后端服务器连接超时时间(代理连接超时)
            proxy_send_timeout 90;        #后端服务器数据回传时间(代理发送超时)
            proxy_read_timeout 90;         #连接成功后，后端服务器响应时间(代理接收超时)
            proxy_buffer_size 4k;             #设置代理服务器（nginx）保存用户头信息的缓冲区大小
            proxy_buffers 4 32k;               #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置
            proxy_busy_buffers_size 64k;    #高负荷下缓冲大小（proxy_buffers*2）
            proxy_temp_file_write_size 64k;  #设定缓存文件夹大小，大于这个值，将从upstream服务器传
        }
    }
}

http {
    include       mime.types;
    default_type  application/octet-stream;
     sendfile        on；
    keepalive_timeout  65;
    proxy_cache_path /cache/nginx/ levels=1:1 keys_zone=mycache:23m;
     #建立缓存目录，目录必须是nginx用户，levels是可建目录几级，mycache是名称，开启缓存，只能在http中开启，具体功能可在http,server,location,if中使用
        fastcgi_cache_path /cache/fastcgi levels=1:1 keys_zone=fcgicache:10m inactive=3m max_size=1g;  
    #factcgi接口使用的命令，建立fastcgi的缓存
       upstream upservers {
               #建立后端负载均衡技术
                #ip_hash;负载均衡中的指令，可不加
                server 192.168.1.11 max_fails=2 fail_timeout=1 weight=2;
                 #添加一台服务器，max_fails失败两次即暂停，fail_timeout 失败后暂停的时间,weigth权重
                server 192.168.1.12  max_fails=2 fail_timeout=1;
                  #后加down即人为停掉这台服务
                  }
 server {
        listen       80;
        server_name  localhost;
        add_header X-Via $server_addr;   # 可以放在任意里面，首部自定义添加内容
        add_header X-cache $upstream_cache_status;    #根据是否缓存命中给出状态，如miss，hit
       location / {
           proxy_pass http://upservers/;
              #按组的形式，把后端已经作成组的服务器加进来
        }
        location /root {
                proxy_pass http://192.168.1.11/root/;   #代理后端服务器
                proxy_set_header Host $remote_addr;   #日志会记录源ip的日志，而不是代理服务器请求的日志，还需要修改后端服务器的日志格式logFormat "%{X-Real-IP}i"
                proxy_cache mycache;  #使用mycahce缓存，http中定义
                proxy_cache_valid 200 1d; #根据响应码确定缓存市场，可多次定义
                proxy_cache_valid 301 10m;
                proxy_cache_valid any 1m; #其他未定的一律1m缓存
                proxy_cache_use_stale error timeout invalid_header http_500 http_502 http_504; #缓存过期后，哪些情况可以继续使用缓存，以上缓存命令在其他location 中可继续使用
        }
        location /forum/ { #此处可以用其他名字，可以不同
                        proxy_pass http://192.179.1.11/bbs/;  #此处必须加上/bbs/        
                      }
        location ~* \.(jpg|png|gif)$ {
                          proxy_pass http://192.168.1.12;  #因为是正则表达式，所以不能加，表示所有访问图片类型的都走这台服务器
                        }
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
        location ~ \.php$ {
               #动静分离，动态页面全走这里
                #注意此处开启php动态功能，需要安装php-fpm,并重启服务
                #如果想用mysql，可安装php-msyql,  mysql-server,并重启服务即可
           root  /usr/share/nginx/html;
           fastcgi_pass   127.0.0.1:9000;
           fastcgi_index  index.php;
            fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;
           include        fastcgi_params;
        }
}

3 Nginx反向代理
1 ）正向代理：通常的代理服务器，用于代理内部网络对Internet的连接请求，客户机必须指定代理服务器,并将本来要直接发送到Web服务器上的http请求发送到
代理服务器中由代理服务器向Internet上的web服务器发起请求，最终达到客户机上网的目的。 
client —(send request)—> clinet proxy –(send request)—> server

2） 反向代理：以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，
此时代理服务器对外就表现为一个反向代理服务器。
反向代理，主要用于服务器集群分布式部署的情况下，反向代理隐藏了服务器的信息！当然反向代理的另一大用处就是隐藏后面的实际服务，以此来达到一定的安全性。 
clinet –(send request)–> server proxy –(send request)–>other server

4 Nginx负载均衡
1 ）网站的访问量越来越大，服务器的服务模式也得进行相应的升级，比如分离出数据库服务器、分离出图片作为单独服务，这些是简单的数据的负载均衡，
将压力分散到不同的机器上。有时候来自web前端的压力，也能让人十分头痛。怎样将同一个域名的访问分散到两台或更多的机器上呢？这其实就是另一种负
载均衡了，nginx自身就可以做到，只需要做个简单的配置就行。
nginx不单可以作为强大的web服务器，也可以作为一个反向代理服务器，而且nginx还可以按照调度规则实现动态、静态页面的分离，可以按照轮询、ip哈希、URL哈希、权重等多种方式对后端服务器做负载均衡，同时还支持后端服务器的健康检查。
2 ）种方式的分配  
@轮询（默认）  
每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 @weight 指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 
@ip_hash/url_ip 每个请求按访问ip或者url的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。  
@fair（第三方） 按后端服务器的响应时间来分配请求，响应时间短的优先分配。  

upstream  wade
{
    server   10.0.1.50:8080;
    server   10.0.1.51:8080;
}
upstream  james  
{
    server   10.0.1.50:8080;
    server   10.0.1.51:8080;
}
server
{
    listen  80;
    server_name  www.linuxidc.com;
    location / {
        proxy_pass        http://wade;
        proxy_set_header   Host             $host;
        proxy_set_header   X-Real-IP        $remote_addr;
        proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;
    }
}
server
{
    listen  80;
    server_name  blog.linuxidc.com wode.linuxidc.com;
    location / {
        proxy_pass        http://james;
        proxy_set_header   Host             $host;
        proxy_set_header   X-Real-IP        $remote_addr;
        proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;
    }
}


5 Nginx高可用
1） 使用集群是网站解决高并发、海量数据问题的常用手段。当一台服务器的处理能力、存储空间不足时，不要企图去换更强大的服务器，对大型网站而言，不管多么强大的服务器，
都满足不了网站持续增长的业务需求。这种情况下，更恰当的做法是增加一台服务器分担原有服务器的访问及存储压力。通过负载均衡调度服务器，将来自浏览器的访问请求分发到应用服务器集群中的任何一台服务器上，如果有更多的用户，就在集群中加入更多的应用服务器，使应用服务器的负载压力不再成为整个网站的瓶颈。
2） Keepalived软件起初是专为LVS负载均衡软件设计的，用来管理并监控LVS集群系统中各个服务节点的状态，后来又加入了可以实现高可用的VRRP功能。因此，Keepalived除了能够
管理LVS软件外，还可以作为其他服务（例如：Nginx、Haproxy、MySQL等）的高可用解决方案软件。
Keepalived软件主要是通过VRRP协议实现高可用功能的。VRRP是Virtual Router RedundancyProtocol(虚拟路由器冗余协议）的缩写，VRRP出现的目的就是为了解决静态路由单点故障问题的，它能够保证当个别节点宕机时，整个网络可以不间断地运行。
3） VRRP ,全 称 Virtual Router Redundancy Protocol ,中文名为虚拟路由冗余协议 ，VRRP的出现就是为了解决静态踣甶的单点故障问题，VRRP是通过一种竞选机制来将路由
的任务交给某台VRRP路由器的。


6 Nginx web缓存
1） 导入配置文件
include vhosts/dev-a/*.conf;
include vhosts/dev-b/*.conf;
include vhosts/test-a/*.conf;
include vhosts/test-b/*.conf;
include vhosts/hotfix/*.conf;

2） Web缓存使用
 upstream webserver {
        server  192.168.0.201 weight=1 max_fails=2  fail_timeout=2;
        server  192.168.0.202 weight=1 max_fails=2  fail_timeout=2;
}
server {
                listen 9008;
                server_name localhost;
                root html/error;
                index index.html;
}

7 动静分离
upstream web {
    server  192.168.0.1 weight=1 max_fails=2  fail_timeout=2;
    server  192.168.0.2 weight=1 max_fails=2  fail_timeout=2;
} 
upstream image  {
    server  192.168.0.3 weight=1 max_fails=2  fail_timeout=2;
    server  192.168.0.4 weight=1 max_fails=2  fail_timeout=2;
} 
upstream php {
    server  192.168.0.5 weight=1 max_fails=2  fail_timeout=2;
    server  192.168.0.6 weight=1 max_fails=2  fail_timeout=2;
} 
location  /{
    root html/web;
    index  index.php index.html;
}
location ~* \.php$ {
    fastcgi_proxy  http://php;}

location ~* "\.(.jpg|png|jpeg|gif)" {
    proxy_pass http://image;
}

8 拦截upload请求到本地硬盘
server {
    listen 80;
    server_name erp.zb25.com.cn;
    access_log  logs/dev.log  main;
    error_log logs/dev-error.log info;

    location /upload {
           alias /home/test/data/apache_new/opserp/upload/; 
    }
    location / {
        proxy_buffering off;
        proxy_pass http://10.10.50.156:8030;
    }
}




二、ms相关
1.Nginx简介
Nginx (engine x) 是一个高性能的HTTP和反向代理web服务器，同时也提供了IMAP/POP3/SMTP服务。
其将源代码以类BSD许可证的形式发布，因它的稳定性、丰富的功能集、示例配置文件和低系统资源的消耗而闻名。2011年6月1日，nginx 1.0.4发布。
Nginx是一款轻量级的Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，在BSD-like 协议下发行。其特点是占有内存少，并发能力强，事实上nginx的并发能力在同类型的网页服务器中表现较好，中国大陆使用nginx网站用户有：百度、京东、新浪、网易、腾讯、淘宝等。
Nginx 是一个很强大的高性能Web和反向代理服务，它具有很多非常优越的特性：
在连接高并发的情况下，Nginx是Apache服务不错的替代品：Nginx在美国是做虚拟主机生意的老板们经常选择的软件平台之一。能够支持高达 50,000 个并发连接数的响应，感谢Nginx为我们选择了 epoll and kqueue作为开发模型。

2.正向代理
在客户端(浏览器)配置代理服务器，通过代理服务器进行互联网访问。

3.反向代理
我们只需要将请求发送到反向代理服务器，由反向代理服务器去选择目标服务器获取数据后，在返回给客户端，此时反向代理服务器和目标服务器对外就是一个服务器,暴露的是代理服务器地址，隐藏了真实服务器IP地址。

4.负载均衡
单个服务器解决不了，我们增加服务器的数量，然后将请求分发到各个服务器上，将原先请求集中到单个服务器上的情况改为将请求分发到多个服务器上，将负载分发到不同的服务器，也就是我们所说的负载均衡。

5.动静分离
为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度。降低原来单个服务器的压力。

6.请列举Nginx的一些特性？
Nginx服务器的特性包括：反向代理/L7负载均衡器 ；嵌入式Perl解释器 ；动态二进制升级；可用于重新编写URL，具有非常好的PCRE支持。

7.nginx和apache的区别？
轻量级，同样起web 服务，比apache 占用更少的内存及资源；抗并发，nginx处理请求是异步非阻塞的，而apache 则是阻塞型的，在高并发下nginx 能保持低资源低消耗高性能；高度模块化的设计，编写模块相对简单；最核心的区别在于apache是同步多进程模型，一个连接对应一个进程；nginx是异步的，多个连接（万级别）可以对应一个进程。

8.nginx是如何实现高并发的？
一个主进程，多个工作进程，每个工作进程可以处理多个请求，每进来一个request，会有一个worker进程去处理。但不是全程的处理，处理到可能发生阻塞的地方，比如向上游（后端）服务器转发request，并等待请求返回。那么，这个处理的worker继续处理其他请求，而一旦上游服务器返回了，就会触发这个事件，worker才会来接手，这个request才会接着往下走。由于web server的工作性质决定了每个request的大部份生命都是在网络传输中，实际上花费在server机器上的时间片不多。这是几个进程就解决高并发的秘密所在。即@skoo所说的webserver刚好属于网络io密集型应用，不算是计算密集型。

9.Nginx如何处理HTTP请求？
Nginx使用反应器模式。主事件循环等待操作系统发出准备事件的信号，这样数据就可以从套接字读取，在该实例中读取到缓冲区并进行处理。单个线程可以提供数万个并发连接。

10.为什么要用Nginx?
跨平台、配置简单
非阻塞、高并发连接：
处理2-3万并发连接数，官方监测能支持5万并发
内存消耗小：
开启10个nginx才占150M内存，Nginx采取了分阶段资源分配技术
nginx处理静态文件好,耗费内存少
内置的健康检查功能：
如果有一个服务器宕机，会做一个健康检查，再发送的请求就不会发送到宕机的服务器了。重新将请求提交到其他的节点上。
节省宽带：
支持GZIP压缩，可以添加浏览器本地缓存
稳定性高：
宕机的概率非常小
master/worker结构：
一个master进程，生成一个或者多个worker进程
接收用户请求是异步的：
浏览器将请求发送到nginx服务器，它先将用户请求全部接收下来，再一次性发送给后端web服务器，极大减轻了web服务器的压力,一边接收web服务器的返回数据，一边发送给浏览器客户端
网络依赖性比较低，只要ping通就可以负载均衡
可以有多台nginx服务器

11.为什么Nginx性能这么高？
得益于它的事件处理机制：
异步非阻塞事件处理机制：运用了epoll模型，提供了一个队列，排队解决

12.为什么不使用多线程？
Nginx:采用单线程来异步非阻塞处理请求（管理员可以配置Nginx主进程的工作进程的数量），不会为每个请求分配cpu和内存资源，节省了大量资源，同时也减少了大量的CPU的上下文切换，所以才使得Nginx支持更高的并发。

13.在Nginx中如何在URL中保留双斜线?
要在URL中保留双斜线，就必须使用merge_slashes_off；语法:merge_slashes [on/off] ； 默认值: merge_slashes on ；环境: http，server

14.ngx_http_upstream_module的作用是什么?
ngx_http_upstream_module用于定义可通过fastcgi传递、proxy传递、uwsgi传递、memcached传递和scgi传递指令来引用的服务器组。

15.什么是C10K问题?
C10K问题是指无法同时处理大量客户端(10,000)的网络套接字。

16.请陈述stub_status和sub_filter指令的作用是什么?
Stub_status指令：该指令用于了解Nginx当前状态的当前状态，如当前的活动连接，接受和处理当前读/写/等待连接的总数 ；
Sub_filter指令：它用于搜索和替换响应中的内容，并快速修复陈旧的数据

17.Nginx是否支持将请求压缩到上游?
可以使用Nginx模块gunzip将请求压缩到上游。gunzip模块是一个过滤器，它可以对不支持“gzip”编码方法的客户机或服务器使用“内容编码:gzip”来解压缩响应。

18.解释如何在Nginx中获得当前的时间?
要获得Nginx的当前时间，必须使用SSI模块、d a t e g m t 和 date_gmt和date 
gmt和date_local的变量。Proxy_set_header THE-TIME $date_gmt;

19.用Nginx服务器解释-s的目的是什么?
用于运行Nginx -s参数的可执行文件。

20.解释如何在Nginx服务器上添加模块?
在编译过程中，必须选择Nginx模块，因为Nginx不支持模块的运行时间选择。

21.列举Nginx服务器的最佳用途。
Nginx服务器的最佳用法是在网络上部署动态HTTP内容，使用SCGI、WSGI应用程序服务器、用于脚本的FastCGI处理程序。它还可以作为负载均衡器。

22.Nginx服务器上的Master和Worker进程分别是什么?
Master进程：读取及评估配置和维持 ；
Worker进程：处理请求。
---------------------------------------------------------------------------------------------------------------
------------------------------------------nginx basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------openstack basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识

1 Openstack简介
• OpenStack是一个由NASA(美国国家航空航天局)和Rackspace合作研发并发起的项目
• OpenStack是一套IaaS解决方案
• OpenStack是一个开源的云计算管理平台
• 以Apache许可证为授权
OpenStack是一个美国国家航空航天局和Rackspace合作研发的云计算软件，以Apache授权条款授权，并且是一个自由软件和开放源代码项目。OpenStack是一个云操作系统，通过数据中心可控制大型的计算、存储、网络等资源池。所有的管理通过前端界面管理员就可以完成，同样也可以通过web接口让最终用户部署资源。OpenStack包含了一组由社区维护的开源项目，主要项目有Compute（Nova）， Object Storage（Swift），Image Service（Glance）。Nova提供虚拟计算服务，Swift提供存储服务，Glance提供虚拟机镜像的注册、分发服务。

OpenStack是一整套开源软件项目的综合，它允许企业或服务提供者建立、运行自己的云计算和存储设施。Rackspace与NASA是最初重要的两个贡献者，前者提供了“云文件”平台代码，该平台增强了OpenStack对象存储部分的功能，而后者带来了“Nebula”平台形成了OpenStack其余的部分。而今，OpenStack基金会已经有150多个会员，包括很多知名公司如“Canonical、DELL、Citrix”等。

也是一个项目和一个开源软件，提供开放源码软件，建立公共和私有云，它提供了一个部署云的操作平台或工具集，其宗旨在于：帮助组织运行为虚拟计算或存储服务的云，为公有云、私有云，也为大云、小云提供可扩展的、灵活的云计算。
OpenStackd开源项目由社区维护，包括OpenStack计算（代号为Nova），OpenStack对象存储（代号为Swift），并OpenStack镜像服务（代号Glance）的集合。 OpenStack提供了一个操作平台，或工具包，用于编排云。

OpenStack提供开放源码软件，建立公共和私有云。 OpenStack是一个社区和一个项目，以及开放源码软件，以帮助企业运行的虚拟计算或者存储云。 OpenStackd开源项目由社区维护，包括OpenStack计算（代号为Nova），OpenStack对象存储（代号为SWIFT），并OpenStack镜像服务（代号Glance）的集合。 OpenStack提供了一个操作平台，或工具包，用于编排云。

2 Openstack主要组件
• Horizon
– 用于管理Openstack各种服务的、基于web的管理接口
– 通过图形界面实现创建用户、管理网络、启动实例等操作
• Keystone
– 为其他服务提供认证和授权的集中身份管理服务
– 也提供了集中的目录服务
– 支持多种身份认证模式,如果密码认证、令牌认证、以及AWS(亚马逊Web服务)登陆
– 为用户和其他服务提供了SSO认证服务
• Neutron
– 一种软件定义网络服务
– 用于创建网络、子网、路由器、管理浮动IP地址
– 可以实现虚拟交换机、虚拟路由器
– 可用于在项目中创建VPN
• Cinder
– 为虚拟机管理存储卷的服务
– 为运行在Nova中的实例提供永久的块存储
– 可以通过快照进行数据备份
– 经常应用在实例存储环境中,如果数据库文件
• Nova
– 在节点上用于管理虚拟机的服务
– Nova是一个分布式的服务,能够与Keystone交互实现认证,与Glance交互实现镜像管理
– Nova被设计成在标准硬件上能够进行水平扩展
– 启动实例时,如果有需要则下载镜像
• Glance
– 扮演虚拟机镜像注册的角色
– 允许用户为直接存储拷贝服务器镜像
– 这些镜像可以用于新建虚拟机的模板

3 Openstack的网络拓扑结构图
整个OpenStack是由控制节点，计算节点，网络节点，存储节点四大部分组成。（这四个节点也可以安装在一台机器上，单机部署）
控制节点负责对其余节点的控制，包含虚拟机建立，迁移，网络分配，存储分配等等
计算节点负责虚拟机运行
网络节点负责对外网络与内网络之间的通信
存储节点负责对虚拟机的额外存储管理等等

4 OpenStack三个组件
计算，存储，镜像。
OpenStack计算是一个云控制器，用来启动一个用户或一个组的虚拟实例，它也用于配置每个实例或项目中包含多个实例为某个特定项目的联网。
OpenStack对象存储是一个在具有内置冗余和容错的大容量系统中存储对象的系统。对象存储有各种应用，如备份或存档数据，存储图形或视频（流媒体数据传输到用户的浏览器），储存二级或三级静态数据，发展与数据存储集成新的应用程序，当预测存储容量困难时存储数据，创造弹性和灵活的云存储Web应用程序。
OpenStack镜像服务是一个查找和虚拟机图像检索系统。它可以配置三种方式：使用OpenStack对象存储来存储图像;使用亚马逊S3直接存储，或使用S3对象存储作为S3访问中间存储。
终端用户通过nova-api 接口与Openstack 计算交互。
OpenStack计算守护进程通过队列的交换信息（行动）和数据库（信息）进行API请求。
OpenStack Glance是一个完全独立的基础上设施。

5 OpenStack计算设施----Nova
Nova是OpenStack计算的弹性控制器。OpenStack云实例生命期所需的各种动作都将由Nova进行处理和支撑，这就意味着Nova以管理平台的身份登场，负责管理整个云的计算资源、网络、授权及测度。虽然Nova本身并不提供任何虚拟能力，但是它将使用libvirt API与虚拟机的宿主机进行交互。Nova通过Web服务API来对外提供处理接口，而且这些接口与Amazon的Web服务接口是兼容的。
（1）功能及特点
实例生命周期管理
计算资源管理
网络与授权管理
基于REST的API
异步连续通信
支持各种宿主：Xen、XenServer/XCP、KVM、UML、VMware vSphere及Hyper-V
（2）OpenStack计算部件
Nova弹性云包含以下主要部分：
API Server（nova-api）
消息队列（rabbit-mq server）
运算工作站（nova-compute）
网络控制器（nova-network）
卷管理（nova-volume）
调度器（nova-scheduler）
（3）API服务器（nova-api）
API服务器提供了云设施与外界交互的接口，它是外界用户对云实施管理的唯一通道。通过使用web服务来调用各种EC2的API，接着API服务器便通过消息队列把请求送达至云内目标设施进行处理。作为对EC2-api的替代，用户也可以使用OpenStack的原生API，我们把它叫做“OpenStack API”。
（4）消息队列（Rabbit MQ Server）
OpenStack内部在遵循AMQP（高级消息队列协议）的基础上采用消息队列进行通信。Nova对请求应答进行异步调用，当请求接收后便则立即触发一个回调。由于使用了异步通信，不会有用户的动作被长置于等待状态。例如，启动一个实例或上传一份镜像的过程较为耗时，API调用就将等待返回结果而不影响其它操作，在此异步通信起到了很大作用，使整个系统变得更加高效。
（5）运算工作站（nova-compute）
运算工作站的主要任务是管理实例的整个生命周期。他们通过消息队列接收请求并执行，从而对实例进行各种操作。在典型实际生产环境下，会架设许多运算工作站，根据调度算法，一个实例可以在可用的任意一台运算工作站上部署。
（6）网络控制器（nova-network）
网络控制器处理主机的网络配置，例如IP地址分配，配置项目VLAN，设定安全群组以及为计算节点配置网络。
（7）卷工作站（nova-volume）
卷工作站管理基于LVM的实例卷，它能够为一个实例创建、删除、附加卷，也可以从一个实例中分离卷。卷管理为何如此重要？因为它提供了一种保持实例持续存储的手段，比如当结束一个实例后，根分区如果是非持续化的，那么对其的任何改变都将丢失。可是，如果从一个实例中将卷分离出来，或者为这个实例附加上卷的话，即使实例被关闭，数据仍然保存其中。这些数据可以通过将卷附加到原实例或其他实例的方式而重新访问。因此，为了日后访问，重要数据务必要写入卷中。这种应用对于数据服务器实例的存储而言，尤为重要。
（8）调度器（nova-scheduler）
调度器负责把nova-API调用送达给目标。调度器以名为“nova-schedule”的守护进程方式运行，并根据调度算法从可用资源池中恰当地选择运算服务器。有很多因素都可以影响调度结果，比如负载、内存、子节点的远近、CPU架构等等。强大的是nova调度器采用的是可插入式架构。目前nova调度器使用了几种基本的调度算法：
随机化：主机随机选择可用节点；
可用化：与随机相似，只是随机选择的范围被指定；
简单化：应用这种方式，主机选择负载最小者来运行实例。负载数据可以从别处获得，如负载均衡服务器。

6 OpenStack镜像服务器----Glance
OpenStack镜像服务器是一套虚拟机镜像发现、注册、检索系统，我们可以将镜像存储到以下任意一种存储中：
本地文件系统（默认）
OpenStack对象存储
S3直接存储
S3对象存储（作为S3访问的中间渠道）
HTTP（只读）
（1）功能及特点
提供镜像相关服务
（2）Glance构件
Glance控制器
Glance注册器

7 OpenStack存储设施----Swift
Swift为OpenStack提供一种分布式、持续虚拟对象存储，它类似于Amazon Web Service的S3简单存储服务。Swift具有跨节点百级对象的存储能力。Swift内建冗余和失效备援管理，也能够处理归档和媒体流，特别是对大数据（千兆字节）和大容量（多对象数量）的测度非常高效。
（1）功能及特点
海量对象存储
大文件（对象）存储
数据冗余管理
归档能力-----处理大数据集
为虚拟机和云应用提供数据容器
处理流媒体
对象安全存储
备份与归档
良好的可伸缩性
（2）Swift组件
Swift账户
Swift容器
Swift对象
Swift代理
Swift RING
（3）Swift代理服务器
用户都是通过Swift-API与代理服务器进行交互，代理服务器正是接收外界请求的门卫，它检测合法的实体位置并路由它们的请求。
此外，代理服务器也同时处理实体失效而转移时，故障切换的实体重复路由请求。
（4）Swift对象服务器
对象服务器是一种二进
制存储，它负责处理本地存储中的对象数据的存储、检索和删除。对象都是文件系统中存放的典型的二进制文件，具有扩展文件属性的元数据（xattr）。
注意：xattr格式被Linux中的ext3/4，XFS，Btrfs，JFS和ReiserFS所支持，但是并没有有效测试证明在XFS，JFS，ReiserFS，Reiser4和ZFS下也同样能运行良好。不过，XFS被认为是当前最好的选择。

（5）Swift容器服务器
容器服务器将列出一个容器中的所有对象，默认对象列表将存储为SQLite文件（译者注：也可以修改为MySQL，安装中就是以MySQL为例）。容器服务器也会统计容器中包含的对象数量及容器的存储空间耗费。

（6）Swift账户服务器
账户服务器与容器服务器类似，将列出容器中的对象。

（7）Ring（索引环）
Ring容器记录着Swift中物理存储对象的位置信息，它是真实物理存储位置的实体名的虚拟映射，类似于查找及定位不同集群的实体真实物理位置的索引服务。这里所谓的实体指账户、容器、对象，它们都拥有属于自己的不同的Rings。

8 OpenStack认证服务（Keystone）
（1）Keystone为所有的OpenStack组件提供认证和访问策略服务，它依赖自身REST（基于Identity API）系统进行工作，主要对（但不限于）Swift、Glance、Nova等进行认证与授权。事实上，授权通过对动作消息来源者请求的合法性进行鉴定。如下图所示：
Keystone采用两种授权方式，一种基于用户名/密码，另一种基于令牌（Token）。除此之外，Keystone提供以下三种服务：
令牌服务：含有授权用户的授权信息
目录服务：含有用户合法操作的可用服务列表
策略服务：利用Keystone具体指定用户或群组某些访问权限
（2）认证服务组件
服务入口：如Nova、Swift和Glance一样每个OpenStack服务都拥有一个指定的端口和专属的URL，我们称其为入口（endpoints）。
区位：在某个数据中心，一个区位具体指定了一处物理位置。在典型的云架构中，如果不是所有的服务都访问分布式数据中心或服务器的话，则也称其为区位。
用户：Keystone授权使用者
译者注：代表一个个体，OpenStack以用户的形式来授权服务给它们。用户拥有证书（credentials），且可能分配给一个或多个租户。经过验证后，会为每个单独的租户提供一个特定的令牌。[来源：//www.jb51.net/article/96989.htm]
服务：总体而言，任何通过Keystone进行连接或管理的组件都被称为服务。举个例子，我们可以称Glance为Keystone的服务。
角色：为了维护安全限定，就云内特定用户可执行的操作而言，该用户关联的角色是非常重要的。
译者注：一个角色是应用于某个租户的使用权限集合，以允许某个指定用户访问或使用特定操作。角色是使用权限的逻辑分组，它使得通用的权限可以简单地分组并绑定到与某个指定租户相关的用户。
租间：租间指的是具有全部服务入口并配有特定成员角色的一个项目。
译者注：一个租间映射到一个Nova的“project-id”，在对象存储中，一个租间可以有多个容器。根据不同的安装方式，一个租间可以代表一个客户、帐号、组织或项目。

9 OpenStack管理的Web接口----Horizon
Horizon是一个用以管理、控制OpenStack服务的Web控制面板，它可以管理实例、镜像、创建密匙对，对实例添加卷、操作Swift容器等。除此之外，用户还可以在控制面板中使用终端（console）或VNC直接访问实例。总之，Horizon具有如下一些特点：
实例管理：创建、终止实例，查看终端日志，VNC连接，添加卷等
访问与安全管理：创建安全群组，管理密匙对，设置浮动IP等
偏好设定：对虚拟硬件模板可以进行不同偏好设定
镜像管理：编辑或删除镜像
查看服务目录
管理用户、配额及项目用途
用户管理：创建用户等
卷管理：创建卷和快照
对象存储处理：创建、删除容器和对象
为项目下载环境变量

10 Openstack案例
对于OpenStack的具体安装，可以查看“五岳之巅”的博客 http://blog.chinaunix.net/uid/22414998/frmd/154248.html 讲解较为详细。
以下内容是如何在linux命令行下进行nova-compute实例的相关操作，这些操作均可以通过OpenStack的Horizon服务在web界面上完成，本文只是作者笔记，供参考用。
客户端系统环境：
ubuntu-desktop-12.04
python-novaclient glance-client swift kvm
export SERVICE_TOKEN=admin
export OS_TENANT_NAME=admin
export OS_USERNAME=admin
export OS_PASSWORD=admin
export OS_AUTH_URL="http://192.168.111.128:5000/v2.0/"
export SERVICE_ENDPOINT=http://192.168.111.128:35357/v2.0
以上是客户端主机系统的基本要求，本文中由于Nova是安装在192.168.111.128上面的，所以读者应根据实际情况设置。
 
在拥有以上的环境后，可以通过命令操作来查看、创建、管理实例。 
查看Image的信息：
root@client:~# nova image-list
+--------------------------------------+--------------+--------+--------+
|                  ID                  |     Name     | Status | Server |
+--------------------------------------+--------------+--------+--------+
| 50a278f9-54e2-485c-9592-f0e485689df0 | ubuntu-12.04 | ACTIVE |        |
+--------------------------------------+--------------+--------+--------+
root@client:~# nova image-list
+--------------------------------------+--------------+--------+--------+
|                  ID                  |     Name     | Status | Server |
+--------------------------------------+--------------+--------+--------+
| 50a278f9-54e2-485c-9592-f0e485689df0 | ubuntu-12.04 | ACTIVE |        |
+--------------------------------------+--------------+--------+--------+
查看可用的kvm实例化配置信息：
root@client:~# nova flavor-list
+----+--------------+-----------+------+-----------+------+-------+-------------+
| ID |     Name     | Memory_MB | Disk | Ephemeral | Swap | VCPUs | RXTX_Factor |
+----+--------------+-----------+------+-----------+------+-------+-------------+
| 1  | m1.tiny      | 512       | 0    | 0         |      | 1     | 1.0         |
| 2  | m1.small     | 2048      | 10   | 20        |      | 1     | 1.0         |
| 3  | m1.medium    | 4096      | 10   | 40        |      | 2     | 1.0         |
| 4  | m1.large     | 8192      | 10   | 80        |      | 4     | 1.0         |
| 5  | m1.xlarge    | 16384     | 10   | 160       |      | 8     | 1.0         |
| 6  | svr_2-512-10 | 512       | 10   | 20        |      | 2     | 1.0         |
+----+--------------+-----------+------+-----------+------+-------+-------------+
 
启动一个实例：
root@client:~# nova boot --flavor=1 --image=50a278f9-54e2-485c-9592-f0e485689df0 testserver
+-------------------------------------+--------------------------------------+
|               Property              |                Value                 |
+-------------------------------------+--------------------------------------+
| OS-DCF:diskConfig                   | MANUAL                               |
| OS-EXT-SRV-ATTR:host                | None                                 |
| OS-EXT-SRV-ATTR:hypervisor_hostname | None                                 |
| OS-EXT-SRV-ATTR:instance_name       | instance-00000004                    |
| OS-EXT-STS:power_state              | 0                                    |
| OS-EXT-STS:task_state               | scheduling                           |
| OS-EXT-STS:vm_state                 | building                             |
| accessIPv4                          |                                      |
| accessIPv6                          |                                      |
| adminPass                           | sJcaPJYp22Fc                         |
| config_drive                        |                                      |
| created                             | 2012-12-22T06:36:02Z                 |
| flavor                              | m1.tiny                              |
| hostId                              |                                      |
| id                                  | 6b92ce5a-5499-4b42-a346-13b78e28d3e8 |
| image                               | ubuntu-12.04                         |
| key_name                            |                                      |
| metadata                            | {}                                   |
| name                                | testserver                           |
| progress                            | 0                                    |
| status                              | BUILD                                |
| tenant_id                           | dac9bcbdf94d4764b1fc919b126727ca     |
| updated                             | 2012-12-22T06:36:02Z                 |
| user_id                             | bb1468f01a8548cf8160836ca6a82679     |
+-------------------------------------+--------------------------------------+
该实例使用flavor中ID为1的资源配置，镜像使用ID为50a278f9-54e2-485c-9592-f0e485689df0 的镜像，实例的显示名称为testserver
启动完该实例后，直观的从web上看：


命令行查看实例情况：
root@client:~# nova list
+--------------------------------------+------------+--------+----------+
|                  ID                  |    Name    | Status | Networks |
+--------------------------------------+------------+--------+----------+
| 6b92ce5a-5499-4b42-a346-13b78e28d3e8 | testserver | ACTIVE |          |
+--------------------------------------+------------+--------+----------+
 
 查看实例的详细信息：
root@client:~# nova show 6b92ce5a-5499-4b42-a346-13b78e28d3e8
+-------------------------------------+----------------------------------------------------------+
|               Property              |                          Value                           |
+-------------------------------------+----------------------------------------------------------+
| OS-DCF:diskConfig                   | MANUAL                                                   |
| OS-EXT-SRV-ATTR:host                | svr1                                                     |
| OS-EXT-SRV-ATTR:hypervisor_hostname | None                                                     |
| OS-EXT-SRV-ATTR:instance_name       | instance-00000004                                        |
| OS-EXT-STS:power_state              | 1                                                        |
| OS-EXT-STS:task_state               | None                                                     |
| OS-EXT-STS:vm_state                 | active                                                   |
| accessIPv4                          |                                                          |
| accessIPv6                          |                                                          |
| config_drive                        |                                                          |
| created                             | 2012-12-22T06:36:02Z                                     |
| flavor                              | m1.tiny                                                  |
| hostId                              | 0cb64f5bbe94b0a71f29d17025afe844d0fd047f8dae71d0142ebae1 |
| id                                  | 6b92ce5a-5499-4b42-a346-13b78e28d3e8                     |
| image                               | ubuntu-12.04                                             |
| key_name                            |                                                          |
| metadata                            | {}                                                       |
| name                                | testserver                                               |
| progress                            | 0                                                        |
| status                              | ACTIVE                                                   |
| tenant_id                           | dac9bcbdf94d4764b1fc919b126727ca                         |
| updated                             | 2012-12-22T06:36:05Z                                     |
| user_id                             | bb1468f01a8548cf8160836ca6a82679                         |
+-------------------------------------+----------------------------------------------------------+




二、ms相关
1 解释OpenStack。
OpenStack是一种开放源代码和免费的软件工具集或云计算平台, 用于管理和构建私有和公共云的云计算平台。
OpenStack被称为云计算的未来。

2 OpenStack的模块化体系结构组件是什么？
以下是OpenStack模块化体系结构组件的列表：
仪表板
计算
联网
对象存储
块存储
身份服务
影像服务
遥测
编排
数据库服务等

3 使用OpenStack有哪些优点/好处？
使用OpenStack的优点/好处：
OpenStack可用于开发任何软件即服务(SAAS 应用程序, 进行新开发或改进现有解决方案。
它可以用作为IT用户提供自助服务存储的强大基础。
它以较低的成本提供易于处理的存储。
它可以提供按需目标或具有更高可扩展性的块存储。
通过将在VMware上运行的虚拟机切换到OpenStack, 企业可以节省大量许可费用。

4 在OpenStack中什么是”角色”和”租户”？
角色：指定用户的授权级别。
租户：它指定一组用户。

5 OpenStack计算允许哪些存储类型？
OpenStack支持两种类型的存储：
1)永久存储或卷存储
2)临时存储
持久存储/卷存储：它是持久的, 独立于任何特定实例。此存储由用户创建。持久性存储分为三种类型：
对象存储：用于通过REST API访问二进制对象。
块存储：通过附加卷的当前VM实例, 提供对块存储设备的访问。
共享文件系统存储：它提供了一组服务来一起管理多个文件, 以进行存储并一次与多个用户交换。
临时存储：临时存储指定单个实例。这是一个临时且短暂的存储, 在VM终止后会消失。

6 什么是虚拟机监控程序？ OpenStack支持哪种类型的管理程序？
虚拟机监控程序是用于创建和运行虚拟机的软件或硬件工具。 OpenStack支持各种虚拟机管理程序, 例如VMware, Citrix和Microsoft等。

7 OpenStack中最重要的身份服务是什么？
Keystone是OpenStack中最重要和首选的身份服务。它执行完整的OpenStack Identity API。

8 OpenStack中使用了哪些不同的网络选项？
Open Stack中使用的网络选项包括：
Flat DHCP Network Manager：用于从VM实例的子网中获取IP地址, 但通过DHCP(动态主机配置协议 分配给VM的IP地址。
Flat Network Manager：用于从VM实例的子网中获取IP地址, 然后在启动时注入到映像中。
VLAN网络管理器：：VLAN为VM提供更安全和独立的网络。它具有一个物理交换机, 可为每个租户提供单独的虚拟网络以及单独的IP范围和网桥。这是更可取的选择。

9 哪些命令用于暂停和取消暂停(恢复 实例？
暂停：$ nova pause INSTANCE_NAME
取消暂停：$ novaunpause INSTANCE_NAME

10 OpenStack映像存储在哪里？
Glance是OpenStack的映像管理器。因此, OpneStack映像存储在：
Default: /var/lib/glance/images/

11 OpenStack中的令牌是什么？
令牌是一种身份验证类型, 例如基于密码的验证。当用户插入凭据并以Keystone用户身份进行身份验证时, 将生成令牌, 然后可以使用令牌来访问OpenStack服务, 而无需任何重新验证。

12 如何创建令牌？
用户首先需要验证其Keystone凭据以创建令牌。

13 解释OpenStack Python SDK吗？
Python SDK(软件开发工具包 用于帮助用户通过调用Python对象来编写用于在Python中执行自动化任务的应用程序。
它提供了一个平台, 可以在一个地方使用多个OpenStack服务。

14 解释API服务器在OpenStack中的作用吗？
在OpenStack中, API服务器为外部世界提供了与云基础架构进行交互的接口。

15 在OpenStack中用于生成密钥对的命令有哪些？
用于在OpenStack中生成密钥对的命令：
ssh-keygen
光盘
nova keypair-add -pub_key id_rsa.pub mykey

16 OpenStack中联网需要哪些硬件？
在OpenStack中, 可以使用以下硬件进行联网：
网路
路由器
子网路
港口
供应商插件

17 哪个命令用于管理OpenStack中的浮动IP地址？
新星浮动IP *

18 解释Cinder在OpenStack中的用法？
OpenStack Cinder用于在OpenStack上下文中处理块存储。

19 在OpenStack中$ nova float-ip-pool-list命令的用途是什么？
$ nova float-ip-pool-list命令用于列出OpenStack中的IP地址信息。

20 在OpenStack中解释术语”风味”吗？
术语”风味”是服务器的可用硬件配置, 它定义了可以启动的虚拟服务器的大小。

---------------------------------------------------------------------------------------------------------------
------------------------------------------openstack basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------pig basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识




---------------------------------------------------------------------------------------------------------------
------------------------------------------pig basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------python basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 Python 
一种解释型、面向对象、动态数据类型的高级程序设计语言。
Python 由 Guido van Rossum 于 1989 年底发明，第一个公开发行版发行于 1991 年。
像 Perl 语言一样, Python 源代码同样遵循 GPL(GNU General Public License) 协议。
官方宣布，2020 年 1 月 1 日， 停止 Python 2 的更新。
Python 2.7 被确定为最后一个 Python 2.x 版本。
Python 是一个高层次的结合了解释性、编译性、互动性和面向对象的脚本语言。
Python 的设计具有很强的可读性，相比其他语言经常使用英文关键字，其他语言的一些标点符号，它具有比其他语言更有特色语法结构。
Python 是一种解释型语言： 这意味着开发过程中没有了编译这个环节。类似于PHP和Perl语言。
Python 是交互式语言： 这意味着，您可以在一个 Python 提示符 >>> 后直接执行代码。
Python 是面向对象语言: 这意味着Python支持面向对象的风格或代码封装在对象的编程技术。
Python 是初学者的语言：Python 对初级程序员而言，是一种伟大的语言，它支持广泛的应用程序开发，从简单的文字处理到 WWW 浏览器再到游戏


2 执行Python程序
对于大多数程序语言，第一个入门编程代码便是 "Hello World！"，以下代码为使用 Python 输出 "Hello World！"：
#!/usr/bin/python
print("Hello, World!")
运行实例 »
Python 3.0+ 版本已经把 print 作为一个内置函数，输出 "Hello World！" 代码如下：
实例(Python 3.0+)
#!/usr/bin/python3
print("Hello, World!")

3 Unix & Linux 平台安装 Python:
以下为在 Unix & Linux 平台上安装 Python 的简单步骤：
打开 WEB 浏览器访问https://www.python.org/downloads/source/
选择适用 于Unix/Linux 的源码压缩包。
下载及解压压缩包。
如果你需要自定义一些选项修改Modules/Setup
执行 ./configure 脚本
make
make install


二、ms相关
2、Python的主要功能是什么？
Python是一种解释型语言。与C语言等语言不同，Python不需要在运行之前进行编译。
Python是动态语言，当您声明变量或类似变量时，您不需要声明变量的类型。
Python适合面向对象的编程，因为它允许类的定义以及组合和继承。Python没有访问说明（如C ++的public，private）。
在Python中，函数是第一类对象。它们可以分配给变量。类也是第一类对象
编写Python代码很快，但运行比较慢。Python允许基于C的扩展，例如numpy函数库。
Python可用于许多领域。Web应用程序开发，自动化，数学建模，大数据应用程序等等。它也经常被用作“胶水”代码。

3、Python是通用编程语言吗？
Python能够编写脚本，但从一般意义上讲，它被认为是一种通用编程语言。

4、Python是如何解释语言的？
Python在运行之前不需要对程序进行解释。因此，Python是一种解释型语言。

5、什么是pep？
PEP代表Python Enhancement Proposal。它是一组规则，指定如何格式化Python代码以获得最大可读性。

6、如何在Python中管理内存？
python中的内存管理由Python私有堆空间管理。所有Python对象和数据结构都位于私有堆中。程序员无权访问此私有堆。python解释器负责处理这个问题。
Python对象的堆空间分配由Python的内存管理器完成。核心API提供了一些程序员编写代码的工具。
Python还有一个内置的垃圾收集器，它可以回收所有未使用的内存，并使其可用于堆空间。

7、Python中的命名空间是什么？
命名空间是一个命名系统，用于确保名称是唯一性，以避免命名冲突。

8、什么是PYTHONPATH？
它是导入模块时使用的环境变量。每当导入模块时，也会查找PYTHONPATH以检查各个目录中是否存在导入的模块。解释器使用它来确定要加载的模块。

9、什么是python模块？Python中有哪些常用的内置模块？
Python模块是包含Python代码的.py文件。此代码可以是函数类或变量。一些常用的内置模块包括：sys、math、random、data time、JSON。

10、Python中的局部变量和全局变量是什么？
全局变量：在函数外或全局空间中声明的变量称为全局变量。这些变量可以由程序中的任何函数访问。
局部变量：在函数内声明的任何变量都称为局部变量。此变量存在于局部空间中，而不是全局空间中。

11、python是否区分大小写？
是。Python是一种区分大小写的语言。

12、什么是Python中的类型转换？
类型转换是指将一种数据类型转换为另一种数据类型。
int（）  - 将任何数据类型转换为整数类型
float（）  - 将任何数据类型转换为float类型
ord（）  - 将字符转换为整数
hex（） - 将整数转换为十六进制
oct（）  - 将整数转换为八进制
tuple（） - 此函数用于转换为元组。
set（） - 此函数在转换为set后返回类型。
list（） - 此函数用于将任何数据类型转换为列表类型。
dict（） - 此函数用于将顺序元组（键，值）转换为字典。
str（） - 用于将整数转换为字符串。
complex（real，imag）  - 此函数将实数转换为复数（实数，图像）数。

13、如何在Windows上安装Python并设置路径变量？
要在Windows上安装Python，请按照以下步骤操作：
从以下链接安装python：https：//http://www.python.org/downloads/
下载之后，将其安装在您的PC上。在命令提示符下使用以下命令查找PC上安装PYTHON的位置：cmd python。
然后转到高级系统设置并添加新变量并将其命名为PYTHON_NAME并粘贴复制的路径。
查找路径变量，选择其值并选择“编辑”。
如果值不存在，请在值的末尾添加分号，然后键入％PYTHON_HOME％

14、python中是否需要缩进？
缩进是Python必需的。它指定了一个代码块。循环，类，函数等中的所有代码都在缩进块中指定。通常使用四个空格字符来完成。如果您的代码没有必要缩进，它将无法准确执行并且也会抛出错误。

15、Python数组和列表有什么区别？
Python中的数组和列表具有相同的存储数据方式。但是，数组只能包含单个数据类型元素，而列表可以包含任何数据类型元素。

16、Python中的函数是什么？
函数是一个代码块，只有在被调用时才会执行。要在Python中定义函数，需要使用def关键字。

17、什么是__init__?
__init__是Python中的方法或者结构。在创建类的新对象/实例时，将自动调用此方法来分配内存。所有类都有__init__方法。

18、什么是lambda函数？
lambda函数也叫匿名函数，该函数可以包含任意数量的参数，但只能有一个执行操作的语句。

19、Python中的self是什么？
self是类的实例或对象。在Python中，self包含在第一个参数中。但是，Java中的情况并非如此，它是可选的。它有助于区分具有局部变量的类的方法和属性。init方法中的self变量引用新创建的对象，而在其他方法中，它引用其方法被调用的对象。

21、[:: - 1}表示什么？
[:: - 1]用于反转数组或序列的顺序。

22、如何在Python中随机化列表中的元素？
可以使用shuffle函数进行随机列表元素。举例如下：
代码输出为：

23、什么是python迭代器？
迭代器是可以遍历或迭代的对象。

24、如何在Python中生成随机数？
random模块是用于生成随机数的标准模块。该方法定义为：
random.random()方法返回[0,1]范围内的浮点数。该函数生成随机浮点数。随机类使用的方法是隐藏实例的绑定方法。可以使用Random的实例来显示创建不同线程实例的多线程程序。其中使用的其他随机生成器是：
randrange(a,b)：它选择一个整数并定义[a，b]之间的范围。它通过从指定范围中随机选择元素来返回元素。它不构建范围对象。
uniform(a,b)：它选择一个在[a，b)范围内定义的浮点数
normalvariate(mean,sdev)：它用于正态分布，其中mean是平均值，sdev是用于标准偏差的sigma。
使用和实例化的Random类创建一个独立的多个随机数生成器。

25、range＆xrange有什么区别？
在大多数情况下，xrange和range在功能方面完全相同。它们都提供了一种生成整数列表的方法，唯一的区别是range返回一个Python列表对象，x range返回一个xrange对象。这就表示xrange实际上在运行时并不是生成静态列表。它使用称为yielding的特殊技术根据需要创建值。该技术与一种称为生成器的对象一起使用。因此如果你有一个非常巨大的列表，那么就要考虑xrange。

26、如何在python中写注释？
Python中的注释以＃字符开头。也可以使用doc-strings（三重引号中包含的字符串）进行注释。

27、什么是pickling和unpickling？
Pickle模块接受任何Python对象并将其转换为字符串表示形式，并使用dump函数将其转储到文件中，此过程称为pickling。从存储的字符串中检索原始Python对象的过程称为unpickling。

28、python中的生成器是什么？
返回可迭代项集的函数称为生成器。

29、你如何把字符串的第一个字母大写？
在Python中，capitalize()函数可以将字符串的第一个字母大写。如果字符串在开头已经包含大写字母，那么它将返回原始字符串。

30、如何将字符串转换为全小写？
要将字符串转换为小写，可以使用lower()函数。

31、如何在python中注释多行？
注释多行代码时。所有要注释的行都要在开头前加#。还可以使用快捷方式来注释多行，就是按住Ctrl键并在每个想要包含＃字符的地方左键单击并键入一次＃。

32、什么是Python中的文档Docstrings？
Docstrings实际上不是注释，它们是文档字符串。这些文档字符串在三引号内。它们没有分配给任何变量，因此有时也用于注释。

33、operators中的is、not和in各有什么功能？
Operators是特殊函数，它们比较一个或多个值并产生相应的结果。其中is：当2个操作数为true时返回true（例如：“a”是'a'）
not：返回布尔值的倒数
in：检查某个元素是否存在于某个序列中

34、Python中help()和dir()函数的用法是什么？
Help()和dir()这两个函数都可以从Python解释器直接访问，并用于查看内置函数的合并转储。
help()函数：help()函数用于显示文档字符串，还可以查看与模块，关键字，属性等相关的使用信息。
dir()函数：dir()函数用于显示定义的符号。

35、当Python退出时，为什么不清除所有分配的内存？
当Python退出时，尤其是那些对其他对象具有循环引用的Python模块或者从全局名称空间引用的对象并没有被解除分配或释放。
无法解除分配C库保留的那些内存部分。
退出时，由于拥有自己的高效清理机制，Python会尝试取消分配/销毁其他所有对象。

36、Python中的字典是什么？
Python中的内置数据类型称为字典。它定义了键和值之间的一对一关系。字典包含一对键及其对应的值。字典由键索引。

37、如何在python中使用三元运算符？
三元运算符是用于显示条件语句的运算符。这包含true或false值，并且必须为其评估语句。其基本语法为：
三元运算符是用于显示条件语句的运算符。这包含true或false值，并且必须为其评估语句。其基本语法为：
[on_true] if [expression] else [on_false] x，y = 25,50big = x if x <y else y

38、为什么使用* args，** kwargs？
当我们不确定将多少个参数传递给函数，或者我们想要将存储的列表或参数元组传递给函数时，我们使用* args。**当我们不知道将多少关键字参数传递给函数时使用kwargs，或者它可以用于将字典的值作为关键字参数传递。标识符args和kwargs是一个约定，你也可以使用* bob和** billy。

39、len()函数有什么作用？
len()函数可用于确定字符串，列表，数组等的长度。

40、在Python中split()，sub()，subn()功能。
如果要修改字符串，Python的“re”模块提供了3种方法。他们是：
split() - 使用正则表达式模式将给定字符串“拆分”到列表中。
sub() - 查找正则表达式模式匹配的所有子字符串，然后用不同的字符串替换它们
subn() - 它类似于sub()，并且还返回新字符串。

41、什么是负指数，功能是什么？
Python中的序列是索引的，它由正数和负数组成。积极的数字使用'0'作为第一个索引，'1'作为第二个索引，进程继续使用。
负数的索引从'-1'开始，表示序列中的最后一个索引，' - 2'作为倒数第二个索引，序列像正数一样前进。
负索引用于从字符串中删除任何换行符，并允许该字符串除了作为S [： - 1]给出的最后一个字符。负索引还用于显示索引以正确的顺序表示字符串。

42、什么是Python包？
Python包是包含多个模块的命名空间。

43、如何在Python中删除文件？
要在Python中删除文件，您需要导入OS模块。之后，您需要使用os.remove()函数。

44、什么是python的内置类型？
Python中的内置类型如下：整型、浮点型、复数、字符串、布尔等。

45、NumPy中有哪些操作Python列表的函数？
Python的列表是高效的通用容器。它们支持（相当）有效的插入，删除，追加和连接，Python的列表推导使它们易于构造和操作。
它们有一定的局限性：它们不支持像素化加法和乘法等“向量化”操作，并且它们可以包含不同类型的对象这一事实意味着Python必须存储每个元素的类型信息，并且必须执行类型调度代码在对每个元素进行操作时。
NumPy不仅效率更高; 它也更方便。你可以免费获得大量的向量和矩阵运算，这有时可以避免不必要的工作。它们也得到有效实施。
NumPy数组更快，你可以使用NumPy，FFT，卷积，快速搜索，基本统计，线性代数，直方图等内置。

46、如何将值添加到python数组？
可以使用append()，extend()和insert(i，x)函数将元素添加到数组中。

47、如何删除python数组的值？
可以使用pop()或remove()方法删除数组元素。这两个函数之间的区别在于前者返回已删除的值，而后者则不返回。

48、Python有OOps概念吗？
Python是一种面向对象的编程语言。这意味着可以通过创建对象模型在python中解决任何程序。同时Python可以被视为程序语言和结构语言。

49、深拷贝和浅拷贝有什么区别？
在创建新实例类型时使用浅拷贝，并保留在新实例中复制的值。浅拷贝用于复制引用指针，就像复制值一样。这些引用指向原始对象，并且在类的任何成员中所做的更改也将影响它的原始副本。浅拷贝允许更快地执行程序，它取决于所使用的数据的大小。
深拷贝用于存储已复制的值。深拷贝不会将引用指针复制到对象。它引用一个对象，并存储一些其他对象指向的新对象。原始副本中所做的更改不会影响使用该对象的任何其他副本。由于为每个被调用的对象创建了某些副本，因此深拷贝会使程序的执行速度变慢。

50、如何在Python中实现多线程？
Python有一个多线程库，但是用多线程来加速代码的效果并不是那么的好，
Python有一个名为Global Interpreter Lock（GIL）的结构。GIL确保每次只能执行一个“线程”。一个线程获取GIL执行相关操作，然后将GIL传递到下一个线程。
虽然看起来程序被多线程并行执行，但它们实际上只是轮流使用相同的CPU核心。
所有这些GIL传递都增加了执行的开销。这意味着多线程并不能让程序运行的更快。

---------------------------------------------------------------------------------------------------------------
------------------------------------------python basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------redis basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识

1 Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、一个高性能的key-value数据库。并提供多种语言的API。说到Key-Value数据库NoSQL数据库可以想到MongoDB。和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set --有序集合)和hash（哈希类型）。这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，redis支持各种不同方式的排序。与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步。 Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。

2 Redis 与其他 key - value 缓存产品有以下三个特点：
@Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。
@Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。
@Redis支持数据的备份，即master-slave模式的数据备份。 

3  Redis是一款开源的、高性能的键-值存储（key-value store）。
它常被称作是一款数据结构服务器（data structure server）。Redis的键值可以包括字符串（strings）类型，同时它还包括哈希（hashes）、列表（lists）、集合（sets）和 有序集合（sorted sets）等数据类型。 对于这些数据类型，你可以执行原子操作。例如：对字符串进行附加操作（append）；递增哈希中的值；向列表中增加元素；计算集合的交集、并集与差集等。为了获得优异的性能，Redis采用了内存中（in-memory）数据集（dataset）的方式。同时，Redis支持数据的持久化，你可以每隔一段时间将数据集转存到磁盘上（snapshot），或者在日志尾部追加每一条操作命令（append only file,aof）。Redis同样支持主从复制（master-slave replication），并且具有非常快速的非阻塞首次同步（ non-blocking first synchronization）、网络断开自动重连等功能。同时Redis还具有其它一些特性，其中包括简单的事物支持、发布订阅 （ pub/sub）、管道（pipeline）和虚拟内存（vm）等 。Redis具有丰富的客户端，支持现阶段流行的大多数编程语言。

4 redis优势
1）速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)
2）持丰富数据类型，支持string，list，set，sorted set，hash
3）持事务，但是对事务的支持不够好，如果在一个事务中执行多少操作，有一个操作失败，不会回滚
4）富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除

5 redis的并发竞争问题如何解决
Redis为单进程单线程模式，采用队列模式将并发访问变为串行访问。Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争，但是在Jedis客户端对Redis进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题，这些问题均是由于客户端连接混乱造成。对此有2种解决方法：
1）客户端角度，为保证每个客户端间正常有序与Redis进行通信，对连接进行池化，同时对客户端读写Redis操作采用内部锁synchronized
2）服务器角度，利用setnx实现锁。
对于第一种，需要应用程序自己处理资源的同步，可以使用的方法比较通俗，可以使用synchronized也可以使用lock；第二种需要用到Redis的setnx命令，但是需要注意一些问题。

6 redis事物的了解CAS(check-and-set 操作实现乐观锁 )
和众多其它数据库一样，Redis作为NoSQL数据库也同样提供了事务机制。在Redis中，MULTI/EXEC/DISCARD/WATCH这四个命令是我们实现事务的基石。相信对有关系型数据库开发经验的开发者而言这一概念并不陌生，即便如此，我们还是会简要的列出Redis中事务的实现特征：
1）在事务中的所有命令都将会被串行化的顺序执行，事务执行期间，Redis不会再为其它客户端的请求提供任何服务，从而保证了事物中的所有命令被原子的执行
2）和关系型数据库中的事务相比，在Redis事务中如果有某一条命令执行失败，其后的命令仍然会被继续执行
3）我们可以通过MULTI命令开启一个事务，有关系型数据库开发经验的人可以将其理解为”BEGIN TRANSACTION”语句。在该语句之后执行的命令都将被视为事务之内的操作，最后我们可以通过执行EXEC/DISCARD命令来提交/回滚该事务内的所有操作。这两个Redis命令可被视为等同于关系型数据库中的COMMIT/ROLLBACK语句。
4） 在事务开启之前，如果客户端与服务器之间出现通讯故障并导致网络断开，其后所有待执行的语句都将不会被服务器执行。然而如果网络中断事件是发生在客户端执行EXEC命令之后，那么该事务中的所有命令都会被服务器执行
5） 当使用Append-Only模式时，Redis会通过调用系统函数write将该事务内的所有写操作在本次调用中全部写入磁盘。然而如果在写入的过程中出现系统崩溃，如电源故障导致的宕机，那么此时也许只有部分数据被写入到磁盘，而另外一部分数据却已经丢失。Redis服务器会在重新启动时执行一系列必要的一致性检测，一旦发现类似问题，就会立即退出并给出相应的错误提示。此时，我们就要充分利用Redis工具包中提供的redis-check-aof工具，该工具可以帮助我们定位到数据不一致的错误，并将已经写入的部分数据进行回滚。修复之后我们就可以再次重新启动Redis服务器了

7  WATCH命令和基于CAS的乐观锁
1）在Redis的事务中，WATCH命令可用于提供CAS(check-and-set)功能。假设我们通过WATCH命令在事务执行之前监控了多个Keys，倘若在WATCH之后有任何Key的值发生了变化，EXEC命令执行的事务都将被放弃，同时返回Null multi-bulk应答以通知调用者事务执行失败。例如，我们再次假设Redis中并未提供incr命令来完成键值的原子性递增，
如果要实现该功能，我们只能自行编写相应的代码。其伪码如下：
val = GET mykey
val = val + 1
SET mykey $val	
2）以上代码只有在单连接的情况下才可以保证执行结果是正确的，因为如果在同一时刻有多个客户端在同时执行该段代码，那么就会出现多线程程序中经常出现的一种错误场景–竞态争用(race condition)。比如，客户端A和B都在同一时刻读取了mykey的原有值，假设该值为10，此后两个客户端又均将该值加一后set回Redis服务器，这样就会导致mykey的结果为11，而不是我们认为的12。为了解决类似的问题，我们需要借助WATCH命令的帮助，见如下代码：
WATCH mykey
val = GET mykey
val = val + 1
MULTI
SET mykey $val
EXEC
和此前代码不同的是，新代码在获取mykey的值之前先通过WATCH命令监控了该键，此后又将set命令包围在事务中，这样就可以有效的保证每个连接在执行EXEC之前，如果当前连接获取的mykey的值被其它连接的客户端修改，那么当前连接的EXEC命令将执行失败。这样调用者在判断返回值后就可以获悉val是否被重新设置成功。

8 备份模式和容灾模式
（1）备份模式-主从复制
@常用Redis主从复制，这是最常见的一种架构，一个Master节点，两个Slave节点。客户端写数据的时候是写Master节点，读的时候，是读取两个Slave，这样实现读的扩展，减轻了Master节点读负载。
@这种架构同样是一个Master和两个Slave。不同的是Master和Slave1使用keepalived进行VIP转移。Client连接Master的时候是通过VIP进行连接的。避免了方案一IP更改的情况。
（2）Redis主从复制优点 
实现了对master数据的备份，一旦master出现故障，slave节点可以提升为新的master，顶替旧的master继续提供服务。实现读扩展。使用主从复制架构， 一般都是为了实现读扩展。Master主要实现写功能， Slave实现读的功能。
（3）Redis主从复制不足
当Master出现故障时，Client就与Master端断开连接，无法实现写功能，同时Slave也无法从Master进行复制。当master出现故障后，Client可以连接到Slave1上进行数据操作，但是Slave1就成了一个单点，就出现了经常要避免的单点故障(single point of failure)。
（4）Redis Sentinel架构
使用sentinel实现了Redis的高可用，当master出现故障时，完全无需人工干预即可实现故障转移。避免了对业务的影响，提高了运维工作效率。在部署sentinel的时候，建议使用奇数个sentinel节点，最少三个sentinel节点。
	
9 redis的缓存失效策略和主键失效机制
作为缓存系统都要定期清理无效数据，就需要一个主键失效和淘汰策略。在Redis当中，有生存期的key被称为volatile。在创建缓存时，要为给定的key设置生存期，当key过期的时候（生存期为0）它可能会被删除。
1） 影响生存时间的一些操作
生存时间可以通过使用 DEL 命令来删除整个 key 来移除，或者被 SET 和 GETSET 命令覆盖原来的数据，也就是说，修改key对应的value和使用另外相同的key和value来覆盖以后，当前数据的生存时间不同。
比如说，对一个 key 执行INCR命令，对一个列表进行LPUSH命令，或者对一个哈希表执行HSET命令，这类操作都不会修改 key 本身的生存时间。另一方面，如果使用RENAME对一个 key 进行改名，那么改名后的 key的生存时间和改名前一样。
RENAME命令的另一种可能是，尝试将一个带生存时间的 key 改名成另一个带生存时间的 another_key ，这时旧的 another_key (以及它的生存时间)会被删除，然后旧的 key 会改名为 another_key ，因此，新的 another_key 的生存时间也和原本的 key 一样。使用PERSIST命令可以在不删除 key 的情况下，移除 key 的生存时间，让 key 重新成为一个persistent key 。
2） 如何更新生存时间
可以对一个已经带有生存时间的 key 执行EXPIRE命令，新指定的生存时间会取代旧的生存时间。过期时间的精度已经被控制在1ms之内，主键失效的时间复杂度是O（1）
EXPIRE和TTL命令搭配使用，TTL可以查看key的当前生存时间。设置成功返回 1；当 key 不存在或者不能为 key 设置生存时间时，返回 0
3）最大缓存配置
在 redis 中，允许用户设置最大使用内存大小server.maxmemory默认为0，没有指定最大缓存，如果有新的数据添加，超过最大内存，则会使redis崩溃，所以一定要设置。redis 内存数据集大小上升到一定大小的时候，就会实行数据淘汰策略。

10 六种数据淘汰策略
1） volatile-lru：从已设置过期时间的数据集（server.db[i].expires）挑选最近最少使用的数据淘汰 
2） volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）挑选将要过期的数据淘汰 
3） volatile-random：从已设置过期时间的数据集（server.db[i].expires）任意选择数据淘汰 
4） allkeys-lru：从数据集（server.db[i].dict）挑选最近最少使用的数据淘汰 
5） allkeys-random：从数据集（server.db[i].dict）任意选择数据淘汰 
6） no-enviction（驱逐）禁止驱逐数据 
注意这里的6种机制，volatile和allkeys规定了是对已设置过期时间的数据集淘汰数据还是从全部数据集淘汰数据，后面的lru、ttl以及random是三种不同的淘汰策略，再加上一种no-enviction永不回收的策略

11 使用策略规则：
1） 如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用allkeys-lru
2） 如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用allkeys-random

12 三种数据淘汰策略：
ttl和random比较容易理解，实现也会比较简单。主要是Lru最近最少使用淘汰策略，设计上会对key 按失效时间排序，然后取最先失效的key进行淘汰

13 与memcached相比：
1、Redis和Memcache都是将数据存放在内存中，都是内存数据库。不过memcache还可用于缓存其他东西，例如图片、视频等等；
2、Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，hash等数据结构的存储；
3、虚拟内存--Redis当物理内存用完时，可以将一些很久没用到的value 交换到磁盘；
4、过期策略--memcache在set时就指定，例如set key1 0 0 8,即永不过期。Redis可以通过例如expire 设定，例如expire name 10；
5、分布式--设定memcache集群，利用magent做一主多从;redis可以做一主多从。都可以一主一从；
6、存储数据安全--memcache挂掉后，数据没了；redis可以定期保存到磁盘（持久化）；
7、灾难恢复--memcache挂掉后，数据不可恢复; redis数据丢失后可以通过aof恢复；
8、Redis支持数据的备份，即master-slave模式的数据备份；
9、应用场景不一样：Redis出来作为NoSQL数据库使用外，还能用做消息队列、数据堆栈和数据缓存等；Memcached适合于缓存SQL语句、数据集、用户临时性数据、延迟查询数据和session等。

14 Redis支持五种数据类型
string（字符串）hash（map< string, string>）list（链表）set（没有排序的集合）zset（有序集合）

15  Redis多数据库操作：
主要为了防止key冲突问题，默认情况下，客户端连接到数据库0，可通过修改配置文件redis.conf下的参数来进行修改：
databases 16
可通过select <数据库ID>来进行修改，每个数据库都有自己单独的空间，不用担心key冲突问题。


13 相关命令
（1）redis keys命令
（2）reids字符串命令
	SET key value
	GET key
	STRLEN key
（3）Redis hash 命令
    HDEL key field1 [field2] 
    HGET key field 
    HKEYS key 
（4）Redis 列表命令
   LLEN key 
   LPOP key 
   LPUSH key value1 [value2] 
（5）Redis 集合命令
   SADD key member1 [member2] 
（7）Redis 有序集合命令
   ZADD key score1 member1 [score2 member2] 
   ZCARD key 

14  Redis持久化方式
（1）RDB-在指定时间间隔内生成数据集的时间点快照。
@优点：RDB是一个非常紧凑的文件，它保存了Redis在某个时间点上的数据集。非常适合用于进行备份：比如：每小时备份一次RDB文件，遇上问题可随时还原数据集到不同的版本。非常适合灾难恢复：它只有一个文件,并且内容紧凑，可传输到其他地方。RDB在恢复大数据集时的速度比AOF的恢复速度快；RDB可最大化redis性能，父进程保存RDB文件时要做的是fork一个子进程，然后子进程处理接下来的保存操作，父进程无须执行任何磁盘I/O操作。
@缺点：如需要尽量避免在服务器故障时丢失数据，RDB不适合。每隔一段时间保存数据集的状态，一旦故障会丢失这部分数据。每次保存RDB时，redis都要fork()一个子进程，并由子进程进行实际的持久化工作。在数据集庞大时，fork()会很耗时,造成服务器在某毫秒内停止处理客户端。
@redis.conf里rdb相关配置：
    save 900 1 # 900秒有1个更改，进行数据同步
    save 300 10 # 300秒有10个更改，进行数据同步
    save 60 10000 # 60秒有10000更改，进行数据同步
    dbfilename dump.rdb # 指定rdb备份数据的文件名

（2）AOF-记录服务器执行的所有写操作命令,并在服务器启动时，通过重新执行这些命令来还原数据库
@优点：让redis更耐久，你可以设置不同的 fsync 策略，比如无 fsync ，每秒钟一次 fsync ，或者每次执行写入命令时 fsync 。 AOF 的默认策略为每秒钟 fsync 一次，在这种配置下，Redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据（ fsync 会在后台线程执行，所以主线程可以继续努力地处理命令请求）AOF 文件是一个只进行追加操作的日志文件（append only log） 因此对 AOF 文件的写入不需要进行 seek ， 即使日志因为某些原因而包含了未写入完整的命令（比如写入时磁盘已满，写入中途停机，等等） redis-check-aof 工具也可以轻易地修复这种问题。Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）很轻松。 导出（export）AOF 文件也非常简单： 举个例子， 如果你不小心执行了 FLUSHALL 命令， 但只要 AOF 文件未被重写， 那么只要停止服务器， 移除 AOF 文件末尾的 FLUSHALL 命令， 并重启 Redis ， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。
@缺点：对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB 。 在一般情况下， 每秒 fsync 的性能依然非常高， 而关闭 fsync 可以让 AOF 的速度和 RDB 一样快， 即使在高负荷之下也是如此。
@redis.conf里AOF的相关配置：
    　appendonly yes //启用aof持久化方式
    　appendfilename appendonly.aof // 更新日志文件名，默认为appendonly.aof
    　appendfsync always //每次收到写命令就立即强制写入磁盘，最慢的，但是保证完全的持久化，不推荐使用
    　appendfsync everysec //每秒钟强制写入磁盘一次，在性能和持久化方面做了很好的折中，推荐
    　appendfsync no //完全依赖os，性能最好,持久化没保证


15 影响Redis性能的因素
    * 网络带宽和延迟。在执行基准测试前使用ping快速检测客户端和服务器端的延迟是一个良好的做法。对于带宽，比较好的做法是估计Gbits/s的吞吐量和网络的理论带宽值比较。在很多实际的情况，Redis的吞吐量在网络之前会受限于CPU。
    * CPU也会是一个重要因素。由于单线程的，Redis受益于快速的含有巨大缓存的CPU。
    * 内存的速度和容量对于小的对象影响不大。但对于大于10KB的对象，可能对需要注意。通常购买昂贵的快速内存模块并不是真正的很有效。
    * Redis在虚拟机上运行慢。虚拟化对很多普通操作来说代价太高了，Redis并没有增加多少开销在所需的系统调用和网络中断上。
    * 客户端和服务器在一台机器运行，对于基准测试TCP/IP回送和UNIX域套接字都可以使用。取决于平台，但UNIX域套接字比TCP/IP回送增加50%的吞吐量。
    * 当大量使用 pipelining时，UNIX域套接字获得的性能好处会减少。
    * 当以太网访问Redis时，在数据大小小于以太网数据包的大小（大约1500字节）时，聚集命令使用 pipelining会非常有效。
    * 在多CPU套接字服务器，Redis的表现变得依赖于NUMA配置和处理位置。
    * 在高端配置，客户端连接的数量也是一个重要的因素。基于epool/kqueue模型，Redis的事件循环是相当可伸缩的。
    * 在高端的配置，通过调优NIC(s)配置和相关中断可能取得高吞吐量。
    * 根据平台，Redis编译可以使用不同的内存分配器，这可能有不同的行为在原始速度,内部和外部的碎片方面
	
	
16 Redis的数据类型
（1）Redis支持五种数据类型：string（字符串），hash（哈希），list（列表），set（集合）及zset(sorted set：有序集合)。
类型	简介	特性	场景
String(字符串)	二进制安全	可以包含任何数据,比如jpg图片或者序列化的对象,一个键最大能存储512M	---
Hash(字典)	键值对集合,即编程语言中的Map类型	适合存储对象,并且可以像数据库中update一个属性一样只修改某一项属性值(Memcached中需要取出整个字符串反序列化成对象修改完再序列化存回去)	存储、读取、修改用户属性
List(列表)	链表(双向链表)	增删快,提供了操作某一段元素的API	1,最新消息排行等功能(比如朋友圈的时间线) 2,消息队列
Set(集合)	哈希表实现,元素不重复	1,添加、删除,查找的复杂度都是O(1) 2,为集合提供了求交集、并集、差集等操作	1,共同好友 2,利用唯一性,统计访问网站的所有独立ip 3,好用推荐时,根据tag求交集,大于某个阈值就可以推荐
Sorted Set(有序集合)	将Set中的元素增加一个权重参数score,元素按score有序排列	数据插入集合时,已经进行天然排序	1,排行榜 2,带权重的消息队列
（2）String（字符串）
string是redis最基本的类型，你可以理解成与Memcached一模一样的类型，一个key对应一个value。
string类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象 。
string类型是Redis最基本的数据类型，一个键最大能存储512MB。
实例
redis 127.0.0.1:6379> SET name "runoob"
OK
redis 127.0.0.1:6379> GET name
"runoob"
在以上实例中我们使用了 Redis 的 SET 和 GET 命令。键为 name，对应的值为 runoob。
注意：一个键最大能存储512MB。
（3）Hash（哈希）
Redis hash 是一个键值(key=>value)对集合。
Redis hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。
实例
redis> HMSET myhash field1 "Hello" field2 "World"
"OK"
redis> HGET myhash field1
"Hello"
redis> HGET myhash field2
"World"
实例中我们使用了 Redis HMSET, HGET 命令，HMSET 设置了两个 field=>value 对, HGET 获取对应 field 对应的 value。
每个 hash 可以存储 232 -1 键值对（40多亿）。
（4）List（列表）
Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。
实例
redis 127.0.0.1:6379> lpush runoob redis
(integer) 1
redis 127.0.0.1:6379> lpush runoob mongodb
(integer) 2
redis 127.0.0.1:6379> lpush runoob rabitmq
(integer) 3
redis 127.0.0.1:6379> lrange runoob 0 10
1) "rabitmq"
2) "mongodb"
3) "redis"
redis 127.0.0.1:6379>
列表最多可存储 232 - 1 元素 (4294967295, 每个列表可存储40多亿)。
（5）Set（集合）
Redis的Set是string类型的无序集合。
集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。
sadd 命令
添加一个 string 元素到 key 对应的 set 集合中，成功返回1，如果元素已经在集合中返回 0，如果 key 对应的 set 不存在则返回错误。
sadd key member
实例
redis 127.0.0.1:6379> sadd runoob redis
(integer) 1
redis 127.0.0.1:6379> sadd runoob mongodb
(integer) 1
redis 127.0.0.1:6379> sadd runoob rabitmq
(integer) 1
redis 127.0.0.1:6379> sadd runoob rabitmq
(integer) 0
redis 127.0.0.1:6379> smembers runoob
1) "redis"
2) "rabitmq"
3) "mongodb"
注意：以上实例中 rabitmq 添加了两次，但根据集合内元素的唯一性，第二次插入的元素将被忽略。
集合中最大的成员数为 232 - 1(4294967295, 每个集合可存储40多亿个成员)。
（6）zset(sorted set：有序集合)
Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。
不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。
zset的成员是唯一的,但分数(score)却可以重复。
zadd 命令
添加元素到集合，元素在集合中存在则更新对应score
zadd key score member 
实例
redis 127.0.0.1:6379> zadd runoob 0 redis
(integer) 1
redis 127.0.0.1:6379> zadd runoob 0 mongodb
(integer) 1
redis 127.0.0.1:6379> zadd runoob 0 rabitmq
(integer) 1
redis 127.0.0.1:6379> zadd runoob 0 rabitmq
(integer) 0
redis 127.0.0.1:6379> > ZRANGEBYSCORE runoob 0 1000
1) "mongodb"
2) "rabitmq"
3) "redis"

16 Redis事务
（1）MULTI、EXEC、DISCARD和WATCH命令是Redis事务功能的基础。Redis事务允许在一次单独的步骤中执行一组命令，并且可以保证如下两个重要事项：
1）Redis会将一个事务中的所有命令序列化，然后按顺序执行。Redis不可能在一个Redis事务的执行过程中插入执行另一个客户端发出的请求。这样便能保证Redis将这些命令作为一个单独的隔离操作执行。 
2） 在一个Redis事务中，Redis要么执行其中的所有命令，要么什么都不执行。

因此，Redis事务能够保证原子性。EXEC命令会触发执行事务中的所有命令。
因此，当某个客户端正在执行一次事务时，如果它在调用MULTI命令之前就从Redis服务端断开连接，那么就不会执行事务中的任何操作；相反，如果它在调用EXEC命令之后才从Redis服务端断开连接，那么就会执行事务中的所有操作。当Redis使用只增文件（AOF：Append-only File）时，Redis能够确保使用一个单独的write(2)系统调用，这样便能将事务写入磁盘。然而，如果Redis服务器宕机，或者系统管理员以某种方式停止Redis服务进程的运行，那么Redis很有可能只执行了事务中的一部分操作。Redis将会在重新启动时检查上述状态，然后退出运行，并且输出报错信息。使用redis-check-aof工具可以修复上述的只增文件，这个工具将会从上述文件中删除执行不完全的事务，这样Redis服务器才能再次启动。 从2.2版本开始，除了上述两项保证之外，Redis还能够以乐观锁的形式提供更多的保证，这种形式非常类似于“检查再设置”（CAS：Check And Set）操作。本文稍后会对Redis的乐观锁进行描述。
（2）相关命令
1）. MULTI 用于标记事务块的开始。Redis会将后续的命令逐个放入队列中，然后才能使用EXEC命令原子化地执行这个命令序列。 这个命令的运行格式如下所示：
MULTI 这个命令的返回值是一个简单的字符串，总是OK。
2）. EXEC 在一个事务中执行所有先前放入队列的命令，然后恢复正常的连接状态。 当使用WATCH命令时，只有当受监控的键没有被修改时，EXEC命令才会执行事务中的命令，这种方式利用了检查再设置（CAS）的机制。 这个命令的运行格式如下所示：EXEC 这个命令的返回值是一个数组，其中的每个元素分别是原子化事务中的每个命令的返回值。 当使用WATCH命令时，如果事务执行中止，那么EXEC命令就会返回一个Null值。
3）. DISCARD 清除所有先前在一个事务中放入队列的命令，然后恢复正常的连接状态。 如果使用了WATCH命令，那么DISCARD命令就会将当前连接监控的所有键取消监控。 这个命令的运行格式如下所示： DISCARD 这个命令的返回值是一个简单的字符串，总是OK。
4）. WATCH 当某个事务需要按条件执行时，就要使用这个命令将给定的键设置为受监控的。 这个命令的运行格式如下所示： WATCH key [key ...] 这个命令的返回值是一个简单的字符串，总是OK。 对于每个键来说，时间复杂度总是O(1)。
5）. UNWATCH 清除所有先前为一个事务监控的键。 如果你调用了EXEC或DISCARD命令，那么就不需要手动调用UNWATCH命令。 这个命令的运行格式如下所示： UNWATCH 这个命令的返回值是一个简单的字符串，总是OK。 时间复杂度总是O(1)。
（3）使用方法 
使用MULTI命令便可以进入一个Redis事务。这个命令的返回值总是OK。此时，用户可以发出多个Redis命令。Redis会将这些命令放入队列，而不是执行这些命令。一旦调用EXEC命令，那么Redis就会执行事务中的所有命令。 相反，调用DISCARD命令将会清除事务队列，然后退出事务。 以下示例会原子化地递增foo键和bar键的值： <img> 正如从上面的会话所看到的一样，EXEC命令的返回值是一个数组，其中的每个元素都分别是事务中的每个命令的返回值，返回值的顺序和命令的发出顺序是相同的。 当一个Redis连接正处于MULTI请求的上下文中时，通过这个连接发出的所有命令的返回值都是QUEUE字符串（从Redis协议的角度来看，返回值是作为状态回复（Status Reply）来发送的）。当调用EXEC命令时，Redis会简单地调度执行事务队列中的命令。
（4）事务内部的错误 
在一个事务的运行期间，可能会遇到两种类型的命令错误：一个命令可能会在被放入队列时失败。因此，事务有可能在调用EXEC命令之前就发生错误。例如，这个命令可能会有语法错误（参数的数量错误、命令名称错误，等等），或者可能会有某些临界条件（例如：如果使用maxmemory指令，为Redis服务器配置内存限制，那么就可能会有内存溢出条件）。
在调用EXEC命令之后，事务中的某个命令可能会执行失败。例如，我们对某个键执行了错误类型的操作（例如，对一个字符串（String）类型的键执行列表（List）类型的操作）。 可以使用Redis客户端检测第一种类型的错误，在调用EXEC命令之前，这些客户端可以检查被放入队列的命令的返回值：如果命令的返回值是QUEUE字符串，那么就表示已经正确地将这个命令放入队列；否则，Redis将返回一个错误。如果将某个命令放入队列时发生错误，那么大多数客户端将会中止事务，并且丢弃这个事务。 然而，从Redis 2.6.5版本开始，服务器会记住事务积累命令期间发生的错误。
然后，Redis会拒绝执行这个事务，在运行EXEC命令之后，便会返回一个错误消息。最后，Redis会自动丢弃这个事务。 在Redis 2.6.5版本之前，如果发生了上述的错误，那么在客户端调用了EXEC命令之后，Redis还是会运行这个出错的事务，执行已经成功放入事务队列的命令，而不会关心先前发生的错误。从2.6.5版本开始，Redis在遭遇上述错误时，会采用先前描述的新行为，这样便能轻松地混合使用事务和管道。在这种情况下，客户端可以一次性地将整个事务发送至Redis服务器，稍后再一次性地读取所有的返回值。 相反，在调用EXEC命令之后发生的事务错误，Redis不会进行任何特殊处理：在事务运行期间，即使某个命令运行失败，所有其他的命令也将会继续执行。 这种行为在协议层面上更加清晰。
在以下示例中，当事务正在运行时，有一条命令将会执行失败，即使这条命令的语法是正确的： <img> 上述示例的EXEC命令的返回值是批量的字符串，包含两个元素，一个是OK代码，另一个是-ERR错误消息。客户端会根据自身的程序库，选择一种合适的方式，将错误信息提供给用户 需要注意的是，即使某个命令执行失败，事务队列中的所有其他命令仍然会执行 —— Redis不会停止执行事务中的命令。 再看另一个示例，再次使用telnet通信协议，观察命令的语法错误是如何尽快报告给用户的： <img> 这一次，由于INCR命令的语法错误，Redis根本就没有将这个命令放入事务队列。
（5）为什么Redis不支持回滚？ 
如果你具备关系型数据库的知识背景，你就会发现一个事实：在事务运行期间，虽然Redis命令可能会执行失败，但是Redis仍然会执行事务中余下的其他命令，而不会执行回滚操作，你可能会觉得这种行为很奇怪。 然而，这种行为也有其合理之处：     只有当被调用的Redis命令有语法错误时，这条命令才会执行失败（在将这个命令放入事务队列期间，Redis能够发现此类问题），或者对某个键执行不符合其数据类型的操作：实际上，这就意味着只有程序错误才会导致Redis命令执行失败，这种错误很有可能在程序开发期间发现，一般很少在生产环境发现。
    Redis已经在系统内部进行功能简化，这样可以确保更快的运行速度，因为Redis不需要事务回滚的能力。 对于Redis事务的这种行为，有一个普遍的反对观点，那就是程序有可能会有缺陷（bug）。但是，你应当注意到：事务回滚并不能解决任何程序错误。例如，如果某个查询会将一个键的值递增2，而不是1，或者递增错误的键，那么事务回滚机制是没有办法解决这些程序问题的。请注意，没有人能解决程序员自己的错误，这种错误可能会导致Redis命令执行失败。正因为这些程序错误不大可能会进入生产环境，所以我们在开发Redis时选用更加简单和快速的方法，没有实现错误回滚的功能。
（6）丢弃命令队列 DISCARD命令可以用来中止事务运行。
在这种情况下，不会执行事务中的任何命令，并且会将Redis连接恢复为正常状态。示例如下所示
（7）通过CAS操作实现乐观锁 Redis使用WATCH命令实现事务的“检查再设置”（CAS）行为。 作为WATCH命令的参数的键会受到Redis的监控，Redis能够检测到它们的变化。在执行EXEC命令之前，如果Redis检测到至少有一个键被修改了，那么整个事务便会中止运行，然后EXEC命令会返回一个Null值，提醒用户事务运行失败。 例如，设想我们需要将某个键的值自动递增1（假设Redis没有INCR命令）。 首次尝试的伪码可能如下所示： 
val = GET mykey
val = val + 1
SET mykey $val 
如果我们只有一个Redis客户端在一段指定的时间之内执行上述伪码的操作，那么这段伪码将能够可靠的工作。如果有多个客户端大约在同一时间尝试递增这个键的值，那么将会产生竞争状态。例如，客户端-A和客户端-B都会读取这个键的旧值（例如：10）。这两个客户端都会将这个键的值递增至11，最后使用SET命令将这个键的新值设置为11。因此，这个键的最终值是11，而不是12。 现在，我们可以使用WATCH命令完美地解决上述的问题，伪码如下所示： WATCH mykey
val = GET mykey
val = val + 1
MULTI
SET mykey $val
EXEC 由上述伪码可知，如果存在竞争状态，并且有另一个客户端在我们调用WATCH命令和EXEC命令之间的时间内修改了val变量的结果，那么事务将会运行失败。 我们只需要重复执行上述伪码的操作，希望此次运行不会再出现竞争状态。这种形式的锁就被称为乐观锁，它是一种非常强大的锁。在许多用例中，多个客户端可能会访问不同的键，因此不太可能发生冲突 —— 也就是说，通常没有必要重复执行上述伪码的操作。
（8）WATCH命令详解
那么WATCH命令实际做了些什么呢？这个命令会使得EXEC命令在满足某些条件时才会运行事务：我们要求Redis只有在所有受监控的键都没有被修改时，才会执行事务。
（但是，相同的客户端可能会在事务内部修改这些键，此时这个事务不会中止运行。）否则，Redis根本就不会进入事务。（注意，如果你使用WATCH命令监控一个易失性的键，然后在你监控这个键之后，Redis再使这个键过期，那么EXEC命令仍然可以正常工作。） WATCH命令可以被调用多次。
简单说来，所有的WATCH命令都会在被调用之时立刻对相应的键进行监控，直到EXEC命令被调用之时为止。你可以在单条的WATCH命令之中，使用任意数量的键作为命令参数。 当调用EXEC命令时，所有的键都会变为未受监控的状态，Redis不会管事务是否被中止。当一个客户单连接被关闭时，所有的键也都会变为未受监控的状态。 你还可以使用UNWATCH命令（不需要任何参数），这样便能清除所有的受监控键。当我们对某些键施加乐观锁之后，这个命令有时会非常有用。因为，我们可能需要运行一个用来修改这些键的事务，但是在读取这些键的当前内容之后，我们可能不打算继续进行操作，此时便可以使用UNWATCH命令，清除所有受监控的键。在运行UNWATCH命令之后，Redis连接便可以再次自由地用于运行新事务。 
如何使用WATCH命令实现ZPOP操作呢？ 本文将通过一个示例，说明如何使用WATCH命令创建一个新的原子化操作（Redis并不原生支持这个原子化操作），此处会以实现ZPOP操作为例。这个命令会以一种原子化的方式，从一个有序集合中弹出分数最低的元素。以下源码是最简单的实现方式： WATCH zset
element = ZRANGE zset 0 0
MULTI
ZREM zset element
EXEC 如果伪码中的EXEC命令执行失败（例如，返回Null值），那么我们只需要重复运行这个操作即可。
（9）Redis脚本和事务 
根据定义，Redis脚本也是事务型的。因此，你可以通过Redis事务实现的功能，同样也可以通过Redis脚本来实现，而且通常脚本更简单、更快速。 由于Redis从2.6版本才开始引入脚本特性，而事务特性是很久以前就已经存在的，所以目前的版本才有两个看起来重复的特性。但是，我们不太可能在短时间内移除对事务特性的支持。因为，即使不用求助于Redis脚本，用户仍然能够规避竞争状态，这从语义上来看是适宜的。还有另一个更重要的原因，Redis事务特性的实现复杂度是最小的。 但是，在相当长的一段时间之内，我们不大可能看到整个用户群体都只使用Redis脚本。如果发生这种情况，那么我们可能会废弃，甚至最终移除Redis事务。 

17 Redis线程模型
（1）Redis 基于 Reactor 模式开发了自己的网络事件处理器： 这个处理器被称为文件事件处理器（file event handler）：文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字， 并根据套接字目前执行的任务来为套接字关联不同的事件处理器。当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时， 与操作相对应的文件事件就会产生， 这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。虽然文件事件处理器以单线程方式运行， 但通过使用 I/O 多路复用程序来监听多个套接字， 文件事件处理器既实现了高性能的网络通信模型， 又可以很好地与 redis 服务器中其他同样以单线程方式运行的模块进行对接， 这保持了 Redis 内部单线程设计的简单性。
（2）进程，线程
@进程：在计算机发明之初就发现，在输入数据时（I/O速度慢），CPU是空闲的，这样就浪费了CPU资源，为了充分利用CPU资源，发明了进程，在输入程序A的数据时，程序B在占用CPU资源进行计算。
@线程：为了减少进程的上下文切换的损耗，满足人机交互的实时性，同时保留进程充分利用CPU资源的优点，出现了线程。

（3）redis为什么不用多线程（不划算）
	1）纯内存操作；
	2）多线程仍然会有上下文切换的损耗，虽然比进程切换损耗小；
	3）采用了非阻塞I/O多路复用机制
（4）单线程模型
redis中的数据结构并不全是简单的kv，还有list、hash等复杂的结构，这些结构很可能会进行细粒度的操作，比如在很长的列表偶棉添加一个元素，在hash当中或者删除一个对象，这样的一个操作就会添加很多的锁，导致同步的开销大大增加，redis权衡之后选择使用单线程，突出自己功能的灵活性，在单线程基础上任何原子操作都可以无代价的实现，多复杂的数据结构都可以轻松运用。Redis客户端对服务端的每次调用都经历了发送命令、执行命令、返回结果三个过程，其中执行命令阶段，由于redis是单线程来处理命令的，所以每一条到达服务端的命令不会立即执行，所有的命令都会进入一个队列中，然后逐个被执行，并且多个客户端发送的命令的执行顺序是不确定的，但是可以确定的是不会有两个命令被同时执行，不会产生并发问题，这就是redis的单线程基本模型
（5）单线程模型每秒万级别处理能力的原因：
1） 纯内存访问，数据存放在内存中，内存的响应时间大约是100ns，这是redis每秒万级别访问的重要基础
2） 非阻塞I/O，redis采用epoll作为I/O多路复用技术的实现，再加上redis自身的事件处理模型将epoll中的连接、读写、关闭都转换为了时间，不在I/O上浪费过多的时间
3） 单线程避免了线程切换和竞态产生的消耗
4） redis采用单线程模型，每条命令执行如果占用大量时间，会造成其他线程的阻塞，对于redis这种高性能服务是致命的，所以redis是面向高速执行的数据
（6）Redis为什么是单线程的？
因为CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存或者网络带宽，既然单线程容易实现，而且CPU不会成为瓶颈，那就顺便成章的采用单线程的方案。如果万一CPU成为你的Redis瓶颈了，或者，你就是不想让服务器其他核闲置，那怎么办？那也很简单，你多起几个Redis进程就好了。Redis是keyvalue数据库，又不是关系数据库，数据之间没有约束。只要客户端分清哪些key放在哪个Redis进程上就可以了。redis-cluster可以帮你做的更好。


18 Redis分页
（1）传统分页
一般分页做缓存都是直接查找出来，按页放到缓存里，但是这种缓存方式有很多缺点。如缓存不能及时更新，一旦数据有变化，所有的之前的分页缓存都失效了。比如像微博这样的场景，微博下面现在有一个顶次数的排序。这个用传统的分页方式很难应对。
（2）Redis缓存分页
1、String: 主要用于存储字符串，显然不支持分页和排序。
2、Hash: 主要用于存储key-value型数据，评论模型中全是key-value型数据，所以在这里Hash无疑会用到。
3、List: 主要用于存储一个列表，列表中的每一个元素按元素的插入时的顺序进行保存，如果我们将评论模型按createDate排好序后再插入List中，似乎就能做到排序了，而且再利用List中的LRANGE key start stop指令还能做到分页。嗯，到这里List似乎满足了我们分页和排序的要求，但是评论还会被删除，就需要更新Redis中的数据，如果每次删除评论后都将Redis中的数据全部重新写入一次，显然不够优雅，效率也会大打折扣，如果能删除指定的数据无疑会更好，而List中涉及到删除数据的就只有LPOP和RPOP这两条指令，但LPOP和RPOP只能删除列表头和列表尾的数据，不能删除指定位置的数据，所以List也不太适合(转载的时候看了下，是有 LREM命令可以做到删除，但是LRANGE 似乎是一个耗时命令 O(N) )。
4、Set: 主要存储无序集合，无序！排除。
5、SortedSet: 主要存储有序集合，SortedSet的添加元素指令ZADD key score member [[score,member]…]会给每个添加的元素member绑定一个用于排序的值score，SortedSet就会根据score值的大小对元素进行排序，在这里就可以将createDate当作score用于排序，SortedSet中的指令ZREVRANGE key start stop又可以返回指定区间内的成员，可以用来做分页，SortedSet的指令ZREM key member可以根据key移除指定的成员，能满足删评论的要求，所以，SortedSet在这里是最适合的（时间复杂度O(log(N))）

19 哨兵模式
（1）Redis-Sentinel是官方推荐的高可用解决方案，当redis在做master-slave的高可用方案时，假如master宕机了，redis本身（以及其很多客户端）都没有实现自动进行主备切换，而redis-sentinel本身也是独立运行的进程，可以部署在其他与redis集群可通讯的机器中监控redis集群。
（2）它的主要功能有一下几点
1）、不时地监控redis是否按照预期良好地运行;
2）、如果发现某个redis节点运行出现状况，能够通知另外一个进程(例如它的客户端);
3）、能够进行自动切换。当一个master节点不可用时，能够选举出master的多个slave(如果有超过一个slave的话)中的一个来作为新的master,其它的slave节点会将它所追随的master的地址改为被提升为master的slave的新地址。
4）、哨兵为客户端提供服务发现，客户端链接哨兵，哨兵提供当前master的地址然后提供服务，如果出现切换，也就是master挂了，哨兵会提供客户端一个新地址。
哨兵（sentinel）本身也是支持集群的
哨兵(sentinel) 的一些设计思路和zookeeper非常类似
（3）单个哨兵会存在自己挂掉而无法监控整个集群的问题，所以哨兵也是支持集群的，我们通常用三台哨兵机器来监控一组redis集群。

20 Redis应用场景
1）.取最新N个数据的操作
比如典型的取你网站的最新文章，通过下面方式，我们可以将最新的5000条评论的ID放在Redis的List集合中，并将超出集合部分从数据库获取
使用LPUSH latest.comments<ID>命令，向list集合中插入数据 
插入完成后再用LTRIM latest.comments 0 5000命令使其永远只保存最近5000个ID 
然后我们在客户端获取某一页评论时可以用下面的逻辑（伪代码） 
FUNCTION get_latest_comments(start,num_items):
id_list = redis.lrange("latest.comments",start,start+num_items-1)
IF id_list.length < num_items 
id_list = SQL_DB("SELECT ... ORDER BY time LIMIT ...") 
END 
RETURN id_list 
END 
如果你还有不同的筛选维度，比如某个分类的最新N条，那么你可以再建一个按此分类的List，只存ID的话，Redis是非常高效的。
2）.排行榜应用，取TOP N操作
这个需求与上面需求的不同之处在于，前面操作以时间为权重，这个是以某个条件为权重，比如按顶的次数排序，这时候就需要我们的sorted set出马了，将你要排序的值设置成sorted set的score，将具体的数据设置成相应的value，每次只需要执行一条ZADD命令即可。
3）.需要精准设定过期时间的应用
比如你可以把上面说到的sorted set的score值设置成过期时间的时间戳，那么就可以简单地通过过期时间排序，定时清除过期数据了，不仅是清除Redis中的过期数据，你完全可以把Redis里这个过期时间当成是对数据库中数据的索引，用Redis来找出哪些数据需要过期删除，然后再精准地从数据库中删除相应的记录。
4）.计数器应用
Redis的命令都是原子性的，你可以轻松地利用INCR，DECR命令来构建计数器系统。
5）.Uniq操作，获取某段时间所有数据排重值
这个使用Redis的set数据结构最合适了，只需要不断地将数据往set中扔就行了，set意为集合，所以会自动排重。
6）.实时系统，反垃圾系统
通过上面说到的set功能，你可以知道一个终端用户是否进行了某个操作，可以找到其操作的集合并进行分析统计对比等。没有做不到，只有想不到。
7）.Pub/Sub构建实时消息系统
Redis的Pub/Sub系统可以构建实时的消息系统，比如很多用Pub/Sub构建的实时聊天系统的例子。
8）.构建队列系统
使用list可以构建队列系统，使用sorted set甚至可以构建有优先级的队列系统。
9）.缓存
这个不必说了，性能优于Memcached（在某些方面，并不是全面优于），数据结构更多样化。
	
21 同步原理
从服务器会向主服务器发出SYNC指令，当主服务器接到此命令后，就会调用BGSAVE指令来创建一个子进程专门进行数据持久化工作，也就是将主服务器的数据写入RDB文件中。在数据持久化期间，主服务器将执行的写指令都缓存在内存中。在BGSAVE指令执行完成后，主服务器会将持久化好的RDB文件发送给从服务器，从服务器接到此文件后会将其存储到磁盘上，然后再将其读取到内存中。这个动作完成后，主服务器会将这段时间缓存的写指令再以redis协议的格式发送给从服务器。
另外，要说的一点是，即使有多个从服务器同时发来SYNC指令，主服务器也只会执行一次BGSAVE，然后把持久化好的RDB文件发给多个下游。在redis2.8版本之前，如果从服务器与主服务器因某些原因断开连接的话，都会进行一次主从之间的全量的数据同步；而在2.8版本之后，redis支持了效率更高的增量同步策略，这大大降低了连接断开的恢复成本。主服务器会在内存中维护一个缓冲区，缓冲区中存储着将要发给从服务器的内容。从服务器在与主服务器出现网络瞬断之后，从服务器会尝试再次与主服务器连接，一旦连接成功，从服务器就会把“希望同步的主服务器ID”和“希望请求的数据的偏移位置（replication offset）”发送出去。主服务器接收到这样的同步请求后，首先会验证主服务器ID是否和自己的ID匹配，其次会检查“请求的偏移位置”是否存在于自己的缓冲区中，如果两者都满足的话，主服务器就会向从服务器发送增量内容。增量同步功能，需要服务器端支持全新的PSYNC指令。这个指令，只有在redis-2.8之后才具有。
	
	
22 Redis 分区
（1）分区是分割数据到多个Redis实例的处理过程，因此每个实例只保存key的一个子集。
（2）分区的优势
@通过利用多台计算机内存的和值，允许我们构造更大的数据库。
@通过多核和多台计算机，允许我们扩展计算能力；通过多台计算机和网络适配器，允许我们扩展网络带宽。
（3）分区的不足
@涉及多个key的操作通常是不被支持的。举例来说，当两个set映射到不同的redis实例上时，你就不能对这两个set执行交集操作。
@涉及多个key的redis事务不能使用。
@当使用分区时，数据处理较为复杂，比如你需要处理多个rdb/aof文件，并且从多个实例和主机备份持久化文件。
@增加或删除容量也比较复杂。redis集群大多数支持在运行时增加、删除节点的透明数据平衡的能力，但是类似于客户端分区、代理等其他系统则不支持这项特性。然而，一种叫做presharding的技术对此是有帮助的。
（4）分区类型
Redis 有两种类型分区。 假设有4个Redis实例 R0，R1，R2，R3，和类似user:1，user:2这样的表示用户的多个key，对既定的key有多种不同方式来选择这个key存放在哪个实例中。也就是说，有不同的系统来映射某个key到某个Redis服务。
1）范围分区
最简单的分区方式是按范围分区，就是映射一定范围的对象到特定的Redis实例。比如，ID从0到10000的用户会保存到实例R0，ID从10001到 20000的用户会保存到R1，以此类推。这种方式是可行的，并且在实际中使用，不足就是要有一个区间范围到实例的映射表。这个表要被管理，同时还需要各 种对象的映射表，通常对Redis来说并非是好的方法。
2）哈希分区
另外一种分区方法是hash分区。这对任何key都适用，也无需是object_name:这种形式，像下面描述的一样简单：用一个hash函数将key转换为一个数字，比如使用crc32 hash函数。对key foobar执行crc32(foobar)会输出类似93024922的整数。对这个整数取模，将其转化为0-3之间的数字，就可以将这个整数映射到4个Redis实例中的一个了。93024922 % 4 = 2，就是说key foobar应该被存到R2实例中。注意：取模操作是取除的余数，通常在多种编程语言中用%操作符实现。

23 Pipeline管道
可以将多次IO往返的时间缩减为一次，前提是pipeline执行的指令之间没有因果相关性。使用redis-benchmark进行压测的时候可以发现影响redis的QPS峰值的一个重要因素是pipeline批次指令的数目。redis的底层通信协议对管道提供了支持。通过管道可以一次性发送多条命令并在执行完后一次性将结果返回，当一组命令中每条命令都不依赖之前命令的执行结果时就可以将这组命令一起通过管道发出。管道通过减少客户端与redis的通信次数来实现降低往返实验累计值的目的。
	
	
24 Redis集群和高可用
1） 使用较多的redis部署方式:
通过上表比较可知：如果需要完整的分片、复制和高可用特性，在集群节点不多且在使用sentinel这种模式会带来性能瓶颈和资源消耗的情况下，可以选择使用 Redis集群；如果只需要一部分特性（比如只需要分片，但不需要复制和高可用），那么可以选择Redis Sentinel。

2） 单实例模式
单实例模式是指单台redis完成所有请求任务，因此复用和不具备容错性；同时在单台机器上如果只启用一个redis实例会造成资源浪费 。

3） Redis集群
Redis 集群是一个由多个节点组成的分布式服务器群，它具有复制、高可用和分片特性。Redis集群不需要sentinel哨兵也能完成节点移除和故障转移的功能。需要将每个节点设置成集群模式，这种集群模式没有中心节点，多个节点之间存在着网络通信的消耗。多个节点按照分片来处理不同位置的槽，接受到不属于自己的槽操作的命令时会重新发送命令给正确的节点，这中间必然有一定的资源消耗。如同redis主从配置使用sentinel作为代理来处理请求一样。

4） redis最核心的目标：
▪  性能：这是Redis赖以生存的看家本领，增加集群功能后当然不能对性能产生太大影响，所以Redis采取了P2P而非Proxy方式、异步复制、客户端重定向等设计，而牺牲了部分的一致性、使用性。
▪  水平扩展：集群的最重要能力当然是扩展，文档中称可以线性扩展到1000节点。
▪  可用性：在Cluster推出之前，可用性要靠Sentinel保证。有了集群之后也自动具有了Sentinel的监控和自动Failover能力。

5）分布式
Redis集群是一个由多个Redis服务器组成的分布式网络服务器群，集群中的各个服务器被称为节点（node），这些节点会相互连接并进行通信。分布式的Redis集群没有中心节点，所以用户不必担心某个节点会成为整个集群的性能瓶颈。

6） 复制
Redis 集群的每个节点都有两种角色可选，一个是主节点（master node），另一个是从节点（slavenode），其中主节点用于储存数据，而从节点则是某个主节点的复制品。当用户需要处理更多读请求的时候，可以添加从节点以扩展系统的读性能。因为Redis集群重用了单机Redis复制特性的代码，所以集群的复制行为和我们之前介绍的单机复制特性的行为是完全一样的。

7） 节点故障检测和自动故障转移
Redis 集群的主节点内置了类似Redis Sentinel的节点故障检测和自动故障转移功能，当集群中的某个主节点下线时，集群中的其他在线主节点会注意到这一点，并对已下线的主节点进行故障转移。集群进行故障转移的方法和Redis Sentinel进行故障转移的方法基本一样，不同的是，在集群里面，故障转移是由集群中其他在线的主节点负责进行的，所以集群不必另外使用Redis Sentinel 。

8） 分片
集群使用分片来扩展数据库的容量，并将命令请求的负载交给不同的节点来分担。集群将整个数据库分为 16384 个槽（slot），所有键都属于这 16384 个槽的其中一个，计算键 key属于哪个槽的公式为 slot_number = crc16(key) % 16384 ，其中 crc16 为 16 位的循环冗余校验和函数。集群中的每个主节点都可以处理 0 个至 16384 个槽，当 16384 个槽都有某个节点在负责处理时，集群进入上线状态，并开始处理客户端发送的数据命令请求。
例如，我们有三个主节点7000、7001 和 7002，那么我们可以：
将槽0至5460指派给节点7000负责处理；
将槽 5461至 10922 指派给节点 7001 负责处理；
将槽 10923至 16383指派给节点 7002 负责处理；
这样就可以将16384个槽平均地指派给三个节点负责处理。

9） 转向
对于一个被指派了槽的主节点来说，这个主节点只会处理属于指派给自己的槽的命令请求。如果一个节点接收到了与自己处理的槽无关的命令请求，那么节点会向客户端返回一个转向错误（redirection error），告诉客户端，哪个节点负责处理这条命令，之后客户端需要根据错误中包含的地址和端口号重新向正确的节点发送命令请求。

10） Redis集群客户端
因为集群功能比起单机功能要复杂得多，所以不同语言的 Redis 客户端通常需要为集群添加特别的支持，或者专门开发一个集群客户端。
目前主要的 Redis 集群客户端（或者说，支持集群功能的 Redis 客户端）有以下这些：
- redis-rb-cluster：antirez 使用 Ruby 编写的 Redis 集群客户端，集群客户端的官方实现。
- predis：Redis 的 PHP 客户端，支持集群功能。
- jedis：Redis 的 JAVA 客户端，支持集群功能。
- StackExchange.Redis：Redis 的 C# 客户端，支持集群功能。
-内置的 redis-cli ：在启动时给定 -c 参数即可进入集群模式，支持部分集群功能。

11） Redis Sentinel集群
Sentinel是一个管理redis实例的工具，它可以实现对redis的监控、通知、自动故障转移。sentinel不断地检测redis实例是否可以正常工作，通过API向其他程序报告redis的状态，如果redis master不能工作，则会自动启动故障转移进程，将其中的一个slave提升为master，其他的slave重新设置新的master服务器。

12） Sentinel主要功能
▪ 监控（Monitoring）：实时监控主服务器和从服务器运行状态。
▪ 提醒（Notification）：当被监控的某个Redis服务器出现问题时， Redis Sentinel可以向系统管理员发送通知，也可以通过API向其他程序发送通知。
▪ 自动故障转移（Automatic failover）：当一个主服务器不能正常工作时，Sentinel会开始一次自动故障迁移操作，它会将失效主服务器的其中一个从服务器升级为新的主服务器，
并让失效主服务器的其他从服务器改为复制新的主服务器，当客户端试图连接失效的主服务器时集群也会向客户做出正确的应答。

13） Redis Sentinel备份策略
Redis提供两种相对有效的备份方法：RDB和AOF。
（一）RDB持久化设置
RDB是在某个时间点将内存中的所有数据的快照保存到磁盘上，在数据恢复时，可以恢复备份时间以前的所有数据，但无法恢复备份时间点后面的数据。默认情况下Redis在磁盘上创建二进制格式的命名为dump.rdb的数据快照。可以通过配置文件配置每隔N秒且数据集上至少有M个变化时创建快照、是否对数据进行压缩、快照名称、存放快照的工作目录。
（二）AOF持久化设置
AOF是以协议文本的方式，将所有对数据库进行过写入的命令（及其参数）记录到 AOF 文件，以此达到记录数据库状态的目的。
优点是基本可以实现数据无丢失（缓存的数据有可能丢失）
缺点是随着数据量的持续增加，AOF文件也会越来越大。
在保证数据安全的情况下，尽量避免因备份数据消耗过多的Redis资源，采用如下备份策略：主实例：不采用任何备份机制。Slave端：采用AOF（严格数据要求时可同时开启RDB），每天将AOF文件备份至备份服务器。为了最大限度减少主实例的资源干扰，将备份相关全部迁移至Slave端完成。同时这样也有缺点，当主实例挂掉后，应用服务切换至Slave端，此时的Slave端的负载将会很大。目前Redis不支持RDB和AOF参数动态修改，需要重启Redis生效，希望能在新的版本中实现更高效的修改方式。利用快照的持久化方式不是非常可靠，当运行Redis的计算机停止工作、意外掉电、意外杀掉了Redis进程那么最近写入Redis的数据将会丢。对于某些应用这或许不成问题，但对于持久化要求非常高的应用场景快照方式不是理想的选择。AOF文件是一个替代方案，用以最大限度的持久化数据。同样，可以通过配置文件来开闭AOF。
当主实例Redis服务崩溃（包含主机断电、进程消失等），Redis sentinel将Slave切换为读写状态，提供生产服务。通过故障诊断修复主实例，启动后会自动加入Sentinel并从Slave端完成数据同步，但不会切换。当主实例和Slave同时崩溃（如机房断电），启动服务器后，将备份服务器最新的AOF备份拷贝至主实例，启动主实例。一切完成后再启动Slave。

14） 如何在Python 下使用Redis Sentinel？
首先安装redis-py。
一个简单的测试代码如下，首先获得一个Sentinel对象，然后键入命令vim sentinel.py
执行后成功得到zhanyz这个值，键入python sentinel.py。
上面的master和slave都是标准的建立好连接的StrictRedis实例，slave则是sentinel查询到的第一个可用的slave。
如果正在连接的master不可用时，客户端会先抛出redis.exceptions.ConnectionError异常（此时还未开始failover），然后抛出redis.sentinel.MasterNotFoundError异常（failover进行中），在sentinel正常failover之后，实例正常。

15） 如何在JAVA 下使用Redis Sentinel？
使用Java操作Redis需要jedis-2.1.0.jar，如果需要使用Redis连接池的话，还需commons-pool-2.4.2.jar。JedisTemplate提供了一个template方法，负责对Jedis连接的获取与归还。
注意：
1)cluster环境下redis的slave不接受任何读写操作，比如sentinel模式下只有slave升级为主实例时才能进行读写操作。
2)client端不支持keys批量操作,不支持select dbNum操作，只有一个db:select 0，这个十分尴尬。 
3)JedisCluster 的info()等单机函数无法调用,返回(No way to dispatch this command to Redis Cluster)错误。.
4)JedisCluster 没有针对byte[]的API，需要自己扩展。
5) JedisTemplate中具体代码可以参见附件中JedisTemplate.java



二、ms相关
1.什么是redis?
Redis 是一个基于内存的高性能key-value数据库。 

2.Reids的特点
Redis本质上是一个Key-Value类型的内存数据库，很像memcached，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据flush到硬盘上进行保存。因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。
Redis的出色之处不仅仅是性能，Redis最大的魅力是支持保存多种数据结构，此外单个value的最大限制是1GB，不像 memcached只能保存1MB的数据，因此Redis可以用来实现很多有用的功能，比方说用他的List来做FIFO双向链表，实现一个轻量级的高性 能消
息队列服务，用他的Set可以做高性能的tag系统等等。另外Redis也可以对存入的Key-Value设置expire时间，因此也可以被当作一 个功能加强版的memcached来用。
Redis的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。

3.使用redis有哪些好处？ 
(1) 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)
(2) 支持丰富数据类型，支持string，list，set，sorted set，hash
(3) 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行
(4) 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除

4.redis相比memcached有哪些优势？ 
(1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型
(2) redis的速度比memcached快很多 
(3) redis可以持久化其数据

5.Memcache与Redis的区别都有哪些？    
1)、存储方式 Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。 Redis有部份存在硬盘上，这样能保证数据的持久性。
2)、数据支持类型 Memcache对数据类型支持相对简单。 Redis有复杂的数据类型。
3)、使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。 Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。

6.redis常见性能问题和解决方案： 
1).Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。
2).Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。
3).Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。
4). Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内

7. mySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据
相关知识：redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略（回收策略）。redis 提供 6种数据淘汰策略：
volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰
allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
no-enviction（驱逐）：禁止驱逐数据

8.请用Redis和任意语言实现一段恶意登录保护的代码，限制1小时内每用户Id最多只能登录5次。具体登录函数或功能用空函数即可，不用详细写出。 
用列表实现:列表中每个元素代表登陆时间,只要最后的第5次登陆时间和现在时间差不超过1小时就禁止登陆.用Python写的代码如下：
#!/usr/bin/env python3
import redis  
import sys  
import time  
r = redis.StrictRedis(host=’127.0.0.1′, port=6379, db=0)  
try:       
id = sys.argv[1]
except:      
print(‘input argument error’)    
sys.exit(0)  
if r.llen(id) >= 5 and time.time() – float(r.lindex(id, 4)) <= 3600:      
print(“you are forbidden logining”)
else:       
print(‘you are allowed to login’)    
r.lpush(id, time.time())    
# login_func()

9.为什么redis需要把所有数据放到内存中?
Redis为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以redis具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘I/O速度为严重影响redis的性能。在内存越来越便宜的今天，redis将会越来越受欢迎。
如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。

10.Redis是单进程单线程的
redis利用队列技术将并发访问变为串行访问，消除了传统数据库串行控制的开销

11.redis的并发竞争问题如何解决?
Redis为单进程单线程模式，采用队列模式将并发访问变为串行访问。Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争，但是在Jedis客户端对Redis进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题，这些问题均是
由于客户端连接混乱造成。对此有2种解决方法：
1）.客户端角度，为保证每个客户端间正常有序与Redis进行通信，对连接进行池化，同时对客户端读写Redis操作采用内部锁synchronized。
2）.服务器角度，利用setnx实现锁。
注：对于第一种，需要应用程序自己处理资源的同步，可以使用的方法比较通俗，可以使用synchronized也可以使用lock；第二种需要用到Redis的setnx命令，但是需要注意一些问题。

12.redis事物的了解CAS(check-and-set 操作实现乐观锁 )?
和众多其它数据库一样，Redis作为NoSQL数据库也同样提供了事务机制。在Redis中，MULTI/EXEC/DISCARD/WATCH这四个命令是我们实现事务的基石。相信对有关系型数据库开发经验的开发者而言这一概念并不陌生，即便如此，我们还是会简要的列出Redis中事务的实现特征：
1). 在事务中的所有命令都将会被串行化的顺序执行，事务执行期间，Redis不会再为其它客户端的请求提供任何服务，从而保证了事物中的所有命令被原子的执行。
2). 和关系型数据库中的事务相比，在Redis事务中如果有某一条命令执行失败，其后的命令仍然会被继续执行。
3). 我们可以通过MULTI命令开启一个事务，有关系型数据库开发经验的人可以将其理解为"BEGIN    
    TRANSACTION"语句。在该语句之后执行的命令都将被视为事务之内的操作，最后我们可以通过执行EXEC/DISCARD命令来提交/回滚该事务内的所有操作。
    这两个Redis命令可被视为等同于关系型数据库中的COMMIT/ROLLBACK语句。
4). 在事务开启之前，如果客户端与服务器之间出现通讯故障并导致网络断开，其后所有待执行的语句都将不会被服务器执行。然而如果网络中断事件是发生在
    客户端执行EXEC命令之后，那么该事务中的所有命令都会被服务器执行。
5). 当使用Append-Only模式时，Redis会通过调用系统函数write将该事务内的所有写操作在本次调用中全部写入磁盘。然而如果在写入的过程中出现系统崩溃，
    如电源故障导致的宕机，那么此时也许只有部分数据被写入到磁盘，而另外一部分数据却已经丢失。
Redis服务器会在重新启动时执行一系列必要的一致性检测，一旦发现类似问题，就会立即退出并给出相应的错误提示。此时，我们就要充分利用Redis工具包中提供的redis-check-aof工具，该工具可以帮助我们定位到数据不一致的错误，并将已经写入的部分数据进行回滚。修复之后我们就可以再次重新启动Redis服务器了。

13.WATCH命令和基于CAS的乐观锁：
在Redis的事务中，WATCH命令可用于提供CAS(check-and-set)功能。假设我们通过WATCH命令在事务执行之前监控了多个Keys，倘若在WATCH之后有任何Key的值发生了变化，EXEC命令执行的事务都将被放弃，同时返回Null multi-bulk应答以通知调用者事务
执行失败。例如，我们再次假设Redis中并未提供incr命令来完成键值的原子性递增，如果要实现该功能，我们只能自行编写相应的代码。其伪码如下：
val = GET mykey
val = val + 1
SET mykey $val
以上代码只有在单连接的情况下才可以保证执行结果是正确的，因为如果在同一时刻有多个客户端在同时执行该段代码，那么就会出现多线程程序中经常出现的一种错误场景--竞态争用(race condition)。比如，客户端A和B都在同一时刻读取了mykey的原有值，假设该值为10，此后两个客户端又均将该值加一后set回Redis服务器，这样就会导致mykey的结果为11，而不是我们认为的12。为了解决类似的问题，我们需要借助WATCH命令的帮助，见如下代码：
WATCH mykey
val = GET mykey
val = val + 1
MULTI
SET mykey $val
EXEC
和此前代码不同的是，新代码在获取mykey的值之前先通过WATCH命令监控了该键，此后又将set命令包围在事务中，这样就可以有效的保证每个连接在执行EXEC之前，如果当前连接获取的mykey的值被其它连接的客户端修改，那么当前连接的EXEC命令将执行失败。这样调用者在判断返回值后就可以获悉val是否被重新设置成功。

14.redis持久化的几种方式
1）快照（snapshots）
缺省情况情况下，Redis把数据快照存放在磁盘上的二进制文件中，文件名为dump.rdb。你可以配置Redis的持久化策略，例如数据集中每N秒钟有超过M次更新，就将数据写入磁盘；或者你可以手工调用命令SAVE或BGSAVE。
工作原理
． Redis forks.
． 子进程开始将数据写到临时RDB文件中。
． 当子进程完成写RDB文件，用新文件替换老文件。
． 这种方式可以使Redis使用copy-on-write技术。
2）AOF
快照模式并不十分健壮，当系统停止，或者无意中Redis被kill掉，最后写入Redis的数据就会丢失。这对某些应用也许不是大问题，但对于要求高可靠性的应用来说，
Redis就不是一个合适的选择。
Append-only文件模式是另一种选择。
你可以在配置文件中打开AOF模式
3）虚拟内存方式
当你的key很小而value很大时,使用VM的效果会比较好.因为这样节约的内存比较大.
当你的key不小时,可以考虑使用一些非常方法将很大的key变成很大的value,比如你可以考虑将key,value组合成一个新的value.
vm-max-threads这个参数,可以设置访问swap文件的线程数,设置最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的.可能会造成比较长时间的延迟,但是对数据完整性有很好的保证.
自己测试的时候发现用虚拟内存性能也不错。如果数据量很大，可以考虑分布式或者其他数据库

15.redis的缓存失效策略和主键失效机制
作为缓存系统都要定期清理无效数据，就需要一个主键失效和淘汰策略.
在Redis当中，有生存期的key被称为volatile。在创建缓存时，要为给定的key设置生存期，当key过期的时候（生存期为0），它可能会被删除。
1）影响生存时间的一些操作
生存时间可以通过使用 DEL 命令来删除整个 key 来移除，或者被 SET 和 GETSET 命令覆盖原来的数据，也就是说，修改key对应的value和使用另外相同的key和value来覆盖以后，当前数据的生存时间不同。
比如说，对一个 key 执行INCR命令，对一个列表进行LPUSH命令，或者对一个哈希表执行HSET命令，这类操作都不会修改 key 本身的生存时间。另一方面，如果使用RENAME对一个 key 进行改名，那么改名后的 key的生存时间和改名前一样。
RENAME命令的另一种可能是，尝试将一个带生存时间的 key 改名成另一个带生存时间的 another_key ，这时旧的 another_key (以及它的生存时间)会被删除，然后旧的 key 会改名为 another_key ，因此，新的 another_key 的生存时间也和原本的 key 一样。使用PERSIST命令可以在不删除 key 的情况下，移除 key 的生存时间，让 key 重新成为一个persistent key 。
2）如何更新生存时间
可以对一个已经带有生存时间的 key 执行EXPIRE命令，新指定的生存时间会取代旧的生存时间。过期时间的精度已经被控制在1ms之内，主键失效的时间复杂度是O（1），
EXPIRE和TTL命令搭配使用，TTL可以查看key的当前生存时间。设置成功返回 1；当 key 不存在或者不能为 key 设置生存时间时，返回 0 。
最大缓存配置
在 redis 中，允许用户设置最大使用内存大小
server.maxmemory 默认为0，没有指定最大缓存，如果有新的数据添加，超过最大内存，则会使redis崩溃，所以一定要设置。redis 内存数据集大小上升到一定大小的时候，就会实行数据淘汰策略。
3）redis 提供 6种数据淘汰策略：
． volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
． volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
． volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
． allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰
． allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
． no-enviction（驱逐）：禁止驱逐数据
注意这里的6种机制，volatile和allkeys规定了是对已设置过期时间的数据集淘汰数据还是从全部数据集淘汰数据，后面的lru、ttl以及random是三种不同的淘汰策略，再加上一种no-enviction永不回收的策略。
4）使用策略规则：
如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用allkeys-lru
如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用allkeys-random
三种数据淘汰策略：
ttl和random比较容易理解，实现也会比较简单。主要是Lru最近最少使用淘汰策略，设计上会对key 按失效时间排序，然后取最先失效的key进行淘汰

16.比较Redis与Memcached的区别
如果简单地比较Redis与Memcached的区别，大多数都会得到以下观点：
1）Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。
2）Redis支持数据的备份，即master-slave模式的数据备份。
3）Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。

17.redis 最适合的场景
（1）、会话缓存（Session Cache）
最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。当维护一个不是严格要求一致性的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，
他们还会这样吗？
幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用Redis来缓存会话的文档。甚至广为人知的商业平台Magento也提供Redis的插件。
（2）、全页缓存（FPC）
除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。
再次以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。
此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。
（3）、队列
Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。
如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。
（4），排行榜/计数器
Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的10个用户–我们
称之为“user_scores”，我们只需要像下面一样执行即可：
当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行：
ZRANGE user_scores 0 10 WITHSCORES
Agora Games就是一个很好的例子，用Ruby实现的，它的排行榜就是使用Redis来存储数据的，你可以在这里看到。
（5）、发布/订阅
最后（但肯定不是最不重要的）是Redis的发布/订阅功能。发布/订阅的使用场景确实非常多。我已看见人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至用Redis的发布/订阅功能来建立聊天系统！（不，这是真的，你可以去核实）。
Redis提供的所有特性中，我感觉这个是喜欢的人最少的一个，虽然它为用户提供如果此多功能。

---------------------------------------------------------------------------------------------------------------
------------------------------------------redis basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------rocketmq basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 RocketMQ是阿里巴巴在2012年开源的分布式消息中间件，目前已经捐赠给Apache基金会，已经于2016年11月成为 Apache 孵化项目，相信RocketMQ的未来会发挥着越来越大的作用，将有更多的开发者因此受益。
上图是一个典型的消息中间件收发消息的模型，RocketMQ也是这样的设计，简单说来，RocketMQ具有以下特点：
是一个队列模型的消息中间件，具有高性能、高可靠、高实时、分布式特点。
Producer、Consumer、队列都可以分布式。
Producer向一些队列轮流发送消息，队列集合称为Topic，Consumer如果做广播消费，则一个consumer实例消费这个Topic对应的所有队列，如果做集群消费，则多个Consumer实例平均消费这个topic对应的队列集合。
能够保证严格的消息顺序
提供丰富的消息拉取模式
高效的订阅者水平扩展能力
实时的消息订阅机制
亿级消息堆积能力
较少的依赖

2 一些概念 
--各个角色间的关系
RocketMq中每个Broker（master和slave）与Name Server集群中的所有节点建立长连接，定时注册Topic信息到所有Name Server。
Name Server之间不会有任何信息交互，各自独立。
producer和consumer随机从一个name server即可获得全部topic的路由信息。
producer根据得到的路由信息，同master建立长连接。
consumer根据路由信息，同master个salve都建立长连接。然后根据设置的订阅规则，选择从master或者slave订阅消息。


--Broker
分为master和slave两个角色。master提供读写读物，salve只提供读服务。
为了保证可用性，需要部署多套broker，每套broker至少有1个master和1个以上的salve。
在同一套broker中，master和salve都是同样的brokerName，master的brokerId是0，salve的brokerId必须是非0的。


--同步刷盘和异步刷盘
同步刷盘是说，broker在收到每个消息后，都是先要保存到硬盘上，然后再给producer确认。
异步刷盘就是先回复确认，然后批量保存到硬盘上。异步刷盘有更好的性能，当然也有更大的丢失消息的风险。


--同步复制和异步复制。
是说在master和salve之间复制消息的方式。同步是说在salve也存储了消息后再答复producer。
异步复制是先答复producer，再去向salve复制。通过同步复制技术可以完全避免单点，同步复制势必会影响性能，适合对消息可靠性要求极高的场合，
例如与Money相关的应用。RocketMQ从3.0版本开始支持同步双写。


--MQPullConsumer和MQPushConsumer的区别
consumer被分为2类：MQPullConsumer和MQPushConsumer，其实本质都是拉模式（pull），即consumer轮询从broker拉取消息。
区别是：
push方式里，consumer把轮询过程封装了，并注册MessageListener监听器，取到消息后，唤醒MessageListener的consumeMessage()来消费，
对用户而言，感觉消息是被推送（push）过来的。

pull方式里，取消息的过程需要用户自己写，首先通过打算消费的Topic拿到MessageQueue的集合，遍历MessageQueue集合，然后针对每个
MessageQueue批量取消息，一次取完后，记录该队列下一次要取的开始offset，直到取完了，再换另一个MessageQueue。
对RocketMQ使用长轮询Pull方式，可保证消息非常实时，消息实时性不低于Push的理解


--数据交互有两种模式
Push（推模式）、Pull（拉模式）。
推模式指的是客户端与服务端建立好网络长连接，服务方有相关数据，直接通过长连接通道推送到客户端。其优点是及时，一旦有数据变更，客户端立马能感知到；
拉模式指的是客户端主动向服务端发出请求，拉取相关数据。其优点是此过程由客户端发起请求，故不存在推模式中数据积压的问题。缺点是可能不够及时，对客户端来说需要考虑数据拉取相关逻辑。


--长轮询：
轮询是说，每隔一定时间，客户端想服务端发起一次请求，服务端有数据就返回数据，没有数据就返回空，然后关闭请求。
长轮询，不同之处是，服务端如果此时没有数据，保持连接。等到有数据返回（相当于一种push），或者超时返回。
所以长轮询Pull的好处就是可以减少无效请求，保证消息的实时性，又不会造成客户端积压。
其他对于一个消息中间件来说，持久化部分的性能直接决定了整个消息中间件的性能。RocketMQ充分利用Linux文件系统内存cache来提高性能


--内存Buffer
RocketMq Broker的buffer不会满。原因是RocketMQ没有内存Buffer概念，RocketMQ的队列都是持久化磁盘，数据定期清除。
这是RocketMq和其他消息中间件的重要区别。对RocketMQ来说的内存Buffer抽象成一个无限长度的队列，不管有多少数据进来都能装得下，这个无限是有前提的，Broker会定期删除过期的数据。


--消息堆积。
消息堆积的能力是评价一个消息中间件的重要方面。因为使用消息中间件有一部分功能是为了为后端系统挡住数据洪峰。在产生消息堆积时，消息中间件对外的服务能力至关重要。
因为RocketMq的消息都是持久化硬盘的，当消息不能在内存Cache命中时，要不可避免的访问磁盘，会产生大量读IO，读IO的吞吐量直接决定了消息堆积后的访问能力。

	
--分布式事务。
分布式事务涉及到两阶段提交。分为预提交阶段和commit阶段。在commit阶段需要回去改消息的状态。
RocketMq在这里没有使用KV存储来做。而是在commit阶段会拿到消息的offset，然后直接去找消息，修改其状态。这样的好处是设计更简单，速度更快。缺点是会产生过多的数据脏页。
3 RocketMQ 物理部署结构


4 RocketMQ的部署结构有以下特点：
Name Server是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。
Broker部署相对复杂，Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave的对应关系通过指定相同的BrokerName，不同的BrokerId来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。每个Broker与Name Server集群中的所有节点建立长连接，定时注册Topic信息到所有Name Server。
Producer与Name Server集群中的其中一个节点（随机选择）建立长连接，定期从Name Server取Topic路由信息，并向提供Topic服务的Master建立长连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。
Consumer与Name Server集群中的其中一个节点（随机选择）建立长连接，定期从Name Server取Topic路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。Consumer既可以从Master订阅消息，也可以从Slave订阅消息，订阅规则由Broker配置决定。
5 ZooKeeper是著名的分布式协作框架，提供了Master选举、分布式锁、数据的发布和订阅等诸多功能，为什么RocketMQ没有选择ZooKeeper，而是自己开发了NameServer，我们来具体看看NameServer在RocketMQ集群中的作用就明了了。
结论一：NameServer用来保存活跃的broker列表，包括Master和Slave。
结论二：NameServer用来保存所有topic和该topic所有队列的列表
结论三：NameServer用来保存所有broker的Filter列表。

现在我们再回过头来看看RocketMQ为什么不使用ZooKeeper？
ZooKeeper可以提供Master选举功能，比如Kafka用来给每个分区选一个broker作为leader，
但对于RocketMQ来说，topic的数据在每个Master上是对等的，没有哪个Master上有topic上的全部数据，所以这里选举leader没有意义；

RockeqMQ集群中，需要有构件来处理一些通用数据，比如broker列表，broker刷新时间，虽然ZooKeeper也能存放数据，并有一致性保证，
但处理数据之间的一些逻辑关系却比较麻烦，而且数据的逻辑解析操作得交给ZooKeeper客户端来做，如果有多种角色的客户端存在，自
己解析多级数据确实是个麻烦事情；既然RocketMQ集群中没有用到ZooKeeper的一些重量级的功能，只是使用ZooKeeper的数据一致性和发
布订阅的话，与其依赖重量级的ZooKeeper，还不如写个轻量级的NameServer，NameServer也可以集群部署，NameServer与NameServer之
间无任何信息同步，只有一千多行代码的NameServer稳定性肯定高于ZooKeeper，占用的系统资源也可以忽略不计。

6 RocketMQ 逻辑部署结构


如上图所示，RocketMQ的逻辑部署结构有Producer和Consumer两个特点。
Producer Group
用来表示一个发送消息应用，一个Producer Group下包含多个Producer实例，可以是多台机器，也可以是一台机器的多个进程，或者一个进程的多个Producer对象。一个Producer Group可以发送多个Topic消息，Producer Group作用如下：
1.标识一类Producer
2.可以通过运维工具查询这个发送消息应用下有多个Producer实例
3.发送分布式事务消息时，如果Producer中途意外宕机，Broker会主动回调Producer Group内的任意一台机器来确认事务状态。
Consumer Group
用来表示一个消费消息应用，一个Consumer Group下包含多个Consumer实例，可以是多台机器，也可以是多个进程，或者是一个进程的多个Consumer对象。一个Consumer Group下的多个Consumer以均摊方式消费消息，如果设置为广播方式，那么这个Consumer Group下的每个实例都消费全量数据。
7 RocketMQ 数据存储结构

如上图所示，RocketMQ采取了一种数据与索引分离的存储方法。有效降低文件资源、IO资源，内存资源的损耗。即便是阿里这种海量数据，高并发场景也能够有效降低端到端延迟，并具备较强的横向扩展能力。

8 RocketMQ的重复问题解决方式：
a.MQ的消费端执行的操作具有幂等性，即无论多少次重复执行，其结果是一样的；
b.MQ的消费端做重复校验，比如将受到MQ消息的唯一编号保存到Redis中，即每次收到消息时，将检查唯一编号是否已经在Redis中，如果存在说明消息重复；否则将唯一编号放入到Redis中，可以根据系统需要设置唯一编号在Redis中的过期时间，以防止Redis溢出。
nameServer顾名思义，在系统中肯定是做命名服务，服务治理方面的工作，功能应该是和zookeeper差不多，据我了解，RocketMq的早期版本确实是使用的zookeeper,后来改为了自己实现的nameserver。现在来看一下nameServer在RocketMQ中的两个主要作用：
    1 NameServer维护了一份Broker的地址列表和，broker在启动的时候会去NameServer进行注册，会维护Broker的存活状态.
2 NameServer维护了一份Topic和Topic对应队列的地址列表,broker每次发送心跳过来的时候都会把Topic信息带上.

9 RocketMQ的Maven依赖
    <dependency>  
        <groupId>com.alibaba.rocketmq</groupId>  
        <artifactId>rocketmq-client</artifactId>  
        <version>3.2.6</version>  
    </dependency>  





二、ms相关
1、说说你们公司线上生产环境用的是什么消息中间件?
见【2、多个mq如何选型？】

2、多个mq如何选型？
MQ	描述
RabbitMQ	erlang开发，对消息堆积的支持并不好，当大量消息积压的时候，会导致 RabbitMQ 的性能急剧下降。每秒钟可以处理几万到十几万条消息。
RocketMQ	java开发，面向互联网集群化功能丰富，对在线业务的响应时延做了很多的优化，大多数情况下可以做到毫秒级的响应，每秒钟大概能处理几十万条消息。
Kafka	Scala开发，面向日志功能丰富，性能最高。当你的业务场景中，每秒钟消息数量没有那么多的时候，Kafka 的时延反而会比较高。所以，Kafka 不太适合在线业务场景。
ActiveMQ	java开发，简单，稳定，性能不如前面三个。小型系统用也ok，但是不推荐。推荐用互联网主流的。

3、为什么要使用MQ？
因为项目比较大，做了分布式系统，所有远程服务调用请求都是同步执行经常出问题，所以引入了mq
作用	描述
解耦	系统耦合度降低，没有强依赖关系
异步	不需要同步执行的远程调用可以有效提高响应时间
削峰	请求达到峰值后，后端service还可以保持固定消费速率消费，不会被压垮

4、RocketMQ由哪些角色组成，每个角色作用和特点是什么？
角色	作用
Nameserver	无状态，动态列表；这也是和zookeeper的重要区别之一。zookeeper是有状态的。
Producer	消息生产者，负责发消息到Broker。
Broker	就是MQ本身，负责收发消息、持久化消息等。
Consumer	消息消费者，负责从Broker上拉取消息进行消费，消费完进行ack。

5、RocketMQ中的Topic和JMS的queue有什么区别？
queue就是来源于数据结构的FIFO队列。而Topic是个抽象的概念，每个Topic底层对应N个queue，而数据也真实存在queue上的。

6、RocketMQ Broker中的消息被消费后会立即删除吗？
不会，每条消息都会持久化到CommitLog中，每个Consumer连接到Broker后会维持消费进度信息，当有消息消费后只是当前Consumer的消费进度（CommitLog的offset）更新了。

追问：那么消息会堆积吗？什么时候清理过期消息？
4.6版本默认48小时后会删除不再使用的CommitLog文件

7、RocketMQ消费模式有几种？
消费模型由Consumer决定，消费维度为Topic。
（1）集群消费
1）一条消息只会被同Group中的一个Consumer消费
2）多个Group同时消费一个Topic时，每个Group都会有一个Consumer消费到数据
（2）广播消费
消息将对一 个Consumer Group 下的各个 Consumer 实例都消费一遍。即即使这些 Consumer 属于同一个Consumer Group ，消息也会被 Consumer Group 中的每个 Consumer 都消费一次。

8、消费消息是push还是pull？
RocketMQ没有真正意义的push，都是pull，虽然有push类，但实际底层实现采用的是长轮询机制，即拉取方式
broker端属性 longPollingEnable 标记是否开启长轮询。默认开启

追问：为什么要主动拉取消息而不使用事件监听方式？
事件驱动方式是建立好长连接，由事件（发送数据）的方式来实时推送。
如果broker主动推送消息的话有可能push速度快，消费速度慢的情况，那么就会造成消息在consumer端堆积过多，同时又不能被其他consumer消费的情况。而pull的方式可以根据当前自身情况来pull，不会造成过多的压力而造成瓶颈。所以采取了pull的方式。

9、broker如何处理拉取请求的？
Consumer首次请求Broker
Broker中是否有符合条件的消息
有 ->
响应Consumer
等待下次Consumer的请求
没有
DefaultMessageStore#ReputMessageService#run方法
PullRequestHoldService 来Hold连接，每个5s执行一次检查pullRequestTable有没有消息，有的话立即推送
每隔1ms检查commitLog中是否有新消息，有的话写入到pullRequestTable
当有新消息的时候返回请求
挂起consumer的请求，即不断开连接，也不返回数据
使用consumer的offset

10、RocketMQ如何做负载均衡？
通过Topic在多Broker中分布式存储实现。
1）producer端
发送端指定message queue发送消息到相应的broker，来达到写入时的负载均衡
提升写入吞吐量，当多个producer同时向一个broker写入数据的时候，性能会下降
消息分布在多broker中，为负载消费做准备
默认策略是随机选择：
producer维护一个index
每次取节点会自增
index向所有broker个数取余
自带容错策略
其他实现：
SelectMessageQueueByHash
hash的是传入的args
SelectMessageQueueByRandom
SelectMessageQueueByMachineRoom 没有实现
也可以自定义实现MessageQueueSelector接口中的select方法
MessageQueue select(final List<MessageQueue> mqs, final Message msg, final Object arg);
2）consumer端
采用的是平均分配算法来进行负载均衡。
3）其他负载均衡算法
平均分配策略(默认)(AllocateMessageQueueAveragely) 环形分配策略(AllocateMessageQueueAveragelyByCircle) 手动配置分配策略(AllocateMessageQueueByConfig) 机房分配策略(AllocateMessageQueueByMachineRoom) 一致性哈希分配策略(AllocateMessageQueueConsistentHash) 靠近机房策略(AllocateMachineRoomNearby)

追问：当消费负载均衡consumer和queue不对等的时候会发生什么？
Consumer和queue会优先平均分配，如果Consumer少于queue的个数，则会存在部分Consumer消费多个queue的情况，如果Consumer等于queue的个数，那就是一个Consumer消费一个queue，如果Consumer个数大于queue的个数，那么会有部分Consumer空余出来，白白的浪费了。

11、消息重复消费
影响消息正常发送和消费的重要原因是网络的不确定性。
1）引起重复消费的原因
ACK
正常情况下在consumer真正消费完消息后应该发送ack，通知broker该消息已正常消费，从queue中剔除
当ack因为网络原因无法发送到broker，broker会认为词条消息没有被消费，此后会开启消息重投机制把消息再次投递到consumer
消费模式
在CLUSTERING模式下，消息在broker中会保证相同group的consumer消费一次，但是针对不同group的consumer会推送多次
2）解决方案
数据库表
处理消息前，使用消息主键在表中带有约束的字段中insert
Map
单机时可以使用map ConcurrentHashMap -> putIfAbsent   guava cache
Redis
分布式锁搞起来。

12、如何让RocketMQ保证消息的顺序消费
你们线上业务用消息中间件的时候，是否需要保证消息的顺序性?
如果不需要保证消息顺序，为什么不需要?假如我有一个场景要保证消息的顺序，你们应该如何保证?
首先多个queue只能保证单个queue里的顺序，queue是典型的FIFO，天然顺序。多个queue同时消费是无法绝对保证消息的有序性的。所以总结如下：
同一topic，同一个QUEUE，发消息的时候一个线程去发送消息，消费的时候 一个线程去消费一个queue里的消息。

追问：怎么保证消息发到同一个queue？
Rocket MQ给我们提供了MessageQueueSelector接口，可以自己重写里面的接口，实现自己的算法，举个最简单的例子：判断i % 2 == 0，那就都放到queue1里，否则放到queue2里。

13、RocketMQ如何保证消息不丢失
首先在如下三个部分都可能会出现丢失消息的情况：Producer端、Broker端、Consumer端
1）Producer端如何保证消息不丢失
采取send()同步发消息，发送结果是同步感知的。
发送失败后可以重试，设置重试次数。默认3次。
producer.setRetryTimesWhenSendFailed(10);
集群部署，比如发送失败了的原因可能是当前Broker宕机了，重试的时候会发送到其他Broker上。
2）Broker端如何保证消息不丢失
修改刷盘策略为同步刷盘。默认情况下是异步刷盘的。
flushDiskType = SYNC_FLUSH
集群部署，主从模式，高可用。
3）Consumer端如何保证消息不丢失
完全消费正常后在进行手动ack确认。

14、rocketMQ的消息堆积如何处理
下游消费系统如果宕机了，导致几百万条消息在消息中间件里积压，此时怎么处理?
你们线上是否遇到过消息积压的生产故障?如果没遇到过，你考虑一下如何应对?
首先要找到是什么原因导致的消息堆积，是Producer太多了，Consumer太少了导致的还是说其他情况，总之先定位问题。
然后看下消息消费速度是否正常，正常的话，可以通过上线更多consumer临时解决消息堆积问题

追问：如果Consumer和Queue不对等，上线了多台也在短时间内无法消费完堆积的消息怎么办？
准备一个临时的topic
queue的数量是堆积的几倍
queue分布到多Broker中
上线一台Consumer做消息的搬运工，把原来Topic中的消息挪到新的Topic里，不做业务逻辑处理，只是挪过去
上线N台Consumer同时消费临时Topic中的数据
改bug
恢复原来的Consumer，继续消费之前的Topic

追问：堆积时间过长消息超时了？
RocketMQ中的消息只会在commitLog被删除的时候才会消失，不会超时。也就是说未被消费的消息不会存在超时删除这情况。

追问：堆积的消息会不会进死信队列？
不会，消息在消费失败后会进入重试队列（%RETRY%+ConsumerGroup），18次（默认18次，网上所有文章都说是16次，无一例外。但是我没搞懂为啥是16次，这不是18个时间吗 ？）才会进入死信队列（%DLQ%+ConsumerGroup）。

15、RocketMQ在分布式事务支持这块机制的底层原理?
你们用的是RocketMQ?RocketMQ很大的一个特点是对分布式事务的支持，你说说他在分布式事务支持这块机制的底层原理?
分布式系统中的事务可以使用TCC（Try、Confirm、Cancel）、2pc来解决分布式系统中的消息原子性
RocketMQ 4.3+提供分布事务功能，通过 RocketMQ 事务消息能达到分布式事务的最终一致
RocketMQ实现方式：
**Half Message：**预处理消息，当broker收到此类消息后，会存储到RMQ_SYS_TRANS_HALF_TOPIC的消息消费队列中
**检查事务状态：**Broker会开启一个定时任务，消费RMQ_SYS_TRANS_HALF_TOPIC队列中的消息，每次执行任务会向消息发送者确认事务执行状态（提交、回滚、未知），
如果是未知，Broker会定时去回调在重新检查
**超时：**如果超过回查次数，默认回滚消息。
也就是他并未真正进入Topic的queue，而是用了临时queue来放所谓的half message，等提交事务后才会真正的将half message转移到topic下的queue。

16、如果让你来动手实现一个分布式消息中间件，整体架构你会如何设计实现?
我个人觉得从以下几个点回答吧：
需要考虑能快速扩容、天然支持集群
持久化的姿势
高可用性
数据0丢失的考虑
服务端部署简单、client端使用简单

17、看过RocketMQ 的源码没有。如果看过，说说你对RocketMQ 源码的理解?
要真让我说，我会吐槽蛮烂的，首先没任何注释，可能是之前阿里巴巴写了中文注释，捐赠给apache后，apache觉得中文注释不能留，自己又懒得写英文注释，就都给删了。里面比较典型的设计模式有单例、工厂、策略、门面模式。单例工厂无处不在，策略印象深刻比如发消息和消费消息的时候queue的负载均衡就是N个策略算法类，有随机、hash等，这也是能够快速扩容天然支持集群的必要原因之一。持久化做的也比较完善，采取的CommitLog来落盘，同步异步两种方式。

18、高吞吐量下如何优化生产者和消费者的性能?
开发
同一group下，多机部署，并行消费
单个Consumer提高消费线程个数
批量消费
消息批量拉取
业务逻辑批量处理
运维
网卡调优
jvm调优
多线程与cpu调优
Page Cache

19、再说说RocketMQ 是如何保证数据的高容错性的?
在不开启容错的情况下，轮询队列进行发送，如果失败了，重试的时候过滤失败的Broker
如果开启了容错策略，会通过RocketMQ的预测机制来预测一个Broker是否可用
如果上次失败的Broker可用那么还是会选择该Broker的队列
如果上述情况失败，则随机选择一个进行发送
在发送消息的时候会记录一下调用的时间与是否报错，根据该时间去预测broker的可用时间
其实就是send消息的时候queue的选择。源码在如下：
org.apache.rocketmq.client.latency.MQFaultStrategy#selectOneMessageQueue()

20、任何一台Broker突然宕机了怎么办？
Broker主从架构以及多副本策略。Master收到消息后会同步给Slave，这样一条消息就不止一份了，Master宕机了还有slave中的消息可用，保证了MQ的可靠性和高可用性。而且Rocket MQ4.5.0开始就支持了Dlegder模式，基于raft的，做到了真正意义的HA。

21、Broker把自己的信息注册到哪个NameServer上？
这么问明显在坑你，因为Broker会向所有的NameServer上注册自己的信息，而不是某一个，是每一个，全部！
---------------------------------------------------------------------------------------------------------------
------------------------------------------rocketmq basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------spark basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1、Spark简介
Spark是加州大学伯克利分校AMP实验室（Algorithms, Machines, and People Lab）开发通用内存并行计算框架。Spark在2013年6月进入Apache成为孵化项目，8个月后成为Apache顶级项目，速度之快足见过人之处，Spark以其先进的设计理念，迅速成为社区的热门项目，围绕着Spark推出了Spark SQL、Spark Streaming、MLLib和GraphX等组件，也就是BDAS（伯克利数据分析栈），这些组件逐渐形成大数据处理一站式解决平台。从各方面报道来看Spark抱负并非池鱼，而是希望替代Hadoop在大数据中的地位，成为大数据处理的主流标准，不过Spark还没有太多大项目的检验，离这个目标还有很大路要走。Spark使用Scala语言进行实现，它是一种面向对象、函数式编程语言，能够像操作本地集合对象一样轻松地操作分布式数据集（Scala提供一个称为 Actor 的并行模型，其中Actor通过它的收件箱来发送和接收非同步信息而不是共享数据，该方式被称为：Shared Nothing模型）。

2 Spark特点
（1）运行速度快
Spark拥有DAG执行引擎，支持在内存中对数据进行迭代计算。官方提供的数据表明，如果数据由磁盘读取，速度是Hadoop MapReduce的10倍以上，如果数据从内存中读取，速度可以高达100多倍。
（2）易用性好
Spark不仅支持Scala编写应用程序，而且支持Java和Python等语言进行编写，特别是Scala是一种高效、可拓展的语言，能够用简洁的代码处理较为复杂的处理工作。
（3）通用性强
Spark生态圈即BDAS（伯克利数据分析栈）包含了Spark Core、Spark SQL、Spark Streaming、MLLib和GraphX等组件，这些组件分别处理Spark Core提供内存计算框架、SparkStreaming的实时处理应用、Spark SQL的即席查询、MLlib或MLbase的机器学习和GraphX的图处理，它们都是由AMP实验室提供，能够无缝的集成并提供一站式解决平台。
（4）随处运行
Spark具有很强的适应性，能够读取HDFS、Cassandra、HBase、S3和Techyon为持久层读写原生数据，能够以Mesos、YARN和自身携带的Standalone作为资源管理器调度job，来完成Spark应用程序的计算。

3 Spark与Hadoop差异
（1）Spark是在借鉴了MapReduce之上发展而来的，继承了其分布式并行计算的优点并改进了MapReduce明显的缺陷，具体如下：
首先，Spark把中间数据放到内存中，迭代运算效率高。MapReduce中计算结果需要落地，保存到磁盘上，这样势必会影响整体速度，而Spark支持DAG图的分布式并行计算的编程框架，减少了迭代过程中数据的落地，提高了处理效率。
（2）Spark容错性高。Spark引进了弹性分布式数据集RDD (Resilient Distributed Dataset) 的抽象，它是分布在一组节点中的只读对象集合，这些集合是弹性的，如果数据集一部分丢失，则可以根据“血统”（即充许基于数据衍生过程）对它们进行重建。另外在RDD计算时可以通过CheckPoint来实现容错，而CheckPoint有两种方式：CheckPoint
 Data，和Logging The Updates，用户可以控制采用哪种方式来实现容错。
（3）Spark更加通用。不像Hadoop只提供了Map和Reduce两种操作，Spark提供的数据集操作类型有很多种，大致分为：Transformations和Actions两大类。Transformations包括Map、Filter、FlatMap、Sample、GroupByKey、ReduceByKey、Union、Join、Cogroup、MapValues、Sort和PartionBy等多种操作类型，同时还提供Count。 Actions包括Collect、Reduce、Lookup和Save等操作。另外各个处理节点之间的通信模型不再像Hadoop只有Shuffle一种模式，用户可以命名、物化，控制中间结果的存储、分区等。

 4 Spark的适用场景
（1）复杂的批量处理（Batch Data Processing），偏重点在于处理海量数据的能力，至于处理速度可忍受，通常的时间可能是在数十分钟到数小时；
（2）基于历史数据的交互式查询（Interactive Query），通常的时间在数十秒到数十分钟之间。
（3）基于实时数据流的数据处理（Streaming Data Processing），通常在数百毫秒到数秒之间。
（4）Spark是基于内存的迭代计算框架，适用于需要多次操作特定数据集的应用场合。需要反复操作的次数越多，所需读取的数据量越大，受益越大，数据量小但是计算密集度较大的场合，受益就相对较小。
（5）由于RDD的特性，Spark不适用那种异步细粒度更新状态的应用，例如web服务的存储或者是增量的web爬虫和索引。就是对于那种增量修改的应用模型不适合
（6）数据量不是特别大，但是要求实时统计分析需求

5 Spark演进时间表
  2009年由Berkeley's AMPLab开始编写最初的源代码
  2010年开放源代码
  2013年6月进入Apache孵化器项目
  2014年2月成为Apache的顶级项目（8个月时间）
  2014年5月底Spark1.0.0发布
  2014年9月Spark1.1.0发布
  2014年12月Spark1.2.0发布
  目前已经有30+公司100+开发者在提交代码
  Hadoop最大的厂商Cloudera宣称加大Spark框架的投入来取代Mapreduce
  Hortonworks
  Hadoop厂商MapR投入Spark阵营
  Apache Mahout放弃MapReduce，将使用Spark作为后续算子的计算平台

6 Spark成功案例
目前大数据在互联网公司主要应用在广告、报表、推荐系统等业务上。在广告业务方面需要大数据做应用分析、效果分析、定向优化等，在推荐系统方面则需要大数据优化相关排名、个性化推荐以及热点点击分析等。这些应用场景的普遍特点是计算量大、效率要求高。Spark恰恰满足了这些要求，该项目一经推出便受到开源社区的广泛关注和好评。并在近两年内发展成为大数据处理领域最炙手可热的开源项目。
（1）腾讯
广点通是最早使用Spark的应用之一。腾讯大数据精准推荐借助Spark快速迭代的优势，围绕“数据+算法+系统”这套技术方案，实现了在“数据实时采集、算法实时训练、系统实时预测”的全流程实时并行高维算法，最终成功应用于广点通pCTR投放系统上，支持每天上百亿的请求量。
基于日志数据的快速查询系统业务构建于Spark之上的Shark，利用其快速查询以及内存表等优势，承担了日志数据的即席查询工作。在性能方面，普遍比Hive高2-10倍，如果使用内存表的功能，性能将会比Hive快百倍。
（2）Yahoo
Yahoo将Spark用在Audience Expansion中的应用。Audience Expansion是广告中寻找目标用户的一种方法：首先广告者提供一些观看了广告并且购买产品的样本客户，据此进行学习，寻找更多可能转化的用户，对他们定向广告。Yahoo采用的算法是logistic regression。同时由于有些SQL负载需要更高的服务质量，又加入了专门跑Shark的大内存集群，用于取代商业BI/OLAP工具，承担报表/仪表盘和交互式/即席查询，同时与桌面BI工具对接。目前在Yahoo部署的Spark集群有112台节点，9.2TB内存。
（3）淘宝
阿里搜索和广告业务，最初使用Mahout或者自己写的MR来解决复杂的机器学习，导致效率低而且代码不易维护。淘宝技术团队使用了Spark来解决多次迭代的机器学习算法、高计算复杂度的算法等。将Spark运用于淘宝的推荐相关算法上,同时还利用Graphx解决了许多生产问题，包括以下计算场景：基于度分布的中枢节点发现、基于最大连通图的社区发现、基于三角形计数的关系衡量、基于随机游走的用户属性传播等。
（4）优酷土豆
优酷土豆在使用Hadoop集群的突出问题主要包括：第一是商业智能BI方面，分析师提交任务之后需要等待很久才得到结果；第二就是大数据量计算，比如进行一些模拟广告投放之时，计算量非常大的同时对效率要求也比较高，最后就是机器学习和图计算的迭代运算也是需要耗费大量资源且速度很慢。
最终发现这些应用场景并不适合在MapReduce里面去处理。通过对比，发现Spark性能比MapReduce提升很多。首先，交互查询响应快，性能比Hadoop提高若干倍；模拟广告投放计算效率高、延迟小（同hadoop比延迟至少降低一个数量级）；机器学习、图计算等迭代计算，大大减少了网络传输、数据落地等，极大的提高的计算性能。目前Spark已经广泛使用在优酷土豆的视频推荐（图计算）、广告业务等。

9 生态系统
Spark生态圈也称为BDAS（伯克利数据分析栈），是伯克利APMLab实验室打造的，力图在算法（Algorithms）、机器（Machines）、人（People）之间通过大规模集成来展现大数据应用的一个平台。伯克利AMPLab运用大数据、云计算、通信等各种资源以及各种灵活的技术方案，对海量不透明的数据进行甄别并转化为有用的信息，以供人们更好的理解世界。该生态圈已经涉及到机器学习、数据挖掘、数据库、信息检索、自然语言处理和语音识别等多个领域。
Spark生态圈以Spark Core为核心，从HDFS、Amazon S3和HBase等持久层读取数据，以MESS、YARN和自身携带的Standalone为资源管理器调度Job完成Spark应用程序的计算。 这些应用程序可以来自于不同的组件，如Spark Shell/Spark Submit的批处理、Spark Streaming的实时处理应用、Spark SQL的即席查询、BlinkDB的权衡查询、MLlib/MLbase的机器学习、GraphX的图处理和SparkR的数学计算等等。

10 Spark Core
（1）提供了有向无环图（DAG）的分布式并行计算框架，并提供Cache机制来支持多次迭代计算或者数据共享，大大减少迭代计算之间读取数据局的开销，这对于需要进行多次迭代的数据挖掘和分析性能有很大提升
（2）在Spark中引入了RDD (Resilient Distributed Dataset) 的抽象，它是分布在一组节点中的只读对象集合，这些集合是弹性的，如果数据集一部分丢失，则可以根据“血统”对它们进行重建，保证了数据的高容错性；
（3）移动计算而非移动数据，RDD Partition可以就近读取分布式文件系统中的数据块到各个节点内存中进行计算
 （4）使用多线程池模型来减少task启动开稍
 （5）采用容错的、高可伸缩性的akka作为通讯框架

11 SparkStreaming
SparkStreaming是一个对实时数据流进行高通量、容错处理的流式处理系统，可以对多种数据源（如Kdfka、Flume、Twitter、Zero和TCP 套接字）进行类似Map、Reduce和Join等复杂操作，并将结果保存到外部文件系统、数据库或应用到实时仪表盘。
（1）计算流程：Spark Streaming是将流式计算分解成一系列短小的批处理作业。这里的批处理引擎是Spark Core，也就是把Spark Streaming的输入数据按照batch size（如1秒）分成一段一段的数据（Discretized Stream），每一段数据都转换成Spark中的RDD（Resilient Distributed Dataset），然后将Spark Streaming中对DStream的Transformation操作变为针对Spark中对RDD的Transformation操作，将RDD经过操作变成中间结果保存在内存中。整个流式计算根据业务的需求可以对中间的结果进行叠加或者存储到外部设备。下图显示了Spark Streaming的整个流程。
（2）容错性：对于流式计算来说，容错性至关重要。首先我们要明确一下Spark中RDD的容错机制。每一个RDD都是一个不可变的分布式可重算的数据集，其记录着确定性的操作继承关系（lineage），所以只要输入数据是可容错的，那么任意一个RDD的分区（Partition）出错或不可用，都是可以利用原始输入数据通过转换操作而重新算出的。  对于Spark Streaming来说，其RDD的传承关系如下图所示，图中的每一个椭圆形表示一个RDD，椭圆形中的每个圆形代表一个RDD中的一个Partition，图中的每一列的多个RDD表示一个DStream（图中有三个DStream），而每一行最后一个RDD则表示每一个Batch Size所产生的中间结果RDD。我们可以看到图中的每一个RDD都是通过lineage相连接的，由于Spark Streaming输入数据可以来自于磁盘，例如HDFS（多份拷贝）或是来自于网络的数据流（Spark Streaming会将网络输入数据的每一个数据流拷贝两份到其他的机器）都能保证容错性，所以RDD中任意的Partition出错，都可以并行地在其他机器上将缺失的Partition计算出来。这个容错恢复方式比连续计算模型（如Storm）的效率更高。
（3）实时性：对于实时性的讨论，会牵涉到流式处理框架的应用场景。Spark Streaming将流式计算分解成多个Spark Job，对于每一段数据的处理都会经过Spark DAG图分解以及Spark的任务集的调度过程。对于目前版本的Spark Streaming而言，其最小的Batch Size的选取在0.5~2秒钟之间（Storm目前最小的延迟是100ms左右），所以Spark
 Streaming能够满足除对实时性要求非常高（如高频实时交易）之外的所有流式准实时计算场景。
（4）扩展性与吞吐量：Spark目前在EC2上已能够线性扩展到100个节点（每个节点4Core），可以以数秒的延迟处理6GB/s的数据量（60M records/s），其吞吐量也比流行的Storm高2～5倍，图4是Berkeley利用WordCount和Grep两个用例所做的测试，在Grep这个测试中，Spark Streaming中的每个节点的吞吐量是670k records/s，而Storm是115k records/s。

12 Spark SQL
Shark是SparkSQL的前身，它发布于3年前，那个时候Hive可以说是SQL on Hadoop的唯一选择，负责将SQL编译成可扩展的MapReduce作业，鉴于Hive的性能以及与Spark的兼容，Shark项目由此而生。
Shark即Hive on Spark，本质上是通过Hive的HQL解析，把HQL翻译成Spark上的RDD操作，然后通过Hive的metadata获取数据库里的表信息，实际HDFS上的数据和文件，会由Shark获取并放到Spark上运算。Shark的最大特性就是快和与Hive的完全兼容，且可以在shell模式下使用rdd2sql()这样的API，把HQL得到的结果集，继续在scala环境下运算，支持自己编写简单的机器学习或简单分析处理函数，对HQL结果进一步分析计算。在2014年7月1日的Spark Summit上，Databricks宣布终止对Shark的开发，将重点放到Spark SQL上。Databricks表示，Spark SQL将涵盖Shark的所有特性，用户可以从Shark 0.9进行无缝的升级。在会议上，Databricks表示，Shark更多是对Hive的改造，替换了Hive的物理执行引擎，因此会有一个很快的速度。然而，不容忽视的是，Shark继承了大量的Hive代码，因此给优化和维护带来了大量的麻烦。随着性能优化和先进分析整合的进一步加深，基于MapReduce设计的部分无疑成为了整个项目的瓶颈。因此，为了更好的发展，给用户提供一个更好的体验，Databricks宣布终止Shark项目，从而将更多的精力放到SparkSQL上。
Spark SQL允许开发人员直接处理RDD，同时也可查询例如在 Apache Hive上存在的外部数据。Spark SQL的一个重要特点是其能够统一处理关系表和RDD，使得开发人员可以轻松地使用SQL命令进行外部查询，同时进行更复杂的数据分析。除了Spark SQL外，Michael还谈到Catalyst优化框架，它允许Spark SQL自动修改查询方案，使SQL更有效地执行。
还有Shark的作者是来自中国的博士生辛湜（Reynold Xin），也是Spark的核心成员，具体信息可以看他的专访http://www.csdn.net/article/2013-04-26/2815057-Spark-Reynold。
（1）Spark SQL的特点:
1） 引入了新的RDD类型SchemaRDD，可以象传统数据库定义表一样来定义SchemaRDD，SchemaRDD由定义了列数据类型的行对象构成。SchemaRDD可以从RDD转换过来，也可以从Parquet文件读入，也可以使用HiveQL从Hive中获取。
2）内嵌了Catalyst查询优化框架，在把SQL解析成逻辑执行计划之后，利用Catalyst包里的一些类和接口，执行了一些简单的执行计划优化，最后变成RDD的计算
3）在应用程序中可以混合使用不同来源的数据，如可以将来自HiveQL的数据和来自SQL的数据进行Join操作。
Shark的出现使得SQL-on-Hadoop的性能比Hive有了10-100倍的提高，  那么，摆脱了Hive的限制，SparkSQL的性能又有怎么样的表现呢？虽然没有Shark相对于Hive那样瞩目地性能提升，但也表现得非常优异
（2）sparkSQL在下面几点做了优化
1） 内存列存储（In-Memory Columnar Storage） sparkSQL的表数据在内存中存储不是采用原生态的JVM对象存储方式，而是采用内存列存储；
2）字节码生成技术（Bytecode Generation） Spark1.1.0在Catalyst模块的expressions增加了codegen模块，使用动态字节码生成技术，对匹配的表达式采用特定的代码动态编译。另外对SQL表达式都作了CG优化， CG优化的实现主要还是依靠Scala2.10的运行时放射机制（runtimereflection）；
3）Scala代码优化 SparkSQL在使用Scala编写代码的时候，尽量避免低效的、容易GC的代码；尽管增加了编写代码的难度，但对于用户来说接口统一。

13 BlinkDB
BlinkDB 是一个用于在海量数据上运行交互式 SQ查询的大规模并行查询引擎，它允许用户通过权衡数据精度来提升查询响应时间，其数据的精度被控制在允许的误差范围内。为了达到这个目标，BlinkDB 使用两个核心思想:
（1）一个自适应优化框架，从原始数据随着时间的推移建立并维护一组多维样本；
（2）一个动态样本选择策略，选择一个适当大小的示例基于查询的准确性和（或）响应时间需求。和传统关系型数据库不同，BlinkDB是一个很有意思的交互式查询系统，就像一个跷跷板，用户需要在查询精度和查询时间上做一权衡；如果用户想更快地获取查询结果，那么将牺牲查询结果的精度；同样的，用户如果想获取更高精度的查询结果，就需要牺牲查询响应时间。用户可以在查询的时候定义一个失误边界。

14 MLBase/MLlib
MLBase是Spark生态圈的一部分专注于机器学习，让机器学习的门槛更低，让一些可能并不了解机器学习的用户也能方便地使用MLbase。MLBase分为四部分：MLlib、MLI、ML Optimizer和MLRuntime。
（1）ML Optimizer会选择它认为最适合的已经在内部实现好了的机器学习算法和相关参数，来处理用户输入的数据，并返回模型或别的帮助分析的结果；
（2）MLI 是一个进行特征抽取和高级ML编程抽象的算法实现的API或平台；
（3）MLlib是Spark实现一些常见的机器学习算法和实用程序，包括分类、回归、聚类、协同过滤、降维以及底层优化，该算法可以进行可扩充； MLRuntime 基于Spark计算框架，将Spark的分布式计算应用到机器学习领域。
（4）与其他机器学习Weka和Mahout不同的是：
 MLBase是分布式的，Weka是一个单机的系统；
 MLBase是自动化的，Weka和Mahout都需要使用者具备机器学习技能，来选择自己想要的算法和参数来做处理；
 MLBase提供了不同抽象程度的接口，让算法可以扩充
 MLBase基于Spark这个平台

15 GraphX
（1）GraphX是Spark中用于图(e.g., Web-Graphs and Social Networks)和图并行计算(e.g., PageRank and Collaborative Filtering)的API,可以认为是GraphLab(C++)和Pregel(C++)在Spark(Scala)上的重写及优化，跟其他分布式图计算框架相比，GraphX最大的贡献是，在Spark之上提供一栈式数据解决方案，可以方便且高效地完成图计算的一整套流水作业。GraphX最先是伯克利AMPLAB的一个分布式图计算框架项目，后来整合到Spark中成为一个核心组件。

（2）GraphX的核心抽象是Resilient Distributed Property Graph，一种点和边都带属性的有向多重图。它扩展了Spark RDD的抽象，有Table和Graph两种视图，而只需要一份物理存储。两种视图都有自己独有的操作符，从而获得了灵活操作和执行效率。如同Spark，GraphX的代码非常简洁。GraphX的核心代码只有3千多行，而在此之上实现的Pregel模型，只要短短的20多行。GraphX的代码结构整体下图所示，其中大部分的实现，都是围绕Partition的优化进行的。这在某种程度上说明了点分割的存储和相应的计算优化的确是图计算框架的重点和难点。
（3）GraphX的底层设计有以下几个关键点。
1）.对Graph视图的所有操作，最终都会转换成其关联的Table视图的RDD操作来完成。这样对一个图的计算，最终在逻辑上，等价于一系列RDD的转换过程。因此，Graph最终具备了RDD的3个关键特性：Immutable、Distributed和Fault-Tolerant。其中最关键的是Immutable（不变性）。逻辑上，所有图的转换和操作都产生了一个新图；物理上，GraphX会有一定程度的不变顶点和边的复用优化，对用户透明。
2）.两种视图底层共用的物理数据，由RDD[Vertex-Partition]和RDD[EdgePartition]这两个RDD组成。点和边实际都不是以表Collection[tuple]的形式存储的，而是由VertexPartition/EdgePartition在内部存储一个带索引结构的分片数据块，以加速不同视图下的遍历速度。不变的索引结构在RDD转换过程中是共用的，降低了计算和存储开销。
3）.图的分布式存储采用点分割模式，而且使用partitionBy方法，由用户指定不同的划分策略（PartitionStrategy）。划分策略会将边分配到各个EdgePartition，顶点Master分配到各个VertexPartition，EdgePartition也会缓存本地边关联点的Ghost副本。划分策略的不同会影响到所需要缓存的Ghost副本数量，以及每个EdgePartition分配的边的均衡程度，需要根据图的结构特征选取最佳策略。目前有EdgePartition2d、EdgePartition1d、RandomVertexCut和CanonicalRandomVertexCut这四种策略。在淘宝大部分场景下，EdgePartition2d效果最好。

16 SparkR
（1）SparkR是AMPLab发布的一个R开发包，使得R摆脱单机运行的命运，可以作为Spark的job运行在集群上，极大得扩展了R的数据处理能力。
（2）SparkR的几个特性：
1）提供了Spark中弹性分布式数据集（RDD）的API，用户可以在集群上通过R shell交互性的运行Spark job。
2）支持序化闭包功能，可以将用户定义函数中所引用到的变量自动序化发送到集群中其他的机器上。
3）SparkR还可以很容易地调用R开发包，只需要在集群上执行操作前用includePackage读取R开发包就可以了，当然集群上要安装R开发包。

17 Tachyon
（1）Tachyon是一个高容错的分布式文件系统，允许文件以内存的速度在集群框架中进行可靠的共享，就像Spark和 MapReduce那样。通过利用信息继承，内存侵入，Tachyon获得了高性能。Tachyon工作集文件缓存在内存中，并且让不同的 Jobs/Queries以及框架都能内存的速度来访问缓存文件”。因此，Tachyon可以减少那些需要经常使用的数据集通过访问磁盘来获得的次数。Tachyon兼容Hadoop，现有的Spark和MR程序不需要任何修改而运行。在2013年4月，AMPLab共享了其Tachyon 0.2.0 Alpha版本的Tachyon，其宣称性能为HDFS的300倍，继而受到了极大的关注。
（2）Tachyon的几个特性如下：
1）JAVA-Like File API
Tachyon提供类似JAVA File类的API
2）兼容性
Tachyon实现了HDFS接口，所以Spark和MR程序不需要任何修改即可运行。
3）可插拔的底层文件系统
Tachyon是一个可插拔的底层文件系统，提供容错功能。tachyon将内存数据记录在底层文件系统。它有一个通用的接口，使得可以很容易的插入到不同的底层文件系统。目前支持HDFS，S3，GlusterFS和单节点的本地文件系统，以后将支持更多的文件系统。

18 术语定义
（1）应用程序（Application）： 基于Spark的用户程序，包含了一个Driver Program 和集群中多个的Executor；
（2）驱动程序（Driver Program）：运行Application的main()函数并且创建SparkContext，通常用SparkContext代表Driver Program；
（3）执行单元（Executor）： 是为某Application运行在Worker Node上的一个进程，该进程负责运行Task，并且负责将数据存在内存或者磁盘上，每个Application都有各自独立的Executors；
（4）集群管理程序（Cluster Manager）： 在集群上获取资源的外部服务(例如：Standalone、Mesos或Yarn)；
（5）操作（Operation）：作用于RDD的各种操作分为Transformation和Action；

19 模型组成
（1）Driver部分
Driver部分主要是对SparkContext进行配置、初始化以及关闭。初始化SparkContext是为了构建Spark应用程序的运行环境，在初始化SparkContext，要先导入一些Spark的类和隐式转换；在Executor部分运行完毕后，需要将SparkContext关闭。
（2） Executor部分
Spark应用程序的Executor部分是对数据的处理，数据分三种：
1）原生数据
包含原生的输入数据和输出数据
l对于输入原生数据，Spark目前提供了两种：
Ø  Scala集合数据集：如Array(1,2,3,4,5)，Spark使用parallelize方法转换成RDD
Ø  Hadoop数据集：Spark支持存储在hadoop上的文件和hadoop支持的其他文件系统，如本地文件、HBase、SequenceFile和Hadoop的输入格式。例如Spark使用txtFile方法可以将本地文件或HDFS文件转换成RDD
l对于输出数据，Spark除了支持以上两种数据，还支持scala标量
Ø  生成Scala标量数据，如count（返回RDD中元素的个数）、reduce、fold/aggregate；返回几个标量，如take（返回前几个元素）。
Ø  生成Scala集合数据集，如collect（把RDD中的所有元素倒入 Scala集合类型）、lookup（查找对应key的所有值）。
Ø  生成hadoop数据集，如saveAsTextFile、saveAsSequenceFile
2） RDD
RDD具体在下一节中详细描述，RDD提供了四种算子：
@输入算子：将原生数据转换成RDD，如parallelize、txtFile等
@转换算子：最主要的算子，是Spark生成DAG图的对象，转换算子并不立即执行，在触发行动算子后再提交给driver处理，生成DAG图 -->  Stage --> Task  --> Worker执行。
@缓存算子：对于要多次使用的RDD，可以缓冲加快运行速度，对重要数据可以采用多备份缓存。
@行动算子：将运算结果RDD转换成原生数据，如count、reduce、collect、saveAsTextFile等。
3）共享变量
在Spark运行时，一个函数传递给RDD内的patition操作时，该函数所用到的变量在每个运算节点上都复制并维护了一份，并且各个节点之间不会相互影响。但是在Spark Application中，可能需要共享一些变量，提供Task或驱动程序使用。Spark提供了两种共享变量：
@广播变量（Broadcast Variables）：可以缓存到各个节点的共享变量，通常为只读
– 广播变量缓存到各个节点的内存中，而不是每个 Task
– 广播变量被创建后，能在集群中运行的任何函数调用
– 广播变量是只读的，不能在被广播后修改
– 对于大数据集的广播， Spark 尝试使用高效的广播算法来降低通信成本
使用方法：
val broadcastVar = sc.broadcast(Array(1, 2, 3))

20 RDD
（1）RDD术语
1）弹性分布式数据集（RDD）： Resillient Distributed Dataset，Spark的基本计算单元，可以通过一系列算子进行操作（主要有Transformation和Action操作）；
2）有向无环图（DAG）：Directed Acycle graph，反应RDD之间的依赖关系；
3）有向无环图调度器（DAG Scheduler）：根据Job构建基于Stage的DAG，并提交Stage给TaskScheduler；
4）任务调度器（Task Scheduler）：将Taskset提交给worker（集群）运行并回报结果；
5）窄依赖（Narrow dependency）：子RDD依赖于父RDD中固定的data partition；
6）宽依赖（Wide Dependency）：子RDD对父RDD中的所有data partition都有依赖。
（2）RDD概念
RDD是Spark的最基本抽象,是对分布式内存的抽象使用，实现了以操作本地集合的方式来操作分布式数据集的抽象实现。RDD是Spark最核心的东西，它表示已被分区，不可变的并能够被并行操作的数据集合，不同的数据集格式对应不同的RDD实现。RDD必须是可序列化的。RDD可以cache到内存中，每次对RDD数据集的操作之后的结果，都可以存放到内存中，下一个操作可以直接从内存中输入，省去了MapReduce大量的磁盘IO操作。这对于迭代运算比较常见的机器学习算法, 交互式数据挖掘来说，效率提升非常大。
RDD 最适合那种在数据集上的所有元素都执行相同操作的批处理式应用。在这种情况下， RDD 只需记录血统中每个转换就能还原丢失的数据分区，而无需记录大量的数据操作日志。所以 RDD 不适合那些需要异步、细粒度更新状态的应用 ，比如 Web 应用的存储系统，或增量式的 Web 爬虫等。对于这些应用，使用具有事务更新日志和数据检查点的数据库系统更为高效。
（3）RDD的特点
1）.来源：一种是从持久存储获取数据，另一种是从其他RDD生成
2）.只读：状态不可变，不能修改
3）.分区：支持元素根据 Key 来分区 ( Partitioning ) ，保存到多个结点上，还原时只会重新计算丢失分区的数据，而不会影响整个系统
4）.路径：在 RDD 中叫世族或血统 ( lineage ) ，即 RDD 有充足的信息关于它是如何从其他 RDD 产生而来的
5）.持久化：可以控制存储级别（内存、磁盘等）来进行持久化
6）.操作：丰富的动作 ( Action ) ，如Count、Reduce、Collect和Save 等
（4）RDD基础数据类型
目前有两种类型的基础RDD：并行集合（Parallelized Collections）：接收一个已经存在的Scala集合，然后进行各种并行计算。 Hadoop数据集（Hadoop Datasets）：在一个文件的每条记录上运行函数。只要文件系统是HDFS，或者hadoop支持的任意存储系统即可。这两种类型的RDD都可以通过相同的方式进行操作，从而获得子RDD等一系列拓展，形成lineage血统关系图。

21 Spark运行架构
（1）Application：Spark Application的概念和Hadoop MapReduce中的类似，指的是用户编写的Spark应用程序，包含了一个Driver 功能的代码和分布在集群中多个节点上运行的Executor代码；
（2）Driver：Spark中的Driver即运行上述Application的main()函数并且创建SparkContext，其中创建SparkContext的目的是为了准备Spark应用程序的运行环境。在Spark中由SparkContext负责和ClusterManager通信，进行资源的申请、任务的分配和监控等；当Executor部分运行完毕后，Driver负责将SparkContext关闭。通常用SparkContext代表Drive；
（3）Executor：Application运行在Worker 节点上的一个进程，该进程负责运行Task，并且负责将数据存在内存或者磁盘上，每个Application都有各自独立的一批Executor。在Spark on Yarn模式下，其进程名称为CoarseGrainedExecutorBackend，类似于Hadoop MapReduce中的YarnChild。一个CoarseGrainedExecutorBackend进程有且仅有一个executor对象，它负责将Task包装成taskRunner，并从线程池中抽取出一个空闲线程运行Task。每个CoarseGrainedExecutorBackend能并行运行Task的数量就取决于分配给它的CPU的个数了；
（4）Cluster Manager：指的是在集群上获取资源的外部服务，目前有：
Ø  Standalone：Spark原生的资源管理，由Master负责资源的分配；
Ø  Hadoop Yarn：由YARN中的ResourceManager负责资源的分配；
（5）Worker：集群中任何可以运行Application代码的节点，类似于YARN中的NodeManager节点。在Standalone模式中指的就是通过Slave文件配置的Worker节点，在Spark on Yarn模式中指的就是NodeManager节点；
（6）作业（Job）：包含多个Task组成的并行计算，往往由Spark Action催生，一个JOB包含多个RDD及作用于相应RDD上的各种Operation；
（7）阶段（Stage）：每个Job会被拆分很多组Task，每组任务被称为Stage，也可称TaskSet，一个作业分为多个阶段；
（8）任务（Task）： 被送到某个Executor上的工作任务；


22 Spark运行基本流程
1）构建Spark Application的运行环境（启动SparkContext），SparkContext向资源管理器（可以是Standalone、Mesos或YARN）注册并申请运行Executor资源；
2）资源管理器分配Executor资源并启动StandaloneExecutorBackend，Executor运行情况将随着心跳发送到资源管理器上；
3）SparkContext构建成DAG图，将DAG图分解成Stage，并把Taskset发送给Task Scheduler。Executor向SparkContext申请Task，Task Scheduler将Task发放给Executor运行同时SparkContext将应用程序代码发放给Executor。
4）Task在Executor上运行，运行完毕释放所有资源。

23 Spark运行架构特点
（1）每个Application获取专属的executor进程，该进程在Application期间一直驻留，并以多线程方式运行tasks。这种Application隔离机制有其优势的，无论是从调度角度看（每个Driver调度它自己的任务），还是从运行角度看（来自不同Application的Task运行在不同的JVM中）。当然，这也意味着Spark Application不能跨应用程序共享数据，除非将数据写入到外部存储系统。
（2）Spark与资源管理器无关，只要能够获取executor进程，并能保持相互通信就可以了。
（3）提交SparkContext的Client应该靠近Worker节点（运行Executor的节点)，最好是在同一个Rack里，因为Spark Application运行过程中SparkContext和Executor之间有大量的信息交换；如果想在远程集群中运行，最好使用RPC将SparkContext提交给集群，不要远离Worker运行SparkContext。
（4）Task采用了数据本地性和推测执行的优化机制。

24 Spark在不同集群中的运行架构
Spark注重建立良好的生态系统，它不仅支持多种外部文件存储系统，提供了多种多样的集群运行模式。部署在单台机器上时，既可以用本地（Local）模式运行，也可以使用伪分布式模式来运行；当以分布式集群部署的时候，可以根据自己集群的实际情况选择Standalone模式（Spark自带的模式）、YARN-Client模式或者YARN-Cluster模式。Spark的各种运行模式虽然在启动方式、运行位置、调度策略上各有不同，但它们的目的基本都是一致的，就是在合适的位置安全可靠的根据用户的配置和Job的需要运行和管理Task。

25 Spark on Standalone运行过程
Standalone模式是Spark实现的资源调度框架，其主要的节点有Client节点、Master节点和Worker节点。其中Driver既可以运行在Master节点上中，也可以运行在本地Client端。当用spark-shell交互式工具提交Spark的Job时，Driver在Master节点上运行；当使用spark-submit工具提交Job或者在Eclips、IDEA等开发平台上使用”new SparkConf.setManager(“spark://master:7077”)”方式运行Spark任务时，Driver是运行在本地Client端上的。
1）.SparkContext连接到Master，向Master注册并申请资源（CPU Core 和Memory）；
2）.Master根据SparkContext的资源申请要求和Worker心跳周期内报告的信息决定在哪个Worker上分配资源，然后在该Worker上获取资源，然后启动StandaloneExecutorBackend；
3）.StandaloneExecutorBackend向SparkContext注册；
4）.SparkContext将Applicaiton代码发送给StandaloneExecutorBackend；并且SparkContext解析Applicaiton代码，构建DAG图，并提交给DAG Scheduler分解成Stage（当碰到Action操作时，就会催生Job；每个Job中含有1个或多个Stage，Stage一般在获取外部数据和shuffle之前产生），然后以Stage（或者称为TaskSet）提交给Task Scheduler，Task Scheduler负责将Task分配到相应的Worker，最后提交给StandaloneExecutorBackend执行；
5）.StandaloneExecutorBackend会建立Executor线程池，开始执行Task，并向SparkContext报告，直至Task完成。
6）.所有Task完成后，SparkContext向Master注销，释放资源。

26 Spark on YARN运行过程
YARN是一种统一资源管理机制，在其上面可以运行多套计算框架。目前的大数据技术世界，大多数公司除了使用Spark来进行数据计算，由于历史原因或者单方面业务处理的性能考虑而使用着其他的计算框架，比如MapReduce、Storm等计算框架。Spark基于此种情况开发了Spark on YARN的运行模式，由于借助了YARN良好的弹性资源管理机制，不仅部署Application更加方便，而且用户在YARN集群中运行的服务和Application的资源也完全隔离，更具实践应用价值的是YARN可以通过队列的方式，管理同时运行在集群中的多个服务。Spark on YARN模式根据Driver在集群中的位置分为两种模式：一种是YARN-Client模式，另一种是YARN-Cluster（或称为YARN-Standalone模式）。
（1）YARN框架流程
任何框架与YARN的结合，都必须遵循YARN的开发模式。在分析Spark on YARN的实现细节之前，有必要先分析一下YARN框架的一些基本原理。
Yarn框架的基本运行流程图为：
其中，ResourceManager负责将集群的资源分配给各个应用使用，而资源分配和调度的基本单位是Container，其中封装了机器资源，如内存、CPU、磁盘和网络等，每个任务会被分配一个Container，该任务只能在该Container中执行，并使用该Container封装的资源。NodeManager是一个个的计算节点，主要负责启动Application所需的Container，监控资源（内存、CPU、磁盘和网络等）的使用情况并将之汇报给ResourceManager。ResourceManager与NodeManagers共同组成整个数据计算框架，ApplicationMaster与具体的Application相关，主要负责同ResourceManager协商以获取合适的Container，并跟踪这些Container的状态和监控其进度。
（2）YARN-Client
Yarn-Client模式中，Driver在客户端本地运行，这种模式可以使得Spark Application和客户端进行交互，因为Driver在客户端，所以可以通过webUI访问Driver的状态，默认是http://hadoop1:4040访问，而YARN通过http:// hadoop1:8088访问。
YARN-client的工作流程分为以下几个步骤：
1）Spark Yarn Client向YARN的ResourceManager申请启动Application Master。同时在SparkContent初始化中将创建DAGScheduler和TASKScheduler等，由于我们选择的是Yarn-Client模式，程序会选择YarnClientClusterScheduler和YarnClientSchedulerBackend；
2）ResourceManager收到请求后，在集群中选择一个NodeManager，为该应用程序分配第一个Container，要求它在这个Container中启动应用程序的ApplicationMaster，与YARN-Cluster区别的是在该ApplicationMaster不运行SparkContext，只与SparkContext进行联系进行资源的分派；
3）Client中的SparkContext初始化完毕后，与ApplicationMaster建立通讯，向ResourceManager注册，根据任务信息向ResourceManager申请资源（Container）；
4）一旦ApplicationMaster申请到资源（也就是Container）后，便与对应的NodeManager通信，要求它在获得的Container中启动启动CoarseGrainedExecutorBackend，CoarseGrainedExecutorBackend启动后会向Client中的SparkContext注册并申请Task；
5）Client中的SparkContext分配Task给CoarseGrainedExecutorBackend执行，CoarseGrainedExecutorBackend运行Task并向Driver汇报运行的状态和进度，以让Client随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务；
6）应用程序运行完成后，Client的SparkContext向ResourceManager申请注销并关闭自己。
（3）YARN-Cluster
在YARN-Cluster模式中，当用户向YARN中提交一个应用程序后，YARN将分两个阶段运行该应用程序：第一个阶段是把Spark的Driver作为一个ApplicationMaster在YARN集群中先启动；第二个阶段是由ApplicationMaster创建应用程序，然后为它向ResourceManager申请资源，并启动Executor来运行Task，同时监控它的整个运行过程，直到运行完成。
YARN-cluster的工作流程分为以下几个步骤：
1）Spark Yarn Client向YARN中提交应用程序，包括ApplicationMaster程序、启动ApplicationMaster的命令、需要在Executor中运行的程序等；
2）   ResourceManager收到请求后，在集群中选择一个NodeManager，为该应用程序分配第一个Container，要求它在这个Container中启动应用程序的ApplicationMaster，其中ApplicationMaster进行SparkContext等的初始化；
3）  ApplicationMaster向ResourceManager注册，这样用户可以直接通过ResourceManage查看应用程序的运行状态，然后它将采用轮询的方式通过RPC协议为各个任务申请资源，并监控它们的运行状态直到运行结束；
4）   一旦ApplicationMaster申请到资源（也就是Container）后，便与对应的NodeManager通信，要求它在获得的Container中启动启动CoarseGrainedExecutorBackend，CoarseGrainedExecutorBackend启动后会向ApplicationMaster中的SparkContext注册并申请Task。这一点和Standalone模式一样，只不过SparkContext在Spark Application中初始化时，使用CoarseGrainedSchedulerBackend配合YarnClusterScheduler进行任务的调度，其中YarnClusterScheduler只是对TaskSchedulerImpl的一个简单包装，增加了对Executor的等待逻辑等；
5）  ApplicationMaster中的SparkContext分配Task给CoarseGrainedExecutorBackend执行，CoarseGrainedExecutorBackend运行Task并向ApplicationMaster汇报运行的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务；
6）应用程序运行完成后，ApplicationMaster向ResourceManager申请注销并关闭自己。
（4）YARN-Client 与 YARN-Cluster 区别
理解YARN-Client和YARN-Cluster深层次的区别之前先清楚一个概念：Application Master。在YARN中，每个Application实例都有一个ApplicationMaster进程，它是Application启动的第一个容器。它负责和ResourceManager打交道并请求资源，获取资源之后告诉NodeManager为其启动Container。从深层次的含义讲YARN-Cluster和YARN-Client模式的区别其实就是ApplicationMaster进程的区别。
1）YARN-Cluster模式下，Driver运行在AM(Application Master)中，它负责向YARN申请资源，并监督作业的运行状况。当用户提交了作业之后，就可以关掉Client，作业会继续在YARN上运行，因而YARN-Cluster模式不适合运行交互类型的作业；
2）YARN-Client模式下，Application Master仅仅向YARN请求Executor，Client会和请求的Container通信来调度他们工作，也就是说Client不能离开。
clip_image024 clip_image026
3）Spark在不同集群中的运行演示
在以下运行演示过程中需要启动Hadoop和Spark集群，其中Hadoop需要启动HDFS和YARN，启动过程可以参见第三节《Spark编程模型（上）--概念及Shell试验》。

27 Shark和SparkSQL 
但是，随着Spark的发展，对于野心勃勃的Spark团队来说，Shark对于Hive的太多依赖（如采用Hive的语法解析器、查询优化器等等），制约了Spark的One Stack Rule Them All的既定方针，制约了Spark各个组件的相互集成，所以提出了SparkSQL项目。SparkSQL抛弃原有Shark的代码，汲取了Shark的一些优点，如内存列存储（In-Memory Columnar Storage）、Hive兼容性等，重新开发了SparkSQL代码；由于摆脱了对Hive的依赖性，SparkSQL无论在数据兼容、性能优化、组件扩展方面都得到了极大的方便，真可谓“退一步，海阔天空”。
（1）数据兼容方面  不但兼容Hive，还可以从RDD、parquet文件、JSON文件中获取数据，未来版本甚至支持获取RDBMS数据以及cassandra等NOSQL数据；
（2）性能优化方面  除了采取In-Memory Columnar Storage、byte-code generation等优化技术外、将会引进Cost Model对查询进行动态评估、获取最佳物理计划等等；
（3）组件扩展方面  无论是SQL的语法解析器、分析器还是优化器都可以重新定义，进行扩展。
2014年6月1日Shark项目和SparkSQL项目的主持人Reynold Xin宣布：停止对Shark的开发，团队将所有资源放SparkSQL项目上，至此，Shark的发展画上了句话，但也因此发展出两个直线：SparkSQL和Hive on Spark。其中SparkSQL作为Spark生态的一员继续发展，而不再受限于Hive，只是兼容Hive；而Hive on Spark是一个Hive的发展计划，该计划将Spark作为Hive的底层引擎之一，也就是说，Hive将不再受限于一个引擎，可以采用Map-Reduce、Tez、Spark等引擎。

28 SparkSQL优化
1）内存列存储（In-Memory Columnar Storage）
SparkSQL的表数据在内存中存储不是采用原生态的JVM对象存储方式，而是采用内存列存储，如下图所示。
该存储方式无论在空间占用量和读取吞吐率上都占有很大优势。对于原生态的JVM对象存储方式，每个对象通常要增加12-16字节的额外开销，对于一个270MB的TPC-H lineitem table数据，使用这种方式读入内存，要使用970MB左右的内存空间（通常是2～5倍于原生数据空间）；另外，使用这种方式，每个数据记录产生一个JVM对象，如果是大小为200B的数据记录，32G的堆栈将产生1.6亿个对象，这么多的对象，对于GC来说，可能要消耗几分钟的时间来处理（JVM的垃圾收集时间与堆栈中的对象数量呈线性相关）。显然这种内存存储方式对于基于内存计算的Spark来说，很昂贵也负担不起
对于内存列存储来说，将所有原生数据类型的列采用原生数组来存储，将Hive支持的复杂数据类型（如array、map等）先序化后并接成一个字节数组来存储。这样，每个列创建一个JVM对象，从而导致可以快速的GC和紧凑的数据存储；额外的，还可以使用低廉CPU开销的高效压缩方法（如字典编码、行长度编码等压缩方法）降低内存开销；更有趣的是，对于分析查询中频繁使用的聚合特定列，性能会得到很大的提高，原因就是这些列的数据放在一起，更容易读入内存进行计算。
2）字节码生成技术（bytecode generation，即CG）
在数据库查询中有一个昂贵的操作是查询语句中的表达式，主要是由于JVM的内存模型引起的。比如如下一个查询：
SELECT a + b FROM table
3）Scala代码优化
另外，SparkSQL在使用Scala编写代码的时候，尽量避免低效的、容易GC的代码；尽管增加了编写代码的难度，但对于用户来说，还是使用统一的接口，没受到使用上的困难。下图是一个Scala代码优化的示意图：

29 Spark Streaming简介
（1）Spark Streaming 是Spark核心API的一个扩展，可以实现高吞吐量的、具备容错机制的实时流数据的处理。支持从多种数据源获取数据，包括Kafk、Flume、Twitter、ZeroMQ、Kinesis 以及TCP sockets，从数据源获取数据之后，可以使用诸如map、reduce、join和window等高级函数进行复杂算法的处理。最后还可以将处理结果存储到文件系统，数据库和现场仪表盘。在“One Stack rule them all”的基础上，还可以使用Spark的其他子框架，如集群学习、图计算等，对流数据进行处理。Spark Streaming处理的数据流图：
（2）Spark的各个子框架，都是基于核心Spark的，Spark Streaming在内部的处理机制是，接收实时流的数据，并根据一定的时间间隔拆分成一批批的数据，然后通过Spark Engine处理这些批数据，最终得到处理后的一批批结果数据。对应的批数据，在Spark内核对应一个RDD实例，因此，对应流数据的DStream可以看成是一组RDDs，即RDD的一个序列。通俗点理解的话，在流数据分成一批一批后，通过一个先进先出的队列，然后 Spark Engine从该队列中依次取出一个个批数据，把批数据封装成一个RDD，然后进行处理，这是一个典型的生产者消费者模型，对应的就有生产者消费者模型的问题，即如何协调生产速率和消费速率。

30 Spark Streaming术语定义
（1）离散流（discretized stream）或DStream：这是Spark Streaming对内部持续的实时数据流的抽象描述，即我们处理的一个实时数据流，在Spark Streaming中对应于一个DStream 实例。
（2）批数据（batch data）：这是化整为零的第一步，将实时流数据以时间片为单位进行分批，将流处理转化为时间片数据的批处理。随着持续时间的推移，这些处理结果就形成了对应的结果数据流了。
（3）时间片或批处理时间间隔（ batch interval）：这是人为地对流数据进行定量的标准，以时间片作为我们拆分流数据的依据。一个时间片的数据对应一个RDD实例。
（4）窗口长度（window length）：一个窗口覆盖的流数据的时间长度。必须是批处理时间间隔的倍数，
（5）滑动时间间隔：前一个窗口到后一个窗口所经过的时间长度。必须是批处理时间间隔的倍数
（6）Input DStream :一个input DStream是一个特殊的DStream，将Spark Streaming连接到一个外部数据源来读取数据。

31 Storm与Spark Streming比较
（1）处理模型以及延迟
虽然两框架都提供了可扩展性(scalability)和可容错性(fault tolerance)，但是它们的处理模型从根本上说是不一样的。Storm可以实现亚秒级时延的处理，而每次只处理一条event，而Spark Streaming可以在一个短暂的时间窗口里面处理多条(batches)Event。所以说Storm可以实现亚秒级时延的处理，而Spark Streaming则有一定的时延。
（2）容错和数据保证
然而两者的代价都是容错时候的数据保证，Spark Streaming的容错为有状态的计算提供了更好的支持。在Storm中，每条记录在系统的移动过程中都需要被标记跟踪，所以Storm只能保证每条记录最少被处理一次，但是允许从错误状态恢复时被处理多次。这就意味着可变更的状态可能被更新两次从而导致结果不正确。任一方面，Spark Streaming仅仅需要在批处理级别对记录进行追踪，所以他能保证每个批处理记录仅仅被处理一次，即使是node节点挂掉。虽然说Storm的 Trident library可以保证一条记录被处理一次，但是它依赖于事务更新状态，而这个过程是很慢的，并且需要由用户去实现。
（3）实现和编程API
Storm主要是由Clojure语言实现，Spark Streaming是由Scala实现。如果你想看看这两个框架是如何实现的或者你想自定义一些东西你就得记住这一点。Storm是由BackType和 Twitter开发，而Spark Streaming是在UC Berkeley开发的。Storm提供了Java API，同时也支持其他语言的API。 Spark Streaming支持Scala和Java语言(其实也支持Python)。
（4）批处理框架集成
Spark Streaming的一个很棒的特性就是它是在Spark框架上运行的。这样你就可以想使用其他批处理代码一样来写Spark Streaming程序，或者是在Spark中交互查询。这就减少了单独编写流批量处理程序和历史数据处理程序。
（5）生产支持
Storm已经出现好多年了，而且自从2011年开始就在Twitter内部生产环境中使用，还有其他一些公司。而Spark Streaming是一个新的项目，并且在2013年仅仅被Sharethrough使用(据作者了解)。Storm是 Hortonworks Hadoop数据平台中流处理的解决方案，而Spark Streaming出现在 MapR的分布式平台和Cloudera的企业数据平台中。除此之外，Databricks是为Spark提供技术支持的公司，包括了Spark Streaming。虽然说两者都可以在各自的集群框架中运行，但是Storm可以在Mesos上运行, 而Spark Streaming可以在YARN和Mesos上运行。

32 Streaming架构
SparkStreaming是一个对实时数据流进行高通量、容错处理的流式处理系统，可以对多种数据源（如Kdfka、Flume、Twitter、Zero和TCP 套接字）进行类似Map、Reduce和Join等复杂操作，并将结果保存到外部文件系统、数据库或应用到实时仪表盘。
（1）计算流程：Spark Streaming是将流式计算分解成一系列短小的批处理作业。这里的批处理引擎是Spark Core，也就是把Spark Streaming的输入数据按照batch size（如1秒）分成一段一段的数据（Discretized Stream），每一段数据都转换成Spark中的RDD（Resilient Distributed Dataset），然后将Spark Streaming中对DStream的Transformation操作变为针对Spark中对RDD的Transformation操作，将RDD经过操作变成中间结果保存在内存中。整个流式计算根据业务的需求可以对中间的结果进行叠加或者存储到外部设备。下图显示了Spark Streaming的整个流程。
图Spark Streaming构架
（2）容错性：对于流式计算来说，容错性至关重要。首先我们要明确一下Spark中RDD的容错机制。每一个RDD都是一个不可变的分布式可重算的数据集，其记录着确定性的操作继承关系（lineage），所以只要输入数据是可容错的，那么任意一个RDD的分区（Partition）出错或不可用，都是可以利用原始输入数据通过转换操作而重新算出的。  
对于Spark Streaming来说，其RDD的传承关系如下图所示，图中的每一个椭圆形表示一个RDD，椭圆形中的每个圆形代表一个RDD中的一个Partition，图中的每一列的多个RDD表示一个DStream（图中有三个DStream），而每一行最后一个RDD则表示每一个Batch Size所产生的中间结果RDD。我们可以看到图中的每一个RDD都是通过lineage相连接的，由于Spark Streaming输入数据可以来自于磁盘，例如HDFS（多份拷贝）或是来自于网络的数据流（Spark Streaming会将网络输入数据的每一个数据流拷贝两份到其他的机器）都能保证容错性，所以RDD中任意的Partition出错，都可以并行地在其他机器上将缺失的Partition计算出来。这个容错恢复方式比连续计算模型（如Storm）的效率更高。
Spark Streaming中RDD的lineage关系图
（3）实时性：对于实时性的讨论，会牵涉到流式处理框架的应用场景。Spark Streaming将流式计算分解成多个Spark Job，对于每一段数据的处理都会经过Spark DAG图分解以及Spark的任务集的调度过程。对于目前版本的Spark Streaming而言，其最小的Batch Size的选取在0.5~2秒钟之间（Storm目前最小的延迟是100ms左右），所以Spark Streaming能够满足除对实时性要求非常高（如高频实时交易）之外的所有流式准实时计算场景。
（4）扩展性与吞吐量：Spark目前在EC2上已能够线性扩展到100个节点（每个节点4Core），可以以数秒的延迟处理6GB/s的数据量（60M records/s），其吞吐量也比流行的Storm高2～5倍，图4是Berkeley利用WordCount和Grep两个用例所做的测试，在Grep这个测试中，Spark Streaming中的每个节点的吞吐量是670k records/s，而Storm是115k records/s。
Spark Streaming与Storm吞吐量比较图

33 机器学习的定义
（1）“机器学习是一门人工智能的科学，该领域的主要研究对象是人工智能，特别是如何在经验学习中改善具体算法的性能”。
（2）“机器学习是对能通过经验自动改进的计算机算法的研究”。
（3）“机器学习是用数据或以往的经验，以此优化计算机程序的性能标准。” 一种经常引用的英文定义是：A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E。
可以看出机器学习强调三个关键词：算法、经验、性能，其处理过程如下图所示。
上表明机器学习是数据通过算法构建出模型并对模型进行评估，评估的性能如果达到要求就拿这个模型来测试其他的数据，如果达不到要求就要调整算法来重新建立模型，再次进行评估，如此循环往复，最终获得满意的经验来处理其他的数据。

34 机器学习的分类
（1）监督学习
监督是从给定的训练数据集中学习一个函数（模型），当新的数据到来时，可以根据这个函数（模型）预测结果。监督学习的训练集要求包括输入和输出，也可以说是特征和目标。训练集中的目标是由人标注（标量）的。在监督式学习下，输入数据被称为“训练数据”，每组训练数据有一个明确的标识或结果，如对防垃圾邮件系统中“垃圾邮件”、“非垃圾邮件”，对手写数字识别中的“1”、“2”、“3”等。在建立预测模型时，监督式学习建立一个学习过程，将预测结果与“训练数据”的实际结果进行比较，不断调整预测模型，直到模型的预测结果达到一个预期的准确率。常见的监督学习算法包括回归分析和统计分类：
l  二元分类是机器学习要解决的基本问题，将测试数据分成两个类，如垃圾邮件的判别、房贷是否允许等问题的判断。
l  多元分类是二元分类的逻辑延伸。例如，在因特网的流分类的情况下，根据问题的分类，网页可以被归类为体育、新闻、技术等，依此类推。
监督学习常常用于分类，因为目标往往是让计算机去学习我们已经创建好的分类系统。数字识别再一次成为分类学习的常见样本。一般来说，对于那些有用的分类系统和容易判断的分类系统，分类学习都适用。监督学习是训练神经网络和决策树的最常见技术。神经网络和决策树技术高度依赖于事先确定的分类系统给出的信息。对于神经网络来说，分类系统用于判断网络的错误，然后调整网络去适应它；对于决策树，分类系统用来判断哪些属性提供了最多的信息，如此一来可以用它解决分类系统的问题。
（2）无监督学习
与监督学习相比，无监督学习的训练集没有人为标注的结果。在非监督式学习中，数据并不被特别标识，学习模型是为了推断出数据的一些内在结构。常见的应用场景包括关联规则的学习以及聚类等。常见算法包括Apriori算法和k-Means算法。这类学习类型的目标不是让效用函数最大化，而是找到训练数据中的近似点。聚类常常能发现那些与假设匹配的相当好的直观分类，例如基于人口统计的聚合个体可能会在一个群体中形成一个富有的聚合，以及其他的贫穷的聚合。
非监督学习看起来非常困难：目标是我们不告诉计算机怎么做，而是让它（计算机）自己去学习怎样做一些事情。非监督学习一般有两种思路：第一种思路是在指导Agent时不为其指定明确的分类，而是在成功时采用某种形式的激励制度。需要注意的是，这类训练通常会置于决策问题的框架里，因为它的目标不是产生一个分类系统，而是做出最大回报的决定。这种思路很好地概括了现实世界，Agent可以对那些正确的行为做出激励，并对其他的行为进行处罚。
因为无监督学习假定没有事先分类的样本，这在一些情况下会非常强大，例如，我们的分类方法可能并非最佳选择。在这方面一个突出的例子是Backgammon（西洋双陆棋）游戏，有一系列计算机程序（例如neuro-gammon和TD-gammon）通过非监督学习自己一遍又一遍地玩这个游戏，变得比最强的人类棋手还要出色。这些程序发现的一些原则甚至令双陆棋专家都感到惊讶，并且它们比那些使用预分类样本训练的双陆棋程序工作得更出色。
（3）半监督学习
半监督学习（Semi-supervised Learning）是介于监督学习与无监督学习之间一种机器学习方式，是模式识别和机器学习领域研究的重点问题。它主要考虑如何利用少量的标注样本和大量的未标注样本进行训练和分类的问题。半监督学习对于减少标注代价，提高学习机器性能具有非常重大的实际意义。主要算法有五类：基于概率的算法；在现有监督算法基础上进行修改的方法；直接依赖于聚类假设的方法等，在此学习方式下，输入数据部分被标识，部分没有被标识，这种学习模型可以用来进行预测，但是模型首先需要学习数据的内在结构以便合理地组织数据来进行预测。应用场景包括分类和回归，算法包括一些对常用监督式学习算法的延伸，这些算法首先试图对未标识数据进行建模，在此基础上再对标识的数据进行预测，如图论推理算法（Graph Inference）或者拉普拉斯支持向量机（Laplacian SVM）等。
半监督学习分类算法提出的时间比较短，还有许多方面没有更深入的研究。半监督学习从诞生以来，主要用于处理人工合成数据，无噪声干扰的样本数据是当前大部分半监督学习方法使用的数据，而在实际生活中用到的数据却大部分不是无干扰的，通常都比较难以得到纯样本数据。
（4）强化学习
强化学习通过观察来学习动作的完成，每个动作都会对环境有所影响，学习对象根据观察到的周围环境的反馈来做出判断。在这种学习模式下，输入数据作为对模型的反馈，不像监督模型那样，输入数据仅仅是作为一个检查模型对错的方式，在强化学习下，输入数据直接反馈到模型，模型必须对此立刻做出调整。常见的应用场景包括动态系统以及机器人控制等。常见算法包括Q-Learning 以及时间差学习（Temporal difference learning）。

35 机器学习的常见算法
l  构造条件概率：回归分析和统计分类；
l  人工神经网络；
l  决策树；
l  高斯过程回归；
l  线性判别分析；
l  最近邻居法；
l  感知器；
l  径向基函数核；
l  支持向量机；
l  通过再生模型构造概率密度函数；
l  最大期望算法；
l  graphical model：包括贝叶斯网和Markov随机场；
l  Generative Topographic Mapping；
l  近似推断技术；
l  马尔可夫链蒙特卡罗方法；
l  变分法；
l  最优化：大多数以上方法，直接或者间接使用最优化算法。
根据算法的功能和形式的类似性，我们可以把算法分类，比如说基于树的算法，基于神经网络的算法等等。当然，机器学习的范围非常庞大，有些算法很难明确归类到某一类。而对于有些分类来说，同一分类的算法可以针对不同类型的问题，下面用一些相对比较容易理解的方式来解析一些主要的机器学习算法：
（1） 回归算法
回归算法是试图采用对误差的衡量来探索变量之间的关系的一类算法。回归算法是统计机器学习的利器。在机器学习领域，人们说起回归，有时候是指一类问题，有时候是指一类算法，这一点常常会使初学者有所困惑。常见的回归算法包括：最小二乘法（Ordinary Least Square），逻辑回归（Logistic Regression），逐步式回归（Stepwise Regression），多元自适应回归样条（Multivariate Adaptive Regression Splines）以及本地散点平滑估计（Locally Estimated Scatterplot Smoothing）。
（2）基于实例的算法
基于实例的算法常常用来对决策问题建立模型，这样的模型常常先选取一批样本数据，然后根据某些近似性把新数据与样本数据进行比较。通过这种方式来寻找最佳的匹配。因此，基于实例的算法常常也被称为“赢家通吃”学习或者“基于记忆的学习”。常见的算法包括 k-Nearest Neighbor (KNN)，、学习矢量量化（Learning Vector Quantization， LVQ）以及自组织映射算法（Self-Organizing Map，SOM）
（3）正则化方法
正则化方法是其他算法（通常是回归算法）的延伸，根据算法的复杂度对算法进行调整。正则化方法通常对简单模型予以奖励而对复杂算法予以惩罚。常见的算法包括：Ridge Regression、Least Absolute Shrinkage and Selection Operator（LASSO）以及弹性网络（Elastic Net）。
（4）决策树学习
决策树算法根据数据的属性采用树状结构建立决策模型，决策树模型常常用来解决分类和回归问题。常见的算法包括：分类及回归树（Classification And Regression Tree， CART）、 ID3 (Iterative Dichotomiser 3)、C4.5、Chi-squared Automatic Interaction Detection (CHAID)、Decision Stump、机森林（Random Forest）、多元自适应回归样条（MARS）以及梯度推进机（Gradient Boosting Machine，GBM）。
（5）贝叶斯学习
贝叶斯方法算法是基于贝叶斯定理的一类算法，主要用来解决分类和回归问题。常见算法包括：朴素贝叶斯算法、平均单依赖估计（Averaged One-Dependence Estimators， AODE）以及 Bayesian Belief Network（BBN）。
（6）基于核的算法
基于核的算法中最著名的莫过于支持向量机（SVM）了。基于核的算法把输入数据映射到一个高阶的向量空间， 在这些高阶向量空间里， 有些分类或者回归问题能够更容易解决。常见的基于核的算法包括：支持向量机（Support Vector Machine，SVM）、径向基函数（Radial Basis Function，RBF)以及线性判别分析（Linear Discriminate Analysis，LDA)等。
（7）聚类算法
聚类就像回归一样，有时候人们描述的是一类问题，有时候描述的是一类算法。聚类算法通常按照中心点或者分层的方式对输入数据进行归并。所有的聚类算法都试图找到数据的内在结构，以便按照最大的共同点将数据进行归类。常见的聚类算法包括 k-Means 算法以及期望最大化算法（Expectation Maximization，EM）。
（8）关联规则学习
关联规则学习通过寻找最能够解释数据变量之间关系的规则，来找出大量多元数据集中有用的关联规则。常见算法包括 Apriori 算法和 Eclat 算法等。
（9）人工神经网络算法
人工神经网络算法模拟生物神经网络，是一类模式匹配算法。通常用于解决分类和回归问题。人工神经网络是机器学习的一个庞大的分支，有几百种不同的算法（其中深度学习就是其中的一类算法，我们会单独讨论）。重要的人工神经网络算法包括：感知器神经网络（Perceptron Neural Network）、反向传递（Back Propagation）、Hopfield 网络、自组织映射（Self-Organizing Map, SOM）、学习矢量量化（Learning Vector Quantization，LVQ）。
（10）深度学习算法
深度学习算法是对人工神经网络的发展，在近期赢得了很多关注，特别是百度也开始发力深度学习后，更是在国内引起了很多关注。在计算能力变得日益廉价的今天，深度学习试图建立大得多也复杂得多的神经网络。很多深度学习的算法是半监督式学习算法，用来处理存在少量未标识数据的大数据集。常见的深度学习算法包括：受限波尔兹曼机（Restricted Boltzmann Machine， RBN）、 Deep Belief Networks（DBN）、卷积网络（Convolutional Network）、堆栈式自动编码器（Stacked Auto-encoders）。
（11）降低维度算法
像聚类算法一样，降低维度算法试图分析数据的内在结构，不过降低维度算法是以非监督学习的方式，试图利用较少的信息来归纳或者解释数据。这类算法可以用于高维数据的可视化或者用来简化数据以便监督式学习使用。常见的算法包括：主成份分析（Principle Component Analysis， PCA）、偏最小二乘回归（Partial Least Square Regression，PLS）、 Sammon 映射、多维尺度（Multi-Dimensional Scaling, MDS）、投影追踪（Projection Pursuit）等。
（12）集成算法
集成算法用一些相对较弱的学习模型独立地对同样的样本进行训练，然后把结果整合起来进行整体预测。集成算法的主要难点在于究竟集成哪些独立的较弱的学习模型以及如何把学习结果整合起来。这是一类非常强大的算法，同时也非常流行。常见的算法包括：Boosting、Bootstrapped Aggregation（Bagging）、AdaBoost、堆叠泛化（Stacked Generalization， Blending）、梯度推进机（Gradient Boosting Machine, GBM）、随机森林（Random Forest）。

36 Spark MLlib介绍
Spark之所以在机器学习方面具有得天独厚的优势，有以下几点原因：
（1）机器学习算法一般都有很多个步骤迭代计算的过程，机器学习的计算需要在多次迭代后获得足够小的误差或者足够收敛才会停止，迭代时如果使用Hadoop的MapReduce计算框架，每次计算都要读/写磁盘以及任务的启动等工作，这回导致非常大的I/O和CPU消耗。而Spark基于内存的计算模型天生就擅长迭代计算，多个步骤计算直接在内存中完成，只有在必要时才会操作磁盘和网络，所以说Spark正是机器学习的理想的平台。
（2）从通信的角度讲，如果使用Hadoop的MapReduce计算框架，JobTracker和TaskTracker之间由于是通过heartbeat的方式来进行的通信和传递数据，会导致非常慢的执行速度，而Spark具有出色而高效的Akka和Netty通信系统，通信效率极高。
MLlib(Machine Learnig lib) 是Spark对常用的机器学习算法的实现库，同时包括相关的测试和数据生成器。Spark的设计初衷就是为了支持一些迭代的Job, 这正好符合很多机器学习算法的特点。在Spark官方首页中展示了Logistic Regression算法在Spark和Hadoop中运行的性能比较，如图下图所示。

37 Spark MLlib架构解析
l  底层基础：包括Spark的运行库、矩阵库和向量库；
l  算法库：包含广义线性模型、推荐系统、聚类、决策树和评估的算法；
l  实用程序：包括测试数据的生成、外部数据的读入等功能。

38 GraphX应用背景
Spark GraphX是一个分布式图处理框架，它是基于Spark平台提供对图计算和图挖掘简洁易用的而丰富的接口，极大的方便了对分布式图处理的需求。
众所周知，社交网络中人与人之间有很多关系链，例如Twitter、Facebook、微博和微信等，这些都是大数据产生的地方都需要图计算，现在的图处理基本都是分布式的图处理，而并非单机处理。Spark GraphX由于底层是基于Spark来处理的，所以天然就是一个分布式的图处理系统。图的布式或者并行处理其实是把图拆分成很多的子图，然后分别对这些子图进行计算，计算的时候可以分别迭代进行分阶段的计算，即对图进行并行计算。下面我们看一下图计算的简单示例：
从图中我们可以看出：拿到Wikipedia的文档以后，可以变成Link Table形式的视图，然后基于Link Table形式的视图可以分析成Hyperlinks超链接，最后我们可以使用PageRank去分析得出Top Communities。在下面路径中的Editor Graph到Community，这个过程可以称之为Triangle Computation，这是计算三角形的一个算法，基于此会发现一个社区。从上面的分析中我们可以发现图计算有很多的做法和算法，同时也发现图和表格可以做互相的转换。

39 GraphX实现分析 
如同Spark本身，每个子模块都有一个核心抽象。GraphX的核心抽象是Resilient Distributed Property Graph，一种点和边都带属性的有向多重图。它扩展了Spark RDD的抽象，有Table和Graph两种视图，而只需要一份物理存储。两种视图都有自己独有的操作符，从而获得了灵活操作和执行效率。
GraphX的底层设计有以下几个关键点。
（1）对Graph视图的所有操作，最终都会转换成其关联的Table视图的RDD操作来完成。这样对一个图的计算，最终在逻辑上，等价于一系列RDD的转换过程。因此，Graph最终具备了RDD的3个关键特性：Immutable、Distributed和Fault-Tolerant，其中最关键的是Immutable（不变性）。逻辑上，所有图的转换和操作都产生了一个新图；物理上，GraphX会有一定程度的不变顶点和边的复用优化，对用户透明。
（2）两种视图底层共用的物理数据，由RDD[Vertex-Partition]和RDD[EdgePartition]这两个RDD组成。点和边实际都不是以表Collection[tuple]的形式存储的，而是由VertexPartition/EdgePartition在内部存储一个带索引结构的分片数据块，以加速不同视图下的遍历速度。不变的索引结构在RDD转换过程中是共用的，降低了计算和存储开销。
（3）图的分布式存储采用点分割模式，而且使用partitionBy方法，由用户指定不同的划分策略（PartitionStrategy）。划分策略会将边分配到各个EdgePartition，顶点Master分配到各个VertexPartition，EdgePartition也会缓存本地边关联点的Ghost副本。划分策略的不同会影响到所需要缓存的Ghost副本数量，以及每个EdgePartition分配的边的均衡程度，需要根据图的结构特征选取最佳策略。目前有EdgePartition2d、EdgePartition1d、RandomVertexCut和CanonicalRandomVertexCut这四种策略。




二、ms相关
1、driver的功能是什么？
　　1）一个Spark作业运行时包括一个Driver进程，也是作业的主进程，具有main函数，并且有SparkContext的实例，是程序的人口点；
　　2）功能：负责向集群申请资源，向master注册信息，负责了作业的调度，负责作业的解析、生成Stage并调度Task到Executor上。包括DAGScheduler，TaskScheduler。

2、spark的有几种部署模式，每种模式特点？
　　1）本地模式：适用于测试
　　2） standalone 模式：使用spark自带的资源调度框架
　　3） spark on yarn 模式：最流行的方式，使用yarn集群调度资源
　　4） mesos模式：国外使用多

3、Spark为什么比mapreduce快？
　　1）基于内存计算，减少低效的磁盘交互；
　　2）高效的调度算法，基于DAG；
　　3）容错机制Linage，精华部分就是DAG和Lingae

4、hadoop和spark的shuffle相同和差异？
　　1）从 high-level 的角度来看，两者并没有大的差别。 都是将 mapper（Spark 里是 ShuffleMapTask）的输出进行 partition，不同的 partition 送到不同的 reducer（Spark 里 reducer 可能是下一个 stage 里的 ShuffleMapTask，也可能是 ResultTask）。Reducer 以内存作缓冲区，边 shuffle 边 aggregate 数据，等到数据 aggregate 好以后进行 reduce() （Spark 里可能是后续的一系列操作）。
　　2）从 low-level 的角度来看，两者差别不小。 Hadoop MapReduce 是 sort-based，进入 combine() 和 reduce() 的 records 必须先 sort。这样的好处在于 combine/reduce() 可以处理大规模的数据，因为其输入数据可以通过外排得到（mapper 对每段数据先做排序，reducer 的 shuffle 对排好序的每段数据做归并）。目前的 Spark 默认选择的是 hash-based，通常使用 HashMap 来对 shuffle 来的数据进行 aggregate，不会对数据进行提前排序。如果用户需要经过排序的数据，那么需要自己调用类似 sortByKey() 的操作；如果你是Spark 1.1的用户，可以将spark.shuffle.manager设置为sort，则会对数据进行排序。在Spark 1.2中，sort将作为默认的Shuffle实现。
　　3）从实现角度来看，两者也有不少差别。 Hadoop MapReduce 将处理流程划分出明显的几个阶段：map(), spill, merge, shuffle, sort, reduce() 等。每个阶段各司其职，可以按照过程式的编程思想来逐一实现每个阶段的功能。在 Spark 中，没有这样功能明确的阶段，只有不同的 stage 和一系列的 transformation()，所以 spill, merge, aggregate 等操作需要蕴含在 transformation() 中。如果我们将 map 端划分数据、持久化数据的过程称为 shuffle write，而将 reducer 读入数据、aggregate 数据的过程称为 shuffle read。那么在 Spark 中，问题就变为怎么在 job 的逻辑或者物理执行图中加入 shuffle write 和 shuffle read 的处理逻辑？以及两个处理逻辑应该怎么高效实现？ Shuffle write由于不要求数据有序，shuffle write 的任务很简单：将数据 partition 好，并持久化。之所以要持久化，一方面是要减少内存存储空间压力，另一方面也是为了 fault-tolerance。

5、RDD宽依赖和窄依赖？
　　RDD和它依赖的parent RDD(s)的关系有两种不同的类型，即窄依赖（narrow dependency）和宽依赖（wide dependency）。
　　1）窄依赖指的是每一个parent RDD的Partition最多被子RDD的一个Partition使用
　　2）宽依赖指的是多个子RDD的Partition会依赖同一个parent RDD的Partition

6、cache和pesist的区别
　　1）cache和persist都是用于将一个RDD进行缓存的，这样在之后使用的过程中就不需要重新计算了，可以大大节省程序运行时间；
　　2） cache只有一个默认的缓存级别MEMORY_ONLY ，cache调用了persist，而persist可以根据情况设置其它的缓存级别；
　　3）executor执行的时候，默认60%做cache，40%做task操作，persist最根本的函数，最底层的函数

7、常规的容错方式有哪几种类型？RDD通过Linage（记录数据更新）的方式为何很高效？
　　1） ​lazy记录了数据的来源，RDD是不可变的，且是lazy级别的，且rDD之间构成了链条，lazy是弹性的基石。由于RDD不可变，所以每次操作就产生新的rdd，不存在全局修改的问题，
控制难度下降，所有有计算链条将复杂计算链条存储下来，计算的时候从后往前回溯900步是上一个stage的结束，要么就checkpoint
　　2） ​记录原数据，是每次修改都记录，代价很大如果修改一个集合，代价就很小，官方说rdd是粗粒度的操作，是为了效率，为了简化，每次都是操作数据集合，写或者修改操作，
都是基于集合的rdd的写操作是粗粒度的，rdd的读操作既可以是粗粒度的也可以是细粒度，读可以读其中的一条条的记录。
　　3） ​简化复杂度，是高效率的一方面，写的粗粒度限制了使用场景如网络爬虫，现实世界中，大多数写是粗粒度的场景

8、RDD有哪些缺陷？
　　1）不支持细粒度的写和更新操作（如网络爬虫），spark写数据是粗粒度的所谓粗粒度，就是批量写入数据，为了提高效率。但是读数据是细粒度的也就是说可以一条条的读
　　2）不支持增量迭代计算，Flink支持

9、Spark中数据的位置是被谁管理的？
　　每个数据分片都对应具体物理位置，数据的位置是被blockManager，无论数据是在磁盘，内存还是tacyan，都是由blockManager管理

10、Spark的数据本地性有哪几种？
　　答：Spark中的数据本地性有三种：a.PROCESS_LOCAL是指读取缓存在本地节点的数据b.NODE_LOCAL是指读取本地节点硬盘数据c.ANY是指读取非本地节点数据通常读取数据PROCESS_LOCAL>NODE_LOCAL>ANY，尽量使数据以PROCESS_LOCAL或NODE_LOCAL方式读取。其中PROCESS_LOCAL还和cache有关，如果RDD经常用的话将该RDD cache到内存中，注意，由于cache是lazy的，所以必须通过一个action的触发，才能真正的将该RDD cache到内存中

11、rdd有几种操作类型？
RDD（Resilient Distributed Dataset）叫做分布式数据集，是spark中最基本的数据抽象，它代表一个不可变，可分区，里面的元素可以并行计算的集合。
Resilient：表示弹性的，弹性表示
Dataset：就是一个集合，用于存放数据的
Destributed：分布式，可以并行在集群计算
　　1）transformation，rdd由一种转为另一种rdd
　　2）action，
　　3）cronroller，crontroller是控制算子,cache,persist，对性能和效率的有很好的支持三种类型，不要回答只有2中操作

12、Spark程序执行，有时候默认为什么会产生很多task，怎么修改默认task执行个数？
　　1）因为输入数据有很多task，尤其是有很多小文件的时候，有多少个输入block就会有多少个task启动；
　　2）spark中有partition的概念，每个partition都会对应一个task，task越多，在处理大规模数据的时候，就会越有效率。不过task并不是越多越好，如果平时测试，或者数据量没有那么大，则没有必要task数量太多。
　　3）参数可以通过spark_home/conf/spark-default.conf配置文件设置:spark.sql.shuffle.partitions 50 spark.default.parallelism 10第一个是针对spark sql的task数量第二个是非spark sql程序设置生效

13、为什么Spark Application在没有获得足够的资源，job就开始执行了，可能会导致什么什么问题发生?
　　答：会导致执行该job时候集群资源不足，导致执行job结束也没有分配足够的资源，分配了部分Executor，该job就开始执行task，应该是task的调度线程和Executor资源申请是异步的；如果想等待申请完所有的资源再执行job的：需要将spark.scheduler.maxRegisteredResourcesWaitingTime设置的很大；spark.scheduler.minRegisteredResourcesRatio 设置为1，但是应该结合实际考虑否则很容易出现长时间分配不到资源，job一直不能运行的情况。

14、join操作优化经验？
　　join其实常见的就分为两类： map-side join 和 reduce-side join。当大表和小表join时，用map-side join能显著提高效率。将多份数据进行关联是数据处理过程中非常普遍的用法，不过在分布式计算系统中，这个问题往往会变的非常麻烦，因为框架提供的 join 操作一般会将所有数据根据 key 发送到所有的 reduce 分区中去，也就是 shuffle 的过程。造成大量的网络以及磁盘IO消耗，运行效率极其低下，这个过程一般被称为 reduce-side-join。如果其中有张表较小的话，我们则可以自己实现在 map 端实现数据关联，跳过大量数据进行 shuffle 的过程，运行时间得到大量缩短，根据不同数据可能会有几倍到数十倍的性能提升。

15、介绍一下cogroup rdd实现原理，你在什么场景下用过这个rdd？
　　答：cogroup的函数实现:这个实现根据两个要进行合并的两个RDD操作,生成一个CoGroupedRDD的实例,这个RDD的返回结果是把相同的key中两个RDD分别进行合并操作,最后返回的RDD的value是一个Pair的实例,这个实例包含两个Iterable的值,第一个值表示的是RDD1中相同KEY的值,第二个值表示的是RDD2中相同key的值.由于做cogroup的操作,需要通过partitioner进行重新分区的操作,因此,执行这个流程时,需要执行一次shuffle的操作(如果要进行合并的两个RDD的都已经是shuffle后的rdd,同时他们对应的partitioner相同时,就不需要执行shuffle

16. Spark master 使用zookeeper 进行HA 的，有哪些元数据保存在Zookeeper？
       答：spark 通过这个参数spark.deploy.zookeeper.dir 指定master 元数据在zookeeper 中保存的位置，包括Worker，Driver 和Application 以及Executors。standby 节点要从zk 中，获得元数据信息，恢复集群运行状态，才能对外继续提供服务，作业提交资源申请等，在恢复前是不能接受请求的。另外，Master 切换需要注意2 点：
       1） 在Master 切换的过程中，所有的已经在运行的程序皆正常运行！因为Spark Application 在运行前就已经通过Cluster Manager 获得了计算资源，所以在运行时Job 本身的调度和处理和Master 是没有任何关系的！
       2） 在Master 的切换过程中唯一的影响是不能提交新的Job：一方面不能够提交新的应用程序给集群，因为只有Active Master 才能接受新的程序的提交请求；另外一方面，已经运行的程序中也不能够因为Action 操作触发新的Job 的提交请求；

17 Spark master HA 主从切换过程不会影响集群已有的作业运行，为什么？
       答：因为程序在运行之前，已经申请过资源了，driver 和Executors 通讯，不需要和master进行通讯的。

18. Spark on Mesos 中，什么是的粗粒度分配，什么是细粒度分配， 各自的优点和缺点是什么？
       1） 粗粒度：启动时就分配好资源， 程序启动，后续具体使用就使用分配好的资源，不
需要再分配资源；好处：作业特别多时，资源复用率高，适合粗粒度；不好：容易资源浪费， 假如一个job 有1000 个task，完成了999 个，还有一个没完成，那么使用粗粒度，999 个资源就会闲置在那里，资源浪费。
       2） 细粒度分配：用资源的时候分配，用完了就立即回收资源，启动会麻烦一点，启动一次分配一次，会比较麻烦。

19. 如何配置spark master 的HA？
配置zookeeper
修改spark_env.sh 文件,spark 的master 参数不在指定，添加如下代码到各个master 节点export SPARK_DAEMON_JAVA_OPTS=
“-Dspark.deploy.recoveryMode=ZOOKEEPER
-Dspark.deploy.zookeeper.url=zk01:2181,zk02:2181,zk03:2181
-Dspark.deploy.zookeeper.dir=/spark”
将spark_env.sh 分发到各个节点
找到一个master 节点，执行./start-all.sh，会在这里启动主master,其他的master 备节点， 启动master 命令: ./sbin/start-master.sh
提交程序的时候指定master 的时候要指定三台master，例如./spark-shell --master spark://master01:7077,master02:7077,master03:7077

20. Apache Spark 有哪些常见的稳定版本，Spark1.6.0 的数字分别代表什么意思？
答：常见的大的稳定版本有Spark 1.3,Spark1.6, Spark 2.0 ，Spark1.6.0 的数字含义
第一个数字：1
第二个数字：6
第三个数字：0

21  driver 的功能是什么？
一个Spark 作业运行时包括一个Driver 进程，也是作业的主进程，具有main 函数，并且有SparkContext 的实例，是程序的入口点；
功能：负责向集群申请资源，向master 注册信息，负责了作业的调度，负责作业的解析、生成Stage 并调度Task 到Executor 上。包括DAGScheduler，TaskScheduler。

22 你是怎么理解Spark，它的特点是什么？
Spark是一个基于内存的，用于大规模数据处理（离线计算、实时计算、快速查询（交互式查询））的统一分析引擎。
它内部的组成模块，包含SparkCore，SparkSQL，SparkStreaming，SparkMLlib，SparkGraghx等...
它的特点：
快，Spark计算速度是MapReduce计算速度的10-100倍
易用，MR支持1种计算模型，Spsark支持更多的计算模型(算法多)
通用，Spark 能够进行离线计算、交互式查询（快速查询）、实时计算、机器学习、图计算
兼容性，Spark支持大数据中的Yarn调度，支持mesos。可以处理hadoop计算的数据。

23 Spark有几种部署方式，请分别简要论述
1）Local:运行在一台机器上，通常是练手或者测试环境。
2）Standalone:构建一个基于Mster+Slaves的资源调度集群，Spark任务提交给Master运行。是Spark自身的一个调度系统。
3）Yarn: Spark客户端直接连接Yarn，不需要额外构建Spark集群。有yarn-client和yarn-cluster两种模式，主要区别在于：Driver程序的运行节点。
4）Mesos：国内大环境比较少用。
     
24 Spark提交作业的参数
因为我们Spark任务是采用的Shell脚本进行提交，所以一定会涉及到几个重要的参数，而这个也是在面试的时候容易被考察到的“细节”。

25 简述Spark的作业提交流程
Spark的任务提交方式实际上有两种，分别是YarnClient模式和YarnCluster模式。
1）YarnClient 运行模式
在YARNClient模式下，Driver在任务提交的本地机器上运行，Driver启动后会和ResourceManager通讯申请启动ApplicationMaster，随后ResourceManager分配container，在合适的NodeManager上启动ApplicationMaster，此时的ApplicationMaster的功能相当于一个ExecutorLaucher，只负责向ResourceManager申请Executor内存。
ResourceManager接到ApplicationMaster的资源申请后会分配container，然后ApplicationMaster在资源分配指定的NodeManager上启动Executor进程，Executor进程启动后会向Driver反向注册，Executor全部注册完成后Driver开始执行main函数，之后执行到Action算子时，触发一个job，并根据宽依赖开始划分stage，每个stage生成对应的taskSet，之后将task分发到各个Executor上执行。        
2）YarnCluster 模式介绍
在YARN Cluster模式下，任务提交后会和ResourceManager通讯申请启动ApplicationMaster，随后ResourceManager分配container，在合适的NodeManager上启动ApplicationMaster，
此时的ApplicationMaster就是Driver。
Driver启动后向ResourceManager申请Executor内存，ResourceManager接到ApplicationMaster的资源申请后会分配container，然后在合适的NodeManager上启动Executor进程，Executor进程启动后会向Driver反向注册，Executor全部注册完成后Driver开始执行main函数，之后执行到Action算子时，触发一个job，并根据宽依赖开始划分stage，每个stage生成对应的taskSet，之后将task分发到各个Executor上执行。

26 你是如何理解Spark中血统(RDD)的概念?它的作用是什么？
1）定义：RDD是弹性分布式数据集，是Spark中最基本的数据抽象，代表一个不可变、可分区、里面的元素可并行计算 的集合。
2）作用：提供了一个抽象的数据模型，将具体的应用逻辑表达为一系列转换操作(函数)。另外不同RDD之间的转换操作之间还可以形成依赖关系，进而实现管道化，从而避免了中间结果的存储，
大大降低了数据复制、磁盘IO和序列化开销，并且还提供了更多的API(map/reduec/filter/groupBy...)
3）总结：RDD在Lineage依赖方面分为两种Narrow Dependencies与Wide Dependencies，用来解决数据容错时的高效性以及划分任务时候起到重要作用

27 简述Spark的宽窄依赖，以及Spark如何划分stage，每个stage又根据什么决定task个数?
Spark的宽窄依赖问题是SparkCore部分的重点考察内容，多数出现在笔试中，大家需要注意。
窄依赖:父RDD的一个分区只会被子RDD的一个分区依赖
宽依赖:父RDD的一个分区会被子RDD的多个分区依赖(涉及到shuffle)
那Stage是如何划分的呢？
根据RDD之间的依赖关系的不同将Job划分成不同的Stage，遇到一个宽依赖则划分一个Stage。
每个stage又根据什么决定task个数?
Stage是一个TaskSet，将Stage根据分区数划分成一个个的Task。

28 列举Spark常用的transformation和action算子，有哪些算子会导致Shuffle?
我们在Spark开发过程中，避不开与各种算子打交道，其中Spark 算子分为transformation 和 action 算子，下面列出一些常用的算子，具体的功能还需要小伙伴们自行去了解。
transformation
map
mapRartition
flatMap
filter
 ...
action
reduce
collect
first
take
...

29 有哪些会引起Shuffle过程的Spark算子呢?
reduceByKey
groupByKey
...ByKey

30 reduceByKey与groupByKey的区别,哪一种更具优势?
既然你上面都提到 reduceByKey 和groupByKey  ，那哪一种更具优势，你能简单分析一下吗？
能问这样的问题，已经暗示面试官的水平不低了，那么我们该如何回答呢：
reduceByKey：按照key进行聚合，在shuffle之前有combine（预聚合）操作，返回结果是RDD[k,v]。
groupByKey：按照key进行分组，直接进行shuffle
所以，在实际开发过程中，reduceByKey比groupByKey，更建议使用。但是需要注意是否会影响业务逻辑。

31 Repartition和Coalesce 的关系与区别，能简单说说吗？
这道题就已经开始掺和有“源码”的味道了，为什么呢？
1）关系：两者都是用来改变RDD的partition数量的，repartition底层调用的就是coalesce方法：coalesce(numPartitions, shuffle = true)
2）区别：repartition一定会发生shuffle，coalesce 根据传入的参数来判断是否发生shuffle。
一般情况下增大rdd的partition数量使用repartition，减少partition数量时使用coalesce。

32 简述下Spark中的缓存(cache和persist)与checkpoint机制，并指出两者的区别和联系
关于Spark缓存和检查点的区别，大致可以从这3个角度去回答：
位置：Persist 和 Cache将数据保存在内存，Checkpoint将数据保存在HDFS
生命周期：Persist 和 Cache  程序结束后会被清除或手动调用unpersist方法，Checkpoint永久存储不会被删除。
RDD依赖关系：Persist 和 Cache，不会丢掉RDD间的依赖链/依赖关系，CheckPoint会斩断依赖链。

33 简述Spark中共享变量（广播变量和累加器）的基本原理与用途
关于Spark中的广播变量和累加器的基本原理和用途，答案较为固定，大家无需刻意去记忆。
累加器（accumulator）是Spark中提供的一种分布式的变量机制，其原理类似于mapreduce，即分布式的改变，然后聚合这些改变。累加器的一个常见用途是在调试时对作业执行过程中的事件进行计数。
广播变量是在每个机器上缓存一份，不可变，只读的，相同的变量，该节点每个任务都能访问，起到节省资源和优化的作用。它通常用来高效分发较大的对象。

34 当Spark涉及到数据库的操作时，如何减少Spark运行中的数据库连接数？
嗯，有点“调优”的味道，感觉真正的“风暴”即将到来，这道题还是很好回答的，我们只需要减少连接数据库的次数即可。
使用foreachPartition代替foreach，在foreachPartition内获取数据库的连接。        

35 能介绍下你所知道和使用过的Spark调优吗?
恐怖如斯，该来的还是会来的，庆幸自己看了菌哥的面试杀招，丝毫不慌：        
1）资源参数调优
num-executors：设置Spark作业总共要用多少个Executor进程来执行
executor-memory：设置每个Executor进程的内存
executor-cores：设置每个Executor进程的CPU core数量
driver-memory：设置Driver进程的内存
spark.default.parallelism：设置每个stage的默认task数量
2）开发调优
避免创建重复的RDD
尽可能复用同一个RDD
对多次使用的RDD进行持久化
尽量避免使用shuffle类算子
使用map-side预聚合的shuffle操作
3）使用高性能的算子
①使用reduceByKey/aggregateByKey替代groupByKey
②使用mapPartitions替代普通map 
③使用foreachPartitions替代foreach 
④使用filter之后进行coalesce操作
⑤使用repartitionAndSortWithinPartitions替代repartition与sort类操作
4）广播大变量
在算子函数中使用到外部变量时，默认情况下，Spark会将该变量复制多个副本，通过网络传输到task中，此时每个task都有一个变量副本。如果变量本身比较大的话（比如100M，甚至1G），那么大量的变量副本在网络中传输的性能开销，以及在各个节点的Executor中占用过多内存导致的频繁GC(垃圾回收)，都会极大地影响性能。
5）使用Kryo优化序列化性能
6）优化数据结构
在可能以及合适的情况下，使用占用内存较少的数据结构，但是前提是要保证代码的可维护性。
如果能够尽可能的把这些要点说出来，我想面试官可能就一个想法：


36 如何使用Spark实现TopN的获取（描述思路或使用伪代码）？
能让你使用伪代码来描述这已经非常“苛刻”了，但是不慌，这里提供3种思路供大家参考：
方法1：
        （1）按照key对数据进行聚合（groupByKey）
        （2）将value转换为数组，利用scala的sortBy或者sortWith进行排序（mapValues）
        注意：当数据量太大时，会导致OOM
方法2：
        （1）取出所有的key
        （2）对key进行迭代，每次取出一个key利用spark的排序算子进行排序

方法3：
        （1）自定义分区器，按照key进行分区，使不同的key进到不同的分区
        （2）对每个分区运用spark的排序算子进行排序
		
		
		
		
---------------------------------------------------------------------------------------------------------------
------------------------------------------spark basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------spring basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 Spring是一个开源的控制反转(Inversion of Control，IoC)和面向切面(AOP)的容器框架，它的主要目得是简化企业开发。

2 Spring 是一个开源框架，是为了解决企业应用程序开发复杂性而创建的。框架的主要优势之一就是其分层架构，分层架构允许您选择使用哪一个组件，同时为 J2EE 应用程序开发提供集成的框架。
Spring 框架是一个分层架构，由 7 个定义良好的模块组成。Spring 模块构建在核心容器之上，核心容器定义了创建、配置和管理 bean 的方式

3 模块功能
组成 Spring 框架的每个模块（或组件）都可以单独存在，或者与其他一个或多个模块联合实现。
（1）核心容器：核心容器提供 Spring 框架的基本功能。核心容器的主要组件是 BeanFactory，它是工厂模式的实现。BeanFactory 使用控制反转 （IOC） 模式将应用程序的配置和依赖性规范与实际的应用程序代码分开。
（2）Spring 上下文：Spring 上下文是一个配置文件，向 Spring 框架提供上下文信息。Spring 上下文包括企业服务，例如 JNDI、EJB、电子邮件、国际化、校验和调度功能。
（3）Spring AOP：通过配置管理特性，Spring AOP 模块直接将面向方面的编程功能集成到了 Spring 框架中。所以，可以很容易地使 Spring 框架管理的任何对象支持 AOP。Spring AOP 模块为基于 Spring 的应用程序中的对象提供了事务管理服务。通过使用 Spring AOP，不用依赖 EJB 组件，就可以将声明性事务管理集成到应用程序中。
（4）Spring DAO：JDBC DAO 抽象层提供了有意义的异常层次结构，可用该结构来管理异常处理和不同数据库供应商抛出的错误消息。异常层次结构简化了错误处理，并且极大地降低了需要编写的异常代码数量（例如打开和关闭连接）。Spring DAO 的面向 JDBC 的异常遵从通用的 DAO 异常层次结构。
（5）Spring ORM：Spring 框架插入了若干个 ORM 框架，从而提供了 ORM 的对象关系工具，其中包括 JDO、Hibernate 和 iBatis SQL Map。所有这些都遵从 Spring 的通用事务和 DAO 异常层次结构。
（6）Spring Web 模块：Web 上下文模块建立在应用程序上下文模块之上，为基于 Web 的应用程序提供了上下文。所以，Spring 框架支持与 Jakarta Struts 的集成。Web 模块还简化了处理多部分请求以及将请求参数绑定到域对象的工作。
（7）Spring MVC 框架：MVC 框架是一个全功能的构建 Web 应用程序的 MVC 实现。通过策略接口，MVC 框架变成为高度可配置的，MVC 容纳了大量视图技术，其中包括 JSP、Velocity、Tiles、iText 和 POI。
Spring MVC主要是对mvc的支持，包括restful协议
Spring Web则对远程调用和远程服务的支持。

4 在项目中引入Spring立即可以带来下面的好处：
 （1）降低组件之间的耦合度，实现软件各层之间的解耦。
 （2）可以使用容器提供的众多服务，如：事务管理服务、消息服务等等。当我们使用容器管理事务时，开发人员就不再需要手工控制事务，也不需处理复杂的事务传播。
 （3）容器提供单例模式支持，开发人员不再需要自己编写实现代码。
 （4）容器提供了AOP技术，利用它很容易实现如权限拦截、运行期监控等功能。
 （5）容器提供的众多辅作类，使用这些类能够加快应用的开发，如： JdbcTemplate、HibernateTemplate。
 （6）Spring对于主流的应用框架提供了集成支持，如：集成Hibernate、JPA、Struts等，这样更便于应用的开发。
	
5 轻量级与重量级
经常会有人问到Spring是属于轻量级框架，还是属于重量级框架呢？其实划分一个应用是否属于轻量级还是重量级，主要看它使用了多少服务。使用的服务越多，容器要为普通java对象做的工作就越多，必然会影响到应用的发布时间或者是运行性能。对于Spring容器来说，它提供了很多服务，但这些服务并不是默认为应用打开的，应用需要某种服务，还需要指明使用该服务，如果应用使用的服务很少，如：只使用了Spring核心服务，那么我们可以认为此时应用属于轻量级的，如果应用使用了Spring提供的大部分服务，这时应用就属于重量级的。目前EJB容器就因为它默认为应用提供了EJB规范中所有的功能，所以它属于重量级。

6 对于使用Spring框架的开发人员来说，我们主要做的主要有两件事情：①开发Bean;②配置Bean;而Spring帮我们做的就是根据配置文件来创建Bean实例，
并调用Bean实例的方法来完成“依赖注入”，可以把Spring容器理解成一个大型工厂，Bean就是该工厂的产品，工厂(Spirng容器)里能生产出来什么样的产品（Bean），完全取决于我们在配置文件中的配置。

7 Bean的作用域
1）比较常用的是singleton 和 prototype 两种作用域，对于singleton作用域，每次请求该Bean都将获得相同的实例，Spring容器负责跟踪监视Bean实例的状态，负责维护Bean实例的生命周期行为，如果一个Bean被设置成prototype作用域，程序每次请求该id的Bean，Spring都会创建一个新的Bean实例，然后返回给程序，在这种情况下，Spring容器仅仅使用new 关键字创建Bean实例，一旦创建成功，容器Spring不再对Bean的生命周期负责，也不会维护Bean实例的状态。
2）如果不指定Bean的作用域，Spring默认使用singleton作用域。Java在常见Java实例时，需要进行内存申请，销毁实例是，需要完成垃圾回收，这些工作都会导致系统开销的增加。因此prototype作用域Bean 的创建销毁代价比较大。而singleton作用域的Bean 实例一旦创建成功，可以重复使用，因此，除非必要，否则避免将Bean作用域设置成prototype。
3）如果要使用 request,session,global session作用域的Bean，在配置Bean之前，还需要做少量的初始配置(将HTTP 请求banding到该提供服务的线程上，这使得具有request 和 session作用域的Bean实例能够在后面的调用链中被访问到)，如果只是配置常规的作用域（singleton,prototype），则无须设置。如果Web 应用直接使用Spring MVC 作为MVC框架，即使用SpringDispatcherServlet 或DispatcherPorlet 来拦截所有用户请求，则无须设置，因为DispatcherServlet 和DispatcherPorlet已经处理了所有和请求有关的额状态处理。
Spring mvc的action默认单例模式，Struts1的action默认单例模式，Struts2的action多例模式

8 Spring 的 Bean 和 JavaBean比较
规范：Spring容器对Bean 没有特殊要求，不像JavaBean 一样遵循一些规范（为每个属性提供相应的setter 和 getter 方法），不过对于设值注入的Bean,一定要提供setter 方法。
作用：Spring 中的Bean 是 java 实例，java组件，它的作用几乎无所不包，任何应用组件都被称为Bean，而传统的Java应用中的JavaBean通常作为DTO（数据传输对象），来封装值对象，在各层之间传递数据。
生命周期：传统的JavaBean作为值对象传递，不接受任何容器管理其生命周期，Spring中的Bean有Spring管理其生命周期行为。

9 创建Bean三种方式
（1）利用无参构造函数+setter方法注入值  
SpringContext利用无参的构造函数创建一个对象，然后利用setter方法赋值。所以如果无参构造函数不存在，Spring上下文创建对象的时候便会报错。   
public class Person {
}
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.springframework.org/schema/beans 
    http://www.springframework.org/schema/beans/spring-beans.xsd">
    <bean class="com.mc.base.learn.spring.bean.Person" id="person">
        <property name="name" value="LiuChunfu"></property>
        <property name="id" value="125"></property>
    </bean>
</beans>
（2）利用有参构造函数直接注入
public class Person {
}
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.springframework.org/schema/beans 
    http://www.springframework.org/schema/beans/spring-beans.xsd">
    <bean class="com.mc.base.learn.spring.bean.Person" id="person">
        <constructor-arg name="id" value="123"></constructor-arg>
        <constructor-arg name="name" value="LiuChunfu"></constructor-arg>
    </bean>
</beans>
（3）使用静态工厂方法创建Bean
public class PersonStaticFactory {
    public static Person createPerson(){
        return new Person();
    }
    public static Person createPerson(Integer id,String name){
        return new Person(name,id);
    }
}
<bean id="person" class="com.mc.base.learn.spring.factory.PersonStaticFactory" factory-method="createPerson"></bean>
（4）通过工厂方法创建
	package com.mc.base.learn.spring.factory;
	import com.mc.base.learn.spring.bean.Person;
	public class PersonFactory {
		public Person createInstance() {
			return new Person();
		}
	}
    <bean id="personFactory" class="com.mc.base.learn.spring.factory.PersonFactory"></bean>
    <bean id="person2" factory-bean="personFactory" factory-method="createInstance"></bean>


10 Bean加载流程概览
Spring代码加载入口
ApplicationContext ac = new ClassPathXmlApplicationContext("spring.xml");
ac.getBean(XXX.class);
ClassPathXmlApplicationContext用于加载CLASSPATH下的Spring配置文件，可以看到，第二行就已经可以获取到Bean的实例了，那么必然第一行就已经完成了对所有Bean实例的加载，因此可以通过ClassPathXmlApplicationContext作为入口。为了后面便于代码阅读，先给出一下ClassPathXmlApplicationContext这个类的继承关系：
ClassPathXmlApplicationContext存储内容

11 类和接口分析
BeanFactory
AutowireCapableBeanFactory
HierarchicalBeanFactory
ListableBeanFactory
ConfigurableBeanFactory
ConfigurableListableBeanFactory
1）. BeanFactory
BeanFactory是Spring bean容器的根接口.每个bean都是通过string类型bean name进行标识.这边提供了设计模式单例,原型的替代实现.如果bean name配置为单例,应用内只会获取到一个实例.如果配置为原型,那么可以实例化好后填充属性(基于用户的配置).
BeanFactory作为应用集中配置管理的地方,极大简便应用开发,这样开发人员可以集中与业务.
2）. AutowireCapableBeanFactory
正常情况下，不要使用此接口，应该更倾向于使用BeanFactory或者ListableBeanFactory。
在Quartz具体执行任务的代码在Job类当中（具体是实现了Job的类），如果我们在Job类使用@Autorire注入的类话，那么是会报NullPointerException的。好了，这节文章介绍下如何使用AutowireCapableBeanFactory。
在应用中一般普通的JavaPojo都是由Spring来管理的，所以使用autowire注解来进行注入不会产生问题，但是有两个东西是例外的，一个是Filter，一个是Servlet，这两样东西都是由Servlet容器来维护管理的，所以如果想和其他的Bean一样使用Autowire来注入的 话，是需要做一些额外的功夫的。
3）. HierarchicalBeanFactory
提供父容器的访问功能.至于父容器的设置,需要找ConfigurableBeanFactory的setParentBeanFactory(接口把设置跟获取给拆开了!).
4）. ListableBeanFactory
获取bean时,Spring 鼓励使用这个接口定义的api. 还有个Beanfactory方便使用.其他的4个接口都是不鼓励使用的.
提供容器中bean迭代的功能,不再需要一个个bean地查找.比如可以一次获取全部的bean(太暴力了),根据类型获取bean.在看SpringMVC时,扫描包路径下的具体实现策略就是使用的这种方式(那边使用的是BeanFactoryUtils封装的api).
如果同时实现了HierarchicalBeanFactory,返回值不会考虑父类BeanFactory,只考虑当前factory定义的类.当然也可以使用BeanFactoryUtils辅助类来查找祖先工厂中的类. 
这个接口中的方法只会考虑本factory定义的bean.这些方法会忽略ConfigurableBeanFactory的registerSingleton注册的单例bean(getBeanNamesOfType和getBeansOfType是例外,一样会考虑手动注册的单例).当然BeanFactory的getBean一样可以透明访问这些特殊bean.当然在典型情况下,所有的bean都是由external bean定义,所以应用不需要顾虑这些差别.
5）. ConfigurableBeanFactory
定义BeanFactory的配置.
这边定了太多太多的api,比如类加载器,类型转化,属性编辑器,BeanPostProcessor,作用域,bean定义,处理bean依赖关系,合并其他ConfigurableBeanFactory,bean如何销毁.
6）. ConfigurableListableBeanFactory
提供bean definition的解析,注册功能,再对单例来个预加载(解决循环依赖问题). 
貌似我们一般开发就会直接定义这么个接口了事.而不是像Spring这样先根据使用情况细分那么多,到这边再合并

12 Bean 组件
前面已经说明了 Bean 组件对 Spring 的重要性，下面看看 Bean 这个组件式怎么设计的。Bean 组件在 Spring 的 org.springframework.beans 包下。这个包下的所有类主要解决了三件事：Bean 的定义、Bean 的创建以及对 Bean 的解析。对 Spring 的使用者来说唯一需要关心的就是 Bean 的创建，其他两个由 Spring 在内部帮你完成了，对你来说是透明的。Spring Bean 的创建时典型的工厂模式，他的顶级接口是 BeanFactory，下图是这个工厂的继承层次关系：
BeanFactory 有三个子类：
ListableBeanFactory、HierarchicalBeanFactory 和 AutowireCapableBeanFactory。
但是从上图中我们可以发现最终的默认实现类是 DefaultListableBeanFactory，他实现了所有的接口。那为何要定义这么多层次的接口呢？查阅这些接口的源码和说明发现，每个接口都有他使用的场合，它主要是为了区分在 Spring 内部在操作过程中对象的传递和转化过程中，对对象的数据访问所做的限制。例如 ListableBeanFactory 接口表示这些 Bean 是可列表的，而 HierarchicalBeanFactory 表示的是这些 Bean 是有继承关系的，也就是每个 Bean 有可能有父 Bean。AutowireCapableBeanFactory 接口定义 Bean 的自动装配规则。这四个接口共同定义了 Bean 的集合、Bean 之间的关系、以及 Bean 行为。
Bean 的定义主要有 BeanDefinition 描述，如下图说明了这些类的层次关系：
Bean 的定义就是完整的描述了在 Spring 的配置文件中你定义的 <bean/> 节点中所有的信息，包括各种子节点。当 Spring 成功解析你定义的一个 <bean/> 节点后，在 Spring 的内部他就被转化成 BeanDefinition 对象。以后所有的操作都是对这个对象完成的。
Bean 的解析过程非常复杂，功能被分的很细，因为这里需要被扩展的地方很多，必须保证有足够的灵活性，以应对可能的变化。Bean 的解析主要就是对 Spring 配置文件的解析。这个解析过程主要通过下图中的类完成：
当然还有具体对 tag 的解析这里并没有列出。

13 Context 组件
Context 在 Spring 的 org.springframework.context 包下，前面已经讲解了 Context 组件在 Spring 中的作用，他实际上就是给 Spring 提供一个运行时的环境，用以保存各个对象的状态。下面看一下这个环境是如何构建的。
ApplicationContext 是 Context 的顶级父类，他除了能标识一个应用环境的基本信息外，他还继承了五个接口，这五个接口主要是扩展了 Context 的功能。
从上图中可以看出 ApplicationContext 继承了 BeanFactory，这也说明了 Spring 容器中运行的主体对象是 Bean，另外 ApplicationContext 继承了 ResourceLoader 接口，使得 ApplicationContext 可以访问到任何外部资源，这将在 Core 中详细说明。
ApplicationContext 的子类主要包含两个方面：	
（1）ConfigurableApplicationContext 表示该 Context 是可修改的，也就是在构建 Context 中用户可以动态添加或修改已有的配置信息，它下面又有多个子类，其中最经常使用的是可更新的 Context，即 AbstractRefreshableApplicationContext 类。
（2）WebApplicationContext 顾名思义，就是为 web 准备的 Context 他可以直接访问到 ServletContext，通常情况下，这个接口使用的少。再往下分就是按照构建 Context 的文件类型，接着就是访问 Context 的方式。这样一级一级构成了完整的 Context 等级层次。
总体来说 ApplicationContext 必须要完成以下几件事：
标识一个应用环境
利用 BeanFactory 创建 Bean 对象
保存对象关系表
能够捕获各种事件
Context 作为 Spring 的 Ioc 容器，基本上整合了 Spring 的大部分功能，或者说是大部分功能的基础。

14 Core 组件
Core 组件作为 Spring 的核心组件，他其中包含了很多的关键类，其中一个重要组成部分就是定义了资源的访问方式。这种把所有资源都抽象成一个接口的方式很值得在以后的设计中拿来学习。
下面就重要看一下这个部分在 Spring 的作用。
从上图可以看出 Resource 接口封装了各种可能的资源类型，也就是对使用者来说屏蔽了文件类型的不同。对资源的提供者来说，如何把资源包装起来交给其他人用这也是一个问题，我们看到 Resource 接口继承了 InputStreamSource 接口，这个接口中有个 getInputStream 方法，返回的是 InputStream 类。这样所有的资源都被可以通过 InputStream 这个类来获取，所以也屏蔽了资源的提供者。另外还有一个问题就是加载资源的问题，也就是资源的加载者要统一，从上图中可以看出这个任务是由 ResourceLoader 接口完成，他屏蔽了所有的资源加载者的差异，只需要实现这个接口就可以加载所有的资源，他的默认实现是 DefaultResourceLoader。
从上图可以看出，Context 是把资源的加载、解析和描述工作委托给了 ResourcePatternResolver 类来完成，他相当于一个接头人，他把资源的加载、解析和资源的定义在一起便于其他组件使用。Core 组件中还有很多类似的方式。

15 Spring ioc
1 IOC（Inversion of Control，控制反转）
这是spring的核心，贯穿始终。所谓IoC，对于spring框架来说，就是由spring来负责控制对象的生命周期和对象间的关系。我们必须自己设计和面对每个环节。传统的程序开发也是如此，在一个对象中，如果要使用另外的对象，就必须得到它（自己new一个，或者从JNDI中查询一个），使用完之后还要将对象销毁（比如Connection等），对象始终会和其他的接口或类藕合起来。目的是降低模块的耦合性。解耦。
●谁控制谁，控制什么：传统Java SE程序设计，我们直接在对象内部通过new进行创建对象，是程序主动去创建依赖对象；而IoC是有专门一个容器来创建这些对象，即由Ioc容器来控制对 象的创建；谁控制谁？当然是IoC 容器控制了对象；控制什么？那就是主要控制了外部资源获取（不只是对象包括比如文件等）。
●为何是反转，哪些方面反转了：有反转就有正转，传统应用程序是由我们自己在对象中主动控制去直接获取依赖对象，也就是正转；而反转则是由容器来帮忙创建及注入依赖对象；为何是反转？因为由容器帮我们查找及注入依赖对象，对象只是被动的接受依赖对象，所以是反转；哪些方面反转了？依赖对象的获取被反转了。

16 DI—Dependency Injection依赖注入
组件之间依赖关系由容器在运行期决定，形象的说，即由容器动态的将某个依赖关系注入到组件之中。依赖注入的目的并非为软件系统带来更多功能，而是为了提升组件重用的频率，并为系统搭建一个灵活、可扩展的平台。
通过依赖注入机制，我们只需要通过简单的配置，而无需任何代码就可指定目标需要的资源，完成自身的业务逻辑，而不需要关心具体的资源来自何处，由谁实现。
　　●谁依赖于谁：当然是应用程序依赖于IoC容器；
　　●为什么需要依赖：应用程序需要IoC容器来提供对象需要的外部资源；
　　●谁注入谁：很明显是IoC容器注入应用程序某个对象，应用程序依赖的对象；
　　●注入了什么：就是注入某个对象所需要的外部资源（包括对象、资源、常量数据）。

17 AOP [ Aspect Oriented Programing ]
面向切面编程。AOP适合于那些具有横切逻辑的应用：如性能监测，访问控制，事务管理、缓存、对象池管理以及日志记录。AOP将这些分散在各个业务逻辑中的代码通过横向切割的方式抽取到一个独立的模块中。
AOP 实现的关键就在于 AOP 框架自动创建的 AOP 代理，AOP 代理则可分为静态代理和动态代理两大类，其中静态代理是指使用 AOP 框架提供的命令进行编译，从而在编译阶段就可生成 AOP 代理类，因此也称为编译时增强；而动态代理则在运行时借助于 JDK 动态代理、CGLIB 等在内存中“临时”生成 AOP 动态代理类，因此也被称为运行时增强。
代理对象的方法 = 增强处理 + 被代理对象的方法
Spring AOP 底层实现是动态代理+二进制字节码技术 

18 Spring AOP 的实现机制
1）. 实现机制
spring AOP 属于第二代AOP（动态AOP），采用动态代理机制和字节码生成技术实现，与最初的 AspectJ采用编译器将横切逻辑织入目标对象不同，动态代理机制和字节码生成都是在运行期间为目标对象生成一个代理对象，而将横切逻辑织入到这个代理对象中，系统最终使用的是织入了横切逻辑的代理对象，而不是真正的目标对象
2）.动态代理
一般的代理模式是有多少需要代理的对象就要写多少代理类，但是jdk 1.3 之后引入了一种称之为动态代理的机制，使用该机制，可以为指定的接口在系统运行期间动态的生成代理对象
实现：java.lang.reflect.Proxy 类 和 java.lang.reflect.InvocatingHandler 接口。当 Proxy动态生成的代理对象上的相应的接口方法被调用时，对应的InvocationHandler就会拦截相应的方法调用，并进行相应的处理。InvocationHandler 就是实现横切逻辑的地方，是横切逻辑的载体
适用：只能对实现了相应 Interface 的类使用。如果目标对象没有实现任何 Interface，spring AOP 会尝试使用一个称为 CGLIB 的开源的动态字节码生成类库，为目标对象生成动态的代理对象实例
3）.动态字节码生成
原理：对目标对象进行继承扩展，为其生成相应的子类，而子类可以通过重写类扩展父类的行为，只要将横切逻辑的实现放到子类中，然后让系统使用扩展后的目标对象的子类，就OK了。

19 AOP使用场景
AOP用来封装横切关注点，具体可以在下面的场景中使用
Authentication 权限
Caching 缓存
Context passing 内容传递
Error handling 错误处理
Lazy loading 懒加载
Debugging 调试
logging, tracing, profiling and monitoring 记录跟踪 优化 校准
Performance optimization 性能优化
Persistence 持久化
Resource pooling 资源池
Synchronization 同步
Transactions 事务
Filter的实现和struts2的拦截器的实现都是AOP思想  

20 AOP相关概念
@方面（Aspect）：一个关注点的模块化，这个关注点实现可能另外横切多个对象。事务管理是J2EE应用中一个很好的横切关注点例子。方面用Spring的 Advisor或拦截器实现。
@连接点（Joinpoint）: 程序执行过程中明确的点，如方法的调用或特定的异常被抛出
@通知（Advice）: 在特定的连接点，AOP框架执行的动作。各种类型的通知包括“around”、“before”和“throws”通知。通知类型将在下面讨论。许多AOP框架包括Spring都是以拦截器做通知模型，维护一个“围绕”连接点的拦截器链。Spring中定义了四个advice: BeforeAdvice, AfterAdvice, ThrowAdvice和DynamicIntroductionAdvice
@切入点（Pointcut）: 指定一个通知将被引发的一系列连接点的集合。AOP框架必须允许开发者指定切入点,例如，使用正则表达式。 Spring定义了Pointcut接口，用来组合MethodMatcher和ClassFilter，可以通过名字很清楚的理解， MethodMatcher是用来检查目标类的方法是否可以被应用此通知，而ClassFilter是用来检查Pointcut是否应该应用到目标类上
@引入（Introduction）: 添加方法或字段到被通知的类。 Spring允许引入新的接口到任何被通知的对象。例如，你可以使用一个引入使任何对象实现 IsModified接口，来简化缓存。Spring中要使用Introduction, 可有通过DelegatingIntroductionInterceptor来实现通知，通过DefaultIntroductionAdvisor来配置Advice和代理类要实现的接口
@目标对象（Target Object）: 包含连接点的对象。也被称作被通知或被代理对象。POJO
@AOP代理（AOP Proxy）, AOP框架创建的对象，包含通知。 在Spring中，AOP代理可以是JDK动态代理或者CGLIB代理。
@织入（Weaving）: 组装方面来创建一个被通知对象。这可以在编译时完成（例如使用AspectJ编译器），也可以在运行时完成。Spring和其他纯Java AOP框架一样，在运行时完成织入。

21 Spring Security 
基于Spring 应用程序提供的声明式安全保护的安全框架。
Spring Sercurity 提供了完整的安全性解决方案，它能够在Web请求级别和方法调用级别处理身份认证和授权，因为是基于Spring，所以Spring Security充分利用了依赖注入(Dependency injection DI) 和面向切面的技术。
Spring Security从两个角度来解决安全性，他使用Servlet规范中的Filter保护Web请求并限制URL级别的访问。
Spring Security还能够使用AOP保护方法调用——借助于对象代理和使用通知，能够取保只有具备适当权限的用户才能访问安全保护的方法。
在用户认证方面，Spring Security 框架支持主流的认证方式，包括 HTTP 基本认证、HTTP 表单验证、HTTP 摘要认证、OpenID 和 LDAP 等。
在用户授权方面，Spring Security 提供了基于角色的访问控制和访问控制列表（Access Control List，ACL），可以对应用中的领域对象进行细粒度的控制。

22 事务初解
理解事务取钱
比如你去ATM机取1000块钱，大体有两个步骤：首先输入密码金额，银行卡扣掉1000元钱；然后ATM出1000元钱。这两个步骤必须是要么都执行要么都不执行。如果银行卡扣除了1000块但是ATM出钱失败的话，你将会损失1000元；如果银行卡扣钱失败但是ATM却出了1000块，那么银行将损失1000元。所以，如果一个步骤成功另一个步骤失败对双方都不是好事，如果不管哪一个步骤失败了以后，整个取钱过程都能回滚，也就是完全取消所有操作的话，这对双方都是极好的。
事务就是用来解决类似问题的。事务是一系列的动作，它们综合在一起才是一个完整的工作单元，这些动作必须全部完成，如果有一个失败的话，那么事务就会回滚到最开始的状态，仿佛什么都没发生过一样。

23 Spring事务的本质
其实就是数据库对事务的支持，没有数据库的事务支持，spring是无法提供事务功能的。对于纯JDBC操作数据库，想要用到事务，可以按照以下步骤进行：
    获取连接 Connection con = DriverManager.getConnection()
    开启事务con.setAutoCommit(true/false);
    执行CRUD
    提交事务/回滚事务 con.commit() / con.rollback();
    关闭连接 conn.close();
使用Spring的事务管理功能后，我们可以不再写步骤 2 和 4 的代码，而是由Spirng 自动完成。 那么Spring是如何在我们书写的 CRUD 之前和之后开启事务和关闭事务的呢？解决这个问题，也就可以从整体上理解Spring的事务管理实现原理了。

23 Spring并不直接管理事务，而是提供了多种事务管理器，他们将事务管理的职责委托给Hibernate或者JTA等持久化机制所提供的相关平台框架的事务来实现。
Spring事务管理器的接口
org.springframework.transaction.PlatformTransactionManager，
通过这个接口，Spring为各个平台如JDBC、Hibernate等都提供了对应的事务管理器，但是具体的实现就是各个平台自己的事情了。
Public interface PlatformTransactionManager()...{  
    // 由TransactionDefinition得到TransactionStatus对象
    TransactionStatus getTransaction(TransactionDefinition definition) throws TransactionException; 
    // 提交
    Void commit(TransactionStatus status) throws TransactionException;  
    // 回滚
    Void rollback(TransactionStatus status) throws TransactionException;  
    } 
从这里可知具体的具体的事务管理机制对Spring来说是透明的，它并不关心那些，那些是对应各个平台需要关心的，所以Spring事务管理的一个优点就是为不同的事务API提供一致的编程模型，如JTA、JDBC、Hibernate、JPA。
（1）JDBC事务
如果应用程序中直接使用JDBC来进行持久化，DataSourceTransactionManager会为你处理事务边界。为了使用DataSourceTransactionManager，你需要使用如下的XML将其装配到应用程序的上下文定义中：
    <bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager">
        <property name="dataSource" ref="dataSource" />
    </bean>
实际上，DataSourceTransactionManager是通过调用java.sql.Connection来管理事务，而后者是通过DataSource获取到的。通过调用连接的commit()方法来提交事务，同样，事务失败则通过调用rollback()方法进行回滚。
（2）Hibernate事务
如果应用程序的持久化是通过Hibernate实习的，那么你需要使用HibernateTransactionManager。对于Hibernate3，需要在Spring上下文定义中添加如下的<bean>声明：
    <bean id="transactionManager" class="org.springframework.orm.hibernate3.HibernateTransactionManager">
        <property name="sessionFactory" ref="sessionFactory" />
    </bean>
sessionFactory属性需要装配一个Hibernate的session工厂，HibernateTransactionManager的实现细节是它将事务管理的职责委托给org.hibernate.Transaction对象，而后者是从Hibernate Session中获取到的。当事务成功完成时，HibernateTransactionManager将会调用Transaction对象的commit()方法，反之，将会调用rollback()方法。
（3）Java持久化API事务（JPA）
Hibernate多年来一直是事实上的Java持久化标准，但是现在Java持久化API作为真正的Java持久化标准进入大家的视野。如果你计划使用JPA的话，那你需要使用Spring的JpaTransactionManager来处理事务。
你需要在Spring中这样配置JpaTransactionManager：
    <bean id="transactionManager" class="org.springframework.orm.jpa.JpaTransactionManager">
        <property name="sessionFactory" ref="sessionFactory" />
    </bean>
JpaTransactionManager只需要装配一个JPA实体管理工厂（javax.persistence.EntityManagerFactory接口的任意实现）。JpaTransactionManager将与由工厂所产生的JPA EntityManager合作来构建事务。
（4）分布式Jta事务
如果你没有使用以上所述的事务管理，或者是跨越了多个事务管理源（比如两个或者是多个不同的数据源），你就需要使用JtaTransactionManager：
    <bean id="transactionManager" class="org.springframework.transaction.jta.JtaTransactionManager">
        <property name="transactionManagerName" value="java:/TransactionManager" />
    </bean>
JtaTransactionManager将事务管理的责任委托给javax.transaction.UserTransaction和javax.transaction.TransactionManager对象，
其中事务成功完成通过UserTransaction.commit()方法提交，事务失败通过UserTransaction.rollback()方法回滚。

24 七种传播行为
事务的第一个方面是传播行为（propagation behavior）。当事务方法被另一个事务方法调用时，必须指定事务应该如何传播。例如：方法可能继续在现有事务中运行，也可能开启一个新事务，并在自己的事务中运行。
PROPAGATION_REQUIRED 	表示当前方法必须运行在事务中。如果当前事务存在，方法将会在该事务中运行。否则，会启动一个新的事务
PROPAGATION_SUPPORTS 	表示当前方法不需要事务上下文，但是如果存在当前事务的话，那么该方法会在这个事务中运行
PROPAGATION_MANDATORY 	表示该方法必须在事务中运行，如果当前事务不存在，则会抛出一个异常
PROPAGATION_REQUIRED_NEW 	表示当前方法必须运行在它自己的事务中。一个新的事务将被启动。如果存在当前事务，在该方法执行期间，当前事务会被挂起。如果使用JTATransactionManager的话，则需要访问TransactionManager
PROPAGATION_NOT_SUPPORTED 	表示该方法不应该运行在事务中。如果存在当前事务，在该方法运行期间，当前事务将被挂起。如果使用JTATransactionManager的话，则需要访问TransactionManager
PROPAGATION_NEVER 	表示当前方法不应该运行在事务上下文中。如果当前正有一个事务在运行，则会抛出异常
PROPAGATION_NESTED 	表示如果当前已经存在一个事务，那么该方法将会在嵌套事务中运行。嵌套的事务可以独立于当前事务进行单独地提交或回滚。如果当前事务不存在，那么其行为与PROPAGATION_REQUIRED一样。注意各厂商对这种传播行为的支持是有所差异的。可以参考资源管理器的文档来确认它们是否支持嵌套事务

25 隔离级别---一个事务可能受其他并发事务影响的程度
（1）并发事务引起的问题
在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务。并发虽然是必须的，但可能会导致一下的问题。
@脏读（Dirty reads）——脏读发生在一个事务读取了另一个事务改写但尚未提交的数据时。如果改写在稍后被回滚了，那么第一个事务获取的数据就是无效的。
@不可重复读（Nonrepeatable read）——不可重复读发生在一个事务执行相同的查询两次或两次以上，但是每次都得到不同的数据时。这通常是因为另一个并发事务在两次查询期间进行了更新。
@幻读（Phantom read）——幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录。
不可重复读与幻读的区别
不可重复读的重点是修改:
同样的条件, 你读取过的数据, 再次读取出来发现值不一样
（2）隔离级别
隔离级别 	含义
ISOLATION_DEFAULT 	使用后端数据库默认的隔离级别
ISOLATION_READ_UNCOMMITTED 	最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读
ISOLATION_READ_COMMITTED 	允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生
ISOLATION_REPEATABLE_READ 	对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生
ISOLATION_SERIALIZABLE 	最高的隔离级别，完全服从ACID的隔离级别，确保阻止脏读、不可重复读以及幻读，也是最慢的事务隔离级别，因为它通常是通过完全锁定事务相关的数据库表来实现的
（3）只读
事务的第三个特性是它是否为只读事务。如果事务只对后端的数据库进行改操作，数据库可以利用事务的只读特性来进行一些特定的优化。通过将事务设置为只读，你就可以给数据库一个机会，让它应用它认为合适的优化措施。
（4）事务超时
为了使应用程序很好地运行，事务不能运行太长的时间。因为事务可能涉及对后端数据库的锁定，所以长时间的事务会不必要的占用数据库资源。事务超时就是事务的一个定时器，在特定时间内事务如果没有执行完毕，那么就会自动回滚，而不是一直等待其结束。
（5）回滚规则
事务五边形的最后一个方面是一组规则，这些规则定义了哪些异常会导致事务回滚而哪些不会。默认情况下，事务只有遇到运行期异常时才会回滚，而在遇到检查型异常时不会回滚（这一行为与EJB的回滚行为是一致的）
但是你可以声明事务在遇到特定的检查型异常时像遇到运行期异常那样回滚。同样，你还可以声明事务遇到特定的异常不回滚，即使这些异常是运行期异常。
（6）事务状态
上面讲到的调用PlatformTransactionManager接口的getTransaction()的方法得到的是TransactionStatus接口的一个实现，这个接口的内容如下：
public interface TransactionStatus{
    boolean isNewTransaction(); // 是否是新的事物
    boolean hasSavepoint(); // 是否有恢复点
    void setRollbackOnly();  // 设置为只回滚
    boolean isRollbackOnly(); // 是否为只回滚
    boolean isCompleted; // 是否已完成
} 

26 编程式事务
（1）编程式和声明式事务的区别
Spring提供了对编程式事务和声明式事务的支持，编程式事务允许用户在代码中精确定义事务的边界，而声明式事务（基于AOP）有助于用户将操作与事务规则进行解耦。
简单地说，编程式事务侵入到了业务代码里面，但是提供了更加详细的事务管理；而声明式事务由于基于AOP，所以既能起到事务管理的作用，又可以不影响业务代码的具体实现。
（2）如何实现编程式事务
Spring提供两种方式的编程式事务管理，分别是：使用TransactionTemplate和直接使用PlatformTransactionManager。
（3）使用TransactionTemplate
采用TransactionTemplate和采用其他Spring模板，如JdbcTempalte和HibernateTemplate是一样的方法。它使用回调方法，把应用程序从处理取得和释放资源中解脱出来。如同其他模板，TransactionTemplate是线程安全的。
（4）使用PlatformTransactionManager
    DataSourceTransactionManager dataSourceTransactionManager = new DataSourceTransactionManager(); //定义一个某个框架平台的TransactionManager，如JDBC、Hibernate
    dataSourceTransactionManager.setDataSource(this.getJdbcTemplate().getDataSource()); // 设置数据源
    DefaultTransactionDefinition transDef = new DefaultTransactionDefinition(); // 定义事务属性
    transDef.setPropagationBehavior(DefaultTransactionDefinition.PROPAGATION_REQUIRED); // 设置传播行为属性
    TransactionStatus status = dataSourceTransactionManager.getTransaction(transDef); // 获得事务状态
    try {
        // 数据库操作
        dataSourceTransactionManager.commit(status);// 提交
    } catch (Exception e) {
        dataSourceTransactionManager.rollback(status);// 回滚
    }

	
27 声明式事务--五种Spring事务的配置方式
（1）每个Bean都有一个代理
<bean id="transactionManager"
	class="org.springframework.orm.hibernate3.HibernateTransactionManager">
	<property name="sessionFactory" ref="sessionFactory" />
</bean>
（2）所有Bean共享一个代理基类
<bean id="transactionBase" 
		class="org.springframework.transaction.interceptor.TransactionProxyFactoryBean" 
		lazy-init="true" abstract="true"> 
	<!-- 配置事务管理器 --> 
	<property name="transactionManager" ref="transactionManager" /> 
	<!-- 配置事务属性 --> 
	<property name="transactionAttributes"> 
		<props> 
			<prop key="*">PROPAGATION_REQUIRED</prop> 
		</props> 
	</property> 
</bean>   
（3）使用拦截器
<bean id="transactionInterceptor" 
	class="org.springframework.transaction.interceptor.TransactionInterceptor"> 
	<property name="transactionManager" ref="transactionManager" /> 
	<!-- 配置事务属性 --> 
	<property name="transactionAttributes"> 
		<props> 
			<prop key="*">PROPAGATION_REQUIRED</prop> 
		</props> 
	</property> 
</bean>
（4）使用tx标签配置的拦截器
<bean id="transactionManager"
	class="org.springframework.orm.hibernate3.HibernateTransactionManager">
	<property name="sessionFactory" ref="sessionFactory" />
</bean>
（5）全注解
@Transactional
@Component("userDao")
public class UserDaoImpl extends HibernateDaoSupport implements UserDao {
    public List<User> listUsers() {
        return this.getSession().createQuery("from User").list();
    }  
}

29 readOnly
该属性用于设置当前事务是否为只读事务，设置为true表示只读，false则表示可读写，默认值为false。例如：@Transactional(readOnly=true)
从这一点设置的时间点开始（时间点a）到这个事务结束的过程中，其他事务所提交的数据，该事务将看不见！（查询中不会出现别人在时间点a之后提交的数据）
在将事务设置成只读后，相当于将数据库设置成只读数据库，此时若要进行写的操作，会出现错误
应用场合：
如果你一次执行单条查询语句，则没有必要启用事务支持，数据库默认支持SQL执行期间的读一致性； 
如果你一次执行多条查询语句，例如统计查询，报表查询，在这种场景下，多条查询SQL必须保证整体的读一致性，否则，在前条SQL查询之后，后条SQL查询之前，数据被其他用户改变，则该次整体的统计查询将会出现读数据不一致的状态，此时，应该启用事务支持。
【注意是一次执行多次查询来统计某些信息，这时为了保证数据整体的一致性，要用只读事务】
（1）在JDBC中，指定只读事务的办法为： connection.setReadOnly(true);
（2）在Hibernate中，指定只读事务的办法为： session.setFlushMode(FlushMode.NEVER); 此时，Hibernate也会为只读事务提供Session方面的一些优化手段
（3）在Spring的Hibernate封装中，指定只读事务的办法为： bean配置文件中，prop属性增加“readOnly”，或者用注解方式@Transactional(readOnly=true)


30 spring mvc介绍
1 Spring MVC 属于 SpringFrameWork 的后续产品，已经融合在 Spring Web Flow 里面，是一个强大灵活的 Web 框架。Spring MVC 提供了一个 DispatcherServlet 作为前端控制器来分配请求。通过策略接口，Spring 框架是高度可配置的。Spring MVC 还包含多种视图技术，如 Java Server Pages（JSP）、Velocity、Tiles、iText 和 POI 等。Spring MVC 分离了控制器、模型对象、分派器以及处理程序对象的角色，这种分离让它们更容易进行定制。
2 Spring MVC 框架主要由 DispatcherServlet、处理器映射器、处理器适配器、处理器(控制器)、视图解析器、视图组成


31 spring mvc组成结构
（1）DispatcherServlet
前端控制器，所有的请求都有经过它来统一分发，请求会被分发给对应的 Handler。
（2）HandlerMapping（处理器映射器）
解析请求链接，然后根据请求链接找到执行这个请求的类（HandlerMapping 所说的 handler）。
（3）HandlerAdapter（处理器适配器）
调用具体的方法对用户发来的请求来进行处理。
（4）Controller
Controller 将处理用户请求，Controller 处理完用户请求，则返回 ModelAndView 对象给 DispatcherServlet 前端控制器。
从宏观角度考虑，DispatcherServlet 是整个 Web 应用的控制器；从微观考虑，Controller 是单个 Http 请求处理过程中的控制器。
（5）ViewResolver（视图解析器）
解析 MdoelAndView，将 MdoelAndView 中的逻辑视图名变为一个真正的 View 对象，并将 MdoelAndView 中的 Model 取出。
controller指定的是类，handler指定的类中的一个方法。

32 spring mvc 核心类与接口
DispatcherServlet   -- 前置控制器
HandlerMapping接口 -- 处理请求的映射
HandlerMapping接口的实现类：
SimpleUrlHandlerMapping  通过配置文件，把一个URL映射到Controller
DefaultAnnotationHandlerMapping  通过注解，把一个URL映射到Controller类上

HandlerAdapter接口 -- 处理请求的映射
AnnotationMethodHandlerAdapter类，通过注解，把一个URL映射到Controller类的方法上
Controller接口 -- 控制器
由于我们使用了@Controller注解，添加了@Controller注解注解的类就可以担任控制器（Action）的职责,

HandlerInterceptor 接口--拦截器,我们自己实现这个接口，来完成拦截的器的工作。

ViewResolver接口的实现类
UrlBasedViewResolver类 通过配置文件，把一个视图名交给到一个View来处理
InternalResourceViewResolver类，比上面的类，加入了JSTL的支持

View接口
JstlView类
LocalResolver接口
HandlerExceptionResolver接口 --异常处理
SimpleMappingExceptionResolver实现类
ModelAndView类

33 Log4jConfigListener好处： 
1）. 动态的改变记录级别和策略，不需要重启Web应用。 
2）. 把log文件定在 /WEB-INF/logs/ 而不需要写绝对路径。 
因为 系统把web目录的路径压入一个叫webapp.root的系统变量。这样写log文件路径时不用写绝对路径了. 
log4j.appender.logfile.File=${webapp.root}/WEB-INF/logs/myfuse.log 
3）. 可以把log4j.properties和其他properties一起放在/WEB-INF/ ，而不是Class-Path。 
4）.log4jRefreshInterval为6000表示 开一条watchdog线程每6秒扫描一下配置文件的变化;

34 ContextLoaderListener
1 实现了ServletContextListener这个接口，tomcat启动时，spring通过下述配置会初始化spring容器，注入applicationContext.xml中配置的bean以及其他一些配置。
部署applicationContext的xml文件，如果在web.xml中不写任何参数配置信息，默认的路径是"/WEB-INF/applicationContext.xml，在WEB-INF目录下创建的xml文件的名称必须是applicationContext.xml。
如果是要自定义文件名可以在web.xml里加入contextConfigLocation这个context参数：
 <listener>
   <listener-class>org.springframework.web.context.ContextLoaderListener</listener-class>
 </listener>
  <context-param>
   <param-name>contextConfigLocation</param-name>
<param-value>classpath*:applicationContext-*.xml,/WEB-INF/applicationContext.xml,/WEB-INF/classes/applicationContext-*.xml
</param-value>
  </context-param>

35 RequestContextListener
1） 在Spring2.0中除了以前的Singleton和Prototype外又加入了三个新的web作用域，分别为request、session和global session，如果你想让你的容器里的某个bean拥有其中某种新的web作用域，除了在bean级上配置相应的scope属性，还必须在容器级做一个额外的初始化配置。 
   <listener>  
       <listener-class>
org.springframework.web.context.request.RequestContextListener
</listener-class>  
   </listener> 
2） 基于LocalThread将HTTP request对象绑定到为该请求提供服务的线程上。这使得具有request和session作用域的bean能够在后面的调用链中被访问到。 
<bean id="loginAction" class="com.foo.LoginAction" scope="request"/>
针对每次HTTP请求，Spring容器会根据loginAction bean定义创建一个全新的LoginAction bean实例，
且该loginAction bean实例仅在当前HTTP request内有效，因此可以根据需要放心的更改所建实例的
内部状态，而其他请求中根据loginAction bean定义创建的实例，将不会看到这些特定于某个请求的
状态变化。当处理请求结束，request作用域的bean实例将被销毁。 
3）为什么需要额外的配置RequestContextFilter 	
已经通过ContextLoaderListener(或ContextLoaderServlet)将Web容器与Spring容器整合，为什么这里还要用额外的RequestContextListener以支持Bean的另外3个作用域，
原因是ContextLoaderListener实现ServletContextListener监听器接口，而ServletContextListener只负责监听Web容器的启动和关闭的事件。
RequestContextFilter实现ServletRequestListener监听器接口，该监听器监听HTTP请求事件，Web服务器接收的每次请求都会通知该监听器。
通过配置RequestContextFilter，Spring容器与Web容器结合的更加密切。

36 PropertyPlaceholderConfigurer
大型项目中，我们往往会对我们的系统的配置信息进行统一管理，一般做法是将配置信息配置与一个cfg.properties的文件中，然后在我们系统初始化的时候，系统自动读取cfg.properties配置文件中的key value（键值对），然后对我们系统进行定制的初始化。一般情况下，我们使用的java.util.Properties,也就是java自带的。往往有一个问题是，每一次加载的时候，我们都需要手工的去读取这个配置文件，一来编码麻烦，二来代码不优雅，往往我们也会自己创建一个类来专门读取，并储存这些配置信息
Spring中提供着一个PropertyPlaceholderConfigurer，这个类是BeanFactoryPostProcessor的子类。
其主要的原理在是。Spring容器初始化的时候，会读取xml或者annotation对Bean进行初始化。初始化的时候，这个PropertyPlaceholderConfigurer会拦截Bean的初始化，初始化的时候会对配置的${pname}进行替换，根据我们Properties中配置的进行替换。从而实现表达式的替换操作 。

37 context:component-scan
通常情况下我们在创建spring项目的时候在xml配置文件中都会配置这个，配置完这个标签后，spring就会去自动扫描base-package对应的路径或者该路径的子包下面的java文件，如果扫描到文件中带有@Service,@Component,@Repository,@Controller等这些注解的类，则把这些类注册为bean，在注解后加上例如@Component(value=”abc”)时，注册的这个类的bean的id就是adc.
如果配置了<context:component-scan>那么<context:annotation-config/>标签就可以不用在xml中再配置了，因为前者包含了后者。另外<context:annotation-config/>还提供了两个子标签 <context:include-filter>和 <context:exclude-filter>

<context:component-scan base-package="com.sparta.trans">  
    <context:include-filter type="annotation" expression="org.springframework.stereotype.Controller"/>   
</context:component-scan>
@Service告诉spring容器，这是一个Service类，标识持久层Bean组件，默认情况会自动加载它到spring容器中。
@Autowried注解告诉spring，这个字段需要自动注入
@Scope指定此spring bean的scope是单例
@Repository注解指定此类是一个容器类，是DA层类的实现。标识持久层Bean组件
@Componet：基本注解，标识一个受Spring管理的Bean组件
@Controller:标识表现层Bean组件

38 WebApplicationContext
WebApplicationContext是实现ApplicationContext接口的子类，专门为web应用准备的,他允许从相对于web根目录的路劲中装载配置文件完成初始化工作，
从WebApplicationContext中可以获得ServletContext的引用，
整个Web应用上下文对象将作为属性放置在ServletContext中，以便web应用可以访问spring上下文,spring中提供WebApplicationContextUtils的
getWebApplicationContext(ServletContext src)方法来获得WebApplicationContext对象
WebApplicationContext扩展了ApplicationContext.在 WebApplicationContext中定义了一个常量 ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE，在上下文启动时，
WebApplicationContext以此为键放置在ServletContext属性列表中

39 ServletContext 
Servlet与Servlet容器之间直接通信的接口，Servlet容器在启动一个web应用时，会为它创建一个ServletContext对 象，每个web应用有唯一的ServletContext对象，同一个web应用的所有Servlet对象共享一个 ServletContext，Servlet对象可以通过它来访问容器中的各种资源WEB容器在启动时，它会为每个WEB应用程序都创建一个对应的ServletContext对象，它代表当前web应用。
1）request获取servletContext
ServletContext servletContext = request.getServletContext();
2）使用ContextLoader
ServletContext servletContext = 
ContextLoader.getCurrentWebApplicationContext().getServletContext();
3）使用spring注入自动注入
@Autowiredprivate 
ServletContext servletContext;

39 xml解析
<mvc:annotation-driven /> 是一种简写形式，完全可以手动配置替代这种简写形式，简写形式可以让初学都快速应用默认配置方案。<mvc:annotation-driven /> 会自动注册DefaultAnnotationHandlerMapping与AnnotationMethodHandlerAdapter 两个bean,是spring MVC为@Controllers分发请求所必须的。
并提供了：数据绑定支持，@NumberFormatannotation支持，@DateTimeFormat支持，@Valid支持，读写XML的支持（JAXB），读写JSON的支持（Jackson）。
后面，我们处理响应ajax请求时，就使用到了对json的支持。
后面，对action写JUnit单元测试时，要从spring IOC容器中取DefaultAnnotationHandlerMapping与AnnotationMethodHandlerAdapter 两个bean，来完成测试，取的时候要知道是<mvc:annotation-driven />这一句注册的这两个bean。

如何替换 <mvc:annotation-driven />？他到底做了什么工作，请看，最后面的 十九节 <mvc:annotation-driven /> 到底做了什么工作。
<mvc:interceptors/> 是一种简写形式。通过看前面的大图，知道，我们可以配置多个HandlerMapping。<mvc:interceptors/>会为每一个HandlerMapping，注入一个拦截器。其实我们也可以手动配置为每个HandlerMapping注入一个拦截器。
<mvc:default-servlet-handler/> 使用默认的Servlet来响应静态文件。
<mvc:resources mapping="/images/**" location="/images/" cache-period="31556926"/> 匹配URL  /images/**  的URL被当做静态资源，由Spring读出到内存中再响应http。

40 spring mvc 中的拦截器：
Spring为我们提供了：
org.springframework.web.servlet.HandlerInterceptor接口，
org.springframework.web.servlet.handler.HandlerInterceptorAdapter适配器，
实现这个接口或继承此类，可以非常方便的实现自己的拦截器。
 
41 spring mvc 如何实现全局的异常处理
在spring MVC的配置文件中：
    <bean id="exceptionResolver" class="org.springframework.web.servlet.handler.SimpleMappingExceptionResolver">  
        <property name="defaultErrorView">     
            <value>/error/error</value>  
        </property>  
        <property name="defaultStatusCode">     
            <value>500</value>  
        </property>      
    <property name="warnLogCategory">     
            <value>org.springframework.web.servlet.handler.SimpleMappingExceptionResolver</value>  
        </property>      
    </bean>   

42 Spring Data JPA简介
1） Spring基于Hibernate开发的一个JPA框架。如果用过Hibernate或者MyBatis的话，就会知道对象关系映射（ORM）框架有多么方便。但是Spring Data JPA框架功能更进一步，为我们做了 一个数据持久层框架几乎能做的任何事情。下面来逐步介绍它的强大功能。是Spring在ORM框架，以及JPA规范的基础上，封装的一套JPA应用框架，并提供了一整套的数据访问层解决方案。
2） Spring Data是一个用于简化数据库访问，并支持云服务的开源框架。其主要目标是使得对数据的访问变得方便快捷，并支持map-reduce框架和云计算数据服务。 
3） Spring Data 包含多个子项目：
Commons - 提供共享的基础框架，适合各个子项目使用，支持跨数据库持久化
JPA - 简化创建 JPA 数据访问层和跨存储的持久层功能
Hadoop - 基于 Spring 的 Hadoop 作业配置和一个 POJO 编程模型的 MapReduce 作业
Key-Value  - 集成了 Redis 和 Riak ，提供多个常用场景下的简单封装
Document - 集成文档数据库：CouchDB 和 MongoDB 并提供基本的配置映射和资料库支持
Graph - 集成 Neo4j 提供强大的基于 POJO 的编程模型
Graph Roo AddOn - Roo support for Neo4j
JDBC Extensions - 支持 Oracle RAD、高级队列和高级数据类型
Mapping - 基于 Grails 的提供对象映射框架，支持不同的数据库
Examples - 示例程序、文档和图数据库
Guidance - 高级文档

43 Spring data JPA的功能
Repository：仅仅是一个标识，表明任何继承它的均为仓库接口类，方便Spring自动扫描识别 
CrudRepository：继承Repository，实现了一组CRUD相关的方法 
PagingAndSortingRepository：继承CrudRepository，实现了一组分页排序相关的方法 
JpaRepository：继承PagingAndSortingRepository，实现一组JPA规范相关的方法 
JpaSpecificationExecutor：比较特殊，不属于Repository体系，实现一组JPA Criteria查询相关的方法。

44 源码分析
spring-data-commons包是核心包。颗粒度划得很细，这主要也是为了责任分离。
Repository：空的接口，目的是为了统一所有Repository的类型，其接口类型使用了泛型，泛型参数中T代表实体类型，ID则是实体中id的类型
CrudRepository :简单的增删改查
PagingAndSortingRepository：分页排序




二、ms相关
1. 什么是Spring?
Spring 是个Java企业级应用的开源开发框架。Spring主要用来开发Java应用，但是有些扩展是针对构建J2EE平台的web应用。Spring 框架目标是简化Java企业级应用开发，并通过POJO为基础的编程模型促进良好的编程习惯。

2. 使用Spring框架的好处是什么？
轻量：Spring 是轻量的，基本的版本大约2MB。
控制反转：Spring通过控制反转实现了松散耦合，对象们给出它们的依赖，而不是创建或查找依赖的对象们。
面向切面的编程(AOP)：Spring支持面向切面的编程，并且把应用业务逻辑和系统服务分开。
容器：Spring 包含并管理应用中对象的生命周期和配置。
MVC框架：Spring的WEB框架是个精心设计的框架，是Web框架的一个很好的替代品。
事务管理：Spring 提供一个持续的事务管理接口，可以扩展到上至本地事务下至全局事务（JTA）。
异常处理：Spring 提供方便的API把具体技术相关的异常（比如由JDBC，Hibernate or JDO抛出的）转化为一致的unchecked 异常。

3. Spring由哪些模块组成?
以下是Spring 框架的基本模块：
Core module
Bean module
Context module
Expression Language module
JDBC module
ORM module
OXM module
Java Messaging Service(JMS) module
Transaction module
Web module
Web-Servlet module
Web-Struts module
Web-Portlet module

4. 核心容器（应用上下文) 模块。
这是基本的Spring模块，提供spring 框架的基础功能，BeanFactory 是 任何以spring为基础的应用的核心。Spring 框架建立在此模块之上，它使Spring成为一个容器。

5. BeanFactory – BeanFactory 实现举例。
Bean 工厂是工厂模式的一个实现，提供了控制反转功能，用来把应用的配置和依赖从正真的应用代码中分离。
最常用的BeanFactory 实现是XmlBeanFactory 类。

6. XMLBeanFactory
最常用的就是org.springframework.beans.factory.xml.XmlBeanFactory ，它根据XML文件中的定义加载beans。该容器从XML 文件读取配置元数据并用它去创建一个完全配置的系统或应用。

7. 解释AOP模块
AOP模块用于发给我们的Spring应用做面向切面的开发， 很多支持由AOP联盟提供，这样就确保了Spring和其他AOP框架的共通性。这个模块将元数据编程引入Spring。

8. 解释JDBC抽象和DAO模块。
通过使用JDBC抽象和DAO模块，保证数据库代码的简洁，并能避免数据库资源错误关闭导致的问题，它在各种不同的数据库的错误信息之上，提供了一个统一的异常访问层。它还利用Spring的AOP 模块给Spring应用中的对象提供事务管理服务。

9. 解释对象/关系映射集成模块。
Spring 通过提供ORM模块，支持我们在直接JDBC之上使用一个对象/关系映射映射(ORM)工具，Spring 支持集成主流的ORM框架，如Hiberate,JDO和 iBATIS SQL Maps。Spring的事务管理同样支持以上所有ORM框架及JDBC。

10. 解释WEB 模块。
Spring的WEB模块是构建在application context 模块基础之上，提供一个适合web应用的上下文。这个模块也包括支持多种面向web的任务，如透明地处理多个文件上传请求和程序级请求参数的绑定到你的业务对象。它也有对Jakarta Struts的支持。

12. Spring配置文件
Spring配置文件是个XML 文件，这个文件包含了类信息，描述了如何配置它们，以及如何相互调用。

13. 什么是Spring IOC 容器？
Spring IOC 负责创建对象，管理对象（通过依赖注入（DI），装配对象，配置对象，并且管理这些对象的整个生命周期。

14. IOC的优点是什么？
IOC 或 依赖注入把应用的代码量降到最低。它使应用容易测试，单元测试不再需要单例和JNDI查找机制。最小的代价和最小的侵入性使松散耦合得以实现。IOC容器支持加载服务时的饿汉式初始化和懒加载。

15. ApplicationContext通常的实现是什么?
FileSystemXmlApplicationContext ：此容器从一个XML文件中加载beans的定义，XML Bean 配置文件的全路径名必须提供给它的构造函数。
ClassPathXmlApplicationContext：此容器也从一个XML文件中加载beans的定义，这里，你需要正确设置classpath因为这个容器将在classpath里找bean配置。
WebXmlApplicationContext：此容器加载一个XML文件，此文件定义了一个WEB应用的所有bean。

16. Bean 工厂和 Application contexts 有什么区别？
Application contexts提供一种方法处理文本消息，一个通常的做法是加载文件资源（比如镜像），它们可以向注册为监听器的bean发布事件。另外，在容器或容器内的对象上执行的那些不得不由bean工厂以程序化方式处理的操作，可以在Application contexts中以声明的方式处理。Application contexts实现了MessageSource接口，该接口的实现以可插拔的方式提供获取本地化消息的方法。

17. 一个Spring的应用看起来象什么？
一个定义了一些功能的接口。
这实现包括属性，它的Setter ， getter 方法和函数等。
Spring AOP。
Spring 的XML 配置文件。
使用以上功能的客户端程序。

18. 什么是Spring的依赖注入？
依赖注入，是IOC的一个方面，是个通常的概念，它有多种解释。这概念是说你不用创建对象，而只需要描述它如何被创建。你不在代码里直接组装你的组件和服务，但是要在配置文件里描述哪些组件需要哪些服务，之后一个容器（IOC容器）负责把他们组装起来。

19. 有哪些不同类型的IOC（依赖注入）方式？
构造器依赖注入：构造器依赖注入通过容器触发一个类的构造器来实现的，该类有一系列参数，每个参数代表一个对其他类的依赖。
Setter方法注入：Setter方法注入是容器通过调用无参构造器或无参static工厂 方法实例化bean之后，调用该bean的setter方法，即实现了基于setter的依赖注入。
20. 哪种依赖注入方式你建议使用，构造器注入，还是 Setter方法注入？
你两种依赖方式都可以使用，构造器注入和Setter方法注入。最好的解决方案是用构造器参数实现强制依赖，setter方法实现可选依赖。

21.什么是Spring beans?
Spring beans 是那些形成Spring应用的主干的java对象。它们被Spring IOC容器初始化，装配，和管理。这些beans通过容器中配置的元数据创建。比如，以XML文件中<bean/> 的形式定义。
Spring 框架定义的beans都是单件beans。在bean tag中有个属性”singleton”，如果它被赋为TRUE，bean 就是单件，否则就是一个 prototype bean。默认是TRUE，所以所有在Spring框架中的beans 缺省都是单件。

22. 一个 Spring Bean 定义 包含什么？
一个Spring Bean 的定义包含容器必知的所有配置元数据，包括如何创建一个bean，它的生命周期详情及它的依赖。

23. 如何给Spring 容器提供配置元数据?
这里有三种重要的方法给Spring 容器提供配置元数据。
XML配置文件。
基于注解的配置。
基于java的配置。

24. 你怎样定义类的作用域?
当定义一个<bean> 在Spring里，我们还能给这个bean声明一个作用域。它可以通过bean
定义中的scope属性来定义。如，当Spring要在需要的时候每次生产一个新的bean实例，bean的scope属性被指定为prototype。另一方面，一个bean每次使用的时候必须返回同一个实例，这个bean的scope 属性 必须设为 singleton。

25. 解释Spring支持的几种bean的作用域。
Spring框架支持以下五种bean的作用域：
singleton : bean在每个Spring ioc 容器中只有一个实例。
prototype：一个bean的定义可以有多个实例。
request：每次http请求都会创建一个bean，该作用域仅在基于web的Spring ApplicationContext情形下有效。
session：在一个HTTP Session中，一个bean定义对应一个实例。该作用域仅在基于web的Spring ApplicationContext情形下有效。
global-session：在一个全局的HTTP Session中，一个bean定义对应一个实例。该作用域仅在基于web的Spring ApplicationContext情形下有效。
缺省的Spring bean 的作用域是Singleton.

26. Spring框架中的单例bean是线程安全的吗?
不，Spring框架中的单例bean不是线程安全的。

27. 解释Spring框架中bean的生命周期。
Spring容器 从XML 文件中读取bean的定义，并实例化bean。
Spring根据bean的定义填充所有的属性。
如果bean实现了BeanNameAware 接口，Spring 传递bean 的ID 到 setBeanName方法。
如果Bean 实现了 BeanFactoryAware 接口， Spring传递beanfactory 给setBeanFactory 方法。
如果有任何与bean相关联的BeanPostProcessors，Spring会在postProcesserBeforeInitialization()方法内调用它们。
如果bean实现IntializingBean了，调用它的afterPropertySet方法，如果bean声明了初始化方法，调用此初始化方法。
如果有BeanPostProcessors 和bean 关联，这些bean的postProcessAfterInitialization() 方法将被调用。
如果bean实现了 DisposableBean，它将调用destroy()方法。

28. 哪些是重要的bean生命周期方法？ 你能重载它们吗？
有两个重要的bean 生命周期方法，第一个是setup ， 它是在容器加载bean的时候被调用。第二个方法是 teardown 它是在容器卸载类的时候被调用。
The bean 标签有两个重要的属性（init-method和destroy-method）。用它们你可以自己定制初始化和注销方法。它们也有相应的注解（@PostConstruct和@PreDestroy）。

29. 什么是Spring的内部bean？
当一个bean仅被用作另一个bean的属性时，它能被声明为一个内部bean，为了定义inner bean，在Spring 的 基于XML的
配置元数据中，可以在 <property/>或 <constructor-arg/>
元素内使用<bean/> 元素，内部bean通常是匿名的，它们的Scope一般是prototype。

30. 在 Spring中如何注入一个java集合？
Spring提供以下几种集合的配置元素：
<list>类型用于注入一列值，允许有相同的值。
<set> 类型用于注入一组值，不允许有相同的值。
<map> 类型用于注入一组键值对，键和值都可以为任意类型。
<props>类型用于注入一组键值对，键和值都只能为String类型。

31. 什么是bean装配?
装配，或bean 装配是指在Spring 容器中把bean组装到一起，前提是容器需要知道bean的依赖关系，如何通过依赖注入来把它们装配到一起。

32. 什么是bean的自动装配？
Spring 容器能够自动装配相互合作的bean，这意味着容器不需要<constructor-arg>和<property>配置，能通过Bean工厂自动处理bean之间的协作。

33. 解释不同方式的自动装配 。
有五种自动装配的方式，可以用来指导Spring容器用自动装配方式来进行依赖注入。
no：默认的方式是不进行自动装配，通过显式设置ref 属性来进行装配。
byName：通过参数名 自动装配，Spring容器在配置文件中发现bean的autowire属性被设置成byname，之后容器试图匹配、装配和该bean的属性具有相同名字的bean。
byType:：通过参数类型自动装配，Spring容器在配置文件中发现bean的autowire属性被设置成byType，之后容器试图匹配、装配和该bean的属性具有相同类型的bean。如果有多个bean符合条件，则抛出错误。
constructor：这个方式类似于byType， 但是要提供给构造器参数，如果没有确定的带参数的构造器参数类型，将会抛出异常。
autodetect：首先尝试使用constructor来自动装配，如果无法工作，则使用byType方式。

34.自动装配有哪些局限性 ?
自动装配的局限性是：
重写： 你仍需用 <constructor-arg>和 <property> 配置来定义依赖，意味着总要重写自动装配。
基本数据类型：你不能自动装配简单的属性，如基本数据类型，String字符串，和类。
模糊特性：自动装配不如显式装配精确，如果有可能，建议使用显式装配。

35. 你可以在Spring中注入一个null 和一个空字符串吗？
可以。

36. 什么是基于Java的Spring注解配置? 给一些注解的例子.
基于Java的配置，允许你在少量的Java注解的帮助下，进行你的大部分Spring配置而非通过XML文件。
以@Configuration 注解为例，它用来标记类可以当做一个bean的定义，被Spring IOC容器使用。另一个例子是@Bean注解，它表示此方法将要返回一个对象，作为一个bean注册进Spring应用上下文。

37. 什么是基于注解的容器配置?
相对于XML文件，注解型的配置依赖于通过字节码元数据装配组件，而非尖括号的声明。
开发者通过在相应的类，方法或属性上使用注解的方式，直接组件类中进行配置，而不是使用xml表述bean的装配关系。

38. 怎样开启注解装配？
注解装配在默认情况下是不开启的，为了使用注解装配，我们必须在Spring配置文件中配置 <context:annotation-config/>元素。

39. @Required 注解
这个注解表明bean的属性必须在配置的时候设置，通过一个bean定义的显式的属性值或通过自动装配，若@Required注解的bean属性未被设置，容器将抛出BeanInitializationException。

40. @Autowired 注解
@Autowired 注解提供了更细粒度的控制，包括在何处以及如何完成自动装配。它的用法和@Required一样，修饰setter方法、构造器、属性或者具有任意名称和/或多个参数的PN方法。

41. @Qualifier 注解
当有多个相同类型的bean却只有一个需要自动装配时，将@Qualifier 注解和@Autowire 注解结合使用以消除这种混淆，指定需要装配的确切的bean。

42.在Spring框架中如何更有效地使用JDBC?
使用SpringJDBC 框架，资源管理和错误处理的代价都会被减轻。所以开发者只需写statements 和 queries从数据存取数据，JDBC也可以在Spring框架提供的模板类的帮助下更有效地被使用，这个模板叫JdbcTemplate （例子见这里here）

43. JdbcTemplate
JdbcTemplate 类提供了很多便利的方法解决诸如把数据库数据转变成基本数据类型或对象，执行写好的或可调用的数据库操作语句，提供自定义的数据错误处理。

44. Spring对DAO的支持
Spring对数据访问对象（DAO）的支持旨在简化它和数据访问技术如JDBC，Hibernate or JDO 结合使用。这使我们可以方便切换持久层。编码时也不用担心会捕获每种技术特有的异常。

45. 使用Spring通过什么方式访问Hibernate?
在Spring中有两种方式访问Hibernate：
控制反转 Hibernate Template和 Callback。
继承 HibernateDAOSupport提供一个AOP 拦截器。

46. Spring支持的ORM
Spring支持以下ORM：
Hibernate
iBatis
JPA (Java Persistence API)
TopLink
JDO (Java Data Objects)
OJB

47.如何通过HibernateDaoSupport将Spring和Hibernate结合起来？
用Spring的 SessionFactory 调用 LocalSessionFactory。集成过程分三步：
配置the Hibernate SessionFactory。
继承HibernateDaoSupport实现一个DAO。
在AOP支持的事务中装配。

48. Spring支持的事务管理类型
Spring支持两种类型的事务管理：
编程式事务管理：这意味你通过编程的方式管理事务，给你带来极大的灵活性，但是难维护。
声明式事务管理：这意味着你可以将业务代码和事务管理分离，你只需用注解和XML配置来管理事务。

49. Spring框架的事务管理有哪些优点？
它为不同的事务API 如 JTA，JDBC，Hibernate，JPA 和JDO，提供一个不变的编程模式。
它为编程式事务管理提供了一套简单的API而不是一些复杂的事务API如
它支持声明式事务管理。
它和Spring各种数据访问抽象层很好得集成。

50. 你更倾向用那种事务管理类型？
大多数Spring框架的用户选择声明式事务管理，因为它对应用代码的影响最小，因此更符合一个无侵入的轻量级容器的思想。声明式事务管理要优于编程式事务管理，虽然比编程式事务管理（这种方式允许你通过代码控制事务）少了一点灵活性。

51. 解释AOP
面向切面的编程，或AOP， 是一种编程技术，允许程序模块化横向切割关注点，或横切典型的责任划分，如日志和事务管理。

52. Aspect 切面
AOP核心就是切面，它将多个类的通用行为封装成可重用的模块，该模块含有一组API提供横切功能。比如，一个日志模块可以被称作日志的AOP切面。根据需求的不同，一个应用程序可以有若干切面。在Spring AOP中，切面通过带有@Aspect注解的类实现。

53. 在Spring AOP 中，关注点和横切关注的区别是什么？
关注点是应用中一个模块的行为，一个关注点可能会被定义成一个我们想实现的一个功能。
横切关注点是一个关注点，此关注点是整个应用都会使用的功能，并影响整个应用，比如日志，安全和数据传输，几乎应用的每个模块都需要的功能。因此这些都属于横切关注点。

54. 连接点
连接点代表一个应用程序的某个位置，在这个位置我们可以插入一个AOP切面，它实际上是个应用程序执行Spring AOP的位置。

55. 通知
通知是个在方法执行前或执行后要做的动作，实际上是程序执行时要通过SpringAOP框架触发的代码段。
Spring切面可以应用五种类型的通知：
before：前置通知，在一个方法执行前被调用。
after: 在方法执行之后调用的通知，无论方法执行是否成功。
after-returning: 仅当方法成功完成后执行的通知。
after-throwing: 在方法抛出异常退出时执行的通知。
around: 在方法执行之前和之后调用的通知。

56. 切点
切入点是一个或一组连接点，通知将在这些位置执行。可以通过表达式或匹配的方式指明切入点。

57. 什么是引入?
引入允许我们在已存在的类中增加新的方法和属性。

58. 什么是目标对象?
被一个或者多个切面所通知的对象。它通常是一个代理对象。也指被通知（advised）对象。

59. 什么是代理?
代理是通知目标对象后创建的对象。从客户端的角度看，代理对象和目标对象是一样的。

60. 有几种不同类型的自动代理？
BeanNameAutoProxyCreator
DefaultAdvisorAutoProxyCreator
Metadata autoproxying

61. 什么是织入，什么是织入应用的不同点？
织入是将切面和到其他应用类型或对象连接或创建一个被通知对象的过程。
织入可以在编译时，加载时，或运行时完成。

62. 解释基于XML Schema方式的切面实现。
在这种情况下，切面由常规类以及基于XML的配置实现。

63. 解释基于注解的切面实现
在这种情况下(基于@AspectJ的实现)，涉及到的切面声明的风格与带有java5标注的普通java类一致。

64. 什么是Spring的MVC框架？
Spring 配备构建Web 应用的全功能MVC框架。Spring可以很便捷地和其他MVC框架集成，如Struts，Spring 的MVC框架用控制反转把业务对象和控制逻辑清晰地隔离。它也允许以声明的方式把请求参数和业务对象绑定。

65. DispatcherServlet
Spring的MVC框架是围绕DispatcherServlet来设计的，它用来处理所有的HTTP请求和响应。

66. WebApplicationContext
WebApplicationContext 继承了ApplicationContext 并增加了一些WEB应用必备的特有功能，它不同于一般的ApplicationContext ，因为它能处理主题，并找到被关联的servlet。

67. 什么是Spring MVC框架的控制器？
控制器提供一个访问应用程序的行为，此行为通常通过服务接口实现。控制器解析用户输入并将其转换为一个由视图呈现给用户的模型。Spring用一个非常抽象的方式实现了一个控制层，允许用户创建多种用途的控制器。

68. @Controller 注解
该注解表明该类扮演控制器的角色，Spring不需要你继承任何其他控制器基类或引用Servlet API。

69. @RequestMapping 注解
该注解是用来映射一个URL到一个类或一个特定的方处理法上。
---------------------------------------------------------------------------------------------------------------
------------------------------------------spring basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------springboot basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------

一、基础知识
1 Spring 官方网站本身使用Spring 框架开发，随着功能以及业务逻辑的日益复杂，应用伴随着大量的XML配置文件以及复杂的Bean依赖关系。随着Spring 3.0的发布，Spring IO团队主键开始摆脱XML配置文件，并且在开发过程中大量使用“约定优先配置”（convention over configuration）的思想来摆脱Spring框架中各种复杂的配置，衍生了Java Config。

2 Spring Boot正是在这样的一个背景下被抽象出来的开发框架，它本身并不提供Spring框架的核心特性以及扩展功能，只是用于快速、敏捷地开发新一代基于Spring框架的应用程序。也就是说，它并不是用来替代Spring的解决方案，而是和Spring框架紧密结合用于提升Spring开发者体验的工具。同时它集成了大量常用的第三方库配置（例如Jackson, JDBC, Mongo, Redis, Mail等等），Spring Boot应用中这些第三方库几乎可以零配置的开箱即用（out-of-the-box），大部分的Spring Boot应用都只需要非常少量的配置代码，开发者能够更加专注于业务逻辑。

3 Spring Boot不生成代码，且完全不需要XML配置。其主要目标如下：
- 为所有的Spring开发工作提供一个更快、更广泛的入门经验。
- 开箱即用，你也可以通过修改默认值来快速满足你的项目的需求。
- 提供了一系列大型项目中常见的非功能性特性，如嵌入式服务器、安全、指标，健康检测、外部配置等。

4 为什么用springboot
创建独立的 Spring 应用程序
嵌入的 Tomcat，无需部署 WAR 文件
简化 Maven 配置
自动配置 Spring
提供生产就绪型功能，如指标，健康检查和外部配置
开箱即用，没有代码生成，也无需 XML 配置。

5 特性理解　
为基于 Spring 的开发提供更快的入门体验
开箱即用，没有代码生成，也无需 XML 配置。同时也可以修改默认值来满足特定的需求。
提供了一些大型项目中常见的非功能特性，如嵌入式服务器、安全、指标，健康检测、外部配置等。
Spring Boot 并不是对 Spring 功能上的增强，而是提供了一种快速使用 Spring 的方式。

6 Configuration
从Spring3.0，@Configuration用于定义配置类，可替换xml配置文件，被注解的类内部包含有一个或多个被@Bean注解的方法，
这些方法将会被AnnotationConfigApplicationContext或AnnotationConfigWebApplicationContext类进行扫描，并用于构建bean定义，初始化Spring容器。
package com.dxz.demo.configuration;
import org.springframework.context.annotation.Configuration;
@Configuration
public class TestConfiguration 
{
    public TestConfiguration() 
	{
        System.out.println("TestConfiguration容器启动初始化。。。");
    }
}

等价于：
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xmlns:context="http://www.springframework.org/schema/context" xmlns:jdbc="http://www.springframework.org/schema/jdbc"  
    xmlns:jee="http://www.springframework.org/schema/jee" xmlns:tx="http://www.springframework.org/schema/tx"
    xmlns:util="http://www.springframework.org/schema/util" xmlns:task="http://www.springframework.org/schema/task" xsi:schemaLocation="
        http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd
        http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd
        http://www.springframework.org/schema/jdbc http://www.springframework.org/schema/jdbc/spring-jdbc-4.0.xsd
        http://www.springframework.org/schema/jee http://www.springframework.org/schema/jee/spring-jee-4.0.xsd
        http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd
        http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.0.xsd
        http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-4.0.xsd" default-lazy-init="false">
</beans>
   
7 Spring boot拦截器
1） Web开发中，我们除了使用 Filter 来过滤请web求外，还可以使用Spring提供的HandlerInterceptor（拦截器）。HandlerInterceptor 的功能跟过滤器类似，但是提供更精细的的控制能力：在request被响应之前、request被响应之后、视图渲染之前以及request全部结束之后。我们不能通过拦截器修改request内容，但是可以通过抛出异常（或者返回false）来暂停request的执行。
实现 UserRoleAuthorizationInterceptor 的拦截器有：
ConversionServiceExposingInterceptor
CorsInterceptor
LocaleChangeInterceptor
PathExposingHandlerInterceptor
ResourceUrlProviderExposingInterceptor
ThemeChangeInterceptor
UriTemplateVariablesHandlerInterceptor
UserRoleAuthorizationInterceptor
其中 LocaleChangeInterceptor 和 ThemeChangeInterceptor 比较常用。配置拦截器也很简单，Spring 为什么提供了基础类WebMvcConfigurerAdapter ，我们只需要重写 addInterceptors 方法添加注册拦截器。
2） 自定义拦截器3步
@ 创建我们自己的拦截器类并实现 HandlerInterceptor 接口。
@ 创建一个Java类继承WebMvcConfigurerAdapter，并重写 addInterceptors 方法。
@ 实例化我们自定义的拦截器，然后将对像手动添加到拦截器链中（在addInterceptors方法中添加）。

8 Spring boot总结
1）.强大的解耦，集成能力。
2）.零配置（简单配置）
是的springboot完全可以做到零配置，而且这也是它们倡导的。这样的好处是显而易见的，那就是降低了入门的门槛，对于一个新手来说，怎么做配置从来都是一件十分头疼的事，配置越多，对应的学习难度也就越大。那么它是如何做到的呢，下面以比较常用的数据源配置作为比较，以期能够更好理解，
这是一个常见的数据源配置，可以看见我们配置了dataSource,sqlSessionFactory,sqlSession,myBatisSessionManager，事实上我们只配置了dataSource,sqlSessionFactory，另外两个bean是基于前面的配置构造出来的，这么看来后两个配置并不是必须的，那么前两个也可以不配么，目前来看是不行的，因为里面很多是我们自定义的属性值，官方没办法通过默认值去填充，那么是不是没办法了，当然不是，官方没办法默认，但可以约定，比如约定property文件spring.datasource.url这个key对应的属性为数据库连接的url，用户只需要配置这个属性，其他就可以交给官方去处理了，这样也就做到了零配置，或者说简单配置就可以用了。
3）.依赖管理
对于开发来说，依赖管理是一件很烦人的事，到了后面有了maven，发现一下子好了很多，但仍然有很多不足，比如依赖的jar包冲突，很多惨痛的事故都是由此引发的，显然有人意识到了这一点，springboot就做了很好的处理，它定义了一个大而全的依赖管理，所有主流开源的依赖都包括在内（当然个人或公司私有的不包括），然后统一版本，这样也就解决了冲突问题
    <groupId>org.springframework.boot</groupId>  
    <artifactId>spring-boot-dependencies</artifactId>  
4）.容器集成	
springboot整合了Tomcat，jetty等主流的容器，默认是Tomcat
5）.开闭原则
支持扩展，不支持修改，springboot提供了最为通用，或者官方建议的一种配置方式，这种配置方式是不可以修改的。但是有时候官方的并不能很好的满足我们的需要，这个时候重写官方的配置，来实现以下自定义的属性。

9 Spring Boot Maven Plugin插件提供spring boot在maven中的支持。允许你打包可运行的jar包或war包。
插件提供了几个maven目标和Spring Boot 应用一起工作。总的有：
spring-boot:repackage  请阅读：Spring cloud的Maven插件（一）：repackage目标
spring-boot:run  请阅读：Spring cloud的Maven插件（二）：run目标
spring-boot:start and spring-boot:stop 
spring-boot:build-info
repackage：创建一个自动可执行的jar或war文件。它可以替换常规的artifact，或者用一个单独的classifier附属在maven构建的生命周期中。




二、ms相关
1.谈谈你对Spring Boot的理解？
SpringBoot主要用来简化使用Spring的难度和繁重的XML配置，它是Spring组件的一站式解决方案，采取了习惯优于配置的方法。通过.properties或者.yml文件替代了Spring繁杂的XML配置文件，同时支持@ImportResource注解加载XML配置。Spring Boot还提供了嵌入式HTTP服务器、命令行接口工具、多种插件等等，使得应用程序的测试和开发简单起来。

2. 为什么需要Spring Boot？
Spring Boot 优点非常多，如：独立运行、简化配置、自动配置和无需部署war文件等等

3. 说出Spring Boot 的优点
简化开发，提高整体生产力
Spring Boot 使用 JavaConfig 有助于避免使用 XML，同时避免大量的Maven导入和各种版本冲突
Spring Boot 引导的应用程序可以很容易地与 Spring 生态系统集成，如Spring JDBC、Spring ORM、Spring Data、Spring Security等等
Spring Boot 应用程序提供嵌入式HTTP服务器，如Tomcat和Jetty，可以轻松地开发和测试web应用程序。
Spring Boot 提供命令行接口工具，用于开发和测试应用程序
Spring Boot 提供了多种插件，可以使用内置Maven工具开发和测试 应用程序
Spring Boot 没有单独的 Web 服务器需要，这意味着不再需要启动 Tomcat或其他任何东西

4. Spring Boot 的核心配置文件有哪几个？它们的区别是什么？
Spring Boot 的核心配置文件是 application 和 bootstrap 配置文件。
application 配置文件主要用于 Spring Boot 项目的自动化配置。
bootstrap 配置文件有三个应用场景。
使用Spring Cloud Config配置中心时，需要在 bootstrap 配置文件中添加连接到配置中心的配置属性，来加载外部配置中心的配置信息；
一些固定的不能被覆盖的属性；
一些加密或解密的场景；

5. Spring Boot 的配置文件有哪几种格式？它们有什么区别？
主要有.properties 和 .yml格式，它们的区别主要是书写格式不同。另外，.yml 格式不支持 @PropertySource 注解导入配置。

6. 开启SpringBoot特性有哪几种方式？
继承spring-boot-starter-parent项目
导入spring-boot-dependencies项目依赖

7. 什么是Spring Boot Starter？
Starters可以理解为启动器，它包含了一系列可以集成到应用里面的依赖包，可以一站式集成 Spring 和其他技术，而不需要到处找示例代码和依赖包。Spring Boot Starter的工作原理是：Spring Boot 在启动时扫描项目所依赖的JAR包，寻找包含spring.factories文件的JAR包，根据spring.factories配置加载AutoConfigure类，根据 @Conditional注解的条件，进行自动配置并将Bean注入Spring Context

8. Spring Boot 有哪几种读取配置的方式？
使用@Value注解加载单个属性值
使用@ConfigurationProperties注解可以加载一组属性的值，针对于要加载的属性过多的情况，比@Value注解更加简洁

9. Spring Boot 支持哪些日志框架？推荐和默认的日志框架是哪个？
Spring Boot 支持 Java Util Logging, Log4j2, Logback 作为日志框架，如果使用 Starters 启动器，Spring Boot 将使用 Logback 作为默认日志框架，推荐的日志框架是Log4j2。

10. Spring Boot 可以兼容老 Spring 项目吗？
可以兼容，使用 @ImportResource 注解导入老 Spring 项目配置文件。

11. 保护 Spring Boot 应用有哪些方法？
在生产中使用HTTPS
使用Snyk检查依赖关系
升级到最新版本
启用CSRF保护
使用内容安全策略防止XSS攻击

12. 什么是 JavaConfig？
JavaConfig 是 Spring 社区的产品，它提供了配置 Spring IoC 容器的纯 Java 方法，有助于避免使用 XML 配置。

13. （Spring Boot 的核心注解是哪个？它主要由哪几个注解组成的）介绍一下 @SpringBootApplication 注解
Spring Boot 的核心注解是@SpringBootApplication，它也是启动类使用的注解，主要包含了 3 个注解：
@SpringBootConfiguration：它组合了 @Configuration 注解，实现配置文件的功能。
@EnableAutoConfiguration：具有打开自动配置的功能，也可以关闭某个自动配置的选项。
@ComponentScan：用于Spring组件扫描。

14. Spring Boot 自动配置原理是什么？
@EnableAutoConfiguration注解、 @Configuration注解和 @ConditionalOnClass注解组成了Spring Boot自动配置的核心，首先它得是一个配置文件，其次根据类路径下是否有这个类去自动配置。具体是通过maven读取每个starter中的spring.factories文件，该文件配置了所有需要被创建在spring容器中的bean。

15. 你如何理解 Spring Boot 配置加载顺序？
Spring Boot配置加载顺序优先级是:propertiese文件、YAML文件、系统环境变量、命令行参数。

16. Spring Boot支持哪些嵌入式Web容器？
Spring Boot支持的嵌入式servlet容器有: Tomcat、Jetty、Undertow。

17. 什么是YAML?
YAML 是一种可读的数据序列化语言，它通常用于配置文件。

18. YAML 配置的优势在哪里 ?
配置有序
支持数组，数组中的元素可以是基本数据类型或者对象
简洁方便

19. Spring Boot 是否可以使用 XML 配置 ?
Spring Boot 推荐使用 Java 配置同时支持 XML 配置，通过 @ImportResource 注解加载 XML 配置。

20. application.properties和bootstrap.properties有何区别 ?
bootstrap比 applicaton 优先加载，配置在应用程序上下文的引导阶段生效, 而且boostrap 里面的属性不能被覆盖；
application用于 spring boot 项目的自动化配置。

21. 什么是 Spring Profiles？
Spring Profiles 允许用户根据配置文件（dev，prod，test等等）来注册 bean。当应用程序在开发环境中运行时，只有某些 bean 可以加载，而在生产环境中，某些其他 bean 也可以加载。比如要求 Swagger 文档仅适用于测试环境，并且禁用所有其他文档，可以使用配置文件来完成。

22. 如何在自定义端口上运行 Spring Boot 应用程序
可以在 application.properties 配置文件中指定端口，比如server.port = 8090

23. 如何实现 Spring Boot 应用程序的安全性？
为了实现 Spring Boot 的安全性，可以使用 spring-boot-starter-security 依赖，添加安全配置和重写WebSecurityConfigurerAdapter 配置类的方法。

24. 什么是 WebSocket？
WebSocket 是一种计算机通信协议，通过单个 TCP 连接提供全双工通信信道。
WebSocket 是双向的 ，使用 WebSocket 客户端或服务器可以实现消息发送。
WebSocket 是全双工的 ，客户端和服务器通信是相互独立的。
WebScoket 使用单个 TCP 连接 ，与http 相比，WebSocket 消息数据交换要轻得多。

25. Spring Boot 中的监视器是什么？（什么是Spring Boot Actuator）？
Spring boot actuator 是 spring 启动框架中的重要功能之一，Spring boot 监视器可以访问生产环境中正在运行的应用程序的当前状态。监视器模块公开了一组可直接作为 HTTP URL 访问的 REST 端点来检查状态。

26. 如何在 Spring Boot 中禁用 Actuator 端点安全性？
默认情况下，所有敏感的 HTTP 端点都是安全的，只有具有 ACTUATOR 角色的用户才能访问它们。
安全性是使用标准的 HttpServletRequest.isUserInRole 方法实施的，可以用来禁用安全性。
只有在执行机构端点在防火墙后访问时，才建议禁用安全性。

27. 什么是 CSRF 攻击？
CSRF 代表跨站请求伪造，这是一种攻击，迫使最终用户在当前通过身份验证的Web 应用程序上执行不需要的操作。CSRF 攻击专门针对状态改变请求，而不是数据窃取，因为攻击者无法查看对伪造请求的响应。

28. 如何使用 Spring Boot 实现异常处理？
Spring 通过使用 @ControllerAdvice 注解处理异常，实现一个ControllerAdvice 类来处理控制器类抛出的所有异常。

29. 如何监视所有 Spring Boot 微服务？
Spring Boot 提供监视器端点监控各个微服务，这些端点对于获取有关应用程序的信息（如它们是否已启动）以及它们的组件（如数据库等）是否正常运行很有帮助。但是用监视器的一个主要缺点是，必须单独打开应用程序的知识点以了解其状态或健康状况。

30. 运行 Spring Boot 有哪几种方式？
用命令打包或者放到容器中运行
用 Maven 插件运行
直接执行 main 方法运行
---------------------------------------------------------------------------------------------------------------
------------------------------------------springboot basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------springcloud basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 Spring Cloud 简介
开发人员提供了快速构建分布式系统的一些工具，包括配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等等。
Spring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。Spring并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。
Spring Cloud和云计算没有关系，只是一个基于Spring Boot的快速构建分布式系统的工具集。
Spring Cloud Config：配置管理工具包，让你可以把配置放到远程服务器，集中化管理集群配置，目前支持本地存储、Git以及Subversion。
Spring Cloud Bus：事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与Spring Cloud Config联合实现热部署。
Eureka：云端服务发现，一个基于 REST 的服务，用于定位服务，以实现云端中间层服务发现和故障转移。
Hystrix：熔断器，容错管理工具，旨在通过熔断机制控制服务和第三方库的节点,从而对延迟和故障提供更强大的容错能力。
Ribbon：提供云端负载均衡，有多种负载均衡策略可供选择，可配合服务发现和断路器使用。
Zuul：Zuul 是在云平台上提供动态路由,监控,弹性,安全等边缘服务的框架。Zuul 相当于是设备和 Netflix 流应用的 Web 网站后端所有请求的前门。
Archaius：配置管理API，包含一系列配置管理API，提供动态类型化属性、线程安全配置操作、轮询框架、回调机制等功能。
Consul：封装了Consul操作，consul是一个服务发现与配置工具，与Docker容器可以无缝集成。
Spring Cloud for Cloud Foundry：通过Oauth2协议绑定服务到CloudFoundry，CloudFoundry是VMware推出的开源PaaS云平台。
Spring Cloud Sleuth：日志收集工具包，封装了Dapper和log-based追踪以及Zipkin和HTrace操作，为SpringCloud应用实现了一种分布式追踪解决方案。

2 服务注册与发现
1） 服务注册
在服务治理框架中，通常都会构建一个注册中心，每个服务单元向注册中心登记自己提供的服务，包括服务的主机与端口号、服务版本号、通讯协议等一些附加信息。注册中心按照服务名分类组织服务清单，同时还需要以心跳检测的方式去监测清单中的服务是否可用，若不可用需要从服务清单中剔除，以达到排除故障服务的效果。
2） 服务发现
在服务治理框架下，服务间的调用不再通过指定具体的实例地址来实现，而是通过服务名发起请求调用实现。服务调用方通过服务名从服务注册中心的服务清单中获取服务实例的列表清单，通过指定的负载均衡策略取出一个服务实例位置来进行服务调用。
3） Eureka服务端
Eureka服务端，即服务注册中心。它同其他服务注册中心一样，支持高可用配置。依托于强一致性提供良好的服务实例可用性，可以应对多种不同的故障场景。Eureka服务端支持集群模式部署，当集群中有分片发生故障的时候，Eureka会自动转入自我保护模式。它允许在分片发生故障的时候继续提供服务的发现和注册，当故障分配恢复时，集群中的其他分片会把他们的状态再次同步回来。集群中的的不同服务注册中心通过异步模式互相复制各自的状态，这也意味着在给定的时间点每个实例关于所有服务的状态可能存在不一致的现象。
4） Eureka客户端
Eureka客户端，主要处理服务的注册和发现。客户端服务通过注册和参数配置的方式，嵌入在客户端应用程序的代码中。在应用程序启动时，Eureka客户端向服务注册中心注册自身提供的服务，并周期性的发送心跳来更新它的服务租约。同时，他也能从服务端查询当前注册的服务信息并把它们缓存到本地并周期行的刷新服务状态。

3 断路器
SpringCloud Netflix实现了断路器库的名字叫Hystrix. 在微服务架构下，通常会有多个层次的服务调用. 下面是微服架构下, 浏览器端通过API访问后台微服务的一个示意图：
一个微服务的超时失败可能导致瀑布式连锁反映，下图中，Hystrix通过自主反馈实现的断路器， 防止了这种情况发生。
图中的服务B因为某些原因失败，变得不可用，所有对服务B的调用都会超时。当对B的调用失败达到一个特定的阀值(5秒之内发生20次失败是Hystrix定义的缺省值), 链路就会被处于open状态， 之后所有所有对服务B的调用都不会被执行， 取而代之的是由断路器提供的一个表示链路open的Fallback消息.  Hystrix提供了相应机制，可以让开发者定义这个Fallbak消息.
open的链路阻断了瀑布式错误， 可以让被淹没或者错误的服务有时间进行修复。这个fallback可以是另外一个Hystrix保护的调用, 静态数据，或者合法的空值. Fallbacks可以组成链式结构，所以，最底层调用其它业务服务的第一个Fallback返回静态数据.

4 在Feign应用中使用断路器
1）. Feign内部已经支持了断路器，所以不需要想Ribbon方式一样，在Spring Boot启动类上加额外注解
2）. 用@FeignClient注解添加fallback类， 该类必须实现@FeignClient修饰的接口。
1 @FeignClient(name = "SERVICE-HELLOWORLD", fallback = HelloWorldServiceFailure.class)
2 public interface HelloWorldService {
3     @RequestMapping(value = "/", method = RequestMethod.GET)
4     public String sayHello();
5 }

5 路由网关
1） 在微服务架构中，需要几个关键的组件，服务注册与发现、服务消费、负载均衡、断路器、智能路由、配置管理等，由这几个组件可以组建一个简单的微服务架构。
客户端的请求首先经过负载均衡（zuul、Ngnix），再到达服务网关（zuul集群），然后再到具体的服务，服务统一注册到高可用的服务注册中心集群，服务的所有的配置文件由配置服务管理（下一篇文章讲述），配置服务的配置文件放在Git仓库，方便开发人员随时改配置。
2） 基于Spring的微服务结点在能力上没有高低贵贱之分，但是在角色上会分为边缘服务和内部服务两部分。内部服务顾名思义是为对内暴露服务的结点，供架构内部来调用；
边缘服务是对外部网络暴露的服务结点，也就是对外API接口。
开发人员头疼的地方：为了防止我的程序在网络上被人攻击，我们需要写各种权限机制，这些机制在每个微服务结点都要实现一次。一旦鉴权上有什么bug，又要全部节点上推倒重来，噩梦。
运维人员头疼的地方：边缘服务前段都会架一个F5或者Nginx等负载均衡的代理，需要手动维护一份服务列表和服务地址的路由信息，随着结点的扩展或地址调整这份列表要变来变去。
3） 为了解决鉴权重复的问题，使业务结点本身只关心实现自己的业务，将对权限的处理抽离到上层。外部客户先请求到Zuul上，在Zuul服务上对权限进行统一实现和过滤，
以实现微服务结点的过滤和验证。为了解决请求路由和安全过滤，Spring Cloud推出了一个API gateway组件：Spring Cloud Zuul。在路由方面，Zuul将自己作为一个微服务结点注册到Eureka上，就获取了所有微服务的实例信息，同时又以服务名为ContextPath的方式创建路由映射。

6 继承抽象类zuulFilter，有4个方法需要实现：
filterType:过滤器类型，决定了过滤器在哪个周期生效。类型有pre、route、post、error，对应Spring AOP里的前加强、前后加强、后加强、异常处理。
filterOrder:过滤器的执行顺序，多个过滤器同时存在时根据这个order来决定先后顺序，越小优先级越高
shouldFilter:过滤器是否被执行，只有true时才会执行run()里的代码。我们这里除开访问163会放行其他情况都需要进行过滤判断，在生产环境一般是要根据函数条件来判断的。
run:过滤逻辑，整个代码的zuul的代码逻辑很简单，对外统一的访问路径是zuul服务的地址，如果直接访问163过滤器不生效直接放行，访问其它内部服务结点需要判断是否有accessToken。
由于我内部服务设置了随机sleep时间，测试时发现请求consumer的时候页面会TIMEOUT，检查日志发现service和consumer都正常，再回来看zuul的日志：
Caused by: com.netflix.hystrix.exception.HystrixRuntimeException:demo-feign-freeservice timed-out and no fallback available.
再回头细想Zuul的原理，它包含了Hystrix的部分，怀疑是我被请求的服务处理超时了引起了客户端Zuul的服务降级，但是我又没给Zuul开发fallback代码，所以请求失败报了这个错。
为了验证我的观点给zuul的application.yml添加如下内容：
    hystrix:  
      command:  
        default:  
          execution:  
            timeout:  
              enabled: false  

重启Zuul后再试下：搞定
再验证下zuul默认的路由规则：
http://127.0.0.1:9053/demo-feign-freeservice/feign-service/serviceGet?name=yuanyuan&accessToken=123
http://127.0.0.1:9053/api-service/feign-service/serviceGet?name=yuanyuan&accessToken=123
两个是等效的。

7 高可用的分布式配置中心
1） 下面我们通过整合Eureka来实现配置中心的高可用，因为作为架构内的配置管理，本身其实也是可以看作架构中的一个微服务，我们可以把config server也注册为服务，这样所有客户端就能以服务的方式进行访问。通过这种方法，只需要启动多个指向同一Gitlab仓库位置的config server端就能实现高可用了。
2） 配置中心如何从远程git读取配置文件，当服务实例很多时，都从配置中心读取文件，这时可以考虑将配置中心做成一个微服务，将其集群化，从而达到高可用，架构图如下：
3 新建一个eureka server工程，命名为config-eureka-server,作为配置服务的注册中心。

8 消息总线
在微服务架构的系统中，我们通常会使用轻量级的消息代理来构建一个共用的消息主题让系统中所有微服务实例都连接上来，由于该主题中产生的消息会被所有实例监听和消费，
所以我们称它为消息总线。
spring CloudBus将分布式的节点和轻量的消息代理连接起来。这可以用于广播配置文件的更改或者其他的管理工作。一个关键的思想就是，消息总线可以为微服务做监控，
也可以作为应用程序之间相互通讯。本文要讲述的是用AMQP实现通知微服务架构的配置文件的更改。
目前已经有非常多的开源产品可以供大家使用， 比如：
    ActiveMQ
    Kafka
    RabbitMQ
    RocketMQ

9 Ribbon负载均衡
Netfilx发布的负载均衡器，是一个基于http、tcp的客户端负载均衡工具，具有控制http、tcp客户端的行为，为ribbon配置服务提供者的地址后，ribbon就可以经过springCloud的封装实心客户端负载均衡的服务调用。负载均衡主要是实现对系统的高可用、网络压力的缓解、处理能力的伸缩。对于数据流量过大，往往单一设备是无法承担的，需要多台的设计进行分流。
1）.软负载均衡
在一台机器上安装附加的某种软件，如nginx负载均衡，配置简单、成本低。根据部署的应用于系统的状态来分配资源进行负载、负载的能力不过受限于机器本身，性能越好，负载能力越大。
2）.硬负载均衡
通过服务器和外部网络间安装负载均衡的设备，称为"负载均衡器"，硬件的负载均衡在功能想、性能上往往高于软负载均衡，不过价格昂贵，例：F5负载均衡器。能够通过智能交换机来实现负载，负载的能力与系统、应用无关，主要是通过网络层来判断，比如某时候系统处理能力已经不行了，但是可以通过网络来进行分配，成本高，除设备价格高昂，而且配置冗余．很难想象后面服务器做一个集群，但最关键的负载均衡设备却是单点配置；无法有效掌握服务器及应用状态。
3） 服务器端负载均衡：例如Nginx，通过Nginx进行负载均衡，先发送请求，然后通过负载均衡算法，在多个服务器之间选择一个进行访问；即在服务器端再进行负载均衡算法分配。
4） 客户端负载均衡：例如spring cloud中的ribbon，客户端会有一个服务器地址列表，在发送请求前通过负载均衡算法选择一个服务器，然后进行访问，这是客户端负载均衡；即在客户端就进行负载均衡算法分配。

10 添加Ribbon支持
1）、添加Ribbon的依赖
2）、添加负载均衡支持
@Bean  
@LoadBalanced  
public RestTemplate restTemplate() {  
        return builder.build();  
}  




二、ms相关
1、什么是Spring Cloud？
Spring cloud 流应用程序启动器是基于 Spring Boot 的 Spring 集成应用程序，提供与外部系统的集成，更专注于服务治理。Spring cloud Task，一个生命周期短暂的微服务框架，用于快速构建执行有限数据处理的应用程序。

2、Spring Cloud和Dubbo的区别
Dubbo关注的领域是Spring Cloud的一个子集。Dubbo专注于服务治理，其在服务治理、灰度发布、流量分发方面比Spring Cloud更全面。Spring Cloud覆盖整个微服务架构领域。
Dubbo使用RPC调用效率高一些，Spring Cloud使用HTTP调用效率低，使用更简单。

3、REST和RPC的区别
REST格的系统交互更方便，RPC调用服务提供方和调用方式之间依赖太强。
REST调用系统性能较低，RPC调用效率比REST高。
REST的灵活性可以跨系统跨语言调用，RPC只能在同语言内调用。
REST可以和Swagger等工具整合，自动输出接口API文档。

4、SpringCloud如何实现服务的注册和发现
服务在发布时 指定对应的服务名（服务名包括了IP地址和端口） 将服务注册到注册中心（eureka或者zookeeper）。
这一过程是springcloud自动实现 只需要在main方法添加@EnableDisscoveryClient  同一个服务修改端口就可以启动多个实例。
调用方法：传递服务名称通过注册中心获取所有的可用实例 通过负载均衡策略调用（ribbon和feign）对应的服务。

5、什么是服务熔断和服务降级？
熔断机制是应对雪崩效应的一种微服务链路保护机制。当某个微服务不可用或者响应时间太长时，会进行服务降级，进而熔断该节点微服务的调用，快速返回“错误”的响应信息。当检测到该节点微服务调用响应正常后恢复调用链路。在SpringCloud框架里熔断机制通过Hystrix实现，Hystrix会监控微服务间调用的状况，当失败的调用到一定阈值，缺省是5秒内调用20次，如果失败，就会启动熔断机制。
服务降级，一般是从整体负荷考虑。就是当某个服务熔断之后，服务器将不再被调用，此时客户端可以自己准备一个本地的fallback回调，返回一个缺省值。这样做，虽然会出现局部的错误，但可以避免因为一个服务挂机，而影响到整个架构的稳定性。
Hystrix相关注解：
@EnableHystrix：开启熔断
@HystrixCommand(fallbackMethod=”XXX”)：声明一个失败回滚处理函数XXX，当被注解的方法执行超时（默认是1000毫秒），就会执行fallback函数，返回错误提示。

6、什么是Hystrix？它如何实现容错？
Hystrix是一个延迟和容错库，旨在隔离远程系统，服务和第三方库的访问点，当出现故障是不可避免的故障时，停止级联故障并在复杂的分布式系统中实现弹性。
通常对于使用微服务架构开发的系统，涉及到许多微服务。这些微服务彼此协作。 
假设如果上图中的微服务9失败了，那么使用传统方法我们将传播一个异常。但这仍然会导致整个系统崩溃。 
随着微服务数量的增加，这个问题变得更加复杂。微服务的数量可以高达1000.这是hystrix出现的地方 我们将使用Hystrix在这种情况下的Fallback方法功能。我们有两个服务employee-consumer使用由employee-consumer公开的服务。 
现在假设由于某种原因，employee-producer公开的服务会抛出异常。我们在这种情况下使用Hystrix定义了一个回退方法。这种后备方法应该具有与公开服务相同的返回类型。如果暴露服务中出现异常，则回退方法将返回一些值。

7、什么是Hystrix断路器？我们需要它吗？
由于某些原因，employee-consumer公开服务会引发异常。在这种情况下使用Hystrix我们定义了一个回退方法。如果在公开服务中发生异常，则回退方法返回一些默认值。
如果firstPage method() 中的异常继续发生，则Hystrix电路将中断，并且员工使用者将一起跳过firtsPage方法，并直接调用回退方法。断路器的目的是给第一页方法或第一页方法可能调用的其他方法留出时间，并导致异常恢复。可能发生的情况是，在负载较小的情况下，导致异常的问题有更好的恢复机会 。

8、项目中zuul常用的功能
提供动态路由
提供安全、鉴权处理
跨域处理
全局动态路由的hystrix(熔断、降级、限流)处理

9、服务网关的作用
简化客户端调用复杂度，统一处理外部请求。
数据裁剪以及聚合，根据不同的接口需求，对数据加工后对外。
多渠道支持，针对不同的客户端提供不同的网关支持。
遗留系统的微服务化改造，可以作为新老系统的中转组件。
统一处理调用过程中的安全、权限问题。
Spring Cloud中的网关有：Zuul和Spring Cloud Gateway，最新版本中推荐使用后者。

10、ribbon和feign区别
Ribbon添加maven依赖 spring-starter-ribbon 使用@RibbonClient(value="服务名称") 使用RestTemplate调用远程服务对应的方法。
feign添加maven依赖 spring-starter-feign 服务提供方提供对外接口 调用方使用 在接口上使用@FeignClient("指定服务名")
Ribbon和Feign的区别：
Ribbon和Feign都是用于调用其他服务的，不过方式不同。
启动类使用的注解不同，Ribbon用的是@RibbonClient，Feign用的@EnableFeignClients。
服务的指定位置不同，Ribbon是在@RibbonClient注解上声明，Feign则是在定义抽象方法的接口中使用@FeignClient声明。
调用方式不同，Ribbon需要自己构建http请求，模拟http请求然后使用RestTemplate发送给其他服务，步骤相当繁琐。
Feign则是在Ribbon的基础上进行了一次改进，采用接口的方式，将需要调用的其他服务的方法定义成抽象方法即可，
不需要自己构建http请求。不过要注意的是抽象方法的注解、方法签名要和提供服务的方法完全一致。

11、ribbon的负载均衡策略
RoundRobinRule: 轮询策略，Ribbon以轮询的方式选择服务器，这个是默认值。所以示例中所启动的两个服务会被循环访问;
RandomRule: 随机策略，也就是说Ribbon会随机从服务器列表中选择一个进行访问;
BestAvailableRule: 最大可用策略，即先过滤出故障服务器后，选择一个当前并发请求数最小的;
WeightedResponseTimeRule: 带有加权的轮询策略，对各个服务器响应时间进行加权处理，然后在采用轮询的方式来获取相应的服务器;
AvailabilityFilteringRule: 可用过滤策略，先过滤出故障的或并发请求大于阈值的一部分服务实例，然后再以线性轮询的方式从过滤后的实例清单中选出一个;
ZoneAvoidanceRule: 区域感知策略，先使用主过滤条件（区域负载器，选择最优区域）对所有实例过滤并返回过滤后的实例清单，依次使用次过滤条件列表中的过滤条件对主过滤条件的结果进行过滤，判断最小过滤数（默认1）和最小过滤百分比（默认0），最后对满足条件的服务器则使用RoundRobinRule(轮询方式)选择一个服务器实例。

12、简述什么是CAP,并说明Eureka包含CAP中的哪些?
CAP理论：一个分布式系统不可能同时满足C (一致性),A(可用性),P(分区容错性).由于分区容错性P在分布式系统中是必须要保证的,因此我们只能从A和C中进行权衡.
Eureka 遵守 AP
Eureka各个节点都是平等的,几个节点挂掉不会影响正常节点的工作,神域的节点依然可以提供注册和查询服务。
而Eureka的客户端在向某个Eureka 注册或查询是如果发现连接失败,则会自动切换至其他节点，只要有一台Eureka还在,就能保证注册服务可用(保证可用性),只不过查的信息可能不最新的不保证强一致性)。

13、Eureka和zookeeper都可以提供服务注册与发现的功能，请说说两个的区别？ 
Zookeeper保证了CP（C：一致性，P：分区容错性）
Eureka保证了AP（A：高可用） 
当向注册中心查询服务列表时，我们可以容忍注册中心返回的是几分钟以前的信息，但不能容忍直接down掉不可用。也就是说，服务注册功能对高可用性要求比较高，但zk会出现这样一种情况，当master节点因为网络故障与其他节点失去联系时，剩余节点会重新选leader。问题在于，选取leader时间过长，30 ~ 120s，且选取期间zk集群都不可用，这样就会导致选取期间注册服务瘫痪。在云部署的环境下，因网络问题使得zk集群失去master节点是较大概率会发生的事，虽然服务能够恢复，但是漫长的选取时间导致的注册长期不可用是不能容忍的。
Eureka保证了可用性，Eureka各个节点是平等的，几个节点挂掉不会影响正常节点的工作，剩余的节点仍然可以提供注册和查询服务。而Eureka的客户端向某个Eureka注册或发现时发生连接失败，则会自动切换到其他节点，只要有一台Eureka还在，就能保证注册服务可用，只是查到的信息可能不是最新的。除此之外，Eureka还有自我保护机制，如果在15分钟内超过85%的节点没有正常的心跳，那么Eureka就认为客户端与注册中心发生了网络故障，此时会出现以下几种情况： 
Eureka不在从注册列表中移除因为长时间没有收到心跳而应该过期的服务。 
Eureka仍然能够接受新服务的注册和查询请求，但是不会被同步到其他节点上（即保证当前节点仍然可用）。
当网络稳定时，当前实例新的注册信息会被同步到其他节点。 
因此，Eureka可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像Zookeeper那样使整个微服务瘫痪。

14、什么是 Spring Cloud Bus?我们需要它吗?
Spring Cloud Bus通过轻量消息代理连接各个分布的节点。这会用在广播状态的变化（例如配置变化）或者其他的消息指令。Spring Cloud Bus的一个核心思想是通过分布式的启动器对Spring Boot应用进行扩展，也可以用来建立一个多个应用之间的通信频道。
考虑以下情况:我们有多个应用程序使用 Spring Cloud Config 读取属性，而 Spring Cloud Config 从GIT 读取这些属性。
下面的例子中多个员工生产者模块从 Employee Config Module 获取 Eureka 注册的财产。
如果假设 GIT 中的 Eureka 注册属性更改为指向另一台 Eureka 服务器，会发生什么情况。在这种情况 下，我们将不得不重新启动服务以获取更新的属性。
还有另一种使用执行器端点/刷新的方式。但是我们将不得不为每个模块单独调用这个 url。例如，如果Employee Producer1 部署在端口 8080 上，则调用 http:// localhost:8080 / refresh。同样对于Employee Producer2 http:// localhost:8081 / refresh 等等。这又很麻烦。这就是 Spring Cloud Bus 发挥作用的地方。

15、链路跟踪Sleuth是什么？
当我们项目中引入Spring Cloud Sleuth后，每次链路请求都会添加一串追踪信息，格式是[server-name, main-traceId,sub-spanId,boolean]：
server-name：服务结点名称。
main-traceId：一条链路唯一的ID，为TraceID。
sub-spanId：链路中每一环的ID，为SpanID。
boolean：是否将信息输出到Zipkin等服务收集和展示。
Sleuth的实现是基于HTTP的，为了在数据的收集过程中不能影响到正常业务，Sleuth会在每个请求的Header上添加跟踪需求的重要信息。这样在数据收集时，只需要将Header上的相关信息发送给对应的图像工具即可，图像工具根据上传的数据，按照Span对应的逻辑进行分析、展示。
---------------------------------------------------------------------------------------------------------------
------------------------------------------springcloud basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------sqoop basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------

一、基础知识
1 Sqoop(发音：skup)
一款开源的工具，主要用于在Hadoop(Hive)与传统的数据库(mysql、postgresql...)间进行数据的传递，可以将一个关系型数据库（例如 ： MySQL ,Oracle ,Postgres等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。
Sqoop项目开始于2009年，最早是作为Hadoop的一个第三方模块存在，后来为了让使用者能够快速部署，也为了让开发人员能够更快速的迭代开发，Sqoop独立成为一个Apache项目。

2 注意事项
尽管有以上的优点，在使用Sqoop的时候还有一些事情需要注意。首先，对于默认的并行机制要小心。默认情况下的并行意味着Sqoop假设大数据是在分区键范围内均匀分布的。这在当你的源系统是使用一个序列号发生器来生成主键的时候工作得很好。打个比方，当你有一个10个节点的集群，那么工作负载是在这10台服务器上平均分配的。但是，如果你的分割键是基于字母数字的，拥有比如以“A”作为开头的键值的数量会是“M”作为开头键值数量的20倍，那么工作负载就会变成从一台服务器倾斜到另一台服务器上。
如果你最担心是性能，那么可以研究下直接加载。直接加载绕过通常的Java数据库连接导入，使用数据库本身提供的直接载入工具，比如MySQL的mysqldump。但是有特定数据库的限制。比如，你不能使用MySQL或者PostgreSQL的连接器来导入BLOB和CLOB类型。也没有驱动支持从视图的导入。Oracle直接驱动需要特权来读取类似dba_objects和v_$parameter这样的元数据。请查阅你的数据库直连驱动程序局限性的相关文档。
进行增量导入是与效率有关的最受关注的问题，因为Sqoop专门是为大数据集设计的。Sqoop支持增量更新，将新记录添加到最近一次的导出的数据源上，或者指定上次修改的时间戳。
由于Sqoop将数据移入和移出关系型数据库的能力，其对于Hive—Hadoop生态系统里的著名的类SQL数据仓库—有专门的支持不足为奇。命令“create-hive-table”可以用来将数据表定义导入到Hive。

3 常用命令
sqoop import 导入
--connect jdbc:mysql://127.0.0.1:3306/$db_name 连接数据库
--username root 数据库用户名
--password root 数据库密码
--target-dir /origin_data/$db_name/db/$1/$db_date HDFS地址
--delete-target-dir HDFS地址存在删除
--num-mappers $2 \--split-by $3 maptask数量
--input-null-string '\\N' 空值转换
--input-null-non-string '\\N' 非空字符串替换
--fields-terminated-by "\t" 字符串分割
--query "$4"' and $CONDITIONS;'
-hive-home <dir> 重写$HIVE_HOME
-hive-import 插入数据到hive当中，使用hive的默认分隔符
-hive-overwrite 重写插入
-create-hive-table 建表，如果表已经存在，该操作会报错
-hive-table <table-name> 设置到hive当中的表名
-hive-drop-import-delims 导入到hive时删除 \n, \r, and \0001
-hive-delims-replacement 导入到hive时用自定义的字符替换掉 \n, \r, and \0001
-hive-partition-key hive分区的key
-hive-partition-value <v> hive分区的值
-map-column-hive <map> 类型匹配，sql类型对应到hive类型

4 示例编辑 
sqoop import \
--connect jdbc:mysql://127.0.0.1(可以使用虚拟机名称):3306/database \
--username root \
--password root \
--table tablename \
--target-dir /a/a
--delete-target-dir \
--num-mappers 1 \
--fields-terminated-by "\t"


二、ms相关
1. Sqoop导入数据到hdfs中的参数
--connect \ # 特殊的jdbc连接的字符串
--username \
--password \
--target-dir \ # hdfs目标的目录
--delete-target-dir \ # 导入的目标目录如果存在则删除那个目录
--num-mappers \ #相当于 -m ,并行导入时map task的个数
--fields-terminated-by \
--query "$2" ' and $CONDITIONS;' # 指定满足sql和条件的数据导入

2.Sqoop导入hive时的参数
一步将表结构和数据都导入到hive中
--connect jdbc的url字符串 \
--table mysql中的表名\
--username 账号 \
--password 密码\
--hive-import \
--m mapTask的个数\
--hive-database hive中的数据库名;

3.Rdbms中的增量数据如何导入？
--check-column 字段名 \ #指定判断检查的依据字段
--incremental 导入模式\ # 用来指定增量导入的模式（Mode），append和lastmodified
--last-value 上一次导入结束的时间\
--m mapTask的个数 \
--merge-key 主键
补充：
·如果使用merge-key合并模式 如果是新增的数据则增加，因为incremental是lastmodified模式，那么当有数据更新了，而主键没有变，则会进行合并。
·--check-column字段当数据更新和修改这个字段的时间也要随之变化，mysql中建表时该字段修饰符，字段名timestamp default current_timestamp on update current_timestamp

4. Sqoop导入导出Null存储一致性问题
Hive中的Null在底层是以“\N”来存储，而MySQL中的Null在底层就是Null，为了保证数据两端的一致性,转化的过程中遇到null-string,null-non-string数据都转化成指定的类型，通常指定成"\N"。在导出数据时采用–input-null-string “\N” --input-null-non-string “\N” 两个参数。导入数据时采用–null-string “\N” --null-non-string “\N”。

5.Sqoop数据导出一致性问题
场景1：如Sqoop在导出到Mysql时，使用4个Map任务，过程中有2个任务失败，那此时MySQL中存储了另外两个Map任务导入的数据，此时老板正好看到了这个报表数据。而开发工程师发现任务失败后，会调试问题并最终将全部数据正确的导入MySQL，那后面老板再次看报表数据，发现本次看到的数据与之前的不一致，这在生产环境是不允许的。
Sqoop官网中的用户指南
使用—staging-table选项，将hdfs中的数据先导入到辅助表中，当hdfs中的数据导出成功后，辅助表中的数据在一个事务中导出到目标表中（也就是说这个过程要不完全成功，要不完全失败）。
为了能够使用staging这个选项，staging表在运行任务前或者是空的，要不就使用—clear-staging-table配置，如果staging表中有数据，并且使用了—clear-staging-table选项,sqoop执行导出任务前会删除staging表中所有的数据。
注意：–direct导入时staging方式是不可用的，使用了—update-key选项时staging方式也不能用。
sqoop export \
--connect url \
--username root \
--password 123456 \
--table app_cource_study_report \
--columns watch_video_cnt,complete_video_cnt,dt \
--fields-terminated-by "\t" \
--export-dir "/user/hive/warehouse/tmp.db/app_cource_study_analysi_${day}" \
--staging-table app_cource_study_report_tmp \
--clear-staging-table \
--input-null-string '\\N' \
--null-non-string "\\N"
场景2：设置map数量为1个（不推荐，面试官想要的答案不只这个）
多个Map任务时，采用–staging-table方式，仍然可以解决数据一致性问题。

6.Sqoop底层运行的任务是什么
只有Map阶段，没有Reduce阶段的任务。

7. Map task并行度设置大于1的问题
并行度导入数据的 时候 需要指定根据哪个字段进行切分 该字段通常是主键或者是自增长不重复的数值类型字段，否则会报下面的错误。
Import failed: No primary key could be found for table. Please specify one with --split-by or perform a sequential import with ‘-m 1’.
那么就是说当map task并行度大于1时，下面两个参数要同时使用
–split-by id 指定根据id字段进行切分
–m n 指定map并行度n个

8.Sqoop数据导出的时候一次执行多长时间
Sqoop任务5分钟-2个小时的都有。取决于数据量。

---------------------------------------------------------------------------------------------------------------
------------------------------------------sqoop basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------storm basic.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------

一、基础知识
1 Storm含义 
（1）Storm是Twitter开源的分布式实时大数据处理框架，最早开源于github，从0.9.1版本之后，归于Apache社区，被业界称为实时版Hadoop。随着越来越多的场景对Hadoop的MapReduce高延迟无法容忍，比如网站统计、推荐系统、预警系统、金融系统(高频交易、股票)等等，大数据实时处理解决方案（流计算）的应用日趋广泛，目前已是分布式技术领域最新爆发点，而Storm更是流计算技术中的佼佼者和主流。
（2）Storm是一个开源免费的分布式实时计算系统，storm可以可靠地处理无限的数据流（大数据），可以实时的处理 Hadoop 所处理的事项。Storm 是一个分布式的，可靠的，容错的数据流处理系统。它会把工作任务委托给不同类型的组件，每个组件负责处理一项简单特定的任务。Storm 集群的输入流由一个被称作 spout 的组件管理，spout 把数据传递给 bolt， bolt 要么把数据保存到某种存储器，要么把数据传递给其它的 bolt。你可以想象一下，一个 Storm 集群就是在一连串的 bolt 之间转换 spout 传过来的数据。这里用一个简单的例子来说明这个概念。昨晚我在新闻节目里看到主持人在谈论政治人物和他们对于各种政治话题的立场。他们一直重复着不同的名字，而我开始考虑这些名字是否被提到了相同的次数，以及不同次数之间的偏差。想像播音员读的字幕作为你的数据输入流。你可以用一个 spout 读取一个文件（或者 socket，通过 HTTP，或者别的方法）。文本行被 spout 传给一个 bolt，再被 bolt 按单词切割。单词流又被传给另一个 bolt，在这里每个单词与一张政治人名列表比较。每遇到一个匹配的名字，第二个 bolt 为这个名字在数据库的计数加1。你可以随时查询数据库查看结果， 而且这些计数是随着数据到达实时更新的。
（3）Storm有很多优势
 1）它使用很简单，多种语言均可以使用它，它也有很多使用者； 
2）它处理数据非常快，基本每秒可以处理一百万组单元数据； 
 3）它伸缩性很强，容错性很好，可以保证数据一直被处理 
 4）它很容易设置以及操作 
 （4）Storm使用场景
1）实时分析 
2）机器算法 
3）持续计算 
4）分布式远程服务调用 
5）数据仓库技术 
6）还有更多功能待挖掘 
storm将会集成消息与数据库技术，storm拓扑在数据流和更复杂的处理流处理中，可以实现每个流计算的需要。

2 Storm的核心组件
（1）Nimbus：即Storm的Master，负责资源分配和任务调度。一个Storm集群只有一个Nimbus。
（2）Supervisor：即Storm的Slave，负责接收Nimbus分配的任务，管理所有Worker，一个Supervisor节点中包含多个Worker进程。
（3）Worker：工作进程，每个工作进程中都有多个Task。
（4）Task：任务，在 Storm 集群中每个 Spout 和 Bolt 都由若干个任务（tasks）来执行。每个任务都与一个执行线程相对应。
（5）Topology：计算拓扑，Storm 的拓扑是对实时计算应用逻辑的封装，它的作用与 MapReduce 的任务（Job）很相似，区别在于 MapReduce 的一个 Job 在得到结果之后总会结束，而拓扑会一直在集群中运行，直到你手动去终止它。拓扑还可以理解成由一系列通过数据流（Stream Grouping）相互关联的 Spout 和 Bolt 组成的的拓扑结构。Topology和MapReduce很相像。MapReduce是Map进行获取数据，Reduce进行处理数据。而Topology则是使用Spout获取数据，Bolt来进行计算。总的来说就是一个Topology由一个或者多个的Spout和Bolt组成。
（6）Stream：数据流（Streams）是 Storm 中最核心的抽象概念。一个数据流指的是在分布式环境中并行创建、处理的一组元组（tuple）的无界序列。数据流可以由一种能够表述数据流中元组的域（fields）的模式来定义。
（7）Spout：数据源（Spout）是拓扑中数据流的来源。一般 Spout 会从一个外部的数据源读取元组然后将他们发送到拓扑中。根据需求的不同，Spout 既可以定义为可靠的数据源，也可以定义为不可靠的数据源。一个可靠的 Spout能够在它发送的元组处理失败时重新发送该元组，以确保所有的元组都能得到正确的处理；相对应的，不可靠的 Spout 就不会在元组发送之后对元组进行任何其他的处理。一个 Spout可以发送多个数据流。
（8）Bolt：拓扑中所有的数据处理均是由 Bolt 完成的。通过数据过滤（filtering）、函数处理（functions）、聚合（aggregations）、联结（joins）、数据库交互等功能，Bolt 几乎能够完成任何一种数据处理需求。一个 Bolt 可以实现简单的数据流转换，而更复杂的数据流变换通常需要使用多个 Bolt 并通过多个步骤完成。
（9）Stream grouping：为拓扑中的每个 Bolt 的确定输入数据流是定义一个拓扑的重要环节。数据流分组定义了在 Bolt 的不同任务（tasks）中划分数据流的方式。在 Storm 中有八种内置的数据流分组方式。
（10）Reliability：可靠性。Storm 可以通过拓扑来确保每个发送的元组都能得到正确处理。通过跟踪由 Spout 发出的每个元组构成的元组树可以确定元组是否已经完成处理。每个拓扑都有一个“消息延时”参数，如果 Storm 在延时时间内没有检测到元组是否处理完成，就会将该元组标记为处理失败，并会在稍后重新发送该元组。

3 Topology模式
第一种比较简单，就是由一个Spout获取数据，然后交给一个Bolt进行处理;
第二种稍微复杂点，由一个Spout获取数据，然后交给一个Bolt进行处理一部分，然后在交给下一个Bolt进行处理其他部分。
第三种则比较复杂，一个Spout可以同时发送数据到多个Bolt，而一个Bolt也可以接受多个Spout或多个Bolt，最终形成多个数据流。但是这种数据流必须是有方向的，有起点和终点，不然会造成死循环，数据永远也处理不完。就是Spout发给Bolt1，Bolt1发给Bolt2，Bolt2又发给了Bolt1,最终形成了一个环状。

4 Storm特性 
（1）简单方便 
storm拥有简单方便的API，当用storm编程时，开发者可以很巧妙的处理和转换元组的数据流，一个元组就是一个有名字的列表中的一个值 ，元组里面可以包含任何对象或者类型，当你想用某一个类型的时候，storm可以很轻松为那个类型序列化。 在storm中仅有三个抽象的概念： spouts（发射器）, bolts（闪电），topologies （拓扑）。
（2）可伸缩 
storm拓扑是并行的运行在集群当中，拓扑不同的部分可以通过调整他们的并行性进行单独扩展，在storm客户端通过 rebalance  命令可以动态调整运行中的拓扑的并行（平衡度），storm与生俱来的并行性意味着它可以低延迟的处理大吞吐量的消息，通过测试得知，在处理器： 2x Intel E5645@2.4Ghz   ，内存：24G 的服务器环境下，storm可以完成 每节点一百万每秒100字节的信息。 
（3）高容错（自救） 
storm有很高的容错性，当处理任务死亡时，storm将会自动重新启动他们，如果一个节点服务器死亡时，storm将会自动把处理任务在其他节点服务器运行。 storm的守护进程、矢量图和监测者均被设计为无状态模式和快速死亡，所以，当他们死亡时，他们会自动重启，就像什么都没发生过似的，这意味着如果你强制实行 kill -9命令杀死storm进程，也不会影响你的拓扑正常运行。 
（4）高可用（零容错） 
storm可以保证每个元组均被正常执行，storm的核心机制之一，就是它可以追踪到每一个元组关系，这是保证每个元组不丢失的有效方法。 storm提供了一个“至少一次”处理的机制，当使用一个队列系统时，你将使用同一个机制，当他们失败时，消息就会被重新发送。 Trident是storm更高级别的抽象语义，它可以保证消息只被执行一次。 
（5）跨语言 
storm可以在任何编程语言中使用，storm的核心是通过Thrift规范来定义和提交拓扑，Thrift是可以跨语言调用，所以拓扑也可以任何编程语言中定义或者提交。 同样的， spouts（发射器）和bolts（闪电） 也可以在任何编程语言中定义或者提交，无虚拟机的spouts（发射器）和bolts（闪电）的输入/输出将会基于json的基础协议进行通讯。通讯适配器用 Ruby, Python, Javascript, Perl 这些语言的协议进行了实现。 
（6）集群易搭建 
 storm只需要很少的配置和设置就可以运行起来，storm生产配置开箱即用，EC2可以一键发布、配置storm项目集群。另外，storm发布的时候操作很简单，storm的设计很强壮，集群可以日复一日的运行下去。

5 Storm架构
（1）Nimbus负责代码分发、任务发布、监控集群状态。
（2）Supervisor负责执行分派到的任务，启动或停止工作进程。
（3）UI是一个能看到集群信息的网页。
（4）ZooKeeper是Hadoop的正式子项目，它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。
（5）Storm和Zookeeper的关系：，Storm依靠ZooKeeper集群实现节点间的信息交换
（6）Storm、ZooKeeper和ZeroMQ的关系
Nimbus通过Zookeeper发布任务、管理节点、监控集群状态、统计信息。
Supervisor通过ZooKeeper注册节点状态、领取任务。
Nimbus和Supervisor之间通过ZeroMQ传递消息和数据。
（7）Spouts：数据源，是消息生产者，他会从一个外部源读取数据并向topology里面面发出消息（tuple）。
（8）Stream：数据流，是一个没有边界的tuple序列，这些tuples会被以一种分布式的方式并行地创建和处理。
（9）Bolts：消息处理者，所有的消息处理逻辑被封装在bolts里面，处理输入的数据流并产生输出的新数据流,可执行过滤，聚合，查询数据库等操作。

6 Storm和 Spark 对比 
对比点	Storm	Spark Streaming
实时计算模型	纯实时，来一条数据，处理一条数据	准实时，对一个时间段内的数据收集起来，作为一个RDD，再处理
实时计算延迟度	毫秒级	秒级
吞吐量	低	高
事务机制	支持完善	支持，但不够完善
健壮性 / 容错性	ZooKeeper，Acker，非常强	Checkpoint，WAL，一般
动态调整并行度	支持	不支持
 
7 Spark Streaming与Storm的应用场景
对于Storm来说：
1）、建议在那种需要纯实时，不能忍受1秒以上延迟的场景下使用，比如实时金融系统，要求纯实时进行金融交易和分析
2）、此外，如果对于实时计算的功能中，要求可靠的事务机制和可靠性机制，即数据的处理完全精准，一条也不能多，一条也不能少，也可以考虑使用Storm
3）、如果还需要针对高峰低峰时间段，动态调整实时计算程序的并行度，以最大限度利用集群资源（通常是在小型公司，集群资源紧张的情况），也可以考虑用Storm
4）、如果一个大数据应用系统，它就是纯粹的实时计算，不需要在中间执行SQL交互式查询、复杂的transformation算子等，那么用Storm是比较好的选择

8 Spark Streaming与Storm的优劣分析
（1）事实上，Spark Streaming绝对谈不上比Storm优秀。这两个框架在实时计算领域中，都很优秀，只是擅长的细分场景并不相同。
（2）Spark Streaming仅仅在吞吐量上比Storm要优秀，而吞吐量这一点，也是历来挺Spark Streaming，贬Storm的人着重强调的。但是问题是，是不是在所有的实时计算场景下，都那么注重吞吐量？不尽然。因此，通过吞吐量说Spark Streaming强于Storm，不靠谱。事实上，Storm在实时延迟度上，比Spark Streaming就好多了，前者是纯实时，后者是准实时。而且，Storm的事务机制、健壮性 / 容错性、动态调整并行度等特性，都要比Spark Streaming更加优秀。
（3）Spark Streaming，有一点是Storm绝对比不上的，就是：它位于Spark生态技术栈中，因此Spark Streaming可以和Spark Core、Spark SQL无缝整合，也就意味着，我们可以对实时处理出来的中间数据，立即在程序中无缝进行延迟批处理、交互式查询等操作。这个特点大大增强了Spark Streaming的优势和功能。

9 Storm事务
（1）Spout
ITransactionalSpout<T>，同BaseTransactionalSpout<T>，普通事务Spout
IPartitionedTransactionalSpout<T>，同BasePartitionedTransactionalSpout<T>，分区事务Spout
IOpaquePartitionedTransactionalSpout<T>：同BaseOpaquePartitionedTransactionalSpout<T>，不透明分区事务Spout
（2）Bolt
IBatchBolt<T>：同BaseBatchBolt<T>，普通批处理
BaseTransactionalBolt：事务Bolt
接口Icommitter：标识IBatchBolt 或BaseTransactionalBolt是否是一个committer CoordinatedBolt
（3）传统事务
ITransactionalSpout<T>：普通事务Spout
  -- ITransactionalSpout.Coordinator<X>
       --initializeTransaction(BigInteger txid, XprevMetadata) ：
创建一个新的metadata，当isReady() 为true时，发射该metadata（事务tuple）到“batchemit”流
       --isReady() ：为true时启动新事务，需要时可以在此sleep
  -- ITransactionalSpout.Emitter<X>
      --emitBatch(TransactionAttempt tx,X coordinatorMeta,       BatchOutputCollector collector) ：逐个发射batch的tuple
（4）分区事务
IPartitionedTransactionalSpout<T>：分区事务Spout，主流事务Spout，原因是目前主流MessageQueue都支持分区，分区的作用是增加MQ的吞吐量（每个分区作为一个数据源发送点），主流MQ如Kafka、RocketMQ
  --IPartitionedTransactionalSpout.Coordinator
    --isReady()：同上
    --numPartitions()：返回分区个数。当增加了数据源新分区，同时一个事务被replayed，此时则不发射新分区的tuples，因为它知道该事务中有多少个分区。
--IPartitionedTransactionalSpout.Emitter<X>
     --emitPartitionBatchNew(TransactionAttempt tx,BatchOutputCollector collector,int partition,X lastPartitionMeta)：发射一个新的Batch，返回Metadata
     --emitPartitionBatch(TransactionAttempt tx,BatchOutputCollector collector,int partition,X partitionMeta)：如果这批消息Bolt消费失败了，emitPartitionBatch负责重发这批消息

10 Storm并行度详解
（1）Storm并行度相关的概念
Storm集群有很多节点，按照类型分为nimbus（主节点）、supervisor（从节点），在conf/storm.yaml中配置了一个supervisor,有多个槽（supervisor.slots.ports），每个槽就是一个JVM，就是一个worker(一个节点，运行一个worker)，在每个worker里面可以运行多个线程叫做executor，在executor里运行一个topology的一个component（spout、bolt）叫做task。task  是storm中进行计算的最小的运行单位，表示是spout或者bolt的运行实例。
总结一下，supervisor(节点)>worker(进程)>executor(线程)>task(实例)
程序执行的最大粒度的运行单位是进程，刚才说的task也是需要有进程来运行它的，在supervisor中，运行task的进程称为worker，Supervisor节点上可以运行非常多的worker进程，一般在一个进程中是可以启动多个线程的，所以我们可以在worker中运行多个线程，这些线程称为executor，在executor中运行task。
（2）提高storm的并行度，可 考虑如下几点：
worker(进程)>executor(线程)>task(实例)
增加work进程，增加executor线程，增加task实例
（3）看下面的图：
这表示是一个work进程，其实就是一个jvm虚拟机进程，在这个work进程里面有多个executor线程，每个executor线程会运行一个或多个task实例。一个task是最终完成数据处理的实体单元。(默认情况下一个executor运行一个task).
（4）worker,executor,task解释
1个worker进程执行的是1个topology的子集（注：不会出现1个worker为多个topology服务）。1个worker进程会启动1个或多个executor线程来执行1个topology的component(spout或bolt)。因此，1个运行中的topology就是由集群中多台物理机上的多个worker进程组成的。
executor是1个被worker进程启动的单独线程。每个executor只会运行1个topology的1个component(spout或bolt)的task（注：task可以是1个或多个，storm默认是1个component只生成1个task，executor线程里会在每次循环里顺序调用所有task实例）。
task是最终运行spout或bolt中代码的单元（注：1个task即为spout或bolt的1个实例，executor线程在执行期间会调用该task的nextTuple或execute方法）。topology启动后，1个component(spout或bolt)的task数目是固定不变的，但该component使用的executor线程数可以动态调整（例如：1个executor线程可以执行该component的1个或多个task实例）。这意味着，对于1个component存在这样的条件：#threads<=#tasks（即：线程数小于等于task数目）。默认情况下task的数目等于executor线程数目，即1个executor线程只运行1个task。
（5）worker(进程)>executor(线程)>task(实例) 是如何设置的
1）worker(进程)：这个worker进程数量是在集群启动之前配置好的，在哪配置的呢？是在storm/conf/storm.yaml文件中，参数是supervisor.slots.port，如果我们不在这进行配置的话，这个参数也是有默认值的，在strom-0.9.3的压缩包中的lib目录下，有一个strom-core.jar，打开这个jar文件，在里面有一个defaults.yaml文件中是有一些默认配置的。默认情况下一个storm项目只使用一个work进程，也可以通过代码进行修改，通过config.setNumWorkers(workers)设置。(最好一台机器上的一个topology只使用一个worker,主要原因时减少了worker之间的数据传输)
2） executor(线程)：默认情况下一个executor运行一个task，可以通过在代码中设置builder.setSpout(id,spout, parallelism_hint);或者builder.setBolt(id,bolt,parallelism_hint);来提高线程数的。
3） task(实例)：通过boltDeclarer.setNumTasks(num);来设置实例的个数
默认情况下，一个supervisor节点会启动4个worker进程。每个worker进程会启动1个executor，每个executor启动1个task。

11 Storm运行模式
（1）本地模式(Local Mode)： 即Topology（相当于一个任务，后续会详细讲解）  运行在本地机器的单一JVM上，这个模式主要用来开发、调试。
（2）远程模式(Remote Mode):在这个模式，我们把我们的Topology提交到集群，在这个模式中，Storm的所有组件都是线程安全的，因为它们都会运行在不同的Jvm或物理机器上，这个模式就是正式的生产模式。




二、ms相关
1 Storm与hadoop对比？
应用场景：Storm专注于分布式实时流处理；Hadoop关注的是离线批处理

2 Storm集群架构是什么样的，简单介绍一下
Storm是master/slave架构，在传统的master/slave架构中，主节点一般负责任务的接受分配和监控，从节点负责具体任务的执行，Storn框架也类似，但是在其中有一些不同：
nimbus主节点依然负责集群中分发任务以及监控
supervisor从节点会启动一个worker来执行具体的任务，一个worker就是一个JVM进程
实际项目中，有四个服务器节点，选择了两台机器部署supervisor，防止单点问题；把nimbus和zookeeper部署在另外一台服务器上，只部署了一个实例，这个是根据Storm官方文档推荐部署的。因为对我们的业务系统来说，nimbus和zookeeper本身负载不算高。

3 Storm集群中的任务是什么样子的?简单介绍一下
Storm集群中的任务叫做拓扑，拓扑中包含两种类型的组件：
Spoult：负责对接外部数据源，获取数据
bolt：负责处理数据
我们实际项目中，有一个spoult对接RabbitMQ获取读写器实时数据，一个bolt组件进行去重分组以及相关统计信息的计算。处理完毕的数据，会继续传递到RabbitMQ中等待下层服务处理。

4 Topology在Storm集群中是如何分发的？
storm jar命令上传jar包到storm的nimbus节点
nimbus节点根据配置的信息查询空闲的worker
分配任务到具体的worker中，worker从nimbus下载待处理的jar包

5 具体的线程模型是怎样的？并发度如何设置？
Storm中多线程的设置叫做并发度，一个bolt或者spoult如果并发度设置大于1的话，就会实例多个，每一个对应一个线程去处理。
我们实际项目中，从RabbitMQ中获取数据使用了并发度为2的设置，一可以提高处理速度，二可以防止单点问题。bolt实际处理线程设置为10，分别对应了epc尾数0-9，可以并发的处理

6 消息是如何分发的？如何进行grouping分组设置？
storm中可以通过设置grouping分组，来自定义消息的分发细节。比如随机分组，按字段分组
我们实际项目中，使用的是按字段分组，分组字段是epc的后一位，相同epc尾数的可以被分到同一个线程处理，保证了线程安全问题。

7 Storm中是如何保证消息可靠性的？
Storm中消息链中的处理过消息的链条都会产生一个以数据源为tuple头的处理链，链上的每一个节点都需要显式的说明处理成功或者失败，如果有一个没有显式处理，那么这个消息就没有正确处理完毕。如果超时时间范围内没有处理完毕，就算处理失败。
如果成功处理或者处理失败，Storm框架会回调Spoult中的ack方法或者fail方法，可以在里面做可靠性的后续业务处理。
---------------------------------------------------------------------------------------------------------------
------------------------------------------storm basic.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------zk ms.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------
一、基础知识
1 ZooKeeper
一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。最终，将简单易用的接口和性能高效、功能稳定的系统提供给用户。
提供了文件系统和通知机制。
超过1/2的zookeeper集群节点正常工作后，zookeeper就可以提供服务了

2 通知机制
客户端注册监听它关心的目录节点，当目录节点发生变化（数据改变、被删除、子目录节点增加删除）时，zookeeper会通知客户端。

3 Zookeeper功能
1.命名服务   2.配置管理   3.集群管理   4.分布式锁  5.队列管理

4 文件系统
每个子目录项如 NameService 都被称作为znode，和文件系统一样，我们能够自由的增加、删除znode，在一个znode下增加、删除子znode，唯一的不同在于znode是可以存储数据的。 
@ PERSISTENT-持久化目录节点 
客户端与zookeeper断开连接后，该节点依旧存在 
@ PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点 
客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号 
@ EPHEMERAL-临时目录节点 
客户端与zookeeper断开连接后，该节点被删除 
@ EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点 
客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号 

5 命名服务
在zookeeper的文件系统里创建一个目录，即有唯一的path。在我们使用tborg无法确定上游程序的部署机器时即可与下游程序约定好path，通过path即能互相探索发现。

6 会话
会话就是一个客户端与服务器之间的一个TCP长连接。客户端和服务器的一切交互都是通过这个长连接进行的；会话会在客户端与服务器断开链接后，如果经过了设点的sessionTimeout时间内没有重新链接后失效。

7 节点
节点在ZeeKeeper中包含两层含义：
（1）集群中的一台机器，我们成为机器节点，比如领导者，跟随者
（2）ZooKeeper数据模型中的数据单元，我们成为数据节点（ZNode）。ZooKeeper的数据模型是内存中的一个ZNode数，由斜杠(/)进行分割的路径，就是一个ZNode，每个ZNode上除了保存自己的数据内容，还保存一系列属性信息；ZooKeeper中的数据节点分为两种：持久节点和临时节点。所谓的持久节点是指一旦这个ZNode创建成功，除非主动进行ZNode的移除操作，节点会一直保存在ZooKeeper上；而临时节点的生命周期是跟客户端的会话相关联的，一旦客户端会话失效，这个会话上的所有临时节点都会被自动移除。

8 版本
ZooKeeper为每一个ZNode节点维护一个叫做Stat的数据结构，在Stat中维护了节点相关的三个版本：
dataVersion 
数据版本号，每次对节点进行set操作，dataVersion的值都会增加1（即使设置的是相同的数据）。
cversion 
子节点的版本号。当znode的子节点有变化时，cversion 的值就会增加1。
aclVersion 
ACL的版本号，关于znode的ACL（Access Control List，访问控制），可以参考 参考资料1 有关ACL的描述。
	
9 ACL（Access Control Lists）
    CREATE：创建子节点的权限
    READ：获取节点数据和子节点列表的权限
    WRITE：跟新节点数据的权限
    DELETE：删除子节点的权限
    ADMIN：设置节点ACL的权限。
	
10 监听器Watcher
ZooKeeper允许用户在指定节点上注册一些Watcher，并且在一些特定事件触发的时候，ZooKeeper会通过事件通知到感兴趣的客户端上。

11 ZooKeeper的数据模型
上面有提到ZooKeeper的数据模型是一个ZNode节点树，是一个类型与标准文件系统的层次结构，也是使用斜杠(/)进行分割，在ZooKeeper中每一个节点都可以使用其路径唯一标识，如节点p_1的标识为：/app1/p_1每个ZNode节点都可以存储自己的数据，还可以拥有自己的子节点目录。
ZooKeeper虽然提供了在节点存储数据的功能，但它并不将自己定位为一个通用的数据库，也就是说，你不应该在节点存储过多的数据。Zk规定节点的数据大小不能超过1M，但实际上我们在znode的数据量应该尽可能小，因为数据过大会导致zk的性能明显下降。如果确实需要存储大量的数据，一般解决方法是在另外的分布式数据库（例如redis）中保存这部分数据，然后在znode中我们只保留这个数据库中保存位置的索引即可。

12 ZooKeeper分布式命名服务
zookeeper的命名服务，有两个应用方向:  
1、提供类似JNDI的功能:利用zookeeper中的树形分层结构，可以把系统中的各种服务的名称，地址以及目录信息存放在zookeeper中，需要的时候去zookeeper中读取
2、利用zookeeper中的顺序节点的特性，制作分布式的序列号生成器(ID生成器)，（在往数据库查询数据时，通常需要一个id，在单机环境下，可以利用数据库的自动成功id号，但是这种在分布式环境下就无法使用了，可以使用UUID，但是UUID有一个缺点，就是没有规律很难理解。使用zookeeper的命名服务可以生成有顺序的容易理解的，支持分布式的编号）

13 ZooKeeper分布式配置管理
程序总是需要配置的，如果程序分散部署在多台机器上，要逐个改变配置就变得困难。现在把这些配置全部放到zookeeper上去，保存在 Zookeeper 的某个目录节点中，然后所有相关应用程序对这个目录节点进行监听，一旦配置信息发生变化，每个应用程序就会收到 Zookeeper 的通知，然后从 Zookeeper 获取新的配置信息应用到系统中就好 

14 ZooKeeper分布式集群管理
1）所谓集群管理无在乎两点：是否有机器退出和加入、选举master。 
对于第一点，所有机器约定在父目录GroupMembers下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与 zookeeper的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除，于是，所有人都知道：它上船了。
新机器加入也是类似，所有机器收到通知：新兄弟目录加入，highcount又有了，对于第二点，我们稍微改变一下，所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为master就好。
2）它们的实现方式都是在 Zookeeper 上创建一个 EPHEMERAL 类型的目录节点，然后每个 Server 在它们创建目录节点的父目录节点上调用 getChildren(String path, boolean watch) 方法并设置 watch 为 true，由于是 EPHEMERAL 目录节点，当创建它的 Server 死去，这个目录节点也随之被删除，所以 Children 将会变化，这时 getChildren上的 Watch 将会被调用，所以其它 Server 就知道已经有某台 Server 死去了。新增 Server 也是同样的原理。
3）Zookeeper 如何实现 Leader Election，也就是选出一个 Master Server。和前面的一样每台 Server 创建一个 EPHEMERAL 目录节点，不同的是它还是一个 SEQUENTIAL 目录节点，所以它是个 EPHEMERAL_SEQUENTIAL 目录节点。之所以它是 EPHEMERAL_SEQUENTIAL 目录节点，是因为我们可以给每台 Server 编号，我们可以选择当前是最小编号的 Server 为 Master，假如这个最小编号的 Server 死去，由于是 EPHEMERAL 节点，死去的 Server 对应的节点也被删除，所以当前的节点列表中又出现一个最小编号的节点，我们就选择这个节点为当前 Master。这样就实现了动态选择 Master，避免了传统意义上单 Master 容易出现单点故障的问题。

15 ZooKeeper选主流程
1 ）考虑7*24小时向外提供服务的系统，不能有单点故障，于是我们使用集群，采用的是Master+Slave。集群中有一台主机和多台备机，由主机向外提供服务，
备机监听主机状态，一旦主机宕机，备机必需迅速接管主机继续向外提供服务。在这个过程中，从备机选出一台机作为主机的过程，就是Master选举。
2 ）左边是ZooKeeper集群，右边是3台工作服务器。工作服务器启动时，会去ZooKeeper的Servers节点下创建临时节点，并把基本信息写入临时节点。
这个过程叫服务注册，系统中的其他服务可以通过获取Servers节点的子节点列表，来了解当前系统哪些服务器可用，这该过程叫做服务发现。接着这些服务器会尝试创建Master临时节点，谁创建成功谁就是Master，其他的两台就作为Slave。所有的Work Server必需关注Master节点的删除事件。通过监听Master节点的删除事件，来了解Master服务器是否宕机
（创建临时节点的服务器一旦宕机，它所创建的临时节点即会自动删除）。一旦Master服务器宕机，必需开始新一轮的Master选举。

16 同步流程
选完Leader以后，zk就进入状态同步过程。 
1. Leader等待server连接； 
2 .Follower连接leader，将最大的zxid发送给leader； 
3 .Leader根据follower的zxid确定同步点； 
4 .完成同步后通知follower 已经成为uptodate状态； 
5 .Follower收到uptodate消息后，又可以重新接受client的请求进行服务了。

17 工作流程-Leader
1） .恢复数据； 
2 ）.维持与Learner的心跳，接收Learner请求并判断Learner的请求消息类型； 
3） .Learner的消息类型主要有PING消息、REQUEST消息、ACK消息、REVALIDATE消息，根据不同的消息类型，进行不同的处理。 
PING 消息是指Learner的心跳信息；
REQUEST消息是Follower发送的提议信息，包括写请求及同步请求；
ACK消息是 Follower的对提议的回复，超过半数的Follower通过，则commit该提议；
REVALIDATE消息是用来延长SESSION有效时间。

18 工作流程-Follower
（1）Follower主要有四个功能： 
1）.向Leader发送请求（PING消息、REQUEST消息、ACK消息、REVALIDATE消息）； 
2）.接收Leader消息并进行处理； 
3）.接收Client的请求，如果为写请求，发送给Leader进行投票；
4）.返回Client结果。 
（2）Follower的消息循环处理如下几种来自Leader的消息： 
1） .PING消息： 心跳消息； 
2） .PROPOSAL消息：Leader发起的提案，要求Follower投票； 
3） .COMMIT消息：服务器端最新一次提案的信息； 
4） .UPTODATE消息：表明同步完成； 
5） .REVALIDATE消息：根据Leader的REVALIDATE结果，关闭待revalidate的session还是允许其接受消息； 
6） .SYNC消息：返回SYNC结果到客户端，这个消息最初由客户端发起，用来强制得到最新的更新。

19 ZooKeeper分布式锁
我们常说的锁是单进程多线程锁，在多线程并发编程中，用于线程之间的数据同步，保护共享资源的访问。而分布式锁，指在分布式环境下，保护跨进程、跨主机、跨网络的共享资源，实现互斥访问，保证一致性。
左侧是zookeeper集群，locker是数据节点，node_1到node_n代表一系列的顺序节点。
右侧client_1至client_n代表客户端，Service代表需要互斥访问的服务。总实现思路，是在获取锁的时候在locker节点下创建顺序节点，在释放锁的时候，把自己创建的节点删除。


20 ZooKeeper分布式队列
（1）首先DistributedQueue 的构造器中要传入
ZooKeeper：连接服务端的核心类；
dir：表示znode组的结点
acl：每个结点的访问控制列表
（2）所谓的入队，也就是在dir组下新建一个znode结点，不过结点类型是CreateMode.PERSISTENT_SEQUENTIAL，这就表明了新建结点的值根据序号是有一定顺序性的。其核心实现就是：
zookeeper.create(dir+"/"+prefix, data, acl, CreateMode.PERSISTENT_SEQUENTIAL);
（3）所谓的出队，其实就是取出所有的子结点，然后用treeMap维护有序性，然后将最小的结点出队(也就是在服务端删除结点最小的结点)
（4）该分布式队列的实现严重依赖于zookeeper的一致性保证。

21 ZooKeeper服务发现和注册
1）服务提供者
服务提供者作为服务的提供方将自身的服务信息注册到服务注册中心中。服务信息包含：
▪ 隶属于哪个系统
▪ 服务的IP，端口
▪ 服务的请求URL
▪ 服务的权重等等
2）服务注册中心
服务注册中心主要提供所有服务注册信息的中心存储，同时负责将服务注册信息的更新通知实时的Push给服务消费者(主要是通过Zookeeper的Watcher机制来实现的)。
3）服务消费者
服务消费者主要职责如下：
1）. 服务消费者在启动时从服务注册中心获取需要的服务注册信息
2）. 将服务注册信息缓存在本地
3）. 监听服务注册信息的变更，如接收到服务注册中心的服务变更通知，则在本地缓存中更新服务的注册信息
4）. 根据本地缓存中的服务注册信息构建服务调用请求，并根据负载均衡策略(随机负载均衡，Round-Robin负载均衡等)来转发请求
5）. 对服务提供方的存活进行检测，如果出现服务不可用的服务提供方，将从本地缓存中剔




二、ms相关
1.ZooKeeper是什么？
ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。最终，将简单易用的接口和性能高效）功能稳定的系统提供给用户。
客户端的读请求可以被集群中的任意一台机器处理，如果读请求在节点上注册了监听器，这个监听器也是由所连接的zookeeper机器来处理。对于写请求，这些请求会同时发给其他zookeeper机器并且达成一致后，请求才会返回成功。因此，随着zookeeper的集群机器增多，读请求的吞吐会提高但是写请求的吞吐会下降。
有序性是zookeeper中非常重要的一个特性，所有的更新都是全局有序的，每个更新都有一个唯一的时间戳，这个时间戳称为zxid（Zookeeper Transaction Id）。而读请求只会相对于更新有序，也就是读请求的返回结果中会带有这个zookeeper最新的zxid。

2.ZooKeeper提供了什么？
1）文件系统
2）通知机制

3.Zookeeper文件系统
Zookeeper提供一个多层级的节点命名空间（节点称为znode）。与文件系统不同的是，这些节点都可以设置关联的数据，而文件系统中只有文件节点可以存放数据而目录节点不行。Zookeeper为了保证高吞吐和低延迟，在内存中维护了这个树状的目录结构，这种特性使得Zookeeper不能用于存放大量的数据，每个节点的存放数据上限为1M。

4.四种类型的znode
1）PERSISTENT-持久化目录节点
客户端与zookeeper断开连接后，该节点依旧存在
2）PERSISTENT_SEQUENTIAL-持久化顺序编号目录节点
客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号
3）EPHEMERAL-临时目录节点
客户端与zookeeper断开连接后，该节点被删除
4）EPHEMERAL_SEQUENTIAL-临时顺序编号目录节点
客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号
clipboard.png

5.Zookeeper通知机制
client端会对某个znode建立一个watcher事件，当该znode发生变化时，这些client会收到zk的通知，然后client可以根据znode变化来做出业务上的改变等。

6.Zookeeper做了什么？
1）命名服务
2）配置管理
3）集群管理
4）分布式锁
5）队列管理

7.zk的命名服务（文件系统）
命名服务是指通过指定的名字来获取资源或者服务的地址，利用zk创建一个全局的路径，即是唯一的路径，这个路径就可以作为一个名字，指向集群中的集群，提供的服务的地址，或者一个远程的对象等等。

8.zk的配置管理（文件系统）通知机制）
程序分布式的部署在不同的机器上，将程序的配置信息放在zk的znode下，当有配置发生改变时，也就是znode发生变化时，可以通过改变zk中某个目录节点的内容，利用watcher通知给各个客户端，从而更改配置。

9.Zookeeper集群管理（文件系统）通知机制）
所谓集群管理无在乎两点：是否有机器退出和加入）选举master。
对于第一点，所有机器约定在父目录下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与 zookeeper的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除，于是，所有人都知道：它上船了。
新机器加入也是类似，所有机器收到通知：新兄弟目录加入，highcount又有了，对于第二点，我们稍微改变一下，所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为master就好。

10.Zookeeper分布式锁（文件系统）通知机制）
有了zookeeper的一致性文件系统，锁的问题变得容易。锁服务可以分为两类，一个是保持独占，另一个是控制时序。
对于第一类，我们将zookeeper上的一个znode看作是一把锁，通过createznode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。用完删除掉自己创建的distribute_lock 节点就释放出锁。
对于第二类， /distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选master一样，编号最小的获得锁，用完删除，依次方便。

11.获取分布式锁的流程
在获取分布式锁的时候在locker节点下创建临时顺序节点，释放锁的时候删除该临时节点。客户端调用createNode方法在locker下创建临时顺序节点，
然后调用getChildren(“locker”)来获取locker下面的所有子节点，注意此时不用设置任何Watcher。客户端获取到所有的子节点path之后，如果发现自己创建的节点在所有创建的子节点序号最小，那么就认为该客户端获取到了锁。如果发现自己创建的节点并非locker所有子节点中最小的，说明自己还没有获取到锁，此时客户端需要找到比自己小的那个节点，然后对其调用exist()方法，同时对其注册事件监听器。之后，让这个被关注的节点删除，则客户端的Watcher会收到相应通知，此时再次判断自己创建的节点是否是locker子节点中序号最小的，如果是则获取到了锁，如果不是则重复以上步骤继续获取到比自己小的一个节点并注册监听。当前这个过程中还需要许多的逻辑判断。
代码的实现主要是基于互斥锁，获取分布式锁的重点逻辑在于BaseDistributedLock，实现了基于Zookeeper实现分布式锁的细节。

12.Zookeeper队列管理（文件系统）通知机制）
两种类型的队列：
1）同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。
2）队列按照 FIFO 方式进行入队和出队操作。
第一类，在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。
第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。在特定的目录下创建PERSISTENT_SEQUENTIAL节点，创建成功时Watcher通知等待的队列，队列删除序列号最小的节点用以消费。此场景下Zookeeper的znode用于消息存储，znode存储的数据就是消息队列中的消息内容，SEQUENTIAL序列号就是消息的编号，按序取出即可。由于创建的节点是持久化的，所以不必担心队列消息的丢失问题。

13.Zookeeper数据复制
Zookeeper作为一个集群提供一致的数据服务，自然，它要在所有机器间做数据复制。数据复制的好处：
1）容错：一个节点出错，不致于让整个系统停止工作，别的节点可以接管它的工作；
2）提高系统的扩展能力 ：把负载分布到多个节点上，或者增加节点来提高系统的负载能力；
3）提高性能：让客户端本地访问就近的节点，提高用户访问速度。
从客户端读写访问的透明度来看，数据复制集群系统分下面两种：
1）写主(WriteMaster) ：对数据的修改提交给指定的节点。读无此限制，可以读取任何一个节点。这种情况下客户端需要对读与写进行区别，俗称读写分离；
2）写任意(Write Any)：对数据的修改可提交给任意的节点，跟读一样。这种情况下，客户端对集群节点的角色与变化透明。
对zookeeper来说，它采用的方式是写任意。通过增加机器，它的读吞吐能力和响应能力扩展性非常好，而写，随着机器的增多吞吐能力肯定下降（这也是它建立observer的原因），而响应能力则取决于具体实现方式，是延迟复制保持最终一致性，还是立即复制快速响应。

14.Zookeeper工作原理
Zookeeper 的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议。Zab协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和 leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态。

15.zookeeper是如何保证事务的顺序一致性的？
zookeeper采用了递增的事务Id来标识，所有的proposal（提议）都在被提出的时候加上了zxid，zxid实际上是一个64位的数字，高32位是epoch（时期; 纪元; 世; 新时代）用来标识leader是否发生改变，如果有新的leader产生出来，epoch会自增，低32位用来递增计数。当新产生proposal的时候，会依据数据库的两阶段过程，首先会向其他的server发出事务执行请求，如果超过半数的机器都能执行并且能够成功，那么就会开始执行。

16.Zookeeper 下 Server工作状态
每个Server在工作过程中有三种状态：
LOOKING：当前Server不知道leader是谁，正在搜寻
LEADING：当前Server即为选举出来的leader
FOLLOWING：leader已经选举出来，当前Server与之同步

17.zookeeper是如何选取主leader的？
当leader崩溃或者leader失去大多数的follower，这时zk进入恢复模式，恢复模式需要重新选举出一个新的leader，让所有的Server都恢复到一个正确的状态。Zk的选举算法有两种：一种是基于basic paxos实现的，另外一种是基于fast paxos算法实现的。系统默认的选举算法为fast paxos。
1）Zookeeper选主流程(basic paxos)
（1）选举线程由当前Server发起选举的线程担任，其主要功能是对投票结果进行统计，并选出推荐的Server；
（2）选举线程首先向所有Server发起一次询问(包括自己)；
（3）选举线程收到回复后，验证是否是自己发起的询问(验证zxid是否一致)，然后获取对方的id(myid)，并存储到当前询问对象列表中，最后获取对方提议的leader相关信息(id,zxid)，并将这些信息存储到当次选举的投票记录表中；
（4）收到所有Server回复以后，就计算出zxid最大的那个Server，并将这个Server相关信息设置成下一次要投票的Server；
（5）线程将当前zxid最大的Server设置为当前Server要推荐的Leader，如果此时获胜的Server获得n/2 + 1的Server票数，设置当前推荐的leader为获胜的Server，将根据获胜的Server相关信息设置自己的状态，否则，继续这个过程，直到leader被选举出来。 通过流程分析我们可以得出：要使Leader获得多数Server的支持，则Server总数必须是奇数2n+1，且存活的Server的数目不得少于n+1. 每个Server启动后都会重复以上流程。在恢复模式下，如果是刚从崩溃状态恢复的或者刚启动的server还会从磁盘快照中恢复数据和会话信息，zk会记录事务日志并定期进行快照，方便在恢复时进行状态恢复。
2）Zookeeper选主流程(basic paxos)
fast paxos流程是在选举过程中，某Server首先向所有Server提议自己要成为leader，当其它Server收到提议以后，解决epoch和 zxid的冲突，并接受对方的提议，然后向对方发送接受提议完成的消息，重复这个流程，最后一定能选举出Leader。

18.Zookeeper同步流程
选完Leader以后，zk就进入状态同步过程。
1）Leader等待server连接；
2）Follower连接leader，将最大的zxid发送给leader；
3）Leader根据follower的zxid确定同步点；
4）完成同步后通知follower 已经成为uptodate状态；
5）Follower收到uptodate消息后，又可以重新接受client的请求进行服务了。

19.分布式通知和协调
对于系统调度来说：操作人员发送通知实际是通过控制台改变某个节点的状态，然后zk将这些变化发送给注册了这个节点的watcher的所有客户端。
对于执行情况汇报：每个工作进程都在某个目录下创建一个临时节点。并携带工作的进度数据，这样汇总的进程可以监控目录子节点的变化获得工作进度的实时的全局情况。

20.机器中为什么会有leader？
在分布式环境中，有些业务逻辑只需要集群中的某一台机器进行执行，其他的机器可以共享这个结果，这样可以大大减少重复计算，提高性能，于是就需要进行leader选举。

21.zk节点宕机如何处理？
Zookeeper本身也是集群，推荐配置不少于3个服务器。Zookeeper自身也要保证当一个节点宕机时，其他节点会继续提供服务。
如果是一个Follower宕机，还有2台服务器提供访问，因为Zookeeper上的数据是有多个副本的，数据并不会丢失；
如果是一个Leader宕机，Zookeeper会选举出新的Leader。
ZK集群的机制是只要超过半数的节点正常，集群就能正常提供服务。只有在ZK节点挂得太多，只剩一半或不到一半节点能工作，集群才失效。
所以：
3个节点的cluster可以挂掉1个节点(leader可以得到2票>1.5)
2个节点的cluster就不能挂掉任何1个节点了(leader可以得到1票<=1)

22.zookeeper负载均衡和nginx负载均衡区别
zk的负载均衡是可以调控，nginx只是能调权重，其他需要可控的都需要自己写插件；但是nginx的吞吐量比zk大很多，应该说按业务选择用哪种方式。

23.zookeeper watch机制
Watch机制官方声明：一个Watch事件是一个一次性的触发器，当被设置了Watch的数据发生了改变的时候，则服务器将这个改变发送给设置了Watch的客户端，以便通知它们。
Zookeeper机制的特点：
1）一次性触发数据发生改变时，一个watcher event会被发送到client，但是client只会收到一次这样的信息。
2）watcher event异步发送watcher的通知事件从server发送到client是异步的，这就存在一个问题，不同的客户端和服务器之间通过socket进行通信，由于网络延迟或其他因素导致客户端在不通的时刻监听到事件，由于Zookeeper本身提供了ordering guarantee，即客户端监听事件后，才会感知它所监视znode发生了变化。所以我们使用Zookeeper不能期望能够监控到节点每次的变化。Zookeeper只能保证最终的一致性，而无法保证强一致性。
3）数据监视Zookeeper有数据监视和子数据监视getdata() and exists()设置数据监视，getchildren()设置了子节点监视。
4）注册watcher getData）exists）getChildren
5）触发watcher create）delete）setData
6）setData()会触发znode上设置的data watch（如果set成功的话）。一个成功的create() 操作会触发被创建的znode上的数据watch，以及其父节点上的child watch。而一个成功的delete()操作将会同时触发一个znode的data watch和child watch（因为这样就没有子节点了），同时也会触发其父节点的child watch。
7）当一个客户端连接到一个新的服务器上时，watch将会被以任意会话事件触发。当与一个服务器失去连接的时候，是无法接收到watch的。而当client重新连接时，如果需要的话，所有先前注册过的watch，都会被重新注册。通常这是完全透明的。只有在一个特殊情况下，watch可能会丢失：对于一个未创建的znode的exist watch，如果在客户端断开连接期间被创建了，并且随后在客户端连接上之前又删除了，这种情况下，这个watch事件可能会被丢失。
8）Watch是轻量级的，其实就是本地JVM的Callback，服务器端只是存了是否有设置了Watcher的布尔类型


---------------------------------------------------------------------------------------------------------------
------------------------------------------zk ms.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Activiti.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------


@网关
互斥、并行、包容

@setVariableLocall区别
setVariable:设置流程变量的时候，流程变量名称相同的时候，后一次的值替换前一次的值，而且可以看到TASK_ID的字段不会存放任务D的值
setVariableLocal:设置流程变量的时候，针对当前活动的节点设置流程变量，如果一个流程中存在2个活动节点，对每个活动节点都设置流程变量，
即使流程变量的名称相同，后一次的版本的值也不会替换
前一次版本的值，它会使用不同的任务D作为标识，存放2个流程变量值，
而且可以看到TASK_ID的字段会存放任务ID的值

@activiti里面的命令模式
一个命令执行器，持有一个能干活的handler,executeComand方法有一个参数commond实现类，行execute.即可降低耦合度。职责分离，解耦。臃肿的、万能的上帝类没有了。
满足“开-闭”原则的、职责单一。

@架构风格
一个团队的所有人写出的代码都有统一的风格，都像是一个人写出来的，很难！
通过“规范”去约束大家这样做，而规范毕竟是程序之外的东西，主观性很强，不遵守规范的情况屡屡发生。
画的东西，主观性很强，不遵守规范的情况屡屡发生。
而如果架构师给出了明确的开发模型，并使用一些基础组件加以强化，把程序员要走的路规定清楚，
就像Activiti做的这样，明确以Command作为基本开发模型，辅之以Event-Listener,这样编程风格的整体性得到了保证。


@源码
activiti里面的责任链模式
CommandContextInterceptor:命令拦截器，使用责任链模式，初始化链把各个拦截器装入。
CompleteTaskCmd为例，拦截器链为：

logger拦截器（打印日志的）->spring事务拦截器（本地事务)->CommandContext拦截器（设置上下文，这个是执行命令的参数啊)->CommandInvoker拦截器(get上下文，执行命令execute方法)

protected
CommandInterceptor
initInterceptorChain(List<CommandInterceptor>chain){
if (chain==null chain.isEmptyO){
throw new ActivitiException("invalid command
interceptor chain configuration:"+chain);
}
for (int i 0;i chain.size)-1;i++){
chain.get(i).setNext(chain.get(i+1));
}
return chain.get(0);
}
/链模式，next.execute
public <T>T execute(CommandConfig config,
Command<T>command){
CommandContext
context
Context.getCommandContextO;
/Push on stack
Context.setCommandContext(context);
Context.setProcessEngineConfiguration(processEngine
Configuration);
return next.execute(config,command);
}

TaskEntity实现了3个接口：Task,DelegateTask和
Persistentobject。其中PersistentObject是一个声明接口，表明TaskEntity需要持久化。
接口是一种角色的声明，是一份职责的描述而TaskEntity就是这个角色的具体扮演者，因此TaskEntity:必须承担如complete,delegate等职责。
说明一个道理：牢记面向抽象编程，把职责拆分为不同的接口，让接口来体现对象的职责，而不用去关心这份职责
具体由哪个对象实现。
监听器：注册监听器，触发监听器


@一个节点结束了，流程怎么知道往下走？
答案是TaskEntity.completeTask)方法会调
用execution.signal(->activityBehavior.signal(->activityBehavior.leave方法，
该方法最终会激
活AtomicOperationTransitionNotifyListenerStart的eventNotificationsCompleted(方法，该方法会创建当前
Transition的destination。


@多实例任务怎么知道该loop已结束？
多实例任务会启动多个任务和execution,调用
execution.signalO-->activityBehavior.signal)-->activityBehavior.leave),
ParallelMultilnstanceBehavior.leave(


@activiti里面的模板方法设计模式
abstract class NeedsActiveExecutionCmd
public
class
SignalCmd
extends
NeedsActiveExecutionCmd<Object>


@部署流程源码
repositoryService.createDeployment).addClasspathResource("diagrams/demo2.bpmn").deploy0;
DeployCmd的excute方法，
再回到DeployCmd接着往下走，实际部署。
/Actually deploy
commandContext
.getProcessEngineConfiguration(
.getDeploymentManager(
deploy(deployment,deploymentSettings);
解析bpmn,保存图片，把xml的内容封装成对象bpmnMode。


@如果自己设计一个如何做？
定义-实例一任务，流程变量，把节点，线条，任务抽象成对象，真正的面向对象，职责单一；
部署流程完毕之后，初始化一堆的节点对象，持有目标线条，目标条件，目标节点的引用；
启动流程了，找到操作当前节点的所有3目标，解释器设计模式，解析当前的条件找到实际的目标线条，目标条件，目标节点，记录到历史表；
以此类推，一直到流程结束了。哈哈，很简单的嘛！






---------------------------------------------------------------------------------------------------------------
------------------------------------------Activiti.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Commons4da.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------



1 Hbase
hadoop生态圈，建立在HDFS之上的分布式、面向NoSQL的数据库系统，存储PB级别；
mongodb面向文档存储；cassandra面向列的存储。
HBase依赖于HDFS做底层的数据存储，BigTable
Google GFS做数据存储
HBase依赖于MapReduce做数据计算，BigTabl
Google MapReduce做数据计算
HBase依赖于ZooKeeper做服务协调，BigTable
Google Chubby做服务协调


3一些语言
Python人工智能和爬虫，openstack云计算
R语言统计分析、绘图；
Ruby简单快捷的面向对象编程（面向对象程序设计创的脚本语言
Scala开发spark的语言，函数式编程


4 Spark
Spark Core、Spark SQL、Spark Streaming、MLl GraphX等组件，这些组件分别处理Spark Core提供
计算框架、SparkStreamingl的实时处理应用、Spark的即席查询、MLlib或MLbase的机器学习和GraphX处理，它们都是由AMP实验室提供，能够无缝的集提供一站式解决平台。

区别于hadoop:
hadoopi静态批量处理和实时数据流的数据处理基于文件系统，中间环节落地磁盘；基于内存，中节基于内存，速度秒杀；
弹性分布式数据集(RDD):Resillient Distrik Dataset,Spark的基本计算单元，可以通过一系列算
行操作（主要有Transformation和Action:操作）
已被分区，不可变的并能够被并行操作的数据集合，的数据集格式对应不同的RDD实现。
每次对RDD数据集的操作之后的结果，都可以存放到中，下一个操作可以直接从内存中输入，省
MapReduce:大量的磁盘O操作。
Spark on Standalone和Spark on YARN


5 Flume
Flume:是Cloudera:提供的一个高可用的，高可靠的，式的海量日志采集、聚合和传输的系统
Hadoop生态圈event从source,流向channel,再到sink,本身为一节数组，并可携带headers(头信息)信息。
flumel的核心就是一个agent,这个agenti对外有两个交互的地方，一个是接受数据的输入一source,一数据的输出sink,sink负责将数据发送到外部指定的地。

flume可以支持多级flume的agent,即flume可以前继，例如sink可以将数据写到下一个agent的source这样的话就可以连成串了。
flume其实就是一个日志采集agent,在每台应用服务装一个flume agent,然后事实采集日志到HDFS集群存储，
以便后续使用hive或者pig等大数据分析日志后可转存到mysql供运维查询或分析用户行为等。
基于Flume的美团日志收集系统。




6 Hadoop
离线大数据计算，电网，交通运输，电商


7 Hadoop1.0和2.0区别
将资源调度和任务调度分开。资源管理器ResourceManager全局管理所有应用程序计算资源的分配，
每一个job的ApplicationMaster:负责相应任务的调度和协调。

8  Shuffle阶段：意为将数据进行整理（核心机制：对数据进行分区，排序，缓存)

9 Hive是一个数据仓库基础工具在Hadoop中用来处理结构化数据。
它架构在Hadoop.之上，总归为大数据，并使得查询和分析方便。
并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。


10 将HiveQL转化为MapReduce任务，整个编译过程主要分为六个阶段：
Antlr定义SQL的语法规则，完成SQL词法，语法解将SQL转化为抽象语法树AST;
块QueryBlock;
遍历QueryBlock,将QueryBlock转化为逻辑查询计
划OperatorTree;
逻辑层优化器进行OperatorTree变换，合并不必要的
ReduceSinkOperator,减少shuffle数据量；
遍历OperatorTree,翻译为MapReduce任务；
物理层优化器进行MapReduce任务的变换，生成最终的
执行计划。



11 HIVE建表和hdfs关联
【需求】有时候我们不想导入数据到hive中，而是通过
在hive中创建关联表的方式查询hdfs上的数据，之后就能
通过hive客户端或者spark应用程序获取hive的数据了。
【原理】由于在hdfs中已存入了我们提前整理好的结构化
数据（例如每条记录都是以逗号分隔），那么在hive中建一
个相同结构的表，再把此表关联到相应的hdfs目录就可以
了。
将hdfs文件导入hive表


12 Pig是一个基于Hadoop的大规模数据分析平台，它提供
的SQL-LlKE语言叫Pig Latin


13 Pig与Hive的区别
对于开发人员，直接使用Java APls可能是乏味或容错的，同时也限制了Java程序员在Hadoop上编程的运用灵活性。
于是Hadoop:提供了两个解决方案，使得Hadoop:编程变得更加容易。
1是Pig是一种编程语言，它简化了Hadoop常见的工作任务。Pig可加载数据、表达转换数据以及存储最终结果。
Pig内置的操作使得半结构化数据变得有意义（如日志文件)。
同时Pig可扩展使用Java中添加的自定义数据类型并支持数据转换。

2是Hive在Hadoop中扮演数据仓库的角色。Hive添加数据的结构在HDFS,并允许使用类似于SQL语法进行数据查询。
与Pig一样，Hive的核心功能是可扩展的。
Pig和Hive总是令人困惑的。Hive更适合于数据仓库的任务，Hive主要用于静态的结构以及需要经常分析的工作。Hive与SQL相似促使其成为Hadoop与其他BI工具结合的理想交集。
Pig赋予开发人员在大数据集领域的灵活性，并允许开发简洁的脚本用于转换数据流以便嵌入到较大的应用程序。
Pig相比Hive相对轻量，它主要的优势是相比于直接使用Hadoop Java APls可大幅削减代码量。正因为如此，Pig仍然是吸引大量的软件开发人员。



14 个人理解
都是为了减少工作量，使得Hadoop的reduce编程变得更
加容易.说穿了一个是数据库管理员用，一个运维人员用；
一个是类似sql,一个是命令，group A,dump a,gro',dump b;








 NoSql中的数据是使用聚合模型来进行处理的。
 
 聚合模型主要分为：KV键值对，BSON，列族，图形等几种方式
 
 1 KV键值对
   临时性键值存储：Memcached，Redis
   永久性键值存储：ROMA，Redis 
应用场景：内容缓存，主要用于处理大量数据的高访问负载，也用于一些日志系统等等
数据模型：Key指向Value的键值对，通常用HashTable来实现
优点：查找速度快
缺点：数据无结构化，通常只被当做字符串或者是二进制数据


2 面向文档的数据库：MongoDB，CouchDB
Mongodb是一个基于分布式文件存储的数据库，由c++语言编写。 为web应用提供可扩展的高性能数据存储解决方案,是一个介于关系数据库和非关系数据库之间的产品，是非关系数据中功能最丰富，最像关系数据库的
应用场景：WEB应用（与key-value类似，value是结构化的，不同的是数据库能够了解到value的内容）
数据模型：Key-Value对应的键值对，Value是结构化的数据
优点：数据结构要求不严格，表结构可变，不需要像关系型数据库一样需要预先定义表结构
缺点：查询性能不高，而且缺乏统一的查询语法


3  面向列的数据库：Cassandra，HBase
应用场景：分布式的文件系统
数据模型：以列簇式存储，将一列数据存储在一起
优点：查找速度快，可扩展性强，更容易进行分布式扩展
缺点：功能相对局限


4 面向图形的数据库：Neo4J，InfoGrid
应用场景：社交网络，推荐系统等，专注于构建关系图谱
数据模型：图结构
优点：利用图结构相关算法。比如最短路径寻址，N度关系查找等等。
缺点：很多时候要对整个图做计算才能得出需要的信息，而且这种结构不太好做分布式的集群方案。




---------------------------------------------------------------------------------------------------------------
------------------------------------------Commons4da.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Commons4ee.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------


1 httpclient
http是要基于TCP连接基础上的，简单的说，TCP就纯建立连接，不涉及任何我们需要请求的实际数据，的传输。http是用来收发数据，即实际应用上来的。
TCP是底层通讯协议，定义的是数据传输和连接方式范；
HTTP是应用层协议，定义的是传输数据的内容的规
HTTP协议中的数据是利用TCP协议传输的，所持HTTP也就一定支持TCP

@HttpClien中使用了连接池，无状态
@HTTP协议的传输层协议是TCP协议，TCP连接的和释放分别需要进行3次握手和4次握手，频繁的建立
即增加了时间开销，同时频繁的创建和销毁Socket同
对服务器端资源的浪费。
对于诸如Web网站之类的B2C应用，并发请求量大，个用户又不需频繁的操作的场景下，维护大量的长连
服务器无疑是一个巨大的考验。而此时，短连接可能适用。
而对于需要频繁发送HTTP请求的应用，需要在客户用HTTP长连接。
HttpConnection没有连接池的概念，多少次请求就会




4 Struts
Struts1和spring mvc一样的额，依赖Servlet;
Struts:2是xwork框架，
原理：用Filter在web.xml配置，拦截请求，把acti在map,利用反射机制读取action;


5 Log
中介者模式：slf4j和common-loggingi两种日志体系
static Logger logger Logger.getLogge
ServerWithLog4j.class.getName ()
一般这种情况都是自身的api。为何？如果用slf4j的定是工厂类的啊！
换包的动作：如果一开始使用的是jdk log,中间用的不了，直接把依赖去除，添加log4j的依赖即可；
在应用中，通过LoggerFactory:类的静态getLogger()
logger。通过查看该类的代码可以看出，最终是StaticLoggerBinder.SINGLETON.getLoggerFactoryO
获取LoggerFactory然后，在通过该具体的LoggerFa
来获取logger的。类org.slf4j.impl.StaticLoggerBinc不在slf4j-api-1.6.1.jar包中，仔细查看每个与具体日
统对应的jar包，就会发现，相应的jar包都有org.slf4j.impl.StaticLoggerBinder的实现，不同的实
回与该日志系统对应的LoggerFactory,因此就实现谓的静态绑定，达到只要选取不同jar包就能简单灵活的目的。


6定时任务
保证一个集群执行一个定时任务
对于只需要执行一次初始化的操作，在全局缓存中设
个全局锁，拿到这个锁的节点执行相应的任务虑zookeeper.。
对于有些定时任务，我们只希望执行一次，也就是说
节点，只有一个节点在执行这个定时任务，可以在数对这个任务进行状态标记，
根据状态来调节节点间定时任务的执，如果宕机了，
考虑重新分配数据库锁



7 webservice
@SOAP与HTTP的区别
都是底层的通信协议，请求包的格式不同，soap是XML格式，http纯文本格式
soap的可以传递结构化的数据，http只能传输纯文据；
SOAP:简单对象访问协议
http是标准超文本协议
SOAP相对http(post/get)由于要进行xml解析，速能会有所降低。

@Soap协议是基于http的应用层协议，soap协议是xml数据。soap=http+xml
wsDL:是基于XML的用于描述webservice及其函数、
和返回值。通俗理解为wsdl是webservice的使用说明

@rest是一种设计风格
http接口按照rest风格设计就是restfull http
webservice接口按照rest风格设计就是re
webserivce.

@CXF,Axis,Xfire对比
Cxf和spring:无缝集成，java专用；
Axis多言语；



8监听器、拦截器、过滤器
过滤器和拦截器的区别
1、拦截器是基于java的反射机制的，而过滤器是基数回调；
2、过滤器依赖与servlet容器，而拦截器不依赖与se容器；
3、拦截器只能对action请求起作用，而过滤器则可几乎所有的请求起作用；
4、拦截器可以访问action上下文、值栈里的对象，滤器不能；
5、在action的生命周期中，拦截器可以多次被调用过滤器只能在容器初始化时被调用一次；

(1)过滤器(Filter):当你有一堆东西的时候，你
望选择符合你要求的某一些东西。定义这些要求的工就是过滤器。filter主要用途是全选复制
逻辑判断等。工作原理是，只安wcv.十百u截的客户端请求，它都会帮你拦截到请求，此时你就
对请求或响应统一设置编码，简化操化同下进行判断，如用户是否已经登陆、有没有权限访问该页面作。随web应用启动而启动，只初始化一次。

(2)拦截器(Interceptor):在一个流程正在进行候，你希望干预它的进展，甚至终止它进行，这是拦做的事情。
拦截器是在面向切面编程中应用的，就是的service或者一个方法前调用一个方法，或者在方调用一个方法。基于java的反射机制

(3)监听器(Listener):当一个事件发生的时候，望在这个时候做一些额外的事情，而并不想干预这个本身的进程，
这就要用到监听器。listener:主要作用做一些初始化的内容添加工作、设置一些基本的内容如一些参数或者一些固定的对象。



9 SSO
使用一个账户通过一次登录，即可在多个相关的系统来回访问。
搭建0Auth2认证授权服务，并不是给每个微服务调而是通过AP1网关进行统一调用来对网关后的微服务置过滤，所有的请求都必须先通过AP网关，AP网进行路由之前对该请求进行前置校验，实现对微
系统中的其他的服务接口的安全与权限校验。对于微安全认证授权机制一块，目前主流的解决方
OAuth2.0与OIDC(OpenlD Connect)等标准协议。

资源拥有者(resource owner):能授权访问受保护的一个实体，可以是一个人，那我们称之为最终用户
资源服务器(resource server):存储受保护资源，端通过access token请求资源，资源服务器响应受保源给客户端；
授权服务器(authorization server):成功验证者并获取授权之后，授权服务器颁发授权令牌个Token)给客户端。




10 Hibernate
@ORM框架，面向对象的思想，
SessionFactory和mybatis的SqlSessionFactory
Session接口和mybatis的SqlSession


@程序和数据库同时设置隔离级别？
Spring:会在事务开始时，根据你程序中设置的隔离级调整数据库隔离级别与你的设置一致。
当使用Serializable级别时，Mysql在执行SQL时会自改为select..lock in share mode,即使用共享锁。此
许同时读，但只允许一个事务写，且锁的是行而不是表。
如果数据库不支持某种隔离级别，那么Spring设置了效。
当使用Serializable:级别时，如果两个事务读写的不是行，那么它们是互不影响的。如果操作同一行记录，
允许同时读，但如果出现一个对此行的写操作，则在务没有提交之前，所有的读事务都会被block。

@缓存和mybatis:差不多
一级缓存就是Session级别的缓存，一个Session做了
查询操作，它会把这个操作的结果放在一级缓存中，
短时间内这个session(一定要同一个session)又做
一个操作，那么hibernate直接从一级缓存中拿，而再去连数据库，取数据。
二级缓存就是SessionFactory:级别的缓存，顾名思义是查询的时候会把查询结果缓存到二级缓存中，如果个sessionFactory创建的某2个session执行了相同作，hibernate就会从二级缓存中拿结果，而不会再接数据库。
Hibernate的二级缓存策略，是针对于D查询的缓
略，对于条件查询则毫无作用。为此，Hibernate提
针对条件查询的Query Cache




@@外网
1 路由器设置，虚拟服务器，不过访问只能是外网ip
2 动态域名解析，花生壳或者nat123
3 云服务，阿里云，腾讯云



@@网段端口
当linux打开防火墙之后，从本机登录23端口没有问题，从另一台pc登录linux，提示错误：不能打开主机连接，端口23连接失败

因为linux防火墙是默认关闭23端口的，如果允许登录，可以关掉防火墙，或者开放23端口。

yum install iptables-service
systemctl start/stop/enable/disable/status firewalld

为了使iptables代替 firewalld, 需要禁用firewalld
systemctl disable firewalld
systemctl stop firewalld


systemctl start/stop/enable/disable/status iptables

firewalld调用了iptables的command, 执行内核的netfilter, 所以说firewalld是CentOS7下管理的iptables的新命令。


每个zone就是一套规则集

firewalld-cmd --get-default-zone
firewalld-cmd --get-active-zone






#（1） Postgresql端口设置。允许192.168.142.166访问5432端口
firewall-cmd --permanent --add-rich-rule="rule family="ipv4" source address="192.168.142.166" port protocol="tcp" port="5432" accept"
#（2）redis端口设置。允许192.168.142.166访问6379端口
firewall-cmd --permanent --add-rich-rule="rule family="ipv4" source address="192.168.142.166" port protocol="tcp" port="6379" accept"
#（3）beanstalkd端口设置。允许192.168.142.166访问11300端口
firewall-cmd --permanent --add-rich-rule="rule family="ipv4" source address="192.168.142.166" port protocol="tcp" port="11300" accept"

systemctl restart firewalld.service


删除规则：
firewall-cmd --permanent --remove-rich-rule="rule family="ipv4" source address="192.168.142.166" port protocol="tcp" port="11300" accept"

systemctl restart firewalld.service



@@idea
1 项目
首先建一个idea workspace,file>open, 选择idea workspace,可以连续打开多个窗口
file>new>project  from version control, 选择gitlab，选择存储在创建的工作区间下，也可以先clone到工作区间，再reload from disk.
可以删除项目之后重新clone.
file>new>module>maven module,项目A， parent是none表示顶级项目，修改pom.xml 打包方式为 pom/war/jar， 然后新建一个module B，parent选择A.
file>setting>maven，设置setting.xml和本地仓库
maven执行有2中方式：
1：右键>run maven>....
2: 右窗口>Maven>Lifecycle...
刚从gitlab导入的项目，先对着pom.xml 右键>add as maven project,然后才有maven菜单。


配置tomcat: run>edit>edit configuration
配置jdk:file>project structure>sdks
提交新项目到git:VCS>Import into Version Control>Create Git Repository


@调试
F8：下一步
F9：下一段点
Alt+F8:执行表达式

@快捷键
Ctrl+F12:查看方法属性
Ctrl+G:跳转到行/列
Ctrl + Alt+O:导入包
shift+shift:查找文件
安装Maven Helper可以查看依赖树

help>register :导入licence
help>edit custom vm options:修改vm参数


https://www.jetbrains.com/idea/download/other.html
Community：社区版，免费，但是功能有限制，Android Studio就是基于这个版本定制的。
Ultimate：终极版，收费，功能无限制。
EAP：终极版的免费版，免费，功能无限制，但是每隔30天要重装一次。



---------------------------------------------------------------------------------------------------------------
------------------------------------------Commons4ee.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Commons4sa.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------


1架构图
@技术架构图
一个公司或者一个项目的技术架构图，比如SD,
层，应用层，服务层，每个层平铺一些技术。一般是
平铺的图。

@业务流程图
业务框图，类似activiti,从业务角度出发。
@部署图
指物理部署图，各个静态工程部署图的调用关系。

@类图
Employee
name:String
-age:int
readInfoO:void
实现（虚线三角）类实现接口
继承（实线三角）接口继承接口，类继承类
依赖（虚线箭头）Person类依赖于Car类和House类义，因为Person类引用了Car和House(方法传参)。联不同的是，Person类里并没有Car和House类型性。
关联（实现箭头）关系是类与类之间的联接，它知道另一个类的属性和方法。关联可以是双向的，也知道另一个类的属性和方法。关联可以是双向的，也是单向的。
聚合（实现菱形空心）强的关联关系。聚合是整体体之间的关系。例如，汽车类与引擎类、轮胎类，一表整体，另一个代表部分。
组合（实现菱形实心）聚合关系强的关系。它要求的聚合关系中代表整体的对象负责代表部分对象的生期，脱离了整体部分不能独活。

@ER图
表结构之间的一对一，一对多，多对多

@调用链图
比如spring源码各种类之间的调用关系（方向自顶向

@数据流图
一般很少画

@时序图
参与者和组件的顺序图，同步和异步线，激活

@组件图
从技术角度描述业务流程图，展现各个组件之间的调
系。



2前后端分离
Web服务器：一般指像Nginx,Apache这类的服务器们一般只能解析静态资源；应用服务器：一般指像Tomcat,Jetty,Resin这类的
器可以解析动态资源也可以解析静态资源，但解析静源的能力没有web服务器好；
只有web服务器才能被外网访问，应用服务器只能内问；
nodejs:本地调的；nginx是在sit环境；
vue是前端样式，webpack是打包工具，管理依赖；


3 nas
它是一种专用数据存储服务器。它以数据为中心，将设备与服务器彻底分离，集中管理数据，从而释放带
提高性能、降低总拥有成本、保护投资。
其成本远远低于使用服务器存储，而效率却远远高者。目前国内比较好的NAS产品是OUO的iboxNAS10下载，使用稳定，而且OUO是三星电子合作伙伴，品能得到保证。
NAS本身能够支持多种协议(
NFS、CIFS、FTP、HTTP等)，而且能够支持各种系统。通过任何一台工作站，采用IE或Netscape浏览可以对NAS设备进行直观方便的管理

NAS,网络附加存储，中心词“存储”，是的，它是存储设备。
比如我装个openfileri或freenas.系统，再块硬盘，对外提供NAS功能，那么这个ope或freenas服务器就变成了很简单的“NAS设备”然，如果是对于小公司来说，一个openfiler做NAS设够了。
而ClFS,是微软提出的，全称叫通用internet文件共它是一种协议。
NFS,网络文件共享，也是一种协议两者之间有什么区别呢？
一句话，CIFS用于UN
windows间共享，而NFS用于UNIX和UNIX之间共享。
所以，NAS是一个设备，一个功能。而CIFS/NFS是协议。可以在NAS上启用CIFS/NFS协议，这样，用能使用CIFS/NFS协议进行访问了。



4 cdn
在网站和用户之间引入CDN之后，用户不会有任何与不同的感觉。使用CDN服务的网站，只需将其域名的
权交给CDN的负载均衡设备，CDN负载均衡设备将为选择一台合适的缓存服务器，用户通过访问这台缓存
器来获取自己所需的数据。由于缓存服务器部署在网营商的机房，而这些运营商又是用户的网络服务提供
因此用户可以以最短的路径，最快的速度对网站进问。因此，CDN可以加速用户访问速度，减少源个载压力。

那末假如百度要在全国各地都布置效劳器，假如说每效劳器上都有雷同的动态资本，那末可以还须要设置的数据库，由于动态资本所纪录的信息一般会存储在库中，那末这就触及到了数据同步等等题目，这会致钱很高。所以CDN解决的主要是静态资本

如今实在有许多CDN供应商，比方阿里，腾讯等等都身的CDN效劳。只需你本身的体系接入了这些大厂所
的CDN效劳，你把本身的静态资本传给CDN效劳，那些静态资本将自动的散布到环球各地去。
一般的DNS体系是做不到的，须要一个特别的DNS器，这个特别DNS须要晓得

@用户当前所在位置

@还须要晓得用户如今接见的这个域名对应哪些P地以及这个P地点离别在哪？
CDN供应商一定晓得他们公司在哪些地方布置了机械它们的IP地点，所以这个题目只能有CDN供应商来处
CDN供应商会供应这个特别的DNS效劳器，我们CDN专用DNS效劳器。
为什么我需要自己搭建CDN服务器来实现网站加速呢
1).要用国内的CDN服务器域名都需要备案。
2).免费的CDN服务器的稳定性和加速效果都不是很：
3).付费的CDN服务器一般都贵的要死，一些草根站
本用不起。
LuManager CDN缓存加速创建



5运维
@软链接，以路径的形式存在。类似于Windows操作中的快捷方式
n-s源文件目标文件：它只会在你选定的位置上生
个文件的镜像，不会占用磁盘空间；硬链接n源文件目标文件，没有参数-s,它会在你的位置上生成一个和源文件大小相同的文件

@UCloud
是基础云计算服务提供商，长期专注于移动网领域
Uhost(云主机)是基于虚拟化技术的主机服务，即组集群物理机上虚拟出多个类似独立主机的部分。该整合了高性能服务器和优质网络带宽，高可靠、易管安全稳定；
ULB(UCloud Load Balancer)是负载均衡服务，即台云主机间实现应用程序流量的自动分配。可实现故动切换，提高业务可用性，并提高资源利用率。
UDisk(UCloud Disk)是为云主机提供持久化存储空块设备硬盘。云硬盘有独立的生命周期，基于网络分访问，为云主机提供的数据高可靠、可扩展的硬盘。
UDB(UCloud DataBase)是架构在云端集群上数据务，通过云服务的方式让关系型数据库的可靠性更高去繁琐的维护工作，节约硬件成本


@NFSH和MFS
NFS存在单点问题，没有容错机制。
MFS是一个具有容错性的网络分布式文件系统。


@公网ip是pc上网必需的，就是一个全球唯一的标识
内网ip即私网ip,只能企业内部使用




6集群负载均衡
@硬负载均衡和软负载均衡
硬件服务器：就是直接购买独立的服务器作为负载均
务器，硬件负载均衡效率高，但是价格贵，例如，阿已经提供。F5
软件服务器：使用具有代理功能的软件作为服务
比如Nginx,HAProxy,LVS等等，软件负载均衡系格较低或者免费，效率较硬件负载均衡系统低
@算法随机、轮询、最少连接数、加权、hash
@集群和分布式：一个是垂直一个是水平



7 keepalived
1).从主被动的角度考虑
nginx serveri通常和keepalived进行结合，那么keepa
是怎么知道nginx是否存活呢？是nginx主动向keep~liv
报信息？不是的。
keepalived是主动向nginx发送请求，如果有响应，
则nginx可用。对于zookeeper言，HDFS,HBase,Yarn基于zookeeper做高可用，这里的zookeeper就是被动的，也就是HDFS,HBase,Yarn主动向zookeeper中写数据。

2).从负载的角度来考虑
keepalived可以帮助我们做到主从，主从的划分是通置文件（主从的priority.之差>50）指定的，
如果主没掉，那么大量的请求通过主然后负载到后端的nginx从如果想要起作用只有等到主挂掉。
而利用zooK∈做HA,zookeeper中可以说是“人人平等”，客户端访问follower,还是observer,异或是leader,都能
们返回相应的结果，可以很好的实现了负载均衡，这以说是zookeeper的一个优点。

3).从存储数据的角度
keepalived不可以存储数据，假设keepalived的主有50个连接，如果没有外部数据库存储这些连接的信主挂了的话，连接信息也就丢了，所以使用keepaliv
要一个外部的数据库，但是如果主挂了的同时数据库了，那么就over了，信息就会丢失，或者从起来后，
上数据库，那么之前的连接信息也会丢失。
zookeeper可以存储数据，zookeeper中可以创个zNode,里面存放数据，zookeeperi可以做到一个式数据的一致性，zookeeper中每个节点的视图是的，
数据本身可以做到最终一致性，也就是个server:挂了，其他的sereri还有存的数据，那么这话就不需要额外的数据库，zookeeper:本身就可以存定量的信息。这也可以说是zookeeper的另一个优点。

4).从业务的角度
keepalived可以说比较简单，只需要简单的配置一下以了，使用keepalived的场景：如果我们只需要简单
道当前的业务中哪个是主，哪个是从，那么可用keepalived。
如果除了高可用以外，比如kafka,storm等还zookeeper中写一些数据，这时候就需要zookeeper.。VRRP是遑过竞选机制来确定主备的，主的优先级备，因此，工作时主会优先获得所有的资源，备节点等待状态，当主挂了的时候，备节点就会接管主节点源，然后顶替主节点对外提供服务。




9 Apollo
和spring cloud config差不多，分布式配置中心配置修改实时生效（热发布）、同一份代码部署在不集群，可以有不同的配置，比如zk的地址等提供Java和.Net原生客户端

@apollo源码
标记@EnableApolloConfig来告诉程序开启apollo配
所以这里就以EnableApolloConfig为入口，来看客户端的实现逻辑。
通过@EnableApolloConfig注解，引入ApolloConfigRegistrar
PropertySourcesProcessor.addNamespaces(Lists.n
rrayList(namespaces),order);

后置处理器->获取environment->装入远程属性
environment.getPropertySources).addAfter(
source name",composite);
environment.getPropertySources).addFirst(compo
根本原理就是利用springl的bean后置处理器把配置信入env中；




10 Devops
持续集成(CI)、持续部署(CD)为基础，来优化
开发、测试、系统运维等所有环节
代码管(SCM):GitHub、GitLab、BitBucket、SubVersio
构建工具：Ant、Gradle、maven
自动部署：Capistrano、CodeDeploy
持续集成(Cl):Bamboo、Hudson、Jenkins
配置理：Ansible、Chef、Puppet、SaltStack、ScriptGuardRail
容器：Docker、LXC、第三方厂商如AWS
编排：Kubernetes、Core、Apache Mesos、DC/OS
服务注册与发现：Zookeeper.、etcd、Consul
脚本语言：python、ruby、shell
日志管理：ELK、Logentries
系统监控：Datadog、Graphite、Icinga、Nagios
性能监控：AppDynamics、New Relic、Splunk
压力测试：JMeter、Blaze Meter.、loader.io
HTTP加速器：Varnish
消息总线：ActiveMQ、SQS
应用服务器：Tomcat、JBOSS
Web服务器：Apache、Nginx、lIS
数据库：MySQL、Oracle、PostgreSQL等关系型
库；cassandra、mongoDB、redis等NoSQL数据库
项目管(PM):Jira、Asana、Taiga、Trello、Basecamp.




11 Etcd
go语言开发的，轻量级zk;一致性协议：ETCD使用[Raft]协议，Z用ZAB(类PAXOS协议)，前者容易理解，方便工现；
API:ETCD提供HTTP+JSON,gRPC接口，跨平台言，ZK需要使用其客户端；
访问安全方面：ETCD支持HTTPS访问，ZK在这方失；
和ZK类似，ETCD有很多使用场景，包括：配置管理，服务注册于发现，应用调度，分布式队列，




12 ServiceComb
@ServiceComb三大件
Java chassis底座，开箱即用Java微服务SDK,编型、运行模型与通信模型，负载均衡、容错熔断、限级、调用链追踪微服务治理能力；

Service Center-一服务注册中心，Etcd的高性能、用、无状态

Saga一分布式事务解决方案，用户只需要通过注解定义事务的执行方法以及撤销方法，Saga框架会自证分布式事务执行的最终一致性。
华为消费者云使用ServiceComb实现1500+集群节点的微服务以支持4亿手机用户在线，QPS提升2倍+，降低45%，从而节省大量硬件资源。




13 SOA/SOAP/REST/HTTP
都是SOA实现的一种技术，但是设计的理念有所不同restful基于HTPP的理念，而SOAP则基于RPC的理念
HTTP理念：访问的资源，访问的方式，传输的数在http的URI中体现
SOAP理念：基于HTTP,但是访问的资源，访问的方传输的数据都在报文中体现，想知道要解析xml
restful可以知道任何东西，而soap想知道必须解析x报文。

Web服务：服务器如何向客户端提供服务，三类：
SOA面向服务的架构【面向消息】
RPC远程过程调用的架构(remote procedure call)向方法】。
RMl只支持java
REST表征状态转移的架构(Representationaltransfer)【面向资源】
RPC一般直接用底层的TCP,这样更加快速，这是
REST只能用HTTP的优势，但它也可用HTTP;

TCP和UDP
tcp和udp都是传输协议，主要区别是tcp协议连接需握手，断开需要四次握手，是通过流来传输的，就是连接后，一直发送信息，传完后断开；
udp不需要进行连接，直接把信息封装成多个报文，发送。所以udp的速度更快写
http协议是建立在TCP协议之上的一种应用，是Web的基础，最显著的特点是客户端发送的每次请求都需务器回送响应，在请求结束后，会主动释放连接。从连接到关闭连接的过程称为“一次连接”；
RPC(Remote Procedure Call)一RPC协议假定某些协议的存在，如TCP或UDP,为通信程序之间携带信据。
Netty:基于tcp协议，实现RPC;




1五视图法的架构设计
逻辑架构~子系统，功能模块，功能，交互，界面
开发架构~分层架构，开发技术，开发规范，软件质
数据架构~分布式存储，ER图，关系数据库，NOS据库
运行架构~控制流、通讯机制、资源争用、锁机制步异步、并发串行、响应时间、吞吐量、容量设计
物理架构~网络拓扑、安全机制、可靠性、可伸缩分布式部署


2 各种协议
(7)应用层例HTTP、SMTP、SNMP、FTP、Telnet、SIP、SSH、、RTSP、XMPP、Whois、ENRP
(6)表示层例如XDR、ASN.1、SMB、AFP、NCP
(5)会话层例如ASAP、TLS、SSH、ISO8327/CX.225、RPC、NetBIOS、ASP、Winsock、BSD sock
(4)传输层例TCP、UDP、RTP、SCTP、SPX、ATP、IL
(3)网络层例IP、ICMP、IGMP、IPX、BGP、OSPF、RIP、I(个RP、ARP、RARP、X.25
(2)数据链路层例如以太网、令牌环、HDLC、继、ISDN、ATM、IEEE802.11、FDDI、PPP
(1)物理层例如线路、无线电、光纤、信鸽
协议就是电脑跟电脑之间说话，对话，传输文件或者
之间所使用的同一种语言
比如说，没有协议的话，电脑跟电脑之间，怎么通信说10101010101010101，对方怎么能明白？所以需个协议来规范，规范各种代码表示的意义。
比如说双方使用FTP协议，就可以传文件了。


3 六大设计原则
(1)单一职责，不同的类具备不同的职责，各施其避免上帝类的出现。
(2)开闭原则，对扩展开放，对修改关闭。
(3)接口隔离，用多个专门的接口，而不使用庞大总接口，客户端不应该依赖他不需要的接口
(4)依赖倒转，依赖抽象而不是实现类，面向接口
(5)最少知道，降低耦合度，类与类耦合（依赖联、组合、聚合)度越大，当一个类发生改变时，对个类的影响也越大。
成员变量、方法参数、方法返回值中的类为直接友，而出现在局部变量中的类则不是直接的朋友。也说，陌生的类最好不要作为局部变量的形式出现个
(6)里氏替换，在继承类时，务必重写(Override类中所有的方法，尤其需要注意父类的protected(它们往往是让您重写的)，子类尽量不要暴露自public方法供外界调用
(7)高内聚低耦合，高内聚是封装的概念，同一类封装到一起，低耦合是OC的体现，依赖注入。高内聚：有a,b,c,d,e,5个方法，a,b,c,d,e分别可以一个功能，a和b一起工作又可以实现另一功能。


4架构模式
分层，应用层，服务层，数据层，MVC差不多
分割，业务垂直分割，比如购物、论坛、搜索、广告
家、卖家分割成不同的应用，交给不同的部门独立开
分布式，微服务，动静分离，反向代理，CDN


5核心五要素
性能、可用性、扩展性、伸缩性、安全性





~~~~~~springcloud的服务治理~~~~~~~~~~
（1）服务注册与发现
Eureka

（2）网关和路由
Zuul 和 gateway 
Spring Cloud Gateway 是 Spring Cloud 微服务平台的一个子项目，属于 Spring 开源社区，依赖名叫：spring-cloud-starter-gateway。
Spring webflux 有一个全新的非堵塞的函数式 Reactive Web 框架，可以用来构建异步的、非堵塞的、事件驱动的服务，在伸缩性方面表现非常好。
使用非阻塞API。 Websockets得到支持，并且由于它与Spring紧密集成，所以将会是一个更好的 开发 体验。

Zuul 是 Netflix 公司的开源项目，Spring Cloud 在 Netflix 项目中也已经集成了 Zuul，依赖名叫：spring-cloud-starter-netflix-zuul。
Zuul 1.x，是一个基于阻塞io的API Gateway。Zuul已经发布了Zuul 2.x，基于Netty，也是非阻塞的，支持长连接，但Spring Cloud暂时还没有整合计划。


（3）限流/降级/熔断/服务隔离
Hystrix


（4）限制并发
信号量


（5）分布式ID
雪花推特
UUID

（6）监控
Hystrix Dashboard 组件监控单个应用的调用情况；
Turbine可以将多个服务聚合成一个 turbine.stream  ,以便于在 Hystrix Dashboard上面查看

（7）链路追踪
Sleuth+zipkin


（8）负载均衡
客户端负载均衡：Ribbion
服务端负载均衡：LVS, Nginx,F5


（9）RPC调用
Feign
RestTemplate






~~~~~~dubbo的服务治理~~~~~~~~~~
（1）服务注册与发现
zk,redis....



（2）网关和路由
Flurry/Kong/gateway/zuul
Flury基于dubbo的高性能 异步 流式网关
在服务治理控制台dubbo-admin写入路由规则，分成应用粒度和服务粒度
conditions：
  -method=sayHello => address=*:20880
  -method=sayHello2 => address=*:20881
  
  

（3）限流/降级/熔断/服务隔离
降级：mock
dubo本身没有熔断器，自己实现或者引入hystrix
Dubbo中限流通过 TpsLimiterFiletr实现 


（4）限制并发
信号量


（5）分布式ID
雪花推特
UUID

（6）监控
Dubbo admin和Dubbo monitor


（7）链路追踪
brave-dubbo+zipkin
brave-dubbo简化了dubbo项目接入zipkin的步骤


（8）负载均衡
loadbalance包含包含服务端，服务端方法，客户端，客户端方法


（9）RPC调用
接口本地透明化（底层netty）






~~~~~~路由和负载均衡~~~~~~~~~~
服务消费者通过服务名称，在众多服务中找到要调用的服务的地址到列表，称为服务的路由。
Consume -- service1 -- service1 server list 

在请求到来时，为了将请求均衡地分配到后端服务器，负载均衡程序将从服务对应的地址列表中，通过相应的负载均衡算法和规则，
选取一台服务器进行访问，这个过程称为服务的负载均衡
service1 server list  ----随机/轮训/权重---- a service1 server 

当服务规模较小时，nginx/f5可以配置多个upstream和server进行反向代理和负载均衡，但是需要写死服务器的ip地址，运维不方便；

需要做一些认证健全的时候每个微服务都要写一遍 代码不利于维护，所以网关横空出世，请请求进行统一的拦截；

nginx也是一个网关，可以限流，缓存，黑白名单等 ，nginx的限流基于漏桶算法，高并发场景非常实用；
但是C语言，实现复杂的安全控制，统一异常处理，XXS， sql注入等；鉴权、认证、权限控制、黑白名单、性能监控、日志打印不利于java的扩展；

所以zuul出来了，解决了不用写死ip地址，因为有服务注册中心，只要写appName可以实现路由功能；

由于nginx扩展需要openrestry,所以kong横空出世，kong在界面支持path和uri的绑定，而且基于lua和openrestry进行更多的网关功能的扩展（比如redis）

nginx 只能启到了后面网关的负载均衡作用，路由和负载均衡的都放在后面了。
 
 
 
 
 
 ~~~~~~负载均衡、集群容错、服务路由~~~~~~~~~~
 有一个Dubbo的用户服务，在北京部署了10个，在上海部署了20个。一个杭州的服务消费方发起了一次调用，然后发生了以下的事情:

根据配置的路由规则，如果杭州发起的调用，会路由到比较近的上海的20个 Provider。
根据配置的随机负载均衡策略，在20个 Provider 中随机选择了一个来调用，假设随机到了第7个 Provider。
结果调用第7个 Provider 失败了。
根据配置的Failover集群容错模式，重试其他服务器。
重试了第13个 Provider，调用成功。

上面的第1，2，4步骤就分别对应了路由，负载均衡和集群容错。


 Dubbo中，先通过路由，从多个 Provider 中按照路由规则，选出一个子集。再根据负载均衡从子集中选出一个 Provider 进行本次调用。
 如果调用失败了，根据集群容错策略，进行重试或定时重发或快速失败等。 
 
 
 
 
 
 总结：
 注册发现：Eureka, Dubbo, Consul, ZooKeeper
 服务配置：Spring Cloud Config, Apollo 
 服务熔断：Hystrix, resilience4j
 服务网关：Zuul, Springcloudconfig, Kong
 负载均衡：Ribbon,Feign
 追踪工具：Sleuth, Zipkin, Htrace
 监控平台：Promethues, Kibana 
 
 
 
 
 
 




10亿次+消息、40亿次+总请求|以58帮帮为例看58同城典型技术架构演变
---------------------------------------------------------
58帮帮在技术架构上持续的演变。58帮帮由即时通讯
(M)部分和非M的业务处理部分构成；
目前，整个帮帮系统每天要处理10亿次+的发消息、加好
友等传统M请求，以及30亿+的非M业务请求操作，总请
求到达40亿次+。
阶段一：传统的M架构我们如何设计？如何满足千万在线的性能需求？
阶段二：从传统M到商家管理平台，58帮帮的架构如何演变？
阶段三：从商家管理平台到移动营销工具，58帮帮的架构又如何演变？
阶段四：如何打造满足58帮帮的移动推送系统
移动推送主要的三种实现方式：
1.客户端轮询(pull)
客户端定期发起查询请求，来达到推送的目的。pull的优点和缺点都很明显，架构简单但实时性差，想提高实时性，只能加快查询频率，但这会造成电量、流量消耗过高。
2.短信推送
通过短信发送推送消息，并在客户端置入短信拦截模块，将接收到的短信拦截，并解析后给应用处理。这个方案实时性好、到达率高，但成本很高。
3.服务端长连接(push)
这是目前的主流实现方式，实时性好，且电量消耗低，技术架构复杂度较高。






------------------------------------
10种常见的软件架构模式
架构模式是一个通用的、可重用的解决方案，用于在给定上下文中的软件体系结构中经常出现的问题。架构模式与
软件设计模式类似，但具有更广泛的范围。

@分层模式比如DDD,一个较低的层可以被不同的层所使用。层使标准化更容易，因为我们可以清楚地定义级别。可以在层内进行更改，而不会影响其他层。不是
普遍适用的。在某些情况下，某些层可能会被跳过。

@客户端-服务器模式比如电子邮件，很好地建立一组服务，用户可以请求他们的服务。请求通常在服务器
上的单独线程中处理。由于不同的客户端具有不同的表示，进程间通信会导致额外开销。

@主从设备模式比如MYSQL主从，准确性—一将服务
的执行委托给不同的从设备，具有不同的实现。从设备是孤立的：没有共享的状态。主-从通信中的延迟可能是
一个问题，例如在实时系统中。这种模式只能应用于可以分解的问题。

@管道-过滤器模式比如编译器。连续的过滤器执行词法
分析、解析、语义分析和代码生成，展示并发处理。
当输入和输出由流组成时，过滤器在接收数据时开始计算。轻松添加过滤器，系统可以轻松扩展。过滤器可重复
使用。可以通过重新组合一组给定的过滤器来构建不同的管道。效率受到最慢的过滤过程的限制。从一个
过滤器移动到另一个过滤器时的数据转换开销。

@代理模式比如MQ,允许动态更改、添加、和重新定位对象，这使开发人员的发布变得透明。
要求对服务描述进行标准化。

@点对点模式比如文件共享网络，支持分散式计算。对任何给定节点的故障处理具有强大的健壮性。
在资源和计算能力方面具有很高的可扩展性。服务质量没有保证，因为节点是自愿合作的。安全是很难得到保证的。
性能取决于节点的数量。

@事件总线模式比如通知服务，新的发布者、订阅者和连接可以很容易地添加。对高度分布式的应用程序有
效。可伸缩性可能是一个问题，因为所有消息都是通过同一事件总线进行的。

@模型-视图-控制器模式比如MVC,可以轻松地拥有同一个模型的多个视图，这些视图可以在运行时连接和断
开。增加复杂性。可能导致许多不必要的用户操作更新。

@黑板模式比如语音识别，很容易添加新的应用程序。
扩展数据空间的结构很简单。修改数据空间的结构非常困难，因为所有应用程序都受到了影响。可能需要同步和访问控制。

@解释器模式比如SQL,高度动态的行为是可行的。对终
端用户编程性提供好处。提高灵活性，因为替换一个解释程序很容易。由于解释语言通常比编译后的语言慢，
因此性能可能是一个问题。






~~~~~~~~~~~~~~~~~~~~3~~~~~~~~~~~~~~
1分钟实现“延迟消息”功能
延时队列
@定期轮询（数据库等）不是很精准有延时，数据量过
大时会消耗太多的资源，效率太低

@DelayQueue本地的，不是分布式的

@Timer定时器工具，不是分布式的

@ScheduledExecutorService线程池

@时间轮(kafka),环状时间轮
假设编号为的时间格或者桶保存着到期时间为t,每一个tick的持续时间(tickDuration)为2Oms,在这个格子
里只能保存着到期时间为[t~t+20]ms的任务，
假设时间轮的时间格有n个，每一个间隔1ms,到期时间为m(ms),那么计算公式m%n=所在的时间格或者桶，比
如n=10,m=34ms,那么他所在桶或者时间格是4

@RabbitMQ
RabbitMQ本身没有直接支持延迟队列功能，但是可以通过以下特性模拟出延迟队列的功能。
RabbitMQ可以针对Queue和Message设置x-message-比，来控制消息的生存时间
@SchedulerX(阿里)阿里产品
@有赞延迟队列






~~~~~~~~~~~~~~~~~4~~~~~~~~~~~~~~
1号店11.11：分布式搜索
引擎的架构实践
11.11挑战~
可扩展

如何抗住这样的流量，针对这个需求，1号店搜索团队构建了分布式搜索引擎，支持横向扩展；并且针对业务特点做了Routing优化，让搜索的效率更高。
快速响应流量越大，单位时间内的流量价值就越大，出现问题的损
失也就越大，如何做到快速响应变得非常关键。针对这个需求，搜索系统支持自动部署和快速扩容以应对突发流量，索引数据从导入、
处理到上线服务会经过层层验证，同时还有监控体系及时发现线上的问题。
选择自己构建分布式方案，而不是采用开源的SolrCloud或ElasticSearch,主要是基于以下几点考虑：

(1)ElasticSearch/SolrCloud都适合于把搜索引擎作为
一个黑盒系统来使用，而号店搜索业务的展现形式多样性很高，搜索条件有的会很复杂，有的需要通过自定义插件来实现，性能调优时也需要对引擎内部的执行细节进行监控。

(2)将ElasticSearch/SolrCloud与公司内部的发布系统、监控系统和SOA体系结合起来，也是一项比较耗时的工作。

(3)相对于整体使用，我们更倾向于把Lucene/Solr开源家族中的各个组件按需引引入，一方面降低引引入复杂工程的可维护性风险，另一方面逐渐深入理解这些组件，可以在必要时替换为定制化的组件。
分布式搜索中有两个主要组件：Shard Searcheri和Broker
其中Shard Searcher与单机搜索引引擎类似，基于
Lucene/Solr完成基本的搜索任务。Broker负责把针对整个索引的搜索请求转化为针对单个Shard的搜索请求，它把Shard搜索请求分发给各个ShardSearcher,并且把各个Shard的结果进行合并，生成最终的结果。高效Routing、自动部署、快速扩容








~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~5~~~~~~~~~~~~~~
40条显著提升Java性能的
优化细节

@合适的场合使用单例，慎用
@避免随意使用静态变量，当某个对象被定义为static变量所引引用，那么GC通常是不会回收这个对象所占有的内存

@避免过多过常地创建Java对象尽量避免在经常调用的方法，循环中new对象，由于系统不仅要花费时间来创建对象，而且还要花时间对这些对象
进行垃圾回收和处理，在我们可以控制的范围内，最大限度地重用对象，最好能用基本的数据类型或数组来替代对象。

@使用final修饰符
带有final修饰符的类是不可派生的。java编译器会寻找机会内联(inline)所有的final方法，此举能够使性能平均提高50%。简单的getter/setter方法应该被置成final;

@使用局部变量
调用方法时传递的参数以及在调用中创建的临时变量都保存在栈(Stack)中，速度较快；其他变量，如静态变量、实例变量等，都在堆(Heap)中创建，速度较慢。
@处理好包装类型和基本类型两者的使用场所
虽然可相互转换，但内存区域是完全不同的，基本类型数据产生和处理都在栈中处理，包装类型是对象，是在堆中产生实例。
在集合类对象，有对象方面需要的处理适用包装类型，其的处理提倡使用基本类型。

@慎用synchronized,尽量减小synchronize的方法，可能造成死锁synchronize方法被调用时，直接会把当前对象锁了，在
方法执行完之前其他线程无法调用当前对象的其他方法。所以，synchronize的方法尽量减小，并且应尽量使用方法同步代替代码块同步。

@不要使用finalize方法或者手动GC由于GC的工作量很大，尤其是回收Young代内存时，大都会引起应用程序暂停，所以再选择使用finalize方法进
行资源清理，会导致GC负担更大，程序运行效率更差。

@使用基本数据类型代替对象
String str="hello"创建一个“hello”字符串，而且JVM的字符缓存池还会缓存这个字符串；
String str=new String("hello");创建新的字符串外，str所引用的String对象底层还包含一个charl数组；

@多线程在未发生线程安全前提下应尽量使用HashMap、ArrayList
HashTable、Vector等使用了同步机制，降低了性能。一般局部变量不涉及线程安全，只有全局变量和静态变量有状态改变的时候才有线程安全；

@预估容量
要创建一个比较大的hashMap时，public HashMap(int
initialCapacity,float loadFactor);
避免HashMap多次进行了hash重构，扩容是一件很耗费性能的事，在默认中initialCapacity只有16，而loadFactor是0.75，需要多大的容量，
你最好能准确的估计你所需要的最佳大小，同样的Hashtable,Vectors也是一样的道理。
StringBuffer同理
StringBuffer的构造器会创建一个默认大小（通常是16）的字符数组。在使用中，如果超出这个大小，就会重新分配内存，创建一个更大的数组，
并将原先的数组复制过来，再丢弃旧的数组。在大多数情况下，你可以在创建StringBuffer的时候指定大小，这样就避免了在容量不够的时候自动增长，以提高性能。

@for(int i=0;i<list.size();i++)
应该改为：for(inti=O,len=list.size(;i<len;i++)并且在循环中应该避免使用复杂的表达式，在循环中，循
环条件会被反复计算，如果不使用复杂表达式，而使循环条件值不变的话，程序将会运行的更快。

@在程序需要时创建对象
如if(i=1){
A a=new AO;
list.add(a);}

@finally块中释放资源比如io流关闭；

@"/是一个代价很高的操作，使用移位的操作将会更快和更有效，同理乘法也适合；

int num=a/8;对应int num=a>>3;
int num=a*4;对应int num=a<<2;

@二维数据占用的内存空间比一维数组多得多，大概10倍以上，避免使用。

@慎用split
split由于支持正则表达式，所以效率比较低，如果是频繁的几十，几百万的调用将会耗费大量资源
确实需要频繁的调用split,使用apache的StringUtils.split(string,char),频繁split的可以缓存结果。

@ArrayList LinkedList一个是线性表，一个是链表，一句话，随机查询尽量使
用ArrayList,ArrayList优于LinkedList,LinkedListi还要移动指针
添加的操作LinkedList优于ArrayList,ArrayList:还要移动数据，不过这是理论性分析，事实未必如此，重要的是理解好2者得数据结构，对症下药。

@System.arraycopyo要比通过循环来复制数组快的多。

@缓存经常使用的对象尽可能将经常使用的对象进行缓存，可以使用数组，
或HashMap的容器来进行缓存，但这种方式可能导致系统占用过多的缓存，性能下降；推荐可以使用一些第三方的开源工具，如
EhCache,Oscache进行缓存，他们基本都实现了
FIFO/FLU等缓存算法。

@避免非常大的内存分配有时候问题不是由当时的堆状态造成的，而是因为分配失败造成的。分配的内存块都必须是连续的，而随着堆越来越满，找到较大的连续块越来越困难。

@重用对象
特别是String.对象的使用中，出现字符串连接情况时应使用StringBuffer代替，由于系统不仅要花时间生成对象，
以后可能还需要花时间对这些对象进行垃圾回收和处理。因此生成过多的对象将会给程序的性能带来很大的影响。

@遍历HaspMap:for(Entry<String,Stringl>entry:paraMap.entrySet(Q)性能最快

@array数组效率最高，但容量固定，无法动态改变，ArrayList容量可以动态增长，但牺牲了效率。








~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~6~~~~~~~~~~~~~~
58到家MQ如何快速实现流量削峰填谷
不管采用通过RPC框架调用还是MQ,都有一个缺点，下游消息接收方无法控制到达自己的流量，如果调用方不限速，很有可能把下游压垮。
上游下单业务简单，每秒发起了10000个请求，下游秒杀业务复杂，每秒只能处理2000个请求，很有可能上游不限速的下单，导致下游系统被压垮，引发雪崩。
1)业务上游队列缓冲，限速发送
2)业务下游队列缓冲，限速执行
消息总线是系统之间的解耦利器，但切勿滥用，未来也会撰文细究MQ的使用场景，消息总线为了尽量保证消息必达，架构设计方向为：
(1)消息收到先落地
(2)消息超时、重传、确认保证消息必达







~~~~~~~~~~~~~~~~~~7~~~~~~~~~~~~~~
58同城数据库架构的最佳
实践
单库，最初的时候数据库都是这么玩的，几乎所有的业务
都有这样的一个库。
分片，数据库的分片是解决数据量大的问题。如果数据量
非常大，就要做水平切分，有一些数据库支持auto
sharding.
分片路由规则：

(1)第一个是按照数据范围路由，比如有两个分片，一个范围是0-1亿，一个范围是1亿-2亿，这样来路由。
这个方式的优点是非常的简单，并且扩展性好，假如两个分片不够了，增加一个2亿-3亿的分片即可。
这个方式的缺点是：虽然数据的分布是均衡的，每一个库的数据量差不多，但请求的负载会不均衡。例如有一些业
务场景，新注册的用户活跃度更高，大范围的分片请求负
载会更高。

(2)第二个是按照hash路由，比如有两个分片，数据模2寻库即可。
这个方式的优点是路由方式很简单，数据分布也是均衡的，请求负载也是均衡的。
这个方式的缺点是如果两个分片数据量过大，要变成三个分片，数据迁移会比较麻烦，即扩展性会受限。

(3)第三个是路由服务。一致性hash.
大部分互联网的业务都是读多写少，“分片”和“分组”，数据量大进行分片，为了提高读性能，保证读的高
可用，进行了分组，80%互联网公司数据库都是这种软件架构。
解决站点的可用性问题冗余多个站点，解决服务的可用性问题冗余多个服务，解决数据的可用性问题冗余多份数据。
数据的冗余会引引发一个副作用，就是一致性的问题。读高可用
很多互联网公司的数据库软件架构都是一主两从或者一主三从，不能够保证“写”的高可用，因为写其实还是只有一个库，仍是单点，如果这个库挂了的话，写会受影响。
那小伙伴们为什么还使用这个架构呢？
刚才提到大部分互联网公司99%的业务都是“读”业务，
写库不是主要矛盾，写库挂了，可能只有1%的用户会受影响。
如果要做到“写”的高可用，对数据库软件架构的冲击比较大，不一定值得，为了解决1%的问题引引入了80%的复杂度，所以很多互联网公司都没有解决写数据库的高可用的问题。


58同城没有使用上述两种方式来保证读写的可用性。58城使用的“双主”当“主从”的方式来保证数据库的读写可用性。
第一是数据库资源的利用率只有50%；
第二是没有办法通过增加读库的方式来扩展系统的读性能。
如何增加数据库的读性能，先看下传统的玩法：
(1)第一种玩法是增加从库，通过增加从库来提升读性能，存在的问题是什么呢？从库越多，写的性能越慢，同步的时间越长，不一致的可能性越高。
(2)第二种常见的玩法是增加缓存，缓存是大家用的非
常多的一种提高系统读性能的一种方法，特别是对于读多
写少的互联网的场景非常的有效。
对于写操作：会先淘汰cache,再写数据库。
对于读操作：先读cache,如果cache hit!则返回数据，如
果cachemiss则读从库，然后把读出来的数据再入缓存。

传统的cache玩法在一种异常时序下，会引发严重的一致性问题：
(1)先来了一个写请求，淘汰了cache,写了数据库；
(2)又来了一个读请求，读cache,cache miss了，然后读从库，此时写请求还没有同步到从库上，于是读了一个脏数据，接着脏数据入缓存；
(3)最后主从同步完成；

一致性架构
如何保证数据的可用性？思路是冗余，但会引发数据的不
一致，58同城保证可用性的实践是双主当主从用，读写流量都在一个库上，另一个库standby,
一个主库挂掉流量自动迁移到另外一个主库，只是资源利用率是50%，并且不能通过增加从库的方式提高读性。性能的实践，传统的玩法是增加从库或者增加缓存。存在的问题是，主从可能不一致，同城的玩法是服务加数据库加缓存一套的方式来解决这些问题。
一致性的实践，解决主从不一致性有两种方法，
一种是增加中间件，中间件记录哪些key上发生了写操作，在主从同步时间窗口之内的读操作也路由到主库。
第二种方法是强制读主。数据库与缓存的一致性，我们的实践是双淘汰，在发生写请求的时候，淘汰缓存，写入数据库，再做一个延时的缓存淘汰操作。
第二个实践是建议为所有的item设置一个超时时间。







~~~~~~~~~~~~~~~~~~8~~~~~~~~~~~~~~
7种JVM垃圾收集器，Java语言实现核心
如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。
Java虚拟机规范中对垃圾收集器应该如何实现并没有任何规定，因此不同的厂商、版本的虚拟机所提供的垃圾收集器都可能会有很大差别，
并且一般都会提供参数供用户根据自己的应用特点和要求组合出各个年代所使用的收集器。收集方式：

新生代GC(Minor GC):指发生在新生代的垃圾收集动作，因为Java对象大多都具备朝生夕灭的特性，
所以Minor GC非常频繁，一般回收速度也比较快。
老年代GC(Major GC/Full GC):指发生在老年代的GC,出现了Major GC,经常会伴随至少一次的Minor GC
(但非绝对的，在Parallel Scavengel收集器的收集策略里就有直接进行Major GC的策略选择过程)。
Major GC的速度一般会比Minor GC慢10倍以上。

常见收集器：
@Serial(串行)收集器是最基本、发展历史最悠久的收集器，它是采用复制算法的新生代收集器，曾经(JDK1.3.1之前)是虚拟机新生代收集的唯一选择。
@ParNew!收集器就是Seriall收集器的多线程版本，它也是一个新生代收集器。

@Parallel Scavengel收集器也是一个并行的多线程新生代
收集器，它也使用复制算法，CMS等收集器的关注点是尽
可能缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标是达到
一个可控制的吞吐量(Throughput)。

@Serial Old是Seriall收集器的老年代版本，它同样是一个
单线程收集器，使用“标记-整理”(Mark-Compact)算法。

@Parallel Old收集器是Parallel Scavengel收集器的老年代版本，使用多线程和“标记整理”算法

@CMS是一款优秀的收集器，老年代，它的主要优点在名字上已经体现出来了：并发收集、低停顿，因此CMS收集器也被称为并发低停顿收集器(Concurrent Low PauseCollector

@G1(Garbage-First)收集器是当今收集器技术发展最前沿的成果之一，它是一款面向服务端应用的垃圾收集器，新生代+老年代，标记整理+复制算法；面向服务端应用，取代CMS;
HotSpot开发团队赋予它的使命是（在比较长期的）未来
可以替换掉JDK1.5中发布的CMS收集器。

与其他GC收集器相比，G1具备如下特点：
1)并行与并发G1能充分利用多CPU、多核环境下的硬件优势，使用多个CPU来缩短“Stop The World”停顿时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G收集器仍然可以通过并发的方式让Java程序继续执行。

2)分代收集与其他收集器一样，分代概念在G1中依然得以保留。虽然G可以不需要其他收集器配合就能独立管
理整个GC堆，但它能够采用不同方式去处理新创建的对象和已存活一段时间、熬过多次GC的旧对象来获取更好的收集效果。

3)空间整合G1从整体来看是基于“标记-整理”算法实现的收集器，从局部（两个Region之间）上来看是基
于“复制”算法实现的。这意味着G1运行期间不会产生内存空间碎片，收集后能提供规整的可用内存。此特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。

4)可预测的停顿这是G1相对CMS的一大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了降低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在GC上的时间不得超过N毫秒，这几乎已经是实时Java(RTSJ)的垃圾收集器的特征了。







~~~~~~~~~~~~~~~~~~9~~~~~~~~~~~~~~
9种高性能高可用高并发
的技术架构
1、分层
分层是企业应用系统中最常见的一种架构模式，将系统在
横向维度上切分成几个部分，每个部分负责一部分相对简
单并比较单一的职责，然后通过上层对下层的依赖和调度组成一个完整的系统。
在网站的分层架构中，常见的为3层，即应用层、服务层、数据层。
应用层，具体负责业务和视图的展示；
服务层，为应用层提供服务支持；
数据层，提供数据存储访问服务，如数据库、缓存、文件、搜索引擎等。
分层架构是逻辑上的，在物理部署上，三层架构可以部署
在同一个物理机器上，但是随着网站业务的发展，必然需要对已经分层的模块分离部署，即三层结构分别部署在不同的服务器上，使网站拥有的计算资源，以应对越来越
多的用户访问。

2、分割
如果说分层是将软件在横向方面进行切分，那么分隔就是
在纵向方面对软件进行切分。网站越大，功能越复杂，服务和数据处理的种类也越多，将这些不同的功能和服务分隔开来，包装成高内聚低耦合
的模块单元，不仅有助于软件的开发维护也便于不同模块的分布式部署，提高网站的并发处理能力和功能扩展能力。
大型网站分隔的粒度可能会很小。比如在应用层，将不同业务进行分隔，例如将购物、论坛、搜索、广告分隔成不同的应用，有对立的团队负责，部署在不同的服务器上。

3、分布式
对于大型网站，分层和分隔的一个主要目的是为了切分后
的模块便于分布式部署，即将不同模块部署在不同的服务器上，通过远程调用协同工作。分布式意味着可以使用更多的计算机完同样的工作，计算机越多，CPU、内存、存储
资源就越多，能过处理的并发访问和数据量就越大，进而能够为的用户提供服务。
在网站应用中，常用的分布式方案有一下几种.
分布式应用和服务：将分层和分隔后的应用和服务模块分布式部署，可以改善网站性能和并发性、加快开发和发布速度、减少数据库连接资源消耗。
分布式静态资源：网站的静态资源如JS、CSS、Logo图片等资源对立分布式部署，并采用独立的域名，即人们常说的动静分离。静态资源分布式部署可以减轻应用服务器的负载压力；通过使用独立域名加快浏览器并发加载的速度。
分布式数据和存储：大型网站需要处理以P为单位的海量数据，单台计算机无法提供如此大的存储空间，这些数据库需要分布式存储。
分布式计算：目前网站普遍使用Hadoop和MapReduce:分
布式计算框架进行此类批处理计算，其特点是移动计算而不是移动数据，将计算程序分发到数据所在的位置以加速计算和分布式计算。

4、集群负载均衡
对于用户访问集中的模块需要将独立部署的服务器集群化，即多台服务器部署相同的应用构成一个集群，通过负
载均衡设备共同对外提供服务。
服务器集群能够为相同的服务提供的并发支持，因此当有的用户访问时，只需要向集群中加入新的机器即可；另外可以实现当其中的某台服务器发生故障时，可以通过负载均衡的失效转移机制将请求转移至集群中其他的服务器上，因此可以提高系统的可用性。

5、消息异步
使用异步，业务之间的消息传递不是同步调用，而是将一个业务操作分成多个阶段，每个阶段之间通过共享数据的方法异步执行进行协作。
具体实现则在单一服务器内部可用通过多线程共享内存的方式处理；在分布式系统中可用通过分布式消息队列来实现异步。
异步架构的典型就是生产者消费者方式，两者不存在直接调用。

6、安全
网站在安全架构方面有许多模式：通过密码和手机校验码进行身份认证；登录、交易需要对网络通信进行加密；为了防止机器人程序滥用资源，需要使用验证码进行识别；对常见的XSS攻击、SQL注入需要编码转换；垃圾信息需要过滤等。

7、自动化
具体有自动化发布过程，自动化代码管理、自动化测试、自动化安全检测、自动化部署、自动化监控、自动化报警、自动化失效转移、自动化失效恢复等。

8、副本
网站需要7×24小时连续运行，那么就得有相应的冗余机制，以防某台机器宕掉时无法访问，而冗余则可以通过部
署至少两台服务器构成一个集群实现服务高可用。数据库除了定期备份还需要实现冷热备份。甚至可以在全球范围内部署灾备数据中心。

9、缓存
缓存目的就是减轻服务器的计算，使数据直接返回给用户。在现在的软件设计中，缓存已经无处不在。具体实现有CDN、反向代理、本地缓存、分布式缓存等。使用缓存有两个条件：访问数据热点不均衡，即某些频繁
访问的数据需要放在缓存中；数据在某个时间段内有效，不过很快过期，否在会因为数据过期而脏读，影响数据的正确性。






~~~~~~~~~~~~~~~~~~~~~~10~~~~~~~~~~~~~
DDD
1许多对象不是由它们的属性来定义，而是通过一系列的连续性(continuity)和标识(identity)来从根本上定义的。标识(identity)主键之类的，不可更改；连续性(continuity)陪伴一生
Message消息实体和Contact联系人实体。
值对象若干（如MessageState、MessageType等）。如果一个对象代表了领域的某种描述性特征，并且没有概念性的标识，我们就称之为值对象。值对象就是那些在
设计中我们只关心它们是什么，而不关心它们谁是谁的对象。
如果我们只关心模型中一个元素的属性，那么就把这个元素划分为值对象。用它来描述它所要表达的那些属性的意义，并提供相应的功能。把值对象看成是不可变的。
不要给它任何标识，这样可以避免实体的维护工作，降低设计的复杂性.

领域模型；
每个微服务是一个界限上下文，界限上下文之间访问通过防腐层，界线上下文下麦包括核心子域，通用子域，支撑子域；
界限上下文，子域，聚合根，实体，值对象，属性；
场景地图（业务层）>关键活动（比如创建魔板，绑定路由)->命令（发起保存/发送XX命令）->事件(XX已完成/已创建)->聚合根（实体，值对象）

一个场景地图是一个applicaion服务，里面调用多个领域服务，完成；比如创建集群(ADS领域，K⑧S领域，路由
等不同领域)；
分布式事务的控制本地事务控制在application)层，分布式事务最终一致性，
仓储层的作用仓储层和领域相关，领域层与基础设施之间的桥梁；
应用层的作用协调多个领域服务共同完成应用服务；
工厂模式尽量满足开闭原则；
基础设施层包括的组件（工具类，系统层，dao,nosql,mg,Globalconfiguration )
界限上下文之间的服务通信(external和防腐层)；服务治理(SGOV);
pom依赖版本制定；
脚手架组件的开发和使用；
命令设计模式（创建集群，部署，弹性伸缩，停止，启
动，重启)解耦扩展性好，
activiti,spring cloud Hystrix ,docker-java

领域模型
1.门界限上下文，每个界限上下文都是一个微服务；
1.n核心子域，通用子域，支撑子域；
1.n聚合（聚合根，实体，值对象）；
~Mall领域模型的界限上下文~
hiya.mall.sale.parent销售微服务，盈利的核心业务
hiya.mall.order.parent订单微服务工程
hiya.mall.shop.parent商户微服务工程
hiya.mall.good.parent商品微服务工程
hiya.mall.payment.parent支付微服务工程
hiya.mall.logistic.parent物流微服务工程
hiya.mall.system.parent系统微服务工程，包括用户，菜单，权限，角色，防腐层，日志调用链追踪，限流等
hiya.mall.component.parent组件微服务工程，提供公共的组件服务
hiya.mall.workflow.parent工作流微服务工程，提供系统的流程运转
hiya.mall.common.parent通用微服务工程，作为jar被引用，提供安全，日志ao,加解密，拦截器等底层通用功能

1核心子域-销售上下文
1.1核心子域-运营
1.1.1聚合1
聚合根A1
实体A11,A12
值对象
1.1.1聚合2
聚合根A2
实体A21,A22
值对象
1.2通用子域-优惠券
1.2.1产品聚合
聚合根产品信息
实体
值对象
1.3支撑子域-促销
1.3.1产品聚合
聚合根产品信息
实体
值对象







~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~11~~~~~~~~~~~~~
DNS在架构设计中的巧用
一般常见的负载均衡有两种：
①客户端与反向代理服务器之间的DNS负载均衡，这个就是dns向nginx:均衡；
②反向代理服务器(nginx)与应用服务器之间的负载衡，这个是nginx向实际的后台服务器均衡
什么是CDN?如果我在广州访问杭州的淘宝网，跨省的通信必然造成延迟。如果淘宝网能在广东建立一个服务器，
静态资源我可以直接从就近的广东服务器获取，必然能提高整个网站的打开速度，这就是CDN。CDN叫内容分发网络，是依靠部署在各地的边缘服务器，使用户就
近获取所需内容，降低网络拥塞，提高用户访问响应速度。和京东物流一样的，京东物流之所以这么快，就是因为分布式的仓库，找个最近的仓库发货

一个典型流程如上：
(1)客户端通过域名daojia.com请求dns-server
(2)dns-serveri返回域名对应的外网ip(1.2.3.4)
(3)客户端访问外网ip(1.2.3.4)向反向代理nginx
(4)反向代理nginx配置了多个后端web-server.服务内网ip(192.168.0.1/192.168.0.2)
(5)请求最终落到某一个web-serveri进行处理
架构设计中，dns有它独特的功能和作用：
1、dns轮询，水平扩展反向代理层dns向nginxt均衡
2、去掉反向代理层，利用dns实施负载均衡

和nginx相比优点：
利用第三方dns实施，服务端架构不用动；少了一层网络请求
和nginx相比不足：
dns只具备解析功能，不能保证对应外网ip的可用性（即
使能够做80口的探测，实时性肯定也是比nginx差很多的)，而nginx做反向代理时，与web-server之间有保活探测机制，当web-server挂掉时，能够自动迁移流量
当web-server需要扩容时，通过dns扩容生效时间长，而nginx:是服务端完全自己可控的部分，web-server扩容更实时更方便

3、智能dns,根据用户ip来就近访问服务器
类似CDN







~~~~~~~~~~~~~~~~~~12~~~~~~~~~~~~~
Istio究竟是干嘛的
一个用来连接、管理和保护微服务的开放平台.
Istio有助于降低这些部署的复杂性，并减轻开发团队的压力。它是一个完全开源的服务网格，可以透明地分层到
现有的分布式应用程序上。它也是一个平台，包括允许它集成到任何日志记录平台、遥测或策略系统的APl。Istio
的多样化功能集使您能够成功高效地运行分布式微服务架构，并提供保护、连接和监控微服务的统一方法。
1流量管理(Pilot):控制服务之间的流量和AP调用的流向，使得调用更灵活可靠，并使网络在恶劣情况下更加健壮。
如果您在Kubernetes集群上安装了Istio,那么它将自检测该集群中的服务和endpoint。
使用此服务注册中心，E门voy代理可以将流量定向到相关服务。大多数基于微服务的应用程序，每个服务的工作负载都有多个实例来处理流量，称为负载均衡池。默认情况下，E门voy代理基于轮询调度模型在服务的负载均衡池内分发流量，按顺序将请求发送给池中每个成员，一旦所有服务实例均接收过一次请求后，重新回到第一个池成员。和K8S紧密融合在一起

1)熔断器（工作负载的并发连接数限制为100）
apiVersion:networking.istio.io/v1alpha3
kind:DestinationRule
metadata:
name:reviews
spec:
host:reviews
subsets:
-name:v1
labels:
version:v1
trafficPolicy:
connectionPool:
tcp:
maxConnections:100

重试（在初始调用失败后最多重试3次来连接到服务子集，每个重试都有2秒的超时)
apiVersion:networking.istio.io/vlalpha3
kind:VirtualService
metadata:
name:ratings
spec:
hosts:
ratings
http:
route:
destination:
host:ratings
subset:v1
retries:
attempts:3
perTryTimeout:2s
timeout:10s(启动超时时间)

Sidecar:微调Envoy代理接受的端口和协议集，限制
Envoy代理可以访问的服务集合。
将bookinfo命名空间中的所有服务配置为仅能访问运行
在相同命名空间和Istio控制平面中的服务
apiVersion:networking.istio.io/v1alpha3
kind:Sidecar
metadata:
name:default
namespace:bookinfo
spec:
egress:
hosts:
-"./*"
-"istio-system/*"

Gateway网关
apiVersion:networking.istio.io/v1alpha3
kind:Gateway
metadata:
name:ext-host-gwy
spec:
selector:
app:my-gateway-controller
servers:
port:
number:443
name:https
protocol:HTTPS
hosts:
-ext-host.example.com
tls:
mode:SIMPLE
serverCertificate:/tmp/tls.crt
privateKey:/tmp/tls.key

2可观察性：过集成zipkin等服务，快速了解服务之间的依赖关系，以及它们之间流量的本质和流向，从而提供快
速识别问题的能力。监控指标，Istio指标收集从sidecar代理(Envoy)开始。
istio_requests_total
{
connection_security_policy="mutual_tls",
destination_app="details",
destination_principal="cluster.local/ns/default/sa/defau
It",
destination_service="details.default.svc.cluster.local",
destination_service_name="details",
destination_service_namespace="default",
destination_version="v1",
destination_workload="details-v1",
destination_workload_namespace="default",
reporter="destination",
request_protocol="http",
response_code="200",
response_flags="-",
source_app="productpage",
source_principal="cluster.local/ns/default/sa/default",
source_version="v1",
source_workload="productpage-v1",
source_workload_namespace="default"
}
Istio支持很多追踪系统，包括
Zipkin、Jaeger、LightStep、Datadog。

3策略执行(mixer):将组织策略应用于服务之间的互动，确保访问策略得以执行，资源在消费者之间良好分配。策略的更改是通过配置网格而不是修改应用程序代码。
Istio允许您为应用程序自定义策略，用以在运行时强制执行相应的规则，例如：限流用于动态限制发送给服务的流量
Denials、白名单和黑名单用于限制服务的访问
Header的重写和重定向
Istio还允许您创建自己的策略适配器，比如，您自定义的授权行为。您必须为您的服务网格启用策略实施以后才能使用此功能。

4服务身份和安全(Istio-auth):为网格中的服务提供可验证身份，并提供保护服务流量的能力，使其可以在不同可信度的网络上流转。
下例显示了一个AuthorizationPolicy,它允许两个来源
(服务帐户cluster.local/ns/default/sa/sleep和命名空间dev)在使用有效的JWT令牌发送请求时，可以访问命名空间foo中的带有标签app:httpbin和
version:v1的工作负载
apiVersion:security.istio.io/v1beta1
kind:AuthorizationPolicy
metadata:
name:httpbin
namespace:foo
spec:
selector:
matchLabels:
app:httpbin
version:v1
rules:
-from:
source:
principals:["cluster.local/ns/default/sa/sleep"
source:
namespaces:["dev"]
to:
operation:
methods:["GET"]
when:
key:request.auth.claims[iss]
values:["https://accounts.google.com"

apiVersion:security.istio.io/v1beta1
kind:AuthorizationPolicy
metadata:
name:httpbin
namespace:foo
spec:
selector:
matchLabels:
app:httpbin
version:v1
rules:
-from:
source:
principals:["cluster.local/ns/default/sa/sleep"
source:
namespaces:["dev"]
to:
operation:
methods:["GET"]
when:
key:request.auth.claims[iss]
values:["https://accounts.google.com"]







~~~~~~~~~~~~~~~~~~~~~~13~~~~~~~~~~~~~
JTA
------JTA+Atomikos
1 Java Transaction APl,通常称为JTA,是用于管理
Java中的事务的API。它允许我们以资源无关的方式启动，提交和回滚事务。
根据用于管理事务的底层实现，Spring中的事务策略可以分为两个主要部分：单连接器策略（相当于本地事务管理器）-底层技术使用单连接器。例如，JDBC使用连接级事务、Hibernate以及
JDO使用会话级事务。可以应用使用AOP和拦截器的声明式事务管理。多连接器策略（相当于全局事务管理器）-底层技术具有
使用多个连接器的能力。当有这方面需求时，JTA是最好的选择。此策略需要启用JTA的数据源实例。JBOSSTS、Atomikos、Bitronix都是开源的JTA实现。
JTA的真正强大之处在于它能够在单个事务中管理多个资源（如数据库，消息服务）。

2PC(两段提交)含义：首先，事务协调员向每个服务器询问一遍，要求每个数据库都进行precommit的操作和是否可能实现commit.如果所有数据库都同意commit,第
二段开始。第二段：事务协调员要求每个数据库commit数据.如果任何数据库否决commit,那么所有数据库将被要求回

Spring提供了JTA介入方式，但是没有提供JTA实现，目
前JTA实现：Java Open Transaction Manager (JOTM)JBoSs TS,Bitronix Transaction Manager(BTM),和Atomikos。
XA规范和JTA:
XA是一种协议或者规范，由X/Open组织提出的分布式事务的架构（或者叫协议）。XA架构主要定义了（全局）
事务管理器(Transaction Manager)和（局部）资源管理器(Resource Manager)之间的接口。也是2PC协议；
JTA是java根据XA规范提供的事务处理标准；
spring.支持JTA事务，但是有不同厂商实现，遵循XA规范，

开源的实现TM提供商
Java Open Transaction Manager (JOTM)
JBOSS TS
Bitronix Transaction Manager (BTM)
Atomikos
Narayana
面向编程者APl:userTranscation
UserTransaction和TransactionManageri这两个？
一个是面向编程者，一个是面向厂商；






~~~~~~~~~~~~~~~~~~14~~~~~~~~~~~~~
Ivs为何不能完全替代DNS轮询

一、问题域
nginx、lvs、keepalived、f5、DNS轮询，每每提到这些技术，往往讨论的是接入层的这样几个问题：
1)可用性：任何一台web服务器机器挂了，服务受不受影响
2)扩展性：能否通过增加机器，扩充系统的性能
3)反向代理+负载均衡：请求是否均匀分摊到后端的web服务器执行

二、上面那些名词都是干嘛的
1)nginx:一个高性能的web-server和实施反向代理的软件
2)lvs:Linux Virtual Server,使用集群技术，实现在Elinux操作系统层面的一个高性能、高可用、负载均衡服务器
3)keepalived:一款用来检测服务状态存活性的软件，常用来做高可用
4)f5:一个高性能、高可用、负载均衡的硬件设备（听上去和vs功能差不多？)
5)DNS轮询：通过在DNS-server.上对一个域名设置多个ip解析，来扩充web-server't性能及实施负载均衡的技术

三、接入层技术演进

【裸奔时代】
1)浏览器通过DNS-server,域名解析到ip
2)浏览器通过ip访问web-server
缺点：
1)非高可用，web-server挂了整个系统就挂了
2)扩展性差，当吞吐量达到web-server.上限时，无法扩容

(简易扩容方案(1)DNS轮询】
假设tomcat的吞吐量是1000次每秒，当系统总吞吐量达到3000时，如何扩容是首先要解决的问题，DNS轮询是
一个很容易想到的方案：
1)多部署几份web-server,1个tomcat抗1000，部署3个tomcati就能抗3000
2)在DNS-server层面，域名每次解析到不同的ip

优点：
1)零成本：在DNS-server.上多配几个ip即可，功能也不收费
2)部署简单：多部署几个web-server即可，原系统架构不需要做任何改造
3)负载均衡：变成了多机，但负载基本是均衡的缺点：
1)非高可用：DNS-server只负责域名解析ip,这个ip对应的服务是否可用，DNS-server是不保证的，假设有一个web-server挂了，部分服务会受到影响
2)扩容非实时：DNS解析有一个生效周期
3)暴露了太多的外网ip

【简易扩容方案(2)nginx】
tomcat的性能较差，但nginx作为反向代理的性能就强多了，假设线上跑到1w,就比tomcati高了10倍，可以利用这个特性来做扩容：
1)站点层与浏览器层之间加入了一个反向代理层，利用高性能的nginx来做反向代理
2)nginx将http请求分发给后端多个web-server
优点：
1)DNS-server:不需要动
2)负载均衡：通过nginx来保证
3)只暴露一个外网ip,nginx->tomcat之间使用内网访问
4)扩容实时：nginx内部可控，随时增加web-server随时实时扩容
5)能够保证站点层的可用性：任何一台tomcat挂了，nginx可以将流量迁移到其他tomcat

缺点：
1)时延增加+架构更复杂了：中间多加了一个反向代理层
2)反向代理层成了单点，非高可用：tomcat挂了不影响服务，nginx挂了怎么办？

【高可用方案(3)keepalived】
为了解决高可用的问题，keepalived出场了（之前的文章“使用shadow-master保证系统可用性”详细介绍过)：
1)做两台nginx组成一个集群，分别部署上keepalived,设置成相同的虚P,保证nginx的高可用
2)当一台nginx挂了，keepalived能够探测到，并将流量自动迁移到另一台nginx.上，整个过程对调用方透明

优点：
1)解决了高可用的问题
缺点：
1)资源利用率只有50%
2)nginx仍然是接入单点，如果接入吞吐量超过的nginx的性能上限怎么办，例如qps达到了50000咧？

【scale up:扩容方案(4)lvs/f5】
nginx.毕竟是软件，性能比tomcats好，但总有个上限，超出了上限，还是扛不住。Vs就不一样了，它实施在操作系统层面；
F5的性能又更好了，它实施在硬件层面；它们性能比nginx好很多，例如每秒可以抗10w,这样可以利用他们来扩容，常见的架构图如下：
此时：
1)如果通过nginx可以扩展多个tomcat一样，可以通过lvs来扩展多个nginx
2)通过keepalived+VIP的方案可以保证可用性99.9999%的公司到这一步基本就能解决接入层高可用、扩展性、负载均衡的问题。


这就完美了嘛？还有潜在问题么？
好吧，不管是使用lvs还是f5,这些都是scaleupl的方案，
根本上，vs/f5还是会有性能上限，假设每秒能处理10W的请求，一天也只能处理80亿的请求(10w秒吞吐量*8W秒)，那万一系统的日
PV超过80亿怎么办呢？（好吧，没几个公司要考虑这个问题)

【scale out扩容方案(5)DNS轮询】
如之前文章所述，水平扩展，才是解决性能问题的根本方案，能够通过加机器扩充性能的方案才具备最好的扩展性。
facebook,google,baidu的PV是不是超过80亿呢，它们的域名只对应一个ip么，终点又是起点，还是得通过DNS轮询来进行扩容：
此时：
1)通过DNS轮询来线性扩展入口IvS层的性能
2)通过keepalived:来保证高可用
3)通过lvs来扩展多个nginx
4)通过nginx来做负载均衡，业务七层路由

四、结论
1)接入层架构要考虑的问题域为：高可用、扩展性、反向代理+扩展均衡
2)nginx.、keepalived、Ivs、f5可以很好的解决高可用、扩展性、反向代理+扩展均衡的问题
3)水平扩展scale out是解决扩展性问题的根本方案，DNS轮询是不能完全被nginx/Ivs/f5所替代的







~~~~~~~~~~~~~~~~~~~~~~15~~~~~~~~~~~~~
RPC框架，底层到底什么
原理
一个RPC框架大致需要动态代理、序列化、网络请求、网络请求接受(netty:实现)、动态加载、反射这些知识点。现在开源及各公司自己造的RPC框架层出不穷，唯有掌握原理是一劳永逸的。






~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~16~~~~~~~~~~~~~
RPC-client)序列化
一、为什么要进行序列化
工程师通常使用“对象”来进行数据的操纵：
class User{
std:Stringuser_name;
uint64_tuser_id;
uint32_tuser_age;
;
User u new User("shenjian");
u.setUid(123);
u.setAge(35);

但当需要对数据进行存储（固化存储，缓存存储）或者传输（跨进程网络传输）时，“对象”就不这么好用了，往
往需要把数据转化成连续空间的二进制字节流，一些典型
的场景是：
(1)数据库索引的磁盘存储：数据库的索引在内存里
是b+树或者hash的格式，但这个格式是不能够直接存储到磁盘上的，所以需要把b+树或者hash转化为连续空间的二进制字节流，才能存储到磁盘上
(2)缓存的KV存储：redis/memcache是KV类型的缓存，缓存存储的value必须是连续空间的二进制字节流，而不能够是User对象
(3)数据的网络传输：socket发送的数据必须是连续空
间的二进制字节流，也不能是对象所谓序列化(Serialization),就是将“对象”形态的数
据转化为“连续空间二进制字节流”形态数据的过程，以方便存储与传输。这个过程的逆过程叫做反序列化。

二、怎么进行序列化
这是一个非常细节的问题，要是让你来把“对象”转化为
字节流，你会怎么做？很容易想到的一个方法是l(或
者json)这类具有自描述特性的标记性语言：
<class name="User">
<element name="user_name"type="std::String"
value="shenjian"/>
<element name="user_id"type="uint64_t"value="123"/>
<element name="user_age"type="uint32_t"value="35"
/>
</class>
规定好转换规则，发送方很容易把User类的一个对象序列化为ml,服务方收到xml二进制流之后，也很容易将其范序列化为User对象（特别是语言支持反射的时候，就更easy了)。
第二个方法是自己实现二进制协议来进行序列化，还是以上面的User对象为例，可以设计一个这样的通用协议：

二进制协议
(1)头4个字节表示序号
(2)序号后面的4个字节表示key的长度m
(3)接下来的m个字节表示key的值
(4)接下来的4个字节表示value的长度n
(5)接下来的n个字节表示value的值
(6)像xl一样递归下去，直到描述完整个对象
上面的User对象，用这个协议描述出来可能是这样的user对象协议
(1)第一行：序号4个字节（设0表示类名），类名长度4个字节（长度为4），接下来4个字节是类名
(”User”),共12字节
(2)第二行：序号4个字节(1表示第一个属性)，属性长度4个字节（长度为9），接下来9个字节是属性名
(”user_name”),属性值长度4个字节（长度为8），属性值8个字节（值为”shenjian”),共29字节
(3)第三行：序号4个字节(2表示第二个属性)，属性长度4个字节（长度为7），接下来7个字节是属性名
(”user_id”),属性值长度4个字节（长度为8），属性值8个字节（值为123），共27字节
(4)第四行：序号4个字节(3表示第三个属性)，属性长度4个字节（长度为8），接下来8个字节是属性名
(”user_name”),属性值长度4个字节（长度为4），属性值4个字节（值为35），共24字节

整个二进制字节流共12+29+27+24=92字节
实际的序列化协议要考虑的细节远比这个多，例如：强类
型的语言不仅要还原属性名，属性值，还要还原属性类型；复杂的对象不仅要考虑普通类型，还要考虑对象嵌套类型等。however,序列化的思路都是类似的。


三、序列化协议要考虑什么因素
不管使用成熟协议xml/json,还是自定义二进制协议来序列化对象，序列化协议设计时要考虑哪些因素呢？
(1)解析效率：这个应该是序列化协议应该首要考虑的因素，像xml/json解析起来比较耗时，需要解析doom树，二进制自定义协议解析起来效率就很高
(2)压缩率，传输有效性：同样一个对象，xml/json传输起来有大量的ml标签，信息有效性低，二进制自定义协议占用的空间相对来说就小多了
(3)扩展性与兼容性：是否能够方便的增加字段，增加字段后旧版客户端是否需要强制升级，都是需要考虑的问题，xml/json和上面的二进制协议都能够方便的扩展
(4)可读性与可调试性：这个很好理解，Xml/json的可读性就比二进制协议好很多
(5)跨语言：上面的两个协议都是跨语言的，有些序列化协议是与开发语言紧密相关的，例如dubbo的序列化协议就只能支持Java的RPC调用
(6)通用性：xml/json非常通用，都有很好的第三方解析库，各个语言解析起来都十分方便，上面自定义的二进制协议虽然能够跨语言，但每个语言都要写一个简易的协议客户端


四、业内常见的序列化方式
(1)Alibaba fastison:将parse的速度提升到极致，超
过所有json库，包括曾经号称最快的jackson。并且还超越了google的二进制协议protocol buf。将Java对象序列化为JSON字符串，支持各种各种
Java基本类型和JavaBean将JSON字符串反序列化为JavaBean
(2)Kryo和FST:dubbo默认的，高效的Java序列化
<dubbo:protocol name="dubbo"
serialization="kryo"/>
<dubbo:protocol name="dubbo"
serialization="fst"/>
(3)protobuf:Google出品，属于二进制协议，可读性差了点，但也有类似的to-string协议帮助调试问题
(4)hessian:比Java原生的对象序列化/反序列化速度更快，序列化出来以后的数据更小.序列化协议跟应用层协议无关
hessianOutput = newHessianOutput(byteArrayOutputStream);
hessianOutput.writeObject(employee)

(5)JDK序列化：jdk自带的，速度慢，基本被淘汰；
ObjectOutputStream oos new
ObjectOutputStream(fos);
oos.writeObject(obj);








~~~~~~~~~~~~~~~~~~~17~~~~~~~~~~~~~
Spring Boot内存
本来只有1G内存的容器，Spring bootp占用了400M内存。
优化Spring boot的内存了。

1、JVM Xmx Xms的设置问题。通过jmap-heap命令查看，eden+from+to+old内存占用了200M,由于Xmx设置比较大，eden区的内存区域比较大，这样就推迟了GC
的动作。导致Spring boot占用了比较大的内存。之后，Xms设置为了64M,Spring boot程序内存减少到200M。

2、Heap内存设置这么小，为什么还占用这么多内存。接下来用jstack查看内存发现了大量的线程在运行，主要有GC task thread,http-nio thread,C2
CompilerThread,足有上百个线程在运行。Docker容器虽然隔离了资源，但是共用了操作系统内核，Spring boot发现有72个核，那就开足了马力跑线程，导致线程数量巨多。VM默认线程栈大小是1M,光线程的开销就耗去了100多M。
@GC task thread:垃圾回收线程
@http-nio thread:tomcat网络处理网络请求线程
@C2 CompilerThread:JIT编译线程，动态编译Java运行代码，C2表示编译的是serveri端代码
@agent的服务比较简单，不会有太深栈层次，因此把Xss
设置为256K,这样可以减少大部分栈内存的开销。Gc线程数量太多，减少为两个=>XX:ParallelGCThreads=2。不

3、Spring boot自带的tomcat线程数默认值为200个，我们没有这么大的并发量，这里修改Spring boot的配置application.properties的内容=>server.tomcat.max-
threads=10。

4、JT是JVM为了优化执行频率比较高的字节码设计的技术，J竹把字节码编译为机器码，之后执行则不需要解释字节码，直接运行机器码即可。
我们的服务没有什么负载，即使不优化也不受影响，这里的优化是把JIT关掉，在Java启动的参数中添加=>-Djava.compiler=NONE,这样就不会再有CompilerThread了。

5、经过线程的优化，VM省去了大量的线程栈开销，最后把程序压到了100M。Java本身就是内存消耗大户，裸
程序启动即消耗了30M内存,这里融合了Spring:框架Tomcat服务器消耗100M内存也没有太离谱，优化到此结束。






~~~~~~~~~~~~~~~~~~~~~~18~~~~~~~~~~~~~
AJA
TCP接入层的负载均衡、高可用、扩展性架构
http是无状态的短连接，以及web应用无状态的特性，理论上任何一个http请求落在任意一台web-server都应该得到正常处理。
tc是有状态的长连接，客户端和服务端一旦建立连接，
一个client发起的请求必须落在同一台tcp-server.上，此时如何做负载均衡，如何保证水平扩展呢？
1单机法tcp-server:无法保证高可用。

2集群法tcp-server:搭建tcp-server集群来保证高可用，客户端来实现负载均衡，每次连接前，需要多实施一次DNS访问，难以预防DNS劫
持，多一次DNS访问意味着更长的连接时间，在手机端更为明显

3解决DNS问题
直接将P配置在客户端，可以解决上述两个问题，很多公司也就是这么做的（俗称“P直通车”）。

4P直通车新问题
将P写死在客户端，在客户端实施负载均衡，扩展性很差：
如果原有P发生变化，客户端得不到实时通知
如果新增IP,即tcp-sever扩容，客户端也得不到实时通知
如果负载均衡策略变化，需要升级客户端


5服务端实施负载均衡
解决了扩展性，但是可用性不好，当有一个P挂掉的时候，而get-tcp-ip接口只是维护静态的tcp-server集群IP,
对于这些P对应的tcp-server是否可用，是完全不知情的，怎么办呢？

6tcp-servery状态上报和状态拉取
状态上报：tcp-server需要依赖和业务无关的web-server状态拉取：解决依赖问题，可选方案







~~~~~~~~~~~~~~~~~~~~~~19~~~~~~~~~~~~~
“反向依赖”与解耦方案
一、缘起
由A的调整（数据库换ip),配合修改和调整的却是BCDE(改配置重启)，BCDE内心非常的郁闷：明明换ip的是你，凭什么配合重启的却是我？
一个“架构耦合”的问题，是一个架构设计上“反向依赖”的问题.

二、寻找不合理反向依赖
变动方是A,配合方却是BCDE(或者说需求方是A,改动方确是BCDE)
如果系统中经常出现了这类情况，就是“反向依赖”的特征，往往架构上有优化的空间。

三、常见的“反向依赖”与优化方案
【case1:公共库导致耦合】
公共库导致耦合
三个服务s1/s2/s3,通过一个公共的库biz.jar来实现一段
业务逻辑，s1/s2/s3其实间接通过biz.jar耦合在了一起，一个业务$1修改一块公共的代码，导致影响其他业务
s2/s3,架构上是不合理的。

优化方案1：业务垂直拆分
业务垂直拆分
如果biz.jar中实现的逻辑“业务特性”很强，可以拆分为biz1.jar/biz2.jar/biz3.jar,来对s1/s2/s3进行解耦。这样的话，任何业务的改动，影响范围只是自己，不会影响
其他人。

优化方案2：服务化
服务化
如果biz.jar中实现的逻辑“业务共性”很强，可以将biz.jar优化为biz.service服务，来对s1/s2/s3进行解耦。服务化之后，兼容性能更好的通过接口自动化回归测试来保证。
基础服务的抽象，本身是一种共性聚焦，是系统解耦常见的方案。


【case2:服务化不彻底导致耦合】
服务化不彻底导致耦合
服务化是解决“业务共性”组件库导致系统耦合的常见方案之一，但如果服务化不彻底，service本身也容易成为业务耦合点。
典型的服务化不彻底导致的业务耦合的特征是，共性服务中，包含大量“根据不同业务，执行不同个性分支”的代码。
switch(biz-type)
case biz-1 exec1
case biz-2 exec2
case biz-3:exec3
在这种架构下，biz-1/biz-2/biz-3有个性的业务需求，可能导致修改代码的是共性的biz-service,使其成为研发瓶颈，架构上也是不合理的。
优化方案：业务特性代码上浮，业务共性代码下沉，彻底解耦特性代码放到业务层实现
把swithc casel中业务特性代码放到业务层实现，这样biz-1/biz-2/biz-3有个性的业务需求，升级的是自己的业务系统。


【case3:notifyl的不合理实现导致的耦合】
notify的不合理实现导致的耦合如何新增消息接收方biz-,会发现修改代码的是消息发送方，新增一个对biz-4的调用，极不合理。优化方案：通过MQ实现解耦
通过MQ实现解耦消息发送方uppery将消息发布给MQ,消息接收方从MQ去订阅，任何新增对消息的消费，upper都不需要修改代码。

【case4:配置中的ip导致上下游耦合】
配置中的ip导致上下游耦合即“缘起”中举的例子，下游服务换i，可能导致多个服务调用方修改配置重启。上下游间接的通过ip这个配置耦合在了一起，架构不合理。
优化方案：通过内网域名而不是ip来进行下游连接
使用内网域名来进行下游连接
如果在配置中使用内网域名来进行下游连接，当下游服务或者数据库更换ip时，只需要运维层面将内网域名指向新的ip,然后统一切断原有旧的连接，连接就能够自动切换
到新的ip上来。这个过程不需要所有上游配合，非常帅气，强烈推荐！


【case5:下游扩容导致上下游耦合】
下游扩容导致上下游耦合
这次不是换换ip这么简单了，下游服务提供方原来是集群
(ip1/ip2/ip3,当然，上游配置的是内网域名)，现在集群要扩容为(ip1/ip2/ip3/ip4/ip5),
如果没有特殊的架构设计，上游往往需要修改配置，新增扩容后的节点，再重启，导致上下游耦合。

四、总结
如何发现系统架构中不合理的“反向依赖”设计？
回答：
(1)变动方是A,配合方却是BCDE
(2)需求方是A,改动方确是BCDE
想想“换P的是你，配合重启的却是我”，此时往往架构上可以进行解耦优化。


常见反向依赖及优化方案？
(1)公共库导致耦合
优化一：如果公共库是业务特性代码，进行公共库垂直拆分
优化二：如果公共库是业务共性代码，进行服务化下沉抽象

(2)服务化不彻底导致耦合
特征：服务中包含大量“根据不同业务，执行不同个性分支”的代码
优化方案：个性代码放到业务层实现，将服务化更彻底更纯粹

(3)notifyl的不合理实现导致的耦合
特征：调用方不关注执行结果，以调用的方式去实现通知，新增订阅者，修改代码的是发布者
优化方案：通过MQ解耦
(4)配置中的ip导致上下游耦合

特征：多个上游需要修改配置重启
优化方案：使用内网域名替代内网ip,通过“修改DNS指向，统一切断旧连接”的方式来上游无感切换

(5)下游扩容导致上下游耦合
特性：多个上游需要修改配置重启








~~~~~~~~~~~~~~~~~~~20~~~~~~~~~~~~~
一线互联网公司的架构实践
1全栈架构。
从本次架构会场的分享涵盖了从基础架构到业务形态，从系统设计到持续交付，从安全、监控到虚拟化技术，从版
本迭代到项目投入产出
比等诸多领域。本质上，架构师的职责就是充分评估业务，人员，成本等要素在技术层面上保障服务的顺利落地，稳定运行并适时推动平滑升级，期间
遇到的所有技术的问题都是架构师需要直面的。既是新业务新技术的探路者，又是扫清线上系统瓶颈的急先锋，架构师的担子，不轻。

2趋同存异。
一天的分享中，服务化、分库分表、异步、分布式、安全、监控等这些高频词反复出现，说明架构设计的基本原则和架构师们关注点是趋同的
，甚至各自系统架构演化到不同阶段遇到的瓶颈和应对的举措也是惊人的相似。当然也有不同，比如安全，有些场景下关注的业务安全，有些则更关注数据安全；比如数据一致性，有些场景要求强一致性，有些只
需关注最终一致性。而其实也正是业务场景的差异给了架构师们展示自己聪明才智的舞台。

3拥抱变化。
从分享的主题来看，变化、变迁、演化，主线是一个“变”字。业务量的迅猛增长会倒逼架构的优化和升
级，快的和饿了么是典型的例子。而新技术出现也会推动架构的变革，比如服务化可以提升开发效率，降
低协作成本；比如流式计算，可以改善用户体验甚至是引导用户需求。无论是业务驱动还是技
术驱动，架构师都需要做的就是时刻拥抱变化，成为一个敏锐的观察者，技术航线的引领者和架构的实践者。








~~~~~~~~~~~~~~~~~~21~~~~~~~~~~~~~
D:\Pcloud Hiya Stores\Adeeps:3业界难题-“跨库分页”的
四种方案
方法一：全局视野法
(1)将order by time offset X limit Y,改写成order bytime offset 0 limit X+Y
(2)服务层对得到的N*(X+Y)条数据进行内存排序，内
存排序后再取偏移量X后的Y条记录
这种方法随着翻页的进行，性能越来越低。

方法二：业务折衷法-禁止跳页查询
(1)用正常的方法取得第一页数据，并得到第一页记录的time_max
(2)每次翻页，将order by time offset X limit Y,改写成order by time where time>Stime._max limit Y以保证每次只返回一页数据，性能为常量。

方法三：二次查询法
(1)将order by time offset X limit Y,改写成order bytime offset X/N limit Y
(2)找到最小值time_min
(3)between二次查询，order by time betweenStime_min and Stime_i_max
(4)设置虚拟time_min,找到time_min在各个分库的offset,从而得到time_min在全局的offset
(5)得到了time_min在全局的offset,自然得到了全局的offset X limit Y








~~~~~~~~~~~~~~~~~~~~~~22~~~~~~~~~~~~~
云计算概念
云计算：
IAAS基础设施即服务
PAAS平台即服务
SAAS软件即服务
BAAS业务即服务
FAAS函数即服务
DAAS数据即服务









~~~~~~~~~~~~~~~~~~~~23~~~~~~~~~~~~~
互联网分层架构的本质
互联网分层架构的本质究竟是什么呢？
如果我们仔细思考会发现，不管是跨进程的分层架构，还是进程内的MVC分层，都是一个“数据移动”，然
后“被处理”和“被呈现”的过程，
归根结底一句话：互联网分层架构，是一个数据移动，处理，呈现的过程，其中数据移动是整个过程的核心。
跨进程移动：数据从数据库和缓存里，转移到service层，到web-server层，到client层
同进程移动：数据从model/层，转移到control层，转移到view层









~~~~~~~~~~~~~~~~~~~24~~~~~~~~~~~~~
D:\Pcloud Hiya Stores\\deeps:3\冗余数据一致性，到底如何保证
互联网数据量大的业务场景，使用水平切分来降低单库数据量
使用数据冗余的反范式设计来满足不同维度的查询需求
1冗余数据三种方案：
(①)服务同步双写法能够很容易的实现数据冗余
(②)为了降低时延，可以优化为服务异步双写法
(③)为了屏蔽“冗余数据”对服务带来的复杂性，可以优化为线下异步双写法
2保证数据一致性的方案：
(①)最简单的方式，线下脚本扫全量数据比对
(②)提高效率的方式，线下脚本扫增量数据比对
(③)最实时的方式，线上检测“消息对”







~~~~~~~~~~~~~~~~~~~~~~25~~~~~~~~~~~~~
写一个服务网关
模拟zuul网关
就是定义一个Servlet接收请求。
然后经过preFilter(封装请求参数)，
routeFilter(请求)，
postFilter(输出内容)。
三个过滤器之间，共享request、responsel以及其他的一
些全局变量。
@WebServlet(name "eatuul",urlPatterns ="/*"
public class EatuulServlet extends HttpServlet
private EatRunner eatRunner new EatRunnerO;
@Override
public void service(HttpServletRequest req,
HttpServletResponse resp)
throws ServletException,IOException
/将request,和response)放入上下文对象中
eatRunner.init(req,resp);
try
//执行前置过滤
eatRunner.preRoute(;
/执行过滤
eatRunner.routeO;
/执行前置过滤
eatRunner.preRouteO;
/执行过滤
eatRunner.routeO;
/执行后置过滤
eatRunner.postRoute);
catch (Throwable e){
RequestContext.getCurrentContext).getResponse
.sendError(HttpServletResponse.SC_NOT_FOUND,
e.getMessage();
finally
/清除变量
RequestContext.getCurrentContext).unsetO;
}
}
}
zuul执行流程：
1.请求一>zuulServlet处理；zuulServlet!里面定义了整个
请求的执行顺序；preRoute(一>route)—>postRoute(;

2.zuulservlet中有一个zuulRunner对象，该对象中初始化了RequestContext,RequestContext继承了
ConcurrentHashMap,并且它是一个单例的；所以它被用来存储整个请求中的与请求相关的数据，被所有不zuulFilter共享。

3.zuulRunner中含有FilterProcessor,FilterProcessor中定义了zuulfilter过滤器的执行规则(filterType,filterOrder,run)。

4.FilterProcessor从filterloaderr中获取zuulfilter;

5.zuulfilter是被filterFileManager所加载，并支持groovy热加载，采用了轮询的方式热加载。

6.加载的过滤器都存放在filterRegistry中。

7.得到这些过滤器后，就开始按preRoute0一>route()一>postRoute)的顺序开始执行这些过滤器。

8.执行这些过滤器有错误的时候会执行errori过滤器。

9.执行完这些过滤器后，将请求结果返回给客户端。
Spring Cloudi已经放弃Netflix Zuul了。现在Spring Cloud中引用的还是Zuul1.x版本，而这个版本是基于过滤器的，是阻塞0，不支持长连接。
Zuul2.x使用netty长连接；
Zuul2.x版本跟1.x的架构大一样，性能也有所提升。既
然Spring Cloud已经不再集成Zuul2.x了，那么是时候了解一下Spring Cloud Gateway了从面向对象设计的角度看，它与外观模式类似。

目前，比较流行的网关有：Nginx、Kong、Orange等等，还有微服务网关Zuul、Spring Cloud Gateway等等
常见的选型有基于Openresty的Kong、基于Go的Tyk和基于Java的Zuul。这三个选型本身没有什么明显的区别，主要还是看技术栈是否能满足快速应用和二次开发。
像Nginx这类网关，性能肯定是没得说，它适合做那种门户网关，是作为整个全局的网关，是对外的，处于最外层的；
而Gateway:这种，更像是业务网关，主要用来对应不同的客户端提供服务的，用于聚合业务的。各个微服务独立部署，职责单一，对外提供服务的时候需要有一个东西把业务聚合起来。
像Nginx这类网关，都是用不同的语言编写的，不易于扩展；而Gateway就不同，它是用Java写的，易于扩展和维护
Gateway这类网关可以实现熔断、重试等功能，这是Nginx.不具备的
Spring Cloud Gateway是Spring Cloud微服务平台的一个子项目，属于Spring开源社区，依赖名叫：spring-
cloud-starter-gateway。
https://spring.io/projects/spring-cloud-gateway

Zuul是Netflix公司的开源项目，Spring Cloud在Netflix项目中也已经集成了Zuul,依赖名叫：spring-cloud-
starter-netflix-zuul。
https://github.com/Netflix/zuul
Zuul构建于Servlet2.5,兼容3.x,使用的是阻塞式的APl,不支持长连接，比如websockets。另外
Spring Cloud Gateway构建于Spring5+,基于SpringBoot2.x响应式的、非阻塞式的AP1。同时，它支持websockets,和Spring框架紧密集成，开发体验相对来说十分不错。
这个没什么好比的，要比就和Zuul2.x比，Zuul2.x在底层上有了很大的改变，使用了异步无阻塞式的AP,性能改善明显，不过现在Spring Cloud也没集成Zuul2.x,所以就没什么好比的。
正是因为Zuul2.x的不断跳票，Spring Cloud才釜底抽薪推出了自己的服务网关：Spring Cloud Gateway,栈长看了下，使用起来比Zuul更简单，配置更方便，

所以说选Spring Cloud Gateway没错，毕竟是SpringCloud亲儿子，不会始乱终弃。








~~~~~~~~~~~~~~~~~~26~~~~~~~~~~~~~
动态权重和过载保护

一、需求缘起
后端的service有可能部署在硬件条件不同的服务器上：
1)如果对标最低配的服务器“均匀”分摊负载，高配的服务器的利用率不足；
2)如果对标最高配的服务器“均匀”分摊负载，低配的服务器可能会扛不住；能否根据异构服务器的处理能力来动态、自适应进行负载均衡及过载保护？

二、service层的负载均衡通常是怎么做的
service.层的负载均衡，一般是通过service连接池来实现的，调用方连接池会建立与下游服务多个连接，每次请求“随机”获取连接，来保证service访问的均衡性。
“RPC-client实现细节”中提到，负载均衡、故障转移、超时处理等细节也都是通过调用方连接池来实现的。

三、通过“静态权重”标识servicel的处理能力
要打破这个随机性，最容易想到的方法，只要为每个下游servicei设置一个“权重”，代表service的处理能力，
来调整访问到每个service的概率，例如：
假设service-ip1,service-ip2,service-ip3的处理能力相同，可以设置weight1=1,weight2=1,weight3=1,这样
三个service连接被获取到的概率分别就
是1/3,1/3,1/3，能够保证均衡访问。
假设service-ip1的处理能力是service-ip2,service-ip3的
处理能力的2倍，可以设置weight1=2,weight22=1,weight3=1,这样三个service
连接被获取到的概率分别就是2/4,1/4,1/4，能够保证处理能力强的service分别到等比的流量，不至于资源浪费。
使用nginx做反向代理与负载均衡，就有类似的机制。
这个方案的优点是：简单，能够快速的实现异构服务器的负载均衡。
缺点也很明显：这个权重是固定的，无法自适应动态调整，而很多时候，服务器的处理能力是很难用一个固定的数值量化。

四、通过“动态权重”标识service的处理能力
1)用一个动态权重来标识每个service的处理能力，默认初始处理能力相同，即分配给每个service的概率相等；
2)每当service成功处理一个请求，认为service处理能力足够，权重动态+1；
3)每当service超时处理一个请求，认为service处理能力可能要跟不上了，权重动态-10（权重下降会更快）；
4)为了方便权重的处理，可以把权重的范围限定为[0，100],把权重的初始值设为60分。

举例说明：
假设service-ip1,service-ip2,service-ip3的动态权重初
始值weight1=weight2=weight3=60,刚开始时，
请求分配给这3台service的概率分别是60/180,60/180,60/180，即负载是均衡的。
随着时间的推移，处理能力强的service成功处理的请求越来越多，处理能力弱的service偶尔有超时，随着动态
权重的增减，
权重可能变化成了
weight1=100,weight2=60,weight3=40,
那么此时，请求分配给这3台service的概率分别是100/200,60/200,40/200，即处理能力强的service
会被分配到的流量。

五、过载保护
互联网软件架构设计中所指的过载保护，是指当系统负载超过一个service的处理能力时，如果service不进行自我保护，可能导致对外呈现处理能力为，且不能自动恢复的现象。
而service的过载保护，是指即使系统负载超过一个service的处理能力，service让能保证对外提供有损的稳定服务。
最简易的方式，服务端设定一个负载阈值，超过这个阈值的请求压过来，全部抛弃。这个方式不是特别优雅。



六、如何借助“动态权重”来实施过载保护
动态权重是用来标识每个service的处理能力的一个值，
它是RPC-client客户端连接池层面的一个东东。服务端处理超时，客户端RPC-client连接池都能够知道，这里只要实施一些策略，
就能够对“疑似过载”的服务器进行降压，而不用服务器“抛弃请求”这么粗暴的实施过载保护。
应该实施一些什么样的策略呢，例如：

1)如果某一个service的连接上，连续3个请求都超时，即连续-10分三次，客户端就可以认为，服务器慢慢的要处理不过来了，得给这个service缓一小口气，于是设定策略：接下来的若干时间内，例如1秒（或者接下来的若干个请求)，请求不再分配给这个service;

2)如果某一个service的动态权重，降为了0（像连续10个请求超时，中间休息了3次还超时)，客户端就可以认为，服务器完全处理不过来了，得给这个service喘一大口气，于是设定策略：接下来的若干时间内，例如1分钟(为什么是1分钟，根据经验，此时service一般在发生fullGC,差不多1分钟能回过神来)，请求不再分配给这个service;

3)可以有更复杂的保护策略…
这样的话，不但能借助“动态权重”来实施动态自适应的异构服务器负载均衡，还能在客户端层面更优雅的实施过载保护，在某个下游service快要响应不过来的时候，给其喘息的机会。
需要注意的是：要防止客户端的过载保护引起servicel的雪崩，如果“整体负载”已经超过了“service集群”的
处理能力，怎么转移请求也是处理不过来的，还得通过抛弃请求来实施自我保护。


七、总结
1)service的负载均衡、故障转移、超时处理通常是RPC-clienti连接池层面来实施的
2)异构服务器负载均衡，最简单的方式是静态权重法，缺点是无法自适应动态调整
3)动态权重法，可以动态的根据service的处理能力来分配负载，需要有连接池层面的微小改动
4)过载保护，是在负载过高时，service为了保护自己，保证一定处理能力的一种自救方法
5)动态权重法，还可以用做service的过载保护








~~~~~~~~~~~~~~~~~~~~~~27~~~~~~~~~~~~~
四层七层反向代理
正向代理
[proxy]代表[访问用向]，此时proxy:是代理在家访问xxoo网站，不希望xxoo网站trace到我们的真实
ip,于是就找一个proxy,通过proxy:来访问，此时proxy代表用户，网站以为proxyl的ip就是用户的ip。反向代理
[proxy]代表[被访问的服务器]，此时proxy是反向代理。
web-server:希望对用户屏蔽高可用、屏蔽web-server扩展、web-server内网ip等细节，于是就找了一个proxyl隔在中间，此时proxy代表web-server集群，用户以为proxy的ip就是被访问web-server的ip(web-
server是集群，具体访问了哪个web-server,用户不知道)，由于web-server集群有多台，此时反向代理服务器要具备负载均衡的功能。

典型拓扑：
客户端-正向代理-反向代理-服务器
正向代理中，代理服务器proxy与client同属于一个LAN局域网，对server透明
反向代理中，代理服务器proxy与server同属一个LAN局域网，对client:透明

nginx的正向代理配置
server
resolver114.114.114.114;
#指定DNS服务器IP地址
listen 80;
location /
proxy-pass http:/Shttp hostSrequest uri;#设定
代理服务器的协议和地址
proxy_set_header HOST Shttp_host;
proxy_buffers 256 4k;
proxy_max_temp_file_size Ok;
proxy_connect_timeout 30;
proxy_send_timeout 60;
proxy_read_timeout 60;
proxy_next_upstream error timeout
invalid_header http_502;
}
}
server
resolver114.114.114.114;
#指定DNS服务器IP地址
listen 443;
location /
proxy._pass https:/ShostSrequest _uri;#设定代理
服务器的协议和地址
proxy_buffers 256 4k;
proxy_max_temp_file_size Ok;
proxy_connect_timeout 30;
proxy_send_timeout 60;
proxy_read_timeout 60;
proxy_next_upstream error timeout invalid_header
http_502;
}
}
clienti立端：
一次代理，直接在shell执行：
#export http_proxy=http://192.168.1.9:8080
永久使用：
#vim .bashrc
export http_proxy=http://192.168.1.9:8080
#source .bashrc
nginx.反向代理配置
略
四层是指传输层，七层是指应用层。更具体的，对应到nginx反向代理hash:
四层：根据用户ip+port来做hash
七层：根据http协议中的某些属性来做hash
4层用的是NAT技术。NAT英文全称是“Network
Address Translation”,中文意思是“网络地址转换”，
请求进来的时候，nginx修改数据包里面的目标和源P和端口，然后把数据包发向目标服务器，服务器处理完成后，nginx再做一次修改，返回给请求的客户端。

7层代理：需要读取并解析http请求内容，然后根据具体
内容(url,参数，cookie,请求头)然后到相应的服务
器，的过程是：建立和目标机器的连接，然后请
求，收到响应数据在给请求客户端。

为什么中间少了几层？
回答：OSI应用层、表示层、会话层合并到TCP/IP的应用
层啦。
上面有四层，七层，那有没有二层，三层呢？
回答：有
二层：根据数据链路层MAC地址完成数据交换
三层：根据网络层P地址完成数据交换

HAProxy是一款提供高可用性、负载均衡以及基于
TCP(第四层)和HTTP(第七层)应用的代理软件，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。
HAProxy:特别适用于那些负载特大的web站点，这些站点
通常又需要会话保持或七层处理。HAProxy:运行在时下的
硬件上，完全可以支持数以万计的并发连接。并且它的
运行模式使得它可以很简单安全的整合进您当前的架构中，同时可以保护你的web服务器不被暴露到网络上。
由于4层代理用的是NAT,所以nginx不知道请求的具体内容，所以nginxl啥也干不了。
用7层代理，可以根据请求内容(url,参数，cookie,请求头)做很多事情，比如：
a:动态代理：不同的url到不同服务器。
b.风控：屏蔽外网IP请求某些敏感url;根据参数屏蔽某些刷单用户。
c.审计：在nginx层记录请求日志。

mysql等中间件的反向代理(tcp)。
stream
upstream mysql-server
hash Sremote_addr consistent;
server192.168.0.145:3306;
server192.168.0.146:3306;
}
server
listen 33306;
proxy_connect_timeout 1s;
proxy_timeout 3s;
proxy_pass mysql-server;
}
http
{
}
后端无状态的负载均衡(http反向代理)
http{
upstream appserver
server 10.0.0.12:8080 weight=2;
server 10.0.0.13:8080 weight=2;
}
server
listen
80;
server_name localhost;
location /
proxy_pass http://appserver;
}
}
}








~~~~~~~~~~~~~~~~~~~~~~28~~~~~~~~~~~~~
大型网站架构演化
大型网站的特点：高并发、大流量、高可用、海量数据等。

1.初始阶段的网站架构初始阶段都比较简单，通常一台服务器就可以搞定一个网站了。

2.应用服务和数据服务分离随着网站业务的发展，一台服务器逐渐不能满足需求；这时候就需要将应用和数据分离。

3.使用缓存改善网站性能
毫无疑问，现在的网站基本上都会使用缓存，即：80%的业务访问都会集中在20%的数据上。

4.使用应用服务器集群改善网站的并发处理能力
因为单一应用服务器能够处理的请求连接有限，在网站访问高峰时期，应用服务器会成为整个网站的瓶颈。因此使用负载均衡处理器势在必然。通过负载均衡调度服务器，可将来自浏览器的访问请求分发到应用的集群中的任何一台服务器上。

5.数据库读写分离
当用户达到一定规模后，数据库因为负载压力过高而成为网站的瓶颈。而目前主流的数据库都提供主从热备功能，
通过配置两台数据库主从关系，可以将一台数据库的数据更新同步到另一台服务器上。网站利用数据库这一功能实
现数据库读写分离，从而改善数据库负载压力。

6.使用反向代理和CDN加上网站相应提高网站的访问速度，主要手段有使用CDN和反向代理。CDN和反向代理的基本原理都是缓存，区别在于CDN部署
在网络提供商的机房，而反向代理是部署在网站的中心机房，当用户请求到达中心机房后，首先访问的反向代理，如果反向代理缓存着用户请求的资源，则直接返回给用户。

7.使用分布式文件系统和分布式数据库系统
任何强大的单一服务器都满足不了大型网站持续增长的业务需求。分布式数据库时网站数据库拆分的最后手段，只用在单表
数据规模非常大的时候才使用。不到不得已时，网站更常用的数据库拆分手段是业务拆分，将不同业务的数据部署在不同的物理服务器上。

8.使用NoSQL和搜索引|擎
搜素引擎也基本已经形成现在大型网站必须提供的功能了，网站需要采用一些非关系数据库技术如NoSQL和非数据库查询技术如搜索引擎。

9.业务拆分
大型网站为了应对日益复杂的业务场景，通过使用分而治之的手段将真个网站业务拆分成不同的产品线。

10.分布式服务
由于每一个应用系统都需要执行许多相同的业务操作，比如用户管理，session管理，那么可以将这些公用的业务提取出来，独立部署。












~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~29~~~~~~~~~~~~~
容量设计
(1)机器能抗住么？
(2)如果扛不住，需要加多少台机器？
(3)数据库需要分库么？
(4)如果需要分库，需要分几个库？
常见的容量评估包括数据量、并发量、带
宽、CPU/MEM/DISK等。

【步骤一：评估总访问量】
如何知道总访问量？对于一个运营活动的访问量评估，或者一个系统上线后PV的评估，有什么好的方法？
答案是：询问业务方，询问运营同学，询问产品同学，看对运营活动或者产品上线后的预期是什么。
举例：58要做一个APP-push的运营活动，计划在30分钟内完成5000w用户的push推送，预计push消息点击率10%,求push落地页系统的总访问量？
回答：5000W*10%=500W

【步骤二：评估平均访问量QPS】
如何知道平均访问量QPS?
答案是：有了总量，除以总时间即可，如果按照天评估，一天按照4w秒计算。
举例1：push落地页系统30分钟的总访问量是500W,求
平均访问量QPS
回答：500W/(30*60)=2778,大概3000QPS
举例2：主站首页估计日均pv8000w,求平均访问QPS
回答：一天按照4W秒算，8000W/4W=2000,大概2000QPS
提问：为什么一天按照4w秒计算？
回答：一天共24小时*60分钟*60秒=8W秒，一般假设所有请求都发生在白天，所以一般来说一天只按照4W秒评估

【步骤三：评估高峰QPS】
系统容量规划时，不能只考虑平均QPS,而是要抗住高峰的QPS,如何知道高峰QPS呢？
答案是：根据业务特性，通过业务访问曲线评估
举例：日均QPS为2000，业务访问趋势图如下图，求峰值QPS预估？
回答：从图中可以看出，峰值QPS大概是均值QPS的2.5倍，日均QPS为2000，于是评估出峰值QPS为5000。
说明：有一些业务例如“秒杀业务”比较难画出业务访问
趋势图，这类业务的容量评估不在此列。

【步骤四：评估系统、单机极限QPS】
如何评估一个业务，一个服务单机能的极限QPS呢？
答案是：压力测试
在一个服务上线前，一般来说是需要进行压力测试的（很
多创业型公司，业务迭代很快的系统可能没有这一步，那就悲剧了)，
以APP-push运营活动落地页为例（日均QPS2000,峰值QPS5000),这个系统的架构可能是这样的：

系统架构举例
1)访问端是APP
2)运营活动H5落地页是一个web站点
3)H5落地页由缓存cache、数据库db中的数据拼装而成通过压力测试发现，web层是瓶颈，tomcat压测单机只能
抗住1200的QPS(一般来说，1%的流量到数据库，数据库500QPS还是能轻松抗住的，cache的话QPS能抗住，需要评估cache的带宽，假设不是瓶颈)，
我们就得到了web单机极限的QPS是1200。一般来说，线上系统是不会跑满到极限的，打个8折，单机线上允许跑到QPS1000。

【步骤五：根据线上冗余度回答两个问题】
好了，上述步骤1-4已经得到了峰值QPS是5000，单机QPS是1000，假设线上部署了2台服务，就能自信自如的回答技术老大提出的问题了：
(1)机器能抗住么？->峰值5000，单机1000，线上2台，扛不住
(2)如果扛不住，需要加多少台机器？->需要额外3台，提前预留1台更好，给4台更稳除了并发量的容量预估，数据量、带宽、CPU/MEM/DISK等评估亦可遵循类似的步骤。

三、总结
互联网架构设计如何进行容量评估：
【步骤一：评估总访问量】
>询问业务、产品、运营
【步骤二：评估平均访问量QPS】
->除以时间，一天算4W秒
【步骤三：评估高峰QPS】
->根据业务曲线图来
【步骤四：评估系统、单机极限QPS】
->压测很重要
【步骤五：根据线上冗余度回答两个问题】
->估计冗余度与线上冗余度差值








~~~~~~~~~~~~~~~~~~30~~~~~~~~~~~~~
幂等的实现方案
在软件系统的开发过程中，我们可能有如下需求：
1)创建业务订单，一次业务请求只能创建一个；
2)单个订单请求调用支付接口，当遇到网络或系统故障请求重发，也应该只支付一次；
3)单个订单完成时，给用户发送消息应该只发一次；
4)等等很多情况下，都需要幂等的特性来支持。

幂等的概念
f(f(x))=f(x)
对应到软件开发领域，即为同样的请求被执行一次与连续
执行多次的效果是一样的，服务器的状态也是一样的，实际上就是接口的可重复调用（包括时间和空间上两个维度)。
不是要求返回值完全相同，而且是指后续多余的调用对系统的数据一致性不造成破坏。对于写入类操作，如果第一
次写入是成功的，后续的写入应该抛出异常或者空操作，或者执行了写入但是未对数据造成变化。对于读取类操
作，需要保证其实现上是真正的读取，不能在读操作中夹带写操作。

幂等实现方案
1.查询操作
查询一次和查询多次，在数据不变的情况下，查询结果都是一样的，select是天然的幂等操作。

2.操作
操作也是幂等的，一次和多次都是把数据删除。

3.建立唯一索引，防止新增脏数据
当表存在唯一索引，并发时新增重复记录就会报错，那么
这时候就查询已存在的记录并返回即可。

4.Token机制，防止页面重复提交
页面数据只能够提交一次，但是由于出现重复点击或者网络重发或Nginx重发等情况导致数据被重复提交的情况
下，可以采用Token+Redis(Redis是单线程的，处理需要排队)的解决方案。处理的流程是，在数据提交前要向服务器申
请带有有效时间的Token,然后Token放到Redis或JVM内存中，当数据正式提交到后台要校验Token并删除Token。首先服务器端生成一个token,传到前端，前端携带token
到服务器侧，token不存在或者失效就失败，否则认证成功立即token,这样第二次肯定失败的，只有第一次成功！

5.悲观锁
获取数据的时候加锁获取：
select from table where id ='xxx'for update;
要注意的是，id字段一定要是主键或者唯一索引引，否则会导致锁表。
悲观锁的使用一般伴随事务一起使用，数据锁定事件可能会很长，要根据实际情况慎用。

6.乐观锁
乐观锁只是在更新数据的那一刻锁表，其他时间不锁表，所以相对于悲观锁效率更高。
乐观锁的实现方式多种多样，可以通过version或者其他状态条件。

7.分布式锁
还是拿插入数据的例子，如果是分布式系统，构建全局唯
一索引比较困难，例如唯一性的字段无法确定。那么这时
候就可以引引入分布式锁，通过第三方的系统(Redis或Zookeeper),
在业务系统插入数据或更新数据，获取分布式锁，然后做操作，之后再释放锁。这样其实是把多线程并发锁的思路
引入了多个系统，也就是分布式系统中的解决思路。
要注意的是，某个长流程处理过程要求不能并发执行，可以在流程执行之前根据某个标志（用户D+后缀等）获取
分布式锁，其他流程执行时获取锁就会失败，也就是同一时间该流程只能有一个能执行成功，执行完成后，释放分布式锁（分布式锁需要第三方系统提供）)。

8.select+insert
对于一些并发不高的后台系统，或者一些任务Job,为了支持幂等，支持重复执行，简单的处理方法是先查询下一些关键数据，判断是否已经执行过，然后再进行业务处理就可以了。但是要注意的是核心高并发流程不要用这种方法，因为效率较低。

9.状态机幂等
在设计单据相关的业务，或者是任务相关的业务，肯定会涉及到状态机（状态变更图），就是业务单据上面有个状态，状态在不同的情况下会发生变更，一般情况下存在有限状态机，
这时候如果状态机已经处于下一个状态，却来了一个上一个状态的变更，理论上是不能够变更的，这样的话，保证了有限状态机的幂等。
要注意的是，订单等单据类业务，存在很长的状态流转，一定要深刻理解状态机，对业务系统设计能力提高有很大帮助。

10.总结
幂等性应该是一个合格程序员的基因，在设计系统的时候一定要考虑进去，尤其是像支付宝、银行、互联网金融公司等涉及的都是钱的系统，既要高效，也要准确，所以不能出现多扣款、多打款等问题，不然这样会很难处理，用户体验也不会好。






~~~~~~~~~~~~~~~~~~~~31~~~~~~~~~~~~~
手写QQ
0基础
OSI四层~
物理层
数据链路层RAP RARP
网络层PXXP(高速公路)
传输层TCP UDP(卡车)
会话层
表示层

*Socket层*（港口码头，在应用层和传输层之间的一个
抽象层)
应用层HTTP HTTPS FTP TELNET(货物)
TCP/IP四层~
网络接口层（物理+数据链路）
网络层
传输层
应用层（会话+表示+应用）

TCP(传输控制协议，Transmission Control
Protocol):(类似打电话)面向连接、传输可靠（保证数据正确性）、有序（保证数据顺序)、传输大量数据（流模式）、速度慢、对系统资源的要求多，程序结构较复杂，
每一条TCP连接只能是点到点的，
TCP首部开销20字节。
UDP(用户数据报协议，User Data Protocol):(类似发短信)
面向非连接、传输不可靠（可能丢包）、无序、传输量数据（数据报模式）、速度快，对系统资源的要求少，程序结构较简单，
UDP支持一对一，一对多，多对一和多对多的交互通信，
UDP的首部开销小，只有8个字节。

Websocket
Websocket协议解决了服务器与客户端全双工通信的问题。
注：什么是单工、半双工、全工通信？
信息只能单向传送为单工；
信息能双向传送但不能同时双向传送称为半双工；
信息能够同时双向传送则称为全双工。

websocket协议解析
wensocket协议包含两部分：一部分是“握手”，一部分是“数据传输”。
WebSocketi和Socket区别
可以把WebSocket想象成HTTP(应用层)，HTTP和Socket什么关系，WebSocket和Socketi就是什么关系。
HTTP协议有一个缺陷：通信只能由客户端发起，做不到服务器主动向客户端推送信息

1 Protobuf数据格式
优点：
json优点就是较XML格式更加小巧，传输效率较xml提高了很多，可读性还不错。
xml优点就是可读性强，解析方便。
protobuf优点就是传输效率快（据说在数据量大的时候，传输效率比xml和json快10-20倍)，序列化后体积相比
Json和XML很小，支持跨平台多语言，消息格式升级和兼容性还不错，序列化反序列化速度很快。

缺点：
json缺点就是传输效率也不是特别高（比xml快，但比
protobuf要慢很多)。
xml缺点就是效率不高，资源消耗过大。
protobuf缺点就是使用不太方便。

在一个需要大量的数据传输的场景中，如果数据量很大，那么选择protobufi可以明显的减少数据量，减少网络lO,从而减少网络传输所消耗的时间。
考虑到作为一个主打社交的产品，消息数据量会非常大，同时为了节约流量，所以采用protobuf是一个不错的选择。

2 TCP拆包与粘包
发生TCP粘包、拆包主要是以下原因：
1)、应用程序写入数据大于套接字缓冲区大小，会发生拆包。
2)、应用程序写入数据小于套接字缓冲区大小，网卡将应用多次写入的数据发送到网络上，这将会发送粘包。
3)、进行MSS(最大报文长度)大小的TCP分段，当TCP报文长度-TCP headert长度>MSS的时候会发生拆包。
4)、接收方法不及时读取套接字缓冲区数据，这将发生粘包。

既然知道TCP是无界的数据流，且协议本身无法避免粘(拆)包的发生。那我们只能再应用层数据协议上加以控制。通常再制定传输数据时，可以使用如下方法：
1)、使用带消息头的协议。消息头存储消息开始标识及消息长度信息，服务器获取消息头的时候解析出消息长度，然后向后读取该长度的内容。
2)、设置定长消息。服务器每次读取既定长度的内容作为一条完整消息。
3)、设置消息边界。服务器从网络流中按消息编辑分离出消息内容。

Netty.功能强大，预置了多种编解码功能，支持多种主流协议定制能力高，可以通过ChannelHandler对通信框架进行灵活地拓展
高性能，与目前多种NIO主流框架相比，Netty:综合性能最
高稳定性，解决了JDK NIO的BUG
Netty:提供的粘包拆包解决方案
1)、FixedLengthFrameDecoder
2)LineBasedFrameDecoder与DelimiterBasedFrameDecoder
3)LengthFieldBasedFrameDecoder与LengthFieldPrepender


3长连接握手认证


4心跳机制
维护任何一个长连接都需要心跳机制，客户端发送一个心跳给服务器，服务器给客户端一个心跳应答，这样就形成
客户端服务器的一次完整的握手，
这个握手是让双方都知道他们之间的连接是没有断开，客户端是在线的。如果超过一个时间的阈值，客户端没有收到服务器的应答，或者服务器没有
收到客户端的心跳，那么对客户端来说则断开与服务器的连接重新建立一个连接，对服务器来说只要断开这个连接即可。


5重连机制
客户端长连接断线重连机制


6消息重发机制
mq回调重发

7读写超时机制


8离线消息

9线程池

10AIDL跨进程通信













~~~~~~~~~~~~~~~~~~32~~~~~~~~~~~~~
构建网站高可用架构
@高可用HA(High Availability)是分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计减少系统不能提供服务的时间
很多公司的高可用目标是4个9，也就是99.99%，这就意味着，系统的年停机时间为8.76个小时。

@百度的搜索首页，是业内公认高可用保障非常出色的系统，甚至人们会通过www.baidu.com能不能访问来判
断“网络的连通性”，百度高可用的服务让人留下啦“网络通畅，百度就能访问”，“百度打不开，应该是网络连不上”的印象，这其实是对百度HA最高的褒奖。

@保证系统高可用，架构设计的核心准则是：冗余。有了冗余之后，还不够，每次出现故障需要人工介入恢复
势必会增加系统的不可服务实践。所以，又往往是通过“自动故障转移”来实现系统的高可用。

@常见互联网分布式架构如上，分为：
(1)客户端层：典型调用方是浏览器browser或者手机应用APP;
(2)反向代理层：系统入口，反向代理，nginx;
(3)站点应用层：实现核心应用逻辑，返回html或者json,前后端分离，这里是前端；
(4)服务层：如果实现了服务化，就有这一层，后端；
(5)数据-缓存层：缓存加速访问存储
(6)数据-数据库层：数据库固化数据存储整个系统的高可用，又是通过每一层的冗余+自动故障转移来综合实现的。

@解决方案
(1)【(客户端层】到（反向代理层】的高可用，
是通过反向代理层的冗余实现的，常见实践是keepalived+virtual IP自动故障转移以nginx为例：有两台nginx,一台对线上提供服务，另一
台冗余以保证高可用，常见的实践是keepalived存活探测，相同virtual IP提供服务。自动故障转移：当nginx挂了的时候，keepalived能够探测到，会自动的进行故障转移，将流量自动迁移到shadow-
nginx,由于使用的是相同的virtual IP,这个切换过程对调用方是透明的。

(2)【反向代理层】到【站点层】的高可用，
是通过站点层的冗余实现的，常见实践是nginx与web-server之间的存活性探测与自动故障转移
假设反向代理层是nginx,nginx.conf里能够配置多个web后端，并且nginxi能够探测到多个后端的存活性。自动故障转移：当web-server:挂了的时候，nginx能够探测到，会自动的进行故障转移，将流量自动迁移到其他的eb-server,整个过程由nginx自动完成，对调用方是透明的。

(3)【站点层】到【服务层】的高可用，
是通过服务层的冗余实现的，常见实践是通过service-connection-pool来保证自动故障转移
自动故障转移：当service挂了的时候，service-connection-pool能够探测到，会自动的进行故障转移，
将流量自动迁移到其他的service,整个过程由连接池自动完成，对调用方是透明的（所以说RPC-client中的服务连接池是很重要的基础组件)。

(4)【服务层】到【缓存层】的高可用，
是通过缓存数据的冗余实现的，常见实践是缓存客户端双读双写，或者利用缓存集群的主从数据同步与sentinel保
活与自动故障转移；的业务场景，对缓存没有高可用要求，可以使用缓存服务化来对调用方屏蔽底层复杂性
以redis为例，redis天然支持主从同步，redis官方也有sentinell哨兵机制，来做redis的存活性检测。
自动故障转移：当service挂了的时候，service-
connection-pool能够探测到，会自动的进行故障转移，
将流量自动迁移到其他的service,整个过程由连接池自动完成，对调用方是透明的（所以说RPC-client中的服务连接池是很重要的基础组件)。

(4)【(服务层】到【缓存层】的高可用，
是通过缓存数据的冗余实现的，常见实践是缓存客户端双读双写，或者利用缓存集群的主从数据同步与sentinel保活与自动故障转移；的业务场景，
对缓存没有高可用要求，可以使用缓存服务化来对调用方屏蔽底层复杂性
以redis为例，redis天然支持主从同步，redis官方也有sentinell哨兵机制，来做redis的存活性检测。
自动故障转移：当redis主挂了的时候，sentinel能够探测到，会通知调用方访问新的redis,整个过程由sentinel和redis:集群配合完成，对调用方是透明的。

(5)【服务层】到【数据库“读”】的高可用，
是通过读库的冗余实现的，常见实践是通过db-connection-pool来保证自动故障转移
自动故障转移：当读库挂了的时候，db-connection-pool能够探测到，会自动的进行故障转移，将流量自动迁移到其他的读库，整个过程由连接池自动完成，对调用方是透明的（所以说DAO中的数据库连接池是很重要的基础组件)。

(6)【服务层】到【数据库“写”】的高可用，
是通过写库的冗余实现的，常见实践是keepalived+virtual IP自动故障转移
自动故障转移：当写库挂了的时候，keepalived能够探测到，会自动的进行故障转移，将流量自动迁移到shadow-db-master,由于使用的是相同的virtual IP,这个切换过程对调用方是透明的。







~~~~~~~~~~~~~~~~~~~~~~37~~~~~~~~~~~~~
线程数究竟设多少合理?
核服务器，通过执行业务的单线程分析出本地计算时间为x,等待时间为y,则工作线程数（线程池线程数）设置为N*(x+y)/x,能让CPU的利用率最大化。
一般来说，非CPU密集型的业务（加解密、压缩解压缩、搜索排序等业务是CPU密集型的业务)，
瓶颈都在后端数据库，本地CPU计算的时间很少，所以设置几十或者几百个工作线程也都是可能的。

如果是10密集型应用，则线程池大小设置为2+1，假设
我的服务器是4核的，且一般进行服务数据库，本地计算很少，那么线程池数量设置为9为最优。
如果是CPU密集型应用，则线程池大小设置为N+1,假设我的服务器是4核的，且一般进行大数据运算，cpu消耗较大，那么线程池数量设置为5为最优。0密集型，即该任务需要大量的0，即大量的阻塞。
在单线程上运|O蕊集型的任务会导致浪费大量的CPU运算能力浪费在等待。
所以在密集型任务中使用多线程可以大大的加速程序运行，即使在单核CPU上，这种加速主要就是利用了被浪费掉的阻塞时间。密集型时，大部分线程都阻塞，故需要多配置线程数：
参考公式：CPU核数/(1-阻系数)
比如8核CPU:8/(1.0.9)=80个线程数
阻塞系数在0.8~0.9之间













~~~~~~~~~~~~~~~~~~39~~~~~~~~~~~~~
进程内缓存
进程内缓存与进程外缓存相比(Redis、memcache),没有网络开销，节省了内网带宽，响应延时更低。但如果
应用集群部署，缓存是在每个服务节点内，数据存了多份，一致性比较难保障。其实就是HashMap这些；
如何保证进程内缓存的数据一致性？
第一种方案，可以通过单节点通知其他节点。不好。
第二种方案，可以通过MQ通知其他节点。前两种方案，节点数量越多，数据冗余份数越多，数据同时更新的原子性越难保证，一致性也就越难保证。
第三种方案，为了避免耦合，降低复杂性，干脆放弃了“实时一致性”，每个节点启动一个timer,定时从后端拉取最新的数据，更新内存缓存。
可以看到，站点与服务的进程内缓存，实际上违背了分层
架构设计的无状态准则，故一般不推荐使用。末了，再次强调，进程内缓存的适用场景并不如redis/memcache广泛，不要为了炫技而使用。






~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~40~~~~~~~~~~~~~
阿里云故障
2019-03-03,阿里云部分瘫痪。
1.能不能快速进行服务器扩容；画外音：昨晚我们迅猛购买了50台ECS,这是云的好处。
2.知道了受影响的服务器P,如何能够快速确定这些P上部署了哪些站点与服务？这些站点与服务的上下游是什么，连带影响范围是什么？
画外音：这是有待提高的地方，每个负责人都知道自己的P上部署了什么，但并不可视化。
3.如何快速站点与服务扩容与缩容，如何服务发现，如何迁移流量？
画外音：服务治理，任重道远。骂阿里云不解决问题，这次事故过程中发现的自身的问题，我们要继续去改进。
特别是服务治理体系，可视化监控与运维体系，任重而道远。
















~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~41~~~~~~~~~~~~~
阿里巴巴的26款超神Java开源项目

1.分布式应用服务开发的一站式解决方案Spring Cloud
Alibaba
Spring Cloud Alibaba致力于提供分布式应用服务开发的一站式解决方案。此项目包含开发分布式应用服务的必需
组件，方便开发者通过Spring Cloud编程模型轻松使用
这些组件来开发分布式应用服务。
依托Spring Cloud Alibaba,您只需要添加一些注解和少量配置，就可以将Spring Cloud应用接入阿里分布式应
用解决方案，通过阿里中间件来迅速搭建分布式应用系统。

Nacos:一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。

Sentinel:把流量作为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。

RocketMQ:开源的分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。

Dubbo/SOFA-RPC:这个就不用多说了，在国内应用非常广泛的一款高性能Java RPC框架。
Seata:阿里巴巴开源产品，使用@GlobalTransactional
注解，在微服务中传递事务上下文，可以对业务零侵入地解决分布式事务问题。

Arthas:开源的Java动态追踪工具，基于字节码增强技
术，功能非常强大

2.JDBC连接池、监控组件Druid
Druid是一个JDBC组件。
1).监控数据库访问性能。.提供了一个高效、功能强大、可扩展性好的数据库连接池。
3).数据库密码加密。
4.SQL执行日志。

3.Java的JSON处理器fastison
fastjson是一个性能很好的Java语言实现的JSON解析器和生成器，来自阿里巴巴的工程师开发。
主要特点：快速FAST(比其它任何基于Java的解析器和生
成器更快，包括jackson);强大（支持普通JDK类包括任意Java BeanClass、Collection、Map、Date或enum);零依赖（没有依赖其它任何类库除了JDK)。

4.服务框架Dubbo
Apache Dubbo(incubating)|是阿里巴巴的一款高性能、轻量级的开源Java RPC框架，它提供了三大核心能力：
面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。

5.企业级流式计算引擎JStorm
JStorm是参考Apache Storm实现的实时流式计算框架，在网络、线程模型、资源调度、可用性及稳定性上
做了持续改进，已被越来越多企业使用，性能比storm更好；
JStorm可以看作是storm的java增强版本，除了内核用
纯java实现外，还包括了thrift、python、facet ui。
从架构上看，其本质是一个基于K的分布式调度系统。
现有Storm无法满足一些需求（无法定制化，Storm任务分配不平衡，RPC OOM一直没有解决，监控太简单，对ZK访问频繁)

6.分布式数据层TDDL
TDDL是一个基于集中式配置的jdbc datasource实现，具有主备切换，读写分离，分表分库，动态数据库配置等功能。

7.淘宝定制JVM:TaobaoJVM
TaobaoJVM基于OpenJDK HotSpot VM,是国内第一个优化、定制且开源的服务器版Java虚拟机。
目前已经在淘宝、天猫上线，全部替换了Oracle官方JVM版本，在性能，功能上都初步体现了它的价值。

8.Java图片处理类库Simplelmage
Simplelmage:是阿里巴巴的一个Java图片处理的类库，可以实现图片缩略、水印等处理。

9.redis的java客户端Tedis
Tedis是另一个redis的java客户端。Tedis的目标是打造一个可在生产环境直接使用的高可用Redis解决方案。

10.开源Java诊断工具Arthas
Arthas(阿尔萨斯)是阿里巴巴开源的Java诊断工具，深受开发者喜爱。
Arthas采用命令行交互模式，同时提供丰富的Tab自动补全功能，进一步方便进行问题的定位和诊断。

13.动态服务发现、配置和服务管理平台Nacos
Nacos致力于帮助您发现、配置和管理微服务。Nacos提供了一组简单易用的特性集，帮助您实现动态服务发现、服务配置管理、服务及流量管理。
Nacos帮助您更敏捷和容易地构建、交付和管理微服务平台。Nacos是构建以“服务”为中心的现代应用架构（例如微服务范式、云原生范式)的服务基础设施

14.Java解析Excel工具easyexcel
Java解析、生成Excel比较有名的框架有Apache
poi、jxl。但他们都存在一个严重的问题就是非常的耗内存，poi有一套SAX模式的API可以一定程度的解决一些内存溢出的问题，但P01还是有一些缺陷，比如07版
Excel解压缩以及解压后存储都是在内存中完成的，内存消耗依然很大。easyexcel重写了poi对07版Excel的解析，能够原本一个3M的excel用POI sax依然需要
100M左右内存降低到KB级别，并且再大的excel不会出现内存溢出，03版依赖PO1的sax模式。在上层做了模型转换的封装，让使用者更加简单方便。

15.高可用流量管理框架Sentinel
Sentinel是面向微服务的轻量级流量控制框架，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。
只要通过Sentinel APl定义的代码，就是资源，能够被Sentinel保护起来。大部分情况下，可以使用方法签名，URL,甚至服务名称作为资源名来标示资源。

16.基于多维度Metrics的系统度量和监控中间件
SOFALookout
Lookout是一个利用多维度的netrics对目标系统进行度量和监控的项目。Lookout的多维度metrics参考
Metrics2.0标准。Lookout项目分为客户端部分与服务器端部分。
客户端是一个Java的类库，可以将它植入您的应用代码中采集metrics信息，客户端。服务端代码部分，将于下一版本提供。通过LOOKOUT的服务，可以对metrics数据进行收集、加工、存储和查询等处理，另外结合grafana,可做数据可视化展示。

19.分布式链路追踪中间件S0 FATracer
SOFATracer是一个用于分布式系统调用跟踪的组件，通过统一的traceld将调用链路中的各种网络调用情况以日志的方式记录下来，以达到透视化网络调用的目的。这些日志可用于故障的快速发现，服务治理等。

20.高性能Java RPC框架SOFARPC
SOFARPC是一个高可扩展性、高性能、生产级的JavaRPC框架。在蚂蚁金服SOFARPC已经经历了十多年及五代版本的发展。
SOFARPC致力于简化应用之间的RPC调用，为应用提供方便透明、稳定高效的点对点远程服务调用方案。为了用户和开发者方便的进行功能扩展，SOFARPC提供了丰富的模型抽象和可扩展接口，包括过滤器、路由、负载均衡等等。同时围绕SOFARPC框架及其周边组件提供丰富的微服务治理方案。


21.基于Netty的网络通信框架SOFABolt
SOFABolt是蚂蚁金融服务集团开发的一套基于Netty实现的网络通信框架。为了让Java程序员能将的精力放在基于网络通信的
业务逻辑实现上，而不是过多的纠结于网络底层O的实现以及处理难以调试的网络问题，Netty应运而生。
为了让中间件开发者能将的精力放在产品功能特性实现上，而不是重复地一遍遍制造通信框架的轮子，SOFABolt应运而生。

22.动态非侵入A0P解决方案JVM-Sandbox
JVM-Sandbox,JVM沙箱容器，一种基于JVM的非侵入式运行期AOP解决方案。

23.面向云的分布式消息领域标准OpenMessaging
OpenMessaging是由阿里巴巴发起，与雅虎、滴滴出行、Streamlio公司共同参与创立，旨在创立厂商无关、平台无关的分布式消息及流处理领域的应用开发标准。

24.P2P文件分发系统Dragonfly
Dragonfly(蜻蜓)是阿里自研的P2P文件分发系统，用于解决大规模文件分发场景下分发耗时、成功率低、带宽浪费等难题。大幅提升发布部署、数据预热、大规模容器镜像分发等业务能力。
开源版的Dragonfly可用于P2P文件分发、容◇镜像分发、局部限速、磁盘容量预检等。它支持多种容器技术，对容器本身无需做任何改造，镜像分发比natvie方式提速可高达57倍，








~~~~~~~~~~~~~~~~~~42~~~~~~~~~~~~~
高并发程序设计入门
响应时间：系统对请求做出响应的时间。例如系统处理一个HTTP请求需要200ms,这个200ms就是系统的响应时间。
吞吐量：单位时间内处理的请求数量。
QP:每秒响应请求数。在互联网领域，这个指标和吞吐量区分的没有这么明显。
并发用户数：同时承载正常使用系统功能的用户数量。例如一个即时通讯系统，同时在线量一定程度上代表了系统的并发用户数。互联网分布式架构设计，提高系统并发能力的方式，

方法论上主要有两种：
垂直扩展(Scale Up)与水平扩展(Scale Out)。

垂直扩展：提升单机处理能。垂直扩展的方式又有两种：
(1)增强单机硬件性能，例如：增加CPU核数如32核，升级更好的网卡如万兆，升级更好的硬盘如SSD,扩充硬盘容量如2T,扩充系统内存如128G;
(2)提升单机架构性能，例如：使用Cache:来减少O次数，使用异步来增加单服务吞吐量，使用无锁数据结构来减少响应时间

不管是提升单机硬件性能，还是提升单机架构性能，都有
一个致命的不足：单机性能总是有极限的。所以互联网分布式架构设计高并发终极解决方案还是水平扩展。
水平扩展：只要增加服务器数量，就能线性扩充系统性能。水平扩展对系统架构设计是有要求的，如何在架构各层进行可水平扩展的设计，以及互联网公司架构各层常见的水平扩展实践，是本文重点讨论的内容。

反向代理层的水平扩展
反向代理层的水平扩展，是通过“DNS轮询”实现的：dns-server对于一个域名配置了多个解析ip,每次DNS解析请求来访问dns-server,会轮询返回这些ip。
当nginx.成为瓶颈的时候，只要增加服务器数量，新增nginx服务的部署，增加一个外网ip,就能扩展反向代理
层的性能，做到理论上的无限高并发。站点层的水平扩展站点层的水平扩展，是通过“nginx”实现的。通过修改nginx.conf,可以设置多个web后端。
当web后端成为瓶颈的时候，只要增加服务器数量，新增web服务的部署，在nginxi配置中配置上新的web后端，就能扩展站点层的性能，做到理论上的无限高并发。

服务层的水平扩展
服务层的水平扩展，是通过“服务连接池”实现的。
站点层通过RPC-client调用下游的服务层RPC-server时，RPC-clientr中的连接池会建立与下游服务多个连接，
当服务成为瓶颈的时候，只要增加服务器数量，
新增服务部署，在RPC-client处建立新的下游服务连接，就能扩展服务层性能，做到理论上的无限高并发。如果需
要优雅的进行服务层自动扩容，这里可能需要配置中心里服务自动发现功能的支持。

数据层的水平扩展
在数据量很大的情况下，数据层（缓存，数据库）涉及数据的水平扩展，将原本存储在一台服务器上的数据（缓存，数据库)水平拆分到不同服务器上去，以达到扩充系统性能的目的。
高并发(High Concurrency)是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计保证系统能够同时并行处理很多请求。
提高系统并发能力的方式，方法论上主要有两种：垂直扩展(Scale Up)与水平扩展(Scale Out)。前者垂直扩展可以通过提升单机硬件性能，或者提升单机架构性能，来提高并发性，但单机性能总是有极限的，互联网分布式架构设计高并发终极解决方案还是后者：水平扩展。

互联网分层架构中，各层次水平扩展的实践又有所不同：
(1)反向代理层可以通过“DNS轮询”的方式来进行水平扩展；
(2)站点层可以通过nginx来进行水平扩展；
(3)服务层可以通过服务连接池来进行水平扩展；
(4)数据库可以按照数据范围，或者数据哈希的方式来进行水平扩展；各层实施水平扩展后，能够通过增加服务器数量的方式来提升系统的性能，做到理论上的性能无限。










-------------------- DDD 架构 --------------------------

附图：
微服务生态圈蓝色
微服务模块黑色
微服务工程红色
微服务组件深灰
备注信息黄色
依赖关系红色箭头
原生态的微服务解决方案
开源微服务生态圈

spring-boot-starter springboot微服务组件
springcloud服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控
dubbo阿里高性能RPC的服务框架
serviceComb微服务开发的一站式解决方案，分布式事务
Saga
service meth微服务架构的核心技术
spring cloud alibaba阿里产品，基于springcloud提供微服务开发的一站式解决方案基于开源组件对公司或组织特有的能力进行封装，如$SO,认证，公共服务等公司/组织级微服务生态圈
jalor-starter-core核心能力
jalor-starter-crud数据库操作
jalor-auth安全，sso,jwt等能力
jalor-starter-eureka服务注册与发现
jalor-starter-usf微服务熔断+调用跟踪+监控对产品或项目特有的能力进行定义和封装，比如公共的返回值，DTO,异常等。每个module可独立deploy到私服，下面的微服务按需引入产品/项目级别starter组件
pcloud-base-starter pom文件，统一的父pom,规定统一的依赖包版本(dependencyManagement)定义deploy发布库配置(distributionManagement)
pcloud-base-starter-core jar文件，定义每个微服务公共的类(Apiresult,BaseDTO,BaseEntity,exception等)定义所有微服务公用的工具类，异常等，定义RPC调用方(HAE,REST等)
pcloud-base-starter-security jar文件定义常用的RSA,DES等加解密能力，数字签名，安全随机数等安全能力
pcloud-base-starter-sms jar文件定义通用的短信发送能力
DDD分层架构中的低层组件应该依赖于高层组件提供的接口，即无论高层还是低层都依赖于抽象，整个分层架构被推平了。形成六边形架构，每个输入和输出由不同的适配器（抽象）完成
abc-parent
Api(接口层)abc-api(如果api业务过多，可以按模块拆分不同的module.)api定义api的uri,method,swagger注解，requestDto,
responseDTO名字
dto定义每个api的出参和入参具体的dto类；
dto共用：
1)api.jar可以deploy到私服，被调用方引用，共用一个dto.
2)api的module.工程不要在parent.pom强行依赖所有的包，按需引入。
App(应用层)abc-app
api api实现类，不包含任何业务逻辑，调用applicationService,安全认证，权限校验，持久化事务控制，或者向其他系统发生基于事件的消息通知
application应用服务层，控制本地事务，编排和协调领域服务共同完成应用服务，防止接口滥用，直接单例
bean模式，代码精简化。
main(springboot应用启动入口
properties springboot.应用配置项，如上下文根端口号
log4j日志文件

接口滥用表现：
1)没有考虑是否有多实现，完全遵从于大家都是这样使用，面向抽象不是面向约定编程。
2)接口方法过多，精心设计的接口，接口方法一般比较精简，才可能有多个实现类。
3)造成了代码复杂化，未达到精简化的目的。
Domain(领域层)abc-domain(如果领域业务复杂，可以按领域拆分不同的module.)
factory抽象工厂，builder构造器，产生实体实例，或者接口实现实例；
model实体，聚合根，值对象，entity:集合
service领域服务层，调用领域仓储层，被应用服务层调用；防止接口滥用，可以省略接口，直接XXXService;
constants领域特有的常量，其他domain不涉及；
enums领域特有的枚举值，其他domain不涉及；
reposirity领域仓储层接口，由基础实施层中的
persistence:实现，操作对象是聚合，领域仓储不关心如
何持久化，持久化到哪，面向的是领域业务，不关心技术
如何实现。仓储层是领域层唯一出入口。

接口使用规范：
1)一个行为已经有多个实现或者有这种趋势的情况需要使用接口。
2)一些设计模式需要使用，如策略模式，桥梁模式，模板方法模式，代理模式等，
3)一些使用动态代理技术实现的使用接口，如Dubbo,Mybatis,数据库连接池等。
4)一些以依赖反转为目的的使用接口，如仓储层。
5)接口常量类，使用接口。
6)接口首字母需要遵守以大写字母开头。
Infrastructure(基础设施核心层)abc-infrastructure
util工具类，类似commons-*包，异常定义和处理等
system系统层级类
aop AOP,注解，jdk/cglib动态代理等，如权限，事务，审计日志等
interceptor可选，系统拦截器，如mybatis分页等
log可选，日志处理器，如log4j日志插件等
listener可选，系统监听器，如
CommandLineRunner
ApplicationEvent
ApplicationListener,ServletRequestListener
postProcessor可选，spring侵入式（比如bean后置处理器)等，如dubbo
configuration可选，springboot配置器，如
SwaggerConfig,ThreadPoolConfig,Autoconfigure,Myba
tisPlusConfig,ShiroConfig
constants整个微服务公共的常量，被多个domain使用，不要重复定义；
enums整个微服务公共的枚举值，被多个domain使用，不要重复定义；


Infrastructure-persistence(基础设施持久层)abc-
infrastructure-persistence
reposirity领域层的仓储接口实现类，依赖领域层，依赖反转解耦，修改持久层不影响领域层的修改，对持久层的编排，按需编排；根据实际情况调用mybatis、mongo
client.、redis client完成实际的存储层操作
dao关系数据库的操作，mybatis接口，底层动态代理实现，把信息持久化到关系数据库
nosql nosql数据库的配置，文档数据库或列式数据库，把信息持久化到nosql服务器
config配置类，如操作分布式配置，把信息持久化到配置服务器
q可选，消息队列的配置，发送、监听，把信息持久化到mq服务器
external可选，操作外部服务数据，调用starter-core包的
rpc调用组件，根据实际情况实例化，把信息持久化到rpc服务器
search可选，写入搜索引擎，把信息持久化到搜索引引擎服务器
registers可选，写入注册中心，把信息持久化到注册中心
nfs可选，生成特定文件，把信息持久化到分布式文件系统服务器
ss可选，发送短信，把信息持久化到短信服务器
email可选，发送邮件，把信息持久化到邮件服务器

持久层范围：
1)持久到关系数据库，如mysql,db2
2)生成特定文件，如分布式文件系统NFS
3)操作nosql,如redis,mongodb,hbase
4)发送mq消息，如kafka,rocketMq
5)操作分布式配置，如apollo,gitlab,scc
6)操作外部服务数据，如RPC接口
7)写入注册中心，如写入zk,consul,etcd等
8)写入搜索引擎，如ElasticSearch,solr
9)发送短信，sms
10)发送邮件，email
11)无限扩展。。。











~~~~~~~~~~~~~~~~~~~~~~44~~~~~~~~~~~~~
大秒杀全集
海涯认为的高并发系统通常要解决2类问题：质量
1)质：线程安全问题，避免超卖，避免扣款不一致；
2)量：抗住大批量并发请求，高并发读取
对于一个互联网平台来说，高并发是经常会遇到的场景。
最有代表性的比如秒杀和抢购。高并发会出现个特点：

1、高并发读取
方案1
先读取redis的缓存数据，如果有直接返回；
如果没有，通过DAO读取数据库的数据，并写入缓存（可异步），再返回；
这个方案是非常常用的方案，那么有缺点么？
我们仔细想想假如缓存失效，访问DB出现慢查询会怎么样？
通常慢查询会导致大部分的请求超时，如果qs很高，数据库层的连接数会持续增高直至打满，导致后续的请求直接被拒绝出现数据库雪崩。

方案2：基于双缓存+重试机制的数据库访问
这种方案提供了一种折中的思路，既然数据库的获取可能出现问题，那么我们能否弄一个相对不那么容易过期的缓存，一旦数据库获取失败（重试多次后），可以访问备用缓存来获取老数据（同时写入Keep up缓存来
保证数据库连接不陡增)，这样对于用户来说不会造成很大的体验降级。所以，这种方案的思路如下：
先访问Keep up Cache,如果命中直接返回；
如果没有命中，带次重试去访问数据库，如果成功，及时更新Keep up Cache和Backup Cache,并返回；
如果数据库访问失败了，输出错误日志，并访
问Backup Cache来获取老数据，同时写入Keep upCache;
一般我们不建议缓存设置永久有效，不过对于
Backup Cache我们可以设置一个相对较长的有效期来保
证在这个长时间内，假如数据库出现问题，能够保证服务不降级，而这个时间足够解决数据库慢查询问题。
这个设计，第一个缓存的根本目的是触发数据更新，第二个缓存是备用缓存。

2、高并发写入（超卖一致性问题）
出现的原因2和线程分别计算出扣款数目同时进行修改，
线程2不知道线程1已经改过了，修改结果不可见，导致线程2覆盖了线程1的修改结果；
解决方案大致是分布式锁但是影响并发量，最好方案就是版本号的乐观锁。

读多写少，
当多个进程同时操作同一个数据，会产生资源争抢，数据一致性的问题。
高并发情况下，涉及到写操作时，不可能直接操作数据库，大并发的连接会导致mysqli请求会阻塞，比
如大量的insert update请求到，会直接导致无数的行锁和表锁，甚至最后堆积很多，从来触发too manyconnections错误。

(1)消息队列：
将票数资源存在redisl中，将请求存入消息队列
(redis下的list阻塞的，可以实现消息队列，还可以实现优先消息队列点击打开链接)中，依次处理。缺点：这
样会处理比较慢，等待时间比较长。对于读操作是否也进入队列，这个问题根据具
体的场景，像12306应该是不在队列中或者是优先排在最前面的，因为只是读，要求块。

(2)加锁
常见的锁：排它锁；乐观锁；悲观锁；
排他锁：在进行写时，禁止一切的读和写；
乐观锁：认为在写的时候，别人不在写，维
护一个version号，等处理后对照version好，一致则对，否则回滚，操作不成功，
悲观锁：认为在写的时候，别人也在写。采
用数据库提供的锁机制：在写操作的时(insert updata
等)myisam默认是锁表，innodb根据是否是主键，主键则行锁，否则表锁。读操作，innodb采用mvcc版本控制。
可以采用乐观锁+回滚：

2013年的小米秒杀吗？三款小米手机各11万台开卖，走的都是大秒系统，3分钟后成为双十一第一家也是最快破亿的旗舰店。经过日志统计，
前端系统双11峰值有效请求约60W以上的QPS,而后端
cache的集群峰值近2000w/s、单机也近30w/s,但到真正的写时流量要小很多了，当时
最高下单减库存tps是红米创造，达到1500/s。
秒杀业务的典型特点有：
1.瞬时流量大
2.参与用户多，可秒杀商品数量少
3.请求读多写少
4.秒杀状态转换实时性要求高
同样是高并发场景，三类业务的架构挑战不一样：
1)QQ类业务，用户主要读写自己的数据，访问基本带有uid属性，数据访问锁冲突较小
2)微博类业务，用户的feed主页由别人发布的消息构成，数据读写有一定锁冲突
3)12306类业务，并发量很高，几乎所有的读写锁冲突都集中在少量数据上，难度最大秒杀系统设计的第一个原则就是将这种热点数据隔离出来，不要让1%的请求影响到另外的99%，隔离出来后也更方便对这1%的请求做针对性优化。

@业务隔离：把秒杀做成一种营销活动，卖家要参加秒杀这种营销活动需要单独报名，从技术上来说，卖家报名后对我们来说就是已知热点，当真正开始时我们可以提前做好预热。

@系统隔离：系统隔离是运行时的隔离，可以通过分组部署的方式和另外99%分开。秒杀还申请了单独的域名，目的也是让请求落到不同的集群中。

@数据隔离：秒杀所调用的数据大部分都是热数据，比如会启用单独cache:集群或MySQL数据库来放热点数据，目前也是不想0.01%的数据影响另外99.99%。

@动静分离：把90%的静态数据缓存在用户端或者CDN上，当真正秒杀时用户只需要点击特殊的按钮“刷新抢宝”即可，而不需要刷新整个页面，这样只向服务端请求很少的有效数据，而不需要重复请求大量静态数据。
基于时间分片削峰：
秒杀答题一个很重要的目的是为了防止秒杀器，2011年秒杀非常火的时候，秒杀器也比较猖獗，而没有达到全民
参与和营销的目的，所以增加的答题来限制秒杀器。增加答题后，下单的时间基本控制在2s后，秒杀器的下单
比例也下降到5%以下。增加答题还有一个重要的功能，就是把峰值的下单请求给拉长了，从以前的1$之内延长到2~10$左右，请求峰值基于时间分片了，这个时间的分片对服务端处理并发非常重要，会减轻很大压力，另外由于请求的先后，靠后的请求自然也没有库存了。

先做数据的动静分离
将90%的数据缓存在客户端浏览器
将动态请求的读数据Cache在Web端
对读数据不做强一致性校验
对写数据进行基于时间的合理分片
对写请求做限流保护
对写数据进行强一致性校验
(1)将请求尽量拦截在系统上游（不要让锁冲突落到数据库上去)。传统秒杀系统之所以挂，请求都压倒了后端数据层，数据读写锁冲突严重，
并发高响应慢，几乎所有请求都超时，流量虽大，下单成功的有效流量甚小。以12306为例，一趟火车其实只
有2000张票，200W个人来买，基本没有人能买成功，请求有效率为。

(2)充分利用缓存，秒杀买票，这是一个典型的读多些
少的应用场景，大部分请求是车次查询，票查询，下单和支付才是写请求。一趟火车其实
只有2000张票，200W个人来买，最多2000个人下单成功，其他人都是查询库存，写比例只有0.1%，读比例占99.9%，非常适合使用缓存来优化。

这种方法，可能会有一个问题，既然限制了请求数，那就
必须要保证放过去的用户能够秒完商品，假设有重复提交的用户，如果重复提交的量大，
比如放过去的请求中有一半都是重复提交，就会造成最后没秒完的情况，怎么屏蔽重复用户呢？就要有个地方来记参与的用户id,可以使用redis的set结构来保存，这个时候set的size代表当前排队的用
户数，扣库存之前add当前用户id到set,根据add是否成
功的结果，来判断是否继续处理请求。后台服务器~
阻塞队列，发起秒杀先去问排队队列是不是已满，满了直接秒杀失败



乐观锁
限流
缓存Redis,内存
异步
抢票的线程安全

1.分库存一般这样做就已经能够满足常规秒杀的需求了，
但有一个问题依然没有解决，那就是加锁扣库存依然很慢假设的活动秒杀的商品量能够再上一个量级，像小米卖个手机，一次有几W到几十万的时候，数据库也是扛不住这个量的，可以先把库存数放在redis.上，
然而单一库存加锁排队依然存在，库存这个热点数据会成为扣库存的瓶颈。
一个解决的办法是分库存，比如总共有50000个秒杀名额，可以分50份，放在redis.上的50个不同的key,那么每
份上1000个库存，用户进入秒杀流程后随机到其中一个库存来修改，这样有50个库存数来竞争，缩短请求的排时间。
这样专门为高并发设计的系统最大的敌人是低流量，在大部分库存都好近，而有几个剩余库存时，用户会看到
明明还能抢却总是抢不到，而在高并发下，用户根本就觉察不到。

2.异步消息如果有必要继续优化，就是扣库存和发货这两个费时的流程，可以改为异步，得到秒杀结果后通过短
信/push异步通知用户。主要是利用消息系统削峰填谷的特性来增加系统的容量。

问题1、按你的架构，其实压力最大的反而是站点层，假
设真实有效的请求数有1000万，不太可能限制请求连接数吧，那么这部分的压力怎么处理？
答：每秒钟的并发可能没有1Kw,假设有1KW,解决方
案2个：
(1)站点层是可以通过加机器扩容的，最不济1K台机器来呗。
(2)如果机器不够，抛弃请求，抛弃50%(50%直接返回稍后再试)，原则是要保护系统，不能让所有用户都失败。

问题2、“控制了10w个肉鸡，手里有10w个uid,同时发求”这个问题怎么解决哈？
答：上面说了，服务层写请求队列控制

问题3：限制访问频次的缓存，是否也可以用于搜索？例如A用户搜索了“手机”，B用户搜索“手机”，优先使用A搜索后生成的缓存页面？
答：这个是可以的，这个方法也经常用在“动态”运营活
动页，例如短时间推送4kw用户app-push运营活动，做页面缓存。

问题4：如果队列处理失败，如何处理？肉鸡把队列被撑爆了怎么办？
答：处理失败返回下单失败，让用户再试。队列成本很低，爆了很难吧。最坏的情况下，缓存了若干请求之后，后续请求都直接返回“无票”（队列里已经有100W请求了，都等着，再接受请求也没有意义了)

问题5：站点层过滤的话，是把uid请求数单独保存到各个站点的内存中么？如果是这样的话，怎么处理多台服务器集群经过负载均衡器将相同用户的响应分布到不同服务器
的情况呢？还是说将站点层的过滤放到负载均衡前？
答：可以放在内存，这样的话看似一台服务器限制了5$一个请求，全局来说（假设有10台机器），其实是限制了5s10个请求，解决办法：
1)加大限制（这是建议的方案，最简单）
2)在nginx)层做7层均衡，让一个uid的请求尽量落到同一个机器上

问题6：服务层过滤的话，队列是服务层统一的一个队列？还是每个提供服务的服务器各一个队列？如果是统的一个队列的话，需不需要在各个服务器提交的请求入队列前进行锁控制？
答：可以不用统一一个队列，这样的话每个服务透过更少
量的请求（总票数/服务个数），这样简单。统一一个队列又复杂了。

问题：秒杀之后的支付完成，以及未支付取消占位，如何对剩余库存做及时的控制更新？
答：数据库里一个状态，未支付。如果超过时间，例如45分钟，库存会重新会恢复（大家熟知的“回仓”），给我
们抢票的启示是，开动秒杀后，45分钟之后再试试看，说不定又有票哟~

问题8：不同的用户浏览同一个商品落在不同的缓存实例显示的库存完全不一样请问老师怎么做缓存数据一致或者是允许脏读？
答：目前的架构设计，请求落到不同的站点上，数据可能不一致（页面缓存不一样），这个业务场景能接受。但数据库层面真实数据是没问题的。

问题9：就算处于业务把优化考虑“3k张火车票，只透3K个下单请求去db”那这3K个订单就不会发生拥堵了吗？
答：(1)数据库抗3K个写请求还是ok的；(2)可以数据拆分；(3)如果3K扛不住，服务层可以控制透过去的并发数量，根据压测情况来吧，3k只是举例；

问题10；如果在站点层或者服务层处理后台失败的话，需不需要考虑对这批处理失败的请求做重放？还是就直接丢弃？
答：别重放了，返回用户查询失败或者下单失败吧，架构
设计原则之一是“fail fast”。

问题11.对于大型系统的秒杀，比如12306，同时进行的秒杀活动很多，如何分流？
答：垂直拆分

问题12、额外又想到一个问题。这套流程做成同步还是异步的？如果是同步的话，应该还存在会有响应反馈慢的情况。但如果是异步的话，如何控制能够将响应结果返回正确的请求方？
答：用户层面肯定是同步的（用户的http请求是夯住的)，服务层面可以同步可以异步。

问题13、秒杀群提问：减库存是在那个阶段减呢？如果是下单锁库存的话，大量恶意用户下单锁库存而不支付如何处理呢？
答：数据库层面写请求量很低，还好，下单不支付，等时间过完再“回仓”，之前提过了。阻塞队列和非阻塞队列~~~~
ArrayBlockingQueue:当队列是空的时，从队列中获取
元素的操作将会被阻塞，或者队列是满时，往队列里添加
元素的操作会被阻塞。典型的生产者-消费者模式；可阻塞的put和take方法。
ConcurrentLinkedQueue:支持并发，
基于锁的算法会带来一些活跃度失败的风险。如果线程在持有锁的时候因为阻塞/，页面错误，或其他原因发生
延迟，很可能所有的线程都不能前进了。一个线程的失败或挂起不应该影响其他线程的失败或挂
起，这样的算法成为非阻塞(nonblocking)算法；1.阻塞队列获取元素时，如果队列为空，则会等待队列有
元素，否则就阻塞队列（普通队列返回结果，无元素）.阻塞队列放入元素时，如果队列满，则等待队列，直到
有空位置，然后插入。（普通队列，要么直接扩容，要么直接无法插入，不阻塞)







~~~~~~~~~~~~~~~~~~~~~~45~~~~~~~~~~~~~
扛住100亿次请求
每台服务器支持的用户数：5.4亿/600=90万。也就是平均单机支持90万用户。如果真实情况比90万。
假设准备600台服务器；
100亿次摇红包这个需求，假设它是均匀地发生在春节联欢晚会的4个小时里，那么服务器的平均QP$应该
是10000000000/600/3600/4.0=1157.也就是单机每秒1000多次，这个数值其实并不高。
如果完全由峰值qs1400万消化
10000000000/(1400*10000)=714秒，也就是说只需要峰值坚持11分钟，就可以完成所有的请求。
单机的峰值QPS为1400万/600=约为2.3万QPS,每秒至少能处理2.3万的QP$,这里我们把目标定得更高一些分别设定到了3万和6万。

从单台服务器看.它需要满足下面一些条件
1.支持至少100万连接用户
系统可用端口数只有：65535-1024=64511，每个TCP连接需要占用一个独立的端口，那最多也只能做到W多并发连接。
忽视了一个很基本的问题，端口号在同一个下不能重
复，但我们可以给一个网卡绑定多个P地址，如果单机要主动发起100万并发连接，我们最少需要使用17个P地址。
如何模拟百万连接？突破局部/全局文件句柄的限制？
Netty可以做到，每个客户端循环建立5万连接，
局部文件句柄：65535，代表一个进程能够打开的最大文件数，一条TCP连接，对应Linux系统里面是一个文件，
最大连接数会受限于这个数字，我们要做百万连接，所以需要修改这个值。
hard nofile 1000000
soft nofile 1000000
soft和hard为两种限制方式，其中soft表示警告的限制，hard表示真正限制，nofile:表示打开的最大文件数

2.每秒至少能处理2.3万的QP$,这里我们把目标定得更
高一些分别设定到了3万和6万。
因为有100万连接连在服务器上，QPS为3万。这就意味着每个连接每33秒，就需要向服务器发一个摇红包的请求。
因为单P可以建立的连接数为6万左右，有17台服务器同时模拟客户端行为。我们要做的就保证在每一秒都有


单机QPS的上限是多少呢？
说到单机，你必须明确指出硬性指标，CPU、内存、硬盘、带宽等
假定CPU为4核、内存8G、硬盘7200转、带宽10M
12306
库存复杂性：旅客A买了一张北京西(01号站)到保定东(02号站)的，那（北京西到保定东】这个商品的库存就
要减一，同时，北京西到石家庄、郑州、武汉、长沙、广州、虎门、深圳等15个站台的商品库存也要减一，也就是说，出一张北京到保定东的票，实际上要减16个商品的库存！
这还不是最复杂的，如果旅客B买了一张北京西(01号站)到深圳北(17号站)的票，除了【北京西到深圳北】这个
商品的库存要减一，北京西到保定东、石家庄、郑州、武汉、长沙、广州、虎门等15个站台的商品库存也要减1，保定东到石家庄、郑州、武汉、长沙、广州、虎门、深圳北
等15个站台的商品库存要减1。。。总计要减库存的商品数是16+15+14+…+1=120个。
防机器人抢票，也不是加个图片验证码那么简单。图片验
证码有6种机器暴力破解的办法，抢票插件用的是我说的

第三种，OCR识别。
Google采用的Wave波形字母已经能比较好地防住机
器OCR了，ems.com.cn上的验证码就是反面教材，机
器0CR成功率接近100%，12306的比ems的图片验证码强一点。
验证码设置得复杂一点吧，人们要喷：这只是便宜大学生
和办公室白领，农民工连26个字母都认不齐，怎么搞？搞
动画验证码吧，也有人喷，视力不好的人怎么办？最后验证码搞得太简单了，皆大欢喜了，其实最高兴的是开发抢票插件的公司。
通常订票系统要处理生成订单、减扣库存、用户支付这三个基本的阶段；
我们系统要做的事情是要保证火车票订单不超卖、不少卖，每张售卖的车票都必须支付才有效，还要保证系统承受极高的并发。下单减库存：
第一就是在极限并发情况下，任何一个内存操作的细节都
至关影响性能，尤其像创建订单这种逻辑，一般都需要存储到磁盘数据库的，对数据库的压力是可想而知的；
第二是如果用户存在恶意下单的情况，只下单不支付这样
库存就会变少，会少卖很多订单，虽然服务端可以限制P
和用户的购买订单数量，这也不算是一个好方法。不支付减库存：

如果等待用户支付了订单在减库存，第一感觉就是不会少卖。但是这是并发架构的大忌，因为在极限并发情况下，
用户可能会创建很多订单，当库存减为零的时候很
多用户发现抢到的订单支付不了了，这也就是所谓的“超卖”。也不能避免并发操作数据库磁盘
预扣库存

从上边两种方案的考虑，我们可以得出结论：只要创建订
单，就要频繁操作数据库。那么有没有一种不需要直接操作数据库的方案呢，这就是预扣库存。
先扣除了库存，保证不超卖，然后异步生成用户订单，这
样响应给用户的速度就会快很多；那么怎么保证不少卖呢？用户拿到了订单，不支付怎么办？我们
都知道现在订单都有有效期，比如说用户五分钟内不支
付，订单就失效了，订单一旦失效，就会加入新的库存，
这也是现在很多网上零售企业保证商品不少
卖采用的方案。订单的生成是异步的，一般都会放
到MQ、kafka这样的即时消费队列中处理，订单量比较少
的情况下，生成订单非常快，用户几乎不用排队。
扣库存：

负载均衡器把100万票分布在100台机器上，本地减库存，MQ生成订单，但是如果其中几台机器宕机了怎么办？引入redis远程统一减库存调度器，为每台机器分
配一些多余的“buffer库存”用来防止机器中有机器宕机的情况。
采用同步调用：
先查询库存，然后if判断库存，足够多时就进行减库存操作。
逻辑是对的，但是这么做有线程上的安全问题，当线程很多、高并发时，有可能引发超卖问题

加锁-synchronized安全，但是性能太差，只有一个线程可以执行，当搭了集群，同时启动好几台服务时，synchronized只锁住了当前
一个tomcat,锁不了别的。
看起来是安全的，但是在分布式服务下不安全（原因：假
如商品微服务启动三台，也就是三个不同的M,锁的原理是内存的一种监视，三个JVM内存就不一致，
则三个减库存方法的锁就不一致，只能一个VM内部锁，
不能锁住对方，因此线程不安全，放在Redis只是数致，不代表对象一致，锁不是一致的，VM的
范围只能作用它自己，所以不能利用synchronized锁来实现)

分布式锁：专门来锁分布式服务的
zookeeper:是树（目录）结构，利用节点的唯一性来实现，也就意味如果有人连到zookeeper以后，会
在zookeeper.上创建一个树节点（在目录下创建一个节点)，
一旦有人创建出来，别人就不能再创建同名节点。任何一
个代码进入到减库存这个地方，先去通过zookeeper在某
个目录下创建一个节点，创建成功就认为得到了锁，继续执行代码；反之则失败（别人已经创建过了），
返回或者wait(取决表如何设计：是否自旋)，因此只有
一个人可以拿到这个锁，执行完毕后节点释放锁，其他人可以再次创建锁，这样就实现单线程。
一靠的是外部工具来模拟锁的机制（权限，同一时刻只能一个人操作)

Redis:SETNX命令
同zookeeper原理类似，但SETNX命令只能set不存在的key,如果不存在，创建并设置value,并返回1；如果存在则会set失败，并返回O,代码运行完以后可以
掉用del命令释放锁但推荐zookeeper:分布式锁，而不是Redis。原因：Redis分布式锁存在搜索？？？题，如果
SETNX成功，成功之后开始执行代码，但是此时服务器宕机，那del命令就一直没有执行，等于这个锁一直被拿着，无法释放，以后这个值将无法再被set成功，因此
我们得想办法解决死锁问题在，服务器宕机的情况下想办法剔除这个值而zookeeper可以创建临时节点，当服务器一旦断开与zookeeper连接，会自动该节点，自动释放锁，但逻辑实现起来较复杂。
但是我们不推荐用锁实现，因为用了锁，就变成单线程了，相当于一执行减库存操作就先把数据库锁死，同一时
刻只能有一个人来操作（类似于悲观锁，即认为线程安全问题一定会发生)，在面对高并发时，往往性能很差。

既然不推荐悲观锁，那是不是可以采用乐观锁呢？乐观锁认为线程安全问题不会发生，不加锁，但是不加锁会有线程安全问题，那如何处理这件事情呢？
答：我们不做查询也不做判断，而是直接去进行减库存操作（上边说了，直接进行减库存会发生超卖现象，不过这
要看我们sq如何写了)我们可以在sql内部加上条件进行判断，任何人来执行，它都会有一个条
件来判断库存，如果库存不足sql本身就会失败，事务回滚，因此不需要加锁与判断，本质上还
是乐观锁，不需要等待、阻塞，任何人都可以执行，如果执行失败会反馈失败信息，而不像是悲观锁那样线程阻塞，导致一直等待，而且还会锁数据库
与表（只有执行完成才会释放），性能上优于加锁方式，
语句如下：
"UPDATE tb_stock SET stock stock -#num)WHERE
sku_id #(id}AND stock >#(num)"
加入一开始100个请求都拿到v=0的库存，都根据v=0去修改count,只有一个扣减成功，其他返回失败，重新提交；接下来新一批请求拿到v=1的；











~~~~~~~~~~~~~~~~~~~~~~48~~~~~~~~~~~~~
架构师成长之路之限流漫谈

1.为什么需要限流
如果业务推出了一个秒杀活动，而你没有任何的限流措施；当你搭建了一个账号平台，而完全没有对十几个业务方设定流量配额……这些很有可能在特定场合下给你的产品
带来大量的业务损失和口碑影响。我们通常重点关注产品业务层面正向和逆向功能的完成，而对于逆向技术保障，
这一点则是企业发展过程中很容易忽视的，所以一旦业务快速增长，这将给你的产品带来很大的隐患。当然，也
不是所有的系统都需要限流，这取决于架构师对于当前业务发展的预判。一般新系统上线前要预估访问量大小，当然评估值不能过大，也不能过小。过大，会导致浪费系统资源，太小，如果遇到峰值，容易压垮系统！
PV:page view页面总访问量，每刷新一次记录一次。
UV:unique view客户端主机访问，指一天内相同lP的访问记为1次。
QPS:query per second,即每秒访问量。qps很大程度上代
表了系统的繁忙度，没次请求可能存在多次的磁盘，网络请求，多个cpu时间片，

一旦qps超过了预先设置的阀值，可以考量扩容增加服务器，避免访问量过大导致的宕机。
如果一次性可以处理100个请求，每个请求耗时100毫秒，则qps=1000
如果一次性可以处理50个请求，每个请求耗时200毫秒，则qps=250
说到单机，你必须明确指出硬性指标，CPU、内存、硬盘、带宽等假定CPU为4核、内存8G、硬盘7200转、带宽10Mqps预估量：
一般预估是有开发测试运维同学一起评估。采用8/2原则。即80%的请求访问在20%的时间内到达。此时根据系统pv测算出qps值
qps=总Pv/60*60*24
峰值qPs=(总Pv*80%)/(60*60*24*20%)。
然后再将峰值qps/单台能承受的最高qps,就是需要的机器数量。
机器数=总峰值pqs/压测单台机子极限qps
比如业务pv为10000000，每台机器的极限qps是100，
则qps=1000000/60*60*24=113;峰值qps=(1000000*80%)/(60*60*24*20%)=463,则需要5台机器；

例子：
每天300WPV的在单台机器上，这台机器需要多少QPS?
答：(3000000*0.8)/(86400*0.2)=139(QPS)

如果一台机器的QPS是58，需要几台机器来支持？
答：139/58=3；

2.信号量计数
信号量竞争是用来控制并发的一个常见手段。比如C和Java中都有Semaphore的实现可以让你方便地上手。鼎
鼎大名的弹性框架Hystrix也默认选择了信号量来作为隔离和控制并发的办法。它的优点即在于简单可靠，但是只能在单机环境中使用。
ExecutorService executorService
Executors.newCachedThreadPoolO;
Semaphoresemaphore new Semaphore(5);
for (int i 0;i<10;i++)
{
final long num i;
executorService.submit(new Runnable)
{
@Override
public void runO
{
try
semaphore.acquire();
System.out.println("Accessing:"num);
Thread.sleep(new
RandomO.nextInt(10000));
semaphore.release(;
System.out.println("Release...");
catch (InterruptedException
e)
{
e.printStackTraceO;
}
}
);
}

3.线程池+阻塞队列
隔离舱技术中也大量使用了线程池隔离的方式来实现，通过限制使用的线程数来对流量进行限制，一般会用阻塞队
列配合线程池来实现。如果线程池和队列都被打满，可以设计对应拒绝策略。需要谨慎调整其参数和线程池隔离的个数，以避免线程过多导致上下文切换带来的高昂成本。也是基于这个考虑，Hystrix默认采用了信号量计数的方式来控制并发。同样，其也只能在单机环境中使用。

4.固定窗口计数-不准确
我们可以以第一次请求访问的时候开始进行计数，而不严格按照自然时间来计数。比如可以利用Redis的INCR和
EXPIRE组合进行计数，如下伪代码所示：
count redis.incrby(key)
if count =1
redis.expire(key,3600)
if count >threshold
println("exceed...")
这种实现方式简单粗暴，可以解决绝大部分分布式限流的问题。但是其存在的问题是：
该计数方式并不是准确计数，由于时间窗口一旦过期，则之前积累的数据就失效，这样可能导致比如本来希望限制“一分钟内访问不能超过100次”，但实际上做不到
精准的限制，
会存在误判放过本应拒绝的流量。每次请求都将访问一次Redis,可能存在大流量并发时候
将缓存打崩最终拖垮业务应用的问题。这个在高并发场景中是非常严重的问题。当然，你可以选择按照业务进行适
当的缓存集群切割来缓解这种问题，但是这仍然是治标不治本。当然，如果你选择单机限流的实现方式，则无需使用Redis,进一步，单机限流情况下该问题不存在。

5.自然窗口计数
有的场景会需要以自然窗口为维度进行限制，实现方式即进行分桶计数。每个slot一般以时间戳为key salt,以单
slot时间长度内的计数值为Value,我们可以根据实际的需求对单slot的时间长度进行限制，比如如果你需要限制一天发送短信数不超限，则以1个自然天为1个
slot,如果希望限制QPS,则以1s为1个slot。然后起定时任务获取slot,进一步取出实际的分桶计算结果，进行判断是否达到阈值，如果超过阈值则执行对应的限制操作。
该策略如果应用在分布式限流环境下，则会碰到若干个问题。这个后面章节中会提到。另外，该策略本质上其实是
也是一种特殊的固定窗口计数策略，那么固定窗口所存在的弊端，自然窗口计数也会存在。那么我们不禁会问，如果希望规避固定窗口的一大问题—一“无法准确计数”的话，要怎么做呢？这时，“滑动窗口计数”方式应运而生。

6.滑动窗口计数
滑动窗口的出现，可以很好地解决精准计数的问题。随着
时间窗口不断地滑动，动态地进行计数判断。可以规避自
然窗口和固定窗口计数所存在的计数不准确的问题。以下有两种常见的滑动窗口计数的实现类别。

6.1基于共享分布式内存
可以采用Redis ZSet,存储结构如下图所示。Key为功能
ID,Value为UUID,Score也记为同一时间戳。整个过程简单概括为“添加记录、设置失效时间、计数、过期记录”四部分。使用ZADD、EXPIRE、ZCOUNT和
zremrangeScore来实现，并同时注意开启Pipeline来尽
可能提升性能。
/开启pipe
pipeline redis.pielinedO
/增加一条请求
pipeline.zadd(key,getUUIDO,now)
/重新设置失效时间
pipeline.expire(key,3600)
/统计在滑动窗口内，有多少次的请求
count pipeline.zcount(key,expire TimeStamp,now)
/过期记录
pipeline.zremrangeByScore(key,0,expireTimeStamp -1)
pipeline.syncO
if count >threshold
println("exceed")
但是该方法，有一个比较突出的问题。就是这是一个重操作，将引发高QPS下Redis的性能瓶颈，也将消耗较多的资源和时间。一般我们可以付出秒级的时延，对其做多阶段异步化的处理。比如将计数、过期数据和新增记
录分为三部分去进行异步处理。此处就不进一步展开了。

6.2基于本地内存
第一个方案中，分布式滑动窗口的难度在于，不得不进行内存共享来达到窗口计数准确的目的。如果考虑分发时进行Key Based Routing是不是能解决这个问题？在付出非幂等、复杂度抬升等一定代价的情况下，引入基于本地内存的分布式限流实现方式。
实现方式有如下两种：
如果可以接受准实时计算的话，可以采用Storm,使用filedsGroup,指定Key到对应的Bolt去处理；
如果需要实时计算的话，那么就采用RPC框架的LB策略为指定Key的一致性Hash。然后路由到对应的服务实例处理。
以上两个实现方式，当到达Bot或者服务实例后，即可基于本地内存进行处理，处理方式也有三种。采用Esper,用DSL语句即可简单实现滑动窗口。Storm1.0后提供了滑动窗口的实现。
如果希望自实现滑动窗口（不推荐），实现思路也比较简单即：循环队列+自然窗口滑动计数。
循环队列来解决无限后延的时间里，计数空间重复利用的问题。而此处，我们看到了一个熟悉的名词—一“自然窗口计数”。没错，底层仍然采用自然窗口计数，但是区别
在于，我们会对自然窗口切分更细的粒度，每次批量超前获取多个分桶，来进行加和计算。这样就可以实现滑动窗口的效果，你可以认为，当分桶被细化到10s


7.令牌桶和漏桶算法计数
这个在业内也是鼎鼎大名。基本谈起限流算法，这两个算法必然会被提起，令牌桶可以有流量应对突发流量，漏桶
算法在单机限流中较为常见，而在分布式限流中罕见踪迹。对于令牌桶来说，你可以采用定时任务去做投递令牌的动作，也可以采用算法的方式去进行简单的计算。Guava
Ratelimiter采用的是后者。

令牌桶的优势之一，在于可以有部分余量用以应对突发流量。但是在实际生产环境中，这不一定是安全的。如果我们的服务没有做好应对更高突发流量的准备，那么很有可能会引发服务雪崩。
所以考虑到这一点，Guava采用了令牌桶+漏桶结合的策略来进行限流。对于默认业务，采用标准令牌桶方式进行“可超支”限速，而对于无法突然应对高峰流量的业务，
会采用缓慢提升投放令牌速率（即逐步缩短业务请求等待时间)的方式来进行热启动控制，具体见Guava
Ratelimiter源码注释描述，此处不赘述，其效果如下图所示：

令牌桶算法：以固定的速率（平均速率）生成对应的令牌放到桶中，客户端只需要在桶中获取到令牌后，就可以访问服务请求。
漏桶算法：以任意速率往桶中放入水滴，如果桶中的水滴没有满的话，可以访问服务。

8.微服务限流几个考虑的点
以上的限流手段，有的能应用在单机环境，有的能应用在分布式环境。而在高并发的分布式环境中，我们需要考虑清楚如下几个问题如何解决。

8.1机器时钟不一致或者时钟回退问题一旦出现这种问题，则可能导致收集的数据相互污染而导致判断出错。所以一方面，在运维层面需要确保机器时钟
能够按期同步。另一方面，需要有准实时检测的手段，及时发
现时钟偏差太大或者时钟回退的机器，基于一定策略筛选
出不合格的数据来源，将其刨除出计算范围并发出警告。

8.2在SDK还是Server端做限流逻辑
你需要考虑你的限流策略迭代的频繁程度，推动业务方改造的成本，语言/技术栈异构情况，是否有需要进行立多系统联合限流的场景，以此来进行决策。如果采用SDK方式，
你需要做好碰到这几个棘手问题的心理准备。而如果采用Server方式，你则需要考虑高并发下数
据堆积，机器资源消耗，以及对业务方性能的影响问题。
一般业内采用的是富SDK的方式来做，但是对于上述的
SDK会面临的几个问题没有很好的解决方案。而ServiceMesh领军人物Istio采用了Mixer来实现Server端限流的方式，但是碰到了很严重的性能问题。所以这是一个很困难的选择。
回顾下架构师成长之路之服务治理漫谈一篇中所讲到的服
务治理发展路径，是不是有点惊人的相似？是不是也许限流的未来，不在SDK也不在Server,而在于ServiceMesh?我不确定，但我觉得这是一个很好的探索方向。

8.3限流是不是会让你的系统变得不可控这是一个很有意思的问题，限流本身是为了“反脆弱”而存在的，但是如果你的分布式复杂拓扑中遍布限流功能，
那么以后你每个服务的扩容，新的功能上线，拓扑结构的变更，都有可能会导致局部服务流量的骤增，进一步引发限流导致业务有损问题。这就是“反脆弱”的本身也有可能会导
致“脆弱”的出现。所以，当你进行大规模限流能力扩张覆盖的时候，需要谨慎审视你的限流能力和成熟度是否能够支撑起如此大规模的应用

8.4拓扑的关联性能给限流带来什么
我们置身于复杂服务拓扑和各种调用链路中，这一方面确实给限流带来了很大的麻烦，但另一方面，我们是不是可以思考一下，这些复杂度，本身是不是可以带给我们什么
样的利好？
比如：底层服务扛不住，那么是不是可以在更上层的调用方入口进行限流？如此是不是可以给予用户更友好提示的同时，也可避免链路上服务各自限流后带来的系统级联处理压力？微服务的本质是自治没错，但是我们是不是可以更好地对各个服务的限流自治能力进行编排，以达到效率、体验、资源利用的优化？相信大家都会有自己的答案。这件事情本身的难度是在于决策的准确性，但如果能很好地进行落地实现，则意味着
我们的限流从自动化已经逐步转向了智能化。这也将是更高一层次的挑战和机遇。

8.5准确性和实时性的权衡
在高并发限流场景下，准确性和实时性理论上不可兼得。
在特定的场景中，你需要作出你的选择，比如前文介绍的基于Redis ZSet实现的滑动窗口实时计算方式可以满足
实时性和准确性，但其会带来很明显的性能问题。所以我们需要作出我们的权衡，比如牺牲准确性将滑动窗口退化为固定窗口来保障性能；或者牺牲实时性，对滑动窗口多阶段去做异步化，分析和决策两阶段分离，来保障性能。这取决于你的判断。

9总结
限流是高可用治理中核心的一环，实现方式也五花八门，每种方式也都有各自的问题，本文只是做了一个简单的回顾。希望随着ServiceMesh、AlOps等理论的兴起，我们对于限流是什么，能做什么，怎么实现，能够释放出更大
的空间去想象。




















 
 
 



 
 
 
---------------------------------------------------------------------------------------------------------------
------------------------------------------Commons4sa.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Commons4se.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------

1注解
@Java5开始添加到Java,取代配置文件；
@元解；@Retention、@Documented、@Target、@lnhe、@Repeatable
@一般和AOP结合使用，比如多数据源切换，审志，事务，安全，身份认证等；


2数组
数组在内存中是连续存储的，所以它的索引速度非常
而且赋值与修改元素也很简单。但是存在缺点，在声明数组的时候必须指定数组的长
数组的长度过长，会造成内存浪费，过短会造成数
的错误。
ArrayList)对象来克服这些缺点，ArrayListi对象的大小
照其中存储的数据来动态扩充与收缩的，
每当执行Add、AddRange、Insert、InsertRange等元素的方法，都会检查内部数组的容量是否不够了，
如果是，它就会以当前容量的两倍来重新构建一个数
将旧元素Copy到新数组中，然后丢弃旧数组，在这
界点的扩容操作，应该来说是比较影响效率的。
然而数组和数组列表都有一个重大的缺陷，这就是从
的中间位置一个元素需要付出很大的代价，其原数组中处于被元素之
后的所有元素都要向数组的前端移动。在数组的中间置插入一个元素也是如此。
这个问题就靠LinkedList(链表)来解决。链表将每个
存放在独立的节点中，每个节点还存放着序列中上一点的引用和下一个节点的引用
这样，从链表中间一个元素是很轻松的操作，即
对被元素附近的节点更新一下即可数组的容量是固定的，只能一次获取或设置一个元值，而ArrayListi或List<T>的容量可根据需要自动扩修改、或插入数据。
ArrayList:是实现了基于动态数组的数据结构，Linke
基于链表的数据结构。
对于随机访问get和set,ArrayList觉得优于LinkedL
因为LinkedList要移动指针。对于新增和操作add和remove,LinedList.比较势，因为ArrayList要移动数据。

@数组内存
遇到创建数组的代码
这时会做两个件事，一是在栈中开辟一块空间，二是中开辟一块空间
首先来看栈中，开辟后就会压在main函数的上面，
这块内存有个名字：array再看堆中，这块内存会有一个地址，这个地址都是十
制，然后把每个值存入对应的索引中
当我们使用这个数组时，肯定会根据数组的名字找到
内存空间，然后发现里面是个地址，然后跳转到堆中
据索引得到对应的值。
当程序执行完后，array内存释放（相当于），然后出栈。



3代码质量
@依赖抽象而不是实现：比如出行，依赖的是抽象的
能力，而不是具体的运输交通工具。

@接口的职责保持单一：
1、类的复杂性降低；
2、可和可维护性提高；
3、降低变更风险

@“java
-XX:+UseParalle
XX:ParallelGCThreads:=20”,这里启用了并行垃圾
机制，并且定义了20个收集线程（默认的收集线程
CPU的数量)，这对多CPU的系统时非常有帮助的，可以大大减
个收对系统的影响，提高系统性能；

@频繁插入和时使用LinkedList;

@不要主动进行垃圾回收，主动进行垃圾回收是一个
危险的动作，因为System.gc要停止所有的响应，才查内存中是否有可回收的对象，所有的请求都会暂停



4集合
List(有序、可重复)，查询快，插入或移动慢；
LinkList:插入、元素比较快，查询效率低，双表、堆栈、队列；
同步性：Hashtable是线程安全的，也就是说是同步
而HashMap是线程序不安全的，不是同步的，hash的key和value都不允许为null。
vector是线程同步的，所以它也是线程安全
而arraylist是线程异步的，是不安全的。



5枚举
enum的语法结构尽管和class的语法不一样，但是
编译器编译之后产生的是一个class文件。该class文过反编译可以看到实际上是生成了一个类，
该类继承了java.lang.Enum<E>。
实际上enum就是一个class,只不过java编译器帮
做了语法的解析和编译而已
可以把enum看成是一个普通的class,它们都可以
一些属性和方法，不同之处是：enum不能使用ext
关键字继承其他类，因为enum已经继j
java.lang.Enum(java是单一继承)。
凡是涉及多个属性的实例可以用枚举，常量类只能表个啊。
如果写一个实体类需要不断new出来啊。比如：
NORMAL("Normal'","正常")，
SHOP_NOT_EXIST("ShopNotExist'","商户不存在")，



6泛型
ClassCastException错误编码过程中不易发现，
K表示键(Key)
V表示值(Value)
T表示类型(Type)
E表示集合元素类型(Entity)
?表示不确定的类型
<?super T>表示包括T在内的任何T的父类
<?extends T>表示包括T在内的任何T的子类



7序列化
对象传输和持久化
serialVersionUID一样序列化和反序列化才会成功，报错。



8正则表达式
A\d+S/匹配非负整数（正整数+0）
A[0-9][1-9][0-9]S
/匹配正整数
(-\d+)I(O+)S
/匹配非正整数（负整数+0）
-[0-9][1-9][0-9]S
//匹配负整数
A-?\d+S
/匹配整数
A\d+(.\d+)?S
/匹配非负浮点数（正浮点数+0）
([0-9]+.[0-9][1-9][0-9])1([0-9][1-9][0-9].[0-9]+)1([0-9]1
9])$/匹配正浮点数
(-\d+(\d+)?)I(O+(.0+)?)S
/匹配非正浮点数(
点数+0)
(-([0-9]+.[0-9][1-9]0-9])1([0-9][1-9][0-9].[0-9]+)1([0-9][
[0-9]))$/匹配负浮点数
(-?\d+)(.\d+)?$/匹配浮点数
[A-Za-z]+S
/匹配由26个英文字母组成的字符串
A[A-Z]+$/匹配由26个英文字母的大写组成的字
A[a-z]+$/匹配由26个英文字母的小写组成的字符
A[A-Za-z0-9]+S
/匹配由数字和26个英文字母组
字符串
A\W+S
/匹配由数字、26个英文字母或者下划线
的字符串
A[W-]+(.[NW-]+)*@[W-]+(.W-]+)+S
/匹配∈
地址



9反射
反射机制性能不太好
1 Spring事务注解
2 Spring MVC,Struts1和Struts2





10JDK源码

(1)String
实现序列化，比较器接口；value是存储Stringl的内容的，即当使用String str="的时候，本质上，"abc"是存储在一个char类型的数的。
hash是String实例化的hashcodel的一个缓存。因为S经常被用于比较，比如在HashMap中。如果每次进较都重新计算hashcode的值的话，那无疑是比较的。
String支持多种初始化方法，包收String,char,bytel,StringBuffers等多种参数类型始化方法。但本质上，其实就是将接收到的参数传递局变量valuel。
知道了String其实内部是通过char实现的，那么就不
现length(,isEmpty),charAto这些方法其实就是
部调用数组的方法。
通过观察equalsO方法的源码我们可以看出，该方法
较两个对象时，首先先去判断两个对象是否具有相同
址，如果是同一个对象的引用，则直接放回true;如
址不一样，则证明不是引用同一个对象，接下来就是
去比较两个字符串对象的内容是否一致，完全相等
true,否则false。
在Object类中的hashCode0方法是返回对象的32位
内存地址，也就是说如果我们不去重写该方法，将会
该对象的32位VM内存地址。所以我们通'
将hashCode方法与equalsO方法一起重写.
hashCode的存在主要是用于查找的快捷性
Hashtable,HashMap等，hashCode是用来在散列
结构中确定对象的存储地址的；
如果两个对象相同，就是适用于equals(java.lang.Ob
方法，那么这两个对象的hashCode一定要相同；
如果对象的equals方法被重写，那么对象的hashCo尽量重写；
两个对象的hashCode相同，并不一定表示两个对象
同，也就是不一定适用于equals(java.lang.Object)方
只能够说明这两个对象在散列存储结构中
Hashtable,他们“存放在同一个篮子里”。

Object的hashcoder函数是native的啊？
使用native:关键字说明这个方法是原生函数，也就是
方法是用C/C++语言实现的，并且被编译成了D
由java去调用。这些函数的实现体在DLL中，JDK的
码中并不包含，你应该是看不到的。对于不同的平台
也是不同的。这也是java的底层机制，实际上java就
不同的平台上调用不同的native方法实现对操作系统问的。

(2)数据结构
堆栈：压缩子弹，先进后出
队列：先进先出
数组：通过索引查找快，增删慢移动的多；
链表：数据域和指针域，查找慢（想查找某个元素，通过连接的节点，依次向后查找指定元素)，增删快要移动下标)
哈希表：底层数组+链表，每个数组存对象据hashcode方法，哈希冲突之后看equals如果true不复放了，false的话放在后面，每个哈希码值位置上存放多个元素。
保证HashSet集合元素的唯一，其实就是根据对
hashCode和equals方法来决定的。如果我们往集合放自定义的对象，那么保证其唯一，就必须
hashCode和equals方法建立属于当前对象的比较方
HashMap底层数据结构数组，链表，哈希表，二叉权

(3)HashMap
HashMap除了允许key和value保存null值和非线程外，其他实现几乎和HashTable一致。
Map是个接口，定义了size,isEmptyO,put,remove一系列的方法；还有default方法，里面有个子接口E
Map.Entry<K,V>entry entrySet)
AbstractMap抽象类实现接口，实现一些共用的方法
HashMap继承AbstractMap,transient修饰的属性不序列化；
HashMap:在resizel的时候会有很大的性能消耗，构造一个是容量（默认16,2的N次方），一个是负载(默认0.75)；
initialCapacity为数组table的大小，即bucket数。loadFactor的DEFAULT_LOAD_FACTOR默认负子为0.75，超过0.75开始扩容resize;
threshold为扩容门槛，=initialCapacity*loadFactor比如初始容量16，负载因子0.75，则门槛是12；超触发resize,扩容后的容量是32。
static class Node<K,V>implements Map.Entry<个
keySetO和entrySetO用于遍历数据；

HashMap是无序的，HashMap在put的时候是根据k
hashcode:进行hash然后放入对应的地方。
对于每个对象而言，JVM都会为其生成一个hash值。HashMap在存储键值对Entry的时候，会根据Khashcode值，以某种映射关系，决定应当将这对键
Entry存储在HashMap中的什么位置上；
当通过Key值取数据的时候，然后根据Key值的hash和内部映射条件，直接定位到Key对应的Value值存放么位置，可以非常高效地将Value值取出。

@数据结构：
哈希表是由数组+链表组成的，一个长度为16的数组
每个元素存储的是一个链表的头结点。
那么这些元素是按照什么样的规则存储到数组中呢。情况是通过hash(key)%len获得，
也就是元素的key的哈希值对数组长度取模得到。比述哈希表中，
12%16=12,28%16=12,108%16=12,140%16=12。F
12、28、108以及140都存储在数组下标为12的位置，
HashMap.底层数据结构数组，链表，哈希表，二叉权
HashMap.里面实现一个静态内部类Entry,其重要的有key,value,next。
HashMap算法，hash%Entryl.length;

JDK7中HashMap:采用的是位桶+链表的方式，即我说的散列链表的方式，而JDK8中采用的是位桶+链黑树，本文研究的是JDK8中的put方法。
HashMap:在jdk1.8之后引|入了红黑树的概念，表示若
链表元素超过8时，会自动转化成红黑树（平衡树)；若桶中元素小于等于6时，树结构还原成链式。为了查找更快。
如何解决hash冲突呢？取模后，总会有两个不一
hash值取模得到相同的值，这个时候，该怎么办？
HashMap的源码中使用冲突解决方法是使用单独法，
Hash冲突后，那么HashMap的单个bucket里存储的
一个Entry,而是一个Entry链。
系统只能必须按顺序遍历每个Entry,直到找到想搜
Entry为止一如果恰好要搜索的Entry位于该Entry
最末端（该Entry是最早放入该bucket中），那系统必须循环到最后才能找到该元素。


(4)ArrayList
动态增长和缩减的索引序列，它是基于数组实现的类。
List<E>是个接口，继承Collection,定义了一系列集方法，add(,get,removeO等；
ArrayList:实现了该接口，继承AbstractCollection,了通用的一些方法，
arrayList的构造方法就做一件事情，就是初始化一下数据的容器，其实本质上就是一个数组，在其中
elementData。
扩容：
private void grow(int minCapacity){
/overflow-conscious code
int oldCapacity=elementData.length;/将扩充
elementData大小给oldCapacity
int newCapacity oldCapacity +(oldCapaci
1);/newCapacity就是1.5倍的oldCapacity
if(newCapacity-minCapacity<O)/这句话就是
于elementData就空数组的时候，length:=O
么oldCapacity=O,newCapacity=O,所以这个判
立，在这里就是真正的初始化elementData的大小了
是为10.前面的工作都是准备工作。
newCapacity minCapacity;
if (newCapacity MAX_ARRAY_SIZE >0)//
newCapacity超过了最大的容量限制，
用hugeCapacity,也就是将能给的最大值给newCapa
newCapacity hugeCapacity(minCapacity);
/minCapacity is usually close to size,so this
win:
/新的容量大小已经确定好了，就copy数组，改变大小咯。
elementData Arrays.copyof(element
newCapacity);
}
arrayListl区别于数组的地方在于能够自动扩展大小，
关键的方法就是gorw)方法。
arrayList由于本质是数组，所以它在数据的查询方面
快，而在插入这些方面，性能下降很多，有移动
数据才能达到应有的效果；
对传进来的初始化参数initalCapacity进行判断；等三
则将数组初始化为一个空数组，不等于，将数组初
为一个容量为10的数组。
新的容量为旧的容量的1.5倍。



(5)LinkedList
LinkedList是基于链表实现的，
private static class Node<E>{
E item;
Node<E>next;
Node<E>prev;
}
当前元素有指针指向上一个或者下一个元素；
void linkLast(Ee){
final Node<E>=last;/获取尾部元素
final Node<E>newNode new Node<>(l,e,nu
以尾部元素为前继节点创建一个新节点
last=newNode;//更新尾部节点为需要插入的节
if (=null)
/如果空链表的情况：同时更新first节点也为
插入的节点。（也就是说：该节点既是头节点first也
节点last)
first newNode;
else
/不是空链表的情况：将原来的尾部节点（现
倒数第二个节点)的next指向需要插入的节点
I.next newNode;
size++;/更新链表大小和修改次数，插入完毕
modCount++;
}
而且还实现了Deque:接口啊？
peek)返回头元素，并且不。如果不存在也不错
回null
peekLasto:返回尾元素，如果为null则就返回null
pollO返回头节点元素，并头节点。并将下一个
设为头节点。
pollLasto返回尾节点，并且将尾节点，并将尾
的前一个节点置为尾节点
pop)头节点，如果头结点为null.则抛出异常
区别：
顺序插入的速度ArrayList会快些，LinkedList的速度
慢一些。因为ArrarList.只是在指定的位置上赋值即
而LinkedList!则需要创建Node对象，并且需要建立前
联，如果对象较大的话，速度回慢一些。
用for循环效率高还是用Iterator遍历效率高就取
ArrayList、LinkedList是不是实现了RandomAccess
接口来进行选择合适的遍历方式，
查看Collections类中的binarySearch()方法，做了
判断，instanceof其作用是用来判断某对象是否为某
或接口类型，如果是实现了RandomAccess的接口的
就用for循环比较好；
否则的话就调用Collections的IteratorBinarySearch(
法，也就是使用迭代器lterator的遍历方式；

对ArrayListi和LinkedListi而言，在列表末尾增加一个所花的开销都是固定的。
在ArrayList的中间插入或一个元素意味着这个列剩余的元素都会被移动；而在LinkedList的中间插入除一个元素的开销是固定的。
如果待插入、的元素是在数据结构的前半段尤其常靠前的位置的时候，LinkedList的效率将大大ArrayList,因为ArrayList将批量copy大量的元素；
后，对于LinkedList3来说，因为它是双向链表，所以不个元素后面插入一个数据和在倒数第2个元素后面插个元素在效率上基本没有差别，但是ArrayList由于要
coy的元素越来越少，操作速度必然追上乃至LinkedList.

1、如果你十分确定你插入、的元素是在前半段用LinkedList
2、如果你十分确定你、的元素后半段用ArrayList
3、如果你上面的两点不确定，建议你使用LinkedLis1






rcp无法启动的问题：org.osgi.framework.BundleException: Exception in org.eclipse.core.resources.ResourcesPlugin.start()
删除下面两个文件

1) /.metadata/.plugins/org.eclipse.core.resources/.snap
2) /.metadata/.plugins/org.eclipse.core.resources/.root/.markers.snap



~~~~~~~~~~~~~~~~~~~~~~~~~~~eclipse.ini~~~~~~~~~~~~~~~~~
-startup
plugins/org.eclipse.equinox.launcher_1.3.200.v20160318-1642.jar
--launcher.library
plugins/org.eclipse.equinox.launcher.win32.win32.x86_64_1.1.400.v20160518-1444
-product
org.eclipse.epp.package.jee.product
--launcher.defaultAction
openFile
-showsplash
org.eclipse.platform
--launcher.defaultAction
openFile
--launcher.appendVmargs
-vmargs
-Dosgi.requiredJavaVersion=1.8
-XX:+UseG1GC
-XX:+UseStringDeduplication
-Dosgi.requiredJavaVersion=1.8
-XX:MaxPermSize=1056m
-Xms1024m
-Xmx5024m
-Xss1024m
-javaagent:E:\Programme Files\eclipse 4.5\lombok.jar








下载离线包
https://mirrors.tuna.tsinghua.edu.com/gitlab-ce/yum/el6

安装包名称：gitlab-ce-9.4.5-ce.0.el6.x86_64.rpm


rpm -ivh gitlab-ce-9.4.5-ce.0.el6.x86_64.rpm

修改配置文件里面的external_url，改成服务器ip, 如果有域名，改成域名
#vi /etc/gitlab/gitlab.rb
external_url="10.72.4.196"

重新加载配置文件，使其生效
sudo gitlab-ctl reconfigure

启动服务
sudo gitlab-ctl start


http://10.72.4.196
root/Aa123456!  默认账号root,第一次进去强制修改密码
启动成功但是无法访问，可能是防火墙问题

批量克隆（适合多个项目）
@echo off
echo 'start git clone'
pause
for /f %%i in (git-hae-names.txt) do git clone %%i
echo 'start git finish' 
pause


合并分支
git cherry-pick ddsdsfsdfsdfsdfsdf
git cherry-pick --continue
git cherry-pick --abort
git commit --allow-empty


git cherry-pick 123456 123457
git push

如国有冲突，gitlab客户端解决冲突，提交push


记住密码
git config --global credential.helper store

会在用户主目录 .gitconfig文件中生成配置
[credential]
      helper = store
      
      
      
 https支持
 git config --global http.sslVerify false
 git clone https://code.hub.com
  
  
 一些操作：
 New Groups(hiya-boot-group, hiyia-public-group, hiyia-oa-group,hiyia-mall-group)
 New User(caozhijun/Aa123456!)
 
提交maven modules 到gitlab, 右键parent项目，team-share project, 创建仓库，提交push 
右键子项目，直接finish 

如果误操作，把子项目也创建仓库了，打开 show view ------ Git Repositories,找到子项目删除
  
 
 






 
 
 cd /home/hiya003/softwares/jdk8
tar -zxvf jdk-8u45-linux-x64.tar.gz

vim /etc/profile

export JAVA_HOME=/home/hiya003/softwares/jdk8/jdk1.8.0_45
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib:$CLASSPATH
export PATH=$PATH:${JAVA_PATH}

source /etc/profile


java -version


---------------------------------------------------------------------------------------------------------------
------------------------------------------Commons4se.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Concurrent.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------



@海涯总结
线程安全：在多线程的场景下，执行同一段业务逻辑，
每次都是准确的，叫做线程安全；比如struts≌是多利模式，不存在这个问题。springmvc是单例的。
要想并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有被保证，就有可能会导致程序运行不正确。
*这种场景是独立一个复合对象（自定义后者jdk里面的)
*初始化一个线程类，构造好参数，用同一个对象去创建
2个线程。分别start.….
*这样多个线程共享资源了
*一般2种情况，1是分布式处理各自的任务，1是共享资源
*还有一种情况是继承Thread,new出的对象不一样，只能处理各自的任务
*或者new出两个Account,也不是供向资源


@有几层意思：
第一层：单例模式的获取，你要保证多个线程get的情况
下不要产生多个实例，用到同步块，所以有什么懒汉恶汉模式，但是枚举模式是线程安全的。

第二层：tomcati对于每次客户连接都会开启一个线程，
线程代码在tomcat里面，访问同一个controller,只要这
个类没有成员变量或者静态变量的修改就不会有线程安全的问题，也就是有状态的bean。如果是只读操作肯定没问题。因为多线程共享单例只是CPU的切换问题，最大限度利用cpu资源。

第三层：spring采用LocalThread解决安全问题的原理：
每个线程拷贝一个副本，相互独立，只能修改自己的，
开了共享资源的竞争，比如说数据库个连接线程A需要用起来，但是同时线程B可能把他关掉了，造成问题。设计共享变量修改的问题还是要同步或
者lock,原子性等去解决。

第四层：如果涉及A类静态成员变量B的修改，要么看A有没有同步，要么看B的方法是否安全（典型的hashmap,hashtable等)。


@并发concurrency,并行parallell
并发只是最大限度利用cpu资源，有时候线程需要cpou等待，这个时候切换其他线程，不是真正的并行，感觉是并行；
并行才是真正的同时干活


@进程之间通信
kafka消息队列，redis共享内存，信号量(semaphore,Socket套接字


@原子性
只有简单的读取、赋值（而且必须是将数字赋值给某个变
量，变量之间的相互赋值不是原子操作)才是原子操作。
X=10;/语句1，原子性
y=X;/语句2，不是原子性，读取x值，赋值给y
X++;/语句3，不是原子性，X++和X=X+1包括3个操作：
读取的值，进行加1操作，写入新的值
X=X+1;//语句4，不是原子性
由于synchronized和Lock能够保证任一时刻只有一个线程
执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。
还有一个Atomiclnteger保证原子性
volatile保证可见和有序，没有原子性。


@可见性，线程1修改之后存储在高速缓存中，没有到内存中。


@有序性，指令重排序入


@API
Thread vield∩：暂停当前正在执.行的线程对象.并执.行其


@API
Thread.yield(:暂停当前正在执行的线程对象，并执行其他线程。
Thread.sleep(与Object.wait二者都可以暂停当前线程，
释放CPU控制权，主要的区别在于Object.waitO在释放CPU同时，释放了对象锁的控制，sleep)锁并没有释放；
试想如果ait方法没有释放锁那岂不是死锁了，其他线程
没有得到锁怎么去notifyO?
生产者和消费者共用一把锁，如果队列满了，生产者waitO,直到消费者notifyO.如果队列为空，消费者wait,直到生产者notify


@阻塞队列与非阻塞队列区别：
阻塞队列能够阻塞当前试图从队列中获取元素的线程，而非阻塞队列不会。因此在面对类似消费者-生产者的模型时，使用非阻塞队列就必须额外地实现同步策
略以及线程间唤醒策略，这个实现起来就非常麻烦。但是
有了阻塞队列就不一样了，它会对当前线程产生阻塞，比
如一个线程从一个空的阻塞队列中取元素，此时线程会被阻塞直到阻塞队列中有了元素。当队列中有元
素后，被阻塞的线程会自动被唤醒（不需要我们编写代码去唤醒)。这样提供了极大的方便性。


@关于BlockingQueue,线程安全，取代之前的生产者消费
者（同步快）问题

add增加一个元索如果队列已满，则抛出一个lllegalSlabEepeplian.异常
remove移除并返回队列头部的元素如果队列为空，则抛出一个NoSuchElementException.异常
element返回队列头部的元素如果队列为空，则抛出一个NoSuchElementException.异常个offer添加一个元素并返回true如果队列已满，则这一false
offer添加一个元素并返回true如果队列已满，则返回false
pol移除并返问队列头部的元素如果队列为空，则返回null
peek返回队列头部的元素如果队列为空，则返回null
put添加一个元素如果队列满，则阻塞
take移除并返回队列头部的元素如果队列为空，则阻塞超时：

offer(2),poll(2
remove、element、offer、poll、peek其实是属于Queue接口，
从这里可以看出来BlockingQueue加了put和take的方法，
和Queue最大的不同就是可以阻塞。
里面的offer方法使用了锁同步。
public boolean offer(E e){
checkNotNull(e);-不能为null
final ReentrantLock lock this.lock;
lock.lockO;
try
if (count =items.length)
return false;
else
enqueue(e);
return true;
}
finally
lock.unlockO;
}
}
一半用于生产者-消费者的内存队列。断电数据消失。一
个线程往里边放，另外一个线程从里边取的一人
BlockingQueue.





一个线程将会持续生产新对象并将其插入到队列之中，直
到队列达到它所能容纳的临界点。
如果该阻塞队列到达了其临界点，负责生产的线程将会在
往里边插入新对象时发生阻塞。它会一直处于阻塞之中，
直到负责消费的线程从队列中拿走一个对象。
负责消费的线程将会一直从该阻塞队列中拿出对象。如果
消费线程尝试去从一个空的队列中提取对象的话，这个消
费线程将会处于阻塞之中，直到一个生产线程把一个对象丢进队列。
java.util.concurrent.BlockingQueue<Object>bq new
ArrayBlockingQueue<Object>(1024);
new Thread(O->
{
try
{
/bq.add("1111");
Thread.sleep(1);
/bq.put(2222");
Thread.sleep(1);
/bq.offer("3333");
catch (Exception e)
{
e.printStackTraceO;
}).startO;
new Thread(O->
{
try
{
System.out.printIn(bq.pollO);
Thread.sleep(1);
System.out.println(bq.remove));
Thread.sleep(1);

Thread.sleep(1);
System.out.println(bq.take();
catch (Exception e)
{
e.printStackTrace);
}
}).startO);

DelayQueue:只有在延迟期满时才能从中提取元素，无界阻塞队列。
java.util.concurrent.BlockingQueue<Object>bq2 new
LinkedBlockingDeque<>);
如果没有指定容量，看看有多少？将使用Integer.MAX_VALUE(21亿)作为上限
ArrayBlockingQueue实现简单，表现稳定，添加和使用同一个锁，通常性能不如后者，有界。
LinkedBlockingQueue添加和两把锁是分开的，所以竞争会小一些，设定了大小就是有界，没有设定21亿就是无界。
PriorityBlockingQueue:无界优先级，装的肯定是实现了
Comparable接口的，不管怎么putQ.take的是compareTo方法优先级小的出来。
SynchronousQueue:限定线程池的最大大小为一个合理的有限值，而不是Integer.MAX_VALUE,否则可能导致线
程池中的工作者线程的数量一直增加到系统资源所无法承受为止。

有界队列：构造函数一定有大小参数，比如设定了固定大小的LinkedBlockingQueue,又或者大小为O,只是在生
产者和消费者中做中转用的SynchronousQueue.。
无界队列：指的是没有设置固定大小的队列。这些队列的
特点是可以直接入列，直到溢出。当然现实几乎不会这么大的容量（超过Integer.MAX_VALUE),
所以从使用者的体验上，就相当于“无界”。比如没有
设定固定大小的LinkedBlockingQueue。直接把JVM内存撑爆。
Queue和List,Set一样，都是继承Collection的，
问题：BlockingQueue和分布式的Kafka等MQ有何不同？
最大的区别是Kafka是分布式的，可以持久到磁盘，
而BlockingQueue:是本机内存，断电就数据消失。
LocalThread

再次强调，spring采用LocalThread解决安全问题的原
理：每个线程拷贝一个副本，相互独立，只能修改自己的，避开了共享资源的竞争，比如说数据库
连接线程A需要用起来，但是同时线程B可能把他关掉了，造成问题。设计共享变量修改的问题还是要同步或者lock,原子性等去解决。
这里涉及到InheritableThreadLocal(父子线程可共享)
和TransmittableThreadLocal(阿里产品，解决线程池
下InheritableThreadLocal数据错误问题)
ThreadLocal与内存泄漏。
认为ThreadLocal:会引起内存泄漏的说法是因为如果一
个ThreadLocaly对象被回收了，我们往里面放的value对于
【当前线程>当前线程的
threadLocals(ThreadLocal.ThreadLocalMap对象)->Entry数组->某个entry.value】

这样一条强引用链是可达的，因此value?不会被回收。显式调用remove可以避免。

@通信和控制
闭锁CountDownLatch(多个join效果)，计数器初始值设置为3，调用await的地方需要等待0的时候执行。原则
是多个线程公用一个CountDown.。driud使用了大量的个栅栏CyclicBarrier:循环屏障，一组线程相互等待直主.

有线程都到达一个公共的屏障点。比如当等待坐车的乘客到达20人时，汽车站就会发出一辆长途汽车，让这20个
乘客上车走人。可以清空。
CyclicBarrier barrier1
new CyclicBarrier(3,
actionAdd);/有3个线程等待就执行actionAdd
交换机Exchanger:成对出现的线程之间交换数据，共享
一个Exchanger,exchanger.exchange(data);把data传到另一个线程了。
信号量Semaphore:用作限流，同一时刻只有多少个线程并发执行，semaphore.acquire(;


ConcurrentHashMap
HashMap线程不安全，Hashtable内部采用独占锁，线程安全，但效率低。
锁分段机制，保证线程安全和并发量。并发度=分段锁个
数，即Segment的数组长度。默认16.2的幂数，设置17实际32.
多线程环境下，使用Hashmap进行put操作会引起死循环，导致CPU利用率接近100%。
首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其
他段的数据也能被其他线程访问。


CopyOnWriteArrayList
当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy,复制出一个新的容
器，然后新的容器里添加元素，添加完元素之后，
再将原容器的引用指向新的容器。这样做的好处是我们可
以对CopyOnWrite:容器进行并发的读，而不需要加锁，因
为当前容器不会添加任何元素。
所以CopyOnWrite:容器也是一种读写分离的思想，读和写不同的容器。

add需要加锁的，否则多线程写的时候会Copy出N个r出来；读的时候不需要加锁，add需要加锁的，否则多线程写的时候会Copy出N个副本出来；读的时候不需要加锁，
如果读的时候有多个线程正在向CopyOnWriteArrayListi添
加数据，读还是会读到旧的数据，因为写的时候不会锁住l旧的CopyOnWriteArrayList.。
读多写少的并发场景。
缺点：内存占用问题。，两份对象内存；数据一致性问题。不能实时一致性。


@线程池（原理如同数据库连接池，节省不断创建和销毁
线程的开销，提升性能)
ExecutorService(接口)es1=Executors(工具类).newFixedThreadPool(3);
es1.execute(O->{
ystem.out.println(999);
)
ScheduledThreadPoolExecutor->ThreadPoolExecutor-
>AbstractExecutorService实现ExecutorService


@Java多线程中有两种不同类型的任务，Runnable类型
任务（无返回值）与Callable类型任务（有返回值）
submit有返回值一般是callable;execute一般没有返回
值，runnable
Future<String>fs es1.submit(O->{
return "444";
);
System.out.println(fs.get));
其实callable底层也是一个runnable,写了一个适配
器RunnableFuture。


@无锁的非阻塞算法CAS和Atomic
CPU的CAS指令，完成Java的非阻塞算法
AtomicInteger)底层的incrementAndGet方法就是用的指令实现。保证原子性操作。
个当且仅当V(内存值)=A(预期值)时，B(修改的值)的值才更新给A,否则将不做任何操作
解决ABA的问题是版本号，CAS不适合竞争十分频繁的场景。
-AtomicBoolean布尔值的原子性
-AtomicInteger数字原子性
-AtomicLong
-AtomicReference
-AtomiclntegerArray
AtomicLongArray
AtomicMarkableReference
AtomicReferenceArray
AtomicStampedReference

lock
tryLock.所以不容易产生死锁，synchronized要么阻塞要么死锁。速度比synchronized'快一倍
synchronized是Java语言的关键字，因此是内置特性。LocK是一个类，通过这个类可以实现同步访问。
tryLock(long,TimeUnit)实现可定时的锁请求
Condition是与Lock绑定的，
Lock lock =...
lock.lock);
try{
/处理任务
}catch(Exception ex){
}finally{
lock.unlockO;/释放锁
}
lockO方法是平常使用得最多的一个方法，就是用来获取锁。如果锁已被其他线程获取，则进行等待。
tryLock(long time,TimeUnit unit)定时获取锁。
lockInterruptibly)线程正在等待获取锁能够响应中断，线
程获取了锁之后不会被interrupt)方法中断的。synchronized无法被中断一直等待。

Lock lock=.…;
if(lock.tryLockO){
try{
/处理任务
}catch(Exception ex){
}finally{
lock.unlock);/释放锁
}
}else
/如果不能获取锁，则直接做其他事情
}
ReentrantLock -Lock
ReentrantReadWriteLock -ReadWriteLock
文件的读写操作分开，分成2个锁来分配给线程，从而使得多个线程可以同时进行读操作
private ReentrantReadWriteLock rwl
new
ReentrantReadWriteLockO;
rwl.readLockO.lockO;
rwl.readLock).unlockO;
如果有一个线程已经占用了读锁，则此时其他线程如果要申请写锁，则申请写锁的线程会一直等待释放读锁。
public class HiyaMap<K,V>extends HashMap<K,V>
{
private static final long serialVersionUID 15675757L;
private static ReadWriteLock rwLock
new
ReentrantReadWriteLock(false);
private static Lock readLock rwLock.readLock);
private static Lock writeLock rwLock.writeLockO;

@Override
public V put(K key,V value)
writeLock.lockO;
try
{
return super.put(key,value);
finally
writeLock.unlockO;
}
}

@Override
public V get(Object key)
{
readLock.lockO;
try
return super.get(key);
finally
{
readLock.unlockO;
}
}
}


可重入锁
synchronized和ReentrantLock都是可重入锁
class MyClass
public synchronized void method10 (method20;}
public synchronized void method20
上述代码中的两个方法method1和method.
用synchronized修饰了，假如某一时刻，线程A执行到了method1,此时线程A获取了这个对象的锁，而由于
method:2也是synchronized方法，
假如synchronized不具备可重入性，此时线程A需要重新申请锁。但是这就会造成一个问题，因为线程A已经持有
了该对象的锁，而又在申请获取该对象的锁，这样就会线程A一直等待
永远不会获取到的锁。


可中断锁
synchronizedi就不是可中断锁，而Lock是可中断锁

公平锁
等待时间最久的线程（最先请求的线程）会获得该所，这种就是公平锁。
synchronized就是非公平锁，ReentrantLock lock=new
ReentrantLock(true);true为公平锁，false为非公平锁。


@源码分析
(1)ArrayBlockingQueue
关键是看put和take的阻塞实现方法
public void put(Ee)throws InterruptedException
checkNotNull(e);
final ReentrantLock lock this.lock;
lock.lockInterruptiblyO;
try
while (count =items.length)
notFull.awaitO;
enqueue(e);
finally
lock.unlockO;
}
}
获取锁，notFull.await);进行等待，阻塞中，一直到
notFull.signal(唤醒，不用手动写，内部帮你实现了。
同样道理，take实现机制是一样的。


(2)LinkedBlockingQueue
使用node结构来存储数据，put和take原理和
ArrayBlockingQueue一样的。


(3)PriorityBlockingQueue
take方法，阻塞中，利用Comparable找到最小的数字出
队


(4)DelayQueue
首先依然是加锁，然后获取队列中的头元素但是不移除，
如果头元素为空则阻塞线程。若不为空，判断其等待时间
是否结束，结束则返回。若等待时间未结束，
判断当前是否已有leader线程，有则直接阻塞，无责将leader线程设置为当前线程，并设置其在到达delay时间
前阻塞（即队列头元素的等待时间前）。


(5)LocalThread
ThreadLocal里面有个内部静态
类ThreadLocalMap,Thread类有一个类型
为ThreadLocal.ThreadLocalMap的实例变量
threadLocals.
也就是说每个线程有一个自己的ThreadLocalMap。里面
维护了一个Entry数组。
static class ThreadLocalMap
static
class
Entry
extends
WeakReference<ThreadLocal<?>>{
Object value;
Entry(ThreadLocal<?>k,Object v){
super(k);
value v;
}
}
}
key为Entryl的弱引引用，方便垃圾回收。
set方法，首先调用getMap(t),其实就是Thread的成员变
量，t.threadLocals是否null,如果不为空则设置。
Thread类还有一个InheritableThreadLocal>对象，在线程
对象初始化的时候，会调用ThreadLocal的createlnheritedMap从父线程的
inheritableThreadLocals中把有效的entry都拷过来


(6)TransmittableThreadLocal
TransmittableThreadLocal是Alibaba开源的、用于解决
“在使用线程池等会缓存线程的组件情况下传
递ThreadLocal”问题的InheritableThreadLocal扩展。继承extends InheritableThreadLocal<T>.


(7)CountDownLatch
底层原理就是：主线程一直await(,每次调用countDown方法sync.releaseShared(1);
一直到为O的时候，LockSupport.unpark(s.thread);/唤醒线程


(8)ConcurrentHashMap
主要是3个方法，put,get,remove
public V put(K key,V value){
Segment<K,V>s;
/concurrentHashMap不允许key/value为空
if (value =null)
throw new NullPointerExceptionO;
/hash函数对key的hashCode重新散列，避免差劲的不合
理的hashcode,保证散列均匀
int hash hash(key);
/返回的hash值无符号右移segmentShift位与段掩码进行
位运算，定位segment
int j=(hash >>segmentShift)segmentMask;
if ((s =(Segment<K,V>)UNSAFE.getObject /nonvolatile;
recheck
(segments,(j <SSHIFT)SBASE))==null)/in
ensureSegment
s ensureSegment(j);
return s.put(key,hash,value,false);
}
从源码看出，put的主要逻辑也就两步：1.定位segment
并确保定位的Segmenti已初始化2.调用Segmentl的put方
法
get也是先定位所在的Segment,在get


(12)CopyOnWriteArrayList
boolean add(Ee)添加元素加锁了
public boolean add(Ee){
/加独占锁(1)
final ReentrantLock lock this.lock;
lock.lockO;
try
/获取array(2)
Object elements getArrayO;
/拷贝array到新数组，添加元素到新数组（③）
int len elements.length;
Object newElements Arrays.copyof(elements,len
1);
newElementslen]=e;
/使用新数组替换添加前的数组(4)
setArray(newElements);
return true;
finally
/释放独占锁(5)
lock.unlockO;
}
}

Eget(int index)没有加锁
remove(int index)和Eset(int index,E element)都要独占
锁。
CopyOnWriteArrayList使用写时拷贝的策略来保证list的一
致性，而获取拷贝写入三步并不是原子性的，所以在修改增删改的过程中
都是用了独占锁，并保证了同时只有一个线程才能对list数组进行修改。


(13)AbstractExecutorService
ThreadPoolExecutor extends AbstractExecutorService,后者实现了ExecutorService接口


(14-15)Future和Callable
关键看AbstractExecutorService的submit代码实现
public Future<?>submit(Runnable task){
if (task =null)throw new NullPointerExceptionO;
RunnableFuture<Void>ftask newTaskFor(task,null);
execute(ftask);
return ftask;
}
RunnableFuture extends Runnable,Future<V>
public class
FutureTask<V>
implements
RunnableFuture<V>{
底层还是Runnable,只不过进行了join或者阻塞操作
(awaitDone方法，等待任务的完成，或者中断/超时则结
束等待)。


(16)Atomiclnteger
继承Number,持有Unsafe unsafe一个对象，CAS保持
原子性，这个原子性的保证并不是靠java本身保证，而是
靠一个更底层的与操作系统相关的特性实现。
public final int getAndIncremento{
return unsafe.getAndAddInt(this,valueOffset,1);
}
do
{
i=getIntVolatile(paramobject,paramLong);
while (!compareAndSwapInt(paramObject,paramLong,
ii+paramlnt);cas无限循环
return i;
底层：compareAndSwapInto方法是一个navtive方法，
public final native boolean compareAndSwapInt(Object
var1,long var2,int var4,int var5);
第一个参数var1为给定的对象，var2为对象内的偏移量
(其实就是一个字段到对象头部的偏移量，通过这个偏移量可以快速定位字段)，
var4表示期望值，var5表示要设置的值。如果指定的字段的值等于var4,那么就会把它设置为var5


(17)ReentrantLock
AQS(AbstractQueuedSynchronizer):为java中管理锁
的抽象类。该类为实现依赖于先进先出(FFO)等待队列的阻塞锁和相关同
reentrantLock内部最重要的实现是基于这个同步容器做的，维护锁的当前状态和线程等待列表通过对公平锁的分析，在unlock的时候，会对head节点的
next节点做唤醒操作，也就是唤醒下一个节点来竞争锁，
那么体现非公平锁的特性来了，当唤醒下一个节点来竞
争锁的时候，又有几个其他线程调用了locK方法，这个时候另外几个线程和next节点所代表的线程都会去竞争锁，并不保证next节点能够一定获取到锁。


(18)ReentrantReadWriteLock
读锁ReadLock和写锁WriteLock,可以通过这两种锁线程间的同步，五个内部类.
AQS支持独占式同步状态获取/释放、共享式同步状态获
取/释放两种模式，对应的典型应用分别是ReentrantLock
和Semaphore,AQS还可以混合两种模式使用，读写
锁ReentrantReadWriteLock就是如此。
设想以下情景：我们在系统中有一个多线程访问的缓存，
多个线程都可以对缓存进行读或写操作，但是读操作远远
多于写操作，要求写操作要线程安全，
且写操作执行完成要求对当前的所有读操作马上可见。

读写锁：
当有写线程时，则写线程独占同步状态。当没有写线程时
只有读线程时，则多个读线程可以共享同步状态。
Sync继承自AQS、NonfairSync:继承自Sync类、FairSync
继承自Sync类；ReadLock:实现了Lock接口、WriteLock也

实现了Lock接口
WriteLock类中的lock和unlock方法：
public void lockO{
sync.acquire(1);
}
public void unlockO{
sync.release(1);
}
可以看到就是调用的独占式同步状态的获取与释放，因此
真实的实现就是Sync的tryAcquire和tryRelease.。
读锁的lock和unlock的实际实现对应Sync的
tryAcquireShared和tryReleaseShared方法


如果只有1核cpu,那么只能叫并发，如果多核cpu可以叫并行了。

4核8线程有4个物理核心，8线程使用了超线程技术，把一个物理模拟2个逻辑核心，任务管理器会显示8张cpu表，
也就是说4个物理核心,8个逻辑核心.
可以并行处理4个进程或者8个线程，只有可以并发多少线程取决于线程池的配置了，并行和并发是两个概念。


进程：操作系统进行资源（cpu,内存，磁盘 ，io，带宽）调度分配的最小单位。
线程：cpu调度和分配的基本单位。

全球高科技去A化为主旋律，不仅仅是中国的趋势。
并不是简单地去美国化，是去政治化，让科技远离政治。

wait方法
如果当前线程不是对象锁的持有者抛异常
如果是同步方法，锁就是当前对象
如果同步块，说就是参数

interrupt不是真正的中断线程，只能改变中断状态而已。
真正中断需要业务代码判断isInterrupted 去return 或终止代码

volatile看做是一把轻量级的锁，和锁有些不同，当一个线程修改了对象状态之后，其他县城立马就能看到
禁用缓存也可以办得到，volatile关键就是禁用缓存
对非volatile变量进行读写时候，每个线程从内存拷贝到cpu缓存中，如果有多个cpu，被不同的cpu处理，也就是说拷贝到不同的cpu cache中，
如果变量是volatile的，则直接从内存读取的，跳过cpu cache这一步。

并发编程java内存中有3个要素：原子性、可见性、有序性。
synchronized和lock可以保证原子性、可见性、有序性，但是代价太大了、
轻量级的锁volatile（有序和可见）和Atomic原子性。

举例：
synchronized = lock = volatile + Atomic 

//线程1:
init();   //语句1
inited = true;             //语句2
//线程2:
while(!inited ){
  work()
}

单线程没有问题。但是多线程情况下，处理器重拍命令，
假如发生了重排序，在线程1执行过程中先执行语句2，而此是线程2会以为初始化工作已经完成，那么就会跳出while循环，
去执行doSomethingwithconfig(context)方法，而此时context并没有被初始化，就会导致程序出错。

从上面可以看出，指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。


BlockingQueue为空获取元素被阻塞知道非空，添加元素满了被阻塞直到不满，常用于生产者和消费者，相当于对wait和notify的封装，
但是底层代码不是wait和notify，而是Lock和Condition的await,signal和signalAll 


ThreadLocal 是空间换时间，synchronized是时间换空间
注意：ThreadLocal只能是局限在各自使用的层级，如果涉及多个线程共同操作资源不嫩这么做，比如卖票；
比如说template设置每个调用的超时时间。
解决思路是：CommandLineRunner拦截restTemplate.setRequestFactory(ThreadLocalClientHttpRequestFactory);
ThreadLocalClientHttpRequestFactory中封装ThreadLoca超时时间，继承HttpComponentsClientRequestFactory ,
重写mergeRequestConfig方法，从ThreadLocal取出设置爱进去；
TransmittableThreadLocal ,俗称TTL，阿里产品，支持父线程的本地变量传递给子线程。线程池中。


springmvc中，一般controller,service,dao都是单例的，每个请求都是单独的线程，即使同时访问同一个controller，
相对于controller对象而言，只是读操作，没有写，不需要线程同步。
大多数情况下，不需要做同步处理，除非在bean中申明了实例变量或者静态变量，有修改的嫌疑，所以应该尽量避免定义实例变量。


Struts2中的ACTION因为会有user。bizEntity这样的实例对象，是有状态的。
多线程状态不安全，所以是多例的。


四大金刚~~~
闭锁：CountDownLatch，join的升级板，可以操作更多的线程；
栅栏：所有线程相互等待，直到所有线程都到达某一点时才打开栅栏，然后线程继续执行，比如开会；
交换机：线程交换数据
信号量：保护一个重要(代码)部分防止一次超过 N 个线程进入，限制并发。


ConcurrentHashMap采用了分段锁设计，只有在同一个分段之内才会有竞争关系。
保证并发的同时线程安全，分段锁个数就是并发数，默认是16.


CopyOnWriteArrayList
先从原有的数组中拷贝出来，然后新数组写操作，写完之后，将原来的数组引用指向新的数组；
由于所有的写操作都是在新的进行的，这个时候如果有并发的写，则通过锁控制，并发读不加锁。
1）如果写未完成，读的旧的数据；
2）如果写已经完成，但是引用来不及指向新的数组，读的旧的数据；
3）如果写已经完成，引用来指向新的数组，读的新的数据；



线程池提供了一个线程队列，队列中保存着所有等待县城的状态，避免了创建和销毁的开销，提升了相应速度。、
1、降低资源消耗，可以重复利用已经创建好的线程，降低了销毁的消耗
2、提升响应速度，任务达到时不用创建，而是立即执行
3、提高线程可管理性，进行统一的分配，调优和监控。



合理配置线程池的大小：
如果是cpu密集型，尽量压榨cpu，n*cpu+1
如果是io密集型，尽量压榨cpu，2*n*cpu



corePoolSize:最新维持的线程数，就算空闲也不杀死；
maxMumPoolSize:最大的数量
keepAliveTime:空闲的最大活着时间


通过execute方法提交任务时，当线程池中的线程数小于corePoolSize时，新提交的任务将通过创建一个新线程来执行，即使此时线程池中存在空闲线程。
通过execute方法提交任务时，当线程池中线程数量达到corePoolSize时，新提交的任务将被放入workQueue中，等待线程池中线程调度执行。
通过execute方法提交任务时，当workQueue已存满，且maxmumPoolSize大于corePoolSize时，新提交的任务将通过创建新线程执行。
当线程池中的线程执行完任务空闲时，会尝试从workQueue中取头结点任务执行。
通过execute方法提交任务，当线程池中线程数达到maxmumPoolSize，并且workQueue也存满时，新提交的任务由RejectedExecutionHandler执行拒绝操作。
当线程池中线程数超过corePoolSize，并且未配置allowCoreThreadTimeOut=true，空闲时间超过keepAliveTime的线程会被销毁，保持线程池中线程数为corePoolSize。（注：销毁空闲线程，保持线程数为corePoolSize，不是销毁corePoolSize中的线程。）
当设置allowCoreThreadTimeOut=true时，任何空闲时间超过keepAliveTime的线程都会被销毁


AbortPolicy：被拒绝的任务的处理程序，抛出一个 RejectedExecutionException 。
CallerRunsPolicy：一个被拒绝的任务的处理程序，直接在 execute方法的调用线程中运行被拒绝的任务，除非执行程序已经被关闭，否则这个任务被丢弃。
DiscardOldestPolicy：被拒绝的任务的处理程序，丢弃最旧的未处理请求，然后重试 execute ，除非执行程序关闭，在这种情况下，任务被丢弃。
DiscardPolicy：被拒绝的任务的处理程序静默地丢弃被拒绝的任务。



java.util.concurrent包借助CAS实现了区别synchronized同步锁的一种乐观锁。
内存值V，旧的预期值A，要修改的新值B，当且仅当V和A相同时，将内存值修改成B，否则什么都不做。
CAS关键点在于，系统在硬件层面保证了比较并交换操作的原子性。

java的native关键字表示通过JNI调用C++（底层）写的代码。

compareAndSet真实原理：
无限循环，获取当前值，比较内存和当前值，如果一致则修改当前值退出来了；
关键是如果不一致，继续循环，获取当前值（当前值变了），比较内存的致和当前的值，一直到一致后修改当前值并且退出为止。


lock和condition:
tryLock所有不容易产生死锁。
lock必须在finally中释放，否则有异常的话永远不会释放锁。
ReentrantLock会比synchronized好点，同样的测试时间少一半。


其实callable底层也是一个runnable,写了一个适配器RunnableFuture .

ReentrantLock和synchronized都是可重入锁，就是说拿到锁可以执行其他的同步方法不用重新申请锁了。
synchronized不是可中断锁，但是ReentrantLock是可中断锁。
等待时间最久的线程会获得锁这个就是公平锁。
synchronized是公平锁，ReentrantLock lock = new ReentrantLock(true);  true是公平锁，false不是。


虽然futrue以及相关的方法提供了异步执行任务的能力，但是获取结果很不方便，只能通过阻塞或者轮询的方式拿到结果。
阻塞的方式和我们异步编程的初衷相违背，轮询的方式耗费了无谓的cpu资源，
CompletableFutrue回调方式很好的解决了这个问题。



















---------------------------------------------------------------------------------------------------------------
------------------------------------------Concurrent.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Db Pool.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------



###############################
@数据库连接池-享元模式，节约了创建和销毁连接的时间。
网站一天10万访问量，数据库服务器就需要创建10万次连接，极大的浪费数据库的资源，并且极易造成数据库服
务器内存溢出、拓机。
如果循环中不断需要连接池，报错GetConnectionTimeoutException.异常


@实现源理
启动读取配置文件(ul,账户密码这些)，循环最大连接数，获得多个连接装入到LinkedListr中，
获取连接直接removeFirst
关键是调用Connetion.close方法如何还给list?
使用动态代理，判断如果不是close方法调用原来的逻辑，如果是close!则listConnections.add(conn);覆盖原来的逻辑。而不是调用实际的关闭方法。


@成熟产品
DBCP,Apache产品，没有自动回收空闲连接的功能，Tomcat使用
C3P0,开源的，支持JDBC3规范和JDBC2的标准扩展，
有自动回收空闲连接功能，c3p0随着并发的提高，性能急剧下降
DRUD,阿里出品，淘宝和支付宝专用数据库连接池，支
持所有JDBC兼容的数据库，对Oraclel的PS Cache内存占用优化，MySqlE的ping检测优化
防御SQL注入(WallFilter),最全面，扩展性最好，数组
维护连接池。为监控而生的DB连接池。

性能比拼：hikariCP>druid>tomcat-jdbc>dbcp>c3p0
。hikariCP的高性能得益于最大限度的避免锁竞争


@第一种配置：JNDI(基本不用)
它可以把Java对象放在一个容器中(JNDI容器)，并为
容器中的java对象取一个名称，以后程序想获得Java对象，只需通过名称检索即可。
其核心API为Context,它代表JNDl容器，其lookup方法为检索容器中对应名称的对象。
Context initCtx new InitialContext);
Context
envCtx
=
(Context)
initCtx.lookup("java:comp/env");
dataSource
(DataSource)envCtx.lookup("jdbc/datasource");
tomcat server.xml中：
<GlobalNamingResources>
<Resource name="jdbc/TestDB"auth="Container"
web.xml引用JNDI数据源


@第二种配置：data.properties
@tomcat.几个指标
maxThreads(最大线程数)：每一次HTTP请求到达Web
服务创建一个线程，最大线程数决定了Web服务可以同时
处理多少个请求，默认200.
accepCount(最大等待数)：当达到tomcat的最大线程
数时，还有新的HTTP请求这时tomcat:会将该请求放在等
待队列中，默认100.超过acceptCount就会被tomcat:拒绝
connection refused
maxConnections(最大连接数)：这个参数是指在同一
时间，tomcat能够接受的最大连接数。一般这个值要大
于maxThreads+acceptCount。


@druid源码
DruidDataSource implements ManagedDataSo
extends javax.sql.DataSource(回到原点)
getConnectionl的时候去init,如果已经init,return。
init方法：
final ReentrantLock lock=this.lock;//使用lock而不
是synchronized来保证多线程只有一次init
connections new DruidConnectionHolderlmaxActivel;
数组形式
createPhysicalConnection)生成真正的数据库连接
finally{lock.unlock;}释放锁，并且保证只会被执行一
次init
CountDownLatch initedLatch new CountDownLatch(2);
这一行：闭锁有2个，
DestroyConnectionThread和CreateConnectionThread
有2个countDown方法。相当于join的效果，当这几个线
程都执行完了才往下走。
getConnectionDirect->getConnectionlnternal->takeLastO
Lock-Condition.awaitO和singal
方法逻辑：先判断池中的连接数，如果到了，那么本线
程就得被挂起，同时释放empty信号，并且等待notEmpty
的信号。如果还有连接，就取出数组的最后一个，同时更
改poolingCount.。

(1)DruidDataSource持有一个DruidConnectionHolder的数组，保存所有的数据库连接
private volatile DruidConnectionHolder connections;/
注意这里的volatile,保证可见性和有序性，不能有原子性。

(2)DruidConnectionHolder持有数据库连接，还有所在
的DataSource等
private final DruidAbstractDataSource dataSource;
private final Connection conn;

(3)DruidPooledConnection
有DruidConnectionHolder,所在线程等
protected volatile DruidConnectionHolder holder;
private final Thread ownerThread;
最终我们对Connection的操作都是通过
DruidPooledConnection来实现，比如commit、rollback等，它们大都是通过实际的数据库连接完成工作。
重点看下close方法怎么实现的？
recycle(;并没有关闭连接，而是回收引用。
他的实现思路是：封装了一层，并不是直接给
Connection,而是DruidPooledConnection(静态代理)，里面的close方法不直接调用，而是装入到数组中，和动态代理一个模式。


@统计源码分析
简单的操作数据库通常涉及
datasource,connection,preparedstatement ,ResultSet东西，如果我要监控这些，必然要建些代理类。
我们的操作都由代理类完成，在完成的过程中，产生监控的数据。
实现类：PreparedStatementProxylmpl,就持有一
个java.sql.PreparedStatement统计包：JdbcStatementStat:private final AtomicLong
prepareCallCount=new AtomicLong(O);/执行preCall的计数
StatFilter调用
dataSourceStat.getStatementStat).incrementPrepareCo
unterO;
原理分析：比如说我要监控Statement:执行次数，肯定是
写一个Statement代理类，代理类有一个过滤器chain,再
执行前后进行累加操作，达到了监控的目的。
注意必须是AtomicLong保证多线程的原子性，涉及
个
计模式有代理模式，责任链模式。


---------------------------------------------------------------------------------------------------------------
------------------------------------------Db Pool.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------DDD.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------


@定义
领域：从大了看，领域代表整个公司的运作一切。从小了看，是每个组织运作中的一切。所以领域的概念必然与公
司的组织架构所承担的职责有一定的关系。
子域：一个领域内可以包含1个或者多个子域。理论上一个子域对应一个限界上下文是最优也是最理想的情况，但
是有时又要考虑到业务关联度需要做出权衡。子域又分核心域、支撑子域、通用子域。
核心域：它是整个业务领域的一部分，也是业务成功的主
要促成因素。从战略层面上讲，企业应该在核心域上胜人一筹。我们应该给予核心域最高的优先级、最资深的领域
专家和最优秀的开发团队。在实施DDD的过程中将主要关注核心域。
支撑子域：对应着业务的某些重要方面，但却不是核心，
那么它便是一个支撑子域。
通用子域：某个支撑子域的运用范围是整个系统，那么这
个子域便是通用子域。
界限上下文：一个限界上下文可能包含多个聚合，每个聚合都有一个根实体，即聚合根
上下文映射图：由多个界限上下文和子域组成的表示当前单个领域或者多个领域之间的集成关系图。
聚合根：意味着修改数据的一个最小单元。聚合内的所有对象要看成是一个整体最小单元进行保存。聚合的意义是维护聚合的内部一致性；
实体：对现实生活中的对象进行的抽象，通过标识而不具属性对它定义



@领域驱动设计
领域驱动设计是一种设计方法，试图解决的问题是软件的


@领域驱动设计
领域驱动设计是一种设计方法，试图解决的问题是软件的难以理解、难以演化。
领域驱动设计试图分离技术实现的复杂性，用围绕业务概念来构建领域模型的方式来控制业务的复杂性。
@DDD要解决的两个核心问题
1.业务架构如何合理的设计划分？
2.如何使系统架构与业务架构保持一致？


@微服务和DDD
以电商项目为例，分成核心领域（销售领域），支撑领域
(支付领域、用户领域、商品领域)，通用领域（订单领域、物流领域)
销售领域分成销售方式子域、售价子域
售价子域分成促销上下文、内容管理上下文、购买上下文
购买上下文的聚合根是商品购买信息，实体包括
XXA,XXB,XXC

---------------------------------------------------------------------------------------------------------------
------------------------------------------DDD.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------DesignerPattern.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------

@设计模式(Design pattern)是代码设计经验的总结，
集成高内聚低耦合的原则，可重用代码，可读性，扩展性，使代码工程化。

@23种口诀
去安利厂打工，每天都是克隆和建造产品，没意思离去，
迫于养家责任，观察到有一个中介公司，访问了，解释到：
每天命令自己好的工作状态，以老板为模板，一步一个迭代，用好的策略，否则到头来空空如也。我又进厂了，上司曰：邦我把死猪装到外婆桥的代理里面去，我听后毅然离去！


@几个原则深入
开闭，对扩展开放，对修改关闭
依赖倒转，依赖接口不要依赖实现类
接口隔离，功能单一的接口，不要上帝接口，降耦
迪米特，典型高内聚低耦合，最少知道依赖类的内部逻
辑，对外public,对内private


@工厂模式
简单工厂，一个方法不同参数返回不同实例，上帝方法，扩展性差，不符合开闭原则
工厂方法，针对每一种产品提供一个工厂类，符合开闭，
抽象工厂，奔驰宝马作为产品族，奔驰的工厂不只是生产具体的某一个产品，而是一族产品（奔驰轿车、奔驰SUV、奔驰MPV)。
不支持拓展增加产品；支持增加产品族
案例分析：java.sql.Connection!典型的抽象工厂接口
Statement、PreparedStatement、CallableStatement
SqlSessionFactory也是抽象工厂接口，Configuration:和
SqlSession都是在不同的产品等级上


@单例（枚举保证了线程安全）
不用频繁去创建和销毁实例，提升性能，多线程情况注意全局变量的读。
序列化注意复写readResolve方法，只一个实例
单例模式的线程安全有2种模式：1是获取单例的同步（多线程可能创建多个实例，枚举保证只有1个)；
2是spring:多线程共同访问单例逻辑的同步（注意全局变量只读)；


@建造者
httpClientBuilder,SpringApplicationBuilder
改造个性化的对象，比如说解析器，可以得到最基本参数的解析器，可以设置个性化参数得到想要的解析器。


@原型克隆
深克隆（完全独立，io流实现）
clone浅克隆（基本类型独立，数组对象供一个）


@适配器
类（继承），接口（实现多个），对象（持有对象的引用)


@桥接模式
对于两个独立变化的维度，当一个维度平等关系用接口
(邮件/短信/系统消息)，另外一个维度递进后者依赖的
用抽象类（普通/紧急/特急）
消息接口，不同的实现类；至于紧急程度一个抽象类持有
消息的引引用，正常和紧急子类继承抽象类，客户端可以自由搭配。


@装饰器和代理下增加功能和限制权限


@外观模式
slf4j,消息队列发送


@享元模式
int和Integer,数据库连接池，线程池，字符串缓冲池


@代理模式
静态（事先定义好）和动态（运行期生成）


@责任链
activiti,接收者依次传递下去


@命令模式
核心思想：一个commond接口，execute方法有一个handler参数（实际能干活的），一个执行器Executor,持有handler的引用，
客户端把handler注入到执行器，执行各种命令。解耦。


@解释器-解析表达式




###工厂模式
简单工厂~简单粗暴，上帝类，违背了开闭原则，根据type返回实例
工厂方法~每个实例一个工厂类，遵守开闭
抽象工厂~基于工厂方法，适用于产品族，2维模式


###单例
多线程的单例轮流使用CPU,可以节约创建和销毁对象的
时间提升性能，如果只是方法传参线程会开辟栈内存存储，不会有线程安全问题
如果单例有静态属性或者成员属性A,只读的话没关系，
有状态的修改要么用本地线程规避，要么获取单例同步，
要么A是个线程安全的类(hashtable等)
枚举默认序列化和同步了单例。spring默认所
有control,service,dao都是单例的。


###建造者模式
比如httpclientBuilder,applicationBuider,创建一个比较
复杂的对象，可以个性化定制快速创建，


###原型模式
创建一个比较复杂的对象，可以clone需要实现接口，
克隆基本属性独立，对象数组这些共享，深度克隆用流的



###原型模式
创建一个比较复杂的对象，可以clone需要实现接口，浅
克隆基本属性独立，对象数组这些共享，深度克隆用流的
方式完全独立。


###享元
Integer[因此在-128—127的这些数字都采用了这种设计
模式，反复用的都是一个对象。数据库连接池，string常量池。


###适配器
类适配器是继承A,实现B;对象适配器持有A对象实
例，实现；接口适配器接口方法太多了，抽象类实现空方法，业务类继承抽象的。


###组合模式
model类的属性结构，比如人员，有上级也是人员。


###装饰器
代码和静态代理差不多，场景不同，装饰者模式是动态的
给某个对象添加责任（侧重单个）。而代理的核心是控制权限访问（侧重一群）
和被代理者实现同一个接口，持有被代理者一个实例，干活。


###代理模式
静态，代码和装饰器差不多，要代理要么实现同一个接口jdk,要么成为子类复写方法cglib。
动态如果有很多对象需要代理，如果是静态的有很多少
码，而且是动态的(mybatis的mapper),动态就是一个共的。二进制生成码技术。
jdk,newProxyInstance方法一定要接口参数，还要
InvocationHandler[回调参数。
cglib,成为子类复写方法，MethodInterceptor


###外观模式
为子系统中的一组接口提供一个一致的界面，此模式定义
了一个高层接口，这个接口使得这一子系统更加容易用。屏蔽了内部的复杂性。
外观模式所有的请求处理都委托给子系统完成.内部逻辑外界来说是透明的。


###中介者
用一个中介对象来封装一系列的对象交互，使各对象不需要显式地相互引用，从而使其耦合松散，而且可以独立地
改变它们之间的交互。
spring ioc


###桥接模式
两个维度变化，比如说发送对象（邮件，短信，内部消息)，发送类型（特急，加急，普通）接口，发送对象实现类A,抽象类持有A的实例，发送类
型继承抽象类，做二维动作。


###责任链
对象由每一个对象对其下家的引用而连接起来形成一条链。请求在这个链上传递，直到链上的某一个对象决定处
理此请求。
但是每个责任者都是做的同一个方法（同一个接口)，Chain中list累计加一个，控制index的值使每一个责
任者按照秩序执行下去。index++;



###命令
command接口持有实际干活的上下文，实际业务类实现这个接口；
ICommandExecutor接口初始化干活的上下文
commandContext,持有实际业务类的实例
activitii设计模式


###解释器
当有一个简单的语言需要解释执行，并且可以将该语言的
每一个规则表示为一个类时，就可以使用解释模式；
最常见是解释表达式（或，且，非，activiti的条件表达式就是解释器模式)


###观察者
当一个对象被修改时，则会自动通知它的依赖对象
Observerable被观察者接口，定义增删改Observer对象；Observer接口，可以new多个观察者；
当修改时，notifyObserver循环通知list中的进行同步操作。


###状态
针对每次操作都有一堆的if/switch判断的情况，把每种状态抽象成一个实体类；


###策略
和解释器有点类似，但是解释器针对命令语法表达式的解释场景
Context持有策略对象，set进去，进行计算，根据不个需求产生不同的策略或算法的接口，开车奥迪，宝马



###模板方法
有几种入口，大体相同，有个别个性化操作，行为由父类控制，子类实现；
子类可以跳过步骤，或者重写个别逻辑。


###访问者
添加不同类型商品的购物车，当点击结算的时候，它计算出所有不同商品需付的费用。
通过访问者模式我们把此逻辑转移到了另外一个类上面。
让我们实现这个访问者模式的例子。
一个价格计算访问者类（里面定义了价格算法），一个税费计算访问者类（里面定义了税费算法），
通过这种方式，元素的执行算法可以随着访问者改变而改变。





---------------------------------------------------------------------------------------------------------------
------------------------------------------DesignerPattern.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Docker.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------


@go语言开发，容器技术和虚拟技术LXC,不依赖任何语言和框架
资源利用率高，硬盘兆B的使用，安全隔离好，一台机器上千个容器，轻量级，启动快速；


@三大组件-镜像、容器、仓库
原生的仓库https:/hub.docker.com提供了庞大的镜像集合供使用，和maven类似。


@一些细节
save命令导出镜像文件到tar
load反向的，把tar成为镜像文件
获取镜像：容器commit,build dockerfile,pull,load,tag
镜像加速，国内慢使用代理，网易的镜像地址：http:/hub-mirror.c.163.com


@一些命令
yum-y install docker-ce安装
yum remove docker-ce卸载
systemctl start docker:启动服务
tag:定义镜像的别名，每开发一个版本打一个标签，如果以后我想回滚版本，就可以使用指定标签的镜像来创建容器
docker run/stop运行/停止容器docker run-d-p 5:5 training/webapp python app.py
docker ps:查看容器进程
docker logs-f2b1b7a428627:容器的日志查看
docker pull/push拉取/推送镜像杀入容器底层：docker attach44fc0f0582d9;do个
exec -it 775c7c9ee1e1/bin/bash
docker ps和docker service:ps是docker的命令，service是swark的命令；
docker port bf08b7f2cd89:查看容器端口的映射
docker inspect wizardly_chandrasekhar:容器的配置和状态
docker imageslgrep fff:查看本地镜像


@构建镜像
每一个指令都会在镜像上创建一个新的层，


@swarm相关
docker:集群管理，和Kubernetes比较类似，但是更加轻，
具有的功能也较kubernetes更少一些。已经被KS取代。
docker run -d -e --name db affinity:container!=wwW-use1
mysql亲和度
docker service create --replicas 1 --name swarmtest
tomcatssh:v-集群副本控制
docker service scale swarmtest:=5-扩容缩容


@ K8S
创建集群，服务发现，应用安装，滚动升级，扩容缩容，Docker分布式系统的解决方案

@K8S资源对象
Master:负责整个集群的控制和管理，所有的控制命令都是发给它
kube-apiservice:Masteri进程，提供了HTTP REST接口，是k8s所有资源增删改查等操作的唯一入口
kube-controller-manager:Master:进程，一堆的controller管理，Replication Controller,Node ControllerNamespace Controller Token Controller ServiceController,Endpoint Controlle
kube-scheduler:Master进程，Pod调度和绑定到具个Node
Node:工作负载节点，运行着pod,高可用，物理主机或者虚拟机，可以动态注册到master,汇报心跳，一旦失联，标记不可用，触发工作负载大转移的自动流程
kubelet:Node进程，Pod的生命周期管理，Node管理，上报心跳到master
kubectl:Node进程，shell客户端
kube-proxy:Node进程，与Service的通信与负载均衡机制,每个Node上都运行着一个kube-proxy进程
Docker Engine:Docker的生命周期管理
Pod:最小的逻辑概念，有一个pause的根容器和一些业务容器，也可以一个业务容器，共享podip和挂载卷Volume,静态pod存储在node的文件里，普通pod在etcd里面；
EndPoint:PodIP Container Port
ReplicationController:RC,副本控制器，当副本小于期望的，根据模板创建副本。实现高可用。通过kubectl scale修改副本数量。
ReplicationSet:RS,1.2版本新概念，取代RC,基于集合的Label Selector,RC只能等式的。
DaemonSet:确保集群中每个node运行一份pod副本，当node加入集群时创建pod,当node离开集群时回收pod。比如运行集群日志收集守护进程，如fluentd、logstash。
Deploment:1.2版本新概念，在RS基础上集成了滚动升级，扩容等操作，更好解决pod编排问题，监控pod部署进度，创建Deploment会自动创建RS和pod,
Service:分布式集群架构的核心，由很多部署单元组成，kube-proxy负责把service下发的请求到后台某个pod上，内部实现负载均衡和会话保持，每个service一个虚拟IP,ClusterlP,
		Pod的EndPoit个着pod的创建和销毁变动，ClusterlP不会变
HPA:自动水平扩展，不能依赖手动，自动化，智能化，根据cpu利用率。
Label:标签，附加在各种资源对象里面，kube-controller进程通过，RC或者Deploment的通过定义的LabelSelectori查询和筛选同一组标签的资源，保持运行的副本数量全自动控制流程。
kube-proxy进程通过Servicel的Label Selector:来选择pod,
进行路由负载均衡。Node可以定义Label,pod定义NodeSelector:实现定向调度。


@外部访问Service【NodePort、LoadBalancer和Ingress】
Pod IP:Docker引擎分配的虚拟ip,虚拟二层网络，pod之间相互访问。
Node IP:Node节点ip,物理网卡ip,和k8s没关系
Cluster IP:servicel的，无法ping,无法再外部访问
NodePort http://Nodelp:NodePort/spec:type:
NodePort
LoadBalancer:每一个用LoadBalancer暴露的服务都会
有它自己的lP地址，每个用到的LoadBalancer都需要付费，这将是非常昂贵的
Ingress:k8s的nginx,类似nginx的service的负载均衡，client-ingress(a,b,c)-servicea,serviceb,servicec
Ingress可能是暴露服务的最强大方式，但同时也是最复杂的。Ingress控制器有各种类型，包括Google Cloud
Load Balancer,Nginx,Contour,Istio,等等。

apiVersion:extensions/v1beta1
kind:Ingress
metadata:
name:my-ingress
spec:
backend:
serviceName:other
servicePort:8080
rules:
host:foo.mydomain.com
http:
paths:
backend:
serviceName:foo
servicePort:8080
-host:mydomain.com
http:
paths:
-path:/bar/*
backend:
serviceName:bar#service的名称
servicePort:8080
引|入https,Secret


@文件格式
apiVersion:v1#k8s版本
kind:Pod#资源对象类型
metadata:#元数据
name:liveness-exec-pod#元数据的名称
namespace:default#元数据的命名空间，租户隔离
labels:#元数据的标签，用于RS或者deployment的
labelSelector
name:myapp
spec:#资源对象的属性值
containers:#属性值1-容器
name:livess-exec
image:busybox:latest
imagePullPolicy:IfNotPresent
command:["/bin/sh","-c","touch /tmp/test;sleep 30;rm-f
/tmp/test;sleep 3600
livenessProbe:
exec:
command:["test","-e","/tmp/test"
initialDelaySeconds:1
periodSeconds:3
apiVersion:v1
kind:ReplicationController
metadata:
name:php-apache
spec:
replicas:1
template:
metadata:
name:php-apache
labels:
app:php-apache
spec:
containers:
name:php-apache
image:gcr.io/google_containers/hpa-example:latest
imagePullPolicy:IfNotPresent
resources:
requests:
cpu:200m
ports:
containerPort:80


@滚动升级
当集群中的某个服务需要升级时，我们需要停止目前与方
服务相关的所有Pod,然后重新拉取镜像并启动。如.个群规模比较大，则这样操作就比较困难，
Kubernetes提供了rolling-update.功能来解决这个困难。
滚动升级通过执行命令kubectl rolling-update命令一键完成，改命令会创建一个新的RC,然后控制I旧的RC中的Pod数量逐渐减少到O,同时新的RC中的
Pod数量逐渐增加到目标值，最终实现Pod升级。（注：新|旧RC需在同一个Namespace中)
/更新frontend-v1的pod到frontend-v2
kubectl rolling-update frontend-v1 frontend-v2-
image=image:v2
/更新frontend的pods,不更改replication controllerl的名称
kubectl rolling-update frontend --image=image:v2


@安装
systemctl start etcd
systemctl start docker
systemctl start kube-apiservice
systemctl start kube-controller-manager
systemctl start kube-scheduler
systemctl start kubelet
systemctl start kube-proxy
ETCD
GO编写，轻量级zk,高可用，强一致性(raft算法)，分布式存储服务，Kubernetes使用Etcd作为数据存储后端，把需要记录的pod、rc、service等资源信息存储在Etcd中


@常用命令
kubectl [get/delete/create/apply/describe][pods/svc]
name
kubectl cluster-info
kubectl create -f
xxx.yaml(包
pod,service,deployment,rs,rc)
kubectl get podslgrep xxx
kubectl get pods-sort-by=.metadata.name#排序
kubectl get po xxx-o wide#查看pod到哪个节点了
kubectl get po xxx-o yaml#详细信息
kubectl describe pod xxx#看详情
kubectl delete pod xxx
kubectl scale pod xxx-replicas=3#扩容缩容
kubectl logs xxxx
kubectl get configmaplgrep xxx
kubectl describe configmap xxx
kubectl create configmap xxx
kubectl get deploymentlgrep xxx
kubectl get nodes#节点信息
kubectl get nodes,pods#节点和pod信息
kubectl describe node xxx
kubectl get endpointslgrep xxx
kubectl get svclgrep xxx#服务信息
kubectl get pod/pod1pod/pod2#获取2个
kubectl create -f xxx1.yaml -f xxx2.yaml -f xxx3.yam

@亲和度affinity
reqire必须的
prefer不要的

@liveness:监控监测
(httpAction,Exec,Tcp)

@存储卷Volume
Pod中能够被多个容器访问的共享目录
Pod中先定义一个volume,在容器中引用，并且mount到容
器的某个目录上。
apiVersion:v1
kind:Pod
metadata:
name:volume-pod
spec:
volumes:
-name:app-logs#定义一个名称
emptyDir:#类型，
containers:
name:tomcat
image:tomcat
ports:
containerPort:8080
volumeMounts:
name:app-logs
mountPath:/usr/local/tomcat,/logs#挂载的容器内部的目录
name:app-logs2
hostPath:
path:/etc/ssl/certs
name:busybox
image:busybox
command:["sh","-c","tail -f /logs/catalina*.log"
volumeMounts:
-name:app-logs
mountPath:/logs#挂载的容器内部的目录
这里设置的Volume名为app-logs,类型为emptyDir,挂载到tomcat容器内/usr/local/tomcat,logs目录同时挂载到logreader容器内的/logs目录
tomcat向其中写日志文件，busybox读取日志文件。
emptyDir:l临时数据，pod离开了这个宿主机，EmptyDirr中的数据就会被永久
HostDir:本地数据卷，宿主机上的指定目录
NFS:网络数据卷


@Namespace(命名空间)
kubernetes系统中的另一个重要的概念，通过将系统内部
的对象“分配”到不同的Namespace中，形成逻辑上分组的不同项目、小组或用户组，便于不同的分组在
共享使用整个集群的资源的同时还能被分别管理。启动后
创建一个名为“default”的Namespace,如果不特别指明Namespace,则用户创建的Pod、RC、Service都
被系统创建到“default”的Namespacel中。可以实现对用户的分组，即“多租户”管理。对不同的租户还可以进
行单独的资源配额设置和管理，使得整个集群的资源配置非常灵活、方便。
kubectl get namespace
kubectl get pods-namespace:=development#需要加上
参数
apiVersion:v1
kind:Namespace
metadata:
name:development
labels:
name:development


@配置文件
Unit(After,want Required)Service Install
/usr/lib/systemd/system/etcd.service
/usr/lib/systemd/system/kube-apiserver.service

@安全设置
http:/apiserver:8080是非安全端口
各个组件访问apiserver,CA签名证书（最安全），生成crt和key文件，或者token方式

@网络配置
pod0的容器1需要访问pod1中的容器2，打通Docker容器和容器之间的网络，不同node之间，不同pod之间器
1)Flannel:Pod1与Pod2不在同一台主机。Pod的地址
是与docker0在同一个网段的，但dockerO网段与宿主机网卡是两个完全不同的P网段，
并且不同Node之间的通信只能通过宿主机的物理网卡进
行。将Pod的IP和所在Node的IP关联起来，通过这个关联让Pod可以互相访问。

2)直接路由：route add-net命令
route add134.105.0.0mask255.255.0.0134.105.64.1
意思是：所有需要发往134.105.0.0/16地址段的1P数据包，全部由134.105.64.1路径。
@重要的属性
imagePullPolicy:(always总是下载最新的，Never,总是使
用本地的，IfNotPresent:本地有使用本地的否则下载)
ports:
-port:30080//service端口，集群内其他pod访问本pod
的时候，需要的一个port,如nginx的pod访问mysql的pod
targetPort:80/pod端口，targetporti说过是pod暴露出
来的port端口，当nginxl的一个请求到达service的33306端口时，service就会将此请求根据selector中的name,将请求到mysql-pod这个pod的3306端口上
nodePort:31/NodePort,外部暴露的端口号
nodeport:是集群外流量访问集群内服务的端口类型，比如客户访问nginx,apache,
port是集群内的pod互相通信用的端口类型，比如nginx访问mysql,而mysql是不需要让客户访问到的
targetport,顾名思义，目标端口，也就是最终端口，也就是pod的端口。
Pod
在目录/etc/kubelet.d中放入static-web.yaml文件，创建静态pod;

静态Pod无法通过API Server直接管理，所以在Master节
点尝试这个Pod,将会使其标为Pending状态，且不会被。
创建Pod有两种方式：配置文件或HTTP方式
重启策略：Always(容器失效时自动重启该容器)OnFailure(容器终止运行且退出码不为O时重启)Never(不论状态为何不重启该容器)
在yaml编排文件中restartPolicy:OnFailure要和container并排。

健康检查：
liveness~~~(容器是否存活Running:状态)
exec:在容器内执行命令
httpGet:访问容器的http服务，可以指定httpHeaders
tcpSocket:访问容器的TCP端口
readiness~~~~(容器是否启动完成ready状态)
node调度之NodeSelector,定向器，只调度到某个拥有特定标签的Node上
node调度之NodeAffinity,亲和度，取代了定向器，NodeAffinity在NodeSelector的基础之上的进行了扩展，使调度更加灵活，除了有一个必须要满足条件的
Node之外，还要可设置优先条件
NodeAffinity语法支持的操作符有ln、NotIn、Exists
创建pod时，节点亲和性有两个，也就是说如果某个Node运行这个Pod,那么这个Node需要满足的条件有两个，
第一个条件是属性为
requiredDuringSchedulinglgnoredDuringExecution,此
为硬性条件，必须要满足的：beta.kubernetes.io/arch=amd64
第二个条件属性为
preferredDuringSchedulinglgnoredDuringExecution
为软性条件，即优先满足的条件，尽可能会满足，如朱元
法满足就退而求其次.运行在其它Node之上



@pod外挂配置管理ConfigMap
apiVersion:v1
data:
special.passwd:yaodidiao
special.user:zhenyu
kind:ConfigMap
metadata:
creation Timestamp:2017-03-21T03:36:12Z
name:game-config-4
namespace:default
resourceVersion:3003915
selfLink:
/api/v1/namespaces/default/configmaps/game-config-
4
uid:8802f6d2-0de7-11e7-b3d5-fa163ebba51b

第一种：通过环境变量引入外挂文件
apiVersion:v1
kind:Pod
metadata:
labels:
name:testenv
role:master
name:testenv
spec:
containers:
name:testenv
image:busybox
imagePullPolicy:IfNotPresent
env:
name:SPECIAL USER
valueFrom:
configMapKeyRef:
n2ma·2mo-confin_M


第二种：通过volumeMounts:挂载
spec:
containers:
name:testvolume
image:busybox
imagePullPolicy:IfNotPresent
volumeMounts:
name:config-volume
mountPath:/etc/config
command:
-sleep
-"360"
volumes:
-name:config-volume
configMap:
name:game-contig
Kubernetes-apiserver

登录master节点，curl localhost:8080/api/v1/pods获取
所有pod
暴露部分rest,通过kubectl proxy1代理实现swagger-ui:master节点
http:/192.168.1.128:8080/swagger-ui/


@Java访问API
HttpClient;Rest Template;Feign





@ docker命令
docker pull images_name-拉去镜像
docker rmi image_name
docker images-所有镜像
docker imageslgrep tomcat
docker imageslgrep node-planner-查找镜像
docker
10.22.142.114:10020/smart5g.node.planner:12
docker pull 10.22.142.114:10020/sd-czj-eureka-serv
docker inspect imageid
docker inspect imageid查看镜像详细信息
docker run hello-world
docker rm hello-world
docker run--name=con_name images
docker ps
docker logs -f sd_mysql.1.3104tlygoo18uqmy8w6pr
docker run -p 8021:8021 10.22.142.114:10020/sd.car.service:1

#我们扩展了应用程序并启用了负载均衡。为此，我
须在分布式应用程序的层次结构中进行一级升级：



服务只能“在容器里生成”。一个服务只运行一个镜
编写一个docker-compose.yml文件。
docker service Islgrep car
docker build -t 10.22.142.114:10020/smart5g-r
planner:12./-根据Dockerfilet创建镜像
docker login -u dockerdev -p12 10.22.142.114:10020
docker push 10.22.142.114:10020/smart5g-r planner:12
docker history sd.car.service
http:/10.22.142.114:10020/v2/catalog-查看远像。

curl http:/172.31.130.18:20202/v2/_catalog
docker pull 10.22.142.114:10020/sd-webservice:1
docker build -t 10.22.142.114:10020/sd-webservice:
docker push 10.22.142.114:10020/sd-webservice:1
docker build -t 10.22.142.114:10020/sd-czj-eu
server:1./
docker
push
10.22.142.114:10020/sd-czj-eu server:1
docker build -t 10.22.142.114:10020/sd-czi-eu




node-planner:12
docker pull 10.22.142.114:10020/sd-webservice:1
docker tag 10.22.142.114:10020/sd-webservice:1
hiya1-webservice:1
docker save -o smart5g-node-planner.12.tar.gz sma
node-planner:12
创建镜像：
(1 docker commit -m "con_name"co
image_name
(2 )Dockerfile docker build
10.22.142.114:10020/smart5g-node-planner:12./
http://127.0.0.1:8106/smartdesigner/car/v1/cars
http://100.101.26.233:8021/smartdesigner/car/v1/
sd-car
进入docker容器：
docker pslgrep kong
docker exec -it 6af608deeff5 bash
Docker Service:是一种声明式的、可扩展的负应用。
Docker Service是面向用户的应用


http://127.0.0.1:8106/smartdesigner/car/v1/cars
http://100.101.26.233:8021/smartdesigner/car/v1/
sd-car
进入docker容器：
docker pslgrep kong
docker exec -it 6af608deeff5 bash
Docker Service:是一种声明式的、可扩展的、负载均应用。Docker Service是面向用户的应用，而Dc
Swarm是面向IT的节点集群。
docker service rm g5_kong
docker
stack
deploy
/opt/5G/blueprint/psrvList/kong.yml g5 --with-reg





~~~~~在线安装：
yum -y install http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm
yum install docker-io
service docker start 
docker version








~~~~离线安装
wget https://download.docker.com/linux/static/stable/x86_64/docker-18.06.1-ce.tgz

cd /home/hiya001/softwares/docker/

tar -xvf docker-18.06.1-ce.tgz

cp docker/* /usr/bin/


vim /etc/systemd/system/docker.service

[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network-online.target firewalld.service
Wants=network-online.target
  
[Service]
Type=notify
# the default is not to use systemd for cgroups because the delegate issues still
# exists and systemd currently does not support the cgroup feature set required
# for containers run by docker
ExecStart=/usr/bin/dockerd
ExecReload=/bin/kill -s HUP $MAINPID
# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity
# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
#TasksMax=infinity
TimeoutStartSec=0
# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes
# kill only the docker process, not all processes in the cgroup
KillMode=process
# restart the docker process if it exits prematurely
Restart=on-failure
StartLimitBurst=3
StartLimitInterval=60s
  
[Install]
WantedBy=multi-user.target


#添加文件权限并启动docker
chmod +x /etc/systemd/system/docker.service 

#重新加载配置文件
systemctl daemon-reload                

#启动Docker 
systemctl start docker        
  
#设置开机自启
systemctl enable docker.service        

#查看Docker状态
systemctl status docker         

#查看Docker版本
docker -v           

docker pull tomcat
阿里云->容器镜像服务->镜像中心->镜像加速器
https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors
镜像加速器 https://tgg47v9o.mirror.aliyuncs.com
vim /etc/docker/daemon.json 
{
  "registry-mirrors": ["https://tgg47v9o.mirror.aliyuncs.com"]
}
sudo systemctl daemon-reload
sudo systemctl restart docker



docker save tomcat -o tomcat.tar
docker save registry -o registry.tar

docker load -i tomcat.tar
docker load -i registry.tar

docker run -p 8081:8080 -d tomcat

docker images


问题描述：
执行docker服务 systemctl restart docker 没有正常启动，查看docker服务的状态
查看日志：
journalctl -u docker --no-pager
clould not change group /var/run/docker.sock to docker:group docker not found
解决方案：
groupadd docker 



问题描述：
Failed to connect to containered:exec:"docker-container":executable file not found in $PATH
解决方案：
cd /home/hiya001/softwares/docker/
cp docker/* /usr/bin/


usr指的是Unix System resource,
/usr不是user的缩写，其实usr是Unix Software Resource的缩写， 也就是Unix操作系统软件资源所放置的目录，
而不是用户的数据；所有系统默认的软件都会放置到/usr, 系统安装完时，这个目录会占用最多的硬盘容量
/usr/bin/，绝大部分的用户可使用指令都放在这里。请注意到他与/bin的不同之处。


docker info 可以看出详细信息
默认的工作目录 Docker Root Dir:/var/bin/docker
默认pull的镜像仓库是 https://registry-1.docker.io/v2


DockerHub 是一个由 Docker 公司运行和管理的基于云的存储库。它是一个在线存储库，Docker 镜像可以由其他用户发布和使用。
有两种库：公共存储库和私有存储库。如果你是一家公司，你可以在你自己的组织内拥有一个私有存储库，而公共镜像可以被任何人使用。
下载公共镜像不需要注册的，但是上传要注册，而且需要互联网，所以一定要有自己的私有仓库。

搭建本地仓库
常见的镜像仓库
Docker Registry：Docker Registry是最流行的开源私有镜像仓库，以镜像格式发布，在下载后运行一个Docker Registry容器即可启动一个私有镜像仓库服务
VMware Harbor：由VMware中国研发团队开发的开源容器镜像仓库系统，基于Docker Registry并对其进行了许多增强
SUSE Portus：SUSE Portus是另一个开源镜像库，在Registry：Docker封装权限控制供功能
ECR：亚马逊的， 完全托管的 Docker 容器注册表，可使开发人员轻松存储、管理和部署 Docker 容器映像。


Registry2提供了快速存储和分发镜像功能，但是没有权限控制，界面操作也没有；
 
 
 ----一些命令
 docker -v
 docker info
 docker images 
 docker ps
 docker container ps
 docker run
 
 
 
先login：http://kweecr02-beta.huawei.com:80
再pull:  docker pull tomcat:1.0
 
docker search httpd
docker build -f Dockerfile -t tomcat:1.0
docker tag
docker save -o registry.tar docker.io/registry
docker load -i  registry.tar
docker exec -it tomcat1 /bin/bash


搭建registry
docker pull registry:2
docker run -d -p 5000:5000 --restart=always --name registry registry:2
docker push localhost:5000/ubuntu

查看仓库有哪些镜像
10.0.07:5000/v2/_catalog


比如有个tomcat基础镜像，应用镜像在这个基础上copy war到webapp下面，应用镜像启动一个实例；
然后又一个密封的容器实例，可以docker exec -it杀入内部，其实就是tomcat内部，目录可以挂载到宿主机器；
一个宿主机器可以运行上千个实例

一个镜像是惊天的模板，基于一个镜像启动2个实例，实际理解为2个独立的容器，每个容器都是以这个模板创建的，各有各的空间；
docker run -d -p 8081:8080 --restart=always --name tomcat1 tomcat:1.0
docker run -d -p 8082:8080 --restart=always --name tomcat2 tomcat:1.0



基于tomcat镜像发布war
docker tag sadfsafsd tomcat8:v1.1

docker run -d -p 8081:8080 --restart=always --name tomcat1 tomcat:1.0

dicker logs 71152520

docker stop 71152520

docker exec -it tomcat1 /bin/bash

docker ps -a

docker rm -f 71152520
docker rmi -f 54366671152520


FROM tomcat2:1.0
MAINTAINER caozhijun
RUN mkdir /applog
RUN mkdir /appfile
ADD hiya-public-docker-1.0.0.war /tctHome/tomcat/webapps
CMD["/tctHome/tomcat/bin/catalina.sh","run"]


cd /home/hiya001/softwares/images/
docker build -t tomcat:2.0 .
docker build -t pod1:3.0 .
(空格.不能少啊，否则报错 docker build requires exactly 1 arguments)


docker run -d -p 8088:8080 --restart=always --name tomcat1 tomcat:2.0

docke inspect tomcat:2.0

docke search tomcat

##一直访问404，我的神啊，原来疏忽了，application.properties里面的端口号和上下文根是本地的tomcat才会生效的
#docker里面的tomcat的port和context在tomcat的配置文件里面啊 
http://10.72.4.196:8080/hiya-public-docker/docker/








## harbor 的搭建

#高速安装docker-compose
a.下载二进制文件
curl -L https://get.daocloud.io/docker/compose/releases/download/1.27.2/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose

b.赋予二进制文件可执行权限
chmod +x /usr/local/bin/docker-compose

c.测试是否安装成功
# docker-compose --version
docker-compose version 1.16.1, build 6d1ac21

# docker-compose命令帮助信息
build    config   down     exec     images   logs     port     pull     restart  run      start    top      up       
bundle   create   events   help     kill     pause    ps       push     rm       scale    stop     unpause  version  




#安装harbor
https://github.com/goharbor/harbor/releases/tag/v2.0.2

tar -zxf harbor-offline-installer-v2.0.2.tgz

修改harbor.cfg
#hostname 改为本地ip，非 Mac OS系统 可以不指定端口
hostname = 192.168.1.111:9090
#设置secretkey_path 的路径为 当前目录的data下
secretkey_path = ./data


通过运行 install.sh 构建镜像，并把服务启动起来：
./install.sh

出现：ERROR: Failed to Setup IP tables: Unable to enable SKIP DNAT rule:  (iptables failed: iptables --wait -t nat -I DOCKER -i br-2add1a39bc5d -j RETURN: iptables: No chain/target/match by that name.
原因是关闭防火墙之后docker需要重启，执行以下命令重启docker即可：
service docker restart

然后再  ./install.sh

[Step 3]: checking existing instance of Harbor ...
[Step 4]: starting Harbor ...
Creating network "harbor_harbor" with the default driver
Creating harbor-log ... done
Creating harbor-db          ... done
Creating harbor-adminserver ... done
Creating registry           ... done
Creating harbor-ui          ... done
Creating harbor-jobservice  ... done
Creating nginx              ... done

✔ ----Harbor has been installed and started successfully.----

Now you should be able to visit the admin portal at http://192.168.1.111.
For more details, please visit https://github.com/vmware/harbor .


启动：docker-compose up -d

停止：docker-compose stop



默认80端口，要修改在docker-compose.yml里面
http协议默认就是80端口 ，所以直接访问http://192.168.1.111就可以了。。。。

访问   http://192.168.1.111/harbor
默认 admin 用户的密码为 Harbor12345 ，可以在 harbor.cfg 进行修改。


docker login -u admin -p Harbor12345 192.168.1.111:80
[root@localhost ~]# docker login 192.168.126.162
Username: admin
Password: 
Error response from daemon: Get https://192.168.126.162/v2/: read tcp 192.168.126.162:49654->192.168.126.162:443: read: connection reset bypeer
 解决方法：
 docker-compose down -v
 
查找docker.service所在的位置 
[root@localhost ~]# find / -name docker.service -type f 

注意是在node节点执行，不是在master ，这样node节点可以pull镜像；
vim /lib/systemd/system/docker.service 

修改配置文件，ExecStart之后添加–insecure-registry=192.168.1.111
[Unit]
Description=Docker Application Container Engine
Documentation=http://docs.docker.io  //重要
After=network.target
Wants=docker-storage-setup.service
Requires=docker-cleanup.timer

[Service]
Type=notify
NotifyAccess=main
EnvironmentFile=-/run/containers/registries.conf
EnvironmentFile=-/etc/sysconfig/docker
EnvironmentFile=-/etc/sysconfig/docker-storage
EnvironmentFile=-/etc/sysconfig/docker-network
Environment=GOTRACEBACK=crash
Environment=DOCKER_HTTP_HOST_COMPAT=1
Environment=PATH=/usr/libexec/docker:/usr/bin:/usr/sbin
ExecStart=/usr/bin/dockerd-current \
		  --add-runtime docker-runc=/usr/libexec/docker/docker-runc-current \
		  --default-runtime=docker-runc \
		  --exec-opt native.cgroupdriver=systemd \
		  --userland-proxy-path=/usr/libexec/docker/docker-proxy-current \
		  --init-path=/usr/libexec/docker/docker-init-current \
		  --seccomp-profile=/etc/docker/seccomp.json \
		  $OPTIONS \
		  $DOCKER_STORAGE_OPTIONS \
		  $DOCKER_NETWORK_OPTIONS \
		  $ADD_REGISTRY \
		  $BLOCK_REGISTRY \
		  $INSECURE_REGISTRY \
	  $REGISTRIES --insecure-registry=192.168.1.111  //重要
	  
	  
	  
重启Docker服务
systemctl daemon-reload
systemctl restart docker
docker-compose up -d

docker login -u admin -p Harbor12345 192.168.1.111
Login Succeeded




 
docker tag pod1:3.0 192.168.1.111/hiya-public/pod1:3.0
docker tag pod2:3.0 192.168.1.111/hiya-public/pod2:3.0

docker push 192.168.1.111/hiya-public/pod1:3.0
docker push 192.168.1.111/hiya-public/pod2:3.0

遇到错误：Get https://192.168.1.111/v1/_ping: http: server gave HTTP response to HTTPS client
原因：打tag的时候 不能是 192.168.1.111:80/hiya-public/pod1:1.0  改成  192.168.1.111/hiya-public/pod1:1.0



http://192.168.1.111/harbor/projects/3/repositories，在 hiya-public 项目下可以看见刚上传的 nginx镜像



[root@hiya_vm_001 images]# docker pull 192.168.1.111/hiya-public/pod1:1.0
Trying to pull repository 192.168.1.111/hiya-public/pod1 ...
1.0: Pulling from 192.168.1.111/hiya-public/pod1
Digest: sha256:723d4f928602351ba970a5d83727c2587a4fd163a39f91e0e8a123a9510eaa70
Status: Image is up to date for 192.168.1.111/hiya-public/pod1:1.0
[root@hiya_vm_001 images]# docker images
REPOSITORY                       TAG                 IMAGE ID            CREATED             SIZE
192.168.1.111/hiya-public/pod1   1.0                 f313ed7b5b12        4 minutes ago       667 MB
pod1                             1.0                 f313ed7b5b12        4 minutes ago       667 MB
192.168.1.111/hiya-public/pod2   1.0                 74ec6ebbcce4        3 hours ago         667 MB
pod2                             1.0                 74ec6ebbcce4        3 hours ago         667 MB
docker.io/tomcat                 latest              5f47aad0b70e        2 days ago          647 MB
vmware/harbor-log                v1.3.0-rc4          58aa9393b1cd        2 years ago         207 MB
vmware/harbor-jobservice         v1.3.0-rc4          b3664e837ab8        2 years ago         197 MB
vmware/harbor-ui                 v1.3.0-rc4          5f6e4c4b41da        2 years ago         211 MB
vmware/harbor-adminserver        v1.3.0-rc4          a907519f7baf        2 years ago         174 MB
vmware/harbor-db                 v1.3.0-rc4          83b013940805        2 years ago         586 MB
vmware/photon                    1.0                 7b154bf6f104        2 years ago         130 MB
vmware/clair                     v2.0.1-photon       7a633033c5b1        2 years ago         365 MB
vmware/postgresql                9.6.5-photon        a5c79b0473d9        2 years ago         285 MB
vmware/registry                  2.6.2-photon        c38af846a0da        2 years ago         240 MB
vmware/mariadb-photon            10.2.10             eaaae71dea19        2 years ago         586 MB
vmware/notary-photon             signer-0.5.1        064b309ad822        2 years ago         246 MB
vmware/notary-photon             server-0.5.1        b8cc51024379        2 years ago         247 MB
vmware/nginx-photon              1.11.13             2971c92cc1ae        2 years ago         200 MB
vmware/harbor-db-migrator        1.3                 6cac2b89f086        2 years ago         1.11 GB



[root@hiya_vm_001 images]# ll
总用量 37244
-rw-r--r--. 1 root root      201 9月  13 23:08 Dockerfile
-rw-r--r--. 1 root root 19065767 9月  13 19:08 hiya-public-k8s-pod1-1.0.0.war
-rw-r--r--. 1 root root 19065711 9月  13 19:08 hiya-public-k8s-pod2-1.0.0.war
[root@hiya_vm_001 images]#






---------------------------------------------------------------------------------------------------------------
------------------------------------------Docker.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Dubbo.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------


@透明化远程服务调用，什么叫透明化，就像本地一样。
每天为2千多个服务提供大于30亿访问量支持（久经考验)。
这样理解，dubbo是一个分布式的RPC框架，扛起2干万
服务器和3亿请求的服务治理和监控框架，默认dubbo协
议请求方式是tcp协议，可以是http协议，rest协议用的是http协议。
netty封装http,tcp,udp。


@api工程是共用的，消费端怎么去调用一个没有实现类的接口？
答案是动态代理，代理类持有一个可以调用RPC的对象
(服务提供方的接口)，去做真实的业务逻辑。
要实现RPCProxyClient代理类，代理类的invoke方法中封装了与远端服务通信的细节，消费方首先从
RPCProxyClient获得服务提供方的接口，当执行helloWorldService.sayHello(“test”)


@动态代理有了，消息数据格式有了，那么序列化如何？
目前国内各大互联网公司广泛使用hessian、protobuf、thrift、avro等成熟的序列化解决
方案来搭建RPC框架，这些都是久经考验的解决方案。


@通信
如何实现RPC的？基于netty的NIO(长连接)。
RPC是在Socket的基础上实现的，工作在传输层，个在TcP协议之上，速度更快，http(比如springcloud)
作在应用层。

SOA
面向服务的架构体系，衍生出了一系列相应的技术，如对服务提供、服务调用、连接处理、通信协议、序列化方
式、服务发现、服务路由、日志输出等行为进行封装的服务框架.
关键功能：服务治理！


@四大中心
Provider:暴露服务的服务提供中心。
Consumer:调用远程服务的服务消费中心。
Registry:服务注册与发现的注册中心。
Monitor:统计服务的调用次数和调用时间的监控中心。
服务提供者在启动时，向注册中心注册自己提供的服务。
服务消费者在启动时，向注册中心订阅自己所需的服务，
服务有变动热推送；
关于调用，软负载均衡，容错机制，限流，熔断。
@注册中心
zk每个节点最大1M


@协议
Dubbo支持多种协议，在通信过程中，不同的服务等级一般
对应着不同的服务质量，那么选择合适的协议便是一件非
常重要的事情。你可以根据你应用的创建来选择。
例如，使用RM协议，一般会受到防火墙的限制，所以对
于外部与内部进行通信的场景就不要使用RM协议，而是
基于HTTP协议或者Hessian协议。
dubbo协议不适合传送大数据量的服务，比如传文件，传视频等，除非请求量很低，小数据量大并发的服务调用。
长连接的意义：比如Morgan的提供者只有6台提供者，却有上百台消费者，每天有1.5亿次调用，
如果采用常个hessian服务，服务提供者很容易就被压跨，通过单一连接，保证单一消费者不会压死提供者，
长连接，减少连接握手验证等，并使用异步，复用线程池，防止C10K问题。
dubbo协议采用单一长连接，即每个消费者和服务提供者
建立一个tcp长连接，消费者调用一次接口后还保持着连接。
Hessiant协议底层采用Http通讯。


@可视化治理
dubbo-admin-2.4.1.war,配置zk地址OK了
webapps/ROOT/WEB-INF/dubbo.properties
dubbo.registry.address=zookeeper://127.0.0.1:2181
dubbo.admin.root.password=root
dubbo.admin.guest.password=guest


@服务治理（服务降级，服务容错，服务熔断，服务限流)
入服务治理是为了对整体的RPC调用进行集中化管理。对
我们来说其核心价值在于，
减少重复劳动、避免手动配置物理文件产生的问题、降低
开发人员的技术运用成本。
服务治理的一些关键活动包括：
1.对开发新服务和升级现有服务的计划
2.管理服务的生命周期：确保升级服务不会影响目前的服
务消费者制定方针来限制服务行为：
3.制定所有服务都要遵从的规则，确保服务的一致性
4.监控服务的性能：由于服务组合，服务停机和性能低下的后果是严重的。通过监控服务的性能和可用性，当问题出现的时候能马上采取应对措施。
5.管理由谁来调用服务、怎样调用服务


@源码-和spring集成方法
定义一些<dubbo:service>等类似的标签，个
在dubbo.xsd中我们主要关注service和reference标签义写在META-INF/spring.handlers
http\://code.alibabatech.com/schema/dubbo=com.alib
aba.dubbo.config.spring.schema.DubboNamespaceHan
dler,这里看到了DubboNamespaceHandler;
DubboNamespaceHandler:针对dubbo集成spring的侵入式处理器，
init方法调用registerBeanDefinitionParser(service",
new
DubboBeanDefinitionParser(ServiceBean.class,
true));
对于每个组件都有一个config和bean,比如ServiceConfig和ServiceBean



@源码-serviceBean:是何时暴露服务的？
ServiceBean<T>extends ServiceConfig<T>implements
Initializing Bean,
DisposableBean,
ApplicationContextAware,
ApplicationListener,
BeanNameAware
afterPropertiesSet方法，有个export,这个export方法
就是将本地服务暴露给外面调用的过程，这样就保证了
spring容器在初始化完成的时候，所有的serivceBean都暴露服务了
Initializing Bean接口：
Spring为bean提供了两种初始化bean的方式，实现
InitializingBean:接口，实现afterPropertiesSet方法，或者
在配置文件中通过init-method指定，两种方式可以同时使用。
实现InitializingBean接口是直接调用afterPropertiesSet方法，比通过反射调用init-method指定的方法效率要高一点，但是init-method:方式消除了对springl的依赖。
doExport(》doExportUrls(》
proxyFactory:接口写了SPI标签，所以这里默认使用户

是javassistProxyFactory,最后到了个@SPI("netty")
public interface Transporter》nettyTransporter》
NettyServer.doOpen(看到了bootstrap等netty原生类了，哈哈
调用nettyl的意义是开辟了一个NIO的长连接服务器，一直监听客户端的请求。
返回Exporti对象之后，register第一个要做的事情就是打注册中心，本例为zookeeper.。
至于注册到z水，只是把服务元数据保存到了
zk(在ResitryBean,里面，ZookeeperRegistry),实际是开启了一个长连接。
本地暴露过程相对简单，主要是通过扩展机制使
用JavassitFactoryi对业务类进行动态代理生成一个动态代理对象，
使用injvmProtocol把invokert包装为一个Exporter.。最后放
到ServiceConfigl的一个属性exports里。exports是一个list集合。
首先ServiceConfig类拿到对外提供服务的实际类ref(如
HelloWorldlmpl),然后通过ProxyFactoryl的getlnvoker
方法使用ref生成一个AbstractProxylnvoker3实例，到这一
步就完成具体服务到Invoker的转化。接下来就是Invoker+协议转换到Exporter的过程。



@源码-服务如何消费？
ReferenceConfig类的init方法调用Protocol的refer方法生
成Invoker3实例，这是服务消费的关键
private T createProxy(Map<String,String>map){构建
invoker关键所在；
return (T)proxyFactory.getProxy(invoker);
以下是JdkProxyFactory和JavassistProxyFactory
个理对象，都是InvokerInvocationHandler
return (T)Proxy.getProxy(interfaces).newInstance(new
InvokerlnvocationHandler(invoker));
return
(T)
Proxy.newProxylnstance(Thread.currentThread).getCon
textClassLoaderO,
interfaces,
new
InvokerInvocationHandler(invoker));
所以调用的时候一定会走
InvokerInvocationHandler.invokeO;
Abstractlnvoker.dolnvoke(invocation)
Dubbolnvoker
消费者端和生产者端交互的大概流程进行了讲解，流程主
要分为三个部分，分别是：消费者发起调用请求、生产者
响应调用请求
和消费者获取调用结果，概括一下就是消费者通过生成的
代理对象调用invoke方法通过Netty的通道去请求生产者的exporteri进行执行，并且通过future的方式将异步的交互转为了同步响应。
Invoker中封装了服务的实现类，和invoke方法，Exporter
持有getlnvokery对象；将Invoker封装成Exporter,并缓存
起来，缓存里使用Invoker的url作为key
public interface Exporter<T>{
Invoker<T>getlnvokerO;
请求来到时，根据请求信息生成key,到缓存查
找Exporter,就找到了Invoker,根据Invoker getProxy.
就可以完成调用。
NettyClient类doOpen方法调用服务端的netty服务获取数据。



@dubbo的设计模式
责任链模式
个dubbo的调用拦截机制是通过Filter扩展点来实现的，服务提供端来说，在服务实现类真正处理请求之前，请求需要
依次经过如下filter的处理：
EchoFilter --ClassLoaderFilter --GenericFilter --
ContextFilter-->ExceptionFilter --
TimeoutFilter-->MonitorFilter --TraceFilter
ProtocolFilterWrapper.buildInvokerChain
private static <T>Invoker<T>buildlnvokerChain(final
Invoker<T>invoker,String key,String group){
Invoker<T>last invoker;
List<Filter>
filters
ExtensionLoader.getExtensionLoader(Filter.class).getAc
tivateExtension(invoker.getUrl(),key,group);
if (filters.size(>0){
for (int i filters.size-1;i >0;i--){
final Filter filter filters.get(i);
final Invoker<T>next last;
last new Invoker<T>0{


观察者模式
Dubbo中使用观察者模式最典型的例子
是RegistryService。
消费者在初始化的时候回调用subscribe方法，注册一个
观察者，如果观察者引用的服务地址列表发生改变，就会
通过NotifyListeneri通知消费者。
public void subscribe(URL url,NotifyListener listener){
super.subscribe(url,listener);
subscribed(url,listener);
}


修饰器模式
Dubbo中还大量用到了修饰器模式。比如
ProtocolFilterWrapper类是对Protocol类的修个
在export和refer方法中，配合责任链模式，
ProtocolFilterWrapper:和持有的引l用共同实现一个接口，
和静态代理太像了，实现功能增强。
public class ProtocolFilterWrapper implements Protocol
{
private final Protocol protocol;
public <T>Invoker<T>refer(Class<T>type,URL url)
throws RpcException
if
(Constants.REGISTRY_PROTOCOL.equals(url.getProtoc
ol(){
return protocol.refer(type,url);
}
return buildlnvokerChain(protocol.refer(type,url),
Constants.REFERENCE_FILTER_KEY,
Constants.CONSUMER);
}


工厂方法模式
CacheFactory的实现采用的是工厂方法模
式。CacheFactory:接口定义getCache方法，然后定义一
个AbstractCacheFactory:抽象
类实现CacheFactory,并将实际创建cache的
createCache方法分离出来，并设置为抽象方法。这样具
体cache的创建工作就留给
具体的子类去完成。


抽象工厂模式
ProxyFactory.及其子类是Dubbo中使用抽象工厂模式的典型例子。ProxyFactory提供两个方法，分别用来生产
Proxy:和Invoker(
这两个方法签名看起来有些矛盾，因为getProxy方法霁西传入一个Invoker对象，而getlnvoker:方法需要传个个Proxy:对象，
看起来会形成循环依赖，但其实两个方式使用的场景不一
样)。AbstractProxyFactory实现了ProxyFactory接口，作为具体实现类的抽象父类。然后定义了JdkProxyFactory和
JavassistProxyFactory两个具体类，分别用来生产基于
jdk代理机制和基于
javassist代理机制的Proxy和Invoker.。


代理模式
Dubbo consumer使用Proxy.类创建远程服务的本地代理，本地代理实现和远程服务一样的接口，并且屏蔽了网络通
信的细节，使得用户在使用本地代理的时候，感觉和使用本地服务一样。




2.7.0之前属于阿里巴巴，2.7.0之后捐献给apache,包名改了；

https://github.com/apache/dubbo/tree/dubbo-2.6.0

eclipse 发布,上下文是dubbo-admin 

dubbo.registry.address=zookeeper://192.168.1.111:2181?backup=192.168.1.112:2181,192.168.1.113:2181
dubbo.admin.root.password=root
dubbo.admin.guest.password=root

http://127.0.0.1:8080/




DubboMonitor发布到dubbo,配置好zk地址，DubboMonitor就有了提供者；
业务代码放开DubboMonitor的监控，定时向提供者汇报调用统计信息写入到zk,DubboMonitor界面安装之后会统计zk的可视化。

dubbo-admin 是服务可视化，不是监控可视化。

出参序列化，指定序列化的名称。
提供者和消费者的版本要保持一致，否则提供没有提供者；

~消费者~
zookeeper.ZookeeperRegistry
[DUBBO]Registrer: consumer://
[DUBBO]Subscribe: consumer://
[DUBBO]Notify urls for subscribe url: consumer://

~提供者~
[DUBBO] dubbo://
[DUBBO] provider://
[DUBBO] provider://


dubbo.registry.address=zookeeper://192.168.1.111:2181?backup=10.72.4.1976:2181,10.72.4.198:2181


Dubboadmin和DubboMonitor都属于Dubbo OPS运维工具

Dubbo 缺省会在启动时检查依赖的服务是否可用，不可用时会抛出异常，阻止 Spring 初始化完成，以便上线时，能及早发现问题，默认 check="true"。
可以通过 check="false" 关闭检查，比如，测试时，有些服务不关心，或者出现了循环依赖，必须有一方先启动。
dubbo.reference.com.foo.BarService.check=false
dubbo.reference.check=false
dubbo.consumer.check=false
dubbo.registry.check=false



dubbo.protocol.dispatcher=all 所有消息都派发到线程池，包括请求，响应，连接事件，断开事件，心跳等。
dubbo.protocol.threadpool=cached 缓存线程池，空闲一分钟自动删除，需要时重建。



有时候希望人工管理服务提供者的上线和下线，此时需将注册中心标识为非动态管理模式。
<dubbo:registry address="10.20.141.150:9090" dynamic="false" />




多注册中心注册




RpcContext 是一个 ThreadLocal 的临时状态记录器，当接收到 RPC 请求，或发起 RPC 请求时，RpcContext 的状态都会变化。
比如：A 调 B，B 再调 C，则 B 机器上，在 B 调 C 之前，RpcContext 记录的是 A 调 B 的信息，在 B 调 C 之后，RpcContext
 记录的是 B 调 C 的信息。
String serverIP = RpcContext.getContext().getRemoteHost();



moke 通常用于服务降级，比如某验权服务，当服务提供方全部挂掉后，客户端不抛出异常，而是通过 Mock 数据返回授权失败。
<dubbo:reference interface="com.foo.BarService" mock="com.foo.BarServiceMock" />  实现同一个接口


限制 com.foo.BarService 的每个方法，服务器端并发执行（或占用线程池线程数）不能超过 10 个：
<dubbo:service interface="com.foo.BarService" executes="10" />


设置优雅停机超时时间，缺省超时时间是 10 秒，如果超时则强制关闭。
dubbo.service.shutdown.wait=10000


当业务线程池满时，我们需要知道线程都在等待哪些资源、条件，以找到系统的瓶颈点或异常点。dubbo通过Jstack自动导出线程堆栈来保留现场，方便排查问题
dubbo.application.dump.directory=/tmp



主要原理是消费端在请求需要鉴权的服务时，会通过SK、请求元数据、时间戳、参数等信息来生成对应的请求签名，通过Dubbo的Attahcment机制携带
到对端进行验签，验签通过才进行业务逻辑处理。
@Service(parameters = {"service.auth","true","param.sign","true"})
public class AuthDemoServiceImpl implements AuthService {
}














---------------------------------------------------------------------------------------------------------------
------------------------------------------Dubbo.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------DynamicProxy.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------


@Javassist jboss子项目，动态改变类的结构和创建类程序在运行期而不是编译器去生成代理对象。。


@一种是有一个类实现了接口，想要实现功能增强，代
理类实现InvocationHandler接口，持有真实对象的引用，反射机制前后进行功能增强；
Proxy.newProxylnstance(Thread.currentThreadO.getCon
textClassLoader),target.getClass(.getInterfaces),this);
源码解析：newProxyInstance实际上是利用javassist3实现
动态生成class类的机制，该类实现目标接口；ProxyGenerator.generateProxyClass利用lO流把class类生成到硬盘。

第二种情况是：只提供接口给你，凡是没有实现类你把接口给我，我给你生成一个代理类，每次调用代理类的方法其实是：
我持有sqlSession对象（正在能够干活的），根据你传进
来的参数进行增删改
查。mapperMethod.execute(sqlSession,args);


@适合场景：审计日志注解和spring事物注解是一个样的，开发一个切面，在目标方法前面或者后面植入公共的代码逻辑。


@模拟mybatis
public interface HiyaMybatis
{
void addBook(String args);
void updateBook(String args);
}

package com.hiya.deeps.mybatis;
public class HiyaMybatisHandler
public void doBusiness(String args)
{
if("add".equalslgnoreCase(args))
System.out.println("Add。。。。。。。");
else if("update".equalslgnoreCase(args))
{
System.out.println(Update。。。。。。。");
}
}
}
package com.hiya.deeps.mybatis;
import java.lang.reflect.InvocationHandler;
import java.lang.reflect.Method;
import java.lang.reflect.Proxy;
public class HiyaMybatisProxy<T>implements
InvocationHandler
{
private HiyaMybatisHandler handler;
private Class<T>hiyalnterface;
public HiyaMybatisProxy(HiyaMybatisHandler handler,
Class<T>hiyalnterface)
{
super);
this.handler handler;
this.hiyalnterface hiyalnterface;
}
@Override
public Object invoke(Object proxy,Method met
个
Object[]args)throws Throwable
{
handler.doBusiness(args[O].toStringO);
return null;
}
@SuppressWarnings("unchecked")
public T getProxy)
{
return
(T)
Proxy.newProxyInstance(hiyalnterface.getClassLoaderO
new Class{hiyalnterface }this);
}
package com.hiya.deeps.mybatis;
public class HiyaMybatisFactory<T>
{
public static <T>T getBean(Class<T>targetInterface)
{
HiyaMybatisHandler
handler
new
HiyaMybatisHandlerO;
HiyaMybatisProxy<T>hmp new HiyaMybatisProxy<T>
(handler,targetlnterface);
return (T)hmp.getProxyo;
}
}
package com.hiya.deeps.mybatis;
public class HiyaMybatisClient
{
public static void main(String args)
{
HiyaMybatis
hm
HiyaMybatisFactory.getBean(IHiyaMybatis.class);
hm.addBook("add");
hm.updateBook("update");


---------------------------------------------------------------------------------------------------------------
------------------------------------------DynamicProxy.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------ELK.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------



1面向文档存储的nosql--ElasticSearch和MongoDb较
es偏向于检索、查询、数据分析，适用于OLA统。
mongodb偏向于大数据规模下的CRUD,适用于务要求不强的OLTP系统
都是以json格式管理数据的nosql数据库；
都支持CR作；
都支持聚合和全文检索；
都支持分片和复制。；
持阉割版的join操作。
都支持处理超大规模数据；
目前都不支持事务或者叫阉割版的事务。
es是java编写，通过RESTFul接口操作数据。
mon是C++编写，通过driver操作数据。
(es对java开发好，利于排查理解)
mongodb的分片有hash和rangei两种方式，es只有一种。
es是天生分布式，主副分片自动分配和复制，开用。
mongodb的分布式是由“前置查询路由+配置+shard:集合”，需要手动配置集群服务。
内部存储ES是到排索引+docvalues+fielddata。

es全文检索有强大的分析器且可以灵活组合，查询时
匹配。mongodb的全文检索字段个数有限制。
es所有字段自动索引l,mongodb的字段需要手动索引
es非实时有数据丢失窗口。mongodb实时理论上无
丢失风险。



2 OLTPhe
OLTP:联机事务处理(On-Line transaction Processin
统的关系型数据库的主要应用，主要是基本的、日常
务处理，例如银行交易。OLTP系统强调数据库的内率，强调内存各种指标的命令率，强调绑定变量，强发操作。
OLAP:联机分析处理(On-Line Analytical Processing)
仓库系统的主要应用，支持复杂的分析操作，侧重决持，并支持提供直观易懂的查询结果，OLAP强调的
分析，强调SQL执行市场，强调磁盘I/O,强调分区等。
3es本质（百台服务器，处理PB级别）
存储，索引、搜索、排序、过滤。高扩展的分布式全索引擎，近乎实时的存储、检索数据，处理PB级别据。
使用Lucene作为其核心，通过简单的RESTful API3来Lucene的复杂性。

Lucene.只是一个库。Lucene:非常复杂，你需要深入
检索的相关知识来理解它是如何工作的才能用它。
Relational DB =Databases =Tables =Row Columns
Elasticsearch =Index=>doc Types =Document Fields

支持插件机制，分词插件、同步插件、Hadoop插件视化插件等。


4一些词汇
每个索引|有一或多个分片(shard),每个分片可以
个副本(replica)分片(shard):Elasticsearch集群允许系统存储的
量超过单机容量，实现这一目标引入分片策略shard一个索引index中，数据(document)被分片
(sharding)到多个分片上。Elasticsearch屏蔽了管
片的复杂性，使得多个分片呈现出一个大索引的样子
当你查询的索引分布在多个分片上时，E会把查询
给每个相关的分片，并将结果组合在一起，而应用程
不知道分片的存在。即：这个过程对用户来说是透明副本(replica)副本策略对index中的每个分片创建
的副本，处理查询时可以把这些副本当做主分片来
(primary shard),此外副本策略提供了高可用和数全的保障。

路由(routing)当向Elasticsearch存放数据时，根据标识符_id将文档分配到多个分片上，负载均衡算法
要实现平均即可。当取用数据时，查询所有的分片然总结果，而并不必须知道数据到底存在哪个分片上。
shard hash(routing)%numberofprimary_shards


5全文检索和倒排索引
全文检索使用倒排索引，根据单个关键词查找多个文
倒排索引~~可以根据单词快速获取包含这个单词的列表，提高查询效率。
ES的一次搜索，是一次scatter/gather过程（这mapreduce也很类似)


6查询类型SearchType.QUERY._THEN_FETCH
QUERY_AND_FETCH、QUERY_THEN_FETCH、DFS
RY_AND_FETCH和DFS_QUERY_THEN_FETCH


7新浪日志处理
LOGS->Flume-Logstash-Rsyslog -Kafka -Logsta
ElasticSearch->Kibana
(1)Kafka:接收用户日志的消息队列。
(2)Logstash:做日志解析，统一成JSON输Elasticsearch.
(3)Elasticsearch:实时日志分析服务的核心技术个schemaless,实时的数据存储服务，通过index:组据，兼具强大的搜索和统计功能。
(4)Kibana:基于Elasticsearch的数据可视化组件强的数据可视化能力是众多公司选择ELK stack的重因。


8ES-Hadoop整合
es和hadoop属于两个不同的框架，如果想互相共享来处理，就需要自己来写程序把各自的数据导入需要方，过程非常繁琐，并且需要关注各自框架的版本，容易出现问题。
ES-Hadoopl的出现则解决了这个问题，我们可以把它是ES和Hadoop:大数据生态圈之间的数据桥梁，通过我们可以快速的分析Hadoop里面的海量数据。
HDFS--ES-Hadoop--ElasticSearch


9 Logstash
Inputs,Outputs,Codecs,Filters(grok表达式)构.
Logstash的核心配置项。
-数据源
input
file
path =>"/tmp/access_log"
start_position =beginning
}
-过滤处理
filter
if [path]="access"{
mutate replace =>"type"=>"apache_access"}
grok
match =>"message"=
(COMBINEDAPACHELOG}"}
}
}
date
match ="timestamp","dd/MMM/yyyy:HH:mm:
]
}
}
-把数据推到es去
output
elasticsearch
host =localhost
}
stdout codec =rubydebug
}


10 Beats
Metricbeat:将Metricbeat部署到您所
Linux、Windows和Mac主机，并将它连
Elasticsearch就大功告成啦：您可以获取系统级的使用率、内存、文件系统、磁盘0和网络0统计数以及获得如同系统上top命令类似的各个进程的统据.
Heartbeat:keeplived主要是控制ip的漂移，配置、应单，而hearbeat!则不但可以控制ip的漂移，更擅长对服务的控制(mysq的重启)，配置，应用比较复杂。
heartbeat或keepalived可以提供一个
1P:10.0.0.102,用户只需要访问10.0.0.102，当A服务时，VIP会设置在A服务器上，当B提供服务时，会设置在B服务器上，这样就可以让用户通过
10.0.0.102来获取web服务，即使A或B服务器切换也响用户的正常访问。
Filebeat:日志文件托运工具，



11 Elasticsearch源码
Elasticsearch作为分布式集群，客户端到服务端，节节点间通信有TCP和Http通信协议，底层实现为Ne架。
Netty4 HttpServerTransport类
首先，NettyHttpServerTransport会负责进行监听H求。通过配置http.netty.http.blocking_server你可以是Nio还是传统的阻塞式服务。
默认是NIO。该类置pipeline的时候，最后添加了HttpRequestHandler以具体的接受到请求后的处理逻辑就由该类来完成了




---------------------------------------------------------------------------------------------------------------
------------------------------------------ELK.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Go Language.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------


@概述
G语言是谷歌推出的一种全新的编程语言，可以在不损失应用程序性能的情况下降低代码的复杂性。
2008年，Google创建，和K8S,Go一般比Python要快30倍
自动回收内存；函数返回多个，getName(p1,p2iint)
(name1,name2,name3 string){return错误处理，defer取代一层层的try catch
并发编程（协程goroutine,协程之间采用消息队列传递chanl相当于管道，当一个协程阻塞让出cpu,轻量级的
进程，百万每秒)
func sum0 go sum);


@Java和GO
Java能够做到的事情Go都能够做到，甚至能够做得更
好。现在Java用于服务端开发的最多，而Go完全能够胜任。
在Java里面有分布式，多线程，微服务，RPC等，用Go
语言也完全不虚，分布式，微服务架构就有用G实的，
一样非常方便快捷。时下流行的趋势是大数据，人工智能，数据挖掘，机器学习等，这些用Java做起来很麻烦，
都有相应的编程语言和框架，用G自然也可以做。在这方面Java和Go的能力基本相当。
那么，Go语言真的是天衣无缝的吗？不，Java框架稳定，技术成熟。当我想要一种什么技术的时候，Java的耳
源框架必然会给出适合的技术解决方案，而且绝不个种。而G语言就没有这个优势了，毕竟作为新兴技术，它的
各类开源框架还不够多。我用过一款Beego的框架，感觉还不错。G短期内还是不能取代Java。
Go语言是编程语言设计的又一次尝试，是对类C语言的重大改进，它不但能让你访问底层操作系统，还提供了强大的网络编程和并发编程支持。
G语言的用途众多，可以进行网络编程、系统编程、并发编程、分布式编程。


@场景
web代理、TCP通信采集前端数据、avro编解码、日志处理、数据打包、编写网络服务和AP处理日志、数据打包、虚拟机处理、文件系统、分布式系统、数据库代理等、网络编程方面，
Go语言广泛应用于Web应用、API应用、下载应用等；
除此之外，G语言还可用于内存数据库和云平台领域，目前国外很多云平台都是采用G0开发。
Nsq:Nsq是由Go语言开发的高性能、高可用消息队列系统，性能非常高，每天能处理数十亿条的消息；
Docker:基于lxc的一个虚拟打包工具，能够实现PAAS平台的组建。
Doozer/Etcd:分布式同步工具，类似ZooKeeper
God:类似redis的缓存系统，但是支持分布式和扩展性
Go:网络流量抓包和重放工具
G语言作为一门大型项目开发语言，在很多大公司相继使用，甚至完全转向Go开发，
其中代表有Google、Facebook、腾讯、百度、阿里巴巴、京东、小米以及360、美团、滴滴以及新浪等


@开发框架
网络开发框架：Beego,MVC、ORM、内置缓存处理玛序、会话处理工具、日志记录机制、操作HTTP对个与Django:很相似的地方是它的命令行工具。例如，你可以使用bee从头创建Beego应用或管理现有的应用。


@命令
go version
go build xx.go
go run xx.go
日志输出为fmt.printf


@个人理解
线程模型主要有三种：
1、内核级别线程；
2、用户级别线程；
3、混合线程

程序不会直接调用系统内核线程，而是利用内核线程的一
种高级接口-LWP用户线程，也就是我们平时所说的线程。
java线程会和native线程有个一一映射的关系，LWP与内
核线程之间1：1的关系称为一对一线程模型，Thread类就
可以发现有很多的native方法，这就涉及到操作系统的线程
在java中创建的线程是与OS线程一一对应的，而在go中
多个协程(goroutine)对应一个逻辑处理器，每个逻辑处理器与OS线程一一对应。
go中存在两级策略，一个是go语言层面的调度多个协程
公用一个时间片，一个是0s层面的调度多个逻辑处理器轮询占用不同的时间片。
go创建一个goroutine,调度器会将其放入全局队列。调
度器为每个goroutine分配一个逻辑处理器。并放到逻辑处理器的本地队列中
本地队列中的goroutine会一直等待直到被逻辑处理器运行
因为在创建协程的数量上一般没有特别的限制，所
个以很轻松的创建出很多个协程出来，而java因为采h是1：1的线程模型，线程数量特别是并发线程数会受到CPU和操作系统的限制


@ G-P-M模型
G就是goroutine,通过go关键字创建，用户线程，对OS透明，具备轻量级，可以大量创建，上下文切换成本低
P:Processor即逻辑处理器，默认GO运行时的Processor数量等于CPU数量，也可以通过GOMAXPROCS函数指定P的数量
M:是操作系统创建的系统线程，属于OS资源Java中Thread实际上就是对M的封装，通过指定runQ函数指定要执行的逻辑。GO语言中讲二者分开，通过P建立G和M的联系从而执行。

P是G的管理者，P将G交由M执行。P的存在解耦了G和
M,当M执行的G被阻塞时，P可以绑定到其他M上继续执行其管理的G,提升并发性能。
runtime.GOMAXPROCS(runtime.NumCPU():设置逻辑调度器和cpu核数相等
goroutine是轻量级的线程，占用的资源非常小(Go将每个goroutine stack的size默认设置为2k)线程的切换由操作系统控制，而goroutine的切换则由用户控制；
Go scheduler实现了M:N的G-P-M线程调度模型。




---------------------------------------------------------------------------------------------------------------
------------------------------------------Go Language.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------JVM.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------


@内存组成
堆，线程栈，方法区，PC


@类加载
Bootstrap ClassLoade:C++编写，核心类库rt.jar,i18n.jar (java_home/jre/lib
Extension (java_home/jre/ext/lib)
AppClassLoader:(classpath)

父类委托机制：1是jvm规范，2是已存在的类
加载的3个步骤：
装载(Load),二进制文件（三种加载）
链接(Link),验证，准备，解析
初始化(nitialize):静态变量赋初始值


@调优工具(pid:1192)

jps -v:
虚拟机进程状态列表

jstack:
当前时刻的线程快照，新找出pid(ps-eflgrep java)11901,
找出耗时的线程(top-Hp pid)-H显示线程信息，-p指定pid,4498,
4498的十六进制是1192，jstack11901|grep1192


jmap:打印java进程的堆内存信息，
jmap-dump:live,format=b,file=fileName pid:将内存使用情况导出到文件中，再用jhat、MAT、VisualVM分析查看，以便查找内存溢出原因
jmap-heap pid:查看堆的配置信息


jstat:强大的工具，
jstat-class1192:类加载情况
Loaded Bytes Unloaded Bytes Time
1575617355.600.011.29
jstat-compiler1192:编译统计
Compiled Failed Invalid Time FailedType FailedMethod
9142 1 0 5.01 1 org/apache/felix/resolver/Resolverlmpl
jstat-gcnewcapacity1192:新生代内存统计
jstat-gcoldcapacity1192:老年代内存统计
jstat-gccapacity1192:总堆内存统计
jstat-gcnew1192:新生代垃圾回收统计
jstat-gcold1192:老年代垃圾回收统计
jstat-gcutil1192:总垃圾回收统计
jstat-gc1192:垃圾回收统计
SOC:第一个幸存区的大小
S1C:第二个幸存区的大小
SOU:第一个幸存区的使用大小
S1U:第二个幸存区的使用大小
EC:伊甸园区的大小
EU:伊甸园区的使用大小
OC:老年代大小
OU:老年代使用大小
MC:方法区大小
MU:方法区使用大小
CCSC:压缩类空间大小
CCSU:压缩类空间使用大小
YGC:年轻代垃圾回收次数
YGCT:年轻代垃圾回收消耗时间
FGC:老年代垃圾回收次数
FGCT:老年代垃圾回收消耗时间
GCT:垃圾回收消耗总时间
NGCMN:新生代最小容量
NGCMX:新生代最大容量
NGCMX:新生代最大容量
NGC:当前新生代容量
SOC:第一个幸存区大小
S1C:第二个幸存区的大小
EC:伊甸园区的大小
OGCMN:老年代最小容量
OGCMX:老年代最大容量
OGC:当前老年代大小
OC:当前老年代大小
MCMN:最小元数据容量
MCMX:最大元数据容量
MC:当前元数据空间大小
CCSMN:最小压缩类空间大小
CCSMX:最大压缩类空间大小
CCSC:当前压缩类空间大小
YGC:年轻代gc次数
FGC:老年代GC次数
iconsole:控制台监控信息


@内存机制
Runtime data area(堆，栈，PC,方法区)
栈：当前线程8种基本类型，非基本引用，局部变量，参
数，运算结果，并且当线程运行完毕后，这些内存也就被自动回收。
方法区：共享，class类信息、（名称/修饰符/Field等）和
方法信息，静态变量，final常量，包括Constant Pooli和String池。-XX:PermSize
在调用方法时，VM会在当前线程的栈中生成一个栈帧，
用来存放局部变量以及字节码的操作数，并且这个栈帧大
小是提前计算好的，且不要求连续分布。当方法执行完比之后，进行出栈操作。

堆：共享，存储对象实例和数组值，新生代10M,Eden为8M,两块Survivor各占1M(118原则)，

持久代&方法区
方法区物理上存在于堆里，而且是在堆的持久代里面；但
在逻辑上，方法区和堆是独立的。
一般说堆的持久代就是说方法区，因为一旦VM把方法区(类信息，常量池，静态字段，方法)加载进内存以后，
这些内存一般是不会被回收的了。
jdk1.8后变成元空间，元空间不再占用堆中的空间，而永久带却是在堆中开辟空间。


@垃圾回收
标记清除/整理-老年代
复制-新生代
效率：复制算法>标记/整理算法>标记/清除算法（标记/清除算法有内存碎片问题，给大对象分配内存时可能
会触发新一轮垃圾回收)
内存整齐率：复制算法=标记/整理算法>标记/清除算法
内存利用率：标记/整理算法=标记/清除算法>复制算法

@内存泄漏（检查工具：leakcanary)
##尽量少用静态变量，因为静态变量是全局的，GC不会回收的；
##大集合对象拥有大数据量的业务对象的时候，可以考虑分块进行处理，然后解决一块释放一块的策略
##单例模式的内存泄漏，长生命周期的对象持有短生命周期的
public class PendingOrderManager
private static PendingOrderManager instance;
private WeakReference<Context>wr;-private Context
mContext;
public PendingOrderManager(Context context){
wr new WeakReference<>(context);--this.mConte.context;
}
public static PendingOrderManager getlnstance(Context
context){
if (instance =null){
instance new PendingOrderManager(context);
return instance;
}
}
soft reference和weak reference一样，但被GC回收的时候需要多一个条件：当系统内存不足时
soft reference指向的object才会被回收.正因为有这个特性，soft reference.比weak reference
更加适合做cache objects的reference.因为它可以尽可能的retain cached objects,减少重建他们所需的时间和消耗.


@调优
持久代一般固定大小为64m。
-Xss1024K,JDK5.0以后每个线程栈大小为1M;
-XX:NewRatio=4,年轻代与年老代所占比值为1：4，年轻代占整个堆栈的1/5
-XX:SurvivorRatio=4,两个Survivorl区与一个Eden区的比值为2：4，一个Survivorl区占整个年轻代的1/6


@总结
eclipse:编译clean build是把java文件编译成class文件，
这时候还没有进内存，只有运行时调用new,反射机制，
调用静态变量，静态方法才会加载到内存中，并且初始化。
在Java语言里面，类型的加载和连接都是在程序运行完成。先触发其父类的初始化。在JVM中并不是一次，
所有的文件都加载到，而是一步一步的，按照需要来加载。


@tomcat/启动时，会创建几种类加载器：
当应用需要到某个类时，则会按照下面的顺序进行类加
载：
1使用bootstrap引导类加载器加载
2使用system系统类加载器加载
3使用应用类加载器在WEB-INF/classes中加载
4使用应用类加载器在WEB-NF/Iib中加载
5使用common类加载器在CATALINA_HOME/Iib中加载
Webapp1 Webapp2.…
通过对上面tomcat类加载机制的理解，就不难明白为什么java文件放在Eclipser中的src文件夹下会优先jar包中的class?


@实际案例
Memory
Analyzer1.8.1下载：
https://www.eclipse.org/mat/downloads.php
X64是64位的操作系统，X86是32位操作系统，X86_64
是64和32兼容性的操作系统
LeakSuspects/:溢出怀疑对象
Problem Suspect1,Problem Suspect2(对象列表)点
击Details?
Shallow Heap表示自身的对大小不包含引用的额，
Retained Heap:表示和引用的一起的固定占用堆大小。
Accumulation:累积
jmap -dump:live,format=b,file=a.hprof 41024


1局部垃圾收集(Scavenge GC)和Full GC
Scavenge GC~当新对象生成，并且在Eden申请空间失败时，就会触发Scavenge GC。
Full GC~对整个堆进行整理，包括Young、Tenured和
Perm。慢，年老代和持久带被写满会触发Full GC.



2一般JVM规则
持久代一般固定大小为64m,-Xmn2g:设置年轻代大小
为2G。整个堆大小=年轻代大小+年老代大小+持久代大小。
-XX:NewRatio:=3年轻代与年老代比值为1：3，年轻代占整个年轻代年老代和的1/4
-XX:SurvivorRatio=3,表示Eden:Survivor:=3:2,一
个Survivor[区占整个年轻代的1/5

1)监控GC的状态
使用各种JVM工具，查看当前日志，分析当前JVM参数设置，并且分析当前堆内存快照和gc日志，根据实际的各区
域内存划分和GC执行时间，觉得是否进行优化；

2)分析结果，判断是否需要优化
如果各项参数设置合理，系统没有超时日志出现，GC频率不高，GC耗时不高，那么没有必要进行GC优化；如果GC时间超过1-3秒，或者频繁GC,则必须优化；
注：如果满足下面的指标，则一般不需要进行GC:
Minor GC执行时间不到50ms;
Minor GC执行不频繁，约10秒一次；
Full GC执行时间不到1s;
Full GC执行频率不算频繁，不低于10分钟1次；

3)调整GC类型和内存分配
如果内存分配过大或过小，或者采用的GC收集器比较慢，则应该优先调整这些参数，并且先找台或几台机器
进行beta,然后比较优化过的机器和没有优化的机器的性能对比，并有针对性的做出最后选择；

4)不断的分析和调整
通过不断的试验和试错，分析并找到最合适的参数

5)全面应用参数
如果找到了最合适的参数，则将这些参数应用到所有服务器，并进行后续跟踪。


3 jvm调优方法
1)多数的Java应用不需要在服务器上进行GC优化；
2)多数导致GC问题的Java应用，都不是因为我们参数设置错误，而是代码问题；
3)在应用上线之前，先考虑将机器的JVM参数设置到最优（最适合）；
4)减少创建对象的数量；
5)减少使用全局变量和大对象；
6)GC优化是到最后不得已才采用的手段；
7)在实际使用中，分析GC情况优化代码比优化GC参数要多得多；


4 优化的目的有两个
1)将转移到老年代的对象数量降低到最小；
2)减少full GC的执行时间；

5 为了达到上面的目的，需要做的事情有：
1)减少使用全局变量和大对象；
2)调整新生代的大小到最合适；
3)设置老年代的大小为最合适；
4)选择合适的GC收集器；







jps -lv:输出类名和启动参数，拿到pid是关键

类加载时机：
1、new一个对象
2、访问类的静态变量，或者对静态变量赋值
3、调用类的静态方法
4、反射（Class.forName）
5、初始化一个类的子类，首先初始化父类
6、JVM启动时标明 的启动类


永久代是HotSpot概念，方法区是java虚拟机的规范定义，是一种规范，而永久代是一种实现，一个是标准一个是实现。
对于java8,HotSpot取消了永久代，并不是没有方法区了，规范没变但是实现变了，取代永久代的是元空间。
永久代存在堆里面，堆包括年轻代，老年代，持久代


maxMemory()表示jvm进程能从操作系统挖到的最大内存-Xmx
totalMemory()表示jvm进程已经从操作系统挖到的内存-Xms
freeMemory()表示挖过来但是没有用上的内存


静态变量、单例模式、长生命周期对象持有短生命周期的引发内存泄漏。


StrongReference
SoftReference
WeakReference
PhantomReference
Java根据其生命周期的长短将引用类型又分为强引用、软引用、弱引用、幻象（虚）引用
应用的强弱顺序是 强>软>弱>虚。


ShallowSize:就是对象本身的大小，不包含对其他对象的引用，也就是对象头+对象成员变量（不是值）总和。
RetainedSize:就是包含对其他对象的引用的总和，自己的ShallowSize + 对象的引用的ShallowSize 的总和

eclipse mat:
Heap dump是一个java进程在某个时间的内存快照。
通常写Heap dump之前会进行一次Full GC, 所以Heap Dump文件保存的是Full GC留下的对象信息。

下载MemoryAnaalyzer-1.10.0 安装

以下配置包括main方法、springboot的内置tomcat:
Run》Run Configuration》Arguments》Vm arguments

-XX:+HeapDumpOnOutOfMemoryError
-Xms20m
-Xmx20m

Dumping heap to java pid20844.hprof


Overview视图 是第一个视图，下面有actions和reports
Actions(Histogram实例列表，Dominator最大的对象，Top Comsumer打印按照类和包分组最昂贵的对象)
Reports( Leak Suspects排查泄露疑点； Top Components)


在eclipse有一个mat可以测试，在idea里面有一个插件就是 JProfilerl 


tomcat配合mat:
vim /${tomcat_home}/bin/catalina.sh 
JAVA_OPTS="$JAVA_OPTS -server -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=D:\heapdump"


除了配置发生oom生成之外，其次可以通过以下命令获得dump文件：
jps -v 找出pid=35500
jmap -dump:format=b,file=d://xxx.hprof 35500


当对象生成并且在eden申请空间失败的时候会触发局部垃圾回收 ；
当老年代和持久代被写满会触发Full GC.



jps -v    =======  ps -ef|grep java
全面的命令，输出进程号和主类，方法，参数，路径


jmap
jmap -dump:format=b,file=d://xxx.hprof 35500  生成dump
jmap -heap 35500 输出heap的概要信息，GC使用算法，heap配置以及jvm内存的使用。
jmap -histo:live 35500 每个class的实例条目 内存占用





jstat:
jstat –class 35500 : 显示加载class的数量，及所占空间等信息。
jstat -compiler 35500: 显示VM实时编译的数量等信息。
jstat -gc 35500: 可以显示gc的信息，查看gc的次数，及时间。
jstat -gccapacity 35500:可以显示，VM内存中三代（young,old,perm）对象的使用和占用大小
jstat -gcutil 35500:统计gc信息
jstat -gcnew 35500:年轻代对象的信息。
jstat -gcnewcapacity 35500: 年轻代对象的信息及其占用量。

- S0C : survivor0区的总容量
- S1C : survivor1区的总容量
- S0U : survivor0区已使用的容量
- S1C : survivor1区已使用的容量
- EC : Eden区的总容量
- EU : Eden区已使用的容量
- OC : Old区的总容量
- OU : Old区已使用的容量
- PC 当前perm的容量 (KB)
- PU perm的使用 (KB)
- YGC : 新生代垃圾回收次数
- YGCT : 新生代垃圾回收时间
- FGC : 老年代垃圾回收次数
- FGCT : 老年代垃圾回收时间
- GCT : 垃圾回收总消耗时间


jstack:
top 找到进程id=67333
top -Hp 67333  找到线程id  67506
jstack 67333 里面的nid（16进制）和线程id（16进制）对应
jstack 67506|grep 54ee




复制算法：
新生代，标记出所有的存活对象，并将这些存活的对象复制到一块儿新的内存上去，之后将原来的那一块儿内存全部回收掉
优化了标记清除算法效率低，内存碎片多的问题，但是对空间要求很高。
GC进行时，Eden的所有存活对象会复制到To Survivor区，接着清空Eden 和 From Survivor,新生代存活的对象都在To Survivor里面。

效率：复制>标记整理>标记清除
内存整齐率：复制=标记整理>标记清除
内存利用率：复制<标记整理=标记清除


 GC Overhead Limit Exceeded:
如果Java进程花费98%以上的时间执行GC，并且每次只有不到2%的堆被恢复，则JVM抛出此错误。换句话说，这意味着我们的应
用程序几乎耗尽了所有可用内存，垃圾收集器花了太长时间试图清理它，并多次失败.
不抛出这个错误会发生gc清理的这一点点内存很快就被填满，迫使gc再次执行，形成恶性循环，cpu使用率一直是100%。

持久代一般固顶大小64m, -Xss128k，设置每个线程的栈大小，JDK1.5之后每个线程堆栈大小为1M。
-XX:NewRatio=4, 年轻代和老年代比值为1:4
-XX:SurvivorRatio=4, 2个Survivor 和eden比率为2:4
Sun官方推荐配置年轻代为整个堆的3/8.



1 并行收集器(parallel) 
多条垃圾收集线程同时进行工作,此时用户线程处于等待状态

2 并发收集器(concurrent)
指多条垃圾收集线程与用户线程同时进行(但不一定是并行的,有可能交替进行工作)，如cms就是典型的并发收集器

-XX:UseParallelGC




隐藏 nginx版本号的目的是防止恶意用户 利用软件漏洞进行攻击。











---------------------------------------------------------------------------------------------------------------
------------------------------------------JVM.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Kafka.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------



@核心
Apache.项目，scala语言编写，基于zk,分区，多replica。
吞吐量每秒17万，数千个客户端同时读写。
消息备份到磁盘和恢复和redis类似。
Advanced Message Queuing Protocol(高级消息队列协议)The Advanced Message Queuing Protocol(AMQP):是
一个标准开放的应用层的消息中间件(Message OrientedMiddleware)协议。AMQP定义了通过网络发送的字节流
的数据格式。因此兼容性非常好，任何实现AMQP协议的程序都可以和与AMQP协议兼容的其他程序交互，可以很容易做到跨语言，跨平台。


@zookeeper作用
broker注册，topic注册，生产者负载均衡(Kafka提供了一个metadata API来管理broker之间的负载（对
Kafka0.8.x而言，对于0.7.x主要靠zookeeper),分区元数据，消费者与分区的对应关系，消费者的offset
Zookeeper集群的工作是超过半数才能对外提供服务，3
台中超过两台超过半数，允许1台挂掉，是否可以用偶数，其实没必要。
如果有四台那么挂掉一台还剩下三台服务器，如果在挂掉一个就不行了，这里记住是超过半数。


@常见API含义
add添加元素，满了异常
remove并返回头部元素，空了异常
element获得头部的元素，没有异常
offer添加元素true,满了false
poll并返回头部元素，空了null
peek获得头部的元素，没有null
put添加元素，满了阻塞
take并返回头部元素，空了阻塞


@Broker的leader.与follower
Kakfa Broker集群受Zookeeper管理。所有的Kafka
Broker节点一起去Zookeeper.上注册一个临时节点，因为只有一个Kafka Broker:会注册成功，
其他的都会失败，所以这个成功在Zookeeper.上注册l临时节点的这个Kafka Broker:会成为Kafka Broker Controller,
其他的Kafka brokerl叫Kafka Broker follower.。masteri和Zookeeperi通信的timeout时间是6s,如果6s中
没有和Zookeeper做心跳，ZK临时节点，其他
follower争着注册临时节点。同一partition的一条message只能被同一个Consumer
Group内的一个Consumeri消费。不能够一个consumer
group的多个consumer同时消费一个partition。多个Consumer Group下的consumer可以消费同一条message.


@分区的leader.与follower
producer写kafka的时候先写partition leader,再由partition leader push给其他的partition follower.。
partition leader所在的broker节点宕机，zookeeper:会冲
其他的broker的partition follower上选择follower变为parition leader.。
第一个partition;是leader,其他的是follower。
如果一个server上有过多的partition leader,意味差
此server>将承受着的lO压力.在选举新leader,需要个到负载均衡”，
partition leader:较少的broker:将会更有可能成为新的leader.
消息路由：分区算法，根据key哈希算法，如果没有轮询选出一个hash


@概念
offset值：指向partition中下一个要被消费的消息位置
message持久化：顺序写入o(1)的时间复杂度，速度非常快。也是高吞吐量的原因。最少一次，最多一次，恰好一次


@Kafka数据有两种方式
按照时间，超过一段时间后过期消息
按照消息大小，消息数量超过一定大小后最旧的数据watcher:
当需要增加broker:结点时，新增的broker:会向zookeeper注册，而producer及consumer:会根据注册在zookeeper.上的watcher!感知这些变化，并及时作出调整。


@源码解析(Scala编写)
github地址：https:/github.com/apache/kafka/tree/trunk/core/src/main/scala/kafka
admin包~kafka的管理员模块，操作和管理其topic,partition相关，包含创建，topic,或者拓展分区等。
cluster包~这里包含多个实体类，有Broker,Cluster,Partition,Replica。其中一个Cluster由多个Broker组成，一个Broker包含多个Partition,一个Topic的所有Partition分布在不同的
Broker中，一个Replica包含都个Partition。
common~这是一个通用模块，其只包含各种异常类以及错误验证。
consumer~消费者处理模块，负责所有的客户端消费者数据和逻辑处理。
controller此模块负责中央控制器的选举，分区的Leader选举，Replica的分配或其重新分配，分区和副本的扩容等。
producer生产者的细节实现模块，包括的内容有同步和异步的消息发送。
server该模块涉及的内容较多，有Leader和Offset的
checkpoint,动态配置，延时创建和Topic,Leader的选举，Admin和Replica的管理，以及各种元数据的缓存等内容





解耦、异步、缓冲、扩展

zookeeper在kafka汇总存储 broker, topic, offset信息等元数据，对于0.7.x 主要靠zk来实现负载均衡；
kafka0.8.x 使用metadata api管理broker之间的负载均衡

所有broker节点去zk注册一个临时节点，只有一个会注册成功，其他都会失败
成功的就是Kafka Broker Controller ,其他的就是follower.


partition也有leader和follower之分，写kafka的时候先写partition leader，再由partition leader push到  follower。
Kafka partition leader的选举过程如下 (由controller执行)：
从Zookeeper中读取当前分区的所有ISR(in-sync replicas)集合
调用配置的分区选择算法选择分区的leader


offset 指向partition中下一个要被消费的消息位置


由于message写入持久性是顺序写入的，高吞吐量的原因，因此也是顺序消费的
保证同一个分区，就是顺序消费的。一般的机器，单机每秒100K条数据。


吞吐量每秒17万，数千个客户端同时读写。
消息备份到磁盘，恢复和redis类似。


watcher:
当新增broker节点时候，新增的broker向zk注册，而producer和consumer会根据注册到zk上的watcher的变化，及时作出调整



离线安装kafka
wget http://apache.01link.hk/kafka/2.0.0/kafka_2.11-2.0.0.tgz

tar -xvf kafka_2.11-2.0.0.tgz

vim /etc/profile
export KAFKA_HOME=/root/soft/kafka_2.11-0.11.0.2
export PATH=$PATH:$KAFKA_HOME/bin

source /etc/profile

查看环境变量们是否成功：
echo $KAFKA_HOME
/root/soft/kafka_2.11-0.11.0.2


vim /home/hiya01/software/kafka/kafka_2.12/config/server.properties
broker.id=1
listeners=PLANINTEXT://10.72.5.198:9092
log.dirs=/home/hiya01/software/kafka/log
zookeeper.connect=10.72.5.196:2181,10.72.5.197:2181,10.72.5.198:2181

broker.id=2
broker.id=3


cd /home/hiya01/software/kafka/kafka_2.12/bin
./kafka-server-start.sh -daemon ../config/server.properties
./kafka-server-start.sh ../config/server.properties

./kafka-topics.sh --create --zookeeper 10.72.5.196:2181,10.72.5.197:2181,10.72.5.198:2181 --replication-factor 3 --partitions 2 --topic hiya-topic1


启动报错：
kafka.zookeeper.ZooKeeperClientTimeoutException:Timed out wating for connection

版本问题，zookeeper的版本和kafka的libs目录下的zookeeper的jar包版本不一致导致的，更换zookeeper使其版本与kafka的libs是
目录下的zookeeper的jar包版本一致。


如果一次发送数据量太大，修改 bufferMemory参数


kafka开启SASL_PLAINTEXT认证
touch kafka_server_jaas.conf,在KafkaServer部分，username和password是broker用于初始化连接到其他broker


props.put("security.protocol","SASL_PLAINTEXT");
props.put("sasl.mechanism","PLAINT");

















---------------------------------------------------------------------------------------------------------------
------------------------------------------Kafka.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Kong.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------

-----Kong总结-----
Kong是一个基于Apache License2.0的开源项目，是一个云原生的快速可扩的分布式微服务抽象层，应用场景为微服务的API网关，类似于spring cloud的zuul。
开发语言是Lua。
-云原生：具有平台无关性，kong即可以运行在物理设备也可以运行在kubernetes上
-动态负载均衡：在多个upstream services:基础上进行负载均衡设定
-基于hash的负载均衡：基于hashing/sticky session的负载均衡
-断路器：能追踪不健康的upstream services
-健康检测：对upstream servicesi进行主动或者被动地监控
-服务发现：可结合consul提供服务注册等功能
-WebSockets:通过WebSockets和upstream service进行通信
-0Auth2.0:可对API方便地添加0Auth2.0进行授权
-日志：通过HTTP/TCP/UDP等方式进行日志相关操作
-安全：ACL,机器人检测，黑白名单|P等
-系统日志：日志可输入到系统日志中
-监控：提供实时监控功能
-认证：HMAC/JWT以及基本认证方式
-限流(Rate-Limiting):基于多变量对请求进行阻塞或者限制
-转换：对TTP请求和相应进行添加//操纵等操作
-缓存：在代理层进行缓存和响应处理
-CLl:通过命令行对kong的集群进行控制
-REST API:可灵活地通过RESTful API>对kong进行操作



-REST API:可灵活地通过RESTful API>对kong进行操作
-失败检测与恢复：Cassandra某一节点停止也不会影响kong的功能
-集群：所有的kong节点都能自动加入集群，并保证配置在整个节点间得到更新
-可扩展性：kong可以通过添加节点很容易地实现横向扩展
-性能：使用nginx作为内核，kong具有nginxE的高性能
-plugin:可以对kong和APl进行扩展
E1P是：100.95.93.5
http:/100.95.93.5:31413/#!
admin/Huawei@123
http://100.95.93.5:31412/framework/authority/swagger
-ui.html
http://sd-
authentication:8080/smartdesigner/authentication/swa
gger-ui.html
https://qithub.com/leolztang/spring-cloud-demo
kong-dashboard通过http://kong-admin:8001操作数据库
Clusterlp是K8S内部IP,KONG_ADMIN是联通kong-
dashboard,KONG_PROXY代理应用。
<dependency>
<groupld>org.projectlombok</groupl
<artifactld>lombok</artifactld>
</dependency>




kong插件：
http://100.101.26.233/framework/auditloq/swaqger-
ui.html
http://100.101.26.233:8008/smartdesigner/auditlog/sw
agger-ui.html
http://100.101.26.233/framework/authority/swagger-
ui.html
http://100.101.26.233:8002/smartdesigner/authority/s
wagger-ui.html
http://10.24.107.39:8002/smartdesigner/authority/swag
ger-ui.html
http://10.24.107.39:8002/smartdesigner/authority/v1/p
ermission/authorize
http://10.24.107.39:8002/smartdesigner/authority/v1/o
pt/qetApisByPageld?pageld=6488360184983978560
http://sd-smartdesigner-
dev.huawei.com/framework/auditlog/swagger-ui.html
http://sd-smartdesigner-
dev.huawei.com/framework/auditlog/v1/auditlog/opera
tions?pageNo=1&pageSize=15&logType=0
http://100.101.26.233/framework/auditlog/v1/auditlog/
addNormalShop



---------------------------------------------------------------------------------------------------------------
------------------------------------------Kong.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Kubernetes.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------

---Kubernetes总结
Kubernetes
kubectl cluster-info-集群状态
kubectl-S
https:/100.101.19.40:6443
componentstatuses-组件状态
kubectl create-f hiya-pod.yaml-创建pod
kubectl get nodes-获取节点信息
kubectl get pods
kubectl get podslgrep nodeplan
kubectl get po sd-nodeplan-7bc98c6ff8-9tkx5-o widE 查看指定pod跑在哪个node上
kubectl describe pod my-alpine
kubectl describe pod hiya-pod
kubectl get pod hiya-pod -o yaml
kubectl delete pods --all
kubectl delete-f hiya-pod.yaml
kubectl exec hiya-pod-c hiya:2data-指定Pod中某个执行data命令
kubectl scale hiya-pod hiya1-replicas:=3-执行扩容Pod的操作
kubectl scale deployment hiya-deployment--replicas
kubectl exec -it hiya-pod -c hiya1/bin/bash
kubectl logs hiya-pod -c hiya1
kubectl logs hiya-pod-c hiya1
kubectl logs sd-nodeplan
kubectl create-f hiya-configmap.yaml
kubectl get configmap

kubectl get configmap
kubectl get configmaplgrep nodeplan
kubectl describe configmap hiya-configmap
kubectl create configmap special-config
literal=special.how=very
literal=special.type=charm
kubectl get deployment
kubectl get deploymentlgrep nodeplan
kubectl create secret generic db-user-pass -f
file=./username.txt--from-file=./password.txt
kubectl run hiya-nginx --image=nginx --replicas=
port=80 --expose --service-overrides='{"spec":{"t"LoadBalancer"}}'
kubectl get service,/hiya-nginx-查看服务信息
kubectl delete deployment,service hiya-nginx-删为hiya-nginx的deployment和service
K8$:创建集群，部署应用，提供服务，扩容缩容，应用在Docker技术的基础上，为容器化的应用提供部署运资源调度、服务发现和动态伸缩等一系列完整功能，了大规模容器集群管理的便捷性。
Pod相当与一个逻辑主机，让几个紧密连接的几个容间共享资源，例如ip地址，共享存储等信息。如果直度容器的话，那么几个容器可能运行在不同的主机上，增加了系统的复杂性。



服务主要是用来提供外界访问的接口，服务可以关联pod,这些pod的ip地址各不相同，而service相当于
复杂均衡的vip,用来指向各个pod,当pod的ip地址
改变之后，也能做到自动进行负载均衡。服务到ETCD中，一个轻量级的zk.
扩容缩容：在业务上线之后，碰到了双十一怎么办容：
kubectl scale deployment hiya-deployme replicas=50;

过了双十一怎么办
缩容：kubectl scale deploy hiya-deployment --replicas=30;

应用更新：发布新版本，滚动更新，根据新的image一个pod,分配各种资源，然后自动负载均衡，
pod,然后继续更新，不会中断服务。
DaemonSet能够让所有（或者特定）的节点运行个pod。

Deployment解决的问题每个Pod都运行给定应用程序个实例。想水平扩展应用程序，则应该使用多个Pod里带来的Pod管理成本.
他的底层还是pod,只不过根据副本数量部署几台机
Deployment部署的副本Pod会分布在各个Node上个Node都可能运行好几个副本。DaemonSet处在于：每个Node上最多只能运行一个副本。

DaemonSet的典型应用场景有:
在集群的每个节点上运行存储Daemon,比如glusteceph.
在每个节点上运行日志收集Daemon,比如flunenlogstash。
在每个节点上运行监控Daemon,比如Promet
Node Exporter或collectd。
HPA全称Horizontal Pod Autoscaling,即pod的水平扩展，针对于实例数目的增减操作对象是RC,
或Deploymenty对应的Pod,根据Pod当前系统的负载：动水平扩容，如果系统负载超过预定值，就开始增加的个数，如果低于某个值，就自动减少Pod的个数。
healm管理、编辑与更新大量的K8s配置文件.He
Kubernetes资源打包到一个chart中，而chart被到chart仓库。
通过chart仓库可用来存储和分享chart。Helm使发布置，支持发布应用配置的版本管理，简化了Kuberne1署应用的版本控制、打包、发布、、更新等操作
values.yaml:模板变量
configmap.yaml:分布式配置信息
Chart.yaml:chart元数据
deployment.yaml:deployment文件。
service.yaml:deployment的service文件。
NOTES.txt/_helpers.tpl:帮助文件
hpa.yaml:水平自动扩展


livenessProbe探针
Exec容器内部执行命令返回值为O则表明容器健康
TCPSocket容器IP地址和端口号执行TCP检查，TCP表明容器健康
HTTPGetAction容器的IP地址/端口号及路径调用
Get方法，状态码>=0&&<=400健康。
ReadinessProbe探针表示container:是否以及处于可接受service请求的了。ReadinessProbe失败endpoints controller将
service所匹配到的endpoint列表中移除关：个container的P地址
affinity:Node亲和性
requiredDuringSchedulinglgnoredDuringExecution,束，Pod只能调度到
preferredDuringSchedulinglgnoredDuringExecution约束，k8s调度会尽量不调度Pod

污点和容忍
Node和Pod上都可以定义多个Taint
Tolerations,Scheduler会根据具体定义进行筛选，I筛选Pod列表的时候，
保留Tolerations定义匹配的，过滤掉没有Tolerations的，过滤的过程是这样的：
如果Node中存在一个或多个影响策略为NoSc Taint,该Pod不会被调度到该Node


Taint,该Pod不会被调度到该Node
如果Node中不存在影响策略为NoSchedule的Taint,存在一个或多个影响策略为PreferNoSchedule的Ta该Pod会尽量不调度到该Node
如果Node中存在一个或多个影响策略为NoExecu
Taint,该Pod不会被调度到该Node,并且会驱逐已度到该Node的Pod实例
MOUNT是将存储设备变成文件来访问的，LINUX所存储设备都是映射成“文件”来访问的，包括U盘驱，硬盘，磁带
mount/dev/cdrom/media,/cdrom这个的意思i
将CDROMI映射成media/CDROM这个文件来访问









http://blog.csdn.net/weixin_38645718/article/details/85931795


0）Install
#######公共安装 #######
EPEL (Extra Packages for Enterprise Linux)是基于Fedora的一个项目，为“红帽系”的操作系统提供额外的软件包，适用于RHEL、CentOS和Scientific Linux.
epel-release会自动配置yum的软件仓库，安装完成之后你就可以直接使用yum来安装额外的软件包了比如 ：yum install nginx pure-ftpd

yum -y install epel-release
systemctl stop firewalld
systemctl disable firewalld
#设置SELinux 成为permissive模式 临时关闭selinux的
setenforce 0

#查看防火墙状态
firewall-cmd --state



#######master安装####### 
yum -y install etcd kubernetes-master


vi /etc/etcd/etcd.conf
#改成：ETCD_LISTEN_CLIENT_URLS="http://0.0.0.0:2379"



vi /etc/kubernetes/apiserver
#改成：KUBE_API_ADDRESS="--insecure-bind-address=0.0.0.0"



#启动etcd、kube-apiserver、kube-controller-manager、kube-scheduler等服务，并设置开机启动。
for SERVICES in etcd kube-apiserver kube-controller-manager kube-scheduler; do systemctl restart $SERVICES;systemctl enable $SERVICES;systemctl status $SERVICES ; done

等效于：
systemctl restart etcd
systemctl restart kube-apiserver
systemctl restart kube-controller-manager
systemctl restart kube-scheduler


etcdctl mk /atomic.io/network/config '{"Network":"172.17.0.0/16"}'



#######node安装 #######
yum -y install flannel kubernetes-node
vi /etc/sysconfig/flanneld
#修改->FLANNEL_ETCD_ENDPOINTS="http://192.168.1.111:2379"

vi /etc/kubernetes/config
#修改->KUBE_MASTER="--master=http://192.168.1.111:8080"

vi /etc/kubernetes/kubelet
#KUBELET_ADDRESS="--address=0.0.0.0"
#KUBELET_HOSTNAME="--hostname-override=192.168.1.112"
#KUBELET_API_SERVER="--api-servers=http://192.168.1.111:8080"


#node节点机上启动kube-proxy,kubelet,docker,flanneld等服务，并设置开机启动。
for SERVICES in kube-proxy kubelet docker flanneld;do systemctl restart $SERVICES;systemctl enable $SERVICES;systemctl status $SERVICES; done

等效于：
systemctl restart kube-proxy
systemctl restart kubelet
systemctl restart docker
systemctl restart flanneld


#测试搭建效果
kubectl get nodes


问题来了：0.0.0.0、 127.0.0.1 、localhost、 实际的ip 什么区别？
假设本机有多个网卡：eth0 :192.168.0.1       eth1:192.168.1.1     lo: 127.0.0.1

127.0.0.1=localhost，特殊的环回地址，命名为localhost(主机名)，一般用来对运行在同一台主机上的程序通过TCP/IP进行通信。
0.0.0.0，不能ping通，代表本机所有的IP地址；

ens33为自动备援模式,名称定为ens33，linux默认的网卡；
在docker安装之后,就会产生一个docker0的虚拟网桥，这个网桥是在ifconfig里面显示的，跟其余网卡一样，拥有一个IP。
lo代表127.0.0.1，即localhost
virbr0 默认分配了一个IP 192.168.122.1，并为连接其上的其他虚拟网卡提供 DHCP 服务。virbr0 是 KVM 默认创建的一个 Bridge，其作用是为连接其上的虚机网卡提供 NAT 访问外网的功能。



9）Kubectl
客户端工具，可以让用户通过命令方式对K8S集群进行操作；
常见命令： 
kubectl [get/delete/create/appl/describe] [pod/srv] name

#获取master所有的node节点
kubectl get nodes 
kubectl get nodes|grep 112












1）Maseter
Master是Kubernetes 的主节点，负责整个集群的控制和管理，所有控制命令都发给他。
四个模块组成：etcd、api server、controller manager、scheduler
etcd：Kubernetes 提供的一个高可用的键值数据库，用于保存集群所有的网络配置和资源对象的状态信息，也就是保存了整个集群的状态。


2）Kube-apiservice
负责对外提供restful的Kubernetes API服务，其他Master组件都通过调用api server提供的rest接口实现各自的功能，
如controller就是通过api server来实时监控各个资源的状态的。
比如操作deployment, pod, secret, cm等。


3）Kube-controller-manager
每个资源一般都对应有一个控制器，这些controller通过api server实时监控各个资源的状态，controller manager就是负责管理这些控制器的。
当有资源因为故障导致状态变化，controller就会尝试将系统由“现有状态”恢复到“期待状态”，保证其下每一个controller所对应的资源始终处于期望状态。
比如：Node Controller, Service Controller(监听service的变化), Replica Controller, Namespace Controller(管理nm的生命周期)


4）Kube-scheduler
通过调度算法为该pod选择一个最合适的Node节点。会检索到所有符合该pod要求的Node节点，执行pod调度逻辑。
调度成功之后，会将pod信息绑定到目标节点上，同时将信息写入到etcd中。
输入是pod和由多个Node组成的列表，输出是pod和一个Node的绑定，即将这个pod部署到这个Node上。


5）Node
实际的工作机器，真正运行工作负载的节点。运行着master分配的pod, 当一个Node宕机，其上的pod会被自动转移到其他Node上。
每一个Node节点都安装了Node组件，包括kubelet、kube-proxy、flannel、container runtime。


6）Kubelet
kubelet 的主要功能就是定时从某个地方获取节点上 pod/container 的期望状态（运行什么容器、运行的副本数量、网络或者存储如何配置等等），
并调用对应的容器平台接口达到这个状态。
每个Node上面都会运行着一个Kubelet进程，作为master和node的桥梁，每个Kubelet都会向apiservice注册自己的信息，定期向master汇报资源使用情况；
相当于每个node的agent。


7）Kube-proxy
kube-proxy负责为Service提供cluster内部的服务发现和负载均衡，它运行在每个Node计算节点上，负责Pod网络代理, 它会定时从etcd服务获取到service
信息来做相应的策略，维护网络规则和四层负载均衡工作。
kube-proxy其实就是管理service的访问入口，包括集群内Pod到Service的访问和集群外访问service。
kube-proxy管理sevice的Endpoints，该service对外暴露一个Virtual IP，也成为Cluster IP, 集群内通过访问这个Cluster IP:Port就能
访问到集群内对应的serivce下的Pod。
举个例子，比如现在有podA，podB，podC和serviceAB。serviceAB是podA，podB的服务抽象(service)。
那么kube-proxy的作用就是可以将pod(不管是podA，podB或者podC)向serviceAB的请求，进行转发到service所代表的一个具体pod(podA或者podB)上。
请求的分配方法一般分配是采用轮询方法进行分配。


8）Docker Engine
容器运行环境，目前k8s支持docker和rkt两种容器；
Docker Engine是其中一种，也就是说K8S基于Docker引擎；


10）Namespace
将系统内部的对象分配到不同的Namespace中，形成逻辑上分组的不同项目、小组或用户组，便于不同的分组在共享使用整个集群的资源的同时还能被分别管理。
Namespace常用来隔离不同的用户，比如Kubernetes自带的服务一般运行在kube-system namespace中。
kubectl get namespaces
kubectl create namespace new-namespace


11）EndPoint
Service和pod之间的中介，endpoint资源就是暴露一个服务的ip地址和端口的列表，服务指向EndPoint，EndPoint指向后端。
EndPoint.metadata.name=Service.metadata.name,然后EndPoint.subSets.address下面是个数组，一堆的ip. 


12）Pod && ReplicationController(RC) && ReplicaSet && Deplyment
Pod: 是k8s项目中的原子调度单位，豆荚，里面有多颗豆子（container）。
一个pod里面有多个容器，A，B容器的pod，共享网络和Volume容器 .
deploy控制RS，RS控制Pod，这一整套，向外提供稳定可靠的Service。

能否在Pod发生问题时自动恢复呢？来看下Replication Controller（简称RC）
RC: 保证在同一时间能够运行指定数量的Pod副本，保证Pod总是可用。如果实际Pod数量比指定的多就结束掉多余的，如果实际数量比指定的少就启动缺少的。
当Pod失败、被删除或被终结时RC会自动创建新的Pod来保证副本数量。

controller-manager中的ReplicationController和K8S中的资源不是同一个东西，为了区分，这里用RC标识，controller-manager中的ReplicationControlle还是叫ReplicationControlle。

Replica Set:
目前与RC的区别只是支持的selector不同
RC只支持基于等式的selector（env=dev或environment!=qa）但Replica Set还支持新的基于集合的selector（version in (v1.0, v2.0)或env notin (dev, qa)），
这对复杂的运维管理带来很大方便。

Deployment: 使用了ReplicaSet，更高一层的概念，拥有更加灵活的强大升级、回滚功能。
创建一个Deployment会自动创建一个ReplicaSet和pod.
Deployment拥有更加灵活强大的升级、回滚功能.
Deployment核心spec.strategy.rollingUpdate属性 滚动升级解释：
maxSurge: 1 用于指定在Deployment更新Pod的过程中Pod总数超过Pod期望副本数部分的最大值。当maxSurge的值被设置为30%时，
						 新的ReplicaSet可以在滚动更新开始时立即进行副本数扩容，只需要保证新旧ReplicaSet的Pod副本数之和不超过期望副本数的130%即可。
maxUnavailable: 1 表示滚动升级时允许的最大Unavailable的pod个数
由于replicas为3,则整个升级,pod个数在2-4个之间。



13）DaemonSet
服务守护进程，它的主要作用是在Kubernetes集群的所有节点中运行我们部署的守护进程，相当于在集群节点上分别部署Pod副本，
如果有新节点加入集群，Daemonset会自动的在该节点上运行我们需要部署的Pod副本，相反如果有节点退出集群，Daemonset也会
移除掉部署在旧节点的Pod副本。这个 Pod 运行在 Kubernetes 集群里的每一个节点（Node）上，只会运行一个。
常见的场景：Flannel，Logstash等。


14）Service
service是通过Selector选择的一组Pods的服务抽象，其实就是一个微服务，提供了服务的LB和反向代理的能力，而kube-proxy的主要作用就是负责service的实现。
service另外一个重要作用是，一个服务后端的Pods可能会随着生存灭亡而发生IP的改变，service的出现，给服务提供了一个固定的IP，而无视后端Endpoint的变化。
ClusterIP：默认，随机分配的集群内部访问的IP；
NodePort：这种方式是常用的，用来对集群外暴露Service，你可以通过访问集群内的每个NodeIP:NodePort的方式，访问到对应Service后端的Endpoint。
LoadBalancer: 这也是用来对集群外暴露服务的，不同的是这需要Cloud Provider的支持，比如AWS等。

Client -> NodeIp:NodePort -> ClusterIp:ServicePort -> PodId:ContainerPort 
实际上一个service映射多个EndPoint，EndPoint会变化，但是service的clusterIp不会变化，回去感知pod变化，重新绑定EndPoint达到客户端稳定访问的效果。


15）Ingress
Ingress是kubernetes集群对外提供服务的一种方式。建议把ingress通过DaemonSet的方式部署集群中进行高可用。
1 ingress controller通过和kubernetes api交互，动态的去感知集群中ingress规则变化。
2 然后读取它，按照自定义的规则，规则就是写明了那个域名对应哪个service，生成一段nginx配置。
3 在写到nginx-ingress-controller的pod里，这个Ingress controller的pod里运行着一个Nginx服务，控制器会把生成的nginx配置写入/etc/nginx.conf文件中。
4 然后reload一下使配置生效，以此达到分配和动态更新问题。

创建ingress-nginx
wget  https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.28.0/deploy/static/mandatory.yaml
创建ingress pod 和service。

-arg
 --watch-namespace=api  
 
 创建一个有问题的ingress，会影响所有创建ingress的规则，一个集群大BUG诞生了，需要提前校验；
 k8s-admission-webhook横空出世了。可以在apiserver持久化对象之前拦截请求，去实现自定义规则的校验。
 
 



16）Configmap
是用于保存配置数据的键值对，可以用来保存单个属性，也可以保存配置文件。Secret可以为Pod提供密码、Token、私钥等敏感数据；对于一些非敏感数据，比如应用的配置信息，则可以使用ConfigMap。
ConfigMap的创建和使用方式与Secret非常类似，主要的不同是以明文的形式存放
注入方式有2种，一种将cm作为存储卷，一种是将cm通过env注入。


17）Secret
Secret是用来保存小片敏感数据的k8s资源，例如密码，token，或者秘钥。这类数据当然也可以存放在Pod或者镜像中，但是放在Secret中是为了更方便的控制如何使用数据，并减少暴露的风险。
用户可以创建自己的secret，系统也会有自己的secret。
Pod需要先引用才能使用某个secret，Pod有2种方式来使用secret：作为volume的一个域被一个或多个容器挂载；在拉取镜像的时候被kubelet引用。


18）Lable
标签，一般在metadata下面，可以模糊查询。


19）Volume
Volume生命周期一般跟着pod走的，生命周期和depoyment一样，先要定义Volume（对应物理机目录）
然后容器你和初始化容器新增 volumeMount (根据name挂载到容器内部的目录)


20）PersistentVolume
集群内，由管理员提供的网络存储的一部分。就像集群中的节点一样，PV也是集群中的一种资源。它也像Volume一样，是一种volume插件，
但是它的生命周期却是和使用它的Pod相互独立的。PV这个API对象，捕获了诸如NFS、ISCSI、或其他云存储系统的实现细节。


21）PersistentVolumeClaim
是用户的一种存储请求。它和Pod类似，Pod消耗Node资源，而PVC消耗PV资源。


22）HPA
Kubernetes有一个HPA(Horizontal Pod Autoscaler)的资源，可以实现基于CPU使用率的Pod自动伸缩的功能。
HPA基于Master Node上的kube-controller-manager服务启动参数–horizontal-pod-autoscaler-sync-period定义的
时长(默认为30秒)，周期性的检测Pod的CPU使用率(需要事先安装heapster)。
kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10
cpu利用率50%，如果大于50%则缩容最小缩到1，如果小于50%则扩容最大到10，
目前只支持cpu, 如果要支持其他指标的话 ，需要自己写自定义控制器扫描指标的利用率进行弹性伸缩。


23）LimitRange
前面我们讲到过资源配额,资源配额是对整个名称空间的资源的总限制,是从整体上来限制的,
而LimitRange则是对pod和container级别来做限制的。
一旦创建了LimitRange，后面创建资源的时候K8S将LimitRange的限制条件强加给pod，一旦发现不符合规则，暂停创建pod.


24）StatefulSet
有状态的集合，管理所有有状态的服务，比如MySQL、MongoDB集群等。StatefulSet本质上是Deployment的一种变体，
它所管理的Pod拥有固定的Pod名称，启停顺序，在StatefulSet中，Pod名字称为网络标识(hostname)，还必须要用到共享存储。
在Deployment中，与之对应的服务是service，而在StatefulSet中与之对应的headless service，headless service，即无头服务
由于StatefulSet控制器创建的pod资源拥有固定、唯一的标识和专用的存储卷，即便重新调度或终止重建，其名称也依然保持不变，并且存储卷不丢失。


25）Job&CronJob
Job负责批量处理短暂的一次性任务 (short lived one-off tasks)，即仅执行一次的任务，它保证批处理任务的一个或多个Pod成功结束.
CronJob即定时任务，就类似于Linux系统的crontab，在指定的时间周期运行指定的任务。


26）K8S APi/K8S Client
http://gitlab.com/kubernates-client/java
K8S及各个开源社区提供的各种语言的Client Library, 让我们可以通过编程的方式实现
调用K8S的API，从而完成pod,service的创建和维护。








---------------------------------------------------------------------------------------------------------------
------------------------------------------Kubernetes.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Linux&Shell.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------


@变量
author=value
author='value'
author:"value"-推荐
echo Sauthor-淘汰
echo S{author}-推荐使用
将命令的结果赋值给变量：author=$(cat log.txt)
只读变量：readonly author
：unset author


@变量作用域
(1)局部变量(local variable);
function funcO{
local a=99

(2)全局变量(global variable);在Shell中定义的变量，默认就是全局变量。
全局变量a仅仅在定义它的第一个Shell进程中有效，对新的Shell进程没有影响
a.sh和b.sh,这三条命令都是在一个进程中执行的，在Shell窗口中以命令行的形式定义的变量a,在a.sh中有效；
在a.sh中定义的变量b,在b.sh中也有效，变量b的作用范围已经超越了a.sh。

(3)环境变量(environment variable):
export a#将a导出为环境变量，强调：环境变量在子进程有效，独立开一个新的进程无效。
通过export导出的环境变量只对当前Shell进程以及的子进程有效，如果最顶层的父进程被关闭了，那么环境
变量也就随之消失了，
其它的进程也就无法使用了，所以说环境变量也是临的。
Shell配置文件中才能达到这个目的！Shell进程每次启动时都会执行配置文件中的代码做一些初始化工作，如果将
变量放在配置文件中，那么每次启动进程都会定义这个变量。


@命令结果赋值
variable=S(commands)-不建议使用反括号
begin_time=`date+%s`#开始时间，使用替换sleep20s#休眠20秒
finish._time=S(date+%s)#结束时间，使用S(替换
run_time=S(finish._time-begin_time)#时间差
echo "begin time:Sbegin_time"
echo "finish time:Sfinish_time"
echo "run time:S{run_times"
UNIX时间戳：%s


@参数位置
#!/bin/bash
#定义函数
function funcO{
echo "Language:$1"
echo "URL:S2"
}
#调用函数
func C++http://c.biancheng.net/cplus/
$#(参数名称)、$*（参数合成返回，整体一个)、$@（参数合成返回彼此之间是独立的）、$？（上
一个的退出状态或返回值)、$$（当前进程D)
$0(脚本名称)、$1（第1个参数）、$2（第2·个数)



@字符串
直接写，单引号，双引引号
str="http://c.biancheng.net/shell/"
echo S{#str}-长度
str5="S{name}Script:S{url}index.html”-拼接，直接空格，变量名加大括号
S{string:start:length}从string字符串的左边第start个字符开始，向右截取length个字符。
S{string:start}从string字符串的左边第start个字符开始截取，直到最后。
S{string:O-start:length}从string字符串的右边第start个字符开始，向右截取length个字符。
S{string:O-start)从string字符串的右边第start个字符开始截取，直到最后。
S{string#*chars}从string字符串第一次出现*chars的位置开始，截取*chars右边的所有字符。
S{string##*chars}从string字符串最后一次出现*chars的位置开始，截取*chars右边的所有字符。
S{string%*chars}从string字符串第一次出现*chars的位置开始，截取*chars左边的所有字符。
S{string%%*chars}从string字符串最后一次出现*chars的位置开始，截取*chars左边的所有字符

str="--aa+++aa@@@"
echo S{str%aa*}#结果为-aa+++
echo S{str%%aa*}#结果为-
url="c.biancheng.net"
echo S{url:0-13:9}
echo S{url:2:9}



@数组
arr=(20 56 "http://c.biancheng.net/shell/")
nums[6]=88-赋值
ages=([3]=24[5]=19[10]=12)-只给第3、5、10个元素赋值，所以数组长度是3。
echo S{nums[3}-取元素值
S{nums[*}-所有元素
nums=(291001389144)
echo S{nums[@]#输出所有数组元素
nums[10]=66#给第10个元素赋值（此时会增加数组长度)
echo S{nums[*}#输出所有数组元素
echo S{nums[4]}#输出第4个元素
S{#array._name[}-获取长度
array1=(2356)
array2=(99 "http://c.biancheng.net/shell/")
array.new=(S{array1[@]}${array?2[]})-数组拼接
echo${array_new[@]}#也可以写作${array_new[*]}
unset array._new[l]-数组的元素
unset array._new-数组


@内置命令
:扩展参数列表，执行重定向操作
.读取并执行指定文件中的命令（在当前shell环境中）
alias为指定命令定义一个别名
bg将作业以后台模式运行
bind将键盘序列绑定到一个readline函数或宏
break退出for、while、select或until循环
builtin执行指定的shell内建命令
caller返回活动子函数调用的上下文
cd将当前目录切换为指定的目录
command执行指定的命令，无需进行通常的shell查7
compgen为指定单词生成可能的补全匹配
complete显示指定的单词是如何补全的
compopt修改指定单词的补全选项
continue继续执行for、while、select或until循环的下一次迭代
declare声明一个变量或变量类型。
dirs显示当前存储目录的列表
disown从进程作业表中指定的作业
echo将指定字符串输出到STDOUT
enable启用或禁用指定的内建shelli命令
eval将指定的参数拼接成一个命令，然后执行该命令
exec用指定命令替换shell进程
exit强制shell以指定的退出状态码退出
export设置子shell进程可用的变量
fc从历史记录中选择命令列表
fg将作业以前台模式运行
getopts分析指定的位置参数
hash查找并记住指定命令的全路径名
help显示帮助文件
history显示命令历史记录
jobs列出活动作业
kill向指定的进程D(PID)发送一个系统信号
let计算一个数学表达式中的每个参数
local在函数中创建一个作用域受限的变量
logout退出登录shell
mapfile从STDIN读取数据行，并将其加入索引数组
popd从目录栈中记录
printf使用格式化字符串显示文本
pushd向目录栈添加一个目录
pwd显示当前工作目录的路径名
read从STDIN读取一行数据并将其赋给一个变量
readarray从STDIN读取数据行并将其放入索引数组
readonly从STDIN读取一行数据并将其赋给一个不可修改的变量
return强制函数以某个值退出，这个值可以被调用脚本取
set设置并显示环境变量的值和shell属性
shift将位置参数依次向下降一个位置
shopt打开/关闭控制shell可选行为的变量值
source读取并执行指定文件中的命令（在当前shell环境中)
suspend暂停Shell的执行，直到收到一个SIGCONT信号
test基于指定条件返回退出状态码0或1
times显示累计的用户和系统时间
trap如果收到了指定的系统信号，执行指定的命令
type显示指定的单词如果作为命令将会如何被解释
typeset声明一个变量或变量类型。
ulimit为系统用户设置指定的资源的上限
umask为新建的文件和目录设置默认权限
unalias指定的别名
unset指定的环境变量或shell属性
wait等待指定的进程完成，并返回退出状态码
alias timestamp='date +%s':
alias命令定义的别名只能在当前Shell进程中使用，在子
进程和其它进程中都不能使用。
当前Shell进程结束后，别名也随之消失。
unalias timestamp别名

@echo-n"S{height}cm in height"不换行

@read是Shell内置命令，用来从标准输入中读取数：个赋值给变量。如果没有进行重定向，默认就是从键盘读取用户输入的数据：如果进行了重定向，那么可以从文件中读取数据。
read-p"Enter some information>"name url age#空格隔开三个参数
echo"网站名字：Sname"
echo"网址：Surl"
echo"年龄：$age"


@declare和typeset都是Shell内建命令，它们的用法相同，都用来设置变量的属性。
不过typeset已经被弃用了，建议使用declare代替。
declare-rn=10#只读属性


@运算
()用于整数运算，效率很高，推荐使用。
let用于整数运算，和())类似，不推荐。
$用于整数运算，不如()灵活，不推荐。
declare-i将变量定义为整数，然后再进行数学运算时就
不会被当做字符串了。功能有限，仅支持最基本的数学运算（加减乘除和取余），不支持逻辑运算、自增自减等，
所以在实际开发中很少使用。
(b=a-15)将a-15的运算结果赋值给变量b
b=$(a-15)将a-15的运算结果赋值给变量b
b=$(1+2*3-4%3)#运算后将结果赋值给变量，变量放
在了括号的外面
(a>7&&b==c)逻辑运算
(a=3+5,b=a+10)同时进行运算
let命令以空格来分隔多个表达式；()以逗号，来分隔多个表达式。
leta+=6c=a+b#多个表达式以空格为分隔
let i+=8
expr命令可以实现数值运算、数值或字符串比较、字个匹配、字符串提取、字符串长度计算等功能
foo=S(expr Sfoo 1)



@选择结构-if语句
#!/bin/bash
read age
if test Sage-le2;then-test也是布尔值
echo"婴儿"
elif (Sage >3 &Sage <8));then
echo"幼儿"
elif (Sage >9 &Sage <17));then
echo"少年"
elif (Sage >18 &Sage <=25));then
echo"成年"
elif I Sstr1 Sstr2 then
echo"青年"
elif (Sage >41 &Sage <60));then
echo"中年"
else
echo"老年"
fi
test Sage -le 2
<Sstr2
[Stel=~A1[0-9]{10}S]


@选择结构-case in语句
#!/bin/bash
printf "Input a character:
read -n 1 char
case Schar in
[a-ZA-Z])
printf "\nletter\n"
[0-9])
printf "\nDigit\n"
L?)
printf "\nPunctuation\n"
printf "\nerror\n"
esac


@循环
#!/bin/bash
i=1
sum=0
while((i <100))
do
((sum +i))
(i++)
done
echo "The sum is:Ssum"
#!/bin/bash
i=1
sum=0
until ((i 100))
do
((sum +=i))
(i++)
done
echo "The sum is:Ssum"
#!/bin/bash
sum=0
i=0
for (()
do
if((i>100 ))then
break
fi
((sum +i))
(i++)
done
echo "The sum is:Ssum"
#!/bin/bash
echo "What is your favourite OS?"
select name in "Linux""Windows""Mac OS""UNIX"
"Android"
do
case Sname in
"Linux")
echo"Linux是一个类UNIX操作系统，它开源免费，运行在各种服务器设备和嵌入式设备。“
break
"Windows")
echo"Windows是微软开发的个人电脑操作系统，它是闭源收费的。"
break
'Mac OS")
echo"Mac OS是苹果公司基于UNIX开发的一款图形界面操作系统，只能运行与苹果提供的硬件之上。"
break
"UNIX")
echo"UNIX是操作系统的开山鼻祖，现在已经逐渐退出历史舞台，只应用在特殊场合。
break
'Android")
echo"Android是由Google开发的手机操作系统，目前已经占据了70%的市场份额。”
break
echo输入错误，请重新输入"
esac
done


@shelli函数
#!/bin/bash
function getsumO{
local sum=0
for n in S@
do
((sum+=n))
done
return Ssum
}
getsum10205515#调用函数并传递参数
echo S?


@重定向
标准输出重定向
command>file以覆盖的方式，把command的正确输出
结果输出到file文件中。
command>>file以追加的方式，把command的正确输
出结果输出到file文件中。
标准错误输出重定向
command2>file以覆盖的方式，把command的错误信
息输出到file文件中。
command>file2>&1以覆盖的方式，把正确输出和错误
信息同时保存到同一个文件(file)中。
command>>file2>&1以追加的方式，把正确输出和错误
信息同时保存到同一个文件(file)中。
command>file12>file2以覆盖的方式，把正确的输出结
果输出到file1文件中，把错误信息输出到file2文件中。
command>>file12>>file2以追加的方式，把正确的输出
结果输出到file1文件中，把错误信息输出到file2文件
中。


@shellt模块化
modules
log.sh
svn_core.sh
utils.sh
-svncobranches.sh


@Centos和红帽
Centos正是这个RHEL的克隆版本。RHEL是很多企业采
用的Linux.发行版本，需要向Red Hat付费才可以使用，并能得到付过费
用的服务和技术支持和版本升级。Centos可以像RHEL一
样的构筑Linux.系统环境，但不需要向Red Hat付任何的产品和服务
费用，同时也得不到任何有偿技术支持和升级服务。
RedHat一直都提供源代码的发行方式，Centos就是
将RedHat发行的源代码重新编译一次，形成一个可使用的二进制版本。
由于Linux的源代码是GNU,所以从获得RedHat的源代码到编译成新的二进制，都是合法。只是RedHat是商标，
所以必须在新的发行版里将RedHat的商标去掉。

RedHati对这种发行版的态度是：“我们其实并不反对这
种发行版，真正向我们付费的用户，他们重视的并不是系统本身，而
是我们所提供的商业服务。”所以，Centos可以得到RedHat的所有功能，甚至是更好的软件。但Centos并
不向用户提供商业支持，当然也不负上任何商业责任。


@目录结构
/bin一些命令；boot核心启动文件；dev设备；
/etc*系统中的配置文件，重要
/vark*:程序跑出的log,具体在/var/log目录
/usr:操作系统的源码包
/root:系统管理员用户主目录
/opt*:这是给主机额外安装软件所摆放的目录。类似于windows下的program files目录。
/home*:用户的主目录，在Linux中，每个用户都有一个自己的目录
/etc/passwd文件是用户管理工作涉及的最重要的一个文件，7段，冒号隔开sam:x:200:50:Sam san:/usr/sam:/bin/sh用户名：口令：用户标识号：组标识号：注释性描述：主目录：登录Shell
/etc/shadow Linux:都使用了shadow技术，把真正的加密后的用户口令字存放到文件中，而在/etc/passwd文件的口令字段中只存放一个特殊的字符，例如“”或者“”。
/etc/group用户组的所有信息


@dr-xr-xr-x 2 root root 4096 Dec 14 2012 bin
第一位当为[d]则是目录，当为[-]则是文件；
后面三个表示用户，用户组，其他用户的权限


@一些命令含义
-R:递割归的意思
chown root:root install.log将install.log的拥有者与群组
改回为root
owner rwx 4+2+1 7
group rwx 4+2+1 7
others=rwx 4+2+1 7
chmod777-R bashrc:把bashrc目录递归授权读写执行
权限到owner,group,others
另外一种u(user),g(group),o(other)来代表三种身份的
权限
chmod u=rwx,g=rx,o=r -R bashrc
/usr/share/doc绝对路径


@一些操作
ls:列出目录
cd:切换目录
pwd:显示目前的目录
mkdir:创建一个新的目录
rmdir:一个空的目录
cp:复制文件或目录
rm:移除文件或目录
cat由第一行开始显示文件内容
tac从最后一行开始显示，可以看出tac是cat的倒著写！
nl显示的时候，顺道输出行号！
more一页一页的显示文件内容
less与more类似，但是比more更好的是，他可以往前翻页！
head只看头几行
tail-fxx.log只看尾巴几行个

监控最后行号高亮（全部显示）：tail-frun.log I perl-pe
s/(request)/\el1;31mS1\el0m/g
useradd-d/usr/sam-msam:此命令创建了一个用户sam,其中-d和-m选项用来为登录名sam产生一个主目录/usr/sam
usermod-s /bin/ksh-d /home/z-g developer sam
userdel-r sam
passwd-sam锁定口令
passwd-dsam将用户sam的口令
passwd输入新旧密码，修改密码
groupadd group1新增用户组
groupdel group1
groupmod-g102 group:2此命令将组group:2的组标识号修改为102。


@磁盘相关
df-h:列出文件系统的整体磁盘使用量，易读方式，查看磁盘使用情况
df-m:以MBytes的容量
du-h:查看目录和文件大小
fdisk:用于磁盘分区
fsck(file system check)用来检查和维护不一致的文件系统
free-h内存使用易读方式
top cpu使用率磁盘挂载使用mount命令，卸载使用umount命令
root@www~#mkdir /mnt/hdc6
root@www~]#mount/dev/hdc6/mnt/hdc6将刚刚创建的/dev/hdc6挂载到/mnt/hdc6上面挂载的含义：将某个未使用的空间或可移动设备的存储空间指向一个目录。
这样，通过该目录就可以访问你的个了。在Windows中，盘和D盘是并列的最顶级目录，但Linux监控最后行号高亮（全部显示）：

tail-frun.log I perl-pes/(request)/\el1;31mS1\el0m/g
useradd-d/usr/sam-msam:此命令创建了一个用户sam,其中-d和-m选项用来为登录名sam产生一个主目录/usr/sam
usermod-s /bin/ksh-d /home/z-g developer sam
userdel-r sam
passwd-sam锁定口令
passwd-dsam将用户sam的口令
passwd输入新旧密码，修改密码
groupadd group1新增用户组
groupdel group1
groupmod-g102 group:2此命令将组group:2的组标识号修改为102。


@磁盘相关
df-h:列出文件系统的整体磁盘使用量，易读方式，查看磁盘使用情况
df-m:以MBytes的容量
du-h:查看目录和文件大小
fdisk:用于磁盘分区
fsck(file system check)用来检查和维护不一致的文件系统
free-h内存使用易读方式
top cpu使用率
磁盘挂载使用mount命令，卸载使用umount命令
root@www~#mkdir /mnt/hdc6
root@www~]#mount/dev/hdc6/mnt/hdc6将刚刚创建的/dev/hdc6挂载到/mnt/hdc6上面
挂载的含义：将某个未使用的空间或可移动设备的存储空间指向一个目录。这样，通过该目录就可以访问你的个了。


在Windows中，C盘和D盘是并列的最顶级目录，但Linux
中没有C盘D盘E盘的概念，整个文件系统就只有一个顶级的根目录(/)，所有的物理磁盘都是根目录(/)下的一个子
目录而已。所以，如果你要给现在的系统加快硬盘或添加分区，就先创建一个目录，然后用MOUNT和相应的格式参
数把硬盘或分区挂载到你创建的那个目录中去，成功后，访问那个目录既是访问你加上的硬盘或分区。


@vi简单说明
vim xxx.log
i:插入
esc:退出，：wq!写退出：q!不写退出


@yum相当于windows的在线安装
yum(全称为Yellow dog Updater,Modified)是一个
在Fedora和RedHat以及SUSE中的Shelli前端软件包管理器。基於RPM包管理，
能够从指定的服务器自动下载RPM包并且安装，可以自动
处理依赖性关系，并且一次安装所有依赖的软体包，无须琐地一次次下载、安装。yum提供了查找、安装、某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。
yum install flex安装
yum update更新所有软件命令
yum install pam-devel
find
find./-size-10G文件size小于10G的文件或目录
find/-size+10M文件size大于10M的文件或目录
find./-group wade查找组名为wade的文件或目录
find./-user czi所有者为czj的文件或目录
find./-perm-o=r其它用户权限有读权限的目录或文件
find./-empty-type f-print-delete查找空文件打印并
find/-name\*.zip查找文件名匹配*.zip的文件


@一些命令
hostname显示主机名
uname显示系统信息
kill-9pid强制终止，杀死进程
tar-zcvf/home/abc.tar.gz/home/abc打包，并用gzip压缩
tar-czf log-date+%Y%m%d.tar.gz/var/log每周5使用
tar命令备份/var/log下的所有日志文件
printf和echo:
(1)首先echo是回显，即代表回车显示，是自带换行的；而printf只是打印出来，没有换行
(2)echo只是回显没有变量替换功能；printf是有的举例：假如我们定义好变量a='hello world'则echo"%s"Sa?显示的结果就是%s而printf"%s\ln”Sa?显示的结果就是hello world


@定时任务
crontab命令用于设置周期性被执行的指令，crontab在/etc目录下面存在cron.hourly,cron.daily,cron.weekly,cron.monthly,cron.d
五个目录和crontab,cron.deny二个文件
在home目录下编写一个test.sh脚本，脚本功能是
把/home下ifcfg-ethO这个文本复制到/mnt目录下
运行crontab-e编写一条定时任务*/5****
/home/test.sh在每5分钟执行一次test.sh脚本。

#crontab-e#编写计划任务，执行备份脚本
00 03 5/root/logbak.sh
查询当前用户定时任务crontab-|
当前用户定时任务。crontab-r
设置crond开机自动启动。


@PS命令
ps aux more
USER PID %CPU %MEM VSZ RSS TTY STAT START
TIME COMMAND
root10.00.04772564?SSep220:03init3]
root 2 0.0 0.0 0 0 S Sep22 0:03 migration/0]
root 3 0.0 0.0 0 0 SN Sep22 0:00 [ksoftirqd/0
root 4 0.0 0.0 0 0 S Sep22 0:02 migration/1]

USER进程的属主；
PID进程的ID;
PPID父进程；
%CPU进程占用的CPU百分比；
%MEM占用内存的百分比；
NI进程的NICE值，数值大，表示较少占用CPU时间；
VSZ进程使用的虚拟内存量(KB);
RSS该进程占用的固定内存量(KB)(驻留中页的数量)；
TTY该进程在那個終端上運行（登陸者的終端位置），若
與終端無關，則顯示(？)。
若为pts/O等，则表示由网络连接主机进程
WCHAN当前进程是否正在進行，若为-表示正在進行；
START該進程被觸發启动时间；
TIME該进程實際使用CPU運行的时间；
COMMAND命令的名称和参数；
STAT狀態位常見的狀態字符

ps aux-sort=+%cpu head-10CPU升序排列前10
或者top,大写的P,按照CPU降序排列

ps aux-sort=+rsshead-10内存升序排列前10
或者top,大写的M,按照内存降序排列


@awk-强大的文本格式化工具
1)命令grep,更适合单纯的查找或匹配文本；
2)命令sed,更适合对匹配到的文本进行编辑；
3)命令awk,更适合文本格式化，对文本进行较复杂的格式处理；逐行执行，支持if,for,while,运算符等。把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。
BEGIN中的内容是在awk开始扫描输入之前执行，一般用来初始化或设置全局变量；而END之后的操作将在扫描完全部的输入之后执行。
awk'S1>="10:05"&&S1<="11:10"c


@mail命令
vim/etc/mail.rc文件尾增加以下内容
set from=1968089885@qq.com smtp="smtp.qq.com"
set smtp-auth-user="1968089885@qq.com"smtp-auth-
password=123456"
set smtp-auth=login
mail-s"测试"1968089885@foxmail.com-简单发送
mail-s"邮件主题”1968089885@foxmail.com<
/data/findyou.txt-正文
mail-s"邮件主题"1968089885@foxmail.com-a
/data/findyou.tar.gz</data/findyou.txt本-附件


@复杂语句
SUSER:当前用户，管理员为root
SUID:当前用户ID,管理员为O
SRANDOM:随机数
sleep5:主线程睡眠5秒钟
#使用openssl生成私钥
openssl genrsa -out ${dir}/S(name).key
#使用openssl生成证书#subj选项可以在生成证书时，非
交互自动填写Common Name信息
openssl req -new -x509 -key $(dir}/S(name).key个"/CN=common"-out S{dir/S(name).crt

virsh list-all:列出所有虚拟机
virsh start DGG01:启动名称是DGG01的虚拟机
virsh destroy DGG01:关闭名称是DGG01的虚拟机
virsh autostart DGG01:开机自启名称是DGG01的虚拟机
virsh autostart-disable DGG0l:关闭开机自启名称
是DGG01的虚拟机ss的含义Socket State
选项-表示不解析服务名；-|显示本地打开的所有监听端口；-n看看服务使用的端口；
echo$$:随机密码
uuidgen:uuid


@Linux shell中的竖线(I)一一管道符号
command1 command2他的功能是把第一个命令
command1执行的结果作为command2的输入传给
command 2






修改主机名为hiya_vm_001 : hostnamectl set-hostname hiya_vm_001


http://isoredirect.centos.org/centos/8/isos/x86_64/CentOS-8.1.1911-x86_64-dvd1.iso



无法获得VMCI驱动程序的版本：句柄无效
D:\Programme files\linux\HIYA_CENTOS_1\HIYA_CENTOS_1.vmx
vmci0.present=FALSE



centos 7 64位
root/root
hiya01/hiya01


vim /etc/sysconfig/network-scripts/ifcfg-ens33

将BOOTPROTO配置项的值由"dhcp" 修改为 "static"；
ONBOOT配置项的值修改为"yes"
IPV6INIT  改成 no 

IPADDR="192.168.1.113"    
GATEWAY="192.168.1.1"     
NETMASK="255.255.255.0" 
NM_CONTROLLED="no"       
DNS1=192.168.1.1
DNS2=8.8.8.8








i    从命令模式切换到编辑模式；
Esc  从编辑模式切换到命令模式；
:wq! 在命令模式下，执行存盘退出操作；



使用cd ../ 退回上层目录，编辑 network 文件，添加DNS:vim network
添加两项配置值：

vi /etc/sysconfig/network-scripts/network
DNS1=192.168.1.1
DNS2=8.8.8.8




2、关闭防火墙并且打开22端口
查看系统版本  root@linuxidc ~]#  lsb_release -a
cat /etc/os-release




（--permanent永久生效，没有此参数重启后失效）

firewall-cmd --zone=public --add-port=22/tcp --permanent    
systemctl restart firewalld.service
systemctl restart network.service




/home/hiya001/softwares/nexus/nexus-3.13.0-01/bin/nexus start




虚拟机断电：
提示Generating /run/initramfs/rdsosreport.txt
xfs_repaire /dev/mapper/cenos-root-L
reboot


虚拟机断电：
VMware Workstation 不可恢复错误: (vmx)Exception 0xc0000006 (disk error while paging) has occurred.
删除或修改虚拟机目录下拓展名为.vmss文件，再次启动即可。





---------------------------------------------------------------------------------------------------------------
------------------------------------------Linux&Shell.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Lua&Nginx&OpenResty&Kong.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------

@Lua仅让你用少量的代码解决关键问题，Lua是一个小巧而简单的语言，因为Lua不致力于做C语言已经做得很好的领域（性能、底层操作、第三方软件的接口）。
Lua依赖于C去做完成这些任务。Lua所提供的机制是C不善于的：高级语言、动态结构、简洁、易于测试和调试等。
体积小，效率高，Lua不是通过使用条件编译实现平台无关，而是完全使用ANSI(ISO)C,这意味着只要你有ANSIC编译器你就可以编译并使用Lua。


@使用Lua脚本的好处
1、减少网络开销：可以将多个请求通过脚本的形式一次发送，减少网络时延和请求次数。
2、原子性的操作：Redis会将整个脚本作为一个整体执行，中间不会被其他命令插入。因此在编写脚本的过程中无需担心会出现竞态条件，无需使用事务。
3、代码复用：客户端发送的脚步会永久存在redis中，这样，其他客户端可以复用这一脚本来完成相同的逻辑。
4、速度快：见与其它语言的性能比较，还有一个JIT编译器可以显著地提高多数任务的性能；对于那些仍然对性能
不满意的人，可以把关键部分使用实现，然后与其集成，这样还可以享受其它方面的好处。
5、可以移植：只要是有ANSI C编译器的平台都可以编译，你可以看到它可以在几乎所有的平台上运行：从
Windows到Linux,同样Mac平台也没问题，再到移动平台、游戏主机，甚至浏览器也可以完美使用（置个成JavaScript).
6、源码小巧：20行C代码，可以编译进182K的可执


@C语言编写，大小写敏感，分号可选
file.lua:print("Hello Lua!")
cd /home/dev/lua/file/


@运行
#命令行运行：lua file.lua
#shelli运行：
cat hello.lua
#!/usr/local/bin/lua
print("Hello,World")
./hello.lua


@注释
-行注释
-[
块注释
J1-
@数字：double型
num=1024
num =3.0
num=3.1416
num=314.16e-2
num=0.31416E1
num Oxff
num 0x56


@字符串：单引号，双引引号，转义
a='alo\n123"
a ="alo\n123\""
a=1971o\10\04923"
a [[alo
123"]-有换行的字符串

@C语言中的NULL在Lua中是nil

@布尔类型：nil和false=false.其他数字O,空字符串都


@变量：lua中的变量如果没有特殊说明，全是全局变量，那怕是语句块或是函数里。前加ocal关键字的是局部变量。
theGlobalVar 50
local theLocalVar "local variable"


@控制语句：Lua没有++或是+=这样的操作
while a do
print(1)
end
if a and b then print("33"..ert)
elseif c and d then io.write("too young,too naive!\n")
else print(3)
end
for i=1,100 do
sum sum +i
end
sum=2
repeat
sum=sum^2-幂操作
until sum >1
“~=”是不等于，而不是！=
条件表达式中的与或非为分是：and,or,not关键字
io库的分别从stdin和stdouti读写的read和write函数


@递归函数
function digui(n)
if n 2 then return 1 end
return digui(n -2)+digui(n-1)
end


@闭包函数
function newCounter(
local i=0
return function-anonymous function
i=i+1
return i
end
end
c1 newCounterO
print(c10)->1
print(c10)-->2


@函数的返回值
function getUserInfo(id)
return "haoel",37,"haoel@hotmail.com","http://jb51.net"
end
name,age,email,website,bGay getUserlnfo
因为没有传id,所以函数中的id输出为nil,因为没有返回bGay,所以bGay也是nil。


@函数可变参数
Lua将函数的参数放在一个叫arg的表中，除了参数以外，arg表中还有一个域n表示参数的个数。
function print(...)
for i,v in ipairs(arg)do
printResult printResult .tostring(v).."\t"
end
printResult printResult ."\n"
end


@Table
Table其实就是一个Key Value的数据结构，它很像
Javascript中的Object
haoel {name="ChenHao",age=37,handsome=True
haoel.website="http://jb51.net/"
local age haoel.age
haoel.handsome false
haoel.name=nil
for k,v in haoel(t)do
print(k,v)
end


@数组（定义成不同的类型的数组）
arr{"string",100,"haoel",functionO
print("coolshell.cn")end}
#arr是arr的长度


@Lua的_G
Lua用Table:来管理全局变量，这些全局变量放在了一个
叫“_G”的Table里
_G.globalVar


@MetaTable和MetaMethod
fraction_a (numerator=2,denominator=3}
fraction_b=(numerator=4,denominator=7)
setmetatable(fraction_a,fraction_op)-setmetatble
是Lua库内置函数
setmetatable(fraction_b,fraction_op)
fraction_op=
function fraction_op._add(f1,f2)
ret =0
ret.numerator f1.numerator f2.denominator
f2.numerator f1.denominator
ret.denominator f1.denominator f2.denominator
return ret
end
fraction_s fraction_a fraction_b;
_add这是MetaMethod,这是Lua内建约定的
_add(a,b)对应表达式a+b
_sub(a,b)对应表达式a-b
_mul(a,b)对应表达式a*b
_div(a,b)对应表达式a/b
_mod(a,b)对应表达式a%b
_pow(a,b)对应表达式ab
_index(a,b)对应表达式a.b


@__index
重载了find key的操作，像Javascript的prototype。
有两个对象a和b,我们想让b作为a的prototype:
setmetatable(a,{_index b))
Window_Prototype ={x=0,y=0,width=100,height=100}
MyWin =(title="Hello"}
setmetatable(MyWin,{_index Window_Prototype))
:MyWin中就可以访问x,y,width,height



@面向对象
Person=
function Person:new(p)
local obj p;
if obj =nil
then obj =(name="Wade",age=25}
end
self._index=self-self就是Person,Person:new(p),
相当于Person.new(self,p)
return setmetatable(obj,self)-setmetatable这个函数返回的是第一个参数的值。

end
function Person:toString)
return self.name.":".self.age."。"
end
me Person:new((name="King's fucking",age=70,
handsome=false})
print(me:toStringO)



@协程
Lua的所有协同函数存放于coroutine table中。createl函数
用于创建新的协同程序，其只有一个参数：一个函数，
即协同程序将要运行的代码。若一切顺利，返回值
为thread类型，表示创建成功。
co coroutine.create(function O
print("hi")
end)
print(co)->thread:0x8071d98
挂起态(suspended)、运行态(running)、停止态(dead)。当我们创建协同程序成功时，其为挂起态，即此时协同程序并未运行
print(coroutine.status(co)-查看状态
coroutine.resume(co)-唤醒，运行态
coroutine.yield(-挂起协程
极高的执行效率：因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显；
不需要多线程的锁机制：因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。



@Stringl库
s string.sub(s,2,-2)
string.lower(a)


@kong公共API
kong.dao操作数据库表中给定类型的实体
kong.plugins.basic-auth.crypto密码用consumer_id(足够长，唯一)进行加盐验证
kong.plugins.galileo.alf向ALF添加一个条目
kong.plugins.galileo.buffer定时器
kong.plugins.jwt.jwt_parse支持签名令牌的算法。7
kong.tools.responses Kong.发送HTTP响应到客户端的方
kong.tools.timestamp timestamp的支持模块
kong.tools.utils通用方法模块
spec.helpers用于帮助测试Kong特性和插件的实用程序的集合


@require "cjson.safe"
如果直接采用cjson
local inputStr ={"name":"void","br}
local iJson=cjson.decode(inputStr)-意外退出，因为这里inputStr不是JSON格式数据，出现解析异常。如果采用cjson.safe模块
local inputStr ={"name":"void","br}
local iJson=cjsonSafe.decode(inputStr)-cjson.safe返回的是nil,可以通过判断iJson是否为nil知道解析是否出现了问题。


@ngx_lua模块
ngx.OK(O)
ngx.ERROR (-1)
ngx.HTTP_GET
ngx.HTTP_OK (200)
ngx.HTTP_FORBIDDEN (403)
ngx.HTTP_UNAUTHORIZED (401)
ngx.config.nginx_version返回nginx版本号
ngx.worker.pid返回当前worker进程的pid
ngx.now返回当前时间
ngx.today返回当前日期
ngx.encode.base64字符串的base64编码
ngx.escape._uri字符串的url编码
ngx.req.get_headers获取请求头
ngx.req.get_post_args获取请求表单
ngx.req.get_uri_args获取请求参数
ngx.log(ngx.Notice,"start'"."ddd"打印日志
ngx.var.uri返回访问路径
ngx.say("Hello,"who,"!"


@kong网关插件
local responses require "kong.tools.responses"
local cjson require "cjson.safe"
local _M=
function _M.execute(conf)
-打印参数日志
ngx.log(ngx.NOTICE,"START "..conf.address..")
-判断白名单
if conf.exception then
local uri ngx.var.uri
for e in string.gmatch(conf.exception,"([',]+)"
do if string.find(uri,e)
then ngx.log(ngx.NOTICE,"白名单OK,直接通过")
return
end
end
end
-判断有没有用户信息
local args ngx.req.get_uri_args)
local headers ngx.req.get_headers
if not headers"user-info"then
ngx.log(ngx.NOTICE,"no user info,return .."
end
-构建参数
local params={
method="GET"
headers={
["Context-Type"="application/json",
["user-info"=headers["user-info"],
["project-id"]=args["project-info"),
["method"=ngx.var.method,
["uri"=uri
}
}
-调用接口鉴权
local
res,err
require("kong.utils.http").new):request_uri(conf.address,
params)
if not res or err then
then ngx.log(ngx.ERR,"address not right")
responses.send(504,"GateWay Error")
elseif string.sub(tostring(res.status),1,1)=='2'then
if tostring(res.body)=="true"then return
end
responses.send(403,"No authorize.")
else responses.send(res.status,"No authorize."
end
end
return _M


@ngx_lua
Nginx採用多进程模型，单Master-一多Worker,由Master处理外部信号、配置文件的读取及Worker的初始化。
Workeri进程採用单线程、非堵塞的事件模型来实现port的
监听及clienti请求的处理和响应，同一时候Workeri还要处理来自Master的信号。
因为Worker使用单线程处理各种事件。所以一定要主循环是非堵塞的，否则会大大减少Worker的响力。
ngx_lua是阿里淘宝开发，将Lua嵌入Nginx,能够让Nginx运行Lua脚本，而且高并发、非堵塞的处理各种请求。Lua内建协程。
ngx_lua在Lua中进行的lO操作都会托付给Nginx的事件模型。从而实现非堵塞调用。开发人员能够採用串行的方式编敲代码，
淘宝、腾讯财经、网易财经、360、去哪儿网.
每一个NginxWorker进程持有一个Lua解释器或者LuaJIT实例，被这个Workers处理的全部请求共享这个实例。
每一个请求的Context:会被Lua轻量级的协程切割，从而保证各个请求是独立的。对于每一个用户请求，ngx_lua会
唤醒一个协程用于执行用户代码处理请求，当请求处理完毕这个协程会被销毁。


@Openresty
在Nginx.上开发成了一个难题，Nginx模块需要用C开发，
而且必须符合一系列复杂的规则，最重要的用C开发模块必须要熟悉Nginx的源代码，
使得开发者对其望而生畏。为了开发人员方便，所以接下
来我们要介绍一种整合了Nginx和lua的框架，那就是OpenResty,它帮我们实现了
可以用ua的规范开发，实现各种业务，并且帮我们弄清楚各个模块的编译顺序。
Openresty在核心nginx:基础上封装了很多实用的第三方
Nginx模块,
比方HttpLuaModule,HttpRedis2Module,HttpEchoModule,Mysql、Redis、Memcached等，
可以直接编写lua语言.是一个基于Nginx与Lua的高性能Web平台.应该可以取代ngx_lua。

Nginx-->Nginx采用的是master-worker模型，一个
master进程管理多个worker进程，基本的事件处理都是放在woker中，master负责一些全局初始化，以及对worker的管理。

Openresty-->在OpenResty中，每个woker使用一个LuaVM,当请求被分配到woker时，将在这个LuaVM里
创建一个coroutine(协程)。协程之间数据隔离，每个协程具有独立的全局变量_G。

lua-resty-memcached缓存
lua-resty-mysql数据库
lua-resty-redis redis
lua-resty-dns域名
lua-resty-limit-traffic限流
lua-resty-template模板
testlua.lua:
local args=nil
local request_method ngx.var.request_method
if"GET"==request_method then
args ngx.req.get_uri_args()
elseif "POST"==request_method then
ngx.req.read_body)
args ngx.req.get_post_args(
if (args =nil or args.data =null)then
args ngx.req.get_uri_args)
end
end
local name args.name
ngx.say("linux hello:".name)
nginx.conf引入lua文件：
location /luatest
{
default_type text/html;
content_by_lua_file
/usr/local/openresty/lualib/testcode/testlua.lua;
}
使用apache bench可以进行并发测试
ab-c20-n200127.0.0.1/uatest
注：20个并发，一共请求20万次
一台1核700兆的llinux虚拟机即可跑出2W的并发，足以说
明OpenResty:处理高并发的能力，由于ab工具的限制，只
能测试上限2W的并发

#lua依赖路径
lua_package_path "/export/App/nginx-app/lualib/?.lua;;";
lua_package_cpath
"/export/App/nginx-
app/lualib/?.so;;";
#server配置
include/export/App/nginx-app/config/domains/*;
#初始化脚本
init_by_lua_file "/export/App/nginx-app/lua/init.lua";



@Redis和lua
1:lua文件
local key=KEYS1;
local args=ARGV
local i=0;
local result=0;
for m,n in ipairs(args)do
local ishit=redis.call("sismember",key,n);
if(ishit)then
table.insert(result,1,n);
end
end
return result;
local redis require("resty.redis")
local red redis:new)
local ok,err red:connect(ip,port)
ok,err red:set("msg","hello world")
local resp,err red:get("msg")
server
listen 80;
server_name _
location /lua_redis_basic
default_type 'text/html';
lua_code_cache off;
content_by_lua_file /home/hiya/test_redis_basic.lua;
}
}
127.0.0.1/lua_redis_basic
2:Redis分布式锁的正确实现方式（原子性）
public static boolean tryGetDistributedLock(Jedis jedis,
String lockKey,String requestld,int expireTime){
String result jedis.set(lockKey,requestld,
SET_IF_NOT_EXIST,
SET_WITH_EXPIRE_TIME,
expireTime);
if (LOCK_SUCCESS.equals(result)){
return true;
}
return false;
}
错误加锁：
public static void wrongGetLock1(Jedis jedis,String
lockKey,String requestld,int expireTime){
Long result jedis.setnx(lockKey,requestld);
if (result =1){
/若在这里程序突然崩溃，则无法设置过期时间，将发死锁个
jedis.expire(lockKey,expireTime);
}
正确解锁（原子性）：
public static boolean releaseDistributedLock(Jedis jedis,
String lockKey,String requestld){
String script="if redis.call('get,KEYS[l])=王ARGV[1]
then return redis.call('del',KEYS[1)else return 0 end";
Object
result
jedis.eval(script,
Collections.singletonList(lockKey)
Collections.singletonList(requestld));
if (RELEASE_SUCCESS.equals(result)){
return true;
}
return false;
}
错误解锁1：
最常见的解锁代码就是直接使用jedis.del)方法锁，
这种不先判断锁的拥有者而直接解锁的方式，会导致任何
客户端都可以随时进行解锁，即使这把锁不是它的。
public static void wrongReleaseLock1(Jedis jedis,String
lockKey){
jedis.del(lockKey);
}
错误解锁2
public static void wrongReleaseLock2(Jedis jedis,String
lockKey,String requestld){
if (requestld.equals(jedis.get(lockKey))){
jedis.del(lockKey);
}
}
如代码注释，问题在于如果调用jedis.delQ方法的时候，
这把锁已经不属于当前客户端的时候会解除他人加的锁。

那么是否真的有这种场景？
答案是肯定的，比如客户端A加锁，一段时间之后客户端A解锁，在执行jedis.delQ之前，锁突然过期了，此时客户
端B尝试加锁成功，然后客户端A再执行del)方法，则将客户端B的锁给解除了。



@Redis+lua实现秒杀
在安装了redis服务器之后，就可以执行lua。那么redis为什么需要ua呢？
简单来说为了性能以及事务的原子性。
因为redis帮我们提供的事务功能太差。
下面以电商秒杀场景作简要说明。在上面所描述的步骤中
校验库存与扣库存，存在先后顺序，但是并没有原子性。
在关系数据库中，可以通过事务来解决
这个问题，但是关系数据库性能有瓶颈。当然在请求量可
以控制的情况下，使用关系数据库的乐观锁，也是可以的。就像现在我在公司所使用的方案为秒杀
单接口进行限流+数据库的乐观锁就完全解决这个问题。
但是这个通过限流来解决了请求的峰值。
如果我们将校验库存，扣库存这段逻辑放在redis上执行，也存在原子性问题。redis帮我们也提供了事务功能，
但是这个事务功能太差强人意了。所以在本文中，我们希望通过redis+lua的方式解决这个问题.
lua脚本需要完成的业务逻辑
用户是否忆秒订单判断；校验库存；扣库存；设置抢单成
功用户标识；返回结果
public boolean orderSecKill(SecKillPara para,Jedis
jedis){
/*0,已抢过单；2.库存不足；1.抢单成功*/
入
Long customerld para.getCustomerld);
String script = "local ismeber=redis.call('sismember',ARGV[1],KEYS[1])
11
+"if ismeber~=0 then”/-判断该用户是否秒杀过，如
果已秒则不允许再秒
+"return 0"
+"end
/+"redis.call(set'KEYS[1],1)”//-设置抢单标识
/+"redis.call('expire'KEYS[1],2)"/-设置过期时间
/-check库存
+"for goodsNum=2,#KEYS do
+"local goodsStock=redis.call('get',KEYS[goodsNum])"
+"if goodsStock ARGV[goodsNum]then
+"return 2;"
+"end
+"end"
/-扣库存
+"for goodsNum=2,#KEYS do
+
redis.call('DECRBY',KEYS[goodsNum],ARGV[goodsNum])
1
+"end
/-所有抢单成功的用户
+"redis.call('sadd',ARGV[1],KEYS[1])"
+"return 1;"
List<String>keys new ArrayList<String>0;
List<String>args new ArrayList<String>0;
keys.add(customerld.toStringO);
args.add("all_order_user");/所有抢单的用户
for (Map.Entry<Long,Integer>
goods
para.getGoodsWithAmount().entrySet(){
keys.add(goods.getKey).toStringO);
args.add(goods.getValue().toString));
}
Object o jedis.eval(script,keys,args);
Long result=Long.valueOf(o.toStringO);
if(result==1){
return true;
}
return false;
}
public static final class SecKillPara{
private final Long customerld;/抢单人
private final Map<Long/*所抢skuld*/,Integer/*所抢sku
个数*/>goodsWithAmount;
public SecKillPara(Long customerld,Map<Long,Integer>
goodsWithAmount){
super);
this.customerld customerld;
this.goodsWithAmount goodsWithAmount;
}
public Long getCustomerldo{
return customerld;
}
public Map<Long,Integer>getGoodsWithAmount({
return goodsWithAmount;
}
}
nginx
负载均衡：在负载均衡之前首先是一个http服务器；
#设定负载均衡的服务器列表
upstream mysvr
#weigth参数表示权值，权值越高被分配到的几率越大
#本机上的Squid开启3128端口
server192.168.8.1:3128 weight=5;
server 192.168.8.2:80 weight=1;
server 192.168.8.3:80 weight=6;
}
前端限流-保护系统不被瞬间到来的高并发流量给打垮，就
需要限流
limit_req_zone Sbinary_remote_addr zone=perip:10m
rate=1r/s-10MB存储10多万lp,一秒一个请求，申
明perip
location /
limit_req zone=perip;-使用perip
proxy_pass http://myserver;
}
反向代理：代理外网用户的请求到内部的指定web服务
器，并将数据返回给用户的一种方式
server
server_name htnginx.chinacloudapp.cn;
#access_log logs/host.access.log main;
location/{#静态网页在本机
root html;
index index.html;
}
location~*/form{#指定目录在后端服务器
proxy_pass http://mysvr
proxy_set_header X-Real-IP Sremote_addr;
}
}
动静分离：tomcat解析静态很慢，使用正则表达式匹配
过滤，然后交个不同的服务器
location ~.*\(htm html giflipglipeg png bmp swflioc rarl
zipltxt|flvlmid|doclpptlpdflxls|mp3|wma)S
个
{
root /static;
expires 30d;
}
location ~.*\.(js|css)?S
{
root /static;
expires 1h;
}
require
local redis require("resty.redis")
require "luasql.mysql"
file io.open("test.lua","r")



@Nginx、OpenRestry、Kong这三个项目紧密相连：
Nginx是模块化设计的反向代理软件，C语言开发；
OpenResty:是一个集成了Nginx、LuaJIT和其它很多moudels的平台，可以理解为一个集成了很多模块的
定制版nginx;Kong是一个OpenResty应用，是一个apigateway,后台存储PostgreSQL,具有AP管理和请求代理的功能。





---------------------------------------------------------------------------------------------------------------
------------------------------------------Lua&Nginx&OpenResty&Kong.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Maven.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------


@Maven:插件干啥的？运行Ant任务、分析项目依赖译代码、jetty、tomcat、

@经典命令
mvn
package/mvn deply/mvn install
compile/mvn clean
·package命令完成了项目编译、单元测试、打包功但没有把打好的可执行jar包(war包或其它形式的包署到本地maven仓库和远程maven:私服仓库
·install命令完成了项目编译、单元测试、打包功能时把打好的可执行jar包(war包或其它形式的包)布本地maven仓库，但没有布署到远程maven私服仓库
·deploy命令完成了项目编译、单元测试、打包功能时把打好的可执行jar包(war包或其它形式的包)布本地maven仓库和远程maven私服仓库

@dependencies和dependencyManagement,plugipluginManagement
dependencyManagement.主要是为了统一管理插件保所有子项目使用的插件版本保持一致

@eclipse右键maven build输入命令即可

@mirror用法
<mirrors>
<mirror>
<id>UK</id>
<name>UK Central</name>
<url>http://uk.maven.org/maven2</url>
<mirrorof>central</mirrorof>
</mirror>
</mirrors>
这样的话，就会给上面id为central的远程仓库做了
像。以后向central这个仓库发的请求都：
到http:/uk.maven.org/maven?2而
是http://repo1.maven.org/maven:2了。
<mirrorOf>central</mirrorOf>里是要替代的仓库的id果填*，就会替代所有仓库。

@pom重点
dependencyManagement:父工程统一定义依赖版
信息
build:一般是插件引入；
profiles配置开发等profile;
profiles-repositories:是jar下载地址；
profiles-distributionManagement为deploy:地址；

@私服
从Maven中央仓库下载所需要的构件(artifact),
通常不是一个好的做法，你应该在本地架设一个Mav库服务器仓库组包括宿主（自己的jar或者数据库驱动）和代理
理对应一个远程；





cd  /home/hiya001/softwares/nexus

tar -zxvf nexus-3.13.0-01-unix.tar.gz

cd  /home/hiya001/softwares/nexus/nexus-3.13.0-01/bin/

./nexus run  是实时启动可以看到日志。
./nexus start 
./nexus stop
./nexus restart


#查询8081端口是否打开
firewall-cmd --query-port=8081/tcp

#开放8081端口
firewall-cmd --permanent --add-port=8081/tcp

#重启防火墙(修改配置后要重启防火墙)
firewall-cmd --reload

#查看当前所有已经使用的端口情况
netstat  -nultp

#82端口没有被占用
netstat  -anp  |grep  82

#修改端口号和上下文
cd /home/hiya001/softwares/nexus/nexus-3.13.0-01/etc
cat nexus-default.properties

#关闭防火墙，否则无法访问 
sudo systemctl stop firewalld

#默认管理员
http://192.168.1.111:8081/nexus
admin/admin123








windows:
nexus.exe /run








hiya-releases
host,发布库

hiya-snapshots
host,开发库

hiya-proxy
阿里云加速 
(http://maven.aliyun.com/nexus/content/repositories/central/)

hiya-releases-group
hiya-releases+hiya-proxy

hiya-snapshots-group  
hiya-snapshots+hiya-proxy

hiya-group 
hiya-releases-group+hiya-snapshots-group 



---------------------------------------------------------------------------------------------------------------
------------------------------------------Maven.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Middleware.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------



@tomcat原理
掌握netty,socket原理
开启一个tcp监听，整合目录下的配置文件。


@Server->Service->(n Connector-+1 Engine)->Host(主机)->Context(工程上下文根)->Wrapper(一个Servlet)


@Server组件：相当于一个物理机或者虚拟机开启了多个JVM进程，但是端口不一样。<Server port=8005"shutdown="SHUTDOWN">

@Service默认一个名字叫做”Catalina”的服务，<Service name=”Catalina”>

@Connector,1)HTTP连接器2)SSL连接器3)AJP1.3连接器4)proxy连接器
APR从操作系统级别来解决异步的IO问题。使用原生C语言编写的非堵塞/，利用了操作系统的网络连接功能，速度很快。
<Connector port:="9090”protocol:"HTTP/1.1”1.1的是bio
<Connectorport="9090"protocol="org.apache.coyote.http11.Http11NioProtocol"
NIO
<Connectorport="8080"protocol="org.apache.coyote.http11.Http11AprProtocol"
打印日志：
Starting ProtocolHandler ["http-nio-8009"]
Starting ProtocolHandler ["http-apr-8009"]


@springboot内嵌tomcat默认是nio的，如果改成apr

@Engine是Servlets处理器的一个实例，即servleti引擎


@Host包括本地主机，和虚拟主机
C:\Windows\System32\drivers\etc\hosts文件末尾添
加：127.0.0.1www.jalja1.org
<Host name="www.jalja1.org"appBase="E:/学
习/activeMq/app1"
<Host name="localhost"appBase="webapps"


@线程安全
在tomcat中每一个用户请求都是一个线程（配置线程池200)；或者自己在程序里面写多线程；


@springboot内嵌了tomcat只是为了方便开发；真正到生产环境搞集群还是导出一个war包，使用k8s管理docker技术，内嵌的tomcat不好管理集群；


@tomcat原理
Http使用可靠的tcp连接，tcp协议默认使用tcp80端口，无状态的。
创建了一个Socket服务器，并循环阻塞监听http请求，当有http请求到来时，该方法便创建一个Requesti对象，构造参数是socket获取的输入流对象，
用于读取客户端请求的数据并解析。然后再创建一个Response对象，构造参数是socket的输出流对象，并
含有一个Request>对象的成员变量。Response对象用于将静态页面发送给浏览器或者是其他的客户端。



---------------------------------------------------------------------------------------------------------------
------------------------------------------Middleware.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Mybatis(Plus).txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------

1传统JDBC的弊端
数据库连接，使用时就创建，不使用立即释放，对数据库进行频繁连接开启和关闭，造成数据库资源浪费，影响数
据库性能。解决方案：使用数据库连接池管理数据库连接。
将sql语句硬编码到java代码中，如果sql语句修改，需要重新编译java代码，不利于系统维护。解决方案：将sql语
句配置在xml配置文件中，即使sql变化，不需要对java代码进行重新编译。
向preparedStatement中设置参数，对占位符号位置和设置参数值，硬编码在java代码中，不利于系统维护。解决
方案：将sql语句及占位符号和参数全部配置在xml中。从resutSet中遍历结果集数据时，存在硬编码，将获取表
的字段进行硬编码，，不利于系统维护。解决方案：将查询的结果集，自动映射成java对象。


2 MyBatis是一个优秀的持久层框架，它对jdbc的操作数据库的过程进行封装，使开发者只需要关注SQL本身，
而不需要花费精力去处理例如注册驱动、创建
connection、创建statement、手动设置参数、结果集检索等jdbc繁杂的过程代码

3基本架构
SqlMapConfig.xml/mapper.xml配置文件
SqlSessionFactory会话工厂-->SqlSession-> Evecutor --Manned Statement (cal


3基本架构
SqlMapConfig.xml/mapper.xml配置文件->SqlSessionFactory会话工厂->SqlSession-->Executor-->Mapped Statement(一个sql)


4缓存机制
一级缓存是在SqlSession层面进行缓存的，默认开启，
本地hashmap缓存，同一个SqlSession多次调用同一个Mapper和同一个方法的同一个参数只会进行一次数据，当有insert和update时候回清空缓存，
集群的场景下，A节点执行update:操作只清空A节点的本地缓存，B节点还是查询旧的数据；
解决方案：SQL加上随机数；每次查询手动清除;select语句加上flushCache="true"。

二级缓存，需要配置打开，可以配置在redis里面；SqlSessionFactory层面上的二级缓存；
映射语句文件中的所有select语句将会被缓存，insert、update和delete语句会刷新缓存，LRU,最近最少使用的算法来收回；1024个引用；
<cache eviction="LRU"
flushInterval="100
readOnly="true"size="1024"/>
<resultMap id="studentMap"type="Student">
<id property="id"column="id"/>
<result property="name"column="name"/>
<result property="age"column="age"/>
<result property="gender"column="gen'"
typeHandler="org.apache.ibatis.type.EnumOrdinalTypeH
andler"/>
</resultMap>
sqlSessionFactory.openSession)一个新的sqlSession查
询同一个，也就是返回的缓存。


5数据源
Mybatis中支持三种形式数据源的配置，分别
为：UNPOOLED、POOLED和JNDI;
public class JndiDataSourceFactory implements
DataSourceFactory
public class UnpooledDataSourceFactory implements
DataSourceFactory
public class PooledDataSourceFactory extends
UnpooledDataSourceFactory


6 Mapperz动态代理
当getMapperO方法被调用时，Mybatis会找到相对应的MapperProxyFactory对象实例，利用这个工厂来创建一个jdk动态代理对象，
是这个Mapper接口的实现类，当Mapper定义的方法被调用时，会调用MapperProxy来处理。


7易混淆概念
DataSource:一个项目可以配置多个数据源，基于这个创建SqlSessionFactory;
SqlSessionFactory:单例模式，SqlSession工厂类；一般情况下，一个项目通常只需要一个SessionFactory就够，当需要操作多个数据库时，可以为每个数据库指定一个SessionFactory。
SqlSession:每个线程都应该有它自己的SqlSession实例，表示和数据库交互的会话，完成必要数据库增删改查功能
1)Execute:调度执行StatementHandler.、ParmmeterHandler、ResultHandler执行相应的SQL语句；
2)StatementHandler:使用数据库中Statement(PrepareStatement)执行操作，即底层是封装好了的prepareStatement;
3)ParammeterHandler:处理SQL参数；
4)ResultHandler:结果集ResultSet封装处理返回。以上4种Handler解释了职责单一的设计原则。
SessionFactory:hibernate的，和mybatis的SqlSessionFactory一个道理；
Session::hibernate的，和nybatis的SqlSession一个道理；
Connection:数据库的链接，一个请求一个线程，一个线程构建一个SqlSession,由于是非线程安全，独占，默认开启一个事务(session.commit(),不过具体的事务管理由事务隔离级别控制；
假如这个事务中有多次数据库操作，则需要多个Connection对象，一般是从数据库连接池中获取。
Mapper:一个mappery对应一个xml文件，通过动态个形式实现；


8源码分析
SqlSessionFactory
SqlSessionFactory一旦被创建就应该在应用的运行期间
一直存在，没有任何理由对它进行清除或重建。使用SqlSessionFactory的最佳实践是在应用运行期间不
要重复创建多次，多次重建SqlSessionFactory被视为一种代码“坏味道(bad smell)”。因此SqlSessionFactory的最佳作用域是应用作用域。
有很多方法可以做到，最简单的就是使用单例模式或者静态单例模式。

SqlSession
每个线程都应该有它自己的SqlSession实例。SqlSession的实例不是线程安全的，因此是不能被共享的，所以它的最佳的作用域是请求或方法作用域。绝对不能将
SqlSession实例的引用放在一个类的静态域，甚至一个类的实例变量也不行。也绝不能将SqlSession实例的引用放在任
何类型的管理作用域中。


9 Mybatis事务深入
在sqlSession中执行了UPDATE操作，需要执行sqlSession.commitO方法提交事务，不然在连接关闭时候会自动回滚；
使用JDBC的事务管理机制：即利用java.sql.Connection对象完成对事务的提交(commit())、回滚(rollback))、关闭(close()等。
使用MANAGED的事务管理机制：这种机制MyBatis自身不会去实现事务管理，而是让程序的容器如
(JBOSS,Weblogic)来实现对事务的管理
JdbcTransactionFactory工厂类创建，直观地讲，就是JdbcTransaction是使用的java.sql.Connection上的
commit和rollback功能，JdbcTransaction只是相当于对
java.sql Connection事务处理进行了一次包装
(wrapper)
public class JdbcTransaction implements Transaction
private static final Log log
LogFactory.getLog(JdbcTransaction.class);
protected Connection connection;
protected DataSource dataSource;
ManagedTransaction让容器来管理事务Transaction的整个生命周期，意思就是说，使用ManagedTransaction的
commiti和rollback.功能不会对事务有任何的影响，它什么都不会做，它将事务管理的权利移交给了容器来实现。
public class ManagedTransaction implements
Transaction
public void commit)throws SQLException
/Does nothing
}
public void rollback)throws SQLException
/Does nothing
}




10 MybatisPlus
代码生成器；
强大的CRUD操作内置通用Mapper、通用Service,仅仅通过少量配置即可
实现单表大部分CRUD操作，更有强大的条件构造器，满足各类使用需求
支持Lambda形式调用
通过Lambda表达式，方便的编写各类查询条件，无需再担心字段写错，Java8中让人又爱又恨的Lambda表达式
支持多种数据库
支持MySQL、MariaDB、Oracle、DB2、H2、HSQL、SQLite、Postgre、SQLServer22005、SQLServer等多种数据库
支持主键自动生成
支持多达4种主键策略（内含分布式唯一D生成个Sequence),可自由配置，完美解决主键问题








一级缓存是基于sqlsession的，当一次请求结束后，意味着session结束，所以sqlsession也就关闭了，所以缓存也清空了。
因此对于多次请求 肯定不存在一级缓存。

二级缓存杜宇namespace和mapper的，只要相同的sql查询，都会优先从缓存区域查询，所以对于多次请求，对于二级缓存没有影响的。

对于缓存更新机制，当一个作用域（一级Session/二级namespace）进行了CRUD操作之后，默认该作用域下面所有的select 中的缓存将被clear.

集群的场景下，A节点执行update操作只会清除A的本地缓存，B节点查询还是旧的数据？
解决方案：sql加上随机数，每次查询手动清除，select语句加上flushCache=true


sqlSessionFactory是单例的，但是每次请求openSession（）创建了一个代理对象，其实是新建一个代理对象，没有线程安全问题。

sqlSessionFactory对应hibernate的SessionFactory
sqlSession对应hibernate的Session

Connection:具体的数据库连接，一个请求一个线程，一个线程构建一个SqlSession，由于非线程安全，独占，默认开启一个事务，
不过具体的事务管理由事务隔离级别决定，假如这个事务由多个数据库操作，则需要多个Connection对象，连接池获取。





---------------------------------------------------------------------------------------------------------------
------------------------------------------Mybatis(Plus).txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Mysql.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------


1冗余
存储两倍数据，冗余可以使系统的速度更快；缺点是需要强一致性，否则很多脏数据；


2数据瓶颈
千万级，MySQL实际上确实不是什么压力，InnoDB的存储引引擎，使用的是+树存储结构，干万级的数据量，基
本也就是三到四层的搜索，如果有合适的索引，性能基本也不是问题。

大表优化顺序：
优化sql和索引>加缓存redis>主从复制&读写分离>mysql分区表>垂直分区（分为多个小的分布式系统/分库分表)>水平切分（分片）>改成nosql


3text和varchar
基本相同，text空格不截断，65535字节全部用来存储数据，额外2字节存大小；varchar!则会占用1-3个字节去存储数据大小


4 datetime和timestamp
都可用来表示YYYY-MM-DDHH:MM:SS[.fraction]类型的日期。
对于TIMESTAMP,它把客户端插入的时间从当前时区转化为UTC(世界标准时间)进行存储。默认东八区，查询时，将其又转化为客户端当前时区进行返回。
而对于DATETIME,不做任何改变，基本上是原样输入和输出。
timestamp所能存储的时间范围为：'1970-01-0100:00:01.到2038-01-1903：14：07.999999。
但是DB2可以存储1-01-0100：00：00的时间。跨数据库要考虑。datetime所能存储的时间范围为：'1-01-0100:00:00.到9999-12-3123：59：59.999999。


5加密相关
mysqlsha1不可逆
select password(bbs.antian365.com); 
md5,不可逆select md.5(bbs.antian365.com);encode)和decode)都有两个参数，第一个是实际需要保存的值，第二个是盐。
aes_encryptO和aes_decrypt()都有两个参数，第一个是实际需要保存的值，第二个是盐。aes对称加密，比
encode(和decode)安全性要高。



6主从复制，读写分离
主服务器(Master)负责网站NonQuery操作，从服务器负责Query:操作，
主从服务器利用MySQL的二进制日志文件，实现数据同步。二进制日志由主服务器产生，从服务器响应获取同步数据库。
同步过程(3个线程)：
1).binlog输出线程：每当有从库连接到主库的时候，主库都会创建一个线程然后发送binlog内容到从库。在从库
里，当复制开始的时候，从库就会创建两个线程进行处理：
2).从库I/O线程：当START SLAVE语句在从库开始执行之后，从库创建一个/线程，该线程连接到主库并请求主
库发送binlog.里面的更新记录到从库上。从库l/O线程读取主库的binlog输出
线程发送的更新并拷贝这些更新到本地文件，其中包括relay log.文件。
3).从库的SQL线程：从库创建一个SQL线程，这个线程读取从库l/O线程写到relay logl的更新事件并执行。


7存储引擎
MyISAM:早期默认的，速度快，无事务，无外键
InnoDB:目前默认的，有事务，有外键
MEMORY:速度快，内存机制，断电消失


8 InnoDB存储引擎索引一B+树索引引
B+树不是一个二叉树，是一个平衡树。二分查找法(binary search)也成为折半查找法，如果要找的元素值小于该中点值，则将待查序列缩小为左半部
分，否则为右半部分。通过一次比较，将查找区间缩小一半。
B+树索引引的本质就是B+树在数据库中的实现。但是B+索引在数据库中有一个特点是高扇出性，因此在数据库中，B+树的高度一般都在2~4层，
这也就是说查找某一键值的行记录时最多只需要2到4次，这道不错，因为当前一般的及其磁盘每秒至少可以
做100次10,2~4次的10意味着查询时间只需0.02~0.04秒。
数据库中的B+树索引可以分为聚集索引引(clusteredindex)和辅助索引(secondary index),
但是不管是聚集索引还是辅助索引，其内部都是+树索引，即高度平衡的，叶子节点存放着所有的数据。聚集索引与辅助索引不同的是，叶子节点存放的是否是一整行的信息。

InnoDB聚集索引就是按照每张表的主键构造一颗B+树，并且叶子节点上存放着整行记录数据。
非聚集索引的叶子节点上仅保存键值以及指向数据页的偏移量。
聚集索引的这个特性决定了索引组织表中数据也是索引的一部分。
除了聚集索引以外的索引都是非聚集索引，只是人们想细分一下非聚集索引，分成普通索引引，唯一索引引，全文索引。
如果非要把非聚集索引类比成现实生活中的东西，那么非聚集索引就像新华字典的偏旁字典，他结构顺序与实际存放顺序不一定一致。
实际上+索引引在数据库中有一个特点就是其高扇出性，因此在数据库中，B+树的高度一般不超过3层，也就是对于查找某一键值的行记录，最多只需要2到3次10。
现在一般的机械硬盘的IOPS(每秒进行读写(I/O)操作的次数)在100~200之间，2~3次的10意味着查询时间只需0.02~0.03秒。
更有甚者，现在大多数企业都使用SSD固态硬盘，IOPS基本超过50，查询效率进一步提升。



9核心概念
(一)单库单表：一个库，一个表T_USER

(二)水平分区：就是将一个数据量比较大的表，用某种方法把数据从物理上分成若干个小表来存储，从逻辑来看还是一个大表。局限在单个数据库范围里的，它不能跨越
服务器的限制是和分片的根本区别。

(三)水平分表：可以通过某种方式将user进行水平的切
分，产生两个表结构完全一样的user_0,user_1等表，user_0+user_1+…的数据刚好是一份完整的数据。

(四)水平分库：则把一个表的数据划分到不同的数据库，两个数据库的表结构一样。根据一定的规则，可以根
据数据的产生者来做引导，上面的数据是由人产生的，可以根据人的id来划分数据库。然后再根据一定的规则，先
获知数据在哪个数据库。

(五)垂直分库：按照业务不同，拆分成多个库。

(六)读写分离/主从复制：一般来说都是通过主从复制(Master-Slave)的方式来同步数据，再通过读写分离(MySQL-Proxy)来提升数据库的并发负载能力这样的
方案来进行部署与实施的。

(七)水平分片：在分布式存储系统中，数据需要分散存储在多台设备上，数据分片(Sharding)就是用来确定数
据在多台存储设备上分布的技术。数据分片要达到三个目的：
分布均匀，即每台设备上的数据量要尽可能相近；负载均衡，即每台设备上的请求量要尽可能相近；扩缩容时产生的数据迁移尽可能少。
水平分区功能确实可以实现表的分区，但是这种分区是局限在单个数据库范围里的，它不能跨越服务器的限制。


10默认隔离级别
Mysql默认的事务处理级别是REPEATABLE-READ',也就是可重复读
Oracle默认系统事务隔离级别是READ COMMITTED,也就是读已提交


11 innoDB锁
共享锁【S锁】又称读锁，若事务T对数据对象A加上S锁，则事务T可以
读A但不能修改A,其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这保证了其他事务可以读A,但在T释放A上的S锁之前不能对A做任何修改。

排他锁【X锁】
又称写锁。若事务T对数据对象A加上X锁，事务T可以读A也可以修改A,其他事务不能再对A加任何锁，直到T释
放A上的锁。这保证了其他事务在T释放A上的锁之前不能再读取和修改A。
共享锁和排他锁都是行锁，意向锁都是表锁，应用中我们只会使用到共享锁和排他锁，意向锁是mysql内部使用的，不需要用户干预。


12 Mycat
分表、读写分离、主从切换，数据库中间件，代理数据库能满足数据库数据大量存储；提高了查询性能，同时保持
了关系数据库的特征。
有些场合NoSQL一些折衷是无法满足使用场景的，就比如
有些使用场景是绝对要有事务与安全指标的。这个时
候NoSQL肯定是无法满足的，所以还是需要使用关系性数据库。
如何使用关系型数据库解决海量存储的问题呢？此时就需要做数据库集群，为了提高查询性能将一个数据库的数据分散到不同的数据库中存储，为应对此问题就出现了

MyCat
server.xml
<user name="test">
<property name="password">test</property>
<property name="schemas">lunch</property>
<property name="readOnly">false</property>
<privileges check="false">
<schema name="TESTDB"dml="0110">
<table name="tbo1"dml="0"></table>
<table name="tbo2"dml="1111"></table>
</schema>
</privileges>
</user>
schema.xml
<?xml version="1.0?>
<DOCTYPE mycat:schema SYSTEM "schema.dtd">
<mycat:schema xmlns:mycat="http://io.mycat/">
<!-数据库配置，与server.xml中的数据库对应->
<schema name="lunch"checkSQLschema="false"
sqlMaxLimit="100">
<table name="lunchmenu"dataNode="dn1"/>
<table name="restaurant"dataNode="dn1"/>
<table name="userlunch"dataNode="dn1"/>
<table name="users"dataNode="dn1"/>
<table name="dictionary"primaryKey="id
autolncrement="true"dataNode="dn1,dn2"rule="mod-
long"/>
</schema>
<!-分片配置->
<dataNode name="dn1"dataHost="test1"
database="lunch"/>
<dataNode name="dn2"dataHost="test2"
database="lunch"/>
<!-物理数据库配置->
<dataHost name="test1"maxCon="1"minCon="10"
balance="0"
writeType="0"
dbType="mysql"
dbDriver="native">
<heartbeat>select user);</heartbeat>
<writeHost host="hostM1"url=192.168.0.2:3306"
user="root"password="123456">
</writeHost>
</dataHost>
<dataHost name="test2"maxCon="1"
minCon="10"balance="0"writeType="0"dbType="mysql"
dbDriver="native">
<heartbeat>select userO;</heartbeat>
<writeHost host="hosts1"url="192.168.0.3:3306
user="root"password="123456">
</writeHost>
</dataHost>
</mycat:schema>
rule.xml
<tableRule name="mod-long">
<rule>
<columns>id</columns>
<algorithm>mod-long</algorithm>
</rule>
下
</tableRule>
<function
name="mod-long"
class="io.mycat.route.function.PartitionByMod">
<!-how many data nodes-->
<property name="count">2</property>
</function>




wget https://repo.mysql.com//mysql80-community-release-el7-3.noarch.rpm

yum -y localinstall mysql80-community-release-el7-3.noarch.rpm

yum -y install mysql-community-server


systemctl start mysqld

#设置开机启动
systemctl enable mysqld
systemctl daemon-reload

#命令查看数据库的密码
cat /var/log/mysqld.log | grep password 
d<t=hGeqo3lT

#进入数据库登陆界面，输入刚刚查到的密码，进行数据库的登陆
mysql -uroot -p 

ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'Aa123456!';

#进行远程访问的授权
create user 'root'@'%' identified with mysql_native_password by 'Aa123456!';
grant all privileges on *.* to 'root'@'%' with grant option;
flush privileges;
exit;

systemctl start firewalld
firewall-cmd --zone=public --add-port=3306/tcp --permanent
firewall-cmd --reload


修改/etc/my.cnf配置文件，在[mysqld]下添加编码配置，如下所示：
character_set_server=utf8
init_connect='SET NAMES utf8'


systemctl restart mysqld




mysql -u root -p
Aa123456!

use mysql

create user hiya_public_local@localhost identified by 'Aa123456#';
create user 'hiya_public_out'@'%' identified by 'Aa123456#';


grant all privileges on *.* to hiya_public_local@localhost with grant option;
grant all privileges on *.* to 'hiya_public_out'@'%' with grant option;




flush privileges;

create database hiya_public_db;
show databases;

create database hiya_mall_db;
create database hiya_oa_db;




InnoDB聚集索引就是按照每张表的主键生成一颗B+树，叶子结点存放着整行记录数据。

平衡二叉树保证了树的构造是平衡的，当我们插入或删除数据导致不满足平衡二叉树不平衡时，平衡二叉树会进行调整树上的节点来保持平衡。
平衡二叉树相比于二叉查找树来说，查找效率更稳定，总体的查找速度也更快。

海量存储二叉树的节点将会非常多，高度也会极其高，我们查找数据时也会进行很多次磁盘 IO，我们查找数据的效率将会极低。
B 树（单个节点可以存储多个键值和数据的平衡树）横空出世

B+ 树非叶子节点上是不存储数据的，仅存储键值，而 B 树节点中不仅存储键值，也会存储数据。
如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘的 IO 次数又会再次减少，数据查询的效率也会更快。

如果 B+ 树一个节点可以存储 1000 个键值，那么 3 层 B+ 树可以存储 1000×1000×1000=10 亿个数据。
所以数据库中b+树的高度一般不大于3层，一般我们查找 10 亿数据，只需要 2 次到3次磁盘 IO。




mycat:
分表、读写分离、主从切换、数据库中间件、代理数据库；
能满足关系数据库大量存储，提升查询性能，同时保持了关系数据库的特征。













---------------------------------------------------------------------------------------------------------------
------------------------------------------Mysql.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Nosql-cassandra.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------


1 nosql数据库分类
文档数据库~mongodb
列式数据库~Hbase,Cassandra
内存数据库~Redis


2 Cassandra在国外发展火爆，国内冷清。1500家国外公司。




3 CAP原理
Consistency(一致性)：time”,即更新操作成功并返回客户端后，所有节点在同一时间的数据完全一致，这就是分
布式的一致性。一致性的问题在并发系统中不可避免，对于客户端来说，一致性指的是并发访问时更新过的数据如何获取的问题。从服务端来看，则是更新如何复制分布到整个系统，以保证数据最终一致。

Availability(可用性)：
可用性指“Reads and writes always succeed”,即服务一直可用，而且是正常响应时间。好的可用性主要是指系
统能够很好的为用户服务，不出现用户操作失败或者访问超时等用户体验不好的情况。

Partition Tolerance(分区容错性)：
即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性或可用性的服务。
分区容错性要求能够使应用虽然是一个分布式系统，而看上去却好像是在一个可以运转正常的整体。比如现在的分
布式系统中有某一个或者几个机器宕掉了，其他剩下的机器还能够正常运转满足系统需求，对于用户而言并没有什么体验上的影响。

假设N1和N2之间通信的时候网络突然出现故障，有用户向N1发送数据更新请求，那N1中的数据DB0将被更新为DB1,由于网络是断开的，N2中的数据库仍旧是DB0;
如果这个时候，有用户向≌发送数据读取请求，由于数据还没有进行同步，应用程序没办法立即给用户返回最新的数据DB1,怎么办呢？
有二种选择
第一，牺牲数据一致性，响应旧的数据DBO给用户；
第二，牺牲可用性，阻塞等待，直到网络连接恢复，数据更新操作完成之后，再给用户响应最新的数据DB1。

上面的过程比较简单，但也说明了要满足分区容错性的分布式系统，只能在一致性和可用性两者中，选择其中一个。也就是说分布式系统不可能同时满足三个特性

4相对Hbase等的主从结构，Cassandra是去中心化的P2P结构


5 Cassandra最初版本是通过一致性Hash来实现节点的动态扩展的


6与HBase相比，除了Colum/Colum Family外，Cassandra还支持SuperColum/SuperColum Family.
SuperColum与Colum的区别就是，标准Column的value是一个“字符串”，而SuperColumn的value:是一个包含
多个Column的map,另一个细微的差别是：SuperColumn没有时间戳。
name:"homeAddress",
value:
street:{name:"street",value:"1234 x street",
timestamp:123456789),
city:{name:"city",value:"san francisco",
timestamp:123456789),
zip:{name:"zip",value:"94107",timestamp:
123456789},
}
}
Column Family(CF)是某个特定Key的Colum集合，是一个行结构类型，每个CF物理上被存放在单独的文件中。



7储存机制
CommitLog:主要记录下客户端提交过来的数据以及操作。这个数据将被持久化到磁盘中，以便数据没有被持久化到磁盘时可以用来恢复
Memtable:用户写的数据在内存中的形式，它的对象结构在后面详细介绍。其实还有另外一种形式是
BinaryMemtable这个格式目前Cassandra并没有使用，这里不再介绍了。
SSTable:数据被持久化到磁盘，这又分为Data、Index和Filter三种数据格式。


8和mongodb比较
Cassandra仅有Java和Python的官方客户端，MongoDB拥有非常广泛的客户端支持；
文档型存储和列式存储；


9点对点通讯协议-gossip
通过这个个协议在集群中的节点间交换位置和状态信息


10 Snitch
定义一个网络拓扑图，用来确定如何放置复制数据，高效地路由请求。
DynamicSnitch:监控各节点的执行情况，根据节点执行性能自动调节，大部分情况推荐使用这种配置
Cassandra.从Gossip信息中确认某个节点是否可用，避免客户端请求路由到一个不可用的节点，或者执行比较慢的节点，这个通过dynamic snitch可以判断出来。


11比较
Hbase是Google bigtablel的开源实现，它的出现弥补了
Hadoop高吞吐、安全可靠但是无法做到随机存取的lO能力。
成员通信及错误检测基于Zookeeper和Gossip;都是Java开发；都是Apache协议；强一致和最终一致性，Quorum NRW策略；
master/slave架构和p2p去中心化架构；
NameNode是HDFS的单点故障点，P≌P和去中心化设计，不会出现单点故障；


12一致性哈希
一致性哈希是Cassandra的核心内容之一，意在提供一个可以增加机器线性扩展性能的集群。一致性哈希是这样工作的：
如上图所示，Cassandra会进行计算一个数据中心一个集
群环境中每一个节点的哈希值，并且将该哈希值映射到圆环上，然后从数据映射的位置开始顺时针寻找，将数据保存在找到的第一台服务器上。如果新增加一台服务器只会影响到
相邻节点的哈希值，而不需要进行重新计算，最大限度抑制重新计算分布的时间和性能消耗。



13使用RPC框架thrift:来通信
thrift: facebook开源的RPC框架，C++,Java,Python,PHP,Ruby,Erlang,Perl,Haskell,C#,Cocoa,JavaScript,Node.js,Smalltalk,and OCaml等等编程语言间无缝结合的、高效的服务。
dubbox:是当当团队基于dubbo升级的一个版本。是一个分布式的服务架构，可直接用于生产环境作为$OA服务框架。
Dubbo:源于阿里的淘宝网开源的分布式的服务架构，致力于提供高性能和透明化的RPC远程服务调用方案，是SOA服务化治理方案的核心框架。
     淘宝网将其开源之后，得到了很多的拓展和支持（比较出名的有：当当网的扩展版本dubbox,京东的扩展版本jd-hydra等)
Dubbox(即Dubbo eXtensions)是当当网Fork基于
dubbo2.x的升级版本，兼容原有的dubbox。其中升级了
zookeeper和spring版本，并且支持restfulll风格的远程调用。。
Spring Cloud:Spring全家桶，用起来很舒服，只有你想不到，没有它做不到。可惜因为发布的比较晚，国内还没出现比较成功的案例。
Dubbox:相对于Dubbo支持了REST,估计是很多公司选择Dubbox的一个重要原因之一，但如果使用Dubbol的RPC调用方式，服务间仍然会存在API强依赖，各有利弊，懂的取舍吧。
Thrift:如果你比较高冷，完全可以基于Thrift自己搞一套抽象的自定义框架吧。
Montan:可能因为出来的比较晚，目前除了新浪微博16年初发布的，
Hessian:如果是初创公司或系统数量还没有超过5个，推荐选择这个，毕竟在开发速度、运维成本、上手难度等都是比较轻量、简单的，即使在以后迁移至SOA,也是无缝迁移。
rpcx/gRPC:在服务没有出现严重性能的问题下，或技术栈没有变更的情况下，可能一直不会引入，即使引入也只是小部分模块优化使用。




14 Cassandra源码

入口
org.apache.cassandra.service.EmbeddedCassandra 

Service类
数据写入：先写入Commitlog;其次写入Memtable;最后
写入SSTable
代码位于org.apache.cassandra.thrift包中，写入请求将
调用CassandraServer类的dolnsert方法
private
void
dolnsert(ConsistencyLevel
consistency_level,List<?extends IMutation>mutations,
boolean
mutateAtomically)
throws
UnavailableException,
TimedOutException,
InvalidRequestException
/关键语句调用存储代理方法，如果提交原子性操
作，则调用batch方法
/此处默认mutateAtomically:=false,非原子性提交，
将直接调用mutate方法
StorageProxy.mutateWithTriggers(mutations,
consistencyLevel,mutateAtomically);
}
Keyspace.applyInternal
/写入commitlog和memtables
CommitLogPosition commitLogPosition null;
if (writeCommitLog)
{
/写入commitLog
commitLogPosition
CommitLog.instance.add(mutation);
}
一般Cassandra是当memtable积累到了一定的大小则自
动刷写到SSTable中进行保存，memtable的内存大小设
置在cassandra.yarm配置文件，
默认大小memtable._heap_space.in_mb=2048,假如
memtablel的超过了配置的，就会进入一个队列然后刷新
到磁盘中去。
synchronized (data)
{
/获取当前的memtable
Memtable current
data.getView(.getCurrentMemtable);
//如果memtable没有超出预设的大小范围，并且我
们已经调度刷新了该节点应有的hit数据信息，那么直接跳过
if (current.isExpiredO)
{
if (current.isCleanO)
{
/if we're still clean,instead of swapping
just reschedule a flush for later
scheduleFlushO;
}
else
{
/强制刷新
forceFlushO;
}
}
}


---------------------------------------------------------------------------------------------------------------
------------------------------------------Nosql-cassandra.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Nosql-Mongodb.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------


@C++编写，基于分布式文件存储的开源数据库系统,BSON格式，二进制JSON。文档中容易内嵌对象及数组


@Nosql根据聚合模型
键值对(redis)、文档数据库(mongodb)、列式(hbase,cassadra)、图表
database->collection->document->field


@分片方式
哈希分片
一致性哈希分片：cassadra,hdfs
区间划分分片：mongodb


@保存在底层文件系统中/data/db:
hiya.ns表和索引表空间元数据
hiya.0数据
hiya.1数据
hiya.2预留空间


@TTL特性
mongodb提供了expire机制，即可以指定文档保存的时长，过期后自动，即TTL特性
collection.createlndex(new Document("created",1),new
IndexOptionsO.expireAfter(15L,TimeUnit.MILLISECOND
S);//15分钟
数据文件映射到内存中，如果是读操作，内存中的数据起
到缓存的作用，如果是写操作，内存还可以把随机的写操
作转换成顺序的写操作，总之可以大幅度提升性能。
MongoDB并不干涉内存管理工作，而是把这些工作留给操作系统的虚拟内存管理器去处理，这样做的好处是个了MongoDB的工作。


@HA架构：
ReplicaSet(副本集，容错，自动恢复高可用)
Sharding Cluster(切片)
Master-Slaver【不推荐】
mongoDB目前已不推荐使用主从模式，取而代之的是副本集模式。
副本集指将数据复制，多份保存，不同服务器保存同一份数据，在出现故障时自动切换。对应的是数据冗余、备份、镜像、读写分离、高可用性等关键词；
Secondary来分担读的压力，Primary只承担写操作。选举出新的Master,并引导其余的Slave服务器连接新的Master,而这个过程对于应用是透明的。
而分片则指为处理大量数据，将数据分开存储，不同服务器保存不同的数据，它们的数据总和即为整个数据集。追求的是高性能。




@ Sharding Cluster(分片集群)
1)分片服务器(Shard Server)
mongod实例，用于存储实际的数据块，实际生产环境中一个shard server角色可由几台机器组个一个relica set承
担，防止主机单点故障这是一个独立普通的mongod:进程，保存数据信息。可以是一个副本集也可以是单独的一台服务器。

2)配置服务器(Config Server)
mongod实例，存储了整个Cluster Metadata,其中包括chunk信息。
这是一个独立的mongod进程，保存集群和分片的元数据，即
各分片包含了哪些数据的信息。最先开始建立，启用日志功能。像启动普通的mongod一样启动
配置服务器，指定configsvr选项。不需要太多的空间和资
源配置服务器的1KB空间相当于真是数据的200MB个存的只是数据的分布表。

3)路由服务器(Route Server)
mongos:实例，前端路由，客户端由此接入，且让整个集群看上去像单一数据库，前端应用起到一个路由的功能，供程序连接。本身不保存数据，在启
动时从配置服务器加载集群信息，开启mongos进程需要
知道配置服务器的地址，指定configdb选项。
在生产环境中，通常是这两种技术结合使用，分片+副本集。所以最终的架构是：多个mongos集群，Config Server集群，每个Shard ServerE由一组RS组成构成高可用。


@高级特性-同步延迟
修改过的信息不改变掉的数据还在显示数据库主从不同步。与其他提供数据同步的数据库一
样，MongoDB也会遇到同步延迟的问题，在MongoDB的Replica Sets模式中，同步延迟也经常是困扰
使用者的一个大问题。



数据的扩展分成横向扩展和纵向扩展。
纵向扩展是使用计算能力更强的机器，也是最省力的方法，但是很容易达到物理极限，无论花多少钱也买不到最新的机器了。
横向扩展就是通过分区将数据分散到更多的机器上，MongoDB的设计采用横向扩展。面向文档的数据模型使它很容易地在多台服务器之间进行数据分割。

注意：这里的扩展只得横向扩展，也就是分片，并不是bson字段结构的扩展。
mysql集群 仅仅是读写分析，主从的集群，后面人为开发的mycat实现了关系数据库的横向扩展。


自动重新分配文档，以及将用户请求路由到正确的机器上。开发者根本不用考虑数据库层次的扩展问题，需要扩展数据库时，
在集群中添加机器即可，MongoDB会自动处理后续的事情。MongoDB有如上各种特性，但为了达到这些，他也放弃了关系型
数据库的某些功能如表连接join和复杂的多行事务。


基于内存，将热数据存放在物理内存中（不仅仅只是索引和少部分数据），从而提高了整体速度和效率。
MongoDB非常吃内存，os有多少内存吃多少，把绝大多数热数据加载到内存汇总提升性能。


为数众多的Web应用程序，知名的如Flicker和LiveJournal，都实现了手动分片，将负载分布到多台MySQL数据库上。
在这些实现中，分片逻辑都寄生于应用程序上。
将数据库分布到多台服务器上，这种方法称为分片，MongoDB横空出世


分片方式：
哈希分片
一致性哈希分片：hdfs, cassadra 
区间划分分片：mongodb

TTL: 提供了 expire机制，可以保存文档的时长，到期后自动删除。

分片特征选择的一个问题---片键

概念对比：
文档(Document) ---- mysql的行
集合(Collection)   ---- mysql的表
数据库(Database) --- mysql数据库


在MongoDB内部，每个数据库都包含一个.ns文件和一些数据文件。
命名空间的元数据集中在*ns文件中，f00.ns, f00.0, f00.1, f00.2, 


Sharding Cluster(分片集群)
mongos: 数据路由，将所有读写请求指引到合适的额分片上
config server:所有存取数据的方式，所有shard节点信息，分片功能一些配置信息，可以理解为正式数据的元数据。
shard: 真正的数据存储位置，以chunk为单位存储。


mongodb目前已经不推荐使用主从模式，取而代之的是副本集群模式，ReplicaSet( 副本集、容错、自动恢复高可用)
再生产环境中，通常是这两种技术的结合，分片+副本集

所以最终的结果是：mongos集群， config server集群，每个shard server由一组RS构成高可用。



搭建集群记录（https://www.cnblogs.com/ityouknow/p/7344005.html）：

10.72.5.196：
mongos+	config server+shard server1 主节点+shard server1 副节点+shard server1 仲裁

10.72.5.197：
mongos+	config server+shard server2 主节点+shard server2 副节点+shard server2 仲裁

10.72.5.198：
mongos+	config server+shard server3 主节点+shard server3 副节点+shard server3仲裁


端口分配：
mongos：20000
config：21000
shard1：27001
shard2：27002
shard3：27003


tar -xvf mongodb-linux-x86_64-3.4.6.tgz -C /usr/local/


vim /etc/profile
export MONGODB_HOME=/usr/local/mongodb
export PATH=$MONGODB_HOME/bin:$PATH
source /etc/profile


三台机器
mongod -f /usr/local/mongodb/conf/config.conf
#副本集名称
replSet=configs


配置分片副本集(三台机器)
vi /usr/local/mongodb/conf/shard1.conf
config = {
...    _id : "shard1",
...     members : [
...         {_id : 0, host : "192.168.0.75:27001" },
...         {_id : 1, host : "192.168.0.84:27001" },
...         {_id : 2, host : "192.168.0.86:27001” , arbiterOnly: true }
...     ]
... }
#初始化副本集配置
rs.initiate(config);


配置路由服务器 mongos
vi /usr/local/mongodb/conf/mongos.conf
#监听的配置服务器,只能有1个或者3个 configs为配置服务器的副本集名字
configdb = configs/192.168.0.75:21000,192.168.0.84:21000,192.168.0.86:21000



mongodb的启动顺序是，先启动配置服务器，在启动分片，最后启动mongos.

mongod -f /usr/local/mongodb/conf/config.conf
mongod -f /usr/local/mongodb/conf/shard1.conf
mongod -f /usr/local/mongodb/conf/shard2.conf
mongod -f /usr/local/mongodb/conf/shard3.conf
mongod -f /usr/local/mongodb/conf/mongos.conf



设置testdb的 table1 表需要分片，根据 id 自动分片到 shard1 ，shard2，shard3 上面去。
要这样设置是因为不是所有mongodb 的数据库和表 都需要分片！
#指定testdb分片生效
db.runCommand( { enablesharding :"testdb"});
#指定数据库里需要分片的集合和片键
db.runCommand( { shardcollection : "testdb.table1",key : {id: 1} } )

for (var i = 1; i <= 100000; i++)
db.table1.save({id:i,"test1":"testval1"});
db.table1.stats();

可以看到数据分到3个分片，各自分片数量为： shard1 “count” : 42183，shard2 “count” : 38937，shard3 “count” : 18880。





关闭时，直接killall杀掉所有进程

killall mongod
killall mongos


















---------------------------------------------------------------------------------------------------------------
------------------------------------------Nosql-Mongodb.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Oracle.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------



1 mysql免费开源，sqlserverl收费，oracle有个人学习版免费，商业版收费。

2 oracle是1979年发布的世界上第一个关系数据库。

3 rownum和rowid
都叫伪列，rownum是逻辑上的编号，且其值总是从1开始，每行的rounum不是固定的。而rowid是“物理”编号。若数据库文件没有移动，则每行的rowid-一般是固定不变的。
rownum是伪列，是在获取查询结果集后再加上去的（获取一条记录加一个rownum)。对符合条件的结果添加一个从1开始的序列号。
rowid:表示每条数据实际的物理地址，类似hashcode值。

4 in和exists
如果子查询得出的结果集记录较少，主查询中的表较大且
又有索引时应该用in,反之如果外层的主查询记录较少，子查询中的表大，又有索引时使用exists。
如果查询语句使用了not in那么内外表都进行全表扫描，
没有用到索引；而not extsts的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。

5 唯一索引不包含ROWID,普通索引|包含rowid.
聚集索引：
主键会默认创建一个唯一聚集索引，创建了聚集索引
CREATE CLUSTERED INDEX Operlog_id ON
dbo.operlog(id)
每个表中只能有一个聚集索引；页节点存放的是真正数据；
新数据按着他在聚集索引里正确的物理顺序插入，可能是主键，也可能不是主键。
主键也可能是非聚集索引引。
聚集索引primary key唯一索引unique普通索引alter
table t1 all index index_name(id)

非聚集索引：
数据叶节点就是真正数据.叶节点存储的不是真正的数据，而是指向数据的指针；
总结索引使用原则：
1):不要索引数据量不大的表，对于小表来讲，表扫描的成本并不高。
2):不要设置过多的索引，在没有聚集索引引的表中，最大可以设置249个非聚集索引引，过多的索引首先会带来更大的磁盘空间，而且在数据发生修改时，对索引的维护是特别消耗性能的。
3):合理应用复合索引，有某些情况下可以考虑创建包含所有输出列的覆盖索引引。
4):对经常使用范围查询的字段，可能考虑聚集索引。
5):避免对不常用的列，逻辑性列，大字段列创建索引引；like“a%”不会使用索引而like“aaa%”可以使用索引。


6分析函数ROW_NUMBER(OVER()
row_numberO OVER (PARTITION BY COL1 ORDER BYCOL2表示根据COL1分组，在分组内部根据COL2排序，
而此函数计算的值就表示每组内部排序后的顺序编号（组内连续的唯一的)
SELECT *Row_Number)OVER (partition by deptid
ORDER BY salary desc)rank FROM employee
SELECT DISTINCT *MIN(salary)OVER (partition by
deptid ORDER BY salary desc)rank FROM employee


7联机事务处理和联机分析处理
OLTP传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易。强调数据库内存效率，
强调内存各种指标的命令率，强调绑定变量，强调并发操作；
OLAP系统则强调数据分析，强调SQL执行市场，强调磁盘/，强调分区等。数据仓库系统的主要应用，支持复
杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果


8 mysql缓存机制
缓存sql文本及缓存结果，用KV形式保存再服务器内存中，如果运行相同的sqL,服务器直接从缓存中去获取结果，不需要在再去解析、优化、执行sql。如果这个表修改了，
那么使用这个表中的所有缓存将不再有效，查询缓存值得相关条目将被清空。表中得任何改变是值表中任何数据或者是结构的改变，
包括insert,update,delete,truncate,alter table,drop table或者是drop database包括那些映射到改变了的表的使
用merge:表的查询，显然，者对于频繁更新的表，查询缓存不合适，对于一些不变的数据且有大量相同sq查询的表，查询缓存会节省很大的性能。
随着在用户访问量的增加，缓存的有效期越来越短，因此mysql在较新的版本中已经不再提供缓存机制（哈哈)。所以数据缓存的重担落在了mybatis一级缓存和二级缓存了。


9 mysql7存储格式
db.frm:表结构文件
db.MYD:my data:表数据文件
db.MYl:my index3表索引文件，没有索引时为空
10 oracle逻辑存储结构和物理存储结构
Oracle数据库磁盘存储的逻辑结构为：一个数据库(Database)对应多个表空
(Tablespace),一个表空间对应多个段(Segment一个段对应多个区(Extent),一个区对应多个数据块



10 oracle逻辑存储结构和物理存储结构
Oracle数据库磁盘存储的逻辑结构为：
一个数据库(Database)对应多个表空间(Tablespace),
一个表空间对应多个段(Segment),
一个段对应多个区(Extent),
一个区对应多个数据块DataBlock )
真正的数据就保存在数据块中。Oraclel中一个数据块的大小默认是2KB(支持2KB,4KB,8KB,16KB,32KB),
而DB2中则默认是4KB(支持4KB,8KB,16KB,32KB);
Oracle中的数据块称为Oracle Block,而DB2中则直接称为Data Page(数据页)
Oracle一共有四种类型的段，分别是Data Segment(数据段)，Index Segment(索引段)，RollbackSegment(回滚段)和Temp Segment(I临时段)
从物理讲，Oracle数据库内的每个表空间由一个或多数据文件组成，并且一个数据文件只能属于一个表空间。
表空间大是所有数据文件大小的总和。这些数据文件与Oracle运行所在的操作系统的文件有
一样的物理结构。数据库的所有数据都存储在数据文件中，数据库的每个表空间都由这些数据文件组成。例如，最简单的Oracle数据库只有一个表空间和一个数据文件



11 oracle高并发
Oracle数据库对高并发有着非常好的支持。高并发的系统
必然产生大量读写操作(DML),进而产生大量事务，也就会消耗大量的锁资源，特别是行锁。
Oracle:行锁物理上是在数据块上面实现的，因此ORACLE
锁资源几乎是无限的，而其他数据库是通过内存实现的锁
机制（比如db2),如果内存不足行锁就会升级为表锁，造成锁升级。
而且，oraclel的读写操作不互相阻塞，对高并发操作也有
很大好处。


12数据库数据量
mysql:千万级
DB2:几千万级
oracle:几千万级




---------------------------------------------------------------------------------------------------------------
------------------------------------------Oracle.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------RabbitMq&RocketMq.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------



1 RabbitMQ是一个实现了AMQP(Advanced MessageQueuing Protocol)高级消息队列协议的消息队列服务，
用Erlangi语言的Erlang是为电话交换机开发的语言，天生自带高并发光环，和高可用特性。和springboot集成；


2 RabbitMg连接原理：
应用程序和Rabbit Server之间会创建一个TCP连接，一旦TCP打开，并通过了认证，认证就是你试图连接Rabbit之前发送的Rabbit服务器连接信息和用户名和密码
,有点像程序连接数据库，使用Java有两种连接认证的方式，一旦认证通过你的应用程序和Rabbit就创建了一条AMQP信道(Channel)。
信道是创建在“真实”TCP上的虚拟连接，AMQP命令都是通过信道发送出去的，每个信道都会有一个唯一的D,
不论是发布消息，订阅队列或者介绍消息都是通过信道完成的。



3为什么不通过TCP直接发送命令？
对于操作系统来说创建和销毁TCP会话是非常昂贵的开销，假设高峰期每秒有成干上万条连接，每个连接都要创建一条TCP会话，这就造成了TCP连接的巨大浪费，
而且操作系统每秒能创建的TCP也是有限的，因此很快就会遇到系统瓶颈。如果我们每个请求都使用一条TCP连接，既满足了性能的需要，又能确保每个连接的私密性，这就是引入信道概念的原因。


4核心概念
ConnectionFactory(连接管理器)：应用程序与Rabbit之间建立连接的管理器，程序代码中使用；
Channel(信道)：消息推送使用的通道；
Exchange(交换器)：用于接受、分配消息；
Queue(队列)：用于存储生产者的消息；
RoutingKey(路由键)：用于把生成者的数据分配到交换器上；
BindingKey(绑定键)：用于把交换器的消息绑定到队列上；


5消息持久化
Rabbit队列和交换器默认情况下重启服务器会导致消息丢失，那么怎么保证Rabbit在重启的时候不丢失呢？答案就是消息持久化。
当你把消息发送到Rabbit服务器的时候，你需要选择你是否要进行持久化，但这并不能保证Rabbiti能从崩溃中恢复，想要Rabbit消息能恢复必须满足3个条件：
投递消息的时候durable设置为true,消息持久化，
代码：channel.queueDeclare(x,true,false,false,null,参
数2设置为true持久化；
设置投递模式deliveryMode设置为2（持久），
代码
channel.basicPublish(x,X,MessageProperties.PERSISTENT_TEXT_PLAIN,x),参数3设置为存储纯文本到磁盘；
Rabbit:会将你的持久化消息写入磁盘上的持久化日志文件，等消息被消费之后，Rabbit会把这条消息标识为等待垃圾回收。


6持久化的缺点
消息持久化的优点显而易见，但缺点也很明显，那就是性能，因为要写入硬盘要比写入内存性能较低很多，从而降低了服务器的吞吐量，尽管使用SSD硬盘
可以使事情得到缓解，但他仍然吸干了Rabbit的性能，当消息成干上万条要写入磁盘的时候，性能是很低的。



7发送端代码
Connection conn = connectionFactoryUtil.GetRabbitConnection;
Channel channel conn.createChannel);
/声明队列【参数说明：参数一：队列名称，参数二：是
否持久化；参数三：是否独占模式；参数四：消费者断开
连接时是否队列；参数五：消息其他参数】
channel.queueDeclare(config.QueueName,false,false,false,null);
String message=String.format(("当前时间：%s,newDateO.getTimeO);
/推送内容【参数说明：参数一：交换机名称；参数二：
队列名称，参数三：消息的其他属性-路由的headers信
息；参数四：消息主体】
channel.basicPublish("",config.QueueName,null,message.getBytes("UTF-8"));



8持续接收
Connection
conn
connectionFactoryUtil.GetRabbitConnectionO;
Channelchannel conn.createChannel);
/声明队列【参数说明：参数一：队列名称，参数二：是
否持久化；参数三：是否独占模式；参数四：消费者断开
连接时是否队列；参数五：消息其他参数】
channel.queueDeclare(config.QueueName,false,false,
false,null);
Consumer
defaultConsumer
new
DefaultConsumer(channel){
@Override
public void handleDelivery(String consumerTag,
Envelope envelope,AMQP.BasicProperties properties,
bytell body)throws lOException
String message=new String(body,"utf-8);//消息
正文
System.out.printIn(“收到消息=>"+message);
channel.basicAck(envelope.getDeliveryTag0,false);
/手动确认消息【参数说明：参数一：该消息的index;
参数二：是否批量应答，true批量确认小于当前id的消
息】
}
;
channel.basicConsume(config.QueueName,false,""
defaultConsumer);



9 RocketMq:是阿里巴巴开源的框架，捐赠给Apache:基金会。
底层代码编写清晰优秀，采用Netty NIOl框架实现数据通信，并结合阿里巴巴的实际业务需求，在天猫双十一的场景，实现业务消峰，分布式事务的优秀框架。
3.X版本弃用Zookeeper,内部使用更轻量级的NameServer进行网络路由，提供了服务性能，并支持消息失败重试机制。
支持集群模式、消费者负载均衡、水平扩展能力，支持广播模式。提供丰富的消息机制，比如顺序消息、事务消息。纯ava开发。


10 RocketMq消息重复消费和顺序消费
如果发送M1耗时大于发送M2的耗时，那么M2就先被消费，仍然不能保证消息的顺序。即使M1和M2同时到达消费端，由于不清楚消费端1和消费端2的负载情况。
RocketMQ只保证消息的顺序发送，通过一定算法，将一组顺序消息发送到同一个broker下面的同一个队列，消费者进行顺序监听即可。
只要是同一个broker下面的同一个队列，消费端肯定是顺序消费的。
造成消息的重复的根本原因是：网络不可达。只要通过网络交换数据，就无法避免这个问题。
RocketMQ不保证消息不重复，如果你的业务需要保证严格的不重复消息，需要你自己在业务端去重。重复消费：
(1)由客户端判断，只要保持幂等性，不管来多少条重复消息，最后处理的结果都一样；
(2)利用一张日志表来记录已经处理成功的消息的，如果新到的消息ID已经在日志表中，那么就不再处理这条消息。


11 RocketMQ除了支持普通消息，顺序消息，另外还支持事务消息。
RocketMQ第一阶段发送Prepared消息时，会拿到消息的地址，第二阶段执行本地事物，第三阶段通过第一阶段拿到的地址去访问消息，并修改状态。
细心的你可能又发现问题了，如果确认消息发送失败了怎么办？RocketMQ会定期扫描消息集群中的事物消息，这
时候发现了Prepared消息，它会向消息发送者确认，Bob的钱到底是减了还是没减呢？如果
减了是回滚还是继续发送确认消息呢？RocketMQ会根据发送端设置的策略来决定是回滚还
是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。
/未决事务，MQ服务器回查客户端
/也就是上文所说的，当RocketMQ发现Prepared消息时，会根据这个Listener实现的策略来决断事务
TransactionCheckListener transactionCheckListener
new TransactionCheckListenerlmplO;
/构造事务消息的生产者
TransactionMQProducer producer
new
TransactionMQProducer("groupName");
/设置事务决断处理类
producer.setTransactionCheckListener(transactionChec
kListener);
/本地事务的处理逻辑，相当于示例中检查Bob账户并扣
钱的逻辑
TransactionExecuterlmpl tranExecuter
new
TransactionExecuterlmplO;
producer.start(
/构造MSG,省略构造参数
Message msg new Message(......);
/发送消息
SendResult
sendResult
=
producer.sendMessageln Transaction(msg,
tranExecuter,null);
producer.shutdown);
但是如果消费失败怎么办？阿里提供给我们的解决方法
是：人工解决。



12核心概念
Producer:消息生成者，负责消息产生，由业务系统负责产生。
Consumer:消息消费者，负责消费消费，由后台业务系统负责异步消费。
Push Consumer:Consumer的一种，应用通常向Consumer对象注册一个Listener:接口，一旦接收到消息，Consumeri对象立刻回调Listener接口方法。
Pull Consumer:Consumer的一种，应用通常主动调用Consumerl的拉消息方法从Broker:拉消息，主动权由应用控制。
Producer Group:一类producer的集合名称，这类Produceri通常发送一类消息，且发送逻辑。
Consumer Group:一类Consumer的集合名称，这类Consumeri通常消费一类消息，且发送逻辑。
Broker:消息中转角色，负责存储消息，消息，一般也称为Server.。
集群消费：一个Consumer Group中的Consumer3实例平均分摊消费消息。例如某个Topic有9条消息，其中一个Consumer Group有3个实例（可能是3个进程或3台机器)，那么每隔实例只消费其中的3条消费。
广播消费：一条消息被多个Consumer消息，即使这些Consumer属于同一个Consumer Group,消息也会被Consumer Group中的每隔Consumer都消费一次。
顺序消费：指消息的消费顺序和产生顺序相同，在有些业务逻辑下，必须保证顺序。比如订单的生成、付款、发货，这3个消息必须按顺序处理才行。


13为何rocketMq可以弃用zk?
在Kafka里面，Maser/Slave是选举出来的！！！RocketMQ不需要选举！！！
在Kafka里面，Master,/Slave的选举，有2步：第1步，先
通过ZK在所有机器中，选举出一个KafkaController;第2步，再由这个Controller,决定每个partition的Master:是谁，Slave是谁。
这里的Master,/Slave是动态的，也就是说：当Master挂了之后，会有1个Slave切换成Master.。
而在RocketMQ中，不需要选举，Master/Slave的角色也是固定的。当一个Master挂了之后，你可以写到其他
Master.上，但不会说一个Slave切换成Master.。
这种简化，使得RocketMQ可以不依赖ZK就很好的管
理Topic,/queue和物理机器的映射关系了，也实现了高可用。
这里，也涉及到了我在上1篇里，所说的“消息顺序”的
问题：在Kafka里面，一个partitiong必须与1个Master有严
格映射关系，这个Master挂了，就要从其他Slave里面选
举出一个Master;而在RocketMQ里面，这个限制放开了，一个queue对应的Master挂了，它会切到其他Master,而不是非要选举出来一个。
说到这，答案基本就知道了：RocketMQ不需要像Kafka
那样有很重的选举逻辑，它把这个问题简化了。剩下的就
是topic/queue的路由信息，那用个简单的NameServeri就搞定了，很轻量，还无状态，可靠性也能得到很好保证。



14与kafka吞吐量对比
(1)kafka在消息存储过程中会根据topic和partition的数量创建物理文件，也就是说我们创建一个topic并指定了3
个partition,那么就会有3个物理文件目录，也就说说
partition的数量和对应的物理文件是一一对应的。
(2)rocketMq在消息存储方式就一个物流问题，也就说
传说中的commitLog,rocketMq的queue的数量其实是在consumeQueue里面体现的，在真正存储消息的
commitLog其实就只有一个物理文件。
(3)kafka的多文件并发写入VS rocketMq的单文件写入，性能差异kafka完胜可想而知。
(4)kafka的大量文件存储会导致一个问题，也就说
在partition!特别多的时候，磁盘的访问会发生很大的瓶颈，毕竟单个文件看着是append操作，但是多个文件之间必然会导致磁盘的寻道。

Kafka的吞吐量高达17.3w/s,不愧是高吞吐量消息中间件的行业老大。这主要取决于它的队列模式保证了写磁盘
的过程是线性lO。此时broker磁盘lO已达瓶颈。

RocketMQ也表现不俗，吞吐量在11.6w/s,磁盘l0%utl已接近100%。RocketMQ的消息写入内存后即返回ack,
由单独的线程专门做刷盘的操作，所有的消息均是顺序写文件。

RabbitMQ的吞吐量5.95w/s,CPU资源消耗较高。它支持AMQP协议，实现非常重量级，为了保证消息的可靠性
在吞吐量上做了取舍。我们还做了RabbitMQ在消息持久化场景下的性能测试，吞吐量在2.6W/s左右。



15心跳机制
单个Brokeri跟所有Namesrv保持心跳请求，心跳间隔为30秒，心跳请求中包括当前Broker所有的Topic信息。Namesrv:会反查Broer的心跳信息，如果某个Broker
在2分钟之内都没有心跳，则认为该Broker下线，调整Topic.跟Brokerl的对应关系。但此时Namesrv不会主动通知Producer、Consumer有Broker宕机。
Consumer跟Broker:是长连接，会每隔30秒发心跳信息到Broker。Broker端每10秒检查一次当前存活的
Consumer,若发现某个Consumer2分钟内没有心跳，就断开与该Consumer的连接，并且向该消费组的其他实例发送通知，触发该消费者集群的负载均衡(rebalance)。
生产者每30秒从Namesrv获取Topic跟Brokerl的映射关系，更新到本地内存中。再跟Topic涉及的所有Broker建立长连接，每隔30秒发一次心跳。
在Broker:端也会每10秒扫描一次当前注册的Producer,如果发现某个Producer超过2分钟都没有发心跳，则断开连接。



16结构部署图
1)启动Namesrv,Namesrv起来后监听端口，等待Broker、Produer、Consumeri连上来，相当于一个路由控制中心。
2)Broker)启动，跟所有的Namesrv保持长连接，定时发送心跳包。心跳包中包含当前Broker信息(P+端口等)以及
存储所有topic信息。注册成功后，namesrv集群中就有Topicl跟Broker的映射关系。
3)收发消息前，先创建topic,创建topic时需要指定该topic要存储在哪些Broker.上。也可以在发送消息时自动创建Topic。
4)Producer发送消息，启动时先跟Namesrv:集群中的其中一台建立长连接，并从Namesrv中获取当前发送的Topic存在哪些Broker.上，然后跟对应的Broker建立长连接，直接向Broker发消息。
5)Consumer跟Producer类似。跟其中一台Namesrv建立长连接，获取当前订阅Topic存在哪些Broker.上，然后直接跟Broker3建立连接通道，开始消费消息



17负载均衡与动态伸缩
负载均衡：
1)RocketMQ的Broker.上存Topic信息，Topic由多个队列组成，队列会平均分散在多个Broker.上，而Producer的发送机制保证消息尽量平均分布到所有队列中，最终效果就是所有消息都平均落在每个Broker_上。
2)kafka采用zookeeperi对集群中的broker、consumeri进行管理，可以注册topic到zookeeper.上；
通过zookeeper的协调机制，producer保存对应topicl的broker1信息，可以随机或者轮询发送到broker.上；
并且produceri可以基于语义指定分片，消息发送到broker的某分片上。
3)rabbitMQ的负载均衡需要单独的loadbalancer:进行支持。动态伸缩能力（非顺序消息、）：Broker的伸缩性体现在两个维度：Topic,Broker.。
Topic维度：假如一个TopicE的消息量特别大，但集群水位压力还是很低，就可以扩大该Topic的队列数，Topic的队列数跟发送、消费速度成正比。
Broker维度：如果集群水位很高了，需要扩容，直接加机器部署Broker就可以。Broker起来后向Namesrv注册，Producer、Consumer:通过Namesrv发现新Broker,立即跟该Brokeri直连，收发消息



18 RocketMQ源码解析
鉴于RocketMQ通信模块的底层源码是Netty实现的
rocketmq-broker:mq的核心，它能接收producer和consumer的请求，并调用store层服务对消息进行处理。HA服务的基本单元，支持同步双写，异步双写等模式。
rocketmq-client:mq客户端实现，目前官方仅仅开源了java版本的mq客户端，c++,go客户端有社区开源贡献。
rocketmq-common:一些模块间通用的功能类，比如一些配置文件、常量。
rocketmq-example:官方提供的例子，对典型的功能比如order message,push consumer,pull consumer的用法进行了示范。
rocketmg-filter:消息过滤服务，相当于在broker和consumer中间加入了一个filter代理。
rocketmq-namesrv:命名服务，更新和路由发现broke服务。
rocketmq-remoting:基于netty的底层通信实现，所有服务间的交互都基于此模块。
rocketmg-srvutil:解析命令行的工具类ServerUtil.。
rocketmq-store:存储层实现，同时包括了索引服务，高可用HA服务实现。
rocketmq-tools:mg集群管理工具，提供了消息查询等功能。

RocketMQ主要的功能集中在rocketmq-broker、rocketmq-remoting、rocketmq-store三个模块
中，所以我们接下来主要分析这三个模块的源码。
Nettyl的Reactor多线程模型设计概念与简述
这里有必要先来简要介绍下Netty的Reactor多线程模型。Reactor多线程模型的设计思想是分而治之+事件驱动。

一般来说，一个网络请求连接的完整处理过程可以分为接
受(accept)、数据读取(read)、解码/编码
(decode/encode)、业务处理(process)、发送响应
(send)这几步骤。Reactor模型将每个步骤都映射成为
一个任务，服务端线程执行的最小逻辑单元不再是一次完
整的网络请求，而是这个任务，且采用以非阻塞方式执
行。

事件驱动
每个任务对应特定网络事件。当任务准备就绪
时，Reactorl收到对应的网络事件通知，并将任务分发给
绑定了对应网络事件的Handler执行

1+N+M1+M2
1 NettyBoss_%d Reactor主线程，负责监听TCP网络连接请求
N NettyServerEPOLLSelector_%d_%d Reactor线程池，负责将建立好连接的socket注册到selector.上去，根据OS的类型选择NIO和Epoll
M1 NettyServerCodecThread._%d Worker线程池，专门用于处理Nettyl网络通信相关的（包括编码/解码、空闲链接管理、网络连接管理以及网络请求处理)
M2 RemotingExecutorThread_%d业务processor处理线程池，处理真正的逻辑。



---------------------------------------------------------------------------------------------------------------
------------------------------------------RabbitMq&RocketMq.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Redis.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------


@C语言开发，开源免费，BSD协议

@提下协议
BSD:你用开源代码(A)修改或做其他增添之后，产生了产品B,这时候，你对B的控制由你自己决定，你可以用任何协议再开源也可以闭源商业发布.但你在B产品的版权声明中，必须有提到你有使用到A,并
且附带上A的开源协议.而且不能做商业推广的时候将B冠以原开源作者的名义以促进商业推广.
而很多的公司企业在选用开源产品的时候都首选BSD协议，因为可以完全控制这些第三方的代码，在必要的时候可以修改或者二次开发.

MT:可以闭源，必须带上A的开源协议，可以以原开源作者的名义以促进商业推广

Apache:可以闭源，每次修改要有版权说明，必须带上A的开源协议

GPL:不可以闭源销售，新增代码要有同样的许可证

LGPL:不可以闭源销售，新增代码不用同样的许可证，不用说明文档

Mozilla:不可以闭源销售，新增代码不用同样的许可证，要说明文档


@单进程单线程模型
每秒10W+查询，不比采用单进程多线程的同样基于内存的KV数据库Memcached差；多路非阻塞IO模型
完全基于内存，类似于HashMap,查找和操作的时间复杂度都是0(1)，单线程避免了上下文切换和竞争条件，
线程切换消耗CPU,没有加锁死锁导致的性能消耗个一个正式的Redis Serveri运行的时候肯定是不止一个线程的，例如Redis进行持久化的时候会以子进程或者子线程的方式执行


@事物深入理解
MULTI开启事务，EXEC/DISCARD命令来提交/回滚该事务内的所有操作
NATCH命令保证多个客户端多线程的执行准确性


@哨兵模式Sentinel
当master出现故障时，完全无需人工干预即可实现故障转移。避免了对业务的影响，提高了运维工作效率。在部署sentinel的时候，建议使用奇数个sentinel节点，最少三个sentinel节点
一些设计思路和zookeeper:非常类似，哨兵本身也是集群。
EXPIRE和TTL命令搭配使用，不配置=O时间无穷大


@淘汰策略
超过最大内存，redisj崩溃，就会实行数据淘汰策略最少使用，将要过期，随机


@备份和恢复
redis可以定期保存到磁盘（持久化），memcache挂掉后，数据不可恢复；redis数据丢失后可以通过aof恢复
1）RDB持久化（原理是指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是fork一个子进程，先将数据集写入临时文件)快，但是数据丢失。
2）AOF持久化（原理是以日志的形式记录服务器所处理的每一个写、操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录)慢，但是最大限度保证准确性。



@主从同步和读写分离
数据可以从主服务器向任意数量的从服务器上同步，同步使用的是发布/订阅机制。



@Lua的分布式锁·
1:lua文件
local key=KEYS[1];
local args=ARGV
local i=0;
local result=;
for m,n in ipairs(args)do
local ishit=redis.call("sismember",key,n);
if(ishit)then
table.insert(result,1,n);
end
end
return result;
2:Redis分布式锁的正确实现方式（原子性）
public static boolean tryGetDistributedLock(Jedis jedis,
String lockKey,String requestld,int expireTime){
String result jedis.set(lockKey,requestld,
SET_IF_NOT_EXIST,
SET_WITH_EXPIRE_TIME,
expireTime);
if (LOCK_SUCCESS.equals(result)){
return true;
}
return false;
}
错误加锁：
public static void wrongGetLock1(Jedis jedis,String
lockKey,String requestld,int expireTime){
Long result jedis.setnx(lockKey,requestld);
if (result =1){
/若在这里程序突然崩溃，则无法设置过期时间，将发生
死锁
jedis.expire(lockKey,expireTime);
}
}
正确解锁（原子性）：
public static boolean releaseDistributedLock(Jedis jedis,
String lockKey,String requestld){
String script="if redis.call('get',KEYS[l])=三ARGV[1]
then return redis.call('del',KEYS[1)else return 0 end";
Object
result
jedis.eval(script,
Collections.singletonList(lockKey),
Collections.singletonList(requestld);
if (RELEASE_SUCCESS.equals(result)){
return true;
}
return false;
}
错误解锁1：
最常见的解锁代码就是直接使用jedis.delQ方法锁，这种不先判断锁的拥有者而直接解锁的方式，会导致任何客户端都可以随时进行解锁，即使这把锁不是它的。
public static void wrongReleaseLock1(Jedis jedis,String
lockKey){
jedis.del(lockKey);
错误解锁2
public static void wrongReleaseLock2(Jedis jedis,String
lockKey,String requestld){
if (requestld.equals(jedis.get(lockKey)){
jedis.del(lockKey);
}
}
如代码注释，问题在于如果调用jedis.delO方法的时候，这把锁已经不属于当前客户端的时候会解除他人加的锁。
那么是否真的有这种场景？
答案是肯定的，比如客户端A加锁，一段时间之后客户端
A解锁，在执行jedis.delQ之前，锁突然过期了，此时客户端B尝试加锁成功，然后客户端A再执行del方法，则将客户端B的锁给解除了。



@Redis+lua实现秒杀
在安装了redis服务器之后，就可以执行lua。那么redis为什么需要ua呢？

简单来说为了性能以及事务的原子性。因为redis帮我们提供的事务功能太差。
下面以电商秒杀场景作简要说明。在上面所描述的步骤中校验库存与扣库存，存在先后顺序，但是并没有原子性。
在关系数据库中，可以通过事务来解决这个问题，但是关系数据库性能有瓶颈。当然在请求量可
以控制的情况下，使用关系数据库的乐观锁，也是可以的。
就像现在我在公司所使用的方案为秒杀单接口进行限流+数据库的乐观锁就完全解决这个问题。
但是这个通过限流来解决了请求的峰值。
如果我们将校验库存，扣库存这段逻辑放在redis上执行，也存在原子性问题。redis帮我们也提供了事务功能，但是这个事务功能太差强人意了。所以在本文中，我们希望通过redis+lua的方式解决这个问题.

lua脚本需要完成的业务逻辑
用户是否忆秒订单判断；校验库存；扣库存；设置抢单成功用户标识；返回结果


public boolean orderSecKill(SecKillPara para,Jedis
jedis){
/*0,已抢过单；2.库存不足；1.抢单成功*/
Long customerld para.getCustomerld);
String script
"local ismeber=redis.call('sismember',ARGV[1],KEYS[1])
11
+"if ismeber~=0 then"/-判断该用户是否秒杀过，如
果已秒则不允许再秒
+"return 0"
+"end
/+"redis.call('set,KEYS[1],1)"/-设置抢单标识
/+"redis.call(expire'KEYS[1],2)"/-设置过期时间
/-check库存
+"for goodsNum=2,#KEYS do"
+"local goodsStock=redis.call('get',KEYS[goodsNum])"
+"if goodsStock ARGV[goodsNum]then
+"return 2;"
+"end"
+"end"
/-扣库存
+"for goodsNum=2,#KEYS do
+
redis.call('DECRBY',KEYS[goodsNum],ARGV[goodsNum])
11
+"end
/-所有抢单成功的用户
+"redis.call('sadd',ARGV[1,KEYS1)"
+"return 1;"
List<String>keys new ArrayList<String>0;
List<String>args new ArrayList<String>0;
keys.add(customerld.toString));
args.add("all_order.user");/所有抢单的用户
for (Map.Entry<Long,Integer>
goods
para.getGoodsWithAmount).entrySet(){
keys.add(goods.getKey).toStringO);
args.add(goods.getValue).toStringO);
}
Object o jedis.eval(script,keys,args);
Long result=Long.valueOf(o.toStringO);
if(result==1){
return true;
}
return false;
public static final class SecKillPara{
private final Long customerld;/抢单人
private final Map<Long/*所抢skuld*/,Integer/*所抢sku
个数*/>goodsWithAmount;
public SecKillPara(Long customerld,Map<Long,Integer>
goodsWithAmount){
super);
this.customerld customerld;
this.goodsWithAmount goodsWithAmount;
}
public Long getCustomerldo{
return customerld;
}
public Map<Long,Integer>getGoodsWithAmount{
return goodsWithAmount;
}
}


@Redis分页
我需要用到的数据类型有SortSet和Hash,SortSet用于做分页排序，Hash用于存储具体的键值对数据


@分布式集群
单机模式（无容错无高可用）
主从模式(Master和Slave,读写分离，主从同步，手工选择一个从数据库来升格为主数据库)
哨兵模式（主数据库中断服务后，自动化选择一个从数据库来升格为主数据库)
分布式分片集群(3.0版本分片技术，高并发，去中心化，集群有16384个哈希槽，最少6台机器，slave检查心跳，选主)
云计算分布式缓存（灵活定制，动态扩容）在集群模式推出之前，主从模式的可用性要靠Sentinel保证，集群模式引入了新的故障检测机制，
而在故障转移这块复用了Sentinel的代码逻辑，不需要单独启动一个Sentinel集群，Redis Cluster本身就能自动进行master选举和failover.




C语言编写。

速度快，数据都是缓存在内存中。
Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。
支持简单事务，原子性
TTL特型

Redis为单进程单线程模式
在Jedis客户端对Redis进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题，这些问题均是由于客户端连接混乱造成。对此有2种解决方法：
客户端角度，为保证每个客户端间正常有序与Redis进行通信，对连接进行池化，同时对客户端读写Redis操作采用内部锁synchronized。
服务器角度，利用setnx实现锁。


单机模式--主从模式--哨兵模式--分布式分片集群（3.0版本分片技术、高并发、去中心化、集群有16384个哈希槽，最少6台机器，slave检查心跳，选主）

哨兵模式可以满足一般的生产要求，具备高可用性，但是数据量过大一台服务器存不下的时候，主从模式或者哨兵模式就不能满足了；
这个时候对存储进行分片，将数据存储到多个redis中，cluster模式的出现就是为了解决单机redis有限的问题，将数据按照一定规则分配到不同的机器。

cluster可以说是哨兵和主从模式的结合体，可以实现master重选功能，所以如果配置2个副本3个分片的话就需要6个redis实例。



使用集群，只需要将redis配置文件的 cluster-enable配置打开，每个集群至少需要三个主数据库才能正常运行，新增节点方便。


采用了非阻塞I/O多路复用机制。
redis采用epoll作为I/O多路复用技术的实现，再加上redis自身的事件处理模型将epoll中的连接、读写、关闭都转换为了时间，不在I/O上浪费过多的时间

Zset数据结构类似set数据结构，只是每个元素都有一个分值，所有分值按照顺序排序，一个经过排序的链表。

Jedis是Redis官方推出的一款面向java程序的客户端，提供了很多接口供java语言调用。
Spring-data-redis是spring大家族的一部分，提供了spring应用中访问redis服务，对redis底层进行封装，RedisTemplate提供了各种操作，异常处理等。






-----安装-------
tar -xvf gcc_rpm_.tar.gz

安装gcc插件
rpm -Uvh *.rpm --nodeps --force

验证gcc
gcc -v




tar -zxvf redis-4.0.2.tar.gz
cd redis-4.0.8
make

cd src

make install PREFIX=/usr/local/redis



配置redis为后台启动
vi /usr/local/redis/etc/redis.conf //将daemonize no 改成daemonize yes


./bin/redis-server redis.conf


ps -ef|grep redis


----------解决RedisDesktopManager连接不上redis问题
1.修改bind 
   原来：  bind  127.0.0.1   代表本地回环地址，访问redis服务只能通过本机的客户端连接，而无法通过远程连接
  修改为：将此行注释或者讲ip改成0.0.0.0   这样就能接受所有来自于可用网络接口的连接

2.修改protected mode  保护模式，只允许本地链接
  修改为：protected mode no

之后 kill -9 34508
./bin/redis-server redis.conf


----------redis-cli命令找不到
cd /usr/local/redis
make install




命令：
redis-cli -p 6379 -h 10.72.5.196
expire age 4000
ttl age
keys *
set age 40
get age
getset age 40
setnx age2 22
setnx age2 24

hset wade name wade399
hset wade age 39

lpush names wade james
lpop names

sadd ages 21 22 24
spop ages 

zadd persons 97 wade 98 james 99 tmac
zrank persons wade
zsore persons wade











---------------------------------------------------------------------------------------------------------------
------------------------------------------Redis.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Search Engine.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------



1倒排索引/反向索引/正向索引/分词/分片/全文检索/全文索引
倒排索引就是反向索引引，在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。
“黄色毛衣”这个query,可以将“黄色”和“毛衣”分成两个基本的语言单位。
分片是哈希分片
全文搜索是指计算机搜索程序通过扫描文章中的每一个词，对每一个词建立一个索引，指明该词在文中出现的次数和位置，当用户查询时，搜索程序就根据事先建立的
索引进行查找，并将查找的结果反馈给用户。
倒排索引关键词频率位置
关键词文章好[出现频率]出现位置
tony 1[1]1
live1[2]2,5


2es和solor
Solr利用Zookeeper进行分布式管理，而Elasticsearch自身带有分布式协调管理功能；
Solr支持格式的数据，而Elasticsearch仅支持json文件格式；
Solr官方提供的功能，而Elasticsearch本身更注重于核心功能，高级功能多有第三方插件提供；
Solr在传统的搜索应用中表现好于Elasticsearch,个处理实时搜索应用时效率明显低于Elasticsearch。
Solr旱传体理玄应田的右力解方安但Flasticsearch画


3三者关系
Lucene:是一个索引引与搜索类库，而不是完整的程序。使用Lucene的方式主要有二种：一是自己编写程序，调用类库；二是使用第三方基于Lucene编写的程序，如下面介绍的Solr等。
Solr:Solr对外提供标准的http接口来实现对数据的索引的增加、、修改、查询。在Solr中，用户通过向部署在servlet容器中的Solr Web应用程序发送HTTP请求来启动索引和搜索。Solr接受请求，确定要使用的适当SolrRequestHandler,然后处理请求。通过HTTP以同样的方式返回响应。
默认配置返回Solr的标准XML响应，也可以配置Solr的备用响应格式。
Nutch:是一个由Java实现的，刚刚诞生开放源代码(open-source)的web搜索引擎。



4 Lucene核心架构
Lucene采用了基于倒排表的设计原理，可以非常高效地实现文本查找，在底层采用了分段的存储模式，使它在读写时几乎完全避免了锁的出现，大大提升了读写性能。
(1)全Java实现、开源、高性能、功能完整、易拓展，功能完整体现在对分词的支持、各种查询方式（前缀、模糊、正则等)、打分高亮、列式存储(DocValues)。

(2)整个过程
系统文件/数据库/WEB页面/人工输入->生成文档->做索引引库->解析查询->返回结果
IndexWriter iw=new IndexWriterO;//e创建IndexWriter
Document doc=new Document(new StringField("name",
"Donald Trump'"Field.Store.YES);/构建索引|文档
iw.addDocument(doc);
/做索引库
IndexReader
reader
DirectoryReader.open(FSDirectory.open(new
File(index)));
IndexSearcher searcher new IndexSearcher(reader);/
打开索引
Query query=parser.parse("name:trump";/解析查询
TopDocs results=searcher.search(query.100);/检索并
取回前100个文档号
for(ScoreDoc hit:results.hits)
Document doc=searcher.doc(hit.doc)/真正取文档
}




(3)索引原理
倒排索引，顾名思义，它相反于一篇文章包含了哪些词，它从词出发，记载了这个词在哪些文档中出现过，由两部
分组成一词典和倒排表。
索引结构：排序列表（简单性能差），哈希表（高性能内存大)，B树（类似MYSQL,磁盘索引，跟新方便，检索慢)，FST(共享前缀，默认的，内存消耗小，输入有序，跟新不易)

FST:通过输入有序字符串构建最小有向无环图。内存占用率低，压缩率一般在3倍~20倍之间、模糊查询支持好、查询快；但是输入要求有序、更新不易
FST性能基本跟HaspMap差距不大，但FST有个不可比拟
的优势就是占用内存小，只有HashMap10分之一左右。内存存放前缀索引、磁盘存放后缀词块。

(1.查询速度；2.内存占用；3.内存+磁盘结合)索引文件结构分为词典、倒排表、正向文件、列式存储DocValues。
倒排表就是文档号（自增数字）集合。
正向文件指的就是原始文档，Lucene对原始文档也提供了存储功能，它存储特点就是分块+压缩。
lucene对原始文件的存放是行是存储，并且为了提高空间
利用率，是多文档一起压缩，因此取文档时需要读入和解压额外文档，因此取文档过程非常依赖随机，以及
lucene虽然提供了取特定列，但从存储结构可以看出，并不会减少取文档时间。
倒排索引能够解决从词到文档的快速映射，但当我们需要
对检索结果进行分类、排序、数学计算等聚合操作时需要文档号到值的快速映射，
而原先不管是倒排索引还是行式存储的文档都无法满足要求。


DocValues站出来解决问题-分类、排序、聚合。
文档(Document):一般搜索引擎的处理对象是互联网网页，而文档这个概念要更宽泛些，代表以文本形式存在的存储对象，相比网页来说，涵盖种形式，比如
Word,PDF,html,XML等不同格式的文件都可以称之为文档。
文档集合(Document Collection):由若干文档构成的集合称之为文档集合。比如海量的互联网网页或者说大量的电子邮件都是文档集合的具体例子。
文档编号(Document ID):将文档集合内每个文档赋予一个唯一的内部编号，以此编号来作为这个文档的唯一标识，这样方便内部处理，每个文档的内部编号即称之
为“文档编号”，后文有时会用DOCD来便捷地代表文档编号。
单词编号(Word ID):与文档编号类似，搜索引擎内部以唯一的编号来表征某个单词，单词编号可以作为某个单词的唯一表征。
单词词典(Lexicon):搜索引擎的通常索引单位是单词，单词词典是由文档集合中出现过的所有单词构成的字符串集合，单词词典内每条索引项记载单词本身的一些信息以及指向“倒排列表”的指针。
倒排列表(PostingList):倒排列表记载了出现过某个单词的所有文档的文档列表及单词在该文档中出现的位置信息，每条记录称为一个倒排项(Posting)。根据倒排列表，即可获知哪些文档包含某个单词。
倒排文件(Inverted File):所有单词的倒排列表往往顺序地存储在磁盘的某个文件里，这个文件即被称之为倒排文件，倒排文件是存储倒排索引引的物理文件

正排索引(Map<id,list<item>>):
Doc1的D>Word1:出现次数，出现位置列表；Word2:出现次数，出现位置列表；
Doc2的D>Word1:出现次数，出现位置列表；Word2:出现次数，出现位置列表；

倒排索引(Map<item,list<id>>):
Word1>Doc1:出现次数，出现位置列表；Doc2:出现次数，出现位置列表；
Word2>Doc1:出现次数，出现位置列表；Doc2:出现次数，出现位置列表
analysis:主要负责词法分析及语言处理，也就是我们常说的分词，通过该模块可最终形成存储或者搜索的最小单元Term。
index模块：主要负责索引的创建工作。
store模块：主要负责索引引的读写，主要是对文件的一些操作，其主要目的是抽象出和平台文件系统无关的存储。
queryParser模块：主要负责语法分析，把我们的查询语句生成Lucene底层可以识别的条件。
search模块：主要负责对索引的搜索工作。
similarity模块：主要负责相关性打分和排序的实现。段(Segment):索引中最小的独立存储单元。一个索引引文件由一个或者多个段组成。在Luence中的段有不变性，也就是说段一旦生成，在其上只能有读操作，不有写操作。




5 solor核心架构
在lucene工具包的基础之上进行了封装，以web服务的形式对外提供索引功能；
业务系统需要使用到索引的功能（建索引，查索引）时，只要发出http请求，并将返回数据进行解析即可
Solr是Apache下的一个顶级开源项目，采用Java开发，它是基于Lucene的全文搜索服务器。
Solr提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展，并对索引引、搜索性能进行了优化。
Solr可以独立运行，运行在Jetty、Tomcat等这些Servlet容器中，Solr索引的实现方法很简单，用POST方法向
Solr服务器发送一个描述Field及其内容的XML文档，Solr根据xml文档添加、、更新索引。
Solr搜索只需要发送HTTP GET请求，然后对Solr返回Xml、json等格式的查询结果进行解析，组织页面布局。Solr不提供构建Ul的功能，Solr提供了一个管理界面，通过管理界面可以查询Solr的配置和运行情况。
solr是门户，lucene是底层基础，solr和lucene的关系正如nadoop:和hdfs的关系。



6 Lucene核心源码

写索引：
IndexWriter.class
public long addDocuments(Iterable<?extends Iterable<?
extends IndexableField>>docs)

查索引：
IndexSearcher.class

分析器：
分析器可能会做的事情有：将文本拆分为单词，去除标
点，将字母变为小写，去除停用词，词干还原，词形归
并，敏感词过滤等等。
lucene中默认自带的分析器有4个：WhitespaceAnalyzer,SimpleAnalyzer,StopAnalyzer,S
tandardAnalyzer
分别用来过滤空白字符，过滤空白符并自动变小写，去占停用词，标准化分词。其中，最常月个是StandardAnalyzer。

核心存储：
索引的结果是缓存在内存中的，等到一定时候才会将其刷
新到硬盘上去。


7solr核心源码
solr是怎么调用到lucene?
人口是SolrDispatchFilter->HttpSolrCall->CoreContainer->RequestHandlerBase->QParser->SolrlndexSearcher->IndexSearcher(Lucene组件)

solr在中嵌入了jetty作为web容器，所以solr归根结底是一
个web服务，所以从web.xml入手查看：
<filter-name>SolrRequestFilter</filter-name>
<filter-class>org.apache.solr.servlet.SolrDispatchFilter</filter-
class>init)->加载nodeconfig->加载cores->后台执行在zk上
注册coreloadNodeConfig只是对于solr.xml的加载，必须保证指定的
solr.home下存在solr.xml文件
在zk上注册core多台zookeeper服务器具备系统高可靠性，高可用性，任意一台zookeeper服务器挂掉，系统会选举出一台服务器为leader。任意一台solr服务器挂掉，系统还是可以用的。下

整体过程：
商城系统（依赖solrClient)--http一SolrServer(含lucene)-ZK



8 ES核心源码
当clienti端将search的请求发送到某一个node之后，剩下的事情就是serveri端来处理了；
Lucene采用了基于倒排表的设计原理，可以非常高效地实现文本查找，在底层采用了分段的存储模式，使它在读写时几乎完全避免了锁的出现，大大提升了读写性能。





---------------------------------------------------------------------------------------------------------------
------------------------------------------Search Engine.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Security.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------



1加解密
1)对称加密-base64(不能算是一种加密，只能说是编码转换)
编码：把3个字节变成4个可打印字符，如果原文长度不能被3整除，Base64要在后面添加\0凑齐3n位。为了正确还原，添加了几个0就加上几个等号。
获取ASCII-8bit字节*3-拆成6bit*4-翻译成10进制-取编码
解码：将4个字节转换成3个字节.先读入4个6位（用或运算)，每次左移6位，再右移3次，每次8位，这样就还原了。
应用；简单的数据加密用户一眼不能看穿实际内容。主要的作用不在于安全性，而在于让内容能在各个网关间无错的传输，这才是Base64编码的核心作用。
在计算机中任何数据都是按ascii码存储的，而ascii码的128~255之间的值是不可见字符。而在网络上交换数据时，比如说从A地传到B地，往往要经过多个路由设备，
由于不同的设备对字符的处理方式有一些不同，这样那些
不可见字符就有可能被处理错误，这是不利于传输的。所以就先把数据先做一个Base64编码，统统变成可见字符，这样出错的可能性就大降低了。
迅雷下载的链接，加密的迅雷专用下载地址：thunder://QUFodHRwOi88vd3d3 LmJhaWR1 LmNvbS
9pbWcvc3NsbTFfbG9nby5naWZaWg==
String orig "hello world!";个Stringdesc
Base64.getEncoderO.encodeToString(orig.getBytes(Sta
ndardCharsets.UTF_8));
System.out.println("加密后的字符串为："+desc);
String
unDecodeStr=new
String(Base64.getDecoder).decode(desc),StandardChar
sets.UTF_8);
System.out.println("解密后的字符串为"+unDecodeStr);

2)对称加密-AES/DES
DES-数据加密标准(Data Encryption Standard)
jdk中jce.jar里面javax.crypto.*,56位密钥的对称加密，实际上函数要求一个64位的密钥作为输入，但是第8、16、24、32、40、48、56、64等8位是校验位，
使得每个密钥都有奇数个1，所以参与加密过程的只有56位。
AES-高级加密标准(Advanced Encryption Standard)替代原先的DES,密钥长度则可以是128,192或256比特，调用AES/DES加密算法包最精要的就是下面两句话：

Cipher
Cipher.getlnstance("DES/CBC/PKCS5Padding");
cipher.init(Cipher.ENCRYPT_MODE,key,zerolv);
bytes ciper.doFinal("hello".getBytes));
工作模式-电子密码本模式(ECB)、加密分组链接模式(CBC)、加密反馈模式(CFB)和输出反馈模式(OFB)四种模式填充模式-PKCS5 Padding
初始化向量-Ⅳ值使用安全随机数生成。AES安全性能比DES高！

3)非对称加密-RSA/DSA
公钥加密，私钥解密，jaa工具类生成公钥和私钥。代码也在rt.jar,java.security包里面；
解密者拥有私钥，并且将由私钥计算生成的公钥发布给加密者。加密都使用公钥进行加密，并将密文发送到解密者，解密者用私钥解密将密文解码为明文。
RSA算法过程：
1).随意选择两个大的质数p和q,p不等于q,计算N=pqo
2).根据欧拉函数，不大于N且与N互质的整数個数為(P-1)(q-1)。
3).选择一个整数e与(p-1)(q-1)互质，并且e小于(p-1)(q-1)。
4).用以下这个公式计算d:d×e≡1(mod(p-1)(q-1)。
5).将p和q的记录销毁。哈希加密算法不可逆加密-MD5/SHA2-256


MD5一般是密码加密认证，和数据库的密码匹配，不可破解。
加密后的密文存储到数据库中，当用户登录时，我们先对密码的明文利用MD5算法进行加密得到密文，然后同数据库中的密文进行匹配。SHA-224、SHA-256、SHA-384,和SHA-512并称为SHA-
2,安全性高，但是性能慢。

5)数字签名和数字证书
a):两人通信，传输数据之间没有任何的加密，直接传输，问题（没有隐私）
b):用到了对称加密，数据只有两个人知道，问题（不单跟女朋友聊天，还要跟爸妈聊天，不可能挨个告诉密码)
c):用到了非对称加密，保留私钥，其他人用公钥加密，这边私钥解密，问题（拿到加密后的数据，虽然不能解密，但是可以篡改)
d):用到了数字签名，原信息hash用私钥加密，另一端用公钥解密，最后比对hash值是否变了。如果变了就说明被篡改了，问题（公钥被伪造了，无法确认公钥的正确性)
e):用到了数字证书，还是可能会被中间人攻击~此时我们

数字证书是由CA(Certificate Authority)机构，发行的用于网络通讯中验证身份的一种方式；关于数字证书在此不做缀述，有兴趣的小伙伴可以自行网上查找；
数字证书中一般包含了此证书拥有者、证书使用者、证书名称、证书公钥等信息。
证书中心用自己的私钥对Bob的公钥和其它信息做了一次加密。这样Bob通过网络将数字证书传递给他的小伙伴后，小伙伴们先用CA给的公钥解密证书，这样就可以安全获取Bob的公钥了


@使用OpenSSL生成公钥和密钥
openssl genrsa -out rsa_private_key.pem 1024
openssl pkcs8 -topk8 -inform PEM -in
rsa_private_key.pem -outform PEM-nocrypt
openssl rsa -in rsa_private_key.pem -pubout -out
rsa_public_key.pem


@使用私钥对文件进行加签、并验证
openssl md5 -sha512 -sign rsa_private_key.pem -out
data_xinbao.tar.gz.sign data_xinbao.tar.gz
openssl md5 -verify rsa_public_key.pem -sha512
signature data_xinbao1.tar.gz.sign data_xinbao.tar.gz

@java用私钥签名
public bytel]rsaSign(byte data,RSAPrivateKey priKey)
throws SignatureException
try{
Signature signature
Signature.getlnstance("SHA512withRSA");
signature.initSign(priKey);
signature.update(data);
byte signed signature.sign);
return signed;
catch (Exception e){
throw new SignatureException("RSAcontent
"data
+"charset ="e);
}
}


@java用公钥验签
public boolean verify(bytell data,byte sign,
RSAPublicKey pubKey)
throws SignatureException
try
Signature signature
Signature.getlnstance("SHA512withRSA");
signature.initVerify(pubKey);
signature.update(data);
return signature.verify(sign);
catch (Exception e){
e.printStackTrace);
throw new SignatureException("RSA验证签名[content="+data+"charset ="+"signaturesign+"门发生异常！"，e);
}
}


@jdk生成证书
keytool -genkey -keyalg RSA -keysize 2048 -validity
36500 -alias SEC_TEST -keypass 123456 -keystore
test.keystore -storepass
123456 -dname
"CN=localhost,OU=DEP,O=CN,L=BJ,ST=BJ,C=CN"
-keyalg指定算法，
-keysize指定密钥大小，
-validity:指定有效期，单位为天，
-alias别名
-keypass指定私钥使用密码，
-keystore指定密钥库名称，
-storepass证书库的使用密码，从里面提取公钥时需要密码
-dname:CN拥有者名字，一般为网站名或IP+端口，如www.baidu.com,OU组织机构名O组织名L城市ST州或省C国家代码
以上命令执行后将在当前目录下产生一个keystore文件，里面保存着密钥和证书信息；
keytool -export -alias SEC_TEST -tile test_pub_cer.cer
keystore test.keystore -storepass 123456
在当前目录下会产生一个test_pub._cer.cer的证书，包含了公钥信息及证书相关信息；
通讯双方假设为A和B,A发布了自己的证书并公开了公钥，B所有经过A的公钥加密的报文发送给A后，A可以正确解密，如果A给B发送报文，A用私钥加密，B可以用公钥解密，
但这里有一个问题就是公钥是公开的，A发送给B的报文，任何有公钥的人都可以解密，不能保证A向B发送信息的安全性，
所以B也需要制作自己的证书，并对A公开自己的公钥，这样A向B发送信息里用B的公钥加密，这样B就可以用私钥解密，而其他截获信息的人因为没有私钥也不能解密；
A需要将B的公钥导入自己的证书库；

导入合作方公钥：
keytool -import -file B.cer -keystore test.keystore
storepass 123456


6)秘钥管理
根秘钥-工作秘钥






2 Web安全
1)防火墙
防火墙是一种保护计算机网络安全的技术性措施，它通过在网络边界上建立相应的网络通信监控系统来隔离内部和外部网络，以阻挡来自外部的网络入侵。
查看防火墙状态：service iptables status
开启防火墙：service iptables start
关闭防火墙：service iptables stop
需要在防火墙里设置服务器P的白名单，或者Mac地址的白名单。

2)SQL注入
Statement s=connection.createStatement(;不安全
ResultSet rs s.executeQuery("SELECT email FROM
member WHERE name ="formField);
预防：预编译，存储过程，检查长度，不要拼接sql,输入
验证和转义
3)CVS注入
Userld,BillToDate,ProjectName,Description,DurationMinu
tes
2,2017-07-25,Important Client,"=2+5+cmd/C calc'!A0",
240
打开的效果是计算器被打开。
预防：替换os命令

3)跨站脚本攻击(XSS)
XSS是指攻击者利用网站没有对用户提交数据进行转义处理或者过滤不足的缺点，进而添加一些代码，嵌入到web页面中去。
使别的用户访问都会执行相应的嵌入代码。从而盗取用户资料、利用用户身份进行某种动作或者对访问者进行病毒侵害的一种攻击方式。

存储式XSS攻击：把具有XSS的代码存储到数据库，所有人被影响了。

反射型xss攻击：一次性的造成攻击Http是无状态，同一个会话的连续两个请求互相不了解，
在cookie中存储一个sessionlD,服务器来识别该用户，那么安全隐患也就引引申而出了，
获得cookie可取得别人的身份，XSS就是在别人的应用程序中恶意执行一段JS以窃取用户的cookie。HttpOnly(在
浏览器的documenti对象中就看不到cookie了)。

预防：标签内容需要过滤、转义，属性值也可能需要；HttpOnly(在浏览器的document对象中就看不到cookie了)；对数据进行Html Encode处理；过滤或移除特殊的Html标签；

4)跨站请求伪造(CSRF)
就是攻击者盗用你的身份，以你的名义发送恶意请求；
CSRF能够做的事情包括：以你名义发送邮件，发消息，盗取你的账号，甚至于购买商品，虚拟货币转账等造成的
问题包括：个人隐私泄露以及财产安全。
用户C登录网站A-A产生Cookie浏览器，登录A成功，可以正常发送请求到网站A一未退出网站A,打开一个钓鱼网站B-网站B接收到用户请求后，返回一些攻击性代码，并
发出一个请求要求访问站点A;根据网站B的请求，在用户不知情的情况下携带Cookie信息，向网站A发出请求。网站A并不知道该请求其实是由B发起的，所以会根据用户C
的Cookie信息以C的权限处理该请求，导致来自网站B的恶意代码被执行。

预防：
1.验证Referer:不是特别安全，有些低版本支持修改，有些用户设置不再提供Referer.。
2.在请求地址中添加token并验证，
3.在HTTP头中自定义属性并验证
<input type='hidden'name='csrf_token_name'value="<?
=S_SESSION['csrf_token_name'l;?>">
s.headers['Csrf-Token-Name']
s.data['csrf_token_name'];

6)Dos攻击
一个用户进行对你的服务进行攻击，TCP半连接，Http协议防火墙，限流，限制并发，快速失败，容错，熔断，防雪崩机制

7)Http Header)加固

8)zip炸弹
参考截图

9)cookie安全
Cookie是可以被篡改的
服务器可以为每个Cookie项生成签名，由于用户篡改Cookie后无法生成对应的签名，服务器便可以得知用户对Cookie进行了篡改。
使用http-only的cookie,防止本地JS读取到用户权限相关的Cookie。

10)JWT
@生成token
public static String generateToken(String username,Date
generateTime){
HashMap<String,Object>map new HashMap<>0;
/可以把任何安全的数据放到map里面
map.put("username",username);
map.put("generate Time",generateTime);
String jwt Jwts.builder)
.setClaims(map)
setExpiration(new
Date(generateTime.getTime(+EXPIRATION_TIME))
.signWith(SignatureAlgorithm.HS512,
SECRET)
.compact);
return jwt;
}

@校验token
public static Map<String,Object>validToken(String
token){
Map<String,Object>resultMap
Maps.newHashMap0;
try
JWSObject jwsObject JWSObject.parse(token);
/palload就是JWT构成的第二部分不过这里自定
义的是私有声明（标准中注册的声明，公共的声明）
Payload payload jwsObject.getPayloadO;
JWSVerifier verifier new MACVerifier(SECRET);
if(jwsObject.verify(verifier)){
JSONObject jsonobject
payload.toJSONObject);
/token检验成功（此时没有检验是否过期）
resultMap.put("state",
TokenState.VALID.toStringO);
/若payload包含ext字段，则校验是否过期
if(jsonObject.containsKey("ext")){
long extTime
Long.valueOf(jsonObject.get("ext").toStringO);
long cur Time System.currentTimeMillis);
/过期了
if(curTime extTime){
resultMap.clearO;
resultMap.put("state",
TokenState.EXPIRED.toStringO);
}
}
resultMap.put("data",jsonobject);
else
/检验失败
resultMap.put("state",
TokenState.INVALID.toStringO);
}
catch (Exception e){
e.printStackTraceO;
/token格式不合法导致的异常
resultMap.clearO;
resultMap.put("state",
TokenState.INVALID.toStringO);
}
return resultMap;
}

@用户注销怎么处理
用户主动注销、强制登出（禁止登陆）、忘记密码、修改密码，JWT续签存储在redis.

11)限流和并发控制
参考截图



12)登录认证
微服务下四种解决方案
1).单点登录(SS0)
这种方案意味着每个面向用户的服务都必须与认证服务交互，这会产生大量非常琐碎的网络流量和重复的工作，当动辄数十个微应用时，这种方案的弊端会更加明显。

2).分布式Session方案
分布式会话方案原理主要是将关于用户认证的信息存储在共享存储中，且通常由用户会话作为key来实现的简单分布式哈希映射。当用户访问微服务时，用户数据可以从共
享存储中获取。在某些场景下，这种方案很不错，用户登录状态是不透明的。同时也是一个高可用且可扩展的解决方案。这种方案的缺点在于共享存储需要一定保护机制，
因此需要通过安全链接来访问，这时解决方案的实现就通常具有相当高的复杂性了。

3).客户端Token方案
令牌在客户端生成，由身份验证服务进行签名，并且必须包含足够的信息，以便可以在所有微服务中建立用户身份。令牌会附加到每个请求上，为微服务提供用户身份验
证，这种解决方案的安全性相对较好，但身份验证注销是一个大问题，缓解这种情况的方法可以使用短期令牌和频
繁检查认证服务等。对于客户端令牌的编码方案，Borsos更喜欢使用JSON Web Tokens(JWT),它足够简单且库支持程度也比较好。

4).客户端Token与AP网关结合
这个方案意味着所有请求都通过网关，从而有效地隐藏了微服务。在请求时，网关将原始用户令牌转换为内部会话D令牌。在这种情况下，注销就不是问题，因为网关可以在注销时撤销用户的令牌。
@首先，前端通过Web表单将自己的用户名和密码发送到
后端的接口。这一过程一般是一个HTTP POST请求。建议的方式是通过SSL加密的传输(https协议)，从而避免敏感信息被嗅探。
@后端核对用户名和密码成功后，将用户的id等其他信息
作为JWT Payload(负载)，将其与头部分别进行Base64编码拼接后签名，形成一个JWT。形成的JWT就是一个形同l.ZzZ.XXx的字符串。
@后端将JWT字符串作为登录成功的返回结果返回给前端。前端可以将返回的结果保存在localStorage或sessionStorage.上，退出登录时前端保存的JWT即可。
@前端在每次请求时将JWT放入HTTP Header中的Authorization位。（解决XSS和XSRF问题）
@后端检查是否存在，如存在验证JWT的有效性。例如，检查签名是否正确；检查Token:是否过期；检查Token的接收方是否是自己（可选）。
@验证通过后后端使用JWT中包含的用户信息进行其他逻辑操作，返回相应结果。


13)鉴权
人机鉴权：如果是单系统shiro可以做到，分布式系统中，用网关拦截鉴权处理。
机机鉴权：分布式系统，考虑网关做法。







3 Https
@HTTP协议由于是明文传送，所以存在三大风险
1)被窃听的风险：第三方可以截获并查看你的内容
2)被篡改的危险：第三方可以截获并修改你的内容
3)被冒充的风险：第三方可以伪装成通信方与你通信

HTTP因为存在以上三大安全风险，所以才有了HTTPS的出现。涉及多概念，比如SSL/TLS,数字证书、数字签名、加密、认证、公钥和私钥等
1、浏览器发起往服务器的443端口发起请求，请求携带了浏览器支持的加密算法和哈希算法。
2、服务器收到请求，选择浏览器支持的加密算法和哈希算法。
3、服务器下将数字证书返回给浏览器，这里的数字证书可以是向某个可靠机构申请的，也可以是自制的。
4、浏览器进入数字证书认证环节，这一部分是浏览器内置的TLS完成的：
4.1首先浏览器会从内置的证书列表中索引，找到服务器下发证书对应的机构，如果没有找到，此时就会提示用户
该证书是不是由权威机构颁发，是不可信任的。如果查到了对应的机构，则取出该机构颁发的公钥。
4.2用机构的证书公钥解密得到证书的内容和证书签名，
内容包括网站的网址、网站的公钥、证书的有效期等。浏览器会先验证证书签名的合法性（验证过程类似上面Bob
和Susan的通信)。签名通过后，浏览器验证证书记录的网址是否和当前网址是一致的，不一致会提示用户。如果
网址一致会检查证书有效期，证书过期了也会提示用户。这些都通过认证时，浏览器就可以安全使用证书中的网站公钥了。
4.3浏览器生成一个随机数R,并使用网站公钥对R进行加密。
5、浏览器将加密的R传送给服务器。
6、服务器用自己的私钥解密得到R。
7、服务器以R为密钥使用了对称加密算法加密网页内容并传输给浏览器。

⑧、浏览器以R为密钥使用之前约定好的解密算法获取网页内容。
备注1：前5步其实就是HTTPS的握手过程，这个过程主要是认证服务端证书（内置的公钥）的合法性。因为非对称加密计算量较大，整个通信过程只会用到一次非对称加
密算法（主要是用来保护传输客户端生成的用于对称加密的随机数私钥)。后续内容的加解密都是通过一开始约定好的对称加密算法进行的。

备注2：SSL/TLS是HTTPS安全性的核心模块，TLS的前身是SSL,TLS1.0就是SSL3.1,TLS1.1
是SSL3.2,TLS1.2则是SSL3.3。SSL/TLS是建立在TCP协议之上，因而也是应用层级别的协议。其包括T儿S
Record Protocol和TLS Handshaking Protocols两个模块，后者负责握手过程中的身份认证，前者则保证数据传输过程中的完整性和私密性。
openssl:一个多功能的命令行工具对称密钥加密方式的优缺点：
优点：处理速度快
缺点：但是容易被第三方盗取非对称密钥加密方式的优缺点：

优点：更加安全，不容易被盗取
缺点：处理效率相比对称密钥加密要慢，如果在通信时用这种方式加密，效率很低
于是HTTPS采用了两者的优点，使用了混合加密的方式使用非对称密钥加密的方式安全地交换再稍后对称密钥加
密中要使用的密钥
确保交换的密钥是安全的之后，放弃非对称密钥加密，使用对称密钥加密来进行通信，保证传输效率







4 Shiro
@Subject,主体，一般是当前操作用户，subject:是通过SecurityManager安全管理器进行认证授权

@SecurityManager,安全管理器，对全部的subjecti进行安全管理，它是shiro的核心，负责对所有的subjecti进行安全管理。
通过SecurityManageri可以完成subject的认证、授权等，
实质上SecurityManager:是通过Authenticatori进行认证，通过Authorizeri进行授权，通过SessionManageri进行会话管理等。
SecurityManager是一个接口，继承了Authenticator,
Authorizer,SessionManager这三个接口。

@Authenticator,认证器

@Authorizer,授权器

@realm,领域，相当于datasource数据源，securityManageri进行安全认证需要通过Realm获取用户权限数据，比如：如果用户身份数据在数据库那么realm就需要从数据库获取用户身份信息。

@sessionManagera&sessionDao,会话管理和会话dao,是对session会话操作的一套接口，比如要将session存储到数据库；

@CacheManager,缓存管理，将用户权限数据存储在缓存，这样可以提高性能。
@Cryptography,密码管理，shiro:提供了一套加密/解密的组件，方便开发。比如提供常用的散列、加/解密等功能自定义Realm继承AuthorizingRealm重写
Authorizationlnfo(授权)和AuthenticationInfo(认证)
doGetAuthenticationlnfo方法和doGetAuthorizationInfo方法精简安全架构：Shiro+JWT+Spring Boot




5 Spring security
@主要特性
应用的安全性包括用户认证(Authentication)和用户授权(Authorization)和攻击防护（防止伪造身份）3个部分。
spring security的主要核心功能为认证和授权，所有的架构也是基于这两个核心功能去实现的。想要对对Web资源进行保护，最好的办法莫过于Filter,要想对方法调用进行保护，最好的办法莫过于AOP。
所以springSecurity:在我们进行用户认证以及授予权限的时候，通过各种各样的拦截器来控制权限的访问，从而实现安全。

@主要组件
SecurityContextHolder:安全上下文持有者，提供对
SecurityContext的访问；
SecurityContext:安全上下文，持有Authentication.对象和其他可能需要的信息；
AuthenticationManager其中可以包含多个AuthenticationProvider,AuthenticationProvider主要
用来进行认证操作的类调用其中的authenticate(方法去进行认证操作
UserDetailsService:通过username构建UserDetails对象，也可以从缓存数据库获取；

@对SpringSecurity:进行相应的配置
SpringSecurityConfig
extends
WebSecurityConfigurerAdapter
@Override
protected void configure(HttpSecurity http)throws
Exception
http.formLoginO
//定义当需要用户登录时候，转到的登录页面。
.loginPage("/login.html")
/设置登录页面
.loginProcessingUrl("/user/login")/自定义的登录接口
.andO
.authorizeRequests)
/定义哪些URL需要被保护、哪些不需要被保护
.antMatchers("/login.html".permitAllO/设置所有人都可以访问登录页面
.anyRequest(
/任何请求，登录后可以访问
.authenticatedO
.and)
.csrf).disable0;
/关闭csrf防护
}
@自定义认证逻辑
public class
MyUserDetailsService implements
UserDetailsService重写loadUserByUsername方法

@密码加密接口
SpringSecurity中有一个PasswordEncoder对密码进行加密
@Autowired
private PasswordEncoder passwordEncoder;
String password passwordEncoder.encode("123456");

@屏蔽CSRF
protected void configure(HttpSecurity http)throws
Exception
http.csrf).disableO;

@添加CSRF的隐藏字段
<input
name="S{(_csrf.parameterName)!y"
value="S{(_csrf.token)!y"type="hidden"/>
xhr.setRequestHeader("S{_csrf.headerName)",
"S(_csrf.token}");

@jQuery的Ajax全局配置
jQuery.ajaxSetup({
"beforeSend":function (request){
request.setRequestHeader("S{_csrf.headerName)",
"S{_csrf.token}");
);

@Csrf拦截器，用来生成或去除CsrfToken
public
class
CsrfInterceptor
extends
HandlerInterceptorAdapter
CsrfTokenRepository保存CsrfToken的dao层，保存在session里面
public void
saveToken(CsrfToken token,
HttpServletRequest request,
HttpServletResponse response){
if (token =null){
HttpSession session
request.getSession(false);
if (session !null){
session.removeAttribute(sessionAttributeName);
}
else
HttpSession session request.getSession();
session.setAttribute(sessionAttributeName,
token);
}


@生成token
public CsrfToken generateToken(HttpServletRequest
request){
return
new
DefaultCsrfToken(headerName,
parameterName,createNewTokenO);
}
private String createNewTokenO{
return UUID.randomUUIDO.toStringO;
}




###安全模块-防CSRF攻击
CSRF攻击又称跨站请求伪造，CSRF主要是拿到身份也就是cookie,并且cookie在有效内，这样的话，服务器就任
务是一个合法用户，能够执行攻击者的任何请求；登录受信任网站A,并在本地生成Cookie;在不登出A的
情况下，访问危险网站B;拿到cookie随便转账，<img src=http://www.mybank.com/Transfer.php?toBankld=11&money=1000>
禁用get请求，其实post请求也可以跨站请求伪造，服务端校验，在客户端页面增加伪随机数。验证码可以完全解决但是易用性不好。
HTTP header中Referer的校验，进行域校验，checkCsrf)
678340678D21C1643DC7B3A521230A8AB5F2D116EE5



###安全模块-DDOS攻击
让服务提供者超过处理极限，资源枯竭，到达服务器瘫痪，通常最多的攻击是利用TCP/IP协议漏洞来进攻击限流处理，zip炸弹校验大小


###安全模块-CVS注入
对excle文件内容进行检查，对特殊字符如=、-、+、@等，cmdl/C calc'!AO这类字符串可以操作任何dos命令


###安全模块-SQL注入
select from users where username="or 1=1#
password=md5("等价于select*from users wi个username="or 1=1


###安全模块-SQL注入
select from users where username="or 1=1#and
password=md5(")等价于select*from users where
username="or 1=1
禁止用$，使用#占位符；参数校验；不要暴露表结构到前端；


###安全模块-Http Header
Requests
Accept指定客户端能够接收的内容类型
Accept:
text/plain,text/html;Charset/Language
Authorization HTTP授权的授权证书，token Authorization:
Basic QWxhZGRpbjpvcGVulHNlc2FtZQ==
Proxy-Authorization连接到代理的授权证书
Proxy-Authorization:
Basic
QWxhZGRpbjpvcGVulHNIc2FtZQ==
Cache-Control指定请求和响应遵循的缓存机制
Cache-Control:no-cache
Connection表示是否需要持久连接。(HTTP1.1默认进行持久连接)
Connection:close
Cookie HTTP请求发送时，会把保存在该请求域名下的所有cookie值一起发送给web服务器。Cookie:
SVersion=1;Skin=new;
Content-Type请求的与实体对应的MIME信息、Content-
Type:application/x-www-form-urlencoded
From发出请求的用户的Email
From:
user@email.com
Host指定请求的服务器的域名和端口号上个
www.zcmhi.com
Referer先前网页的地址，当前请求网页紧随其后.即来


user@email.com
Host指定请求的服务器的域名和端口号
Host:
www.zcmhi.com
Referer先前网页的地址，当前请求网页紧随其后，即来路Referer:http:/www.zcmhi.com/archives/71.html
User-Agent User-Agent的内容包含发出请求的用户信息、User-Agent:Mozilla/5.0(Linux;X11)
Responses部分
Accept-Ranges表明服务器是否支持指定范围请求及哪种类型的分段请求Accept-Ranges:bytes
Age从原始服务器到代理缓存形成的估算时间（以秒计，非负)Age:12
Allow对某网络资源的有效的请求行为，不允许则返回405 Allow:GET,HEAD
Cache-Control告诉所有的缓存机制是否可以缓存及哪种类型Cache-Control:no-cache
Expires响应过期的日期和时间
Expires:Thu,01
Dec201016:00:00GMT
Last-Modified请求资源的最后修改时间Last-Modified:
Tue,15Nov201012:45:26GMT
Proxy-Authenticate它指出认证方案和可应用到代理的该
URL上的参数
Proxy-Authenticate:Basic


###安全模块-文件上传和下载
zip炸弹：在解压前先对压缩包，进行条目累计和大小累
计超过一定大小则丢弃


###对称加密(DES/AES/base64),数据传输数据加密和解密采用的都是同一个密钥，因而其安全心赖干所持有密钥的安全性。


###安全模块-文件上传和下载
zip炸弹：在解压前先对压缩包，进行条目累计和大小累计超过一定大小则丢弃


###对称加密(DES/AES/base64),数据传输
数据加密和解密采用的都是同一个密钥，因而其安全性依赖于所持有密钥的安全性。
算法的特点是算法公开、计算量小、加密速度快、加密效率高。
对称加密又分为分组加密(ECB,CBC,CFB,OFB)和序列密码。
ECB不需要V,明文分组后，每个分组与密钥计算得到一个密文，将每个密文连接起来组成最终的密文。
CBC需要V,明文分组，第一明文分组与IV异或，然后与秘钥计算得到第一个密文，第一个密文与第二个分组异或，然后与秘钥计算得到第二个密文，以此类推。
CFB需要IV加密，取其前n位，与明文异或得到密文。得到的密文当做Ⅳ重复前面的过程。
OFB需要V加密，取其前n位，与明文异或得到密文。将之前异或的结果当做Ⅳ重复前面的过程
V值：在密码学的领域里，初始化向量（英语：initialization vector,缩写为V),或译初向量，是一个固定长度的输入值。随机数。


###非对称加密(SHS/RSA),一般是身份认证公钥和私钥，发信方必须首先知道收信方的公钥，然后利
用收信方的公钥来加密原文；收信方收到加密密文后,用自己的私钥才能解密密文。根据工作秘钥和根秘钥在mian方法生成PublicKey




###非对称加密(SHS/RSA),一般是身份认证公钥和私钥，发信方必须首先知道收信方的公钥，然后利
用收信方的公钥来加密原文；收信方收到加密密文后，使
用自己的私钥才能解密密文。根据工作秘钥和根秘钥在mian方法生成PublicKey和
PrivateKey,用公钥加密，私钥解密。工具类生成salt和partRootkey,common写死一个root秘钥，应用外挂一个root秘钥，两者取值异或，生成rootKey;
根据rootKey,iv值，盐值生成workKey;
数据加密：首先根据rootKey加密workKey生成workKey2,再用workKey2对数据进行加密；
数据解密：首先根据rootKey解密密workKey2生成workKey,再用workKey.对数据进行解密；

springboot配置bean,覆盖jaspty的StringEncryptor。



###不可逆加密算法(MD5,SHA2-256位及以上)，一般登录验证密码
如果直接对密码进行散列，那么黑客可以对通过获得这个密码散列值，然后通过查散列值字典（例如MD5密码破解网站)，得到某用户的密码。
加Salt可以一定程度上解决这一问题。所谓加Salt方法，就是加点“佐料”。其基本想法是这样的：当用户首次提
供密码时（通常是注册时），由系统自动往这个密码里撒一些“佐料”，然后再散列。而当用户登录时，系统为用
户提供的代码撒上同样的“佐料”，然后散列，再比较散列值，已确定密码是否正确。
即便两个用户使用了同一个密码，由于系统为它们生成的salt值不同，他们的散列值也是不同的。
提供统一的安全随机数的产生；SecureRandom即便两个用户使用了同一个密码，由于系统为它们生成的salt值不同，他们的散列值也是不同的。
提供统一的安全随机数的产生；SecureRandom,salt盐值，V初始化值。


###SSL协议
https中SSL/TLS系列中有五种协议：SSLv2,SSLv3,TLSv1.0,TLSv1.1和TLSv1.2
SSLv2是不安全的，不能使用。

当与HTTP(POODLE攻击)一起使用时，SSLv3是不安全的，当与其他协议一起使用时，SSLV3是弱的。它也是过时的，不应该被使用。
TLSv1.0也是不应该使用的传统协议，但在实践中通常仍然是必需的。其主要弱点在现代浏览器中得到缓解，但其他问题仍然存在。
TLSv1.1和v1.2都没有已知的安全问题，只有v1.2提供了现代的加密算法。
TLSv1.2应该是您的主要协议，因为它是唯一提供现代认证加密（也称为AEAD)的版本。如果您今天不支持TLS
v1.2,则缺乏安全性。



###秘钥管理
实现两层密钥管理结构，对根密钥、工作密钥进行生成、使用、更新、安全存储等
密钥的分层管理机制最少把密钥分为两层，即：根密钥和工作密钥，根密钥为工作密钥提供加密保护。
密钥分层管理结构的选择与其应用场景有密切的关系，选择三层结构还是两层结构取决于产品所涉及的加密场景的复杂度，应用场景复杂的情况推荐使用三层管址构。

(③)工作密钥：工作密钥对本地保存的敏感数据和需要在不安全信道上传输的数据提供机密性、完整性保护，还可
提供认证和签名等密码学服务。工作密钥直接被上层应用程序所使用，包括存储密钥、会话密钥、MAC密钥、签名私钥等；

(②)密钥加密密钥：对工作密钥提供机密性保护的密钥，
其自身受到根密钥的保护。对于较为简单、安全等级要求不高的密码应用系统，密钥加密密钥的职能可以直接由根密钥兼任；

(①)根密钥：位于密钥管理分层结构的最底端，用于对上层密钥（如密钥加密密钥）的机密性进行保护。
秘钥修改机制：要给你工具类生成新的工作秘钥，用旧秘钥重新解密和加密历史数据，保存新的秘钥




###http头加固
Cache-Control:no-cache,no-store,max-age=0,must-
revalidate会被缓存的，只不过每次在向客户端（浏览器）提供响应数据时，缓存都要向服务器评估缓存响应的有效性；不缓存；缓存过期向源服务器进行校验
Pragma:no-cache兼容http1.0,Pragma:no-cache可以
应用到http1.0和http1.1,而Cache-Control:no-cache!只能
应用于http1.1.X-Content-Type-Options:nosniff",script和styleSheet元素会拒绝包含错误的MIM正类型的响应。这是一种安全功能，有助于防止基于MIME类型混淆的攻击
HTTP Strict Transport Security(通常简称为HSTS)是一个安全功能，它告诉浏览器只能通过HTTPS访问当个源禁止HTTP方式，仅用于https应答。
X-XSS-Protection:XSS攻击的防御，O(禁用XSS过滤器)，1（不安全的部分；如果没有X-XSS-Protection标题，这是默认设置)1；mode=block(如果找到XSS不渲染文档)
X-Frame-Options。
DENY:页面不能被嵌入到任何iframei或framel中；
SAMEORIGIN:页面只能被本站页面嵌入到iframe或者framel中；
ALLOW-FROM:页面允许frame或frame加载。
Java代码：response.addHeader("x-frame-options","SAMEORIGIN");
Nginxi配置：add_header X-Frame-Options SAMEORIGIN
Apache'配置：Header always append X-Frame-Options
SAMEORIGIN


###cookie安全
Secure=true只能在HTTPS连接中被浏览器传递到服务器端进行会话验证；
HttpOnly属性设置，那么通过程序(JS脚本、Applet等)将无法读取到Cookie信息，这样能有效的防止XSS攻击


###安全模块-HTTPS协议
HTTPS=http+ssl1.2


###登录，人机认证，人机菜单权限，人机接口权限，机机接口权限
用户登录之后传用户名密码，生成token(可以加个成remenber me功能)，带有效期，用户带着token不用登录了。



MD5和SHA
一般适合于验证，在验证过程中，重新输入明文，并经过同样的加密算法处理，得到相同的密文并被系统重新认证。广泛使用于口令加密。
都是不可逆，SHA安全，MD5已经得到破解，不安全，不采用，SHA-1速度比MD5慢。


Base64严格来说并不是一种加密算法,而是一种编码/解码的实现方式.
比如说从A地传到B地，往往要经过多个路由设备，由于不同的设备对字符的处理方式有一些不同，这样那些不可见字符就有可能被处理错误，
这是不利于传输的。所以就先把数据先做一个Base64编码，统统变成可见字符，这样出错的可能性就大降低了。
还有一种例子：AES加密之后乱码，RSA加密之后乱码，可以用base64编码统统变成可见字符。


RSA：
甲方构建密钥对儿，将公钥公布给乙方，将私钥保留。甲方使用私钥加密数据，然后用私钥对加密后的数据签名，发送给乙方签名以及加密后的数据；
乙方使用公钥、签名来验证待解密数据是否有效，如果有效使用公钥对数据解密。
乙方使用公钥加密数据，向甲方发送经过加密后的数据；
甲方获得加密数据，通过私钥解密。



数字证书完全充当加密算法的载体，为必要数据做加密解密和签名验签等操作。
A机器某模块需要将数据导出到一个文件中，将文件发送到B机器，由B将数据导入。在这个场景中，A就相当于服务端，需要将证书给B，
同时用私钥加密数据，生成签名，导出到文件中。
B相当于客户端，用收到的数字证书进行解密和验签。


openssl, keystore,keytool,p12,crt,key,cer概念
keytool是jdk自带的工具，只能生辰自签名的数字证书
openssl能够进行签发好证书链的管理
keystore,证书库，Keytool将秘钥（key）和证书（certificates）存在一个称为keystore的文件中；
p12, crt, key, cer等属于证书的扩展名，也就是证书类型，可以经过keystore中转知乎相互转换。浏览器支持p12格式


keytool -genkey -alias ynhr -keyalg RSA -keysize 1024 -keypass 123456 -validity 36500 -keystore test.keystore -storepass 123456
在目录下生成了 test.keystore

keytool 通过keystone 导出p12文件



从keystore导出cer/crt公钥证书文件
keytool -export -alias ynhr -keystore test.keystore -rfc -file test.cer
keytool -export -alias ynhr -keystore test.keystore -rfc -file test.crt


镜像工厂证书：
自己可以从浏览器导出，也可以通过下面命令获取得到：
echo -n openssl s_client -showcerts -connect kweecr03-beta.his.com:443 2>/dev/null | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/P' > CA.CRT






https://www.cnblogs.com/funyoung/p/9234947.html
CAS包含CAS Client 和 CAS Server两部分
CAS Client：要使用单点登录的Web应用，将与同组下的Web应用构成相互信任的关系，只需在web应用中添加CAS提供的Listener和Filter即可成为CAS Client ，其主要负责对客户端的请求进行登录校验、
重定向和校验ticket工作。
CAS Server：主要负责对用户的用户名/密码进行认证，颁发票据等，需要单独的进行部署。



通过SessionId Cookie匹配到Session对象的理念，不是jwt原理
客户端的filter过滤一切请求，首先校验sessionId匹配到session对象，并且有个属性Assertion，其次校验票据ticket.
如果没有Assertion和ticket，则重定向到cas serevr处理，后面带着一窜原来的url地址。


当浏览器收到CAS Server返回的302重定向请求后，对重定向目标地址重新发起HTTP请求( 携带ticket参数 )，此时请求将会进入项目A的CAS 认证filter,
由于当前不存在Assertion，也没有session, 但是有ticket，此时就会放行，交给下一个过滤器处理。


由于用户第一次访问项目A，并没有携带SessionId Cookie，因此无法成功匹配Session，所以Assertion实体为null，请求中也不存在ticket参数，
则此时项目A认为该用户未登录，返回302状态码示意浏览器将请求重定向到CAS Server进行登录处理，并在请求URL后追加service参数传递
原访问项目A的URL。

当浏览器收到项目A返回的302重定向请求后，对重定向目标地址重新发起HTTP请求，最终到达CAS Server进行登录处理，由于浏览器不存在TGC Cookie，CAS Server认为用户未进行登录，因此将请求转发到登录页面。 


CAS Server对用户输入的用户名/密码进行校验，若校验成功则返回302状态码示意浏览器将请求重定向到原访问项目A的URL地址并在URL后追加ticket参数传递ST，并且最终保存TGC Cookie在客户端浏览器进程所占用的内存中。




shiro主要处理身份认证和权限认证功能，如过自己实现Realms一般是自己数据库登录，一般可以集成sso.
shiro+cas 


shiro和 spring security :
shiro简单容易上手，但是 spring security 有防止CSRF的功能。





双方通讯假设为A和B，A发布了自己的证书并公开了公钥，B经过A的公钥加密的报文发送给A后，A可以正确解密，
如果A给B发送报文，A用私钥加密，B可以用公钥解密。
但是这里有一个问题，公钥是是公开的，A发给B的报文，任何有公钥的人都可以解密，不能保证A发往B的安全性。

所以B也要制作自己的证书，并对A公开自己的公钥，这样A向B发送信息里面用B的公钥加密，B可以用私钥解密，其他人截取之后没有私密也不能解密啊。

A需要将B的公钥导入自己的证书库。




互联网的通信安全，建立在SSL/TLS之上。
TLS的前身是SSL，TLS1.0就是SSL3.1，TLS1.1就是SSL3.2，TLS1.1就是SSL3.3
SSL/TLS是建立在TCP协议基础之上，是会话层级的协议，包括TLS Record Protocol 和 TLS Handshaking Protocol两个模块，后者负责握手过程的身份认证，
前者负责保证数据传输的完整性和私密性。
https = http + SSL/TLS


7应用层  http https ftp telnet ssh smtp pop3 dhcp nds nfs
6表示层 xdr lpp
5会话层 ssl tls rpc
4传输层 tcp udp 
3网路层 ip icmp
2数据链路层 ppp 令牌环
1物理层 光纤



-----------------------------------------------------
80端口是http协议的默认端口，8080是tomcat服务器的http默认端口
443是https协议的默认端口，8443是tomcat服务器的的https默认端口


-----------------------------------------------------
HTTP没有长链接和短连接的说法，http请求和http响应跟准确些，都是通过tcp这个通道来回传输的。
长连接指的是tcp的连接，不是http连接，也就是说复用的是tcp的连接，长连接的情况下，多个http请求可以复用一个tcp连接，这就节省了很多
TCP连接建立和断开的消耗。
http1.0默认使用的是短连接，http1.1默认使用keep-alive方式。
Connection:Keep-alive
Keep-alive::timeout=60


-----------------------------------------------------
https：保密性（AES），完整性（签名），真实性（CA证书）
1.客户端向服务器发起HTTPS请求，连接到服务器的443端口
2.服务器端有一个密钥对，即公钥和私钥，是用来进行非对称加密使用的，服务器端保存着私钥，不能将其泄露，公钥可以发送给任何人。
3.服务器将自己的公钥发送给客户端。
4.客户端收到服务器端的证书之后，会对证书进行检查，验证其合法性，如果发现发现证书有问题，那么HTTPS传输就无法继续。严格的说，这里应该是验证服务器发送的数字证书的合法性，关于客户端如何验证数字证书的合法性，下文会进行说明。如果公钥合格，那么客户端会生成一个随机值，这个随机值就是用于进行对称加密的密钥，我们将该密钥称之为client key，即客户端密钥，这样在概念上和服务器端的密钥容易进行区分。然后用服务器的公钥对客户端密钥进行非对称加密，这样客户端密钥就变成密文了，至此，HTTPS中的第一次HTTP请求结束。
5.客户端会发起HTTPS中的第二个HTTP请求，将加密之后的客户端密钥发送给服务器。
6.服务器接收到客户端发来的密文之后，会用自己的私钥对其进行非对称解密，解密之后的明文就是客户端密钥，然后用客户端密钥对数据进行对称加密，这样数据就变成了密文。
7.然后服务器将加密后的密文发送给客户端。
8.客户端收到服务器发送来的密文，用客户端密钥对其进行对称解密，得到服务器发送的数据。这样HTTPS中的第二个HTTP请求结束，整个HTTPS传输完成





-----------------------------------------------------
1 springboot整合https
@创建证书
keytool -genkey -alias hiyaSecurity -keyalg RSA -keysize 1024 -keypass hiyaSecurity -validity 36500 -keystore hiyaSecurity.keystore -storepass hiyaSecurity
@把证书放在根目录，配置application.properties的ssl参数
@访问https://localhost:8443/security/quick/list?id=444
@可以同时支持http和https
@可以配置访问http自动跳转https



2 tomcat整合https,双向ssl认证
什么是信任库和秘钥库，信任库是用来存放客户端信任的CA证书，在程序交互中，需要确保你访问的服务器证书在信任库里面，秘钥库存放服务器的私钥和证书。

单向验证过程中，客户端会验证自己访问的服务器，服务器对来访的客户端身份不做任何限制。如果服务器需要限制客户端的身份，
则可以选择开启服务端验证，这就是双向验证。从这个过程中我们不难发现，使用单向验证还是双向验证，是服务器决定的。

一般而言，我们的服务器都是对所有客户端开放的，所以服务器默认都是使用单向验证。如果你使用的是Tomcat服务器，
在配置文件server.xml中，配置Connector节点的clientAuth属性即可。若为true，则使用双向验证，若为false，则使用单
向验证。如果你的服务，只允许特定的客户端访问，那就需要使用双向验证了。


@为服务器生成证书
keytool -genkey -alias hiyaSecurity -keyalg RSA -keysize 1024 -keypass hiyaSecurity -validity 36500 -keystore hiyaSecurity.keystore -storepass hiyaSecurity

@为客户端生成证书
keytool -genkey -v -alias hiyaSecurityClient -keyalg RSA -storetype PKCS12 -keystore D:\homes\hiyaSecurityClient.p12
双击mykey.p12文件，输入刚才设置的密码，即可将证书导入至浏览器（客户端）。

@让服务器信任客户端证书
由于不能直接将PKCS12格式的证书库导入，必须先把客户端证书导出为一个单独的CER文件
keytool -export -alias hiyaSecurityClient -keystore D:\homes\hiyaSecurityClient.p12 -storetype PKCS12 -storepass 123123 -rfc -file D:\homes\hiyaSecurityClient.cer
D:\homes下面有3个文件：hiyaSecurity.keystore、hiyaSecurityClient.p12、hiyaSecurityClient.cer 

keytool -import -v -file D:\homes\hiyaSecurityClient.cer -keystore D:\homes\hiyaSecurity.keystore

是否信任该证书？y
证书已添加到信任库中
[正在存储D:\homes\hiyaSecurity.keystore]

使用 keytool -list -keystore D:\homes\hiyaSecurity.keystore
可以查看秘钥库包含2个条目


@让客户端信任服务器证书
由于不能直接将keystore格式的证书库导入，必须先把服务器证书导出为一个单独的CER文件，使用如下命令：
1 keytool -keystore D:\home\hiyaSecurity.keystore -export -alias tomcat -file D:\home\hiyaSecurity.cer

@配置tomcat
conf/server.xml
1 <Connector port="443" protocol="HTTP/1.1" SSLEnabled="true"
2                maxThreads="150" scheme="https" secure="true"
3                clientAuth="false" sslProtocol="TLS" keystoreFile="D:/homes/hiyaSecurity.keystore" keystorePass="hiyaSecurity"/>


@大功告成，访问https://127.0.0.1:8443/security/quick/list?id=444


3 nginx 整合https,kong整合https，openrestry整合https，zuul整合https
原理差不多



4 httpclient访问https接口
@ 绕开ssl认证，X509TrustManager
@ 带上证书，经过ssl认证
resttemplate，feign也是一样的道理


5 镜像仓库的https,镜像工厂和k8s的node需要pull镜像
@走http 
insecure-registries:[]
cat /etc/docker/daemon.json
@拿证书
所有需要push的机器都需要拷贝证书到docker，客户端docker根目录下，重启docker可以登录镜像仓库
cp ca.crt /etc/docker/cets.d/192.168.1.109/ca.crt



-----------------------------------------------------
CSRF和XSS的区别
@CSRF需要登录后操作，XSS不需要
@CSRF使用访问api做非法操作，XSS是向当前页面植入js脚本修改页面内容





-----------------------------------------------------
JWT之通过算法实现对TOKEN的合法性验证，不依赖数据库，memcache等存储系统。
因此可以做到跨服务器验证，只要秘钥和算法相同，不同服务器程序生成的Token就可以相互验证。
token本身就是用户信息，secret被服务器秘密存储在后面，依赖算法和secret, 合法性通过之后认证有效期就行了。
后面这一部分签名主要保证内容没有被篡改。






----------------------------------------------------------------------
webstorage分为localstorage和sessionstorage
localstorage永久有效，关闭页面或浏览器数据不会消失，除非主动删除；
sessionstorage和当前会话有关系，关闭页面或浏览器数据消失。




----------------------------------------------------------------------
1、单点登录（SSO) 是一个多系统登录问题的解决方案，具体可以由CAS技术框架实现，实现效果是：部署一个独立的登录系统，
在此系统登录成功后，所有集成进来的业务系统可免登录进入。
2、OAUTH 是一个授权开放协议，主要用于将系统内部的功能或者数据授权给外部系统调用或者使用。OAUTH也可以实现单点登
录的效果，像我们常见的大型网站除了账号密码登录之外，还提供了 QQ登录、微信登录、微博登录，实际上是通过OAUTH获取
到了openid （比如：微信openid） 直接在系统中创建了一个和openid绑定的账号，间接实现了单点登录。
3、Jwt 是一种Token的数据格式标准，主要用于前后端分离（面向http无状态），不借助cookies情况下的前后端用户身份标识的
传递（默认不加密但可进行非对称加密）。另外在 单点登录/OAUTH 的集成过程中可以考虑将其中需要传递的相关信息以Jwt的形
式代替。
4、Spring Security/Shiro 是权限管理框架，关注 用户-角色-权限 关系，以及权限控制逻辑。主要用于系统内部的权限管理，如果
系统要接入单点登录，需要和内部已有的权限管理框架结合。


适合jwt的场景：有效期短，只希望使用一次
比如：用户注册之后发一封邮件激活，邮件链接包含几个特型：
能够标识用户，时效性，不能被篡改，一次性的，这种场合适合jwt

由于jwt具有一次性特型，单点登录和会话管理不适合jwt, 如果在服务器端存储jwt的状态，还不如使用session,基于session框架可以开箱即用，jwt需要自己实现逻辑。



基于session和基于jwt的方式的主要区别就是用户的状态保存的位置，session是保存在服务端的，而jwt是保存在客户端的。
jwt的优点：session需要做多机数据共享，通常可以存在数据库或者redis里面。而jwt不需要。
jwt的缺点：jwt的payload是使用base64编码的，并没有加密，因此jwt中不能存储敏感数据，session后端更加安全，
jwt是一次性的，无法中途废弃。



如果使用jwt作为会话管理，传统的cookie续签方式是框架自带的，session30分钟有效，如果有访问则刷新到30分钟；
要改变jwt的有效时间就是签发新的jwt一种方法是每次http请求返回新的，这种方式不优雅，每次加密有性能问题；还有一种方式redis存储过期时间，
但是redis引入了违背了jwt的初衷，硬生生变成有状态的了。


OAuth 就是一种授权机制。数据的所有者告诉系统，同意授权第三方应用进入系统，获取这些数据。系统从而产生一个短期的进入令牌（token），用来代替密码，供第三方应用使用。



































---------------------------------------------------------------------------------------------------------------
------------------------------------------Security.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Slf4j.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------

@一般简单的门面日志有slf4j和commons-logging(一般和log4j配合使用)
真正实现日志功能的有logback、log4j、jdklog等
slf4j引进三个jar:slf-api.jar+slf-log4j.jar+log4j.jar


@获取logger对象
门面方式：LoggerFactory.getLogger()
原始方式：Logger.getLogger()


@门面模式一般的原理
1)使用动态代理实现，根据类型代理类持有真实类的实例完成门面的转换；
2)slf4j模式，有一个ILoggerFactory,有不同的工厂实现类，启动初始化标志=success之后，StaticLoggerBinder类获取，
但是请注意，每种方式都有一个StaticLoggerBinder,但是只有一个引进来。
---------------------------------------------------------------------------------------------------------------
------------------------------------------Slf4j.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Socket&NIO&Netty.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------


@核心概念
1)同步阻塞的B10(连接数目比较小且固定的架构)传统的socket,一个用户的请求启动一个线程开销很大，
线程池能避免不必要的开销，几百个连接OK,对于并发量要求较高的企业不可取的。一个连接一个线程。

2)同步非阻塞的I0(连接数目多且连接比较短（轻操作)的架构)
IO采用的是一种多路复用的机制，利用单线程轮询事
件，高效定位就绪的Channel来决定做什么，只是Select阶段是阻塞式的，
能有效避免大量连接数时，频繁线程的切换带来的性能或各种问题。
也就是说，这个时候，已经不是一个连接就要对应一个处理线程了，而是有效的请求，对应一个线程，当连接没有数据时，是没有工作线程来处理的。
BIO与NIO一个比较重要的不同，是我们使用BIO的时候往往会引引入多线程，每个连接一个单独的线程；而O则是
使用单线程或者只使用少量的多线程，每个连接共用一个线程。一个Selector一个线程，轮询channel,
一个连接中的一个有效请求才是一个线程。但是，可能会等待后端应用的资源(JDBC连接等)，其实这个线程就被阻塞了，当并发上来的话，还是会有BO一样的问题

3)异步非阻塞的A10(连接数目多且连接比较长（重作)的架构)个解决NlO后面阻塞的痛点，一般是2.0，read/write方法，会返回一个带回调函数的对象，当执行完读取/写入操作后，直接调用回调函数。
AsynchronousSocketChannel
AsynchronousServerSocketChannel
AsynchronousFileChannel
AsynchronousDatagramChannel
BIO是一个连接一个线程。
NIO是一个请求一个线程。
AIO是一个有效请求一个线程。


@一些协议
7应用层
例如HTTP、SMTP、SNMP、FTP、Telnet、SIP、SSH、NFS、RTSP、XMPP、Whois、ENRP
6表示层
5会话层例如BSD sockets
4传输层例如TCP、UDP
3网络层例如IP
2数据链路层例如以太网、令牌环
1物理层例如线路、无线电


@tcp三次握手四次挥手
手机能够使用联网功能是因为手机底层实现了TCP/IP协议，可以使手机终端通过无线网络建立TCP连接.
三次握手的目的是连接服务器指定端口，建立TCP连接，并同步连接双方的序列号和确认号并交换TCP窗口大小信息.在socket编程中，客户端执行connecto时。将触发三次握手。

(1)A首先向B发起连接，这时TCP头部中的SYN(头部)=1，seq=x(随机)，消息发送后，SYN_SENT状态；
(2)B收到A的连接请求后，SYN=1,ACK=1,ack=x+1,seq=y(随机)，进入SYN_RCVD状态。
(3)A收到B的确认消息后，ACK=1,ack=y+1,seq=x+1,此时A进入ESTABLISHED状态，当B收到A的确认后，
  B也进入ESTABLISHED状态，至此TCP成功建立连接。主要防止已经失效的连接请求报文突然又传送到了服务器，从而产生错误所以要3次。

(1)客户端A发送一个FIN=1,seq=m到服务器；
(2)服务器B收到这个FIN,ACK=1,ack=m+1,seq=n;
(3)服务器B关闭与客户端A的连接，FIN=1,ack=m+1,seq=w;
(4)客户端A发回ACK报文确认，ACK=1,ack=W+1,seq=m+1;


@DDOS攻击-Syn攻击
Syn攻击就是攻击客户端在短时间内伪造大量不存在的IP地址，向服务器不断地发送syn包，服务器确认包，并等待客户的确认，由于源地址是不存在的，
服务器需要不断的重发直至超时，这些伪造的SYN包将长时间占用未连接队列，正常的SYN请求被丢弃，目标系统运行缓慢，严重者引起网络堵塞甚至系统瘫痪。一个典型的DDOS攻击。
检测SYN攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次SYN攻击.在Linux下可以如下命令检测是否被Syn攻击
netstat -n-p TCP I grep SYN_RECV
SynAttackProtect保护机制、SYN cookies:技术防范Dns攻击



@为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？
建立连接的时候，服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。
而关闭连接时，服务器收到对方的FI报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FI报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。


@套接字(socket)
通信的基石，是支持TCP/IP协议的网络通信的基本操作单元。它是网络通信过程中端点的抽象表示，包
含进行网络通信必须的五种信息：连接使用的协议，本地主机的P地址，本地进程的协议端口，远地主机的IP地址，远地进程的协议端口。
创建Socketi连接时，可以指定使用的传输层协议，Socket可以支持不同的传输层协议(TCP或UDP),当使用TCP协议进行连接时，该Socketi连接就是一个TCP连接。
有个比较形象的描述：HTTP是轿车，提供了封装或者显示数据的具体形式；Socket是发动机，提供了网络通信的能力。
我们平时说的最多的socket是什么呢，实际上socket是对TCP/IP协议的封装，Socket本身并不是协议，而是一个调用接口。



@WebSocket
首先，客户端发起http请求，经过3次握手后，建立起TCP连接；http请求里存放WebSocket支持的版本号等信息，如：Upgrade、Connection、WebSocket-Version等；
然后，服务器收到客户端的握手请求后，同样采用HTTP协议回馈数据；
最后，客户端收到连接成功的消息后，开始借助于TCP传输信道进行全双工通信。


@通道Channel
对数据的读取和写入要通过Channeli通道。通道不同于流的地方就是通道是双向的，用于读、写和同时读写操作。
底层的操作系统的通道一般都是全双工的，全双工的Channell比流能更好的映射底层操作系统的APl。


@多路复用器Selector
Selector提供选择已经就绪的任务的能力：
Selector轮询注册在其上的Channel,如果某个Channel发生读写请求并且Channeli就处于就绪状态，会被Selector轮询出来，然后通过SelectionKey可以获取就绪Channell的集合，
        进行后续的/O操作。（同步）一个Selectori可以同时轮询多个Channel,因为JDK使用了
epollO代替传统的select实现，所以没有最大连接句柄1024/2048的限制。所以，
只需要一个线程负责Selector的轮询，就可以接入成干上万的客户端。（非阻塞）


@为何netty:基于NIO,不是AlO
AIO还有个缺点是接收数据需要预先分配缓存，而不是IO那种需要接收时才需要分配缓存，所以对连接数量非常大
但流量小的情况，内存浪费很多个在Linux.系统上，AIO的底层实现仍使用EPOLL,与Nl-同，因此在性能上没有明显的优势；Windows的AlO底层实现良好，但是Netty开发人员并没有把Windows作为主要使用平台考虑


@netty:步骤
创建两个NIO线程组，一个专门用于网络事件处理（接受客户端的连接)，另一个则进行网络通信的读写；
ServerBootstrap对象，组装配置参数
Bootstrap绑定Channellnitializer:指向handler,绑定端口号；
SO_BACKLOG=服务器端TCP内核维护有两个队列，我们称之为A(第一次握手)、B队列（第三次握手）；
当A、B队列的长度之和大于ChannelOption.SO_BACKLOG时，新的连接将会被TCP内核拒绝


@粘包/拆包
他们是连成一片的，没有分界线，TCP底层并不了解上层业务数据的具体含义，它会根据TCP缓冲区的具体情况进行包的划分消息定长，空位补空格；在包尾特殊字符；消息头（定义长度)和消息体；
1)分隔符类：DelimiterBasedFrameDecoder(自定义分隔符)
2)定长：FixedLengthFrameDecoder


@netty:实用
有了Netty,你可以实现自己的HTTP服务器，FTP服务器，UDP服务器，TCP服务器，WebSocket服务器，Redis的Proxy.服务器。
关键就是码解码协议的选择。编码解码协议是HTTP议就是HTTP服务器，协议Redis协议成了Redis服务个协议是WebSocket成了WebSocket服务器


@传统的HTTP服务器的原理
创建一个ServerSocket,监听并绑定一个端口一系列客户端来请求这个端口服务器使用Accept,获得一个来自客户端的Socket连接对象启动一个新线程处理连接读Socket,得到字节流解码协议，
得到Http请求对象处理Http请求，得到一个结果，封装成一个HttpResponse对象编码协议，将结果序列化字节流写Socket,将字节发给客户端继续循环步骤3HTTP服务器之所以称为HTTP服务器，
是因为编码解码协议是HTTP协议，如果协议是Redis协议，那它就成了Redis服务器，如果协议是WebSocket,那它就成了WebSocket服务器，等等。
使用Netty你就可以定制编解码协议，实现自己的特定协议的服务器。上面我们说的是一个传统的多线程服务器，这个也是Apache处理请求的模式。在高并发环境下，线程数量可能会创建太多，操作系统的任务调度压力大，系统负载也会比较高。


@tomcat和netty什么关系
Tomcat是基于Http协议的，他的实质是一个基于http协议的web容器，但是Netty不一样，他能通过编程自定义各种协议，因为netty能够通过codec自己来编码/解码字节流，完成
类似redis访问的功能，这就是netty和tomcat:最大的不同。
有人说netty的性能就一定比tomcat性能高，其实不然，tomcat.从6.个式，并发性能得到了很大提高，特别是arp模式。


@nettyl自己的HTTP服务器
public void initChannel(SocketChannel ch)throws
Exception
ChannelPipeline pipeline ch.pipelineO;
pipeline.addLast(new HttpServerCodecO);
pipeline.addLast(new HttpServerHandlerO);
}
/响应HTML
String responseHtml ="<html><body>Hello,"name +
</body></html>";
bytel responseBytes responseHtml.getBytes("UTF-8");
int contentLength responseBytes.length;
/构造FullHttpResponse对象，FullHttpResponse包
含message body
FullHttpResponse
response
new
DefaultFullHttpResponse(HttpVersion.HTTP_1_1,
HttpResponseStatus.OK,
Unpooled.wrappedBuffer(responseBytes));
response.headers).set("Content-Type",
"text/html;
charset=utf-8");
response.headers).set("Content-Length",
Integer.toString(contentLength));
ctx.writeAndFlush(response);


@netty和spring mvc
netty负责建立一个http服务器，持有DispatcherServlet对象，封装在HttpRequestHandler中；spring mvc作用是接收到http请求的时候统一被
HttpRequestHandler拦截，通过反射机制调用action.(业务调度，线程池)个


@建立http服务器捕步骤
http协议是基于TCP通信的协议，因此，实现web服务器的第一步至少要能实现两个主机不同进程之间的TCP通信。比如说tomcat源码：JloEndpoint.bind)方法
serverSocket
serverSocketFactory.createSocket(getPort),
getBacklogO,getAddressO);


@手写tomcat
bio
bio多线程
nio模式
netty模式


@netty:实现服务器
UDP服务器：serverBootstrap.channel(NioDatagramChannel.class)
TCP服务器：serverBootstrap.channel(NioServerSocketChannel.class);
HTTP服务器：
serverBootstrap.channel(NioServerSocketChannel.class);
sc.pipeline).addLast(new HttpResponseEncoderO);
sc.pipeline).addLast(new HttpRequestDecoder));
FTP服务器：
ch.pipeline).addLast(new ObjectEncoderO);
ch.pipeline).addLast(new
ObjectDecoder(Integer.MAX_VALUE,
ClassResolvers.weakCachingConcurrentResolver(nul


@netty:实现kafka等消息队列
个RocketMQ用netty:实现






netty启动后经过httpServer编码和解码，就是http服务器
tomcat 底层经过比较复杂的编排 启动的时候解析配置文件，启动netty
解析特定目录下的webapps,按照web的规则解析web.xml,初始化spring context.



netty中，通讯的双方简历链接后，会把数据按照ByteBuf的方式进行传输，例如http协议中，就是通过HttpRequestDecoderr对ByteBuf数据流进行处理，
转换成http对象，实现的原理就是 Encoder把java对象转换成ByteBuf进行传输，通过Decoder把ByteBuf转换成java对象进行；



Netty默认是ByteBuf编码，如果需要自定义编码的话，可以直接cx.writeAnfFlush(entity);



使用netty实现代理服务器的思路：


---------------------------------------------------------------------------------------------------------------
------------------------------------------Socket&NIO&Netty.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Spring Boot.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------

1初衷理解
摆脱XML配置文件，向bean进军，摆脱Spring框架中各种复杂的配置，衍生了Java Config。
同时它集成了大量常用的第三方库配置（例如Jackson,JDBC,Mongo,Redis,Mail等等)。
嵌入的Tomcat,无需部署WAR文件。Spring Boot并不是对Spring功能上的增强，而是提供了一种快速使用Spring的方式。


2一些重要注解
@SpringBootApplication 
@Configuration
@EnableAutoConfiguration 
@ComponentScan
@Configuration:启动配置，refresh(-
>invokeBeanFactoryPostProcessors-
>ConfigurationClassPostProcessor-
>ConfigurationClassParser.processConfigurationClass方法进行扫描
@Component:通用的组件，告诉lOC是一个bean,需要被管理；配置@ComponentScan扫描基础包下面的class;
@ConditionalOnProperty:name/havingValue env中有这么一个属性值的时候生效
@ConfigurationProperties:prefix=kafka.producer代表env中的属性和配置的属性一一映射，有前缀
@EnableConfigurationProperties个使@ConfigurationProperties生效，并从lOC容器中狄bean



4 @EnableAutoConfiguration核心
@EnableAutoConfiguration注解
@lmport((AutoConfigurationlmportSelector.class)
在这个类(AutoConfigurationlmportSelector)里面实现了自动配置的加载
在SpringBootr中我们经常可以引入一些startert包来集成一些工具的使用，比如spring-boot-starter-data-redis。就是用自动配置实现的。
比如RedisTemplate,KafkaTemplate其实他已经装载了org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration,


@EnableConfigurationProperties(KafkaProperties.class)
@Bean
@ConditionalOnMissingBean(KafkaTemplate.class)
public KafkaTemplate<?,?kafkaTemplate(
@ConfigurationProperties(prefix ="spring.kafka")
public class KafkaProperties
看出来了，如果prefix不是他默认的，只要新建一个覆盖他就可以；
问题来了，如果有auto的，也有自定义的，那么一个容器中有2个bean都叫做kafkaTemplate?
答：ConditionalOnMissingBean(KafkaTemplate.class)这个已经起作用了，被覆盖了，先加载配置后置处理器，加载自动配置。


@Bean
@ConditionalOnMissingBean(KafkaTemplate.class)
public KafkaTemplate<?,?kafkaTemplate(
举例：新建一个ZookeeperAutoConfigurationMETA-INF/spring.factories中加入
org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.fayayo.fim.zookeeper.ZookeeperAutoConfiguration


5 Servlet/监听器/过滤器/拦截器
@ServletComponentScan
@WebServlet、@WebFilter.、@WebListener


6几个重要监听器
CommandLineRunner:和ApplicationRunner-一样的，项目服务启动完成的时候就做一些事
SpringApplicationRunListener:开始，环境加载，上下文加载，结束事件
ApplicationListener::带一个事件，ApplicationEvent
ApplicationContextlnitializer<ConfigurableApplicationCo
ntext>:启动事件


7源码集合
(1)查看《实战问题》解读启动源码，和spring:无缝对接；
(2)如果不设置的话默认扫描@ComponentScanj注解所在类的同级类和同级目录下的所有类，
所以对于一个SpringBoot]项目，一般会把入口类放在顶层目录中，这样就能够保证源码目录下的所有类都能够被扫描到。


8 Spring全家桶
1.spring framework
也就是我们经常说的spring框架，包括了ioc依赖注入，Context.上下文、bean管理、springmvc等众多功能模块，其它spring.项目比如spring boot也会依赖spring框架。

2.spring boot它的目标是简化Spring应用和服务的创建、开发与部署，简化了配置文件，使用嵌入式web服务器，含有诸多开箱即用的微服务功能，可以和spring cloud联合部署。
Spring Boot的核心思想是约定大于配置，应用只需要很少的配置即可，简化了应用开发模式。

3.Spring Data是一个数据访问及操作的工具集，封装了多种数据源的操作能力，包括：jdbc、Redis、MongoDB等。

4.Spring Cloud是一套完整的微服务解决方案，是一系列不同功能的微服
务框架的集合。Spring Cloud基于Spring Boot,简化了分布式系统的开发，集成了服务发现、配置管理、消息总线、负载均衡、断路器、数据监控等各种服务治理能力。
比如sleuth提供了全链路追踪能力，Netflix套件提供了hystrix熔断器、zuul网关等众多的治理组件。config组件
提供了动态配置能力，bus组件支持使用RabbitMQ、kafka、Activemq等消息队列，实现分布式服务之间的事件通信。

5.Spring Security
主要用于快速构建安全的应用程序和服务，在Spring Boot和Spring Security OAuth2的基础上，可以快速实现常见安全模型，如单点登录，令牌中继和令牌交换。
你可以了解一下oauth2授权机制和jwt认证方式。oauth2是一种授权机制，规定了完备的授权、认证流程。JWT全称
是JSON Web Token,是一种把认证信息包含在token中的认证实现，oauth2授权机制中就可以应用jwt来作为认证的具体实现方法。



---------------------------------------------------------------------------------------------------------------
------------------------------------------Spring Boot.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Spring Cloud.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------


1服务注册与发现
注册是指服务端注册远程服务，发现是指客户端发现服务；
注册中心，用于服务端注册远程服务以及客户端发现服务；
服务端，对外提供后台服务，将自己的服务信息注册到注册中心；客户端，从注册中心获取远程服务的注册信息，然后进行远程过程调用；
Spring Cloud:和云计算没有关系，只是一个基于Spring
Boot的快速构建分布式系统的工具集。
Spring Cloud Config和Apollo差不多，分布式配置；
Spring Cloud Bus:实际上是一个mq,和Spring Cloud Config相互协作实现热推送，使配置实时更新。


2 Spring Cloud Config和Archaius
Spring Booti已经提供了管理外部化配置的工具，为什么还要设置不同的机制呢？
因为Archaius提供了一些其他任何配置框架都没有考虑过的方便有趣的功能。其中的一些关键点是：
动态和类型属性在属性改变时调用的回调机制
动态配置源（如URL,JDBC和Amazon DynamoDB)的
实现；
Spring Boot Actuator或JConsole可以访问的JMXMBean,用于检查和操作属性动态属性验证


3 Consul和Docker
服务注册与服务发现是在分布式服务架构中常常会涉及到的东西，业界常用的服务注册与服务发现工具
有ZooKeeper、etcd、Consul和Eureka。Consul的主要功能有服务发现、健康检查、KV存储、安全服务沟通和多数据中心。


4 Spring Cloud Sleuth:
服务链路追踪，日志收集工具包，封装了Dapper和log-based:追踪以及Zipkin和HTrace操作，为SpringCloud应用实现了一种分布式追踪解决方案。
链路追踪组件有Googlel的Dapper,Twitter的Zipkin(还有一个强大的雪花算法-分布式D),以及阿里的
Eagleeye(鹰眼)等，它们都是非常优秀的链路追踪开源组件。
Spring Cloud Sleuth中集成Zipkin


5 Spring Cloud Netflix
(1)一般的微服务架构需要的功能或使用场景：
我们把整个系统根据业务拆分成几个子系统。每个子系统可以部署多个应用，多个应用之间使用负载均衡。
需要一个服务注册中心，所有的服务都在注册中心注册，负载均衡也是通过在注册中心注册的服务来使用一定策略来实现。
所有的客户端都通过同一个网关地址访问后台的服务，通过路由配置，网关来判断一个URL请求由哪个服务处理。请求到服务上的时候也使用负载均衡。
服务之间有时候也需要相互访问。例如有一个用户模块，其他服务在处理一些业务的时候，要获取用户服务的用户数据。
需要一个断路器，及时处理服务调用时的超时和错误，防止由于其中一个服务的问题而导致整体系统的瘫痪。还需要一个监控功能，监控每个服务调用花费的时间等。

(2)Netflixi满足需求
Eureka,服务注册和发现，它提供了一个服务注册中心、服务发现的客户端，还有一个方便的查看所有注册的服务的界面。
Zuul,网关，所有的客户端请求通过这个网关访问后台的服务。他可以使用一定的路由配置来判断某一个URL由哪个服务来处理。并从Eureka获取注册的服务来请求。
Ribbon,即负载均衡，Zuul网关将一个请求发送给某一个服务的应用的时候，如果一个服务启动了多个实例，就会通过Ribbon:来通过一定的负载均衡策略来发送给某一个服务实例。
Feign,服务客户端，服务之间如果需要相互访问，可以使用RestTemplate,也可以使用Feign客户端访问。它默认会使用Ribbon:来实现负载均衡。
在使用@FeignClient注解的时候是默认使用了ribbon进行客户端的负载均衡的默认的是随机的策略，那么如果我们想要更改策略的话，需要修改消费者yml中的配置
Hystrix,监控和断路器。我们只需要在服务接口上添加Hystrix标签，Hystrix Dashboard是监控面板。
Turbine,监控聚合，使用Hystrix.监控，我们需要打开每一个服务实例的监控信息来查看。



6 Eureka注册中心和zk,etcd不同的地方
虽然都是服务注册中心，但是EurekaServer是一个springboot应用，BS架构，zk是cs模式，安装即可。
推荐使用@EnableDiscoveryClient代替
@EnableEurekaClient注解，注册中心选型改变为Eureka,ZK,ConsulE时不修改代码；
spring cloud config:和apollo之间，一个是需要自己建工程，依赖spring cloud的jar;另外apollo:是开源的。



7一些重点
Hystrix防止其中一个Hello world挂掉后，导致系统发生连锁超时失败。
5秒之内发生20次失败是Hystrix定义的缺省值，链路就会被处于open状态，open的链路阻断了瀑布式错误。熔断
时间窗到了断路器有自我检测并恢复的能力。
Fallbacks可以组成廷式结构，Fallback相当于是降级採作。
一般使用：总开关@EnableCircuitBreaker;确认失败的方法：
@HystrixCommand(fallbackMethod"serviceFailure")
Feign使用：@FeignClient(name="SERVICE-HELLOWORLD",
fallback=HelloWorldServiceFailure.class)
人机鉴权/机机鉴权~为了解决鉴权重复的问题，使业务结点本身只关心实现自己的业务，将对权限的处理抽离到上层。外部客户先请求到Zuul上.
@EnableZuulProxy,标识启动zuul网管控制



8服务聚合
我们在网关开发的过程中，除了有鉴权，参数和返回值校验之外，比较切实关注的一点就是我们有的需求是需要在
网关处把不同的服务进行聚合，因为不同的服务直接为了保证职责单一，复杂的跨数据源
的操作在单服务中就是非常困难的，所以这些工作可以交由网关处进行处理，处理的方式
呢无非就是同时调用不同的服务，然后拿到结果之后做一些数据遍历结果组合，最终返回给调用方，下面的是两种一步的处理方式，大家可以参考这个思路。应为同步调用的话不是很推介，应为调用的远
端服务返回的等待时间，同步的话很可能导致调用网关调用方断开连接。
return Observable.zip(
this.zuulAggregationService.getOrderByorderld(id),
this.zuulAggregationService.getuptoken(id),
(x,y)->{
Map result=new HashMap<>);
result.put("qiniutoken",x);
result.put("orderid",y);
return result;
}
);



9负载均衡ribbon
目前主流的LB方案可分成两类：一种是集中式LB,即在服务的消费方和提供方之间使用独立的LB设施（可以是硬件，如F5,也可以是软件，如nginx),
另一种是进程内LB,将LB逻辑集成到消费方，消费方从服务注册中心获知有哪些地址可用，然后自己再从这些地
址中选择出一个合适的服务器。Ribbon就属于后者，它只是一个类库，集成于消费方进程，消费方通过它来获取到服务提供方的地址。
Ribbon其实就是一个软负载均衡的客户端组件，他可以和其他所需请求的客户端结合使用，和eureka结合只是其中的一个实例。

@Bean @LoadBalanced RestTemplate restTemplate({
return new RestTemplateO;
那么如果被调用端有多个服务提供，那么自动就有了客户端负载均衡的效果。使得使用RestTemplate的时候就非常的方便，在这里不得不说spring的这些大师真的很厉害。看后面的源码实现。






10源码实现
(1)Netfix-Eureka源码

eureka-core.jar
1.com.netflix.eureka.cluster-与peer节点复制(replication)相关的功能
2.com.netflix.eureka.lease-即”租约”，用来控制注册信息的生命周期（添加、清除、续约）
3.com.netflix.eureka.registry-存储、查询服务注册信息(关键，存储注册信息、)
4.com.netflix.eureka.resources-RESTfull风格中的”R”,即资源。相当于SpringMVC中的Controller
5.com.netflix.eureka.transport-发送HTTP请求的客户端，如发送心跳
6.com.netflix.eureka.aws-与amazon AWs服务相关的类
eureka-client.jar:给客户端用，服务注册，比如说
Provider引用这个包发送http进行注册；Eureka客户端，微服务通过该客户端与Eureka进行通讯，屏蔽了通讯细节
spring-cloud-netflix-eureka-server.jar:真正的服务注册中心，包含core包含了servlet应用的基本配置，如web.xml。构建成功后在该模块下会生成可部署的war包
EurekaBootStrap实现了ServletContextListener
public void contextlnitialized(ServletContextEvent event)
/读取配置信息
initEurekaEnvironmentO;
/初始化Eureka Client(用来与其它节点进行同步)
/初始化server
initEurekaServerContext);
Eureka是一个纯正的Servlet.应用，而Spring Boot使用的
是嵌入式Tomcat,因此就需要一定的胶水代码让Eureka跑在Embedded Tomcat中。
EurekaServerInitializerConfiguration调用了
EurekaServerBootstrap.contextInitialized,该类实现了
ServletContextAware(拿到了tomcat的ServletContext对象)
在Spring容器初始化该组件时，Spring调用其生命周期方法startO从而触发了Eureka的启动.
一个分布式系统不可能同时满足C(一致性)、A(可用性)和P(分区容错性)。由于分区容错性在是分布式系统中必须
要保证的，因此我们只能在A和C之间进行权衡。
在此Zookeeper保证的是CP,而Eureka则是AP。高可用架构，副本Replica.服务注册：DiscoveryClient,服务提供者Provideri引用这
个包在DiscoveryClient类有一个服务注册的方法registerO,该方法是通过Http请求向Eureka Client注册。
Eureka Client一启动（不是启动完成），不是立即向Eureka Server注册，它有一个延迟向服务端注册的时间，通过跟踪源码，可以发现默认的延迟时间为40秒。
各个服务内的Eureka Client组件，默认情况下，每隔30秒会发送一个请求到Eureka Server,来拉取最近有变化的服务信息

心跳机制：各个Eureka Client每隔30秒会发送一次心跳到Eureka Server,如果某个Eureka Client很长时间没有发送心跳给Eureka Server,那么就说明这个服务实例已经挂了

注册表存储结构：
有一套大型的分布式系统，一共100个服务，每个服务部署在20台机器上，机器是4核8G的标准配置。部署了100*20=2个服务实例，有2台机器。
每台机器上的服务实例内部都有一个Eureka Client组件，每隔30秒请求一次Eureka Server:拉取变化的注册表；每
隔30秒发送一次心跳请求给Eureka Server。计算出：每秒150次，每分钟8次，每天1152万次，
每天千万级访问量Eureka Server是如何保证轻松抗住这每秒数百次请求，每天干万级请求的呢？

AbstractInstanceRegistry
private final ConcurrentHashMap<String,Map<String,
Lease<Instancelnfo>>>registry
new ConcurrentHashMap<String,Map<String,
Lease<Instancelnfo>>>0;
Eureka Server的注册表直接基于纯内存，即在内存里维护了一个数据结构，各个服务的注册、服务下线、服务故障，全部会在内存里维护和更新这个注册表，
注册表和心跳时间直接存储在内存里面，服务器对内存的要求很高。
ConcurrentHashMap的key就是服务名称，比
如“inventory-service”,就是一个服务名称；value是心跳，主机ip等信息单台4核8G的机器，处理纯内存操作，哪怕加上一些网络的开销，每秒处理几百请求也是轻松加愉快的。
Eureka Server为了避免同时读写内存数据结构造成的个冲突问题，还采用了多级缓存机制来进一步提升服务请求的响应速度。

拉取:首先从ReadOnlyCacheMap,ReadWriteCacheMap里，如果还没有，就从内存中获取实际的注册表数据。
变更：会在内存中更新变更的注册表数据，下次有服务拉取注册表，又会从内存中获取最新的数据了，同时填充各个缓存。Eureka作为微服务注册中心可以承载大规模系统每天干万级访问量的原理。




(2)Spring Cloud Config+Bus源码
spring-cloud-config-server.jar,spring-cloud-config-
client.jar
EnvironmentRepository,提供配置的读取,EnvironmentRepository有多种实现，基于JDBC、SVN、GIT等等；
默认使用MultipleJGitEnvironmentRepository(可以配置多个地址的GT数据源).
ConfigClientAutoConfiguration
与ConfigServiceBootstrapConfiguration。他们被自动引入进我们的容器中作为Bean。


(3)Spring Cloud Sleuth+Zipkin源码分析
Span:基本工作单元，发送一个远程调度任务就会产生一个Span,Span是一个64位D唯一标识的，Trace是用另一个64位D唯一标识的，Span还有其他数据信息，比如摘要、时间戳事件、Span的lD、以及进度D。
Trace:一系列Span组成的一个树状结构。请求一个微服务系统的API接口，这个AP接口，需要调用多个微服务，调用每个微服务都会产生一个新的Span,所有由这个请求产生的Span组成了这个Trace。


(4)Ribbon源码分析
纯属客户端负载均衡
@Bean
@LoadBalanced
public RestTemplate restTemplate){
return new RestTemplate);
}
这么简单的代码就实现了？怎么实现的额？
LoadBalancerClient

第一个，Servicelnstance choose(String serviceld);从方法名上就可以看出，是根据传入的serviceld(服务名)，
从负载均衡器中选择一个服务实例，服务实例个
Servicelnstance类来表示。
第二个，execute方法，使用从负载均衡器中选择的服务实例来执行请求内容。
第三个，URI reconstructURI(Servicelnstance instance,
URI original);方法，是重新构建一个URl的，还记得我们
在代码中，通过RestTemplate请求服务时，写的是服务名吧，这个方法就会把这个请求的URI进行转换，返回
host+port,通过host+port的形式去请求服务。

我们在RestTemplate上添加了@LoadBalanced注解，RibbonLoadBalancerClient就会配置到这
个RestTemplate实例上。
LoadBalancerAutoConfiguration自动'配置LoadBalancer的在自动配置类中，对restTemplate实例添加了
LoadBalancerlnterceptor拦截器。所以，当
用restTemplate发送http请求时，就会执行这个拦截器的
intercept方法。
RibbonLoadBalancerClient中的execute方法：服务名作
为serviceld字段传进来，先通过getLoadBalancer:获取
loadBalancer,再根据loadBalancer获取server,下面是getServe
如果loadBalancer为空，就直接返回空，否则就调用loadBalancer的chooseServer
return rule.choose(key);根据负载均衡规则选择一个服务器执行逻辑；
构造DynamicServerListLoadBalancer:实例的时候，就会启动一个定时任务了，一开始先获取服务列表，之后每隔三十秒获取一次。
负载均衡时，就是通过负载均衡算法在实例列表中选择一个，发送请求。



(5)Zuul源码分析
zuul,在SpringCloud中充当服务网关的角色，它包含了请求路由，过滤，安全等功能，可以说是我们web应用的“安保人员”，保证了我们“微服务园区”的安全，
那么zuul是如何实现路由和过滤等功能的呢。Zuul是在云平台上提供动态路由，监控，弹性，安全等边缘服务的框架。
1.当客户端请求过来首先会到"pre”filters这样的一个前置过滤器做一些处理，然后调用自定义的过滤器
2.前置过滤器执行完了之后会调用“routing”filter过滤器，看名字都知道这是做路由分发的过滤器
3.在路由的过程中出现了异常，那么会走“error”filters过滤器，然后再走“post"filters过滤器，或者正常路由完成也会走到“post”filters
4."post"filters过滤器负责处理响应，最后把结果响应给客户端

EnableZuulProxy的注释告诉我们，这里设设置Zuul服务器端点和安装了一些过滤器，通过这些过滤器它可以转发请求到后端服务器
Zuul提供了一个框架，可以对过滤器进行动态的加载，编译，运行。过滤器之间没有直接的相互通信。他们是通过
一个RequestContext的静态类来进行数据传递的。
RequestContext类中有ThreadLocal变量来记录每个Request所需要传递的数据。过滤器是由Groovy写成。这些过滤器文件被放在ZuulServer.上的特定目录下面。Zuul会定期轮询这些目录。修
改过的过滤器会动态的加载到Zuul Server中以便于request使用。

核心代码ZuulServlet:
@Override
public
void service(javax.servlet.ServletRequest
servletRequest,
javax.servlet.ServletResponse
servletResponse)throws ServletException,lOException
try{
zuulRunner.preRouteO;
zuulRunner.routeO;
zuulRunner.postRoute();
catch (ZuulException e){
zuulRunner.error(e);
postRoute();
return;
}
}
private ZuulRunner zuulRunner;
EnableZuulProxy注解，Application)启动的时候会自动加载ZuulProxyAutoConfiguration:这个类

ZuulServlet是在哪里加载起来的呢？
org.springframework.cloud.netflix.zuul.web.ZuulControll
er
public
class
ZuulController
extends
ServletWrappingController
public ZuulController({
setServletClass(ZuulServlet.class);
setServletName("zuul");
setSupportedMethods((String)null);/Allow
all
ZuulServerAutoConfiguration'配置了
@Bean
public ZuulController zuulController{
return new ZuulController);
}
ZuulController是一个spring-mvc;
@ConfigurationProperties("zuul")
public class ZuulProperties
这里主要把appli*xml里面的zuul属性注入到ZuulProperties类中
Filter是在哪里被加载的呢？
ZuulFilterConfiguration中的private Map<String,
ZuulFilter>filters;
for (Map.Entry<String,ZuulFilter>entry
this.filters.entrySet(){
filterRegistry.put(entry.getKey0,
entry.getValueO);
}




(6)Hystrix源码分析
开启方法：1)启动类添加@EnableHystrix注解；2)方法上添加@HystrixCommand注解，并指定fallback的方法。
@EnableHystrixi引|入了@EnableCircuitBreaker注解命令模式
Hystrix使用命令模式（继承HystrixCommand类）来包裹具体的服务调用逻辑(run方法)，并在命令模式中添加了服务调用失败后的降级逻辑(getFallback)
自动配置HystrixAutoConfiguration(主要是hystrix的健康检查的配置)
@Bean
@ConditionalOnEnabledHealthIndicator("hystrix")
public HystrixHealthlndicator hystrixHealthlndicatorO{
return new HystrixHealthlndicator);
自动配置HystrixCircuitBreakerConfiguration。
@Bean
public
HystrixCommandAspect
hystrixCommandAspectO{
return new HystrixCommandAspect);
}
/*
*/
@Pointcut("@annotation(com.netflix.hystrix.contrib.java
nica.annotation.HystrixCommand)")
/*
*/
public void
hystrixCommandAnnotationPointcut
/**/
/**/
/**/
/*
*/
@Pointcut("@annotation(com.netflix.hystrix.contrib.java
nica.annotation.HystrixCollapser)")
/*
*/
public void
hystrixCollapserAnnotationPointcut(这个Aspect就是利用AOP切面对HystrixCommand、
HystrixCollapser两种注解的方法进行扩展处理。我们在方法上添加@HystrixCommand注解，就会经过这个切面，这个切面中定义了@Around(…)拦截所有请个
@Around("hystrixCommandAnnotationPointcut(
I
hystrixCollapserAnnotationPointcut()")
/*
*/
public Object
methodsAnnotatedWithHystrixCommand(ProceedingJoi
nPoint joinPoint)
/*throws Throwable
/**/{
}
public static ExecutionType getExecutionType(Class<?>
type){
if (Future.class.isAssignableFrom(type)){
return ExecutionType.ASYNCHRONOUS;
else if (isRxType(type)){
return ExecutionType.OBSERVABLE;
else
return ExecutionType.SYNCHRONOUS;
}
}
三种类型，如果返回值是Future就是异步，还有观察者和同步。
在创建MetaHolder的过程中，就会指定fallback方法。创
建完MetaHolder之后，就会根据MetaHolder创建Hystrixlnvokable。
这段代码里定义了后续真正执行HystrixCommand的
GenericCommand实例。这个方法的注释中说明了返回值，可以返回请求的结果,当失败的时候，则会通过getFallback)方法来执行一个回退操作。
final Future<R>delegate=toobservable).toBlockingO.toFuture);通过Future获取结果。Future来实现超时熔断。
result CommandExecutor.execute(invokable,
executionType,netaHolder);/命令模式在execute)方法中使用了rxjava的观察者模式并最终在这里计算出结果返回。当出现失败是，会调
用GenericCommand.java中的getFallBack)方法最终在process0方法中获取降级方法执行的结果，而如果没有设置降级方法则调用父类的getFallBack)方法，
父类的getFallBack方法会抛出一个找不到降级方法的异常。




(7)Feign源码分析
@SpringBootApplication
@EnableFeignClients
@EnableDiscoveryClient
public class Application
public static void main(String args throws
ClassNotFoundException
SpringApplication.run(Application.class,args);
}
}
@FeignClient(value ="xxx-server",configuration
FeignConfiguration.class)
public interface ConsumerSmsService extends
SMSService{
@RequestMapping(value ="/sms/smsMessage",
method RequestMethod.POST)
RespSMSDto sendSms(ReqSMSDto smsReqDto);
}
@EnableFeignClients->FeignClientsRegistrar->扫描name和configuration对所有的FeignClient生成对应的BeanDefinition注册到容器中自动配置类FeignAutoConfiguration建立一个FeignContext子容器或者说上下文，FeignClientFactoryBean.getObject方法，为ConsumerSmsService:接口生成代理类，底层使用HttpURLConnection,这个类继承于
URLConnection,执行接口获取结果。



(8)RestTemplate源码分析
RestTemplate:全部是以HttpClient方式请求的吗？通过源码不难看到，默认RestTemplate使用的
是SimpleClientHttpRequestFactory.工厂。追踪可见，默认它是以java.net下的HttpURLConnection方式发起的请求。
所以RestTemplate是支持多种方式发起请求的。查看该工程的实现类可知，支持包括HttpClient,OkHtt'

(8)RestTemplate源码分析
RestTemplate:全部是以HttpClient方式请求的吗？
通过源码不难看到，默认RestTemplate使用的是SimpleClientHttpRequestFactory.工厂。
追踪可见，默认它是以java.net下的HttpURLConnection方式发起的请求。
所以RestTemplate:是支持多种方式发起请求的。查看该工程的实现类可知，支持包括HttpClient,OkHttp等方式










Spring Boot	Spring Cloud
1.2.x	Angel版本
1.3.x	Brixton版本
1.4.x stripes	Camden版本
1.5.x	Dalston版本、Edgware版本
2.0.x	Finchley版本
2.1.x	Greenwich.SR2

Greenwich.SR2没有规定 spring-cloud-starter-eureka-server版本。
Brixton规定了所以下载成功。


springcloud注册：http.csf.disable();
defaultZone 一定要以 /{cotextPath}/eureka结尾。


<dependency>
			<groupId>org.springframework.cloud</groupId>
			<artifactId>spring-cloud-netflix-eureka-server</artifactId>
</dependency>
换成
<dependency>
			<groupId>org.springframework.cloud</groupId>
			<artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>
</dependency>




hystrix:
@服务熔断：
保险丝，服务器达到最大访问后，直接拒绝访问，然后调用降级的方法，（降级--熔断-恢复）
服务熔断的思想被提出来。类似现实世界中的“保险丝“，当某个异常条件被触发，直接熔断整个服务，而不是一直等到此服务超时。 
熔断的触发条件可以依据不同的场景有所不同，比如统计一个时间窗口内失败的调用次数。

@服务降级：
有了熔断，就得有降级。所谓降级，就是当某个服务熔断之后，服务器将不再被调用，此时客户端可以自己准备一个本地的fallback回调，返回一个缺省值。
 这样做，虽然服务水平下降，但好歹可用，比直接挂掉要强，当然这也要看适合的业务场景。
服务器超时，返回服务器忙，而不是直接给客户端error

@服务限流：
淘宝秒杀，严禁一窝蜂杀过来

@服务隔离：
雪崩效应，服务雪崩效应产生服务堆积在同一个线程池中，因为在同一个线程池中，所有请求全部到一个服务进行访问，这时候会导致其他
服务没有线程接收请求访问，所以就会产生服务雪崩效应。
每个服务接口互不影响，服务隔离有两种实现方式线程池方式、计数器，使用信号量和线程池方式s



http://127.0.0.1:9041/hystrix
输入 http://127.0.0.1:9015/content/hystrix.stream,点击Monitor Stream

Zuul1.基于servlet，BIO，性能低下
Zuul2巨大区别是基于异步和无阻塞框架，NIO。



config:
巨坑啊 ，只能写在bootstrap.xml里面，不能再application.properties,测试2小时发现这个问题  20200716


Sleuth:
 可以把结果汇总到Logstash,ZipKin ,消息中间件
 
 
 






 
 
 
 
---------------------------------------------------------------------------------------------------------------
------------------------------------------Spring Cloud.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Spring.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------

1@autowire注解的含义
aop扫描这个注解，从spring applicationContextr中获取这个bean,并且赋值给变量，所有需要依赖的bean在spring容器里面管理；


2 AutowireCapableBeanFactory
一般普通的JavaPojo都是由Spring来管理的，所以使用autowire注解来进行注入不会产生问题，但是有两个东西是例外的，
一个是Filter,一个是Servlet,这两样东西都是由Servlet容器来维护管理的，所以如果想和其他的Bean一样使
用Autowire来注入的话，是需要做一些额外的功夫的。
AutowireCapableBeanFactory
autowireCapableBeanFactory
WebApplicationContextUtils.getRequiredWebApplication
Context(event.getServletContext)).getAutowireCapable
BeanFactoryO;
autowireCapableBeanFactory.autowireBean(this);


3 HierarchicalBeanFactory
父子关系的bean,可以获取父bean;举例
BeanFactory parent new XmlBeanFactory(r
FileSystemResource("build/parent.xml"));
BeanFactory child new XmlBeanFactory(new
FileSystemResource("build/beans.xml"),parent);
SimpleTarget target1
(SimpleTarget)
child.getBean("target1");
System.out.println(target1.getValO);


4 PointCut切点和Join Point接入点就是从哪里接入？例如方法执行、类初始化、异常处理；
切点运行在任何切点匹配到的接入点上，切点表达式匹配接入点，.*save.*表示所有以save开头的方法都是切入点；


5 Advicel的先后执行顺序
around before -before advice --target method -around
after-after--afterReturning/afterThrowing


6引入和织入
引入Introduction方法，给对象增加方法或者属性，@DeclareParents注解引|入新的方法来增强功能；
织入Weaving.对象，将Advice:织入join point的这个过程


7 spring事务
Spring并不直接管理事务，而是提供了多种事务管理器，他们将事务管理的职责委托给Hibernate或者JTA等持久化机制所提供的相关平台框架的事务来实现。
TransactionDefinition-事务隔离级别/传播特性/超个间等传参-PlatformTransactionManager---
JPA/JTA/JDBC/HIBERNATE
JPA和Hibernate
JPA Java Persistence APl,是EJB3规范中负责对象持久化的应用程序编程接口(ORM接口)，它定义一系列的注释。这些注释大体可分为：类级别注释、方法级别注释、字段级别注释。
给实体类添加适当的注释可以在程序运行时告诉Hibernate如何将一个实体类保存到数据库中以及如何将数据以对象的形式从数据库中读取出来。
JPA是标准接口，Hibernate:是实现。



8 遇到异步的话，注解和代码转换
@Autowired
protected DataSource TransactionManager txManager;
DefaultTransactionDefinition
def
new
DefaultTransactionDefinitionO;
def.setPropagationBehavior(TransactionDefinition.PROP
AGATION_REQUIRES_NEW);/事物隔离级别，开启新事务，这样会比较安全些。
TransactionStatus status = txManager.getTransaction(def);
txManager.commit(status);


 
9 不可重复读和幻读的理解
都表现为两次读取的结果不一致。但如果你从控制的角度来看，两者的区别就比较大。
对于前者，原因是有修改，只需要锁住满足条件的记录。
对于后者，原因是有增加或者，要锁住满足条件及其相近的记录。
脏读的含义是读取了没有提交的数据；


10 隔离级别的理解
未提交读：就是一个事务可以读取另一个未提交事务的数据，可以产生脏读，不可重复读和幻读
提交读：就是提交了才能读，可以避免脏读，但是由于没有锁住满足条件的记录和相近的记录，可以出现不可重复读和幻读
可重复读：重复读，就是在开始读取数据（事务开启）时，不再允许修改操作，可能还会有幻读问题。因为幻读问题对应的是插入INSERT操作，而不是UPDATE操作。
串行化顺序执行：最高级别，可以屏蔽所有的问题，但是并发性太差了，不可取。


11  只读事务的理解
spring中readOnly的定义，并不是不能在事务中进行修改等DML操作，它只是一个“暗示”，提示数据库驱动程序
和数据库系统，这个事务并不包含更改数据的操作，那么JDBC驱动程序和数据库就有可能根据这种情况对该事务进行一些特定的优化，比方说不安排相应
的数据库锁，以减轻事务对数据库的压力，毕竟事务也是要消耗数据库的资源的。只读事务仅仅是一个性能优化的推荐配置而已，并非强制你非要这样处理不可
Oracle默认情况下（没有事务）保证了SQL语句级别的读一致性，即在一条SQL语句执行期间，它只会看到执行前点的数据状态，而不会看到执行期间数据被其他SQL改变的状态。所以如果执行多条SQL的时候呢？

比如你做一个报表查询，在执行完第一条sq的时候，执行第二条查询SQL,而这个之间有数据被改变了，第二条数据查询就有可能不一致而Oracle的只读查询则保证了事务级别的读一致性，即在该事务范围内执行的多条SQL都只会看到执行前点的数据状态，而不会看到事务期间的任何被其他SQL改变的状态。没有事务的时候，在执行一条sql语句看到执行前点的数据状态，保证数据一致性只读事务，在执行多条sql语句看到执行前点的数据状态，保证数据一致性。



12 @Transactional
当标于类前时，标示类中所有方法都进行事物处理；当类中某些方法不需要事物时：@Transactional(propagation=Propagation.NOT_SUPPORTED)
noRollbackForClassName该属性用于设置不需要进行回滚的异常类名称数组，当方法中抛出指定异常名称数组中的异常时，不进行事务回滚。


13 spring mvc的原理
底层还是servlet进行封装了，利用action和path主键的映射，做反射机制，反射到method上，进行业务逻辑处理；


14 ApplicationContext父子
ServletContext ServletContext是web应用级的上下文。web容器（比如tomcat、jboss、weblogic等)启动的时候，它会为每个web应用程序创建一个ServletContext对象它代表当前web应用的上下文
（注意：是每个web应用有且仅创建一个ServletContext,一个web应用，就是你一个web工程)。
一个web中的所有servlet共享一个ServletContexti对象，所以可以通过ServletContext对象来实现Servlet之间的通讯。在一个继承自HttpServlet对象的类中，可以通过this.getServletContext:来获取。
web容器启动时，会触发容器初始化事件，此时ContextLoaderListener会监听到这个事件，其contextlnitialized方法会被调用。初始化一个根上下文，即WebApplicationContext,
Spring以WebApplicationContext.ROOTWEBAPPLICATIONCONTEXTATTRIBUTE为属性KeyWebApplicationContextUtils.getWebApplicationContext(ServletContext);
web.xml可以配置多个Servlet,DispatcherServlet:最常见一个，DispatcherServlet_上下文在初始化的时候会建立自己的loC上下文，先从ServletContext中获取之前的根上下文。子上下文可以访问父上下文中的内容，但父上下文不能访问子上下文中的内容。它也保存
在ServletContext中,key是"org.springframework.web.servlet.FrameworkServlet.CONTEXT"+Servlet名称。



15 Log4jConfigListener
可以动态改变记录级别和策略，不需要重启Web应用；.og4 jRefreshlnterval为6表示开一条watchdog:线程每6秒扫描一下配置文件的变化


16 RequestContextListener
支持bean的作用域：request、session和global session监听器监听HTTP请求事件，Web服务器接收的每次请求都会通知该监听器。
HandlerInterceptor http请求拦截器，处理请求之前之后




17 spring设计模式
1)简单工厂模式，spring中的BeanFactory就是简单工厂模式的体现，根据传入一个唯一的标识来获得bean对象有种情况，一种直接是if判断，返回对象；
还有一种模拟springl的机制，init把所有name和对象放在本地缓存里面，直接get就行了，比如getBean()

2)工厂方法模式
将应用程序自己的工厂对象交给Spring管理，那么Spring管理的就不是普通的bean,而是工厂Bean。
<bean
id="random"
class="example.chapter3.StaticFactoryBean"factory-
method="createRandom"scope="prototype"/>
XmlBeanFactory factory new XmlBeanFactory(new
ClassPathResource("config.xml"));
也就是说bean标签支持factory-bean表示指向那个bean,factory-method:表示这个bean的这个方法产生一个对象；
<bean
id="carFactory"
class="com.baobaotao.ditype.CarFactory"/>
<bean id="cr5 factory-bean="carFactoryfac个
method="createCar"/>

3)单例模式
保证一个类仅有一个实例，并提供一个访问它的全局访问点。全局的访问点BeanFactory;Spring下默认的bean均为singleton。

4)动态代理
在Springl的Aop中，使用的Advice(通知)来增强被代理类的功能。Spring:实现这一AOP功能的原理就使用代理模式
1、JDK动态代理。
2、CGLib字节码生成技术代理。
3、对类进行方法级别的切面增强，即，生成被代理类的代理类，并在代理类的方法前，设置拦截器，通过执行拦截器重的内容增强了代理方法的功能，实现的面向切面编程。

5)适配器模式
advice的类型有：BeforeAdvice,AfterReturningAdvice,ThrowsAdvice等，每个类型的通知都有对应的拦截器
BeforeAdvice---MethodBeforeAdvicelnterceptor
AfterReturningAdvice-AfterReturningAdvicelnterceptor
ThrowsAdvice---ThrowsAdvicelnterceptor
如何转换呢？将每个具体的advice封装成对应的拦截器，
返回给容器，这里对advice转换就需要用到适配器模式、
public interface AdvisorAdapter
boolean supportsAdvice(Advice advice);
MethodInterceptor getInterceptor(Advisor advisor);
}
class MethodBeforeAdviceAdapter implements AdvisorAdapter,Serializable
@Override
public boolean supportsAdvice(Advice advice){
return (advice instanceof
MethodBeforeAdvice);
}
@Override
public MethodInterceptor getlnterceptor(Advisor
advisor){
MethodBeforeAdvice advice
(MethodBeforeAdvice)advisor.getAdvice);
return new
MethodBeforeAdvicelnterceptor(advice);
}
}

5) 包装器模式
spring中用到的包装器模式在类名上有两种表现：一种是类名中含有Wrapper,另一种是类名中含有Decorator.。基本上都是动态地给一个对象添加一些额外的职责。

6) 观察者模式
spring中Observer模式常用的地方是listener的实现。如
ApplicationListener,ContextLoaderListener,
监听器模式将对象分为了三个模块：Source(事件源)、ChangeEvent(事件)、StatusListener(监听器)

7) 策略模式
定义一系列的算法，把它们一个个封装起来，并且使它们可相互替换。本模式使得算法可独立于使用它的客户而变化。
在实例化SimplelnstantiationStrategy中有如下代码说明了策略模式的使用情况：

8) 模板方法模式
AbstractPlatformTransactionManager实现了
PlatformTranscationManager:接口
DatasourceTransactionManager,HibernateTransactionM
anagera等继承了AbstractPlatformTransactionManager类
AbstractPlatformTransactionManager类中定义了事务处
理的若干方法。其中获得事务，提交事务，回滚事务由具体的子类实现。
protected abstract Object doGetTransaction(throws
TransactionException;





18 多数据源的切换[AbstractRoutingDataSource]
(1)数据源信息都配置在xml中，MultiDataSource
extends AbstractRoutingDataSource
private static final ThreadLocal<String>dataSourceKey
new InheritableThreadLocal<String>O;
public static void setDataSourceKey(String dataSource)
{
dataSourceKey.set(dataSource);
}
<bean id="dataSource"
class="com.alibaba.druid.pool.DruidDataSource"init-
method="init"destroy-method="close">
</bean>
<bean id="dataSource1"
class="com.alibaba.druid.pool.DruidDataSource"init-
method="init"destroy-method="close">
</bean>
MultiDataSource.setDataSourceKey("dataSource1");
MultiDataSource.toDefaultO;//切换默认注解：DynamicRoutingDataSource.AOP注解实现类
String dataSourceName annotation.valueO;
MultiDataSource.setDataSourceKey(dataSourceName);
@DynamicRoutingDataSource("dataSource1"加到类或者方法上。



19 后置处理器
Spring提供了两种后处理bean的扩展接口，分别为BeanPostProcessor和BeanFactoryPostProcessor,这两者在使用上是有所区别的。
BeanPostProcessor:提供了初始化前和初始化后执行方法，举例我要在某个bean初始化之后注册到适配器中，
如下：
@Override
public Object postProcessAfterlnitialization(Object bean,
String beanName)throws BeansException
if(bean instanceof AdvisorAdapter){
this.advisorAdapterRegistry.registerAdvisorAdapter((Ad
visorAdapter)bean);
}
return bean;
}
比如spring-kafka包中KafkaListenerAnnotationBeanPostProcessor类在实例化之后注册到监听器。
我们定义一个类实现了BeanPostProcessor,默认是会对整个Spring容器中所有的bean进行处理，根据instanceof后者beanName区分是不是你的bean?

问题：BeanPostProcessor和init-method和InitializingBean的区别？执行顺序：
postProcessBeforelnitialization,
然后是afterPropertiesSet
然后是init-method,
然后是postProcessAfterInitialization。

BeanFactoryPostProcessor:BeanFactory:级别的处理，是针对整个Bean的工厂进行处理
我们拿到BeanDefinition对象时，我们可以手动修改bean标签中所定义的属性值，这个BeanDefinition是个什么对象，当我们在xml中定义了bean标签时，Spring
会把这些bean标签解析成一个javabean,这个BeanDefinition就是bean标签对应的javabean。调
用BeanFactoryPostProcess方法时，这时候bean还没有实例化，
刚被解析成BeanDefinition对象。管理我们的bean工厂内所有的beandefinition(未实例化)数据，可以随心所欲的修改属性。
public
void
postProcessBeanFactory(ConfigurableListableBeanFact
ory beanFactory)
for (String beanName getBeanNames(beanFactory))
BeanDefinition definition
getBeanDefinition(beanName,beanFactory);
Stringl dependencies definition.getDependsOnO;
for (String bean dependsOn){
dependencies
=
StringUtils.addStringToArray(dependencies,bean);
}
definition.setDependsOn(dependencies);
}
}
BeanDefinitionRegistryPostProcessor
它扩展自BeanFactoryPostProcessor,在执行BeanFactoryPostProcessor的功能前，提供了可以添加oean definition的能力，允许在初始化一般bean前，注册额外的bean。
例如可以在这里根据bean的scope创建一个新的代理bean。







20 springi源码解析
(1)启动源码和tomcat打通源码，见《实战问题》文档

(2)事务的源码[spring-tx-5.0.7.jar]
DaoSupport---JdbcDaoSupport(持有JdbcTemplate)/HibernateDaoSupport(有HibernateTemplate)
dao异常转  PersistenceExceptionTranslator,PersistenceExcep
tionTranslationPostProcessor将本地资源异常转换
为spring的DataAccessException.及其子类。
PlatformtransactionManager,事务的核心接口，申明回滚提交等方法；
AbstractPlatformTransactionManager:是抽象父类，使用模板方法设计模式，
JtaTransactionManager/JpaTransactionManager/Hiber
nateTransactionManager/JmsTransactionManager/Dat
aSourceTransactionManager是具体的实现类；
TransactionDefinition:接口定义spring容器事务属性的接口，隔离级别，传播特性，DefaultTransactionDefinition默认的实现类；
TransactionStatus:事务状态表现形式
TransactionInterceptor:事务入口拦截器，实现aop的
MethodInterceptor,就是调用父类的的
invokeWithinTransaction,并传递给此方法一个回调用于继续后续的拦截调用这里调用的事务commiti和rollback方法是从事务管理器中拿到对应的实现类，如下所示：
txlnfo.getTransactionManager).commit(txInfo.getTrans
actionStatusO);
整体思路：根据配置也好，注解也好把需要事务的方法扫描到，利用代理，交给TransactionInterceptor处理，Transactionlnterceptori调用对应的Manager执行功能增强。反射机制执行原逻辑。

(3)10C源码
启动Spring容器：ApplicationContext context=new
ClassPathXmlApplicationContext("classpath:application
file.xml");
spring-context会自动将spring-core、spring-
beans、spring-aop、spring-expression这几个基础jar包带进来。
AnnotationConfigApplicationContext是基于注解来使用的，它不需要配置文件，采用java配置类和各种注解来配置，是比较简单的方式，也是大势所趋。
ApplicationContext启动过程中，会负责创建实例
Bean,往各个Bean中注入依赖；ApplicationContext其实就是一个BeanFactory
ListableBeanFactory,这个Listable的意思就是，通过这个接口，我们可以获取多个Bean,最顶层BeanFactory接口的方法都是获取单个Bean的；
AbstractApplicationContext.refresh(的攻读？略过；
/注册也只是将这些信息都保存到了注册中心（说到底核心是一个beanName->beanDefinition的map)
ConfigurableListableBeanFactory beanFactory
obtainFreshBeanFactoryO;
/把BeanFactoryPostProcessor的子类加载到list中，分类
postProcessBeanFactory(beanFactory);
/调用BeanFactoryPostProcessor各个实现类的
postProcessBeanFactory(factory)方法
invokeBeanFactoryPostProcessors(beanFactory);
个两个方法分别在Bean初始化之前和初始化之后得到执行。注意，到这里Bean还没初始化
registerBeanPostProcessors(beanFactory);
BeanDefinition就是我们所说的Spring的Bean,

我们自己定义的各个Bean其实会转换成一个个BeanDefinition存在于Spring的BeanFactory中。所以，如果有人问你Bean是什么的时候，你要知道
Bean在代码层面上是BeanDefinition的实例。
BeanDefinition中保存了我们的Bean信息，比如这个
Bean指向的是哪个类、是否是单例的、是否懒加载、这个Bean依赖了哪些Bean等等。是否允许Bean定义覆盖，是否允许Bean间的循环依赖
protected
void
customizeBeanFactory(DefaultListableBeanFactory
beanFactory){
if (this.allowBeanDefinitionOverriding !null){
beanFactory.setAllowBeanDefinitionOverriding(this.allo
wBeanDefinitionOverriding);
}
if (this.allowCircularReferences !null){
beanFactory.setAllowCircularReferences(this.allowCircu
larReferences);
}
}
就是在配置文件中定义bean时使用了相同的id或name,默认情况下，allowBeanDefinitionOverriding属性为门ull,如果在同一配置文件中重复了，会抛错，但是如果不是同一配置文件中，会发生覆盖。


循环依赖问题：
循环引用也很好理解：A依赖B,而B依赖A。或A依赖B,B依赖C,而C依赖A。
C容器在读到上面的配置时，会按照顺序，先去实例化beanA。然后发现beanA依赖于beanB,接在又去实例化beanB。实例化beanB时，发现beanB又依赖于beanA。
如果容器不处理循环依赖的话，容器会无限执行上面的流程，直到内存溢出，程序崩溃。

当然，Spring是不会让这种情况发生的。在容器再次发现beanB依赖于beanA时，容器会获取beanA对象的一个早期的引引用(early reference),并把这个早期引用注入到beanB
中，让beanB先完成实例化。beanB完成实例化，beanA就可以获取到beanB的引用，beanA随之完成实例化。
这里已经根据一个<bean/>标签产生了一个BeanDefinitionHolder的实例，这个实例里面也就是一个BeanDefintion的实例和它的beanName、aliases这三个信息，注意，我们的关注点始终在BeanDefinition;
/将BeanDefinition放到这个map中，这个map保存了所有的BeanDefinition
this.beanDefinitionMap.put(beanName,beanDefinition);
/这是个ArrayList,所以会按照bean配置的顺序保存每一个注册的Bean的名字
this.beanDefinitionNames.add(beanName);

总结一下，到这里已经初始化了Bean容器，<bean/>配置也相应的转换为了一个个BeanDefinition,然后注册了各个BeanDefinition到注册中心，并且发送了注册事件。
BeanFactory已经创建完成，并且所有的实现了
BeanFactoryPostProcessor接口的Bean都已经初始化并且其中的postProcessBeanFactory(factory)方法已经得到执行了。所有实现了BeanPostProcessor接口的Bean也都完成了初始化。
finishBeanFactorylnitialization(beanFactory);会负责初始化所有的singleton beans。
createBeanInstance(创建Bean实例
populateBean(beanName,mbd,instanceWrapper);依欶注入，属性注入
exposedObject=initializeBean(beanName,exposedobject,mbd);回调方法，BeanPostProcessor两个回调都发生在这边，只不过中间处理了init-method



(4)A0P源码
这么说吧，不用spring aop也可以开发aop编码，利用动态代理技术实现；
spring-aop包已经封装了实现，实际是一个工具包，而且spring事务也是用的自己的工具包
如果遇到注解审计日志的话，可以直接用起来寻找<aop:aspectj-autoproxy,/>注解对应的解析器
AopNamespaceHandler
registerBeanDefinitionParser("aspectj-autoproxy",
new AspectJAutoProxyBeanDefinitionParserO);
AspectJAutoProxyBeanDefinitionParser:主要的功能就是
将AnnotationAwareAspectJAutoProxyCreator注册到Spring:容器中，把bean交给Spring:去托管。
AnnotationAwareAspectJAutoProxyCreator类的
postProcessAfterInitialization)方法将所有有advice的bean重新包装成proxy;
AbstractAutoProxyCreator.wraplfNecessary(Object
bean,String beanName,Object cacheKey)中的createProxy(代码片段分析：

ProxyFactory-调用jdk或者cglib的方法。实际就是为bean创建一个proxy,JDKproxy或
者CGLIBproxy,然后在调用bean的方法时，会通过proxy来调用bean方法

重点过程可分为：
1)通过AspectJAutoProxyBeanDefinitionParser类将AnnotationAwareAspectJAutoProxyCreator注册到Spring容器中

2)AnnotationAwareAspectJAutoProxyCreator类的postProcessAfterInitialization()方法将所有有advice的bean重新包装成proxy

3)调用bean方法时通过proxy:来调用，proxy依次调用增强器的相关方法，来实现方法切入
思路：我自定义一个注解，凡是使用了before做一些操作，after做一些操作，想到代理了。

(5)Spring MVC源码
HttpServletBean继承HttpServlet,在servlet启动时会执行其init方法。
底层还是servleti进行封装了，利用action:和path主键的映射，做反射机制，反射到method上，进行业务逻辑处理；






###AbstractRoutingDataSource
动态数据源切换，重写determineCurrentLookupKey方法，把routingKey设置进去。
注解aop扫描注解，读取注解的key,切换当前ds为对应的

###匿名类复写，实例初始化块
private static final ThreadLocalkObject>initLocal new
ThreadLocal<Object>(
{
{
set(55);
}
protected Object initialValue){return 666;;
定义了1个ThreadLocalkInteger>对象，并复写它的initialValue方法，初始值是66，
外层的一组“”表示的是一个匿名类，内层的一对“”表示的是实例初始化块，实例初始化块的代码在编译器编译过后，是放在类的构造函数里面的，并且是在原构造函数代码的前面。

###snakeyaml.Yaml
解析yaml工具类
###
CommandLineRunner,ApplicationRunner,SpringAr:
cationRunListener,ApplicationContextlnitializer,个
cationListener区别






###
CommandLineRunner,ApplicationRunner,SpringApplicationRunListener,ApplicationContextlnitializer,ApplicationListener区别
ApplicationContextlnitializer是在springboot启动过程(refresh方法前)调用，比如事先加载apollo;
SpringApplicationRunListener.观察者模式，环境加载，上下文准备，加载等事件。
CommandLineRunner/ApplicationRunner接口都是在容器启动成功后的最后一步回调（类似开机自启动）。
ApplicationListener:启动监听器，带一个具体事件；


###使用Serializable类型参数做方法的形参
这里是应用了java的多态性。目的是为了灵活的传入参数：
对于Serializable接口，java的包装类型(Integer,Long,String,Double.…)几乎都实现了这个接口.
用Serializable来定义id的类型，是使用的接口类型实际调用这个方法时候可以传递Integer,Long,String等类型，或者实现了Serializable接口的类

public interface BaseService<T>extends IService<T>{
<D>D fetchByld(Serializable id,Class<D>dto);
查询出来的结果是T类型，形参是D类型的DTO,中间做出了转换。
IService是mybatis-plus基础的CRUD接口，但是没有转换DTO,所以BaselService:继承，申明自己的方法。
T在接口中申明了，方法可以直接用D saved(Ddto);如果没有神明需要写成<D extends BaseDto:>D save∽dto);



###公认规范
BizResult:包含结果码，结果描述，object;
BizOptional:是可以序列化的Optional
BeanUtils:springl的工具类，支持拷贝对象属性，
CORS:跨域的浏览器会让请求带Origin头，表明来自哪里的跨域请求
Origin:http://foo.example123
响应方的response【必须】有Access-Control-Allow-
Origin:上面origin的地址，表明允许跨域访问
JacksonConfig:返回一个ObjectMapper对象，覆盖日期格式，时间日期序列化和反序列化，注册
SimpleModule模式，对String做html转义，以防XSS
String str objectMapper.writeValueAsString(object);


###spring-boot-maven-plugin
Spring Boot的Maven:插件(Spring Boot Maven plugin)能够以Maven的方式为应用提供Spring Boot的支持，即为Spring Boot应用提供了执行Maven操作的可能。
Spring Boot Maven plugin能够将Spring Boot)应用打包为可执行的jar或war文件，然后以通常的方式运行SpringBoot应用。
5个Goals:
spring-boot:repackage,默认goal。在mvn package之后，再次打包可执行的jar/war,同时保留mvn package生成的jar/war为.origin
?spring-boot:run,运行Spring Boot)应用
?spring-boot:start,在mvn integration-test阶段，进行Spring Boot应用生命周期的管理
?spring-boot:stop,在mvn integration-test阶段，行Spring Boot应用生命周期的管理






<beans default-lazy="true">
懒加载说明 SpringContextHolder加上 @Lazy(false) ,否则不能注入 applicationContext 

<context:component-scan  base-package 全量扫
<bean>是某个bean

slf4j 和 log4j几个包
log-4j-1.2.jar/  slf4j-api.jar /  slf4j-log4j12.jar 
如果加入springboot的logback之后 一直循环栈溢出，把logback包剔除即可。





---------------------------------------------------------------------------------------------------------------
------------------------------------------Spring.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------Storm.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------





@美国推特twitter出品，分布式、可靠的、容错的实时大数据处理框架，对Hadoop的MapReduce高延迟无法容忍，比如网站统计、推荐系统、预警系统、金融系统（高频交易、股票大数据实时处理解决方案呼之欲出。每秒可以处理一百万组单元数据，多语言，


@一连串的bolt之间转换spout传过来的数据语句Spout->语句分割Bolt->单词计数Bolt->上报Bolt
Hadoop的MapReduce作业最终会结束，Storm的Topology:会一直运行（除非显示的杀掉它）。


@组件
Nimbus主节点-Supervisor从节点--Worker.工作进程-Task
Nimbusi通过Zookeeper发布任务、管理节点、监控集群状态、统计信息。
Supervisor通过ZooKeeper注册节点状态、领取任务。
Nimbus和Supervisor之间通过ZeroMQ传递消息和数据。
supervisor(节点)>worker(JVM进程)>executor(线程)>task(spout、bolt实例)提高storm的并行度：增加work进程(storm.yaml参数是supervisor.slots.port),增加executor线程，增加task实例
storm rebalance mytopology -w 10 -n 2 -e spout=2 -e
bolt=2表示10秒之后对nytopology进行并行度调整。把spouti调整为2个executor,把bolt调整为2个executor.。



@Reliability:可靠性。Storm可以通过拓扑来确保色发送的元组都能得到正确处理。通过跟踪由Spout发出的
每个元组构成的元组树可以确定元组是否已经完成处理。
每个拓扑都有一个“消息延时”参数，如果Stom在延时时间内没有检测到元组是否处理完成，就会将该元组标记为处理失败，并会在稍后重新发送该元组。高容错，当处理任务死亡时，storm将会自动重新启动他们，如果一个节点服务器死亡时，stom将会自动把处理任务在其他节点服务器运行。强制实行kll-9命令杀死storm进程，也不会影响你的拓扑正常运行


@Storm和Spark
纯实时，准实时（一段时间之内的RDD),Stom支持动态调整并行度计算延迟度毫秒级但是吞吐量低，延迟度秒级吞吐量高擅长的细分场景并不相同，
它位于Spark生态技术栈中，因此Spark Streaming可以和Spark Core、Spark SQL无缝整合


@ITransactionalSpout传统事务->IPartitionedTransactionalSpout分区事务->lOpaquePartitionedTransactionalSpout.不透明分区事务
把tuple封装成batch进行处理，同时可以保证每一个tuple都被完整地处理，每一个批次(batch)提供一个唯一的事务D
只出现在当某一批次消息消费失败需要重发且恰巧消息中间件故障时这时，IOpaquePartitionedTransactionalSpout不是等待消息中间件故障恢复，而是先读取可读的partition。


@数据分发策略
随机分组，字段分组，广播分组


@本地调试方式和远程集群模式
Netty提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。正好是storm所需要的ZeroMQ不是传统意义上的MQ。
它比较适用于节点之间和节点与Master之间的通信。Storm在0.8之前的Worker之间的通信就是通过ZeroMQ。
但是为什么0.9就是用Netty替代了ZeroMQ呢？说替代不大合适，只是0.9的默认的Worker之间的通信是使用了Netty,ZeroMQ还是支持的。



---------------------------------------------------------------------------------------------------------------
------------------------------------------Storm.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------





---------------------------------------------------------------------------------------------------------------
------------------------------------------ZooKeeper.txt   start-------------------------------------------
---------------------------------------------------------------------------------------------------------------


@谷歌开源实现，基数台原理，超过一半机器正常，集群可以工作，如果3台有2台。


@命名服务，集群管理，分布式锁，分布式配置（几乎不用springcloud config.或者apollo,watch功能)，消息队列（几乎不用，kafka)


@命名服务3个含义
1)命名服务(AP目录服务)：通过指定的名字来获取资源或者服务的地址，树形分层储存AP的地址和名称，
dubbo的注册中心，/dubbo/S{serviceName}/providers服务提供者在启动的时候，向ZK上的指定节点/dubbo./S{serviceName}/providers文件夹下写入自己的URL地址，
这个操作就完毕了服务的公布。服务消费者启动的时候。
订阅/dubbo/{serviceName}/providers文件夹下的提供者URL地址，并向/dubbo,/{serviceName}/consumers文件夹下写入自己的URL地址。
注意，全部向ZK上注冊的地址都是暂时节点。这样就行保证服务提供者和消费者可以自己主动感应资源的变化，每次重启服务把最新的服务写上。
同理，kafkal的topic,生产消费端。

2)分布式1D生成器：创顺序节点，返回序号，后10位。


@节点
create/yujie-persistent"/创建持久节点（有动作)
create-e/yujie-ephemeral"/创建l临时节点（和客！个会话绑定，失效自动清除)qet命令有一个l临时拥有者ephemeralOwner.,有值就是回话D,O的话就是持久节点。

@ZNode
ZNode有领导者，和跟随者，每个ZNode都有数据节点(持久和临时)
stat.此为状态信息，描述该znode的版本，权限等信息
data.与该znode关联的数据，每个结点的数据大小的上限是1Mchildren.该znode下的子节点.

@分布式集群管理
机器退出、机器加入、选举master所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为master

@工作原理
Zab协议，崩溃恢复和消息广播
当Leader服务器出现网络中弄断、崩溃退出或重启等异常时，Zab协议就会进入崩溃恢复模式，选举产生新的
Leader
当选举产生了新的Leader,同时集群中有过半的机器与该Leader服务器完成了状态同步（即数据同步）之后，Zab协议就会退出崩溃恢复模式，进入消息广播模式。


@分布式锁(Redis也可以)
分布式环境下，保护跨进程、跨主机、跨网络的共享资源，实现互斥访问，保证一致性。
2种思路
一是client获取锁的时候在locker节点下创建临时顺序节点，在释放锁的时候，把自己创建的节点。
二是都去创建临时顺序节点，如果发现有比自己小的等待锁，如果没有发现比自己序号小的获得锁。
	zk.create(root,data,ZooDefs.lds.OPEN_ACL_UNS个CreateMode.PERSISTENT);-都去创建
	latch.awaitO;//等待，这里应该一直等待其他线程释放锁

当Leader服务器出现网络中弄断、朋溃退出或重后等异常时，Zab协议就会进入崩溃恢复模式，选举产生新的Leader
当选举产生了新的Leader,同时集群中有过半的机器与该Leader服务器完成了状态同步（即数据同步）之后，Zab协议就会退出崩溃恢复模式，进入消息广播模式。


@分布式队列
实现原理：创建持久性的顺序节点(zookeeper.create(dir+"/"+prefix,data,acl,CreateMode.PERSISTENT_SEQUENTIAL);
出队：将最小的结点出队（也就是在服务端结点最小的结点)


@ZK的订阅-发布功能，观察者模式，观察者会订阅一些
感兴趣的主题，然后这些主题一旦变化了，就会自动通知到这些观察者。客户端注册，服务端发回事件，客户端回调。
连接事件：建立会话，创建节点，节点，修改节点，子节点变化；
其他事件：会话超时，断开连接，身份出错。






cd /home/hiya03/softwares/zookeeper-3.4.14
tar -zxvf zookeeper-3.4.14.tar.gz

cd zookeeper-3.4.14/conf
cp  zoo_sample.cfg  zoo.cfg

vim zoo.cfg
dataDir=/home/hiya03/softwares/zookeeper-3.4.14/data
dataLogDir=/home/hiya03/softwares/zookeeper-3.4.14/log
server.1=192.168.1.111:2888:3888
server.2=192.168.1.112:2888:3888
server.3=192.168.1.113:2888:3888

cd /home/hiya03/softwares/zookeeper-3.4.14/data
touch myid
vim myid
在192.168.180.132上，“myid”文件内容就是1。在192.168.180.133上，内容就是2。


export ZOOKEEPER_INSTALL=/home/hiya03/softwares/zookeeper-3.4.14/zookeeper-3.4.14/
export PATH=$PATH:$ZOOKEEPER_INSTALL/bin


#如果不关闭防火墙 启动失败：java.net.NoRouteToHostException: 没有到主机的路由”
systemctl status firewalld.service
systemctl stop firewalld.service
systemctl disable firewalld.service


cd /home/hiya03/softwares/zookeeper-3.4.14/zookeeper-3.4.14/bin
./zkServer.sh start
./zkServer.sh start-foreground  #查看日志 ，或者在 bin/zookeeper.out查看 
./zkServer.sh stop
./zkServer.sh restart
./zkServer.sh status




命名服务，集群管理，分布式锁，分布式配置（几乎不用，spring cloud config或者apollo）,消息队列（几乎不用，kafka）


zk的服务自注册中心是根据命名服务原理实现
dubbo的注册中心，/dubbo/${serviceName}/providers
服务提供者在启动的时候，向ZK上指定节点指定/dubbo/${serviceName}/providers 文件夹写入自己的URL地址，这个操作完毕了服务的公布。
服务消费者启动的时候，订阅 /dubbo/${serviceName}/providers下的服务，向/dubbo/${serviceName}/consumers文件夹下面写入自己的URL地址。
注意：向ZK上面注册的是暂时节点，这样保证提供者和消费者可以自己主动感应资源的变化。
同理，kafka也是一样样。


zk命名服务吗，类似JNDI的功能；
利用zk的树形分层结构，把服务名称，地址以及目录信息存储，需要的时候去zk读取



zk分布式ID生成器，创建顺序节点，返回序列，后10位
同理uuid和雪花推特是一样的。


选主机制：
优先检查ZXID，ZXID大的作为leader;
如果ZXID相同，比较myid, myid大的作为leader;


zk分布式锁：
创建一个用于发号的节点"test/lock" ， 可以在这个父节点下创建相同的前缀节点，
创建子节点的时候，同时指定有序类型，可以排序比较，节点编号最小的那个获得锁。







---------------------------------------------------------------------------------------------------------------
------------------------------------------ZooKeeper.txt   end-------------------------------------------
---------------------------------------------------------------------------------------------------------------


